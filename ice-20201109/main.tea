/**
 *
 */
import Util;
import OpenApi;
import OpenApiUtil;
import EndpointUtil;

extends OpenApi;


init(config: OpenApi.Config){
  super(config);
  @signatureAlgorithm = 'v2';
  @endpointRule = 'regional';
  @endpointMap = {
    ap-northeast-1 = 'ice.aliyuncs.com',
    ap-northeast-2-pop = 'ice.aliyuncs.com',
    ap-south-1 = 'ice.aliyuncs.com',
    ap-southeast-1 = 'ice.aliyuncs.com',
    ap-southeast-2 = 'ice.aliyuncs.com',
    ap-southeast-3 = 'ice.aliyuncs.com',
    ap-southeast-5 = 'ice.aliyuncs.com',
    cn-beijing = 'ice.aliyuncs.com',
    cn-beijing-finance-1 = 'ice.aliyuncs.com',
    cn-beijing-finance-pop = 'ice.aliyuncs.com',
    cn-beijing-gov-1 = 'ice.aliyuncs.com',
    cn-beijing-nu16-b01 = 'ice.aliyuncs.com',
    cn-chengdu = 'ice.aliyuncs.com',
    cn-edge-1 = 'ice.aliyuncs.com',
    cn-fujian = 'ice.aliyuncs.com',
    cn-haidian-cm12-c01 = 'ice.aliyuncs.com',
    cn-hangzhou = 'ice.aliyuncs.com',
    cn-hangzhou-bj-b01 = 'ice.aliyuncs.com',
    cn-hangzhou-finance = 'ice.aliyuncs.com',
    cn-hangzhou-internal-prod-1 = 'ice.aliyuncs.com',
    cn-hangzhou-internal-test-1 = 'ice.aliyuncs.com',
    cn-hangzhou-internal-test-2 = 'ice.aliyuncs.com',
    cn-hangzhou-internal-test-3 = 'ice.aliyuncs.com',
    cn-hangzhou-test-306 = 'ice.aliyuncs.com',
    cn-hongkong = 'ice.aliyuncs.com',
    cn-hongkong-finance-pop = 'ice.aliyuncs.com',
    cn-huhehaote = 'ice.aliyuncs.com',
    cn-huhehaote-nebula-1 = 'ice.aliyuncs.com',
    cn-north-2-gov-1 = 'ice.aliyuncs.com',
    cn-qingdao = 'ice.aliyuncs.com',
    cn-qingdao-nebula = 'ice.aliyuncs.com',
    cn-shanghai-et15-b01 = 'ice.aliyuncs.com',
    cn-shanghai-et2-b01 = 'ice.aliyuncs.com',
    cn-shanghai-finance-1 = 'ice.aliyuncs.com',
    cn-shanghai-inner = 'ice.aliyuncs.com',
    cn-shanghai-internal-test-1 = 'ice.aliyuncs.com',
    cn-shenzhen = 'ice.aliyuncs.com',
    cn-shenzhen-finance-1 = 'ice.aliyuncs.com',
    cn-shenzhen-inner = 'ice.aliyuncs.com',
    cn-shenzhen-st4-d01 = 'ice.aliyuncs.com',
    cn-shenzhen-su18-b01 = 'ice.aliyuncs.com',
    cn-wuhan = 'ice.aliyuncs.com',
    cn-wulanchabu = 'ice.aliyuncs.com',
    cn-yushanfang = 'ice.aliyuncs.com',
    cn-zhangbei = 'ice.aliyuncs.com',
    cn-zhangbei-na61-b01 = 'ice.aliyuncs.com',
    cn-zhangjiakou = 'ice.aliyuncs.com',
    cn-zhangjiakou-na62-a01 = 'ice.aliyuncs.com',
    cn-zhengzhou-nebula-1 = 'ice.aliyuncs.com',
    eu-central-1 = 'ice.aliyuncs.com',
    eu-west-1 = 'ice.aliyuncs.com',
    eu-west-1-oxs = 'ice.aliyuncs.com',
    me-east-1 = 'ice.aliyuncs.com',
    rus-west-1-pop = 'ice.aliyuncs.com',
    us-east-1 = 'ice.aliyuncs.com',
    us-west-1 = 'ice.aliyuncs.com',
  };

  checkConfig(config);
  @endpoint = getEndpoint('ice', @regionId, @endpointRule, @network, @suffix, @endpointMap, @endpoint);
}

function getEndpoint(productId: string, regionId: string, endpointRule: string, network: string, suffix: string, endpointMap: map[string]string, endpoint: string) throws: string{
  if (!Util.empty(endpoint)) {
    return endpoint;
  }
  
  if (!Util.isUnset(endpointMap) && !Util.empty(endpointMap[regionId])) {
    return endpointMap[regionId];
  }
  return EndpointUtil.getEndpointRules(productId, regionId, endpointRule, network, suffix);
}

model AIAgentRuntimeConfig {
  avatarChat3D?: {
    agentUserId?: string(name='AgentUserId'),
    authToken?: string(name='AuthToken'),
    channelId?: string(name='ChannelId'),
  }(name='AvatarChat3D'),
  visionChat?: {
    agentUserId?: string(name='AgentUserId'),
    authToken?: string(name='AuthToken'),
    channelId?: string(name='ChannelId'),
  }(name='VisionChat'),
  voiceChat?: {
    agentUserId?: string(name='AgentUserId'),
    authToken?: string(name='AuthToken'),
    channelId?: string(name='ChannelId'),
  }(name='VoiceChat'),
}

model AIAgentTemplateConfig {
  avatarChat3D?: {
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    avatarId?: string(name='AvatarId'),
    bailianAppParams?: string(name='BailianAppParams'),
    enableIntelligentSegment?: boolean(name='EnableIntelligentSegment'),
    enablePushToTalk?: boolean(name='EnablePushToTalk'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    gracefulShutdown?: boolean(name='GracefulShutdown'),
    greeting?: string(name='Greeting'),
    llmHistory?: [ 
      {
        content?: string(name='Content'),
        role?: string(name='Role'),
      }
    ](name='LlmHistory'),
    llmHistoryLimit?: int32(name='LlmHistoryLimit'),
    maxIdleTime?: int32(name='MaxIdleTime'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    voiceId?: string(name='VoiceId'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
    wakeUpQuery?: string(name='WakeUpQuery'),
    workflowOverrideParams?: string(name='WorkflowOverrideParams'),
  }(name='AvatarChat3D'),
  visionChat?: {
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    bailianAppParams?: string(name='BailianAppParams'),
    enableIntelligentSegment?: boolean(name='EnableIntelligentSegment'),
    enablePushToTalk?: boolean(name='EnablePushToTalk'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    gracefulShutdown?: boolean(name='GracefulShutdown'),
    greeting?: string(name='Greeting'),
    llmHistory?: [ 
      {
        content?: string(name='Content'),
        role?: string(name='Role'),
      }
    ](name='LlmHistory'),
    llmHistoryLimit?: int32(name='LlmHistoryLimit'),
    maxIdleTime?: int32(name='MaxIdleTime'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    voiceId?: string(name='VoiceId'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
    wakeUpQuery?: string(name='WakeUpQuery'),
    workflowOverrideParams?: string(name='WorkflowOverrideParams'),
  }(name='VisionChat'),
  voiceChat?: {
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    avatarUrl?: string(name='AvatarUrl'),
    avatarUrlType?: string(name='AvatarUrlType'),
    bailianAppParams?: string(name='BailianAppParams'),
    enableIntelligentSegment?: boolean(name='EnableIntelligentSegment'),
    enablePushToTalk?: boolean(name='EnablePushToTalk'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    gracefulShutdown?: boolean(name='GracefulShutdown'),
    greeting?: string(name='Greeting'),
    llmHistory?: [ 
      {
        content?: string(name='Content'),
        role?: string(name='Role'),
      }
    ](name='LlmHistory'),
    llmHistoryLimit?: int32(name='LlmHistoryLimit'),
    maxIdleTime?: int32(name='MaxIdleTime'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    voiceId?: string(name='VoiceId'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
    wakeUpQuery?: string(name='WakeUpQuery'),
    workflowOverrideParams?: string(name='WorkflowOverrideParams'),
  }(name='VoiceChat'),
}

model AppInfoDTO {
  appName?: string(name='AppName'),
  appType?: int32(name='AppType', example='1-普通应用，2-内嵌SDK.'),
  gmtCreate?: string(name='GmtCreate'),
  itemId?: string(name='ItemId'),
  platforms?: [ 
    {
      itemId?: string(name='ItemId'),
      licenseItemIds?: [ string ](name='LicenseItemIds'),
      pkgName?: string(name='PkgName'),
      pkgSignature?: string(name='PkgSignature'),
      platformType?: long(name='PlatformType'),
      type?: long(name='Type'),
    }
  ](name='Platforms'),
  userId?: long(name='UserId'),
}

model Channel {
  accessPolicy?: boolean(name='AccessPolicy'),
  accessToken?: string(name='AccessToken'),
  arn?: string(name='Arn'),
  channelName?: string(name='ChannelName'),
  channelTier?: string(name='ChannelTier'),
  fillerSourceLocationName?: string(name='FillerSourceLocationName'),
  fillerSourceName?: string(name='FillerSourceName'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  outPutConfigList?: [ 
    {
      channelName?: string(name='ChannelName'),
      format?: string(name='Format'),
      manifestName?: string(name='ManifestName'),
      manifestSettings?: string(name='ManifestSettings'),
      playbackUrl?: string(name='PlaybackUrl'),
      sourceGroupName?: string(name='SourceGroupName'),
    }
  ](name='OutPutConfigList'),
  playbackMode?: string(name='PlaybackMode'),
  state?: int32(name='State'),
}

model LicenseInstanceAppDTO {
  appId?: string(name='AppId'),
  beginOn?: string(name='BeginOn'),
  contractNo?: string(name='ContractNo'),
  creationTime?: string(name='CreationTime'),
  expiredOn?: string(name='ExpiredOn'),
  instanceId?: string(name='InstanceId'),
  itemId?: string(name='ItemId'),
  licenseConfigs?: [ 
    {
      businessType?: string(name='BusinessType'),
      featureIds?: string(name='FeatureIds'),
      sdkId?: int32(name='SdkId'),
      sdkName?: string(name='SdkName'),
      subscription?: string(name='Subscription'),
      subscriptionImp?: string(name='SubscriptionImp'),
      subscriptionPkg?: string(name='SubscriptionPkg'),
    }
  ](name='LicenseConfigs'),
  modificationTime?: string(name='ModificationTime'),
  status?: string(name='Status'),
  userId?: long(name='UserId'),
}

model Program {
  adBreaks?: [ 
    {
      channelName?: string(name='ChannelName'),
      messageType?: string(name='MessageType'),
      offsetMillis?: long(name='OffsetMillis'),
      programName?: string(name='ProgramName'),
      sourceLocationName?: string(name='SourceLocationName'),
      sourceName?: string(name='SourceName'),
      spliceInsertSettings?: string(name='SpliceInsertSettings'),
      timeSignalSettings?: string(name='TimeSignalSettings'),
    }
  ](name='AdBreaks'),
  arn?: string(name='Arn'),
  channelName?: string(name='ChannelName'),
  clipRange?: string(name='ClipRange'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  programName?: string(name='ProgramName'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
  transition?: string(name='Transition'),
}

model ScheduleData {
  adBreaks?: [ 
    {
      messageType?: string(name='MessageType'),
      offsetMillis?: string(name='OffsetMillis'),
      sourceLocationName?: string(name='SourceLocationName'),
      sourceName?: string(name='SourceName'),
      spliceInsertSettings?: string(name='SpliceInsertSettings'),
      timeSignalSettings?: string(name='TimeSignalSettings'),
    }
  ](name='AdBreaks'),
  approximateDurationSeconds?: long(name='ApproximateDurationSeconds'),
  approximateStartTime?: string(name='ApproximateStartTime'),
  entryType?: string(name='EntryType'),
  programName?: string(name='ProgramName'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
}

model Source {
  arn?: string(name='Arn'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  httpPackageConfigurations?: string(name='HttpPackageConfigurations'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
  state?: int32(name='State'),
}

model SourceLocation {
  arn?: string(name='Arn'),
  baseUrl?: string(name='BaseUrl'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  segmentDeliveryConfigurations?: string(name='SegmentDeliveryConfigurations'),
  sourceLocationName?: string(name='SourceLocationName'),
  state?: int32(name='State'),
}

model AddCategoryRequest {
  cateName?: string(name='CateName', description='The category name.

*   The value can be up to 64 bytes in length.
*   The value must be encoded in UTF-8.

This parameter is required.'),
  parentId?: long(name='ParentId', description='The ID of the parent category.', example='5'),
  type?: string(name='Type', description='The type of the category. Valid values:

*   default: audio, video, and image files. This is the default value.
*   material: short video materials.', example='default'),
}

model AddCategoryResponseBody = {
  category?: {
    cateId?: long(name='CateId', description='The ID of the created category.', example='45'),
    cateName?: string(name='CateName', description='The category name.'),
    level?: long(name='Level', description='The level of the category. A value of **0** indicates a level-1 category, a value of **1** indicates a level-2 category, and a value of **2** indicates a level-3 category.', example='0'),
    parentId?: long(name='ParentId', description='The ID of the parent category. By default, if ParentId is left empty or less than 1, -1 is returned, which indicates that the created category is the root directory.', example='-1'),
    type?: string(name='Type', description='The type of the category. Valid values:

*   **default**: audio, video, and image files. This is the default value.
*   **material**: short video materials.', example='default'),
  }(name='Category', description='The information about the category.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model AddCategoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddCategoryResponseBody(name='body'),
}

/**
 * @summary Creates a category.
 *
 * @description You can create at most three levels of categories. Each category level can contain a maximum of 100 subcategories.
 *
 * @param request AddCategoryRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AddCategoryResponse
 */
async function addCategoryWithOptions(request: AddCategoryRequest, runtime: Util.RuntimeOptions): AddCategoryResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.cateName)) {
    query['CateName'] = request.cateName;
  }
  if (!Util.isUnset(request.parentId)) {
    query['ParentId'] = request.parentId;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'AddCategory',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Creates a category.
 *
 * @description You can create at most three levels of categories. Each category level can contain a maximum of 100 subcategories.
 *
 * @param request AddCategoryRequest
 * @return AddCategoryResponse
 */
async function addCategory(request: AddCategoryRequest): AddCategoryResponse {
  var runtime = new Util.RuntimeOptions{};
  return addCategoryWithOptions(request, runtime);
}

model AddEditingProjectMaterialsRequest {
  materialMaps?: string(name='MaterialMaps', description='The material ID. Separate multiple material IDs with commas (,). Each type supports up to 10 material IDs. The following material types are supported:

*   video
*   audio
*   image
*   liveStream
*   editingProject

This parameter is required.', example='{"video":"*****2e057304fcd9b145c5cafc*****", "image":"****8021a8d493da643c8acd98*****,*****cb6307a4edea614d8b3f3c*****", "liveStream": "[{\\\\"appName\\\\":\\\\"testrecord\\\\",\\\\"domainName\\\\":\\\\"test.alivecdn.com\\\\",\\\\"liveUrl\\\\":\\\\"rtmp://test.alivecdn.com/testrecord/teststream\\\\",\\\\"streamName\\\\":\\\\"teststream\\\\"}]", "editingProject": "*****9b145c5cafc2e057304fcd*****"}'),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='*****b2101cb318c*****'),
}

model AddEditingProjectMaterialsResponseBody = {
  liveMaterials?: [ 
    {
      appName?: string(name='AppName', description='The application name of the live stream.', example='testrecord'),
      domainName?: string(name='DomainName', description='The domain name of the live stream.', example='test.alivecdn.com'),
      liveUrl?: string(name='LiveUrl', description='The URL of the live stream.', example='rtmp://test.alivecdn.com/testrecord/teststream'),
      streamName?: string(name='StreamName', description='The name of the live stream.', example='teststream'),
    }
  ](name='LiveMaterials', description='The materials associated with the live stream.'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
            duration?: string(name='Duration', description='The duration.', example='216.206667'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
            fileStatus?: string(name='FileStatus', description='The file status.

\\\\-Uploading

\\\\-Normal

\\\\-UploadFail

\\\\-Disable

\\\\-Deleted', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='540'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='960'),
          }(name='FileBasicInfo', description='The basic information of the file, including the duration and size.'),
        }
      ](name='FileInfoList', description='FileInfos'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.', example='audio'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-23T03:32:59Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-23T03:32:59Z'),
        description?: string(name='Description', description='The description of the media asset.', example='sample_description'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/file.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****5cb2e35433198daae94a72*****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='sample_tag'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='Video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-23T03:32:59Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='null'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite of the media asset.', example='http://outin-example.oss-cn-shanghai.aliyuncs.com/test.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        status?: string(name='Status', description='The status of the media asset. Valid values:

\\\\- Init

\\\\- Preparing

\\\\- PrepareFail

\\\\- Normal', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.', example='default_title_2020-12-23T03:32:59Z'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information of the media assets.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****5cb2e35433198daae94a72*****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='*****67ae06542b9b93e0d1c387*****'),
  projectMaterials?: [ string ](name='ProjectMaterials', description='The materials associated with the editing project. A live stream editing project will be associated with a regular editing project after the live streaming ends.', example='*****9b145c5cafc2e057304fcd*****'),
  requestId?: string(name='RequestId', description='The request ID.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
}

model AddEditingProjectMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddEditingProjectMaterialsResponseBody(name='body'),
}

/**
 * @summary Adds one or more materials to an online editing project.
 *
 * @param request AddEditingProjectMaterialsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AddEditingProjectMaterialsResponse
 */
async function addEditingProjectMaterialsWithOptions(request: AddEditingProjectMaterialsRequest, runtime: Util.RuntimeOptions): AddEditingProjectMaterialsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.materialMaps)) {
    query['MaterialMaps'] = request.materialMaps;
  }
  if (!Util.isUnset(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'AddEditingProjectMaterials',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Adds one or more materials to an online editing project.
 *
 * @param request AddEditingProjectMaterialsRequest
 * @return AddEditingProjectMaterialsResponse
 */
async function addEditingProjectMaterials(request: AddEditingProjectMaterialsRequest): AddEditingProjectMaterialsResponse {
  var runtime = new Util.RuntimeOptions{};
  return addEditingProjectMaterialsWithOptions(request, runtime);
}

model AddFavoritePublicMediaRequest {
  mediaIds?: string(name='MediaIds', example='icepublic-****7213c6050cbc66750b469701****,icepublic-****0b4697017213c6050cbc6675****'),
}

model AddFavoritePublicMediaResponseBody = {
  ignoredList?: [ string ](name='IgnoredList'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model AddFavoritePublicMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddFavoritePublicMediaResponseBody(name='body'),
}

/**
 * @summary 收藏公共媒资
 *
 * @param request AddFavoritePublicMediaRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AddFavoritePublicMediaResponse
 */
async function addFavoritePublicMediaWithOptions(request: AddFavoritePublicMediaRequest, runtime: Util.RuntimeOptions): AddFavoritePublicMediaResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaIds)) {
    query['MediaIds'] = request.mediaIds;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'AddFavoritePublicMedia',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 收藏公共媒资
 *
 * @param request AddFavoritePublicMediaRequest
 * @return AddFavoritePublicMediaResponse
 */
async function addFavoritePublicMedia(request: AddFavoritePublicMediaRequest): AddFavoritePublicMediaResponse {
  var runtime = new Util.RuntimeOptions{};
  return addFavoritePublicMediaWithOptions(request, runtime);
}

model AddMediaMarksRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='53afdf003a2171ed9c6a16b5feac6402'),
  mediaMarks?: string(name='MediaMarks', description='The mark information. The value must be a JSONArray.

This parameter is required.'),
}

model AddMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='53afdf003a******6a16b5feac6402'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The IDs of the marks that are added.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
  requestId?: string(name='RequestId', description='The request ID.', example='771A1414-27BF-53E6-AB73-EFCB*****ACF'),
}

model AddMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddMediaMarksResponseBody(name='body'),
}

/**
 * @summary Adds marks for a media asset.
 *
 * @param request AddMediaMarksRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AddMediaMarksResponse
 */
async function addMediaMarksWithOptions(request: AddMediaMarksRequest, runtime: Util.RuntimeOptions): AddMediaMarksResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.mediaMarks)) {
    query['MediaMarks'] = request.mediaMarks;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'AddMediaMarks',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Adds marks for a media asset.
 *
 * @param request AddMediaMarksRequest
 * @return AddMediaMarksResponse
 */
async function addMediaMarks(request: AddMediaMarksRequest): AddMediaMarksResponse {
  var runtime = new Util.RuntimeOptions{};
  return addMediaMarksWithOptions(request, runtime);
}

model AddTemplateRequest {
  config?: string(name='Config', example='参见Timeline模板Config文档'),
  coverUrl?: string(name='CoverUrl', description='The URL of the template thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
  name?: string(name='Name', description='The name of the custom template.', example='视频添加水印模板'),
  previewMedia?: string(name='PreviewMedia', description='The ID of the template preview video.', example='****01bf24bf41c78b2754cb3187****'),
  relatedMediaids?: string(name='RelatedMediaids', description='The IDs of the materials associated with the template for use by the regular template editor.', example='{"video":["1805a0c6ca544fb395a06ca683619655"]}'),
  source?: string(name='Source', description='The source from which the template is created. Valid values:

*   OpenAPI
*   AliyunConsole
*   WebSDK

<!---->', example='OpenAPI'),
  status?: string(name='Status', description='The template state. Valid values:

*   Available: The template is available.
*   Created: The template is created but not ready for use.
*   Uploading: The video is being uploaded.
*   Processing: The advanced template is being processed.
*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.

<!---->', example='Available'),
  type?: string(name='Type', description='The template type. Valid values:

*   Timeline: a regular template created based on the timeline of a video editing project, in which multiple materials are arranged in sequence across multiple layers. It can be used to convert text and images into videos, create photo albums, add opening and closing parts, and apply the default watermark.
*   VETemplate: an advanced template created using effects of Adobe After Effects (AE). It can be used to produce complex animations and advanced media effects.

<!---->', example='Timeline'),
}

model AddTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
  template?: {
    config?: string(name='Config', description='The template configurations.', example='参见Timeline模板Config文档'),
    coverUrl?: string(name='CoverUrl', description='The URL of the template thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
    createSource?: string(name='CreateSource', description='The source from which the template was created.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
    modifiedSource?: string(name='ModifiedSource', description='The source from which the template was modified.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
    name?: string(name='Name', description='The template name.', example='视频添加水印模板'),
    previewMedia?: string(name='PreviewMedia', description='The ID of the preview video.', example='****01bf24bf41c78b2754cb3187****'),
    status?: string(name='Status', description='The template state.

Valid values:

*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.
*   Available: The template is available.
*   Uploading: The video is being uploaded.
*   Created: The template is created but not ready for use.
*   Processing: The advanced template is being processed.', example='Available'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****01bf24bf41c78b2754cb3187****'),
    type?: string(name='Type', description='The template type.

Valid values:

*   Timeline: regular template.
*   VETemplate: advanced template.', example='Timeline'),
  }(name='Template', description='The template information.'),
}

model AddTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddTemplateResponseBody(name='body'),
}

/**
 * @summary Creates a template.
 *
 * @description *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 * *   After an advanced template is created, it enters the Processing state. In this case, the template is unavailable. The template can be used only when it is in the Available state. The time required for template processing varies based on the size of the template file. Generally, it ranges from 10 seconds to 5 minutes.
 *
 * @param request AddTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AddTemplateResponse
 */
async function addTemplateWithOptions(request: AddTemplateRequest, runtime: Util.RuntimeOptions): AddTemplateResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.coverUrl)) {
    query['CoverUrl'] = request.coverUrl;
  }
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.previewMedia)) {
    query['PreviewMedia'] = request.previewMedia;
  }
  if (!Util.isUnset(request.relatedMediaids)) {
    query['RelatedMediaids'] = request.relatedMediaids;
  }
  if (!Util.isUnset(request.source)) {
    query['Source'] = request.source;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.config)) {
    body['Config'] = request.config;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'AddTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Creates a template.
 *
 * @description *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 * *   After an advanced template is created, it enters the Processing state. In this case, the template is unavailable. The template can be used only when it is in the Available state. The time required for template processing varies based on the size of the template file. Generally, it ranges from 10 seconds to 5 minutes.
 *
 * @param request AddTemplateRequest
 * @return AddTemplateResponse
 */
async function addTemplate(request: AddTemplateRequest): AddTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return addTemplateWithOptions(request, runtime);
}

model AlterSearchIndexRequest {
  indexConfig?: string(name='IndexConfig', description='The configurations of the index.

>  You must specify either IndexStatus or IndexConfig.', example='{}'),
  indexStatus?: string(name='IndexStatus', description='The state of the index. Valid values:

*   active (default): the index is enabled.
*   Deactive: the index is not enabled.

>  You must specify either IndexStatus or IndexConfig.', example='Active'),
  indexType?: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.

This parameter is required.', example='mm'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

*   If you leave this parameter empty, the search index is created in the default search library of Intelligent Media Service (IMS). Default value: ims-default-search-lib.
*   To query information about an existing search library, call the [QuerySearchLib](https://help.aliyun.com/document_detail/2584455.html) API operation.', example='test1'),
}

model AlterSearchIndexResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model AlterSearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AlterSearchIndexResponseBody(name='body'),
}

/**
 * @summary Modifies search index information including index status and configurations.
 *
 * @param request AlterSearchIndexRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AlterSearchIndexResponse
 */
async function alterSearchIndexWithOptions(request: AlterSearchIndexRequest, runtime: Util.RuntimeOptions): AlterSearchIndexResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.indexConfig)) {
    query['IndexConfig'] = request.indexConfig;
  }
  if (!Util.isUnset(request.indexStatus)) {
    query['IndexStatus'] = request.indexStatus;
  }
  if (!Util.isUnset(request.indexType)) {
    query['IndexType'] = request.indexType;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'AlterSearchIndex',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Modifies search index information including index status and configurations.
 *
 * @param request AlterSearchIndexRequest
 * @return AlterSearchIndexResponse
 */
async function alterSearchIndex(request: AlterSearchIndexRequest): AlterSearchIndexResponse {
  var runtime = new Util.RuntimeOptions{};
  return alterSearchIndexWithOptions(request, runtime);
}

model BatchGetMediaInfosRequest {
  additionType?: string(name='AdditionType', description='The additional information that you want to query about the media assets. By default, only BasicInfo is returned. The following additional information can be queried:

\\\\- FileInfo

\\\\- DynamicMetaData', example='FileInfo,DynamicMetaData'),
  mediaIds?: string(name='MediaIds', description='The IDs of the media assets that you want to query. Separate the IDs with commas (,).', example='******b48fb04483915d4f2cd8******,******c48fb37407365d4f2cd8******'),
}

model BatchGetMediaInfosResponseBody = {
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
            duration?: string(name='Duration', description='The duration.', example='200'),
            fileName?: string(name='FileName', description='The file name.', example='example'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='1080'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='1920'),
          }(name='FileBasicInfo', description='The basic information of the file, including the duration and size.'),
        }
      ](name='FileInfoList', description='FileInfos'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-26T04:11:10Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-26T04:11:10Z'),
        description?: string(name='Description', description='The description of the media asset.'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        mediaId?: string(name='MediaId', description='MediaId', example='******c48fb37407365d4f2cd8******'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.'),
        mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

\\\\- image

\\\\- video

\\\\- audio

\\\\- text', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-26T04:11:12Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='[{"bucket":"example-bucket","count":"3","iceJobId":"******f48f0e4154976b2b8c45******","location":"oss-cn-beijing","snapshotRegular":"example.jpg","templateId":"******e6a6440b29eb60bd7c******"}]'),
        source?: string(name='Source', description='The source of the media asset. Valid values:

\\\\- oss

\\\\- vod', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite.', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userDataTest'),
      }(name='MediaBasicInfo', description='The basic information of the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******c48fb37407365d4f2cd8******'),
    }
  ](name='MediaInfos', description='The queried media assets.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model BatchGetMediaInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: BatchGetMediaInfosResponseBody(name='body'),
}

/**
 * @summary Queries the information about multiple media assets at a time based on media asset IDs.
 *
 * @param request BatchGetMediaInfosRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return BatchGetMediaInfosResponse
 */
async function batchGetMediaInfosWithOptions(request: BatchGetMediaInfosRequest, runtime: Util.RuntimeOptions): BatchGetMediaInfosResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.additionType)) {
    query['AdditionType'] = request.additionType;
  }
  if (!Util.isUnset(request.mediaIds)) {
    query['MediaIds'] = request.mediaIds;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'BatchGetMediaInfos',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about multiple media assets at a time based on media asset IDs.
 *
 * @param request BatchGetMediaInfosRequest
 * @return BatchGetMediaInfosResponse
 */
async function batchGetMediaInfos(request: BatchGetMediaInfosRequest): BatchGetMediaInfosResponse {
  var runtime = new Util.RuntimeOptions{};
  return batchGetMediaInfosWithOptions(request, runtime);
}

model CancelDNAJobRequest {
  jobId?: string(name='JobId', description='The ID of the media fingerprint analysis job that you want to cancel.

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model CancelDNAJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='2288c6ca184c0e47098a5b665e2a12****'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model CancelDNAJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CancelDNAJobResponseBody(name='body'),
}

/**
 * @summary Cancels a media fingerprint analysis job.
 *
 * @description *   You can cancel a media fingerprint analysis job only if the job is in the Queuing state.
 * *   We recommend that you call the **UpdatePipeline** operation to set the status of the ApsaraVideo Media Processing (MPS) queue to Paused before you cancel a job. This suspends job scheduling in the MPS queue. After the job is canceled, you must set the status of the MPS queue back to Active so that the other jobs in the MPS queue can be scheduled.
 *
 * @param request CancelDNAJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CancelDNAJobResponse
 */
async function cancelDNAJobWithOptions(request: CancelDNAJobRequest, runtime: Util.RuntimeOptions): CancelDNAJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CancelDNAJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Cancels a media fingerprint analysis job.
 *
 * @description *   You can cancel a media fingerprint analysis job only if the job is in the Queuing state.
 * *   We recommend that you call the **UpdatePipeline** operation to set the status of the ApsaraVideo Media Processing (MPS) queue to Paused before you cancel a job. This suspends job scheduling in the MPS queue. After the job is canceled, you must set the status of the MPS queue back to Active so that the other jobs in the MPS queue can be scheduled.
 *
 * @param request CancelDNAJobRequest
 * @return CancelDNAJobResponse
 */
async function cancelDNAJob(request: CancelDNAJobRequest): CancelDNAJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return cancelDNAJobWithOptions(request, runtime);
}

model CancelFavoritePublicMediaRequest {
  mediaIds?: string(name='MediaIds', example='icepublic-****7213c6050cbc66750b469701****,icepublic-****0b4697017213c6050cbc6675****'),
}

model CancelFavoritePublicMediaResponseBody = {
  ignoredList?: [ string ](name='IgnoredList'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model CancelFavoritePublicMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CancelFavoritePublicMediaResponseBody(name='body'),
}

/**
 * @summary 取消收藏公共媒资
 *
 * @param request CancelFavoritePublicMediaRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CancelFavoritePublicMediaResponse
 */
async function cancelFavoritePublicMediaWithOptions(request: CancelFavoritePublicMediaRequest, runtime: Util.RuntimeOptions): CancelFavoritePublicMediaResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaIds)) {
    query['MediaIds'] = request.mediaIds;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CancelFavoritePublicMedia',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 取消收藏公共媒资
 *
 * @param request CancelFavoritePublicMediaRequest
 * @return CancelFavoritePublicMediaResponse
 */
async function cancelFavoritePublicMedia(request: CancelFavoritePublicMediaRequest): CancelFavoritePublicMediaResponse {
  var runtime = new Util.RuntimeOptions{};
  return cancelFavoritePublicMediaWithOptions(request, runtime);
}

model CreateAuditRequest {
  auditContent?: string(name='AuditContent', description='The review results. You can specify the results for a maximum of 20 videos at a time. The value must be converted to a string. For more information about the parameters in AuditContent, see the "AuditContent" section of this topic.

This parameter is required.', example='[
      {
            "MediaId": "93ab850b4f*****b54b6e91d24d81d4",
            "Status": "Normal"
      },
      {
            "MediaId": "f867fbfb58*****8bbab65c4480ae1d",
            "Status": "Blocked",
            "Reason": "xxxx",
            "Comment": "xxxx"
      }
]'),
}

model CreateAuditResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateAuditResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateAuditResponseBody(name='body'),
}

/**
 * @summary Submits manual review results for media assets.
 *
 * @param request CreateAuditRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateAuditResponse
 */
async function createAuditWithOptions(request: CreateAuditRequest, runtime: Util.RuntimeOptions): CreateAuditResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.auditContent)) {
    query['AuditContent'] = request.auditContent;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateAudit',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits manual review results for media assets.
 *
 * @param request CreateAuditRequest
 * @return CreateAuditResponse
 */
async function createAudit(request: CreateAuditRequest): CreateAuditResponse {
  var runtime = new Util.RuntimeOptions{};
  return createAuditWithOptions(request, runtime);
}

model CreateAvatarTrainingJobRequest {
  avatarDescription?: string(name='AvatarDescription', description='*   The description of the digital human.
*   The description can be up to 1,000 characters in length.'),
  avatarName?: string(name='AvatarName', description='*   The name of the digital human.
*   The name can be up to seven characters in length.

This parameter is required.'),
  avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
  portrait?: string(name='Portrait', description='*   The media asset ID of the portrait image.
*   The value must be 32 characters in length.', example='****571c704445f9a0ee011406c2****'),
  thumbnail?: string(name='Thumbnail', description='*   The thumbnail URL.
*   After the digital human is trained, the thumbnail is uploaded to this URL.
*   The URL must be a valid public Object Storage Service (OSS) URL.
*   The URL can be up to 512 characters in length.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
  transparent?: boolean(name='Transparent', description='*   Specifies whether the training video supports alpha channels.

    **

    **Note**: Make sure that the current settings are consistent with those of the submitted training video. Otherwise, the digital human may malfunction.', example='True'),
  video?: string(name='Video', description='*   The ID of the video used for training.
*   The value must be 32 characters in length.
*   Supported formats: MP4, MOV, and WebM.
*   The duration of the video must be 5 to 15 minutes.
*   The resolution of the video must be 1920×1080 or 1080×1920.', example='****571c704445f9a0ee011406c2****'),
}

model CreateAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateAvatarTrainingJobResponseBody(name='body'),
}

/**
 * @summary Creates a digital human training job. You can configure the basic information of the digital human and the materials required for the training. Note: This operation is used to initialize the training job. It does not submit the training job. To submit the training job, call the SubmitAvatarTrainingJob operation.
 *
 * @param request CreateAvatarTrainingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateAvatarTrainingJobResponse
 */
async function createAvatarTrainingJobWithOptions(request: CreateAvatarTrainingJobRequest, runtime: Util.RuntimeOptions): CreateAvatarTrainingJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.avatarDescription)) {
    query['AvatarDescription'] = request.avatarDescription;
  }
  if (!Util.isUnset(request.avatarName)) {
    query['AvatarName'] = request.avatarName;
  }
  if (!Util.isUnset(request.avatarType)) {
    query['AvatarType'] = request.avatarType;
  }
  if (!Util.isUnset(request.portrait)) {
    query['Portrait'] = request.portrait;
  }
  if (!Util.isUnset(request.thumbnail)) {
    query['Thumbnail'] = request.thumbnail;
  }
  if (!Util.isUnset(request.transparent)) {
    query['Transparent'] = request.transparent;
  }
  if (!Util.isUnset(request.video)) {
    query['Video'] = request.video;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateAvatarTrainingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Creates a digital human training job. You can configure the basic information of the digital human and the materials required for the training. Note: This operation is used to initialize the training job. It does not submit the training job. To submit the training job, call the SubmitAvatarTrainingJob operation.
 *
 * @param request CreateAvatarTrainingJobRequest
 * @return CreateAvatarTrainingJobResponse
 */
async function createAvatarTrainingJob(request: CreateAvatarTrainingJobRequest): CreateAvatarTrainingJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return createAvatarTrainingJobWithOptions(request, runtime);
}

model CreateCustomTemplateRequest {
  name?: string(name='Name', description='The template name.

This parameter is required.', example='test-template'),
  subtype?: int32(name='Subtype', description='The template subtype.

Valid values for transcoding templates:

*   1 (Normal): regular template.
*   2 (AudioTranscode): audio transcoding template.
*   3 (Remux): container format conversion template.
*   4 (NarrowBandV1): Narrowband HD 1.0 template.
*   5 (NarrowBandV2): Narrowband HD 2.0 template.

Valid values for snapshot templates:

*   1 (Normal): regular template.
*   2 (Sprite): sprite template.
*   3 (WebVtt): WebVTT template.

Valid values for AI-assisted content moderation templates:

*   1 (Video): video moderation template.
*   2 (Audio): audio moderation template.
*   3 (Image): image moderation template.

Valid values for AI-assisted intelligent erasure templates.

*   1 (VideoDelogo): logo erasure template.
*   2 (VideoDetext): subtitle erasure template.', example='1'),
  templateConfig?: string(name='TemplateConfig', description='The template configurations. For more information, see [Template parameters](https://help.aliyun.com/document_detail/448291.html).

This parameter is required.', example='{"Container":{"Format":"flv"},"Video":{},"Audio":{}}'),
  type?: int32(name='Type', description='The template type. Valid values:

*   1: transcoding template.
*   2: snapshot template.
*   3: animated image template.
*   4\\\\. image watermark template.
*   5: text watermark template.
*   6: subtitle template.
*   7: AI-assisted content moderation template.
*   8: AI-assisted intelligent thumbnail template.
*   9: AI-assisted intelligent erasure template.
*   10: AI-assisted media fingerprint analysis template.
*   11: AI-assisted smart tagging template.

This parameter is required.', example='1'),
}

model CreateCustomTemplateResponseBody = {
  customTemplate?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-04-19T02:04:31Z'),
    isDefault?: boolean(name='IsDefault', description='Indicates whether the template is the default template.', example='true'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-04-19T02:04:31Z'),
    status?: string(name='Status', description='The template state.', example='Normal'),
    subtype?: string(name='Subtype', description='The subtype name of the template.', example='Remux'),
    templateConfig?: string(name='TemplateConfig', description='The template configurations.', example='{"Container":{"Format":"flv"},"Video":{},"Audio":{}}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
    templateName?: string(name='TemplateName', description='The template name.', example='test-template'),
    type?: int32(name='Type', description='The type ID of the template.', example='1'),
    typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
  }(name='CustomTemplate', description='The template information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateCustomTemplateResponseBody(name='body'),
}

/**
 * @summary Creates a custom template.
 *
 * @param request CreateCustomTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateCustomTemplateResponse
 */
async function createCustomTemplateWithOptions(request: CreateCustomTemplateRequest, runtime: Util.RuntimeOptions): CreateCustomTemplateResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.subtype)) {
    query['Subtype'] = request.subtype;
  }
  if (!Util.isUnset(request.templateConfig)) {
    query['TemplateConfig'] = request.templateConfig;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateCustomTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Creates a custom template.
 *
 * @param request CreateCustomTemplateRequest
 * @return CreateCustomTemplateResponse
 */
async function createCustomTemplate(request: CreateCustomTemplateRequest): CreateCustomTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return createCustomTemplateWithOptions(request, runtime);
}

model CreateCustomizedVoiceJobRequest {
  gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male

This parameter is required.', example='female'),
  scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation

This parameter is required.', example='story'),
  voiceDesc?: string(name='VoiceDesc', description='The voice description.

*   The description can be up to 256 characters in length.'),
  voiceId?: string(name='VoiceId', description='The voice ID. It can be the English name or Chinese Pinyin of the voice.

*   The value must be a unique ID that is not used by other custom voices.
*   The ID can be up to 32 characters in length.
*   Only letters and digits are supported.

This parameter is required.', example='xiaozhuan'),
  voiceName?: string(name='VoiceName', description='The voice name.

*   The name can be up to 32 characters in length.'),
}

model CreateCustomizedVoiceJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****29faef8144638ba42eb8e037****'),
    voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
}

model CreateCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Creates a human voice cloning job. You can configure the basic information of the human voice cloning job.
 *
 * @param request CreateCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateCustomizedVoiceJobResponse
 */
async function createCustomizedVoiceJobWithOptions(request: CreateCustomizedVoiceJobRequest, runtime: Util.RuntimeOptions): CreateCustomizedVoiceJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.gender)) {
    query['Gender'] = request.gender;
  }
  if (!Util.isUnset(request.scenario)) {
    query['Scenario'] = request.scenario;
  }
  if (!Util.isUnset(request.voiceDesc)) {
    query['VoiceDesc'] = request.voiceDesc;
  }
  if (!Util.isUnset(request.voiceId)) {
    query['VoiceId'] = request.voiceId;
  }
  if (!Util.isUnset(request.voiceName)) {
    query['VoiceName'] = request.voiceName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Creates a human voice cloning job. You can configure the basic information of the human voice cloning job.
 *
 * @param request CreateCustomizedVoiceJobRequest
 * @return CreateCustomizedVoiceJobResponse
 */
async function createCustomizedVoiceJob(request: CreateCustomizedVoiceJobRequest): CreateCustomizedVoiceJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return createCustomizedVoiceJobWithOptions(request, runtime);
}

model CreateDNADBRequest {
  description?: string(name='Description', description='The description of the media fingerprint library.'),
  model?: string(name='Model', description='The model of the media fingerprint library. Valid values:

*   **Video**
*   **Audio**
*   **Image**
*   **Text** (supported only in the China (Shanghai) region)', example='Video'),
  name?: string(name='Name', description='The name of the media fingerprint library.

This parameter is required.', example='example name'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model CreateDNADBResponseBody = {
  DBInfo?: {
    DBId?: string(name='DBId', description='The ID of the media fingerprint library. We recommend that you save this ID for subsequent calls of other operations.', example='88c6ca184c0e47098a5b665e2a12****'),
    description?: string(name='Description', description='The description of the media fingerprint library.'),
    model?: string(name='Model', description='The model of the media fingerprint library.', example='Video'),
    name?: string(name='Name', description='The name of the media fingerprint library.', example='example name'),
    status?: string(name='Status', description='The state of the media fingerprint library. After a media fingerprint library is created, it enters the offline state. After the media fingerprint library is processed at the backend, it enters the active state.', example='offline'),
  }(name='DBInfo', description='The details of the media fingerprint library.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model CreateDNADBResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDNADBResponseBody(name='body'),
}

/**
 * @summary Creates media fingerprint libraries.
 *
 * @description *   You can create up to five media fingerprint libraries within an account. To increase the quota, submit a ticket. You can call the DeleteDNADB operation to delete the fingerprint libraries that you no longer need.
 *
 * @param request CreateDNADBRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateDNADBResponse
 */
async function createDNADBWithOptions(request: CreateDNADBRequest, runtime: Util.RuntimeOptions): CreateDNADBResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.description)) {
    query['Description'] = request.description;
  }
  if (!Util.isUnset(request.model)) {
    query['Model'] = request.model;
  }
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateDNADB',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Creates media fingerprint libraries.
 *
 * @description *   You can create up to five media fingerprint libraries within an account. To increase the quota, submit a ticket. You can call the DeleteDNADB operation to delete the fingerprint libraries that you no longer need.
 *
 * @param request CreateDNADBRequest
 * @return CreateDNADBResponse
 */
async function createDNADB(request: CreateDNADBRequest): CreateDNADBResponse {
  var runtime = new Util.RuntimeOptions{};
  return createDNADBWithOptions(request, runtime);
}

model CreateEditingProjectRequest {
  businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.

For a live stream editing project, observe the following rules: OutputMediaConfig.StorageLocation is required. OutputMediaConfig.Path is optional. If you do not specify this option, the live streaming clips are stored in the root directory by default.

Valid values of OutputMediaTarget include vod-media and oss-object. If you do not specify OutputMediaTarget, the default value oss-object is used.

If you set OutputMediaTarget to vod-media, the setting of OutputMediaConfig.Path does not take effect.', example='{ "OutputMediaConfig" : { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path" }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
  clipsParam?: string(name='ClipsParam', description='The material parameter corresponding to the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified. For more information<props="china">, see [Create and use a regular template](https://help.aliyun.com/document_detail/328557.html) and [Create and use an advanced template](https://help.aliyun.com/document_detail/291418.html).'),
  coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='https://example.com/example.png'),
  description?: string(name='Description', description='The description of the online editing project.', example='描述'),
  materialMaps?: string(name='MaterialMaps', description='The material associated with the project. Separate multiple material IDs with commas (,). Each type supports up to 10 material IDs.', example='{"video":"*****2e057304fcd9b145c5cafc*****", "image":"****8021a8d493da643c8acd98*****,*****cb6307a4edea614d8b3f3c*****", "liveStream": "[{\\\\"appName\\\\":\\\\"testrecord\\\\",\\\\"domainName\\\\":\\\\"test.alivecdn.com\\\\",\\\\"liveUrl\\\\":\\\\"rtmp://test.alivecdn.com/testrecord/teststream\\\\",\\\\"streamName\\\\":\\\\"teststream\\\\"}]", "editingProject": "*****9b145c5cafc2e057304fcd*****"}'),
  projectType?: string(name='ProjectType', description='The type of the editing project. Valid values: EditingProject and LiveEditingProject. A value of EditingProject indicates a regular editing project, and a value of LiveEditingProject indicates a live stream editing project.', example='LiveEditingProject'),
  templateId?: string(name='TemplateId', description='The template ID. This parameter is used to quickly build a timeline with ease. Note: Only one of Timeline and TemplateId can be specified. If TemplateId is specified, ClipsParam must also be specified.', example='****96e8864746a0b6f3****'),
  templateType?: string(name='TemplateType', description='The template type. This parameter is required if you create a template-based online editing project. Default value: Timeline. Valid values:

*   Timeline: a regular template.
*   VETemplate: an advanced template.', example='Timeline'),
  timeline?: string(name='Timeline', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
  title?: string(name='Title', description='The title of the online editing project.

This parameter is required.', example='example'),
}

model CreateEditingProjectResponseBody = {
  project?: {
    businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{ "OutputMediaConfig" :    { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path"   }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
    businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

*   Reserving
*   ReservationCanceled
*   BroadCasting
*   LoadingFailed
*   LiveFinished', example='Reserving'),
    clipsParam?: string(name='ClipsParam', description='The template material parameters.'),
    coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
    createSource?: string(name='CreateSource', description='The method for creating the online editing project. Valid values:

\\\\- OpenAPI

\\\\- AliyunConsole

\\\\- WebSDK

\\\\- LiveEditingOpenAPI

\\\\- LiveEditingConsole', example='WebSDK'),
    createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2021-01-08T16:52:07Z'),
    description?: string(name='Description', description='The description of the online editing project.', example='example_description'),
    duration?: float(name='Duration', description='The duration of the online editing project.', example='3.4200000'),
    modifiedSource?: string(name='ModifiedSource', description='The method for editing the online editing project. Valid values:

\\\\- OpenAPI

\\\\- AliyunConsole

\\\\- WebSDK

\\\\- LiveEditingOpenAPI

\\\\- LiveEditingConsole', example='WebSDK'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last edited.', example='2021-01-08T16:52:07Z'),
    projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****01bf24bf41c78b2754cb3187****'),
    projectType?: string(name='ProjectType', description='The type of the editing project. Default value: EditingProject. Valid values:

\\\\- EditingProject: a regular editing project.

\\\\- LiveEditingProject: a live stream editing project.', example='LiveEditingProject'),
    status?: long(name='Status', description='The status of the online editing project.

Valid values:

\\\\- 1: Draft

\\\\- 2: Editing

\\\\- 3: Producing

\\\\- 4: Produced

\\\\- 5: ProduceFailed

\\\\- 7: Deleted', example='2'),
    statusName?: string(name='StatusName', description='The status of the online editing project. For more information, see the status list.', example='Editing'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
    templateType?: string(name='TemplateType', description='The template type of the online editing project. Valid values:

\\\\- Timeline

\\\\- VETemplate', example='Timeline'),
    timeline?: string(name='Timeline', description='The timeline of the online editing project, in the JSON format.<props="china">For more information about objects in a timeline, see [Timeline configurations](https://help.aliyun.com/document_detail/198823.htm?spm=a2c4g.11186623.2.9.90dc653dF67srN#topic-2024662).  If you leave this parameter empty, an empty timeline is created and the duration of the online editing project is zero.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
    title?: string(name='Title', description='The title of the online editing project.', example='example_title'),
  }(name='Project', description='The information about the online editing project.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model CreateEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateEditingProjectResponseBody(name='body'),
}

/**
 * @summary Creates an online editing project. You can specify configurations such as the title, description, timeline, and thumbnail for the project.
 *
 * @param request CreateEditingProjectRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateEditingProjectResponse
 */
async function createEditingProjectWithOptions(request: CreateEditingProjectRequest, runtime: Util.RuntimeOptions): CreateEditingProjectResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.businessConfig)) {
    query['BusinessConfig'] = request.businessConfig;
  }
  if (!Util.isUnset(request.clipsParam)) {
    query['ClipsParam'] = request.clipsParam;
  }
  if (!Util.isUnset(request.coverURL)) {
    query['CoverURL'] = request.coverURL;
  }
  if (!Util.isUnset(request.description)) {
    query['Description'] = request.description;
  }
  if (!Util.isUnset(request.materialMaps)) {
    query['MaterialMaps'] = request.materialMaps;
  }
  if (!Util.isUnset(request.projectType)) {
    query['ProjectType'] = request.projectType;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!Util.isUnset(request.templateType)) {
    query['TemplateType'] = request.templateType;
  }
  if (!Util.isUnset(request.title)) {
    query['Title'] = request.title;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.timeline)) {
    body['Timeline'] = request.timeline;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'CreateEditingProject',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Creates an online editing project. You can specify configurations such as the title, description, timeline, and thumbnail for the project.
 *
 * @param request CreateEditingProjectRequest
 * @return CreateEditingProjectResponse
 */
async function createEditingProject(request: CreateEditingProjectRequest): CreateEditingProjectResponse {
  var runtime = new Util.RuntimeOptions{};
  return createEditingProjectWithOptions(request, runtime);
}

model CreateLiveRecordTemplateRequest {
  name?: string(name='Name', description='The name of the template.

This parameter is required.'),
  recordFormat?: [ 
    {
      cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds. If you do not specify this parameter, the default value 6 hours is used.

> 

*   If a live stream is interrupted during a recording cycle but is resumed within 3 minutes, the stream is recorded in the same recording before and after the interruption.

*   If a live stream is interrupted for more than 3 minutes, a new recording is generated. To change the default stream interruption time, submit a ticket.', example='3600'),
      format?: string(name='Format', description='The format.

>  If you set this parameter to m3u8, you must also specify the SliceOssObjectPrefix and SliceDuration parameters.

This parameter is required.', example='m3u8'),
      ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording file that is stored in Object Storage Service (OSS).

*   The name must be less than 256 bytes in length and can contain the {JobId}, {Sequence}, {StartTime}, {EndTime}, {EscapedStartTime}, and {EscapedEndTime} variables.
*   The name must contain the {StartTime} and {EndTime} variables or the {EscapedStartTime} and {EscapedEndTime} variables.', example='record/{JobId}/{Sequence}_{EscapedStartTime}_{EscapedEndTime}'),
      sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds.

>  This parameter takes effect only if you set Format to m3u8.

If you do not specify this parameter, the default value 30 seconds is used. Valid values: 5 to 30.', example='30'),
      sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.

>  This parameter is required only if you set Format to m3u8.

*   By default, the duration of a segment is 30 seconds. The segment name must be less than 256 bytes in length and can contain the {JobId}, {UnixTimestamp}, and {Sequence} variables.
*   The segment name must contain the {UnixTimestamp} and {Sequence} variables.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
    }
  ](name='RecordFormat', description='The list of recording formats.

This parameter is required.'),
}

model CreateLiveRecordTemplateShrinkRequest {
  name?: string(name='Name', description='The name of the template.

This parameter is required.'),
  recordFormatShrink?: string(name='RecordFormat', description='The list of recording formats.

This parameter is required.'),
}

model CreateLiveRecordTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
}

model CreateLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLiveRecordTemplateResponseBody(name='body'),
}

/**
 * @summary Creates a live stream recording template to submit live stream recording jobs.
 *
 * @description You must specify a recording template for live stream recording. You can configure information such as the format and duration of a recording in a recording template. The recording format can be M3U8, MP4, or FLV.
 *
 * @param tmpReq CreateLiveRecordTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateLiveRecordTemplateResponse
 */
async function createLiveRecordTemplateWithOptions(tmpReq: CreateLiveRecordTemplateRequest, runtime: Util.RuntimeOptions): CreateLiveRecordTemplateResponse {
  Util.validateModel(tmpReq);
  var request = new CreateLiveRecordTemplateShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.recordFormat)) {
    request.recordFormatShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.recordFormat, 'RecordFormat', 'json');
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.name)) {
    body['Name'] = request.name;
  }
  if (!Util.isUnset(request.recordFormatShrink)) {
    body['RecordFormat'] = request.recordFormatShrink;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'CreateLiveRecordTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Creates a live stream recording template to submit live stream recording jobs.
 *
 * @description You must specify a recording template for live stream recording. You can configure information such as the format and duration of a recording in a recording template. The recording format can be M3U8, MP4, or FLV.
 *
 * @param request CreateLiveRecordTemplateRequest
 * @return CreateLiveRecordTemplateResponse
 */
async function createLiveRecordTemplate(request: CreateLiveRecordTemplateRequest): CreateLiveRecordTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return createLiveRecordTemplateWithOptions(request, runtime);
}

model CreateLiveSnapshotTemplateRequest {
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   It cannot exceed 255 characters in length.
*   The {JobId} placeholder is supported. It specifies the ID of the snapshot job.
*   Placeholders such as {UnixTimestamp}, {Sequence}, and {Date} are not allowed.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}.jpg'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   It cannot exceed 255 characters in length.
*   The {JobId}, {Date}, {UnixTimestamp}, and {Sequence} placeholders are supported. {JobId} specifies the ID of the snapshot job. {Date} specifies the date on which the snapshot is captured. {UnixTimestamp} specifies the timestamp of the snapshot. {Sequence} specifies the sequence number of the snapshot. You must specify at least one of the {UnixTimestamp} and {Sequence} placeholders.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}/{UnixTimestamp}.jpg'),
  templateName?: string(name='TemplateName', description='The name of the template.

*   It cannot exceed 128 characters in length.

This parameter is required.'),
  timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.

*   Valid values: [5,3600].

This parameter is required.', example='5'),
}

model CreateLiveSnapshotTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287782****'),
}

model CreateLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLiveSnapshotTemplateResponseBody(name='body'),
}

/**
 * @summary Create a live stream snapshot template to facilitate the creation of snapshot jobs.
 *
 * @param request CreateLiveSnapshotTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateLiveSnapshotTemplateResponse
 */
async function createLiveSnapshotTemplateWithOptions(request: CreateLiveSnapshotTemplateRequest, runtime: Util.RuntimeOptions): CreateLiveSnapshotTemplateResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.overwriteFormat)) {
    body['OverwriteFormat'] = request.overwriteFormat;
  }
  if (!Util.isUnset(request.sequenceFormat)) {
    body['SequenceFormat'] = request.sequenceFormat;
  }
  if (!Util.isUnset(request.templateName)) {
    body['TemplateName'] = request.templateName;
  }
  if (!Util.isUnset(request.timeInterval)) {
    body['TimeInterval'] = request.timeInterval;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'CreateLiveSnapshotTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Create a live stream snapshot template to facilitate the creation of snapshot jobs.
 *
 * @param request CreateLiveSnapshotTemplateRequest
 * @return CreateLiveSnapshotTemplateResponse
 */
async function createLiveSnapshotTemplate(request: CreateLiveSnapshotTemplateRequest): CreateLiveSnapshotTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return createLiveSnapshotTemplateWithOptions(request, runtime);
}

model CreateLiveTranscodeTemplateRequest {
  name?: string(name='Name', description='The name of the template.

This parameter is required.', example='my template'),
  templateConfig?: {
    audioParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output audio. Unit: Kbit/s. Valid values: 1 to 1000.', example='100'),
      channels?: string(name='Channels', description='The number of sound channels. Valid values: 1: mono 2: binaural', example='2'),
      codec?: string(name='Codec', description='The audio codec. Valid values:

*   AAC
*   MP3', example='AAC'),
      profile?: string(name='Profile', description='The audio codec profile. Valid values when the Codec parameter is set to AAC:

*   aac_low
*   aac_he
*   aac_he_v2
*   aac_ld', example='aaclow'),
      samplerate?: string(name='Samplerate', description='The audio sampling rate. Valid values: 22050 to 96000.

Note: If you set AudioProfile to aac_ld, the audio sampling rate cannot exceed 44,100.', example='44100'),
    }(name='AudioParams', description='The audio parameters.'),
    videoParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output video. Unit: Kbit/s. Valid values: 1 to 6000.', example='2500'),
      codec?: string(name='Codec', description='The encoding type. Valid values:

*   H.264
*   H.265', example='H.264'),
      fps?: string(name='Fps', description='The frame rate of the output video. Unit: frames per second (FPS). Valid values: 1 to 60.', example='25'),
      gop?: string(name='Gop', description='The group of pictures (GOP) of the output video. Unit: frame. Valid values: 1 to 3000.', example='1000'),
      height?: string(name='Height', description='The height of the output video. Valid values: Height ≥ 128 max (Height,Width) ≤ 2560 min (Height,Width) ≤ 1440

Note: The resolution of the output video that is transcoded by using the H.265 Narrowband HD transcoding template cannot exceed 1280 × 720 pixels.', example='720'),
      profile?: string(name='Profile', description='The encoding profile. The profile determines how a video is encoded. In most cases, a greater value indicates better image quality and higher resource consumption. Valid values: 1: baseline. This value is suitable for mobile devices. 2: main. This value is suitable for standard-definition devices. 3: high. This value is suitable for high-definition devices.', example='2'),
      width?: string(name='Width', description='The width of the output video. Valid values: Width ≥ 128 max (Height,Width) ≤ 2560 min (Height,Width) ≤ 1440

Note: The resolution of the output video that is transcoded by using the H.265 Narrowband HD transcoding template cannot exceed 1280 × 720 pixels.', example='1280'),
    }(name='VideoParams', description='The video parameters.'),
  }(name='TemplateConfig', description='The configuration of the template.'),
  type?: string(name='Type', description='The type of the template. Valid values:

*   normal
*   narrow-band
*   audio-only
*   origin

This parameter is required.', example='normal'),
}

model CreateLiveTranscodeTemplateShrinkRequest {
  name?: string(name='Name', description='The name of the template.

This parameter is required.', example='my template'),
  templateConfigShrink?: string(name='TemplateConfig', description='The configuration of the template.'),
  type?: string(name='Type', description='The type of the template. Valid values:

*   normal
*   narrow-band
*   audio-only
*   origin

This parameter is required.', example='normal'),
}

model CreateLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  templateId?: string(name='TemplateId', description='The ID of the template.', example='****20b48fb04483915d4f2cd8ac****'),
}

model CreateLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLiveTranscodeTemplateResponseBody(name='body'),
}

/**
 * @summary Creates a live stream transcoding template to submit live stream transcoding jobs.
 *
 * @param tmpReq CreateLiveTranscodeTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateLiveTranscodeTemplateResponse
 */
async function createLiveTranscodeTemplateWithOptions(tmpReq: CreateLiveTranscodeTemplateRequest, runtime: Util.RuntimeOptions): CreateLiveTranscodeTemplateResponse {
  Util.validateModel(tmpReq);
  var request = new CreateLiveTranscodeTemplateShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateLiveTranscodeTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Creates a live stream transcoding template to submit live stream transcoding jobs.
 *
 * @param request CreateLiveTranscodeTemplateRequest
 * @return CreateLiveTranscodeTemplateResponse
 */
async function createLiveTranscodeTemplate(request: CreateLiveTranscodeTemplateRequest): CreateLiveTranscodeTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return createLiveTranscodeTemplateWithOptions(request, runtime);
}

model CreatePipelineRequest {
  name?: string(name='Name', description='The name of the MPS queue.

This parameter is required.', example='test-pipeline'),
  priority?: int32(name='Priority', description='The priority. Default value: 6. Valid values: 1 to 10. A greater value specifies a higher priority.', example='6'),
  speed?: string(name='Speed', description='The type of the MPS queue. Valid values:

1.  Standard: standard MPS queue.
2.  Boost: MPS queue with transcoding speed boosted.
3.  NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.

This parameter is required.', example='Standard'),
}

model CreatePipelineResponseBody = {
  pipeline?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
    name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.', example='****20b48fb04483915d4f2cd8ac****'),
    priority?: int32(name='Priority', description='The priority of the MPS queue.', example='6'),
    speed?: string(name='Speed', description='The type of the MPS queue.

Valid values:

*   Boost: MPS queue with transcoding speed boosted.
*   Standard: standard MPS queue.
*   NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.', example='Standard'),
    status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Active'),
  }(name='Pipeline', description='The information about the MPS queue.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreatePipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreatePipelineResponseBody(name='body'),
}

/**
 * @summary Creates an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request CreatePipelineRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreatePipelineResponse
 */
async function createPipelineWithOptions(request: CreatePipelineRequest, runtime: Util.RuntimeOptions): CreatePipelineResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.priority)) {
    query['Priority'] = request.priority;
  }
  if (!Util.isUnset(request.speed)) {
    query['Speed'] = request.speed;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreatePipeline',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Creates an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request CreatePipelineRequest
 * @return CreatePipelineResponse
 */
async function createPipeline(request: CreatePipelineRequest): CreatePipelineResponse {
  var runtime = new Util.RuntimeOptions{};
  return createPipelineWithOptions(request, runtime);
}

model CreateSearchIndexRequest {
  indexConfig?: string(name='IndexConfig', example='{}'),
  indexStatus?: string(name='IndexStatus', example='Active'),
  indexType?: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model. You can use this model to describe complex visual features and identify and search for specific actions, movements, and events in videos, such as when athletes score a goal or get injured.

>  This feature is in the public preview phase. You can use this feature for free for 1,000 hours of videos.

*   face: face recognition. You can use the face recognition technology to describe face characteristics and automatically mark or search for faces in videos.
*   aiLabel: smart tagging. The smart tagging category is used to describe content such as subtitles and audio in videos. You can use the speech recognition technology to automatically extract, mark, and search for subtitles and dialog content from videos. This helps you quickly locate the video content that is related to specific topics or keywords.

This parameter is required.', example='mm'),
  searchLibName?: string(name='SearchLibName', example='test1'),
}

model CreateSearchIndexResponseBody = {
  code?: string(name='Code', example='200'),
  requestId?: string(name='RequestId', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  success?: string(name='Success', example='true'),
}

model CreateSearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSearchIndexResponseBody(name='body'),
}

/**
 * @summary 创建搜索索引
 *
 * @description The large visual model feature is still in the public preview phase. You can use this feature for free for 1,000 hours of videos.
 *
 * @param request CreateSearchIndexRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateSearchIndexResponse
 */
async function createSearchIndexWithOptions(request: CreateSearchIndexRequest, runtime: Util.RuntimeOptions): CreateSearchIndexResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.indexConfig)) {
    query['IndexConfig'] = request.indexConfig;
  }
  if (!Util.isUnset(request.indexStatus)) {
    query['IndexStatus'] = request.indexStatus;
  }
  if (!Util.isUnset(request.indexType)) {
    query['IndexType'] = request.indexType;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateSearchIndex',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 创建搜索索引
 *
 * @description The large visual model feature is still in the public preview phase. You can use this feature for free for 1,000 hours of videos.
 *
 * @param request CreateSearchIndexRequest
 * @return CreateSearchIndexResponse
 */
async function createSearchIndex(request: CreateSearchIndexRequest): CreateSearchIndexResponse {
  var runtime = new Util.RuntimeOptions{};
  return createSearchIndexWithOptions(request, runtime);
}

model CreateSearchLibRequest {
  searchLibName?: string(name='SearchLibName', description='The name of the search library. The name can contain letters and digits and must start with a letter.

This parameter is required.', example='test1'),
}

model CreateSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model CreateSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSearchLibResponseBody(name='body'),
}

/**
 * @summary Creates a search library to store media assets.
 *
 * @param request CreateSearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateSearchLibResponse
 */
async function createSearchLibWithOptions(request: CreateSearchLibRequest, runtime: Util.RuntimeOptions): CreateSearchLibResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateSearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Creates a search library to store media assets.
 *
 * @param request CreateSearchLibRequest
 * @return CreateSearchLibResponse
 */
async function createSearchLib(request: CreateSearchLibRequest): CreateSearchLibResponse {
  var runtime = new Util.RuntimeOptions{};
  return createSearchLibWithOptions(request, runtime);
}

model CreateUploadMediaRequest {
  appId?: string(name='AppId', description='The application ID. Default value: app-1000000.', example='app-1000000'),
  entityId?: string(name='EntityId', description='The entity ID. You can call the CreateEntity operation to create an entity and specify a dynamic metadata structure.', example='9e177cac2fb44f8b8c67b199fcc7bffd'),
  fileInfo?: string(name='FileInfo', description='The file information, which is in the JSON format and contains the following fields:

*   Type: required. The file type. Valid values: video, image, audio, text, and other.
*   Name: required. The file name without the extension.
*   Size: optional. The file size.
*   Ext: required. The file name extension.', example='{\\\\"Type\\\\":\\\\"video\\\\",\\\\"Name\\\\":\\\\"test.mp4\\\\",\\\\"Size\\\\":108078336,\\\\"Ext\\\\":\\\\"mp4\\\\"}'),
  mediaMetaData?: string(name='MediaMetaData', description='The metadata of the media asset, which is a JSON string that contains the following fields:

Title: required.

*   The value can be up to 128 characters in length.
*   The value must be encoded in UTF-8.

Description: optional.

*   The value can be up to 1,024 characters in length.
*   The value must be encoded in UTF-8.

CateId: optional.

Tags: optional.

BusinessType: required. Valid values:

*   opening or ending if Type is set to video
*   default or cover if Type is set to image
*   subtitles or font if Type is set to text
*   watermark if Type is set to material
*   general CoverURL: optional.

DynamicMetaData: The value is a string.', example='{\\\\"Title\\\\": \\\\"UploadTest\\\\", \\\\"Description\\\\": \\\\"UploadImageTest\\\\", \\\\"Tags\\\\": \\\\"tag1,tag2\\\\",\\\\"BusinessType\\\\":\\\\"cover\\\\"}'),
  postProcessConfig?: string(name='PostProcessConfig', description='The postprocessing configurations. You can specify this parameter if Type is set to video or audio.

Set ProcessType to Workflow.', example='{\\\\"ProcessType\\\\":\\\\"Workflow\\\\",\\\\"ProcessID\\\\":\\\\"74ba870f1a4873a3ba238e0bf6fa9***\\\\"}'),
  uploadTargetConfig?: string(name='UploadTargetConfig', description='The destination storage address.

Set StorageType to oss.

Set StorageLocation to an address in ApsaraVideo VOD. You cannot set this field to an OSS URL.', example='{\\\\"StorageType\\\\":\\\\"oss\\\\",\\\\"StorageLocation\\\\":\\\\"outin-***.oss-cn-shanghai.aliyuncs.com\\\\"}'),
  userData?: string(name='UserData', description='The user data. The value must be a JSON string. You can configure settings such as message callbacks.', example='{"MessageCallback":{"CallbackURL":"http://example.aliyundoc.com"},"Extend":{"localId":"*****","test":"www"}}'),
}

model CreateUploadMediaResponseBody = {
  fileURL?: string(name='FileURL', description='The OSS URL of the file. The URL does not contain the information used for authentication.', example='http://outin-***.oss-cn-north-2-gov-1.aliyuncs.com/sv/40360f05-181f63c3110-0004-cd8e-27f-de3c9.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaURL?: string(name='MediaURL', description='The URL of the media asset.

>  If a domain name for Alibaba Cloud CDN (CDN) is specified, a CDN URL is returned. Otherwise, an OSS URL is returned. If the HTTP status code 403 is returned when you access the URL from your browser, the URL authentication feature of ApsaraVideo VOD is enabled. To resolve this issue, disable URL authentication or generate an authentication signature.', example='https://xxq-live-playback.oss-cn-shanghai.aliyuncs.com/capture/5d96d2b4-111b-4e5d-a0e5-20f44405bb55.mp4'),
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  uploadAddress?: string(name='UploadAddress', description='The upload URL.

>  The returned upload URL is a Base64-encoded URL. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAddress only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJFbmRwb2ludCI6Imh0dHBzOi8vb3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbSIsIkJ1Y2tldCI6InN6aGQtdmlkZW8iLCJGaWxlTmFtZSI6InZvZC0yOTYzMWEvc3YvNTBmYTJlODQtMTgxMjdhZGRiMTcvNTBmYTJlODQtMTgxMjdhZGRiM***'),
  uploadAuth?: string(name='UploadAuth', description='The upload credential.

>  The returned upload credential is a Base64-encoded value. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAuth only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJBY2Nlc3NLZXlJZCI6IkxUQUk0Rm53bTk1dHdxQjMxR3IzSE5hRCIsIkFjY2Vzc0tleVNlY3JldCI6Ik9lWllKR0dTMTlkNkZaM1E3UVpJQmdmSVdnM3BPaiIsIkV4cGlyYXRpb24iOiI***'),
}

model CreateUploadMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateUploadMediaResponseBody(name='body'),
}

/**
 * @summary Obtains the upload URL and credential of a media asset and creates information about the media asset.
 *
 * @description *   You can call this operation to obtain the upload URLs and credentials of audio and video files. You can also call this operation to obtain the upload URLs and credentials of images and auxiliary media assets.
 * *   Obtaining an upload URL and credential is essential for Intelligent Media Services (IMS) and is required in each upload operation.
 * *   If the video upload credential expires, you can call the RefreshUploadMedia operation to obtain a new upload credential. The default validity period of a video upload credential is 3,000 seconds.
 * *   After you upload a media asset, you can configure a callback to receive upload event notifications or call the GetMediaInfo operation to determine whether the media asset is uploaded based on the returned status.
 * *   The MediaId parameter returned by this operation can be used for media asset lifecycle management or media processing.
 * *   You can call this operation to upload media assets only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media asset to your own OSS bucket, you can upload the file to your OSS bucket by using [OSS SDK](https://help.aliyun.com/document_detail/32006.html), and then call the [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html) operation to register the file in the OSS bucket with the media asset library.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 *
 * @param request CreateUploadMediaRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateUploadMediaResponse
 */
async function createUploadMediaWithOptions(request: CreateUploadMediaRequest, runtime: Util.RuntimeOptions): CreateUploadMediaResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.appId)) {
    query['AppId'] = request.appId;
  }
  if (!Util.isUnset(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  if (!Util.isUnset(request.fileInfo)) {
    query['FileInfo'] = request.fileInfo;
  }
  if (!Util.isUnset(request.mediaMetaData)) {
    query['MediaMetaData'] = request.mediaMetaData;
  }
  if (!Util.isUnset(request.postProcessConfig)) {
    query['PostProcessConfig'] = request.postProcessConfig;
  }
  if (!Util.isUnset(request.uploadTargetConfig)) {
    query['UploadTargetConfig'] = request.uploadTargetConfig;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateUploadMedia',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Obtains the upload URL and credential of a media asset and creates information about the media asset.
 *
 * @description *   You can call this operation to obtain the upload URLs and credentials of audio and video files. You can also call this operation to obtain the upload URLs and credentials of images and auxiliary media assets.
 * *   Obtaining an upload URL and credential is essential for Intelligent Media Services (IMS) and is required in each upload operation.
 * *   If the video upload credential expires, you can call the RefreshUploadMedia operation to obtain a new upload credential. The default validity period of a video upload credential is 3,000 seconds.
 * *   After you upload a media asset, you can configure a callback to receive upload event notifications or call the GetMediaInfo operation to determine whether the media asset is uploaded based on the returned status.
 * *   The MediaId parameter returned by this operation can be used for media asset lifecycle management or media processing.
 * *   You can call this operation to upload media assets only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media asset to your own OSS bucket, you can upload the file to your OSS bucket by using [OSS SDK](https://help.aliyun.com/document_detail/32006.html), and then call the [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html) operation to register the file in the OSS bucket with the media asset library.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 *
 * @param request CreateUploadMediaRequest
 * @return CreateUploadMediaResponse
 */
async function createUploadMedia(request: CreateUploadMediaRequest): CreateUploadMediaResponse {
  var runtime = new Util.RuntimeOptions{};
  return createUploadMediaWithOptions(request, runtime);
}

model CreateUploadStreamRequest {
  definition?: string(name='Definition', description='The quality of the media stream. Valid values:

*   FD: low definition.
*   LD: standard definition.
*   SD: high definition.
*   HD: ultra-high definition.
*   OD: original quality.
*   2K: 2K resolution.
*   4K: 4K resolution.
*   SQ: standard sound quality.
*   HQ: high sound quality.', example='HD'),
  fileExtension?: string(name='FileExtension', description='The file name extension of the media stream.', example='MP4'),
  HDRType?: string(name='HDRType', description='The high dynamic range (HDR) format of the transcoded stream. Valid values:

*   HDR
*   HDR10
*   HLG
*   DolbyVision
*   HDRVivid
*   SDR+

> 

*   The value is not case-sensitive,

*   You can leave this parameter empty for non-HDR streams.', example='HDR10'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  userData?: string(name='UserData', description='The user data.', example='{"MessageCallback":{"CallbackURL":"http://aliyundoc.com"}, "Extend":{"localId":"xxx","test":"www"}}'),
}

model CreateUploadStreamResponseBody = {
  fileURL?: string(name='FileURL', description='The Object Storage Service (OSS) URL of the file. The URL does not contain the information used for authentication.', example='http://outin-***.oss-cn-shanghai.aliyuncs.com/stream/48555e8b-181dd5a8c07/48555e8b-181dd5a8c07.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****c469e944b5a856828dc2****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  uploadAddress?: string(name='UploadAddress', description='The upload URL.

>  The returned upload URL is a Base64-encoded URL. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAddress only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJFbmRwb2ludCI6Imh0dHBzOi8vb3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbSIsIkJ1Y2tldCI6InN6aGQtdmlkZW8iLCJGaWxlTmFtZSI6InZvZC0yOTYzMWEvc3YvNTBmYTJlODQtMTgxMjdhZGRiMTcvNTBmYTJlODQtMTgxMjdhZGRiM***'),
  uploadAuth?: string(name='UploadAuth', description='The upload credential.

>  The returned upload credential is a Base64-encoded value. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAuth only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJBY2Nlc3NLZXlJZCI6IkxUQUk0Rm53bTk1dHdxQjMxR3IzSE5hRCIsIkFjY2Vzc0tleVNlY3JldCI6Ik9lWllKR0dTMTlkNkZaM1E3UVpJQmdmSVdnM3BPaiIsIkV4cGlyYXRpb24iOiI***'),
}

model CreateUploadStreamResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateUploadStreamResponseBody(name='body'),
}

/**
 * @summary Obtains the upload URL and credential of a media stream.
 *
 * @description *   You can call this operation to upload only a local media stream. After the media stream is uploaded, it is associated with the specified media asset ID.
 * *   You can call this operation to upload media streams only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media stream to your own OSS bucket, you can upload the file to your OSS bucket by using [OSS SDK](https://help.aliyun.com/document_detail/32006.html), and then call the [RegisterMediaStream](https://help.aliyun.com/document_detail/440765.html) operation to associate the media stream with the specified media asset ID.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 *
 * @param request CreateUploadStreamRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateUploadStreamResponse
 */
async function createUploadStreamWithOptions(request: CreateUploadStreamRequest, runtime: Util.RuntimeOptions): CreateUploadStreamResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.definition)) {
    query['Definition'] = request.definition;
  }
  if (!Util.isUnset(request.fileExtension)) {
    query['FileExtension'] = request.fileExtension;
  }
  if (!Util.isUnset(request.HDRType)) {
    query['HDRType'] = request.HDRType;
  }
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateUploadStream',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Obtains the upload URL and credential of a media stream.
 *
 * @description *   You can call this operation to upload only a local media stream. After the media stream is uploaded, it is associated with the specified media asset ID.
 * *   You can call this operation to upload media streams only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media stream to your own OSS bucket, you can upload the file to your OSS bucket by using [OSS SDK](https://help.aliyun.com/document_detail/32006.html), and then call the [RegisterMediaStream](https://help.aliyun.com/document_detail/440765.html) operation to associate the media stream with the specified media asset ID.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 *
 * @param request CreateUploadStreamRequest
 * @return CreateUploadStreamResponse
 */
async function createUploadStream(request: CreateUploadStreamRequest): CreateUploadStreamResponse {
  var runtime = new Util.RuntimeOptions{};
  return createUploadStreamWithOptions(request, runtime);
}

model DecryptKMSDataKeyRequest {
  ciphertextBlob?: string(name='CiphertextBlob', description='The ciphertext that you want to decrypt.

This parameter is required.', example='ODZhOWVmZDktM2QxNi00ODk0LWJkNGYtMWZjNDNmM2YyYWJmS7FmDBBQ0BkKsQrtRnidtPwirmDcS0ZuJCU41xxAAWk4Z8qsADfbV0b+i6kQmlvj79dJdGOvtX69Uycs901qOjop4bTS****'),
}

model DecryptKMSDataKeyResponseBody = {
  dataKey?: {
    keyId?: string(name='KeyId', description='The ID of the customer master key (CMK) that was used to decrypt the ciphertext.', example='202b9877-5a25-46e3-a763-e20791b5****'),
    plaintext?: string(name='Plaintext', description='The plaintext that is generated after decryption.', example='tRYXuCwgja12xxO1N/gZERDDCLw9doZEQiPDk/Bv****'),
  }(name='DataKey', description='The information about the decryption result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DecryptKMSDataKeyResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DecryptKMSDataKeyResponseBody(name='body'),
}

/**
 * @summary Decrypts the ciphertext specified by CiphertextBlob in the Key Management Service (KMS) data key.
 *
 * @param request DecryptKMSDataKeyRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DecryptKMSDataKeyResponse
 */
async function decryptKMSDataKeyWithOptions(request: DecryptKMSDataKeyRequest, runtime: Util.RuntimeOptions): DecryptKMSDataKeyResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.ciphertextBlob)) {
    query['CiphertextBlob'] = request.ciphertextBlob;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DecryptKMSDataKey',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Decrypts the ciphertext specified by CiphertextBlob in the Key Management Service (KMS) data key.
 *
 * @param request DecryptKMSDataKeyRequest
 * @return DecryptKMSDataKeyResponse
 */
async function decryptKMSDataKey(request: DecryptKMSDataKeyRequest): DecryptKMSDataKeyResponse {
  var runtime = new Util.RuntimeOptions{};
  return decryptKMSDataKeyWithOptions(request, runtime);
}

model DeleteAvatarTrainingJobRequest {
  jobId?: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model DeleteAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteAvatarTrainingJobResponseBody(name='body'),
}

/**
 * @summary Deletes a digital human training job that is in the Init or Fail state.
 *
 * @param request DeleteAvatarTrainingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteAvatarTrainingJobResponse
 */
async function deleteAvatarTrainingJobWithOptions(request: DeleteAvatarTrainingJobRequest, runtime: Util.RuntimeOptions): DeleteAvatarTrainingJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteAvatarTrainingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes a digital human training job that is in the Init or Fail state.
 *
 * @param request DeleteAvatarTrainingJobRequest
 * @return DeleteAvatarTrainingJobResponse
 */
async function deleteAvatarTrainingJob(request: DeleteAvatarTrainingJobRequest): DeleteAvatarTrainingJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteAvatarTrainingJobWithOptions(request, runtime);
}

model DeleteCategoryRequest {
  cateId?: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of CateId returned by the AddCategory operation that you called to create a category.
*   View the value of CateId returned by the GetCategories operation that you called to query a category.

This parameter is required.', example='46'),
}

model DeleteCategoryResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model DeleteCategoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCategoryResponseBody(name='body'),
}

/**
 * @summary Deletes a media asset category.
 *
 * @description This operation also deletes the subcategories, including the level-2 and level-3 categories, of the category.
 *
 * @param request DeleteCategoryRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteCategoryResponse
 */
async function deleteCategoryWithOptions(request: DeleteCategoryRequest, runtime: Util.RuntimeOptions): DeleteCategoryResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.cateId)) {
    query['CateId'] = request.cateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteCategory',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes a media asset category.
 *
 * @description This operation also deletes the subcategories, including the level-2 and level-3 categories, of the category.
 *
 * @param request DeleteCategoryRequest
 * @return DeleteCategoryResponse
 */
async function deleteCategory(request: DeleteCategoryRequest): DeleteCategoryResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteCategoryWithOptions(request, runtime);
}

model DeleteCustomTemplateRequest {
  templateId?: string(name='TemplateId', description='The ID of the custom template.

This parameter is required.', example='****96e8864746a0b6f3****'),
}

model DeleteCustomTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCustomTemplateResponseBody(name='body'),
}

/**
 * @summary Deletes a custom template.
 *
 * @param request DeleteCustomTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteCustomTemplateResponse
 */
async function deleteCustomTemplateWithOptions(request: DeleteCustomTemplateRequest, runtime: Util.RuntimeOptions): DeleteCustomTemplateResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteCustomTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes a custom template.
 *
 * @param request DeleteCustomTemplateRequest
 * @return DeleteCustomTemplateResponse
 */
async function deleteCustomTemplate(request: DeleteCustomTemplateRequest): DeleteCustomTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteCustomTemplateWithOptions(request, runtime);
}

model DeleteCustomizedVoiceJobRequest {
  jobId?: string(name='JobId', description='The ID of the human voice cloning job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model DeleteCustomizedVoiceJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Deletes a human voice cloning job that is not in the Training or Success state.
 *
 * @param request DeleteCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteCustomizedVoiceJobResponse
 */
async function deleteCustomizedVoiceJobWithOptions(request: DeleteCustomizedVoiceJobRequest, runtime: Util.RuntimeOptions): DeleteCustomizedVoiceJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes a human voice cloning job that is not in the Training or Success state.
 *
 * @param request DeleteCustomizedVoiceJobRequest
 * @return DeleteCustomizedVoiceJobResponse
 */
async function deleteCustomizedVoiceJob(request: DeleteCustomizedVoiceJobRequest): DeleteCustomizedVoiceJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteCustomizedVoiceJobWithOptions(request, runtime);
}

model DeleteDNADBRequest {
  DBId?: string(name='DBId', description='The ID of the media fingerprint library that you want to delete.

This parameter is required.', example='fb712a6890464059b1b2ea7c8647****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model DeleteDNADBResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model DeleteDNADBResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDNADBResponseBody(name='body'),
}

/**
 * @summary Deletes a media fingerprint library.
 *
 * @param request DeleteDNADBRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteDNADBResponse
 */
async function deleteDNADBWithOptions(request: DeleteDNADBRequest, runtime: Util.RuntimeOptions): DeleteDNADBResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBId)) {
    query['DBId'] = request.DBId;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteDNADB',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes a media fingerprint library.
 *
 * @param request DeleteDNADBRequest
 * @return DeleteDNADBResponse
 */
async function deleteDNADB(request: DeleteDNADBRequest): DeleteDNADBResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteDNADBWithOptions(request, runtime);
}

model DeleteDNAFilesRequest {
  DBId?: string(name='DBId', description='The ID of the media fingerprint library from which you want to delete files.

This parameter is required.', example='fb712a6890464059b1b2ea7c8647****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  primaryKeys?: string(name='PrimaryKeys', description='The primary key values of the files that you want to delete. Separate multiple values with commas (,). You can delete up to 50 files at a time.

This parameter is required.', example='41e6536e4f2250e2e9bf26cdea19****'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model DeleteDNAFilesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model DeleteDNAFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDNAFilesResponseBody(name='body'),
}

/**
 * @summary Deletes files from a media fingerprint library.
 *
 * @param request DeleteDNAFilesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteDNAFilesResponse
 */
async function deleteDNAFilesWithOptions(request: DeleteDNAFilesRequest, runtime: Util.RuntimeOptions): DeleteDNAFilesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBId)) {
    query['DBId'] = request.DBId;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.primaryKeys)) {
    query['PrimaryKeys'] = request.primaryKeys;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteDNAFiles',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes files from a media fingerprint library.
 *
 * @param request DeleteDNAFilesRequest
 * @return DeleteDNAFilesResponse
 */
async function deleteDNAFiles(request: DeleteDNAFilesRequest): DeleteDNAFilesResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteDNAFilesWithOptions(request, runtime);
}

model DeleteEditingProjectMaterialsRequest {
  materialIds?: string(name='MaterialIds', description='The material ID. Separate multiple material IDs with commas (,). You can specify up to 10 IDs.

This parameter is required.', example='*****cbd721b418a89a7dafb1dc*****,*****86f5d534c95997c55c96f*****'),
  materialType?: string(name='MaterialType', description='The material type. Valid values:

\\\\- video

\\\\- image

\\\\- audio

\\\\- subtitle

\\\\- text

This parameter is required.', example='video'),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='*****fb2101cb318*****'),
}

model DeleteEditingProjectMaterialsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******36-3C1E-4417-BDB2-1E034F******'),
}

model DeleteEditingProjectMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteEditingProjectMaterialsResponseBody(name='body'),
}

/**
 * @summary Deletes one or more materials from an online editing project.
 *
 * @param request DeleteEditingProjectMaterialsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteEditingProjectMaterialsResponse
 */
async function deleteEditingProjectMaterialsWithOptions(request: DeleteEditingProjectMaterialsRequest, runtime: Util.RuntimeOptions): DeleteEditingProjectMaterialsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.materialIds)) {
    query['MaterialIds'] = request.materialIds;
  }
  if (!Util.isUnset(request.materialType)) {
    query['MaterialType'] = request.materialType;
  }
  if (!Util.isUnset(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteEditingProjectMaterials',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes one or more materials from an online editing project.
 *
 * @param request DeleteEditingProjectMaterialsRequest
 * @return DeleteEditingProjectMaterialsResponse
 */
async function deleteEditingProjectMaterials(request: DeleteEditingProjectMaterialsRequest): DeleteEditingProjectMaterialsResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteEditingProjectMaterialsWithOptions(request, runtime);
}

model DeleteEditingProjectsRequest {
  projectIds?: string(name='ProjectIds', description='The ID of the online editing project. You can specify multiple IDs separated with commas (,).', example='****fb2101bf24bf41cb318787dc****,****87dcfb2101bf24bf41cb3187****'),
}

model DeleteEditingProjectsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****25818875-5F78-4AF6-D7393642CA58****'),
}

model DeleteEditingProjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteEditingProjectsResponseBody(name='body'),
}

/**
 * @summary Deletes one or more online editing project.
 *
 * @param request DeleteEditingProjectsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteEditingProjectsResponse
 */
async function deleteEditingProjectsWithOptions(request: DeleteEditingProjectsRequest, runtime: Util.RuntimeOptions): DeleteEditingProjectsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.projectIds)) {
    query['ProjectIds'] = request.projectIds;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteEditingProjects',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes one or more online editing project.
 *
 * @param request DeleteEditingProjectsRequest
 * @return DeleteEditingProjectsResponse
 */
async function deleteEditingProjects(request: DeleteEditingProjectsRequest): DeleteEditingProjectsResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteEditingProjectsWithOptions(request, runtime);
}

model DeleteLiveRecordFilesRequest {
  recordIds?: [ string ](name='RecordIds', description='The collection of IDs of recording files.

This parameter is required.'),
  removeFile?: boolean(name='RemoveFile', description='Specifies whether to delete the original files in OSS.', example='true'),
}

model DeleteLiveRecordFilesResponseBody = {
  deleteFileInfoList?: [ 
    {
      code?: string(name='Code', description='The code that identifies the result of the deletion.', example='OK'),
      message?: string(name='Message', description='The result of deletion.', example='OK'),
      recordId?: string(name='RecordId', description='The ID of the deleted recording file.', example='13cbb83e-043c-4728-ac35-*****'),
    }
  ](name='DeleteFileInfoList', description='The list of files deleted.'),
  message?: string(name='Message', description='The description of the state returned.', example='OK'),
  requestId?: string(name='RequestId', description='Id of the request', example='13cbb83e-043c-4728-ac35-*****'),
}

model DeleteLiveRecordFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveRecordFilesResponseBody(name='body'),
}

/**
 * @summary Deletes live stream recording files. You can choose to delete only the recording files or delete both the recording files and the original Object Storage Service (OSS) files.
 *
 * @param request DeleteLiveRecordFilesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLiveRecordFilesResponse
 */
async function deleteLiveRecordFilesWithOptions(request: DeleteLiveRecordFilesRequest, runtime: Util.RuntimeOptions): DeleteLiveRecordFilesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.recordIds)) {
    query['RecordIds'] = request.recordIds;
  }
  if (!Util.isUnset(request.removeFile)) {
    query['RemoveFile'] = request.removeFile;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteLiveRecordFiles',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes live stream recording files. You can choose to delete only the recording files or delete both the recording files and the original Object Storage Service (OSS) files.
 *
 * @param request DeleteLiveRecordFilesRequest
 * @return DeleteLiveRecordFilesResponse
 */
async function deleteLiveRecordFiles(request: DeleteLiveRecordFilesRequest): DeleteLiveRecordFilesResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteLiveRecordFilesWithOptions(request, runtime);
}

model DeleteLiveRecordTemplateRequest {
  templateId?: string(name='TemplateId', description='The ID of the template to be deleted. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ice.console.aliyun.com/live-processing/template/list/record), choose Real-time Media Processing > Template Management, and then click the Recording tab. Alternatively, find the ID from the response parameters of the [CreateLiveRecordTemplate](https://help.aliyun.com/document_detail/448213.html) operation.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
}

model DeleteLiveRecordTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='3E5330CF-B4C8-5BEF-AA6B-8E70BD20FAEE'),
}

model DeleteLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveRecordTemplateResponseBody(name='body'),
}

/**
 * @summary Deletes a live stream recording template without affecting existing jobs.
 *
 * @param request DeleteLiveRecordTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLiveRecordTemplateResponse
 */
async function deleteLiveRecordTemplateWithOptions(request: DeleteLiveRecordTemplateRequest, runtime: Util.RuntimeOptions): DeleteLiveRecordTemplateResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteLiveRecordTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes a live stream recording template without affecting existing jobs.
 *
 * @param request DeleteLiveRecordTemplateRequest
 * @return DeleteLiveRecordTemplateResponse
 */
async function deleteLiveRecordTemplate(request: DeleteLiveRecordTemplateRequest): DeleteLiveRecordTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteLiveRecordTemplateWithOptions(request, runtime);
}

model DeleteLiveSnapshotFilesRequest {
  createTimestampList?: [ long ](name='CreateTimestampList', description='The list of timestamps when the jobs were created. The values are UNIX timestamps representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC. A maximum of 200 jobs can be deleted at a time.

This parameter is required.'),
  deleteOriginalFile?: boolean(name='DeleteOriginalFile', description='Specifies whether to delete the original files at the same time. Default value: false.', example='true'),
  jobId?: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model DeleteLiveSnapshotFilesShrinkRequest {
  createTimestampListShrink?: string(name='CreateTimestampList', description='The list of timestamps when the jobs were created. The values are UNIX timestamps representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC. A maximum of 200 jobs can be deleted at a time.

This parameter is required.'),
  deleteOriginalFile?: boolean(name='DeleteOriginalFile', description='Specifies whether to delete the original files at the same time. Default value: false.', example='true'),
  jobId?: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model DeleteLiveSnapshotFilesResponseBody = {
  deleteFileResultList?: [ 
    {
      createTimestamp?: long(name='CreateTimestamp', description='The time when the file was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1660638613798'),
      result?: string(name='Result', description='The result of deletion. A value of OK indicates that the file is deleted. Other values indicate that the file failed to be deleted.

Valid values:

*   OK: The file was deleted.
*   NotFound: The file was not found.', example='OK'),
    }
  ](name='DeleteFileResultList', description='The list of deleted files.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
}

model DeleteLiveSnapshotFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveSnapshotFilesResponseBody(name='body'),
}

/**
 * @summary Deletes live stream snapshot files. You can choose to delete only the snapshot files or delete both the snapshot files and the original Object Storage Service (OSS) files.
 *
 * @param tmpReq DeleteLiveSnapshotFilesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLiveSnapshotFilesResponse
 */
async function deleteLiveSnapshotFilesWithOptions(tmpReq: DeleteLiveSnapshotFilesRequest, runtime: Util.RuntimeOptions): DeleteLiveSnapshotFilesResponse {
  Util.validateModel(tmpReq);
  var request = new DeleteLiveSnapshotFilesShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.createTimestampList)) {
    request.createTimestampListShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.createTimestampList, 'CreateTimestampList', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.createTimestampListShrink)) {
    query['CreateTimestampList'] = request.createTimestampListShrink;
  }
  if (!Util.isUnset(request.deleteOriginalFile)) {
    query['DeleteOriginalFile'] = request.deleteOriginalFile;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteLiveSnapshotFiles',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes live stream snapshot files. You can choose to delete only the snapshot files or delete both the snapshot files and the original Object Storage Service (OSS) files.
 *
 * @param request DeleteLiveSnapshotFilesRequest
 * @return DeleteLiveSnapshotFilesResponse
 */
async function deleteLiveSnapshotFiles(request: DeleteLiveSnapshotFilesRequest): DeleteLiveSnapshotFilesResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteLiveSnapshotFilesWithOptions(request, runtime);
}

model DeleteLiveSnapshotTemplateRequest {
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model DeleteLiveSnapshotTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveSnapshotTemplateResponseBody(name='body'),
}

/**
 * @summary Deletes a live stream snapshot template.
 *
 * @param request DeleteLiveSnapshotTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLiveSnapshotTemplateResponse
 */
async function deleteLiveSnapshotTemplateWithOptions(request: DeleteLiveSnapshotTemplateRequest, runtime: Util.RuntimeOptions): DeleteLiveSnapshotTemplateResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.templateId)) {
    body['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'DeleteLiveSnapshotTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes a live stream snapshot template.
 *
 * @param request DeleteLiveSnapshotTemplateRequest
 * @return DeleteLiveSnapshotTemplateResponse
 */
async function deleteLiveSnapshotTemplate(request: DeleteLiveSnapshotTemplateRequest): DeleteLiveSnapshotTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteLiveSnapshotTemplateWithOptions(request, runtime);
}

model DeleteLiveTranscodeJobRequest {
  jobId?: string(name='JobId', description='The ID of the transcoding job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model DeleteLiveTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model DeleteLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveTranscodeJobResponseBody(name='body'),
}

/**
 * @summary 删除指定转码任务
 *
 * @param request DeleteLiveTranscodeJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLiveTranscodeJobResponse
 */
async function deleteLiveTranscodeJobWithOptions(request: DeleteLiveTranscodeJobRequest, runtime: Util.RuntimeOptions): DeleteLiveTranscodeJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteLiveTranscodeJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 删除指定转码任务
 *
 * @param request DeleteLiveTranscodeJobRequest
 * @return DeleteLiveTranscodeJobResponse
 */
async function deleteLiveTranscodeJob(request: DeleteLiveTranscodeJobRequest): DeleteLiveTranscodeJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteLiveTranscodeJobWithOptions(request, runtime);
}

model DeleteLiveTranscodeTemplateRequest {
  templateId?: string(name='TemplateId', description='The template ID. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ice.console.aliyun.com/summary), choose Real-time Media Processing > Template Management, and then click the Transcoding tab. Alternatively, find the ID from the response parameters of the [CreateLiveTranscodeTemplate](https://help.aliyun.com/document_detail/449217.html) operation.

This parameter is required.', example='****d80e4e4044975745c14b****'),
}

model DeleteLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model DeleteLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveTranscodeTemplateResponseBody(name='body'),
}

/**
 * @summary Deletes a live stream transcoding template.
 *
 * @param request DeleteLiveTranscodeTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLiveTranscodeTemplateResponse
 */
async function deleteLiveTranscodeTemplateWithOptions(request: DeleteLiveTranscodeTemplateRequest, runtime: Util.RuntimeOptions): DeleteLiveTranscodeTemplateResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteLiveTranscodeTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes a live stream transcoding template.
 *
 * @param request DeleteLiveTranscodeTemplateRequest
 * @return DeleteLiveTranscodeTemplateResponse
 */
async function deleteLiveTranscodeTemplate(request: DeleteLiveTranscodeTemplateRequest): DeleteLiveTranscodeTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteLiveTranscodeTemplateWithOptions(request, runtime);
}

model DeleteMediaFromSearchLibRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
  msgBody?: string(name='MsgBody', description='The message body.', example='{}'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1'),
}

model DeleteMediaFromSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteMediaFromSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaFromSearchLibResponseBody(name='body'),
}

/**
 * @summary Deletes a specific media asset from a search library.
 *
 * @param request DeleteMediaFromSearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteMediaFromSearchLibResponse
 */
async function deleteMediaFromSearchLibWithOptions(request: DeleteMediaFromSearchLibRequest, runtime: Util.RuntimeOptions): DeleteMediaFromSearchLibResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.msgBody)) {
    query['MsgBody'] = request.msgBody;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteMediaFromSearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes a specific media asset from a search library.
 *
 * @param request DeleteMediaFromSearchLibRequest
 * @return DeleteMediaFromSearchLibResponse
 */
async function deleteMediaFromSearchLib(request: DeleteMediaFromSearchLibRequest): DeleteMediaFromSearchLibResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteMediaFromSearchLibWithOptions(request, runtime);
}

model DeleteMediaInfosRequest {
  deletePhysicalFiles?: boolean(name='DeletePhysicalFiles', description='Specifies whether to delete the physical file of the media asset.

If the media asset is stored in your own OSS bucket, you must authorize the service role AliyunICEDefaultRole in advance. For more information<props="china">, see [Authorize IMS to delete recording files in OSS](https://help.aliyun.com/zh/ims/user-guide/record?spm=a2c4g.11186623.0.i8#0737d9c437bmn).', example='false'),
  inputURLs?: string(name='InputURLs', description='The URL of the media asset that you want to delete. The file corresponding to the URL must be registered with IMS. Separate multiple URLs with commas (,). The following two formats are supported:

1.  http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?
2.  OSS://example-bucket/example.mp4?\\\\
    In this format, it is considered by default that the region of the OSS bucket in which the media asset resides is the same as the region in which IMS is activated.'),
  mediaIds?: string(name='MediaIds', description='The ID of the media asset that you want to delete from Intelligent Media Services (IMS).

*   Separate multiple IDs with commas (,).

If you leave MediaIds empty, you must specify InputURLs.', example='****20b48fb04483915d4f2cd8ac****,****15d4a4b0448391508f2cb486****'),
}

model DeleteMediaInfosResponseBody = {
  forbiddenList?: [ string ](name='ForbiddenList', description='The IDs or URLs of media assets that cannot be deleted. Generally, media assets cannot be deleted if you do not have the required permissions.'),
  ignoredList?: [ string ](name='IgnoredList', description='The IDs or URLs of ignored media assets. An error occurred while obtaining such media assets.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
}

model DeleteMediaInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaInfosResponseBody(name='body'),
}

/**
 * @summary Deletes multiple media assets at a time. You can delete at most 20 media assets at a time. If MediaIds is specified, it is preferentially used. If MediaIds is empty, InputURLs must be specified.
 *
 * @param request DeleteMediaInfosRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteMediaInfosResponse
 */
async function deleteMediaInfosWithOptions(request: DeleteMediaInfosRequest, runtime: Util.RuntimeOptions): DeleteMediaInfosResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.deletePhysicalFiles)) {
    query['DeletePhysicalFiles'] = request.deletePhysicalFiles;
  }
  if (!Util.isUnset(request.inputURLs)) {
    query['InputURLs'] = request.inputURLs;
  }
  if (!Util.isUnset(request.mediaIds)) {
    query['MediaIds'] = request.mediaIds;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteMediaInfos',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes multiple media assets at a time. You can delete at most 20 media assets at a time. If MediaIds is specified, it is preferentially used. If MediaIds is empty, InputURLs must be specified.
 *
 * @param request DeleteMediaInfosRequest
 * @return DeleteMediaInfosResponse
 */
async function deleteMediaInfos(request: DeleteMediaInfosRequest): DeleteMediaInfosResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteMediaInfosWithOptions(request, runtime);
}

model DeleteMediaMarksRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****c469e944b5a856828dc2****'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The mark ID. You can specify multiple mark IDs separated with commas (,).

If you do not specify MediaMarkIds, all the marks of the media asset are deleted.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
}

model DeleteMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The IDs of the deleted marks separated with commas (,).', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaMarksResponseBody(name='body'),
}

/**
 * @summary Deletes the marks of a media asset.
 *
 * @param request DeleteMediaMarksRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteMediaMarksResponse
 */
async function deleteMediaMarksWithOptions(request: DeleteMediaMarksRequest, runtime: Util.RuntimeOptions): DeleteMediaMarksResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.mediaMarkIds)) {
    query['MediaMarkIds'] = request.mediaMarkIds;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteMediaMarks',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes the marks of a media asset.
 *
 * @param request DeleteMediaMarksRequest
 * @return DeleteMediaMarksResponse
 */
async function deleteMediaMarks(request: DeleteMediaMarksRequest): DeleteMediaMarksResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteMediaMarksWithOptions(request, runtime);
}

model DeletePipelineRequest {
  pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.

This parameter is required.', example='****96e8864746a0b6f3****'),
}

model DeletePipelineResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeletePipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeletePipelineResponseBody(name='body'),
}

/**
 * @summary Deletes an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request DeletePipelineRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeletePipelineResponse
 */
async function deletePipelineWithOptions(request: DeletePipelineRequest, runtime: Util.RuntimeOptions): DeletePipelineResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.pipelineId)) {
    query['PipelineId'] = request.pipelineId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeletePipeline',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request DeletePipelineRequest
 * @return DeletePipelineResponse
 */
async function deletePipeline(request: DeletePipelineRequest): DeletePipelineResponse {
  var runtime = new Util.RuntimeOptions{};
  return deletePipelineWithOptions(request, runtime);
}

model DeletePlayInfoRequest {
  deletePhysicalFiles?: boolean(name='DeletePhysicalFiles', description='Specifies whether to delete the physical file of the media stream.

If the media asset is stored in your own Object Storage Service (OSS) bucket, you must authorize the service role AliyunICEDefaultRole in advance. <props="china">For more information, see [Authorize IMS to delete recording files in OSS](https://help.aliyun.com/document_detail/449331.html#p-ko2-wc7-iad).

You can delete only the physical files of transcoded streams, but not the physical files of source files.', example='false'),
  fileURLs?: string(name='FileURLs', description='The URL of the media stream file that you want to delete. Separate multiple URLs with commas (,).', example='https://ice-test001.oss-cn-shanghai.aliyuncs.com/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95/%E5%B0%8F%E7%8C%AA%E4%BD%A9%E5%A5%87640*360.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='1d3518e0027d71ed80cd909598416303'),
}

model DeletePlayInfoResponseBody = {
  forbiddenList?: [ string ](name='ForbiddenList', description='The URLs of the media streams that cannot be deleted. Generally, media streams cannot be deleted if you do not have the required permissions.'),
  ignoredList?: [ string ](name='IgnoredList', description='The URLs of ignored media streams. An error occurred while obtaining such media assets because the IDs or URLs of the media assets do not exist.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeletePlayInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeletePlayInfoResponseBody(name='body'),
}

/**
 * @summary Deletes media streams such as video streams and audio streams.
 *
 * @description You can call this operation to delete multiple media streams at a time.
 *
 * @param request DeletePlayInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeletePlayInfoResponse
 */
async function deletePlayInfoWithOptions(request: DeletePlayInfoRequest, runtime: Util.RuntimeOptions): DeletePlayInfoResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.deletePhysicalFiles)) {
    query['DeletePhysicalFiles'] = request.deletePhysicalFiles;
  }
  if (!Util.isUnset(request.fileURLs)) {
    query['FileURLs'] = request.fileURLs;
  }
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeletePlayInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes media streams such as video streams and audio streams.
 *
 * @description You can call this operation to delete multiple media streams at a time.
 *
 * @param request DeletePlayInfoRequest
 * @return DeletePlayInfoResponse
 */
async function deletePlayInfo(request: DeletePlayInfoRequest): DeletePlayInfoResponse {
  var runtime = new Util.RuntimeOptions{};
  return deletePlayInfoWithOptions(request, runtime);
}

model DeleteSmartJobRequest {
  jobId?: string(name='JobId', description='The IDs of the jobs to delete. Separate multiple IDs with commas (,).', example='******b48fb04483915d4f2cd8******,******042d5e4db6866f6289d1******'),
}

model DeleteSmartJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteSmartJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteSmartJobResponseBody(name='body'),
}

/**
 * @summary Deletes intelligent jobs based on job IDs.
 *
 * @param request DeleteSmartJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteSmartJobResponse
 */
async function deleteSmartJobWithOptions(request: DeleteSmartJobRequest, runtime: Util.RuntimeOptions): DeleteSmartJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteSmartJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes intelligent jobs based on job IDs.
 *
 * @param request DeleteSmartJobRequest
 * @return DeleteSmartJobResponse
 */
async function deleteSmartJob(request: DeleteSmartJobRequest): DeleteSmartJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteSmartJobWithOptions(request, runtime);
}

model DeleteTemplateRequest {
  templateIds?: string(name='TemplateIds', description='The IDs of the templates that you want to delete. Separate multiple IDs with commas (,).', example='****20b48fb04483915d4f2cd8ac****,****20b48fb04483915d4f2cd8ac****'),
}

model DeleteTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteTemplateResponseBody(name='body'),
}

/**
 * @summary Deletes templates.
 *
 * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
 * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request DeleteTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteTemplateResponse
 */
async function deleteTemplateWithOptions(request: DeleteTemplateRequest, runtime: Util.RuntimeOptions): DeleteTemplateResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes templates.
 *
 * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
 * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request DeleteTemplateRequest
 * @return DeleteTemplateResponse
 */
async function deleteTemplate(request: DeleteTemplateRequest): DeleteTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteTemplateWithOptions(request, runtime);
}

model DescribeAIAgentInstanceRequest {
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
}

model DescribeAIAgentInstanceResponseBody = {
  instance?: {
    callLogUrl?: string(name='CallLogUrl', example='https://example.com/call_logs/12345'),
    runtimeConfig?: AIAgentRuntimeConfig(name='RuntimeConfig', example='{"VoiceChat":{"AgentUserId":"voice_agent_001","ChannelId":"voice_channel_001","AuthToken":"your_voice_chat_auth_token"}}'),
    status?: string(name='Status', example='Finished'),
    templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', example='{"VoiceChat": {"AppId": "your_voice_chat_app_id"}}'),
    userData?: string(name='UserData', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
  }(name='Instance'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model DescribeAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAIAgentInstanceResponseBody(name='body'),
}

/**
 * @summary 查询实例
 *
 * @param request DescribeAIAgentInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeAIAgentInstanceResponse
 */
async function describeAIAgentInstanceWithOptions(request: DescribeAIAgentInstanceRequest, runtime: Util.RuntimeOptions): DescribeAIAgentInstanceResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeAIAgentInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 查询实例
 *
 * @param request DescribeAIAgentInstanceRequest
 * @return DescribeAIAgentInstanceResponse
 */
async function describeAIAgentInstance(request: DescribeAIAgentInstanceRequest): DescribeAIAgentInstanceResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeAIAgentInstanceWithOptions(request, runtime);
}

model DescribeMeterImsEditUsageRequest {
  endTs?: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1656995036'),
  interval?: long(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='86400'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai'),
  startTs?: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1654403036'),
}

model DescribeMeterImsEditUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='1.23'),
      profile?: string(name='Profile', description='The video profile.', example='1080P'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
    }
  ](name='Data', description='The usage statistics of IMS on VOD editing.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7F3AE2C6-5CC6-5712-BAC5-5A735A157687'),
}

model DescribeMeterImsEditUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsEditUsageResponseBody(name='body'),
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on video-on-demand (VOD) editing. The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsEditUsageRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeMeterImsEditUsageResponse
 */
async function describeMeterImsEditUsageWithOptions(request: DescribeMeterImsEditUsageRequest, runtime: Util.RuntimeOptions): DescribeMeterImsEditUsageResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.endTs)) {
    query['EndTs'] = request.endTs;
  }
  if (!Util.isUnset(request.interval)) {
    query['Interval'] = request.interval;
  }
  if (!Util.isUnset(request.region)) {
    query['Region'] = request.region;
  }
  if (!Util.isUnset(request.startTs)) {
    query['StartTs'] = request.startTs;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeMeterImsEditUsage',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on video-on-demand (VOD) editing. The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsEditUsageRequest
 * @return DescribeMeterImsEditUsageResponse
 */
async function describeMeterImsEditUsage(request: DescribeMeterImsEditUsageRequest): DescribeMeterImsEditUsageResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeMeterImsEditUsageWithOptions(request, runtime);
}

model DescribeMeterImsMediaConvertUHDUsageRequest {
  endTs?: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1656995036'),
  interval?: string(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='3600'),
  regionId?: string(name='RegionId', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai'),
  startTs?: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1654403036'),
}

model DescribeMeterImsMediaConvertUHDUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='308028'),
      specification?: string(name='Specification', description='The transcoding specifications.', example='SuperResolution.Standard.1080P'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
    }
  ](name='Data', description='The usage statistics of IMS on UHD transcoding of MPS.'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
}

model DescribeMeterImsMediaConvertUHDUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsMediaConvertUHDUsageResponseBody(name='body'),
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on ultra high definition (UHD) transcoding of ApsaraVideo Media Processing (MPS). The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsMediaConvertUHDUsageRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeMeterImsMediaConvertUHDUsageResponse
 */
async function describeMeterImsMediaConvertUHDUsageWithOptions(request: DescribeMeterImsMediaConvertUHDUsageRequest, runtime: Util.RuntimeOptions): DescribeMeterImsMediaConvertUHDUsageResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.endTs)) {
    query['EndTs'] = request.endTs;
  }
  if (!Util.isUnset(request.interval)) {
    query['Interval'] = request.interval;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.startTs)) {
    query['StartTs'] = request.startTs;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeMeterImsMediaConvertUHDUsage',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on ultra high definition (UHD) transcoding of ApsaraVideo Media Processing (MPS). The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsMediaConvertUHDUsageRequest
 * @return DescribeMeterImsMediaConvertUHDUsageResponse
 */
async function describeMeterImsMediaConvertUHDUsage(request: DescribeMeterImsMediaConvertUHDUsageRequest): DescribeMeterImsMediaConvertUHDUsageResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeMeterImsMediaConvertUHDUsageWithOptions(request, runtime);
}

model DescribeMeterImsMediaConvertUsageRequest {
  endTs?: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp. The maximum query range is 31 days. The duration between StartTs and EndTs cannot exceed 31 days.

This parameter is required.', example='1656995036'),
  interval?: long(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='86400'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai'),
  startTs?: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp. You can query data within the last 90 days.

This parameter is required.', example='1654403036'),
}

model DescribeMeterImsMediaConvertUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='20'),
      specification?: string(name='Specification', description='The transcoding specifications.', example='H264.HD'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
    }
  ](name='Data', description='The usage statistics of IMS on VOD transcoding.'),
  requestId?: string(name='RequestId', description='The request ID.', example='FBBB5210-2B78-58FB-A6FE-9DD887BB2C61'),
}

model DescribeMeterImsMediaConvertUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsMediaConvertUsageResponseBody(name='body'),
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on video-on-demand (VOD) transcoding. The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsMediaConvertUsageRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeMeterImsMediaConvertUsageResponse
 */
async function describeMeterImsMediaConvertUsageWithOptions(request: DescribeMeterImsMediaConvertUsageRequest, runtime: Util.RuntimeOptions): DescribeMeterImsMediaConvertUsageResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.endTs)) {
    query['EndTs'] = request.endTs;
  }
  if (!Util.isUnset(request.interval)) {
    query['Interval'] = request.interval;
  }
  if (!Util.isUnset(request.region)) {
    query['Region'] = request.region;
  }
  if (!Util.isUnset(request.startTs)) {
    query['StartTs'] = request.startTs;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeMeterImsMediaConvertUsage',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on video-on-demand (VOD) transcoding. The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsMediaConvertUsageRequest
 * @return DescribeMeterImsMediaConvertUsageResponse
 */
async function describeMeterImsMediaConvertUsage(request: DescribeMeterImsMediaConvertUsageRequest): DescribeMeterImsMediaConvertUsageResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeMeterImsMediaConvertUsageWithOptions(request, runtime);
}

model DescribeMeterImsMpsAiUsageRequest {
  endTs?: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp. The maximum query range is 31 days. The duration between StartTs and EndTs cannot exceed 31 days.

This parameter is required.', example='1656995036'),
  interval?: long(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='86400'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai'),
  startTs?: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp. You can query data within the last 90 days.

This parameter is required.', example='1654403036'),
}

model DescribeMeterImsMpsAiUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='644'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
      type?: string(name='Type', description='The AI type. Valid values:'),
    }
  ](name='Data', description='The usage statistics of IMS on AI processing of MPS.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
}

model DescribeMeterImsMpsAiUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsMpsAiUsageResponseBody(name='body'),
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on AI processing of ApsaraVideo Media Processing (MPS). The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsMpsAiUsageRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeMeterImsMpsAiUsageResponse
 */
async function describeMeterImsMpsAiUsageWithOptions(request: DescribeMeterImsMpsAiUsageRequest, runtime: Util.RuntimeOptions): DescribeMeterImsMpsAiUsageResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.endTs)) {
    query['EndTs'] = request.endTs;
  }
  if (!Util.isUnset(request.interval)) {
    query['Interval'] = request.interval;
  }
  if (!Util.isUnset(request.region)) {
    query['Region'] = request.region;
  }
  if (!Util.isUnset(request.startTs)) {
    query['StartTs'] = request.startTs;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeMeterImsMpsAiUsage',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on AI processing of ApsaraVideo Media Processing (MPS). The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsMpsAiUsageRequest
 * @return DescribeMeterImsMpsAiUsageResponse
 */
async function describeMeterImsMpsAiUsage(request: DescribeMeterImsMpsAiUsageRequest): DescribeMeterImsMpsAiUsageResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeMeterImsMpsAiUsageWithOptions(request, runtime);
}

model DescribeMeterImsSummaryRequest {
  endTs?: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1656995036'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai'),
  startTs?: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1654403036'),
}

model DescribeMeterImsSummaryResponseBody = {
  data?: [ 
    {
      editingDuration?: string(name='EditingDuration', description='The duration of video editing.', example='8722'),
      liveEditDuration?: string(name='LiveEditDuration', description='The duration of live editing.', example='2000'),
      liveRecordDuration?: string(name='LiveRecordDuration', description='The duration of live stream recording.', example='100'),
      liveSnapshotCount?: string(name='LiveSnapshotCount', description='The number of live stream snapshots.', example='100'),
      liveTranscodeDuration?: long(name='LiveTranscodeDuration', description='The duration of live stream transcoding.', example='12356'),
      mpsAiDuration?: long(name='MpsAiDuration', description='The duration of AI processing.', example='0'),
      mpsTranscodeDuration?: long(name='MpsTranscodeDuration', description='The duration of video-on-demand (VOD) transcoding.', example='17337'),
      mpsTranscodeUHDDuration?: long(name='MpsTranscodeUHDDuration', description='The duration of audio and video enhancement.', example='300'),
    }
  ](name='Data', description='The usage statistics of IMS.'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
}

model DescribeMeterImsSummaryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsSummaryResponseBody(name='body'),
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS). The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsSummaryRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeMeterImsSummaryResponse
 */
async function describeMeterImsSummaryWithOptions(request: DescribeMeterImsSummaryRequest, runtime: Util.RuntimeOptions): DescribeMeterImsSummaryResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.endTs)) {
    query['EndTs'] = request.endTs;
  }
  if (!Util.isUnset(request.region)) {
    query['Region'] = request.region;
  }
  if (!Util.isUnset(request.startTs)) {
    query['StartTs'] = request.startTs;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeMeterImsSummary',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS). The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsSummaryRequest
 * @return DescribeMeterImsSummaryResponse
 */
async function describeMeterImsSummary(request: DescribeMeterImsSummaryRequest): DescribeMeterImsSummaryResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeMeterImsSummaryWithOptions(request, runtime);
}

model DescribeNotifyConfigRequest {
  AIAgentId?: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
}

model DescribeNotifyConfigResponseBody = {
  callbackUrl?: string(name='CallbackUrl', example='http://customer.com/callback'),
  enableNotify?: boolean(name='EnableNotify', example='true'),
  eventTypes?: string(name='EventTypes', example='agent_start,agent_stop,error'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
  token?: string(name='Token', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx'),
}

model DescribeNotifyConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeNotifyConfigResponseBody(name='body'),
}

/**
 * @summary 描述回调配置
 *
 * @param request DescribeNotifyConfigRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeNotifyConfigResponse
 */
async function describeNotifyConfigWithOptions(request: DescribeNotifyConfigRequest, runtime: Util.RuntimeOptions): DescribeNotifyConfigResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.AIAgentId)) {
    query['AIAgentId'] = request.AIAgentId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeNotifyConfig',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 描述回调配置
 *
 * @param request DescribeNotifyConfigRequest
 * @return DescribeNotifyConfigResponse
 */
async function describeNotifyConfig(request: DescribeNotifyConfigRequest): DescribeNotifyConfigResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeNotifyConfigWithOptions(request, runtime);
}

model DescribePlayListRequest {
  beginTs?: string(name='BeginTs', description='This parameter is required.', example='1676170500011'),
  endTs?: string(name='EndTs', description='This parameter is required.', example='1682474405173'),
  orderName?: string(name='OrderName', example='FirstFrameDuration'),
  orderType?: string(name='OrderType', example='DESC'),
  pageNo?: int32(name='PageNo', description='This parameter is required.', example='1'),
  pageSize?: int32(name='PageSize', description='This parameter is required.', example='10'),
  playType?: string(name='PlayType', example='vod'),
  status?: string(name='Status', example='complete'),
  traceId?: string(name='TraceId', example='0bc5e70516766285805381012d271e'),
}

model DescribePlayListResponseBody = {
  pageNum?: long(name='PageNum', example='1'),
  pageSize?: long(name='PageSize', example='10'),
  playList?: [ 
    {
      firstFrameDuration?: string(name='FirstFrameDuration', example='200'),
      playDuration?: string(name='PlayDuration', example='1000'),
      playTs?: string(name='PlayTs', example='1675922209572'),
      playType?: string(name='PlayType', example='vod'),
      sessionId?: string(name='SessionId', example='91488be2-8381-40c9-8494-e8afe22c4a2d'),
      status?: string(name='Status', example='complete'),
      stuckDuration?: string(name='StuckDuration', example='20'),
      traceId?: string(name='TraceId', example='0b736abf16724820210842673d9543'),
      videoDuration?: string(name='VideoDuration', example='2000'),
      videoId?: string(name='VideoId', example='250314203f0171eebff17035d0b20102'),
    }
  ](name='PlayList'),
  requestId?: string(name='RequestId', description='Id', example='B960580D-26FA-5547-8AFC-3CDC812DBF27'),
  totalNum?: long(name='TotalNum', example='49'),
}

model DescribePlayListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribePlayListResponseBody(name='body'),
}

/**
 * @param request DescribePlayListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribePlayListResponse
 */
async function describePlayListWithOptions(request: DescribePlayListRequest, runtime: Util.RuntimeOptions): DescribePlayListResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.beginTs)) {
    query['BeginTs'] = request.beginTs;
  }
  if (!Util.isUnset(request.endTs)) {
    query['EndTs'] = request.endTs;
  }
  if (!Util.isUnset(request.orderName)) {
    query['OrderName'] = request.orderName;
  }
  if (!Util.isUnset(request.orderType)) {
    query['OrderType'] = request.orderType;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.playType)) {
    query['PlayType'] = request.playType;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  if (!Util.isUnset(request.traceId)) {
    query['TraceId'] = request.traceId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribePlayList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @param request DescribePlayListRequest
 * @return DescribePlayListResponse
 */
async function describePlayList(request: DescribePlayListRequest): DescribePlayListResponse {
  var runtime = new Util.RuntimeOptions{};
  return describePlayListWithOptions(request, runtime);
}

model DescribeRtcRobotInstanceRequest {
  instanceId?: string(name='InstanceId', example='727dc0e296014bb58670940a3da95592'),
}

model DescribeRtcRobotInstanceResponseBody = {
  authToken?: string(name='AuthToken', example='**********'),
  channelId?: string(name='ChannelId', example='testId'),
  config?: {
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt', example='true'),
    greeting?: string(name='Greeting'),
    voiceId?: string(name='VoiceId', example='zhixiaoxia'),
  }(name='Config'),
  requestId?: string(name='RequestId', description='Id of the request', example='20B3A1B6-4BD2-5DE6-BCBC-098C9B4F4E91'),
  status?: string(name='Status', example='Executing'),
  userData?: string(name='UserData', example='{}'),
  userId?: string(name='UserId', example='my-robot'),
}

model DescribeRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeRtcRobotInstanceResponseBody(name='body'),
}

/**
 * @summary 查询实例
 *
 * @param request DescribeRtcRobotInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeRtcRobotInstanceResponse
 */
async function describeRtcRobotInstanceWithOptions(request: DescribeRtcRobotInstanceRequest, runtime: Util.RuntimeOptions): DescribeRtcRobotInstanceResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeRtcRobotInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 查询实例
 *
 * @param request DescribeRtcRobotInstanceRequest
 * @return DescribeRtcRobotInstanceResponse
 */
async function describeRtcRobotInstance(request: DescribeRtcRobotInstanceRequest): DescribeRtcRobotInstanceResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeRtcRobotInstanceWithOptions(request, runtime);
}

model DetectAudioForCustomizedVoiceJobRequest {
  audioRecordId?: int32(name='AudioRecordId', description='The sequence number of the recording file.

This parameter is required.', example='1'),
  recordUrl?: string(name='RecordUrl', description='The URL of the recording file.

> : The URL must be an Object Storage Service (OSS) URL within your Alibaba Cloud account. The OSS bucket must be in the same region in which IMS is activated.

> : The audio file must be in the WAV or PCM format and must be a 16-bit mono audio file at 48000 Hz.

This parameter is required.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/record1.wav'),
  voiceId?: string(name='VoiceId', description='The voice ID.

This parameter is required.', example='xiaozhuan'),
}

model DetectAudioForCustomizedVoiceJobResponseBody = {
  data?: {
    pass?: boolean(name='Pass', description='Indicates whether the audio file passes the check. Valid values:

*   true
*   false', example='false'),
    reason?: string(name='Reason', description='The reason returned if the audio file failed to pass the check.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
}

model DetectAudioForCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DetectAudioForCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Checks whether the reading of users has issues, such as noticeable pronunciation errors or background noise. After the audio is checked on the cloud, the qualified audio is temporarily stored on the cloud for subsequent training. Do not skip this step.
 *
 * @param request DetectAudioForCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DetectAudioForCustomizedVoiceJobResponse
 */
async function detectAudioForCustomizedVoiceJobWithOptions(request: DetectAudioForCustomizedVoiceJobRequest, runtime: Util.RuntimeOptions): DetectAudioForCustomizedVoiceJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.audioRecordId)) {
    query['AudioRecordId'] = request.audioRecordId;
  }
  if (!Util.isUnset(request.recordUrl)) {
    query['RecordUrl'] = request.recordUrl;
  }
  if (!Util.isUnset(request.voiceId)) {
    query['VoiceId'] = request.voiceId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DetectAudioForCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Checks whether the reading of users has issues, such as noticeable pronunciation errors or background noise. After the audio is checked on the cloud, the qualified audio is temporarily stored on the cloud for subsequent training. Do not skip this step.
 *
 * @param request DetectAudioForCustomizedVoiceJobRequest
 * @return DetectAudioForCustomizedVoiceJobResponse
 */
async function detectAudioForCustomizedVoiceJob(request: DetectAudioForCustomizedVoiceJobRequest): DetectAudioForCustomizedVoiceJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return detectAudioForCustomizedVoiceJobWithOptions(request, runtime);
}

model DropSearchIndexRequest {
  indexType?: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.

This parameter is required.', example='mm'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

*   If you leave this parameter empty, the search index is created in the default search library of Intelligent Media Service (IMS). Default value: ims-default-search-lib.
*   To query information about an existing search library, call the [QuerySearchLib](https://help.aliyun.com/document_detail/2584455.html) API operation.', example='test1'),
}

model DropSearchIndexResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DropSearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DropSearchIndexResponseBody(name='body'),
}

/**
 * @summary Deletes a search index. After you delete a search index, the existing index data is cleared and index-based analysis, storage, and query are not supported for subsequent media assets.
 *
 * @param request DropSearchIndexRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DropSearchIndexResponse
 */
async function dropSearchIndexWithOptions(request: DropSearchIndexRequest, runtime: Util.RuntimeOptions): DropSearchIndexResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.indexType)) {
    query['IndexType'] = request.indexType;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DropSearchIndex',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes a search index. After you delete a search index, the existing index data is cleared and index-based analysis, storage, and query are not supported for subsequent media assets.
 *
 * @param request DropSearchIndexRequest
 * @return DropSearchIndexResponse
 */
async function dropSearchIndex(request: DropSearchIndexRequest): DropSearchIndexResponse {
  var runtime = new Util.RuntimeOptions{};
  return dropSearchIndexWithOptions(request, runtime);
}

model DropSearchLibRequest {
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

This parameter is required.', example='test1'),
}

model DropSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DropSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DropSearchLibResponseBody(name='body'),
}

/**
 * @summary Deletes a search library and all media assets in the library.
 *
 * @param request DropSearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DropSearchLibResponse
 */
async function dropSearchLibWithOptions(request: DropSearchLibRequest, runtime: Util.RuntimeOptions): DropSearchLibResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DropSearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Deletes a search library and all media assets in the library.
 *
 * @param request DropSearchLibRequest
 * @return DropSearchLibResponse
 */
async function dropSearchLib(request: DropSearchLibRequest): DropSearchLibResponse {
  var runtime = new Util.RuntimeOptions{};
  return dropSearchLibWithOptions(request, runtime);
}

model GenerateAIAgentCallRequest {
  AIAgentId?: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  expire?: long(name='Expire', example='3600'),
  templateConfig?: AIAgentTemplateConfig(name='TemplateConfig'),
  userData?: string(name='UserData'),
  userId?: string(name='UserId', example='877ae632caae49b1afc81c2e8194ffb4'),
}

model GenerateAIAgentCallShrinkRequest {
  AIAgentId?: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  expire?: long(name='Expire', example='3600'),
  templateConfigShrink?: string(name='TemplateConfig'),
  userData?: string(name='UserData'),
  userId?: string(name='UserId', example='877ae632caae49b1afc81c2e8194ffb4'),
}

model GenerateAIAgentCallResponseBody = {
  AIAgentUserId?: string(name='AIAgentUserId', example='877ae632caae49b1afc81c2e8194ffb4'),
  channelId?: string(name='ChannelId', example='70f22d5784194938a7e387052f2b3208'),
  instanceId?: string(name='InstanceId', example='39f8e0bc005e4f309379701645f4****'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
  token?: string(name='Token', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx'),
  userId?: string(name='UserId', example='user123'),
}

model GenerateAIAgentCallResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GenerateAIAgentCallResponseBody(name='body'),
}

/**
 * @summary 创建一个智能体实例，返回智能体所在的频道、频道内名称以及进入频道所需的token。
 *
 * @param tmpReq GenerateAIAgentCallRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GenerateAIAgentCallResponse
 */
async function generateAIAgentCallWithOptions(tmpReq: GenerateAIAgentCallRequest, runtime: Util.RuntimeOptions): GenerateAIAgentCallResponse {
  Util.validateModel(tmpReq);
  var request = new GenerateAIAgentCallShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.AIAgentId)) {
    query['AIAgentId'] = request.AIAgentId;
  }
  if (!Util.isUnset(request.expire)) {
    query['Expire'] = request.expire;
  }
  if (!Util.isUnset(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  if (!Util.isUnset(request.userId)) {
    query['UserId'] = request.userId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GenerateAIAgentCall',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 创建一个智能体实例，返回智能体所在的频道、频道内名称以及进入频道所需的token。
 *
 * @param request GenerateAIAgentCallRequest
 * @return GenerateAIAgentCallResponse
 */
async function generateAIAgentCall(request: GenerateAIAgentCallRequest): GenerateAIAgentCallResponse {
  var runtime = new Util.RuntimeOptions{};
  return generateAIAgentCallWithOptions(request, runtime);
}

model GenerateKMSDataKeyResponseBody = {
  dataKey?: {
    ciphertextBlob?: string(name='CiphertextBlob', description='The ciphertext of the encrypted data key. This parameter is used as CipherText when you create a transcoding job.', example='ODZhOWVmZDktM2QxNi00ODk0LWJkNGYtMWZjNDNmM2YyYWJmS7FmDBBQ0BkKsQrtRnidtPwirmDcS0ZuJCU41xxAAWk4Z8qsADfbV0b+i6kQmlvj79dJdGOvtX69Uycs901qOjop4bTS****'),
    keyId?: string(name='KeyId', description='The ID of the customer master key (CMK). The ID must be globally unique.', example='7906979c-8e06-46a2-be2d-68e3ccbc****'),
    plaintext?: string(name='Plaintext', description='The Base64-encoded plaintext of the data key.', example='QmFzZTY0IGVuY29kZWQgcGxhaW50****'),
  }(name='DataKey', description='The information about the data key.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GenerateKMSDataKeyResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GenerateKMSDataKeyResponseBody(name='body'),
}

/**
 * @summary Generates a random Key Management Service (KMS) data key used for HTTP Live Streaming (HLS) encryption and transcoding of videos.
 *
 * @param request GenerateKMSDataKeyRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GenerateKMSDataKeyResponse
 */
async function generateKMSDataKeyWithOptions(runtime: Util.RuntimeOptions): GenerateKMSDataKeyResponse {
  var req = new OpenApi.OpenApiRequest{};
  var params = new OpenApi.Params{
    action = 'GenerateKMSDataKey',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Generates a random Key Management Service (KMS) data key used for HTTP Live Streaming (HLS) encryption and transcoding of videos.
 *
 * @return GenerateKMSDataKeyResponse
 */
async function generateKMSDataKey(): GenerateKMSDataKeyResponse {
  var runtime = new Util.RuntimeOptions{};
  return generateKMSDataKeyWithOptions(runtime);
}

model GetAvatarRequest {
  avatarId?: string(name='AvatarId', description='*   The ID of the digital human.

This parameter is required.', example='Avatar-XXXX'),
}

model GetAvatarResponseBody = {
  data?: {
    avatar?: {
      avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
      avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXXX'),
      avatarName?: string(name='AvatarName', description='The name of the digital human.'),
      avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
      height?: int32(name='Height', description='The height of the digital human image in pixels.', example='1920'),
      portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='****571c704445f9a0ee011406c2****'),
      thumbnail?: string(name='Thumbnail', description='The thumbnail URL.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
      transparent?: boolean(name='Transparent', description='Indicates whether the digital human supports alpha channels.', example='true'),
      width?: int32(name='Width', description='The width of the digital human image in pixels.', example='1080'),
    }(name='Avatar', description='The information about the digital human.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetAvatarResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAvatarResponseBody(name='body'),
}

/**
 * @summary Queries the information about a trained digital human.
 *
 * @param request GetAvatarRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetAvatarResponse
 */
async function getAvatarWithOptions(request: GetAvatarRequest, runtime: Util.RuntimeOptions): GetAvatarResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.avatarId)) {
    query['AvatarId'] = request.avatarId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetAvatar',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a trained digital human.
 *
 * @param request GetAvatarRequest
 * @return GetAvatarResponse
 */
async function getAvatar(request: GetAvatarRequest): GetAvatarResponse {
  var runtime = new Util.RuntimeOptions{};
  return getAvatarWithOptions(request, runtime);
}

model GetAvatarTrainingJobRequest {
  jobId?: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetAvatarTrainingJobResponseBody = {
  data?: {
    avatarTrainingJob?: {
      avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
      avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXXX'),
      avatarName?: string(name='AvatarName', description='The name of the digital human.'),
      avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
      firstTrainingTime?: string(name='FirstTrainingTime', description='*   The time when the first training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
      jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****55d86f7f4587943ce7734d6b****'),
      lastTrainingTime?: string(name='LastTrainingTime', description='*   The time when the last training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
      message?: string(name='Message', description='The status description.'),
      portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='****571c704445f9a0ee011406c2****'),
      status?: string(name='Status', description='*   The state of the digital human training job.
*   Valid values: Init, Queuing, Training, Success, and Fail.', example='Success'),
      thumbnail?: string(name='Thumbnail', description='The thumbnail URL.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
      transparent?: boolean(name='Transparent', description='Indicates whether the input video supports alpha channels.', example='true'),
      video?: string(name='Video', description='The ID of the video used for training.', example='****571c704445f9a0ee011406c2****'),
    }(name='AvatarTrainingJob', description='The information about the digital human training job.'),
  }(name='Data', description='The data returned if the request was successful.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAvatarTrainingJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a digital human training job.
 *
 * @param request GetAvatarTrainingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetAvatarTrainingJobResponse
 */
async function getAvatarTrainingJobWithOptions(request: GetAvatarTrainingJobRequest, runtime: Util.RuntimeOptions): GetAvatarTrainingJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetAvatarTrainingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a digital human training job.
 *
 * @param request GetAvatarTrainingJobRequest
 * @return GetAvatarTrainingJobResponse
 */
async function getAvatarTrainingJob(request: GetAvatarTrainingJobRequest): GetAvatarTrainingJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getAvatarTrainingJobWithOptions(request, runtime);
}

model GetBatchMediaProducingJobRequest {
  jobId?: string(name='JobId', description='The ID of the quick video production job.', example='****b4549d46c88681030f6e****'),
}

model GetBatchMediaProducingJobResponseBody = {
  editingBatchJob?: {
    completeTime?: string(name='CompleteTime', description='The time when the job was complete.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:57:07Z'),
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:47:07Z'),
    editingConfig?: string(name='EditingConfig', description='The editing configurations. For more information, see [EditingConfig](~~2692547#1be9bba03b7qu~~).', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}'),
    extend?: string(name='Extend', description='The extended information. This parameter contains the following fields:

ErrorCode: the error code of the main job.

ErrorMessage: the error message of the main job.', example='{
	"ErrorCode": "InvalidMaterial.NotFound",
	"ErrorMessage": "The specified clips id not found:[\\\\"****30d0b5e871eebb2ff7f6c75a****\\\\"]"
}'),
    inputConfig?: string(name='InputConfig', description='The input configurations. For more information, see [InputConfig](~~2692547#2faed1559549n~~).'),
    jobId?: string(name='JobId', description='The job ID.', example='****b6b2750d4308892ac3330238****'),
    jobType?: string(name='JobType'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:57:07Z'),
    outputConfig?: string(name='OutputConfig', description='The output configurations. For more information, see [OutputConfig](~~2692547#447b928fcbuoa~~).', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 20,
  "MaxDuration": 15,
  "Width": 1080,
  "Height": 1920,
  "Video": {"Crf": 27}
}'),
    status?: string(name='Status', description='The job state. Valid values:

Init: The job is initialized.

Processing: The job is in progress.

Finished: The job is complete.', example='Finished'),
    subJobList?: [ 
      {
        errorCode?: string(name='ErrorCode', description='The error code that is returned if the subjob failed. This parameter is not returned if the subjob is successful.', example='InvalidMaterial.NotFound'),
        errorMessage?: string(name='ErrorMessage', description='The error message that is returned if the subjob failed. This parameter is not returned if the subjob is successful.', example='The specified clips id not found:["****30d0b5e871eebb2ff7f6c75a****"]'),
        jobId?: string(name='JobId', description='The subjob ID.', example='****8e81933d44e3ae69e2f81485****'),
        mediaId?: string(name='MediaId', description='The ID of the output media asset.', example='****1470b11171ee9d19e7e6c66a****'),
        mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http:/xxx.oss-cn-shanghai.aliyuncs.com/xxx_0.mp4'),
        projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****7cc47fe04eaa81bd853acb6a****'),
        status?: string(name='Status', description='The subjob state. Valid values:

Init: The subjob is initialized.

Processing: The subjob is in progress.

Success: The subjob is successful.

Failed: The subjob failed.', example='Success'),
      }
    ](name='SubJobList', description='The quick video production subjobs.'),
    userData?: string(name='UserData', description='The user-defined data, including the business and callback configurations. For more information, see [UserData](https://help.aliyun.com/document_detail/357745.html).', example='{"NotifyAddress":"http://xx.xx.xxx"}'),
  }(name='EditingBatchJob', description='The information about the quick video production job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model GetBatchMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetBatchMediaProducingJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a quick video production job, including the input parameters, job state, and the IDs and URLs of the output media assets. You can call this operation to query only quick video production jobs created within the past year.
 *
 * @param request GetBatchMediaProducingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetBatchMediaProducingJobResponse
 */
async function getBatchMediaProducingJobWithOptions(request: GetBatchMediaProducingJobRequest, runtime: Util.RuntimeOptions): GetBatchMediaProducingJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetBatchMediaProducingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a quick video production job, including the input parameters, job state, and the IDs and URLs of the output media assets. You can call this operation to query only quick video production jobs created within the past year.
 *
 * @param request GetBatchMediaProducingJobRequest
 * @return GetBatchMediaProducingJobResponse
 */
async function getBatchMediaProducingJob(request: GetBatchMediaProducingJobRequest): GetBatchMediaProducingJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getBatchMediaProducingJobWithOptions(request, runtime);
}

model GetCategoriesRequest {
  cateId?: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of CateId returned by the AddCategory operation that you called to create a category.
*   View the value of CateId returned by the GetCategories operation that you called to query a category.', example='33'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values: 10 to 100.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting rule of results. Valid values:

\\\\- CreationTime:Desc (default): The results are sorted in reverse chronological order based on the creation time.

\\\\- CreationTime:Asc: The results are sorted in chronological order based on the creation time.', example='CreationTime:Desc'),
  type?: string(name='Type', description='The type of the category. Valid values: default and material. A value of default indicates audio, video, and image files. This is the default value. A value of material indicates short video materials.', example='default'),
}

model GetCategoriesResponseBody = {
  category?: {
    cateId?: long(name='CateId', description='The category ID.', example='46'),
    cateName?: string(name='CateName', description='The category name.'),
    level?: long(name='Level', description='The level of the category. A value of **0** indicates a level-1 category, a value of **1** indicates a level-2 category, and a value of **2** indicates a level-3 category.', example='0'),
    parentId?: long(name='ParentId', description='The ID of the parent category.', example='-1'),
    type?: string(name='Type', description='The type of the category. Valid values:

*   **default**: audio, video, and image files. This is the default value.
*   **material**: short video materials.', example='default'),
  }(name='Category', description='The information about the category.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  subCategories?: {
    category?: [ 
    {
      cateId?: long(name='CateId', description='The category ID.', example='129'),
      cateName?: string(name='CateName', description='The category name.

*   The value can be up to 64 bytes in length.
*   The value is encoded in UTF-8.'),
      level?: long(name='Level', description='The level of the category. A value of **0** indicates a level-1 category, a value of **1** indicates a level-2 category, and a value of **2** indicates a level-3 category.', example='1'),
      parentId?: long(name='ParentId', description='The ID of the parent category.', example='46'),
      subTotal?: long(name='SubTotal', description='The total number of subcategories.', example='100'),
      type?: string(name='Type', description='The type of the category. Valid values:

*   **default**: audio, video, and image files. This is the default value.
*   **material**: short video materials.', example='default'),
    }
  ](name='Category')
  }(name='SubCategories', description='The subcategories in the category.'),
  subTotal?: long(name='SubTotal', description='The total number of subcategories.', example='100'),
}

model GetCategoriesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCategoriesResponseBody(name='body'),
}

/**
 * @summary Queries the information about a category and its subcategories.
 *
 * @description You can call this operation to query the information about a category and its subcategories based on the category ID and category type.
 *
 * @param request GetCategoriesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetCategoriesResponse
 */
async function getCategoriesWithOptions(request: GetCategoriesRequest, runtime: Util.RuntimeOptions): GetCategoriesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.cateId)) {
    query['CateId'] = request.cateId;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetCategories',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a category and its subcategories.
 *
 * @description You can call this operation to query the information about a category and its subcategories based on the category ID and category type.
 *
 * @param request GetCategoriesRequest
 * @return GetCategoriesResponse
 */
async function getCategories(request: GetCategoriesRequest): GetCategoriesResponse {
  var runtime = new Util.RuntimeOptions{};
  return getCategoriesWithOptions(request, runtime);
}

model GetContentAnalyzeConfigResponseBody = {
  contentAnalyzeConfig?: {
    auto?: boolean(name='Auto', example='true'),
    saveType?: string(name='SaveType', example='TEXT,FACE'),
    templateId?: string(name='TemplateId', example='S00000101-100070'),
  }(name='ContentAnalyzeConfig'),
  requestId?: string(name='RequestId', example='31FEC819-2344-5771-9366-9172DB0D26C9'),
}

model GetContentAnalyzeConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetContentAnalyzeConfigResponseBody(name='body'),
}

/**
 * @summary 获取内容分析搜索配置
 *
 * @param request GetContentAnalyzeConfigRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetContentAnalyzeConfigResponse
 */
async function getContentAnalyzeConfigWithOptions(runtime: Util.RuntimeOptions): GetContentAnalyzeConfigResponse {
  var req = new OpenApi.OpenApiRequest{};
  var params = new OpenApi.Params{
    action = 'GetContentAnalyzeConfig',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 获取内容分析搜索配置
 *
 * @return GetContentAnalyzeConfigResponse
 */
async function getContentAnalyzeConfig(): GetContentAnalyzeConfigResponse {
  var runtime = new Util.RuntimeOptions{};
  return getContentAnalyzeConfigWithOptions(runtime);
}

model GetCustomTemplateRequest {
  subtype?: int32(name='Subtype', description='The template subtype.', example='1'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
  type?: int32(name='Type', description='The ID of the template type that is used to query the default template. This parameter is required if TemplateId is not specified.', example='1'),
}

model GetCustomTemplateResponseBody = {
  customTemplate?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-01-01T10:00:00Z'),
    frontendHint?: {
      transcodeTemplateHint?: {
        bitrateControlType?: string(name='BitrateControlType'),
      }(name='TranscodeTemplateHint'),
    }(name='FrontendHint'),
    isDefault?: boolean(name='IsDefault', description='Indicates whether the template is the default template.', example='true'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-01-01T11:00:00Z'),
    status?: string(name='Status', description='The template state.', example='Normal'),
    subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='1'),
    subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='Normal'),
    templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Type":"Normal","FrameType":"normal","Time":0,"Count":10}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
    templateName?: string(name='TemplateName', description='The template name.', example='测试转码模板'),
    type?: int32(name='Type', description='The type ID of the template.', example='2'),
    typeName?: string(name='TypeName', description='The type name of the template.', example='SnapshotTemplate'),
  }(name='CustomTemplate', description='The template information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCustomTemplateResponseBody(name='body'),
}

/**
 * @summary Queries the information about a custom template.
 *
 * @description You can call this operation to query the information about a template with the ID specified by the TemplateId parameter. You can also query the information about the default template. If TemplateId is specified, other parameters are ignored and the template whose ID is specified is queried. If TemplateId is not specified, the default template is queried based on other parameters. In this case, Type is required.
 * Template types:
 * 1.  1: transcoding template.
 * 2.  2: snapshot template.
 * 3.  3: animated image template.
 * 4.  4\\. image watermark template.
 * 5.  5: text watermark template.
 * 6.  6: subtitle template.
 * 7.  7: AI-assisted content moderation template.
 * 8.  8: AI-assisted intelligent thumbnail template.
 * 9.  9: AI-assisted intelligent erasure template.
 * Subtypes of transcoding templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (AudioTranscode): audio transcoding template.
 * 3.  3 (Remux): container format conversion template.
 * 4.  4 (NarrowBandV1): Narrowband HD 1.0 template.
 * 5.  5 (NarrowBandV2): Narrowband HD 2.0 template.
 * Subtypes of snapshot templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (Sprite): sprite template.
 * 3.  3 (WebVtt): WebVTT template.
 * Subtypes of AI-assisted content moderation templates:
 * 1.  1 (Video): video moderation template.
 * 2.  2 (Audio): audio moderation template.
 * 3.  3 (Image): image moderation template.
 * Subtypes of AI-assisted intelligent erasure templates:
 * 1.  1 (VideoDelogo): logo erasure template.
 * 2.  2 (VideoDetext): subtitle erasure template.
 *
 * @param request GetCustomTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetCustomTemplateResponse
 */
async function getCustomTemplateWithOptions(request: GetCustomTemplateRequest, runtime: Util.RuntimeOptions): GetCustomTemplateResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.subtype)) {
    query['Subtype'] = request.subtype;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetCustomTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a custom template.
 *
 * @description You can call this operation to query the information about a template with the ID specified by the TemplateId parameter. You can also query the information about the default template. If TemplateId is specified, other parameters are ignored and the template whose ID is specified is queried. If TemplateId is not specified, the default template is queried based on other parameters. In this case, Type is required.
 * Template types:
 * 1.  1: transcoding template.
 * 2.  2: snapshot template.
 * 3.  3: animated image template.
 * 4.  4\\. image watermark template.
 * 5.  5: text watermark template.
 * 6.  6: subtitle template.
 * 7.  7: AI-assisted content moderation template.
 * 8.  8: AI-assisted intelligent thumbnail template.
 * 9.  9: AI-assisted intelligent erasure template.
 * Subtypes of transcoding templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (AudioTranscode): audio transcoding template.
 * 3.  3 (Remux): container format conversion template.
 * 4.  4 (NarrowBandV1): Narrowband HD 1.0 template.
 * 5.  5 (NarrowBandV2): Narrowband HD 2.0 template.
 * Subtypes of snapshot templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (Sprite): sprite template.
 * 3.  3 (WebVtt): WebVTT template.
 * Subtypes of AI-assisted content moderation templates:
 * 1.  1 (Video): video moderation template.
 * 2.  2 (Audio): audio moderation template.
 * 3.  3 (Image): image moderation template.
 * Subtypes of AI-assisted intelligent erasure templates:
 * 1.  1 (VideoDelogo): logo erasure template.
 * 2.  2 (VideoDetext): subtitle erasure template.
 *
 * @param request GetCustomTemplateRequest
 * @return GetCustomTemplateResponse
 */
async function getCustomTemplate(request: GetCustomTemplateRequest): GetCustomTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return getCustomTemplateWithOptions(request, runtime);
}

model GetCustomizedVoiceRequest {
  voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
}

model GetCustomizedVoiceResponseBody = {
  data?: {
    customizedVoice?: {
      demoAudioMediaId?: string(name='DemoAudioMediaId', description='The media asset ID of the sample audio file.', example='****42d3c312402982be65975f5b****'),
      gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
      scenario?: string(name='Scenario', description='The demonstration scenario.

Valid values:

*   **story**
*   **interaction**
*   **navigation**', example='interaction'),
      voiceDesc?: string(name='VoiceDesc', description='The voice description.'),
      voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
      voiceName?: string(name='VoiceName', description='The voice name.'),
    }(name='CustomizedVoice', description='The personalized human voice.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetCustomizedVoiceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCustomizedVoiceResponseBody(name='body'),
}

/**
 * @summary Queries the information about a personalized human voice.
 *
 * @param request GetCustomizedVoiceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetCustomizedVoiceResponse
 */
async function getCustomizedVoiceWithOptions(request: GetCustomizedVoiceRequest, runtime: Util.RuntimeOptions): GetCustomizedVoiceResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.voiceId)) {
    query['VoiceId'] = request.voiceId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetCustomizedVoice',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a personalized human voice.
 *
 * @param request GetCustomizedVoiceRequest
 * @return GetCustomizedVoiceResponse
 */
async function getCustomizedVoice(request: GetCustomizedVoiceRequest): GetCustomizedVoiceResponse {
  var runtime = new Util.RuntimeOptions{};
  return getCustomizedVoiceWithOptions(request, runtime);
}

model GetCustomizedVoiceJobRequest {
  jobId?: string(name='JobId', description='The ID of the human voice cloning job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetCustomizedVoiceJobResponseBody = {
  data?: {
    customizedVoiceJob?: {
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-06-07T02:27:08Z'),
      gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
      jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****571c704445f9a0ee011406c2****'),
      message?: string(name='Message', description='The status description.'),
      scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation', example='story'),
      status?: string(name='Status', description='The job state. Valid values:

*   Initialization
*   AudioDetecting
*   PreTraining
*   Training
*   Success
*   Fail', example='Fail'),
      type?: string(name='Type', description='The type of the human voice cloning job. Valid values:

*   Basic
*   Standard', example='Standard'),
      voiceDesc?: string(name='VoiceDesc', description='The voice description.', example='This is an exclusive voice'),
      voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
      voiceName?: string(name='VoiceName', description='The voice name.', example='Xiaozhuan'),
    }(name='CustomizedVoiceJob', description='The information about the human voice cloning job.'),
  }(name='Data', description='The data returned if the request was successful.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a human voice cloning job.
 *
 * @param request GetCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetCustomizedVoiceJobResponse
 */
async function getCustomizedVoiceJobWithOptions(request: GetCustomizedVoiceJobRequest, runtime: Util.RuntimeOptions): GetCustomizedVoiceJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a human voice cloning job.
 *
 * @param request GetCustomizedVoiceJobRequest
 * @return GetCustomizedVoiceJobResponse
 */
async function getCustomizedVoiceJob(request: GetCustomizedVoiceJobRequest): GetCustomizedVoiceJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getCustomizedVoiceJobWithOptions(request, runtime);
}

model GetDefaultStorageLocationResponseBody = {
  bucket?: string(name='Bucket', example='oss-test-bucket'),
  path?: string(name='Path', example='ice/dir'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
  status?: string(name='Status', example='normal'),
  storageType?: string(name='StorageType', example='user_oss_bucket'),
}

model GetDefaultStorageLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDefaultStorageLocationResponseBody(name='body'),
}

/**
 * @summary 获取用户默认存储地址
 *
 * @param request GetDefaultStorageLocationRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetDefaultStorageLocationResponse
 */
async function getDefaultStorageLocationWithOptions(runtime: Util.RuntimeOptions): GetDefaultStorageLocationResponse {
  var req = new OpenApi.OpenApiRequest{};
  var params = new OpenApi.Params{
    action = 'GetDefaultStorageLocation',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 获取用户默认存储地址
 *
 * @return GetDefaultStorageLocationResponse
 */
async function getDefaultStorageLocation(): GetDefaultStorageLocationResponse {
  var runtime = new Util.RuntimeOptions{};
  return getDefaultStorageLocationWithOptions(runtime);
}

model GetDemonstrationForCustomizedVoiceJobRequest {
  scenario?: string(name='Scenario', description='The demonstration scenario.

Valid values:

*   **story**
*   **interaction**
*   **navigation**

This parameter is required.', example='story'),
}

model GetDemonstrationForCustomizedVoiceJobResponseBody = {
  data?: {
    demonstrationList?: [ 
      {
        audioId?: int32(name='AudioId', description='The sequence number of the text, which corresponds to the AduioRecordId parameter to be passed during audio check.', example='2'),
        demoAudio?: string(name='DemoAudio', description='The URL of the sample audio.

*   The value is an Object Storage Service (OSS) URL.

    **

    **Note**: The URL expires in 12 hours.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/1.wav'),
        text?: string(name='Text', description='The text content to be read.'),
      }
    ](name='DemonstrationList', description='A list of 20 text entries to be read and the corresponding sample audio.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetDemonstrationForCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDemonstrationForCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Queries the text to be read and sample audio for training a personalized human voice.
 *
 * @param request GetDemonstrationForCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetDemonstrationForCustomizedVoiceJobResponse
 */
async function getDemonstrationForCustomizedVoiceJobWithOptions(request: GetDemonstrationForCustomizedVoiceJobRequest, runtime: Util.RuntimeOptions): GetDemonstrationForCustomizedVoiceJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.scenario)) {
    query['Scenario'] = request.scenario;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetDemonstrationForCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the text to be read and sample audio for training a personalized human voice.
 *
 * @param request GetDemonstrationForCustomizedVoiceJobRequest
 * @return GetDemonstrationForCustomizedVoiceJobResponse
 */
async function getDemonstrationForCustomizedVoiceJob(request: GetDemonstrationForCustomizedVoiceJobRequest): GetDemonstrationForCustomizedVoiceJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getDemonstrationForCustomizedVoiceJobWithOptions(request, runtime);
}

model GetDynamicImageJobRequest {
  jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
}

model GetDynamicImageJobResponseBody = {
  dynamicImageJob?: {
    code?: string(name='Code', description='Error codes', example='ResourceNotFound'),
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
    input?: {
      media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://test-bucket/sample-input.mp4'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='sample-input.mp4'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
    message?: string(name='Message', description='The error message that is returned.', example='The specified resource for "CustomTemplate" could not be found.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
    name?: string(name='Name', description='The name of the job.', example='SampleJob'),
    output?: {
      media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='****d80e4e4044975745c14b****'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='sample-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='path/to/object'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the input file. Valid values: OSS: an OSS object. Media: a media asset.', example='Media'),
    }(name='Output', description='The output of the job.'),
    outputUrl?: string(name='OutputUrl', description='The URL of the output animated image.', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/output.gif'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****d80e4e4044975745c14b****'),
    status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
    templateConfig?: string(name='TemplateConfig', description='The animation template configuration.', example='{"Format":"gif","Fps":5,"Height":1080,"Width":1920}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****d80e4e4044975745c14b****'),
    triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
    userData?: string(name='UserData', description='The user-defined data.', example='{"sampleParam": "sampleValue"}'),
  }(name='DynamicImageJob', description='The information about the snapshot job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******36-3C1E-4417-BDB2-1E034F******'),
}

model GetDynamicImageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDynamicImageJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about an image animation job.
 *
 * @param request GetDynamicImageJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetDynamicImageJobResponse
 */
async function getDynamicImageJobWithOptions(request: GetDynamicImageJobRequest, runtime: Util.RuntimeOptions): GetDynamicImageJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetDynamicImageJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about an image animation job.
 *
 * @param request GetDynamicImageJobRequest
 * @return GetDynamicImageJobResponse
 */
async function getDynamicImageJob(request: GetDynamicImageJobRequest): GetDynamicImageJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getDynamicImageJobWithOptions(request, runtime);
}

model GetEditingProjectRequest {
  projectId?: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='****fb2101bf24b2754cb318787dc****'),
  requestSource?: string(name='RequestSource', description='The ID of the request source. Valid values:

\\\\- OpenAPI (default): Timeline conversion is not performed.

\\\\- WebSDK: If you specify this value, the project timeline is automatically converted into the frontend style, and the materials in the timeline are associated with the project to enable preview by using frontend web SDKs.', example='WebSDK'),
}

model GetEditingProjectResponseBody = {
  project?: {
    businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{ "OutputMediaConfig" : { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path" }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
    businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

Reserving

ReservationCanceled

BroadCasting

LoadingFailed

LiveFinished', example='Reserving'),
    clipsParam?: string(name='ClipsParam', description='The material parameter corresponding to the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified. For more information<props="china">, see [Create and use a regular template](https://help.aliyun.com/document_detail/328557.html) and [Create and use an advanced template](https://help.aliyun.com/document_detail/291418.html).'),
    coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='oss://example-bucket/example.jpg'),
    createSource?: string(name='CreateSource', description='The method for creating the online editing project. Valid values:

\\\\- OpenAPI

\\\\- AliyunConsole

\\\\- WebSDK

\\\\- LiveEditingOpenAPI

\\\\- LiveEditingConsole', example='OpenAPI'),
    createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2020-12-20T12:00:00Z'),
    description?: string(name='Description', description='The description of the online editing project.'),
    duration?: long(name='Duration', description='The total duration of the online editing project.', example='24.120000'),
    modifiedSource?: string(name='ModifiedSource', description='The method for editing the online editing project. Valid values:

\\\\- OpenAPI

\\\\- AliyunConsole

\\\\- WebSDK

\\\\- LiveEditingOpenAPI

\\\\- LiveEditingConsole', example='OpenAPI'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last modified.', example='2020-12-20T13:00:00Z'),
    projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fb2101bf24b2754cb318787dc****'),
    projectType?: string(name='ProjectType', description='The type of the editing project. Default value: EditingProject. Valid values:

\\\\- EditingProject: a regular editing project.

\\\\- LiveEditingProject: a live stream editing project.', example='EditingProject'),
    status?: string(name='Status', description='The status of the online editing project. Valid values:

\\\\- Draft

\\\\- Editing

\\\\- Producing

\\\\- Produced

\\\\- ProduceFailed

\\\\- Deleted', example='Editing'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
    templateType?: string(name='TemplateType', description='The template type of the online editing project. Valid values:

\\\\- Timeline

\\\\- VETemplate', example='Timeline'),
    timeline?: string(name='Timeline', description='The timeline of the online editing project.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****9b4d7cf14dc7b83b0e801cbe****"},{"MediaId":"****9b4d7cf14dc7b83b0e801cbe****"},{"MediaId":"****1656bca4474999c961a6d2a2****"}]}]}'),
    timelineConvertErrorMessage?: string(name='TimelineConvertErrorMessage', description='The error message returned if the project conversion failed. The error message displays the detailed information about the failure, and is returned only if the value of TimelineConvertStatus is ConvertFailed.', example='The StorageLocation must be in the same division(apiRegion) as ICE service access point.'),
    timelineConvertStatus?: string(name='TimelineConvertStatus', description='The project conversion status. Conversion of an API-style timeline into a frontend-style timeline is an asynchronous process and takes effect only if RequestSource:WebSDK is specified.

\\\\- Unconverted

\\\\- Converting

\\\\- Converted

\\\\- ConvertFailed', example='Converted'),
    title?: string(name='Title', description='The title of the online editing project.'),
  }(name='Project', description='The information about the online editing project.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model GetEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEditingProjectResponseBody(name='body'),
}

/**
 * @summary Queries the information about an online editing project.
 *
 * @param request GetEditingProjectRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetEditingProjectResponse
 */
async function getEditingProjectWithOptions(request: GetEditingProjectRequest, runtime: Util.RuntimeOptions): GetEditingProjectResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  if (!Util.isUnset(request.requestSource)) {
    query['RequestSource'] = request.requestSource;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetEditingProject',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about an online editing project.
 *
 * @param request GetEditingProjectRequest
 * @return GetEditingProjectResponse
 */
async function getEditingProject(request: GetEditingProjectRequest): GetEditingProjectResponse {
  var runtime = new Util.RuntimeOptions{};
  return getEditingProjectWithOptions(request, runtime);
}

model GetEditingProjectMaterialsRequest {
  projectId?: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='*****fb2101cb318*****'),
}

model GetEditingProjectMaterialsResponseBody = {
  liveMaterials?: [ 
    {
      appName?: string(name='AppName', description='The application name of the live stream.', example='testrecord'),
      domainName?: string(name='DomainName', description='The domain name of the live stream.', example='test.alivecdn.com'),
      liveUrl?: string(name='LiveUrl', description='The URL of the live stream.', example='rtmp://test.alivecdn.com/testrecord/teststream'),
      streamName?: string(name='StreamName', description='The name of the live stream.', example='testrecord'),
    }
  ](name='LiveMaterials', description='The materials associated with the live stream.'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
            duration?: string(name='Duration', description='The duration.', example='216.206667'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='540'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='960'),
          }(name='FileBasicInfo', description='The basic information of the file, such as the duration and size.'),
        }
      ](name='FileInfoList', description='The information about the file.'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.', example='video'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://sample-bucket.oss-cn-shanghai.aliyuncs.com/sample-corver.jpg?Expires=1628670610&OSSAccessKeyId=AK&Signature=signature'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-26T04:11:08Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-26T04:11:08Z'),
        description?: string(name='Description', description='The description of the media asset.', example='sample_description'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/file.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****64623a94eca8516569c8f*****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-26T04:11:08Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='null'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite of the media asset', example='null'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.', example='file.mp4'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.

Valid values:

*   TranscodeSuccess: transcoding completed.
*   TranscodeFailed: transcoding failed.
*   Init: initializing.
*   Transcoding: transcoding in progress.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information of the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****64623a94eca8516569c8fe*****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  projectId?: string(name='ProjectId', description='The project ID.', example='*****67ae06542b9b93e0d1c387*****'),
  projectMaterials?: [ string ](name='ProjectMaterials', description='The materials associated with the editing project. A live stream editing project will be associated with a regular editing project after the live streaming ends.', example='*****9b145c5cafc2e057304fcd*****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******89-C21D-4B78-AE24-3788B8******'),
}

model GetEditingProjectMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEditingProjectMaterialsResponseBody(name='body'),
}

/**
 * @summary Queries all materials associated with an online editing project.
 *
 * @param request GetEditingProjectMaterialsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetEditingProjectMaterialsResponse
 */
async function getEditingProjectMaterialsWithOptions(request: GetEditingProjectMaterialsRequest, runtime: Util.RuntimeOptions): GetEditingProjectMaterialsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetEditingProjectMaterials',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries all materials associated with an online editing project.
 *
 * @param request GetEditingProjectMaterialsRequest
 * @return GetEditingProjectMaterialsResponse
 */
async function getEditingProjectMaterials(request: GetEditingProjectMaterialsRequest): GetEditingProjectMaterialsResponse {
  var runtime = new Util.RuntimeOptions{};
  return getEditingProjectMaterialsWithOptions(request, runtime);
}

model GetEventCallbackResponseBody = {
  authKey?: string(name='AuthKey', description='The authentication key. This parameter is returned only for HTTP callbacks.', example='TestKey001'),
  authSwitch?: string(name='AuthSwitch', description='Specifies whether callback authentication is enabled. This parameter is returned only for **HTTP** callbacks. Valid values:

*   **on**
*   **off**', example='on'),
  callbackQueueName?: string(name='CallbackQueueName', description='The name of the Simple Message Queue (SMQ) queue to which callback messages are sent.', example='ice-callback-queue'),
  callbackType?: string(name='CallbackType', description='The callback method. Valid values:

*   **HTTP**
*   **MNS**', example='HTTP'),
  callbackURL?: string(name='CallbackURL', description='The callback URL to which event notifications are sent.', example='http://xxx.yyy/callback'),
  eventTypeList?: string(name='EventTypeList', description='The type of the callback event. Multiple values are separated with commas (,). For more information about callback event types, see [Event notification content](https://help.aliyun.com/document_detail/610204.html).', example='ProduceMediaComplete,TranscodeComplete'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetEventCallbackResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEventCallbackResponseBody(name='body'),
}

/**
 * @summary Queries event callback configurations.
 *
 * @param request GetEventCallbackRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetEventCallbackResponse
 */
async function getEventCallbackWithOptions(runtime: Util.RuntimeOptions): GetEventCallbackResponse {
  var req = new OpenApi.OpenApiRequest{};
  var params = new OpenApi.Params{
    action = 'GetEventCallback',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries event callback configurations.
 *
 * @return GetEventCallbackResponse
 */
async function getEventCallback(): GetEventCallbackResponse {
  var runtime = new Util.RuntimeOptions{};
  return getEventCallbackWithOptions(runtime);
}

model GetLiveEditingIndexFileRequest {
  appName?: string(name='AppName', description='The application name of the live stream.', example='testrecord'),
  domainName?: string(name='DomainName', description='The domain name of the live stream.', example='test.alivecdn.com'),
  projectId?: string(name='ProjectId', description='The ID of the live stream editing project.', example='*****cb6307a4edea614d8b3f3c*****'),
  streamName?: string(name='StreamName', description='The name of the live stream.', example='teststream'),
}

model GetLiveEditingIndexFileResponseBody = {
  indexFile?: string(name='IndexFile', description='The URL of the index file.'),
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
}

model GetLiveEditingIndexFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveEditingIndexFileResponseBody(name='body'),
}

/**
 * @summary Queries the index file of a live stream. The index file is used to preview an editing project in the console.
 *
 * @param request GetLiveEditingIndexFileRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveEditingIndexFileResponse
 */
async function getLiveEditingIndexFileWithOptions(request: GetLiveEditingIndexFileRequest, runtime: Util.RuntimeOptions): GetLiveEditingIndexFileResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.appName)) {
    query['AppName'] = request.appName;
  }
  if (!Util.isUnset(request.domainName)) {
    query['DomainName'] = request.domainName;
  }
  if (!Util.isUnset(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  if (!Util.isUnset(request.streamName)) {
    query['StreamName'] = request.streamName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetLiveEditingIndexFile',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the index file of a live stream. The index file is used to preview an editing project in the console.
 *
 * @param request GetLiveEditingIndexFileRequest
 * @return GetLiveEditingIndexFileResponse
 */
async function getLiveEditingIndexFile(request: GetLiveEditingIndexFileRequest): GetLiveEditingIndexFileResponse {
  var runtime = new Util.RuntimeOptions{};
  return getLiveEditingIndexFileWithOptions(request, runtime);
}

model GetLiveEditingJobRequest {
  jobId?: string(name='JobId', description='The ID of the live editing job.', example='****d80e4e4044975745c14b****'),
}

model GetLiveEditingJobResponseBody = {
  liveEditingJob?: {
    clips?: string(name='Clips', description='The clips.', example='[{\\\\"StartTime\\\\": \\\\" 2021-06-21T08:01:00Z\\\\",  \\\\"EndTime\\\\": \\\\" 2021-06-21T08:03:00Z\\\\" }]'),
    code?: string(name='Code', description='The response code. Note: Pay attention to this parameter if the job failed.', example='InvalidParameter'),
    completeTime?: string(name='CompleteTime', description='The time when the live editing job was completed. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:52Z'),
    creationTime?: string(name='CreationTime', description='The time when the live editing job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
    jobId?: string(name='JobId', description='The ID of the live editing job.', example='****cdb3e74639973036bc84****'),
    liveStreamConfig?: {
      appName?: string(name='AppName', description='The name of the application to which the live stream belongs.', example='app'),
      domainName?: string(name='DomainName', description='The domain name of the live stream.', example='domain.com'),
      streamName?: string(name='StreamName', description='The name of the live stream.', example='streamName'),
    }(name='LiveStreamConfig', description='The live editing configurations.'),
    mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****0cc6ba49eab379332c5b****'),
    mediaProduceConfig?: {
      mode?: string(name='Mode', description='The editing mode. Default value: Accurate.', example='Accurate'),
    }(name='MediaProduceConfig', description='The production configurations.'),
    mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example2.mp4'),
    message?: string(name='Message', description='The returned message. Note: Pay attention to this parameter if the job failed.', example='The specific parameter LiveStreamConfig is not valid.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the live editing job was last modified. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:49Z'),
    outputMediaConfig?: {
      bitrate?: long(name='Bitrate', description='The bitrate of the output file. Unit: Kbit/s. You can leave this parameter empty. The default value is the maximum bitrate of the input materials.', example='1000'),
      fileName?: string(name='FileName', description='If OutputMediaTarget is set to vod-media, this parameter indicates the file name of the output file. The value contains the file name extension but not the path.', example='test.mp4'),
      height?: int32(name='Height', description='The height of the output file. You can leave this parameter empty. The default value is the maximum height of the input materials.', example='480'),
      mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='https://testice-testbucket.oss-cn-shanghai.aliyuncs.com/test.mp4'),
      storageLocation?: string(name='StorageLocation', description='If OutputMediaTarget is set to vod-media, this parameter indicates the storage location of the media asset in ApsaraVideo VOD. The storage location is the path of the file in ApsaraVideo VOD, excluding the prefix http://. Example: outin-xxxxxx.oss-cn-shanghai.aliyuncs.com.', example='outin-xxxxxx.oss-cn-shanghai.aliyuncs.com'),
      vodTemplateGroupId?: string(name='VodTemplateGroupId', description='The ID of the VOD transcoding template group. If VOD transcoding is not required, set the value to VOD_NO_TRANSCODE.', example='VOD_NO_TRANSCODE'),
      width?: int32(name='Width', description='The width of the output file. You can leave this parameter empty. The default value is the maximum width of the input materials.', example='640'),
    }(name='OutputMediaConfig', description='The storage configurations of the output file.'),
    projectId?: string(name='ProjectId', description='The ID of the live editing project.', example='****fddd7748b58bf1d47e95****'),
    status?: string(name='Status', description='The state of the live editing job. Valid values: Init, Queuing, Processing, Success, and Failed.', example='Success'),
    userData?: string(name='UserData', description='The user-defined data.', example='{"key": "value\\\\"}'),
  }(name='LiveEditingJob', description='The information about the live editing job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model GetLiveEditingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveEditingJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a live editing job. The requested information includes the state, timeline, and template of the job, the ID and URL of the output file, and the configurations of the job. You can call this operation to query only live editing jobs created within the past year.
 *
 * @param request GetLiveEditingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveEditingJobResponse
 */
async function getLiveEditingJobWithOptions(request: GetLiveEditingJobRequest, runtime: Util.RuntimeOptions): GetLiveEditingJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetLiveEditingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a live editing job. The requested information includes the state, timeline, and template of the job, the ID and URL of the output file, and the configurations of the job. You can call this operation to query only live editing jobs created within the past year.
 *
 * @param request GetLiveEditingJobRequest
 * @return GetLiveEditingJobResponse
 */
async function getLiveEditingJob(request: GetLiveEditingJobRequest): GetLiveEditingJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getLiveEditingJobWithOptions(request, runtime);
}

model GetLiveRecordJobRequest {
  jobId?: string(name='JobId', description='The ID of the recording job.

This parameter is required.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
}

model GetLiveRecordJobResponseBody = {
  recordJob?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T02:48:58Z'),
    jobId?: string(name='JobId', description='The ID of the recording job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
    name?: string(name='Name', description='The name of the recording job.'),
    notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify'),
    recordOutput?: {
      bucket?: string(name='Bucket', description='The bucket name.', example='imsbucket1'),
      endpoint?: string(name='Endpoint', description='The endpoint of the storage service.', example='oss-cn-shanghai.aliyuncs.com'),
      type?: string(name='Type', description='The type of the storage address.

Valid values:

*   vod
*   oss', example='oss'),
    }(name='RecordOutput', description='The storage address of the recording.'),
    status?: string(name='Status', description='The state of the recording job.

Valid values:

*   paused: The job is paused.
*   initial: The job is not started.
*   started: The job is in progress.', example='paused'),
    streamInput?: {
      type?: string(name='Type', description='The type of the live stream. The value can only be rtmp.', example='rtmp'),
      url?: string(name='Url', description='The URL of the live stream.', example='rtmp://example.com/app/stream'),
    }(name='StreamInput', description='The URL of the live stream.'),
    templateId?: string(name='TemplateId', description='The ID of the recording template.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
    templateName?: string(name='TemplateName', description='The name of the recording template.', example='test template'),
  }(name='RecordJob', description='The details of the recording job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='B57A046C-CE33-5FBB-B57A-D2B89ACF6907'),
}

model GetLiveRecordJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveRecordJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a live stream recording job.
 *
 * @param request GetLiveRecordJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveRecordJobResponse
 */
async function getLiveRecordJobWithOptions(request: GetLiveRecordJobRequest, runtime: Util.RuntimeOptions): GetLiveRecordJobResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetLiveRecordJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a live stream recording job.
 *
 * @param request GetLiveRecordJobRequest
 * @return GetLiveRecordJobResponse
 */
async function getLiveRecordJob(request: GetLiveRecordJobRequest): GetLiveRecordJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getLiveRecordJobWithOptions(request, runtime);
}

model GetLiveRecordTemplateRequest {
  jobId?: string(name='JobId', description='The ID of the recording job. You can specify the JobId parameter to retrieve the snapshot of the template used by the job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
}

model GetLiveRecordTemplateResponseBody = {
  recordTemplate?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
    lastModified?: string(name='LastModified', description='The time when the template was last modified.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
    name?: string(name='Name', description='The template name.', example='test template'),
    recordFormatList?: [ 
      {
        cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds. If you do not specify this parameter, the default value 6 hours is used.', example='7200'),
        format?: string(name='Format', description='The output file format.', example='m3u8'),
        ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording file that is stored in Object Storage Service (OSS).', example='record/{JobId}/{Sequence}{EscapedStartTime}{EscapedEndTime}'),
        sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds.', example='30'),
        sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
      }
    ](name='RecordFormatList', description='The list of recording formats.'),
    templateId?: string(name='TemplateId', description='The template ID.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
    type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
  }(name='RecordTemplate', description='The recording template.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C892855F-95DF-50D6-A28C-279ABDB76810'),
}

model GetLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveRecordTemplateResponseBody(name='body'),
}

/**
 * @summary Queries the information about a live stream recording template or a snapshot of the template.
 *
 * @param request GetLiveRecordTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveRecordTemplateResponse
 */
async function getLiveRecordTemplateWithOptions(request: GetLiveRecordTemplateRequest, runtime: Util.RuntimeOptions): GetLiveRecordTemplateResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetLiveRecordTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a live stream recording template or a snapshot of the template.
 *
 * @param request GetLiveRecordTemplateRequest
 * @return GetLiveRecordTemplateResponse
 */
async function getLiveRecordTemplate(request: GetLiveRecordTemplateRequest): GetLiveRecordTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return getLiveRecordTemplateWithOptions(request, runtime);
}

model GetLiveSnapshotJobRequest {
  jobId?: string(name='JobId', description='The job ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model GetLiveSnapshotJobResponseBody = {
  callbackUrl?: string(name='CallbackUrl', description='The snapshot callback URL.', example='http://www.aliyun.com/snapshot/callback'),
  createTime?: string(name='CreateTime', description='The time when the file was created.', example='2022-02-02T22:22:22Z'),
  jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287782****'),
  jobName?: string(name='JobName', description='The name of the job.'),
  lastModified?: string(name='LastModified', description='The time when the file was last modified.', example='2022-02-02T22:22:22Z'),
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.', example='snapshot/{JobId}.jpg'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.', example='snapshot/{JobId}/{UnixTimestamp}.jpg'),
  snapshotOutput?: {
    bucket?: string(name='Bucket', description='The bucket of the output endpoint. If the storage type is set to oss, the OSS bucket is returned.', example='testbucket'),
    endpoint?: string(name='Endpoint', description='The output endpoint. If the storage type is set to oss, the Object Storage Service (OSS) domain name is returned.', example='oss-cn-shanghai.aliyuncs.com'),
    storageType?: string(name='StorageType', description='The storage type. The value can only be oss.', example='oss'),
  }(name='SnapshotOutput', description='The output information.'),
  status?: string(name='Status', description='The state of the job.

Valid values:

*   init: The job is not started.
*   paused: The job is paused.
*   started: The job is in progress.', example='started'),
  streamInput?: {
    type?: string(name='Type', description='The type of the input stream. The value can only be rtmp.', example='rtmp'),
    url?: string(name='Url', description='The URL of the input stream.', example='rtmp://www.aliyun.com/stream'),
  }(name='StreamInput', description='The input information.'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287666****'),
  templateName?: string(name='TemplateName', description='The name of the template.'),
  timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots.', example='5'),
}

model GetLiveSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveSnapshotJobResponseBody(name='body'),
}

/**
 * @summary Queries the information a live stream snapshot job.
 *
 * @param request GetLiveSnapshotJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveSnapshotJobResponse
 */
async function getLiveSnapshotJobWithOptions(request: GetLiveSnapshotJobRequest, runtime: Util.RuntimeOptions): GetLiveSnapshotJobResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetLiveSnapshotJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information a live stream snapshot job.
 *
 * @param request GetLiveSnapshotJobRequest
 * @return GetLiveSnapshotJobResponse
 */
async function getLiveSnapshotJob(request: GetLiveSnapshotJobRequest): GetLiveSnapshotJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getLiveSnapshotJobWithOptions(request, runtime);
}

model GetLiveSnapshotTemplateRequest {
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model GetLiveSnapshotTemplateResponseBody = {
  createTime?: string(name='CreateTime', description='The time when the configuration was modified.', example='2022-02-02T22:22:22Z'),
  lastModified?: string(name='LastModified', description='The time when the template was created.', example='2022-02-02T22:22:22Z'),
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.', example='snapshot/{JobId}.jpg'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.', example='snapshot/{JobId}/{UnixTimestamp}.jpg'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287782****'),
  templateName?: string(name='TemplateName', description='The template name.'),
  timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots.', example='5'),
  type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
}

model GetLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveSnapshotTemplateResponseBody(name='body'),
}

/**
 * @summary Queries the information about a live stream snapshot template.
 *
 * @param request GetLiveSnapshotTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveSnapshotTemplateResponse
 */
async function getLiveSnapshotTemplateWithOptions(request: GetLiveSnapshotTemplateRequest, runtime: Util.RuntimeOptions): GetLiveSnapshotTemplateResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetLiveSnapshotTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a live stream snapshot template.
 *
 * @param request GetLiveSnapshotTemplateRequest
 * @return GetLiveSnapshotTemplateResponse
 */
async function getLiveSnapshotTemplate(request: GetLiveSnapshotTemplateRequest): GetLiveSnapshotTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return getLiveSnapshotTemplateWithOptions(request, runtime);
}

model GetLiveTranscodeJobRequest {
  jobId?: string(name='JobId', description='The ID of the transcoding job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetLiveTranscodeJobResponseBody = {
  job?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T02:48:58Z'),
    jobId?: string(name='JobId', description='The ID of the transcoding job.', example='****20b48fb04483915d4f2cd8ac****'),
    name?: string(name='Name', description='The name of the transcoding job.', example='task1'),
    outputStream?: {
      streamInfos?: [ 
        {
          outputUrl?: string(name='OutputUrl', description='The URL of the output stream.', example='rtmp://mydomain/app/mytranscode1'),
          type?: string(name='Type', description='The type of the output stream protocol. Only the RTMP protocol is supported.', example='rtmp'),
        }
      ](name='StreamInfos', description='The information about the output stream.'),
    }(name='OutputStream', description='The information about the output stream.'),
    startMode?: int32(name='StartMode', description='The start mode of the job.', example='0'),
    status?: int32(name='Status', description='The state of the job.

*   0: The job is not started.
*   1: The job is in progress.
*   2: The job is stopped.', example='1'),
    streamInput?: {
      inputUrl?: string(name='InputUrl', description='The URL of the input stream.', example='rtmp://mydomain/app/stream1'),
      type?: string(name='Type', description='The type of the input stream.', example='rtmp'),
    }(name='StreamInput', description='The information about the input stream.'),
    templateId?: string(name='TemplateId', description='The template ID.', example='b6491d5b3e514b7d895d14b5453ea119'),
    templateName?: string(name='TemplateName', description='The template name.', example='basic'),
    templateType?: string(name='TemplateType', description='The type of the template.', example='normal'),
  }(name='Job', description='The information about the transcoding job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model GetLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveTranscodeJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a live stream transcoding job.
 *
 * @param request GetLiveTranscodeJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveTranscodeJobResponse
 */
async function getLiveTranscodeJobWithOptions(request: GetLiveTranscodeJobRequest, runtime: Util.RuntimeOptions): GetLiveTranscodeJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetLiveTranscodeJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a live stream transcoding job.
 *
 * @param request GetLiveTranscodeJobRequest
 * @return GetLiveTranscodeJobResponse
 */
async function getLiveTranscodeJob(request: GetLiveTranscodeJobRequest): GetLiveTranscodeJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getLiveTranscodeJobWithOptions(request, runtime);
}

model GetLiveTranscodeTemplateRequest {
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287666****'),
}

model GetLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  templateContent?: {
    category?: string(name='Category', description='The category of the template. Valid values:

*   system
*   customized', example='customized'),
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-25T06:15:14Z'),
    name?: string(name='Name', description='The name of the template.', example='my-template'),
    templateConfig?: {
      audioParams?: {
        bitrate?: string(name='Bitrate', description='The bitrate of the output audio.', example='1000'),
        channels?: string(name='Channels', description='The number of sound channels.', example='2'),
        codec?: string(name='Codec', description='The audio codec.', example='AAC'),
        profile?: string(name='Profile', description='The audio codec profile.', example='1'),
        samplerate?: string(name='Samplerate', description='The audio sampling rate.', example='44100'),
      }(name='AudioParams', description='The audio parameters.'),
      videoParams?: {
        bitrate?: string(name='Bitrate', description='The bitrate of the output video.', example='2500'),
        codec?: string(name='Codec', description='The encoding type.', example='H.264'),
        fps?: string(name='Fps', description='The frame rate of the output video.', example='30'),
        gop?: string(name='Gop', description='The group of pictures (GOP) of the output video.', example='1000'),
        height?: string(name='Height', description='The height of the output video.', example='720'),
        profile?: string(name='Profile', description='The encoding profile.', example='2'),
        width?: string(name='Width', description='The width of the output video.', example='1280'),
      }(name='VideoParams', description='The video parameters.'),
    }(name='TemplateConfig', description='The configuration of the template.'),
    templateId?: string(name='TemplateId', description='The template ID.', example='bcfa57950bc649b2abfb476ecd36ea4f'),
    type?: string(name='Type', description='The type of the template.', example='normal'),
  }(name='TemplateContent', description='The content of the template.'),
}

model GetLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveTranscodeTemplateResponseBody(name='body'),
}

/**
 * @summary Queries the information a live stream transcoding template.
 *
 * @param request GetLiveTranscodeTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveTranscodeTemplateResponse
 */
async function getLiveTranscodeTemplateWithOptions(request: GetLiveTranscodeTemplateRequest, runtime: Util.RuntimeOptions): GetLiveTranscodeTemplateResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetLiveTranscodeTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information a live stream transcoding template.
 *
 * @param request GetLiveTranscodeTemplateRequest
 * @return GetLiveTranscodeTemplateResponse
 */
async function getLiveTranscodeTemplate(request: GetLiveTranscodeTemplateRequest): GetLiveTranscodeTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return getLiveTranscodeTemplateWithOptions(request, runtime);
}

model GetMediaInfoRequest {
  inputURL?: string(name='InputURL', description='The input URL of the media asset in another service. The URL must be registered in the IMS content library and bound to the ID of the media asset in IMS.

*   For a media asset from Object Storage Service (OSS), the URL may have one of the following formats:

http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4 or

oss://example-bucket/example.mp4. The second format indicates that the region in which the OSS bucket of the media asset resides is the same as the region in which OSS is activated.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset in IMS. If this parameter is left empty, the InputURL parameter must be specified.', example='****20b48fb04483915d4f2cd8ac****'),
  outputType?: string(name='OutputType', description='The type of the URL of the media asset to return in the response. Valid values:

*   oss (default): an OSS URL.
*   cdn: a CDN URL. A CDN URL is returned only if the media asset is imported from ApsaraVideo VOD and the relevant domain name is an accelerated domain name in ApsaraVideo VOD.', example='cdn'),
  returnDetailedInfo?: string(name='ReturnDetailedInfo', description='Specifies whether to return detailed information for specific media asset attributes. Supported attributes: AiRoughData.StandardSmartTagJob, which specifies whether to return detailed tag information if a tagging job has been submitted for the media asset. Valid values for the attribute:

*   false (default): The job result is returned as a URL.
*   true: The job result is returned as text.', example='{"AiRoughData.StandardSmartTagJob": false}'),
}

model GetMediaInfoResponseBody = {
  mediaInfo?: {
    aiRoughData?: {
      aiCategory?: string(name='AiCategory', description='The AI category. Valid values:

*   Life
*   Good-looking
*   Cute pets
*   News
*   Ads
*   Environmental resources
*   Automobile'),
      aiJobId?: string(name='AiJobId', description='The ID of the AI task.', example='****483915d4f2cd8ac20b48fb04****'),
      result?: string(name='Result', description='The analysis result.', example='https://sample-bucket.cn-shanghai.aliyuncs.com/result.json'),
      saveType?: string(name='SaveType', description='The storage type. This parameter indicates the library in which the analysis data is stored. Valid values:

*   TEXT: the text library.', example='TEXT'),
      standardSmartTagJob?: {
        aiJobId?: string(name='AiJobId', description='The ID of the AI task.', example='****483915d4f2cd8ac20b48fb04****'),
        resultUrl?: string(name='ResultUrl', description='The URL of the tagging result.', example='http://xx.oss-cn-shanghai.aliyuncs.com/result2.txt'),
        results?: [ 
          {
            data?: string(name='Data', description='The result data. The value is a JSON string. For information about the data structures of different data types<props="china">, see [Description of the Results parameter](https://help.aliyun.com/zh/ims/developer-reference/api-ice-2020-11-09-querysmarttagjob?spm=a2c4g.11186623.0.0.521d48b7KfapOL#api-detail-40).', example='{"autoChapters": [...]}'),
            type?: string(name='Type', description='The tagging type. Valid values:

*   NLP: natural language processing (NLP)-based tagging', example='NLP'),
          }
        ](name='Results', description='The recognized tags.'),
        status?: string(name='Status', description='The analysis status. Valid values:

*   Analyzing
*   AnalyzeSuccess
*   AnalyzeFailed', example='Analyzing'),
      }(name='StandardSmartTagJob', description='The information about the tagging job.'),
      status?: string(name='Status', description='The analysis status. Valid values:

*   Analyzing
*   AnalyzeSuccess
*   AnalyzeFailed
*   Saving
*   SaveSuccess
*   SaveFailed
*   Deleting
*   DeleteSuccess
*   DeleteFailed', example='Analyzing'),
    }(name='AiRoughData', description='The original AI analysis data.'),
    fileInfoList?: [ 
      {
        audioStreamInfoList?: [ 
          {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='127.794'),
            channelLayout?: string(name='ChannelLayout', description='The output layout of sound channels.', example='stereo'),
            channels?: string(name='Channels', description='The number of sound channels.', example='2'),
            codecLongName?: string(name='CodecLongName', description='The full name of the codec.', example='AAC (Advanced Audio Coding)'),
            codecName?: string(name='CodecName', description='The short name of the codec.', example='aac'),
            codecTag?: string(name='CodecTag', description='The tag of the codec.', example='0x6134706d'),
            codecTagString?: string(name='CodecTagString', description='The tag string of the codec.', example='mp4a'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the codec.', example='1/24000'),
            duration?: string(name='Duration', description='The duration.', example='16.200998'),
            fps?: string(name='Fps', description='The audio frame rate.', example='8'),
            index?: string(name='Index', description='The sequence number of the audio track.', example='1'),
            lang?: string(name='Lang', description='The language.', example='und'),
            numFrames?: string(name='NumFrames', description='The number of frames.', example='10'),
            profile?: string(name='Profile', description='The codec profile.', example='High'),
            sampleFmt?: string(name='SampleFmt', description='The sampling format.', example='fltp'),
            sampleRate?: string(name='SampleRate', description='The sampling rate.', example='44100'),
            startTime?: string(name='StartTime', description='The start time.', example='0.000000'),
            timebase?: string(name='Timebase', description='The time base.', example='1/44100'),
          }
        ](name='AudioStreamInfoList', description='The information about the audio tracks. A media asset may have multiple audio tracks.'),
        fileBasicInfo?: {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
          createTime?: string(name='CreateTime', description='The time when the file was created.', example='2020-12-26T04:11:08Z'),
          duration?: string(name='Duration', description='The duration.', example='216.206667'),
          fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
          fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
          fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
          fileType?: string(name='FileType', description='The file type.', example='source_file'),
          fileUrl?: string(name='FileUrl', description='The OSS URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
          formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
          height?: string(name='Height', description='The height.', example='540'),
          modifiedTime?: string(name='ModifiedTime', description='The time when the file was last modified.', example='2020-12-26T04:11:10Z'),
          region?: string(name='Region', description='The region in which the file is stored.', example='cn-shanghai'),
          width?: string(name='Width', description='The width.', example='960'),
        }(name='FileBasicInfo', description='The basic information about the file, including the duration and size.'),
        subtitleStreamInfoList?: [ 
          {
            codecLongName?: string(name='CodecLongName', description='The full name of the codec.', example='SubRip Text'),
            codecName?: string(name='CodecName', description='The short name of the codec.', example='srt'),
            codecTag?: string(name='CodecTag', description='The tag of the codec.', example='unicode'),
            codecTagString?: string(name='CodecTagString', description='The tag string of the codec.', example='unicode'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the codec.', example='29.97'),
            duration?: string(name='Duration', description='The duration.', example='1'),
            index?: string(name='Index', description='The sequence number of the subtitle track.', example='1'),
            lang?: string(name='Lang', description='The language.', example='und'),
            startTime?: string(name='StartTime', description='The start time.', example='0'),
            timebase?: string(name='Timebase', description='The time base.', example='30'),
          }
        ](name='SubtitleStreamInfoList', description='The information about the subtitle tracks. A media asset may have multiple subtitle tracks.'),
        videoStreamInfoList?: [ 
          {
            avgFPS?: string(name='AvgFPS', description='The average video frame rate.', example='24.0'),
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1001.594'),
            codecLongName?: string(name='CodecLongName', description='The full name of the codec.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
            codecName?: string(name='CodecName', description='The short name of the codec.', example='h264'),
            codecTag?: string(name='CodecTag', description='The tag of the codec.', example='0x0000'),
            codecTagString?: string(name='CodecTagString', description='The tag string of the codec.', example='[0][0][0][0]'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the codec.', example='1/48'),
            dar?: string(name='Dar', description='The display aspect ratio (DAR).', example='0:1'),
            duration?: string(name='Duration', description='The duration.', example='216.206706'),
            fps?: string(name='Fps', description='The video frame rate.', example='24.0'),
            hasBFrames?: string(name='HasBFrames', description='Indicates whether the video track contains bidirectional frames (B-frames).', example='2'),
            height?: string(name='Height', description='The height.', example='540'),
            index?: string(name='Index', description='The sequence number of the video track.', example='0'),
            lang?: string(name='Lang', description='The language.', example='und'),
            level?: string(name='Level', description='The codec level.', example='30'),
            nbFrames?: string(name='Nb_frames', description='The total number of frames.', example='5184'),
            numFrames?: string(name='NumFrames', description='The number of frames.', example='5184'),
            pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
            profile?: string(name='Profile', description='The codec profile.', example='High'),
            rotate?: string(name='Rotate', description='The rotation angle.', example='0'),
            sar?: string(name='Sar', description='The sample aspect ratio (SAR).', example='0:1'),
            startTime?: string(name='StartTime', description='The start time.', example='0.081706'),
            timebase?: string(name='Timebase', description='The time base.', example='1/12288'),
            width?: string(name='Width', description='The width.', example='960'),
          }
        ](name='VideoStreamInfoList', description='The information about the video tracks. A media asset may have multiple video tracks.'),
      }
    ](name='FileInfoList', description='The file information.'),
    mediaBasicInfo?: {
      biz?: string(name='Biz', description='The service to which the media asset belongs.', example='ICE'),
      businessType?: string(name='BusinessType', description='The business type.', example='general'),
      cateId?: long(name='CateId', description='The category ID.', example='3048'),
      cateName?: string(name='CateName', description='The category name.', example='cateName'),
      category?: string(name='Category', description='The category.'),
      coverURL?: string(name='CoverURL', description='The URL of the thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
      createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-26T04:11:08Z'),
      deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-26T04:11:15Z'),
      description?: string(name='Description', description='The content description.'),
      inputURL?: string(name='InputURL', description='The input URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
      mediaTags?: string(name='MediaTags', description='The tags.'),
      mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-26T04:11:10Z'),
      referenceId?: string(name='ReferenceId', description='The custom ID. The ID can be 6 to 64 characters in length and can contain only letters, digits, hyphens (-), and underscores (_). The ID is unique among users.', example='123-1234'),
      snapshots?: string(name='Snapshots', description='The snapshots.', example='[
    "http://example-bucket.oss-cn-shanghai.aliyuncs.com/snapshot-00001.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>",
    "http://example-bucket.oss-cn-shanghai.aliyuncs.com/snapshot-00002.jpg?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>",
    "http://example-bucket.oss-cn-shanghai.aliyuncs.com/snapshot-00003.jpg?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>"
]'),
      source?: string(name='Source', description='The source.', example='oss'),
      spriteImages?: string(name='SpriteImages', description='The sprite.', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
      status?: string(name='Status', description='The resource status.', example='Normal'),
      title?: string(name='Title', description='The title.'),
      uploadSource?: string(name='UploadSource', description='The upload source of the media asset.', example='general'),
      userData?: string(name='UserData', description='The user data.', example='userDataTest'),
    }(name='MediaBasicInfo', description='The basic information about the media asset.'),
    mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  }(name='MediaInfo', description='The information about the media asset.'),
  requestId?: string(name='RequestId', description='The request ID.', example='2FDE2411-DB8D-4A9A-875B-275798F14A5E'),
}

model GetMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaInfoResponseBody(name='body'),
}

/**
 * @summary Queries information about a media asset based on the ID of the media asset in Intelligent Media Services (IMS) or the input URL of the media asset.
 *
 * @description If the MediaId parameter is specified, the MediaId parameter is preferentially used for the query. If the MediaId parameter is left empty, the InputURL parameter must be specified.
 *
 * @param request GetMediaInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaInfoResponse
 */
async function getMediaInfoWithOptions(request: GetMediaInfoRequest, runtime: Util.RuntimeOptions): GetMediaInfoResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.inputURL)) {
    query['InputURL'] = request.inputURL;
  }
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.outputType)) {
    query['OutputType'] = request.outputType;
  }
  if (!Util.isUnset(request.returnDetailedInfo)) {
    query['ReturnDetailedInfo'] = request.returnDetailedInfo;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetMediaInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries information about a media asset based on the ID of the media asset in Intelligent Media Services (IMS) or the input URL of the media asset.
 *
 * @description If the MediaId parameter is specified, the MediaId parameter is preferentially used for the query. If the MediaId parameter is left empty, the InputURL parameter must be specified.
 *
 * @param request GetMediaInfoRequest
 * @return GetMediaInfoResponse
 */
async function getMediaInfo(request: GetMediaInfoRequest): GetMediaInfoResponse {
  var runtime = new Util.RuntimeOptions{};
  return getMediaInfoWithOptions(request, runtime);
}

model GetMediaInfoJobRequest {
  jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
}

model GetMediaInfoJobResponseBody = {
  mediaInfoJob?: {
    async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
    input?: {
      media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    mediaInfoProperty?: {
      audioStreamInfoList?: [ 
        {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
          channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
          codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
          codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
          codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
          codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
          duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
          index?: string(name='Index', description='The sequence number of the stream.', example='1'),
          lang?: string(name='Lang', description='The language of the stream.', example='us'),
          sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
          sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
          startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
          timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
        }
      ](name='AudioStreamInfoList', description='The information about the audio stream.'),
      fileBasicInfo?: {
        bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
        duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
        fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
        fileSize?: string(name='FileSize', description='The file size.', example='31737'),
        fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
        fileType?: string(name='FileType', description='The file type.', example='source_file'),
        fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
        formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
        height?: string(name='Height', description='The height of the output video.', example='478'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='e520090207114cc7a392d44f0b211574'),
        region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
        width?: string(name='Width', description='The width of the output video.', example='848'),
      }(name='FileBasicInfo', description='The basic file information.'),
      videoStreamInfoList?: [ 
        {
          avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
          bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
          codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
          codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
          codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
          codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
          codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
          dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          fps?: string(name='Fps', description='The frame rate.', example='25.0'),
          hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
          height?: string(name='Height', description='The height of the output video.', example='478'),
          index?: string(name='Index', description='The sequence number of the stream.', example='0'),
          lang?: string(name='Lang', description='The language of the stream.', example='zh'),
          level?: string(name='Level', description='The codec level.', example='31'),
          numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
          pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
          profile?: string(name='Profile', description='The encoder profile.', example='High'),
          rotate?: string(name='Rotate', description='The rotation angle of the video image.', example='0'),
          sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
          startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
          timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
          width?: string(name='Width', description='The width of the output video.', example='848'),
        }
      ](name='VideoStreamInfoList', description='The information about the video stream.'),
    }(name='MediaInfoProperty', description='The details of the media information.'),
    name?: string(name='Name', description='The job name.', example='job-name'),
    requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling information.'),
    status?: string(name='Status', description='The state of the job. Valid values: Init (the job is submitted), Success (the job is successful), and Fail (the job failed).', example='Init'),
    submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='MediaInfoJob', description='MediaInfoJobDTO'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model GetMediaInfoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaInfoJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a media information analysis job.
 *
 * @param request GetMediaInfoJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaInfoJobResponse
 */
async function getMediaInfoJobWithOptions(request: GetMediaInfoJobRequest, runtime: Util.RuntimeOptions): GetMediaInfoJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetMediaInfoJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a media information analysis job.
 *
 * @param request GetMediaInfoJobRequest
 * @return GetMediaInfoJobResponse
 */
async function getMediaInfoJob(request: GetMediaInfoJobRequest): GetMediaInfoJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getMediaInfoJobWithOptions(request, runtime);
}

model GetMediaMarksRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The mark ID. You can specify multiple mark IDs separated with commas (,).', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
}

model GetMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaMarks?: string(name='MediaMarks', description='The queried marks.

*   The value is in the JSONArray format.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaMarksResponseBody(name='body'),
}

/**
 * @summary Queries the information about marks based on mark IDs.
 *
 * @param request GetMediaMarksRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaMarksResponse
 */
async function getMediaMarksWithOptions(request: GetMediaMarksRequest, runtime: Util.RuntimeOptions): GetMediaMarksResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.mediaMarkIds)) {
    query['MediaMarkIds'] = request.mediaMarkIds;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetMediaMarks',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about marks based on mark IDs.
 *
 * @param request GetMediaMarksRequest
 * @return GetMediaMarksResponse
 */
async function getMediaMarks(request: GetMediaMarksRequest): GetMediaMarksResponse {
  var runtime = new Util.RuntimeOptions{};
  return getMediaMarksWithOptions(request, runtime);
}

model GetMediaProducingJobRequest {
  jobId?: string(name='JobId', description='The ID of the media editing and production job.', example='****cdb3e74639973036bc84****'),
}

model GetMediaProducingJobResponseBody = {
  mediaProducingJob?: {
    clipsParam?: string(name='ClipsParam', description='The template parameters of the media editing and production job.', example='{"VideoArray":["****05512043f49f697f7425****","****05512043f49f697f7425****","****05512043f49f697f7425****"]}'),
    code?: string(name='Code', description='The response code

Note: Pay attention to this parameter if the job failed.', example='ExceededMaximumValue'),
    completeTime?: string(name='CompleteTime', description='The time when the media editing and production job was complete.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:52Z'),
    createTime?: string(name='CreateTime', description='The time when the media editing and production job was created.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
    duration?: float(name='Duration', description='The duration of the output file.

Note: This parameter has a value if the job is successful and the output file is an audio or video file.', example='30.500000'),
    jobId?: string(name='JobId', description='The ID of the media editing and production job.', example='****cdb3e74639973036bc84****'),
    mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****0cc6ba49eab379332c5b****'),
    mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example2.mp4'),
    message?: string(name='Message', description='The returned message.

Note: Pay attention to this parameter if the job failed.', example='The specified "Width_Height" has exceeded maximum value.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the media editing and production job was last modified.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:49Z'),
    progress?: int32(name='Progress'),
    projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fddd7748b58bf1d47e95****'),
    status?: string(name='Status', description='The state of the media editing and production job. Valid values:

Init

Queuing

Processing

Success

Failed', example='Failed'),
    subJobMaterials?: string(name='SubJobMaterials', description='The materials of the media editing and production job if the job is a subjob of a quick video production job, including the broadcast text and title.', example='{"Title": "Title", "SpeechText": "Broadcast text of a quick video production job"}'),
    templateId?: string(name='TemplateId', description='The ID of the template used by the media editing and production job.', example='****6e76134d739cc3e85d3e****'),
    timeline?: string(name='Timeline', description='The timeline of the media editing and production job.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
    userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"NotifyAddress":"http://xx.xx.xxx","Key":"Valuexxx"}'),
    vodMediaId?: string(name='VodMediaId', description='The media asset ID of the output file in ApsaraVideo VOD if the output file is stored in ApsaraVideo VOD.', example='****332c5b0cc6ba49eab379****'),
  }(name='MediaProducingJob', description='The information about the online editing project.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****83B7-7F87-4792-BFE9-63CD2137****'),
}

model GetMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaProducingJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a media editing and production job. The requested information includes the state, timeline, template, and data of the job. You can call this operation to query only media editing and production jobs created within the past year.
 *
 * @param request GetMediaProducingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaProducingJobResponse
 */
async function getMediaProducingJobWithOptions(request: GetMediaProducingJobRequest, runtime: Util.RuntimeOptions): GetMediaProducingJobResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetMediaProducingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a media editing and production job. The requested information includes the state, timeline, template, and data of the job. You can call this operation to query only media editing and production jobs created within the past year.
 *
 * @param request GetMediaProducingJobRequest
 * @return GetMediaProducingJobResponse
 */
async function getMediaProducingJob(request: GetMediaProducingJobRequest): GetMediaProducingJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getMediaProducingJobWithOptions(request, runtime);
}

model GetPackageJobRequest {
  jobId?: string(name='JobId', description='The job ID. You can obtain the job ID from the response parameters of the [SubmitPackageJob](https://help.aliyun.com/document_detail/461964.html) operation.

This parameter is required.', example='ab4802364a2e49208c99efab82dfa8e8'),
}

model GetPackageJobResponseBody = {
  packageJob?: {
    code?: string(name='Code', description='The error code returned if the job fails.', example='InvalidParameter'),
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:34:05Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:44:05Z'),
    inputs?: [ 
      {
        input?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
        }(name='Input', description='The information about the input stream file.'),
      }
    ](name='Inputs', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    message?: string(name='Message', description='The error message that is returned.', example='Resource content bad.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:44:05Z'),
    name?: string(name='Name', description='The name of the job.', example='job-name'),
    output?: {
      media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.m3u8'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
    }(name='Output', description='The output of the job.'),
    outputUrl?: string(name='OutputUrl', description='The URL of the output file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/output.m3u8'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='36f3fee40aa047c0b067d0fb85edc12b'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='6'),
    status?: string(name='Status', description='The state of the job.', example='Init'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:34:05Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
    userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}'),
  }(name='PackageJob', description='The information about the packaging job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model GetPackageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPackageJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a packaging job.
 *
 * @param request GetPackageJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetPackageJobResponse
 */
async function getPackageJobWithOptions(request: GetPackageJobRequest, runtime: Util.RuntimeOptions): GetPackageJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetPackageJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a packaging job.
 *
 * @param request GetPackageJobRequest
 * @return GetPackageJobResponse
 */
async function getPackageJob(request: GetPackageJobRequest): GetPackageJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getPackageJobWithOptions(request, runtime);
}

model GetPipelineRequest {
  pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.

This parameter is required.', example='****96e8864746a0b6f3****'),
}

model GetPipelineResponseBody = {
  pipeline?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
    name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.', example='****20b48fb04483915d4f2cd8ac****'),
    priority?: int32(name='Priority', description='The priority of the MPS queue. Valid values: 1 to 10.', example='6'),
    speed?: string(name='Speed', description='The type of the MPS queue.

Valid values:

*   Standard: standard MPS queue.
*   Boost: MPS queue with transcoding speed boosted.
*   NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.', example='Standard'),
    status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Active'),
  }(name='Pipeline', description='The information about the MPS queue.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetPipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPipelineResponseBody(name='body'),
}

/**
 * @summary Queries the information about an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request GetPipelineRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetPipelineResponse
 */
async function getPipelineWithOptions(request: GetPipelineRequest, runtime: Util.RuntimeOptions): GetPipelineResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.pipelineId)) {
    query['PipelineId'] = request.pipelineId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetPipeline',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request GetPipelineRequest
 * @return GetPipelineResponse
 */
async function getPipeline(request: GetPipelineRequest): GetPipelineResponse {
  var runtime = new Util.RuntimeOptions{};
  return getPipelineWithOptions(request, runtime);
}

model GetPlayInfoRequest {
  inputURL?: string(name='InputURL', description='The input URL that you specified for the media asset when you registered the media asset. For more information, see [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html).

>  You must specify at least one of the MediaId and InputURL parameters.'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.

>  You must specify at least one of the MediaId and InputURL parameters.', example='86434e152b7d4f20be480574439fe***'),
}

model GetPlayInfoResponseBody = {
  mediaBase?: {
    cateId?: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of the CateId parameter returned by the AddCategory operation that you called to create a category.
*   View the value of the CateId parameter returned by the GetCategories operation that you called to query a category.', example='4220'),
    coverURL?: string(name='CoverURL', description='The URL of the thumbnail.', example='https://***.oss-cn-shanghai.aliyuncs.com/cover/281c64d6-b5fb-4c57-97cd-84da56a8b151_large_cover_url.jpg'),
    creationTime?: string(name='CreationTime', description='The time when the media asset was created.', example='2021-09-22T10:07:31+08:00'),
    description?: string(name='Description', description='The content description.', example='desc'),
    mediaId?: string(name='MediaId', description='The ID of the media asset.', example='2eea77a61c7b4ddd95bec34a6f65b***'),
    mediaTags?: string(name='MediaTags', description='The tags.

*   Up to 16 tags are supported.
*   Multiple tags are separated by commas (,).
*   Each tag can be up to 32 bytes in length.
*   The value is encoded in UTF-8.', example='test,ccc'),
    mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

video audio', example='video'),
    status?: string(name='Status', description='The resource status. Valid values:

Init: the initial state, which indicates that the source file is not ready.

Preparing: The source file is being prepared. For example, the file is being uploaded or edited.

PrepareFail: The source file failed to be prepared. For example, the information of the source file failed to be obtained.

Normal: The source file is ready.', example='Normal'),
    title?: string(name='Title', description='The title.', example='testTitle'),
  }(name='MediaBase', description='The information about the media asset.'),
  playInfoList?: [ 
    {
      bitDepth?: int32(name='BitDepth', description='The color depth.', example='8'),
      bitrate?: string(name='Bitrate', description='The bitrate of the media stream. Unit: Kbit/s.', example='20'),
      creationTime?: string(name='CreationTime', description='The time when the media stream was created. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2022-05-10T02:28:49Z'),
      definition?: string(name='Definition', description='The quality of the media stream. Valid values:

*   **FD**: low definition
*   **LD**: standard definition
*   **SD**: high definition
*   **HD**: ultra-high definition
*   **OD**: original definition
*   **2K**
*   **4K**
*   **SQ**: standard sound quality
*   **HQ**: high sound quality
*   **AUTO**: adaptive bitrate', example='HD'),
      duration?: string(name='Duration', description='The duration of the media stream. Unit: seconds.', example='9.0464'),
      encrypt?: long(name='Encrypt', description='Indicates whether the media stream is encrypted. Valid values:

*   **0**: The media stream is not encrypted.
*   **1**: The media stream is encrypted.', example='0'),
      encryptType?: string(name='EncryptType', description='The encryption type of the media stream. Valid values:

*   **AliyunVoDEncryption**: Alibaba Cloud proprietary cryptography
*   **HLSEncryption**: HTTP Live Streaming (HLS) encryption

>  If the encryption type is AliyunVoDEncryption, only ApsaraVideo Player SDK can be used to play videos.', example='AliyunVoDEncryption'),
      fileURL?: string(name='FileURL', description='The OSS URL of the file.', example='http://outin-***.oss-cn-shanghai.aliyuncs.com/sv/43a68ee9-181809b6aba/43a68ee9-181809b6aba.mpeg'),
      format?: string(name='Format', description='The format of the media stream.

*   If the media asset is a video file, the valid values are **mp4** and **m3u8**.
*   If the media asset is an audio-only file, the value is **mp3**.', example='mp4'),
      fps?: string(name='Fps', description='The frame rate of the media stream. Unit: frames per second (FPS).', example='25'),
      HDRType?: string(name='HDRType', description='The high dynamic range (HDR) type of the media stream. Valid values:

*   HDR
*   HDR10
*   HLG
*   DolbyVision
*   HDRVivid
*   SDR+', example='HDR'),
      height?: long(name='Height', description='The height of the media stream. Unit: pixels.', example='1080'),
      jobId?: string(name='JobId', description='The task ID.', example='36c9d38e70bf43ed9f7f8f48d6356***'),
      modificationTime?: string(name='ModificationTime', description='The time when the media stream was updated. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2022-05-13T11:39:41.714+08:00'),
      narrowBandType?: string(name='NarrowBandType', description='The type of Narrowband HD™ transcoding. Valid values:

*   **0**: standard transcoding
*   **1.0**: Narrowband HD™ 1.0 transcoding
*   **2.0**: Narrowband HD™ 2.0 transcoding

This parameter is returned only when a definition that is available in the built-in Narrowband HD™ 1.0 transcoding template is specified. For more information, see the [Definition parameter in TranscodeTemplate](https://help.aliyun.com/document_detail/52839.html) table.', example='0'),
      playURL?: string(name='PlayURL', description='The playback URL of the media stream.', example='https://***.aliyuncdn.com/sv/756bee1-17f980f0945/756bee1-17f980f0945.mp4'),
      size?: long(name='Size', description='The size of the media stream. Unit: bytes.', example='418112'),
      status?: string(name='Status', description='The status of the media stream. Valid values:

*   **Normal**
*   **Invisible**', example='Normal'),
      streamTags?: string(name='StreamTags', description='The tags of the media stream, which are used to identify the transcoding type.', example='"{\\\\"ims.audioServiceType\\\\": \\\\"AudioEnhancement\\\\"}"'),
      streamType?: string(name='StreamType', description='The type of the media stream. If the media stream is a video stream, the value is **video**. If the media stream is an audio-only stream, the value is **audio**.', example='video'),
      transTemplateType?: string(name='TransTemplateType', description='The type of the transcoding template. Valid values:

*   Normal: standard transcoding
*   AudioTranscode: audio transcoding
*   Remux: container format conversion
*   NarrowBandV1: Narrowband HD™ 1.0
*   NarrowBandV2: Narrowband HD™ 2.0
*   UHD: audio and video enhancement (ultra-high definition)', example='Normal'),
      watermarkId?: string(name='WatermarkId', description='The ID of the watermark that is associated with the media stream.', example='5bed88672b1e2520ead228935ed51***'),
      width?: long(name='Width', description='The width of the media stream. Unit: pixels.', example='1024'),
    }
  ](name='PlayInfoList', description='The information about the audio or video stream.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetPlayInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPlayInfoResponseBody(name='body'),
}

/**
 * @summary Queries the playback URL of a video or audio file based on its ID.
 *
 * @description You use the ID of a video or audio file to query the playback URL of the file. Then, you can use the playback URL to play the audio or video in ApsaraVideo Player SDK (for URL-based playback) or a third-party player.
 *
 * @param request GetPlayInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetPlayInfoResponse
 */
async function getPlayInfoWithOptions(request: GetPlayInfoRequest, runtime: Util.RuntimeOptions): GetPlayInfoResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.inputURL)) {
    query['InputURL'] = request.inputURL;
  }
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetPlayInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the playback URL of a video or audio file based on its ID.
 *
 * @description You use the ID of a video or audio file to query the playback URL of the file. Then, you can use the playback URL to play the audio or video in ApsaraVideo Player SDK (for URL-based playback) or a third-party player.
 *
 * @param request GetPlayInfoRequest
 * @return GetPlayInfoResponse
 */
async function getPlayInfo(request: GetPlayInfoRequest): GetPlayInfoResponse {
  var runtime = new Util.RuntimeOptions{};
  return getPlayInfoWithOptions(request, runtime);
}

model GetPublicMediaInfoRequest {
  mediaId?: string(name='MediaId', example='icepublic-****14e501538aeef0a3140176f6****'),
}

model GetPublicMediaInfoResponseBody = {
  mediaInfo?: {
    dynamicMetaData?: {
      data?: string(name='Data', example='{"AuditionUrl": "http://example-bucket.cdn.domain.com/example.mp4", "AuditionCount": 3}'),
      type?: string(name='Type', example='system'),
    }(name='DynamicMetaData'),
    fileInfoList?: [ 
      {
        audioStreamInfoList?: [ 
          {
            bitrate?: string(name='Bitrate', example='192.0'),
            channelLayout?: string(name='ChannelLayout', example='stereo'),
            channels?: string(name='Channels', example='2'),
            codecLongName?: string(name='CodecLongName', example='AAC (Advanced Audio Coding)'),
            codecName?: string(name='CodecName', example='aac'),
            codecTag?: string(name='CodecTag', example='0x6134706d'),
            codecTagString?: string(name='CodecTagString', example='mp4a'),
            codecTimeBase?: string(name='CodecTimeBase', example='1/44100'),
            duration?: string(name='Duration', example='16.2'),
            fps?: string(name='Fps', example='10'),
            index?: string(name='Index', example='1'),
            lang?: string(name='Lang', example='und'),
            numFrames?: string(name='NumFrames', example='162'),
            profile?: string(name='Profile', example='High'),
            sampleFmt?: string(name='SampleFmt', example='fltp'),
            sampleRate?: string(name='SampleRate', example='44100'),
            startTime?: string(name='StartTime', example='0.000000'),
            timebase?: string(name='Timebase', example='1/44100'),
          }
        ](name='AudioStreamInfoList'),
        fileBasicInfo?: {
          bitrate?: string(name='Bitrate', example='192.0'),
          duration?: string(name='Duration', example='16.2'),
          fileName?: string(name='FileName', example='example.mp4'),
          fileSize?: string(name='FileSize', example='27007'),
          fileStatus?: string(name='FileStatus', example='Normal'),
          fileType?: string(name='FileType', example='source_file'),
          fileUrl?: string(name='FileUrl', example='http://example-bucket.cdn.domain.com/example.mp4'),
          formatName?: string(name='FormatName', example='mp4'),
          height?: string(name='Height', example='0'),
          region?: string(name='Region', example='cn-shanghai'),
          width?: string(name='Width', example='0'),
        }(name='FileBasicInfo'),
        subtitleStreamInfoList?: [ 
          {
            codecLongName?: string(name='CodecLongName', example='SubRip Text'),
            codecName?: string(name='CodecName', example='srt'),
            codecTag?: string(name='CodecTag', example='unicode'),
            codecTagString?: string(name='CodecTagString', example='unicode'),
            codecTimeBase?: string(name='CodecTimeBase', example='29.97'),
            duration?: string(name='Duration', example='1'),
            index?: string(name='Index', example='1'),
            lang?: string(name='Lang', example='und'),
            startTime?: string(name='StartTime', example='0'),
            timebase?: string(name='Timebase', example='30'),
          }
        ](name='SubtitleStreamInfoList'),
        videoStreamInfoList?: [ 
          {
            avgFPS?: string(name='AvgFPS', example='24.0'),
            bitrate?: string(name='Bitrate', example='1001.594'),
            codecLongName?: string(name='CodecLongName', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
            codecName?: string(name='CodecName', example='h264'),
            codecTag?: string(name='CodecTag', example='0x0000'),
            codecTagString?: string(name='CodecTagString', example='[0][0][0][0]'),
            codecTimeBase?: string(name='CodecTimeBase', example='1/48'),
            dar?: string(name='Dar', example='0:1'),
            duration?: string(name='Duration', example='216.206706'),
            fps?: string(name='Fps', example='24.0'),
            hasBFrames?: string(name='HasBFrames', example='2'),
            height?: string(name='Height', example='540'),
            index?: string(name='Index', example='0'),
            lang?: string(name='Lang', example='und'),
            level?: string(name='Level', example='30'),
            nbFrames?: string(name='Nb_frames', example='5184'),
            numFrames?: string(name='NumFrames', example='5184'),
            pixFmt?: string(name='PixFmt', example='yuv420p'),
            profile?: string(name='Profile', example='High'),
            rotate?: string(name='Rotate', example='0'),
            sar?: string(name='Sar', example='0:1'),
            startTime?: string(name='StartTime', example='0.081706'),
            timebase?: string(name='Timebase', example='1/12288'),
            width?: string(name='Width', example='960'),
          }
        ](name='VideoStreamInfoList'),
      }
    ](name='FileInfoList', description='FileInfos'),
    mediaBasicInfo?: {
      businessType?: string(name='BusinessType', example='general'),
      category?: string(name='Category', example='category'),
      coverURL?: string(name='CoverURL', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
      createTime?: string(name='CreateTime', example='2020-12-26T04:11:08Z'),
      deletedTime?: string(name='DeletedTime', example='2020-12-26T04:11:15Z'),
      description?: string(name='Description', example='description'),
      mediaId?: string(name='MediaId', description='MediaId', example='icepublic-****14e501538aeef0a3140176f6****'),
      mediaTags?: string(name='MediaTags'),
      mediaType?: string(name='MediaType', example='video'),
      modifiedTime?: string(name='ModifiedTime', example='2020-12-26T04:11:10Z'),
      source?: string(name='Source', example='oss'),
      spriteImages?: string(name='SpriteImages', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
      status?: string(name='Status', example='Normal'),
      title?: string(name='Title', example='title'),
      userData?: string(name='UserData', example='{"key":"value"}'),
    }(name='MediaBasicInfo', description='BasicInfo'),
    mediaId?: string(name='MediaId', example='icepublic-****14e501538aeef0a3140176f6****'),
  }(name='MediaInfo'),
  requestId?: string(name='RequestId', description='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetPublicMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPublicMediaInfoResponseBody(name='body'),
}

/**
 * @summary 获取公共媒资内容信息
 *
 * @param request GetPublicMediaInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetPublicMediaInfoResponse
 */
async function getPublicMediaInfoWithOptions(request: GetPublicMediaInfoRequest, runtime: Util.RuntimeOptions): GetPublicMediaInfoResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetPublicMediaInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'Anonymous',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 获取公共媒资内容信息
 *
 * @param request GetPublicMediaInfoRequest
 * @return GetPublicMediaInfoResponse
 */
async function getPublicMediaInfo(request: GetPublicMediaInfoRequest): GetPublicMediaInfoResponse {
  var runtime = new Util.RuntimeOptions{};
  return getPublicMediaInfoWithOptions(request, runtime);
}

model GetSmartHandleJobRequest {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetSmartHandleJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  jobResult?: {
    aiResult?: string(name='AiResult', description='The AI analysis result.', example='Intelligent segmentation or tagging information'),
    mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
    mediaUrl?: string(name='MediaUrl'),
    usage?: string(name='Usage', description='The token usage. This parameter is returned only for keyword-based text generation jobs.', example='{"total_tokens":100}'),
  }(name='JobResult', description='The job results.'),
  output?: string(name='Output', description='The job results.', example='{}'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  smartJobInfo?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2020-12-26T04:11:10Z'),
    description?: string(name='Description', description='The job description.', example='测试描述'),
    inputConfig?: {
      inputFile?: string(name='InputFile', description='The OSS URL or the ID of the material in the media asset library.', example='oss://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4 或 ******11-DB8D-4A9A-875B-275798******'),
    }(name='InputConfig', description='The input configurations.'),
    jobType?: string(name='JobType', description='The job type.', example='ASR'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2020-12-26T04:11:10Z'),
    outputConfig?: {
      bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
      object?: string(name='Object', description='The OSS object.', example='test-object'),
    }(name='OutputConfig', description='The output configurations.'),
    title?: string(name='Title', description='The job title.', example='测试标题'),
    userId?: string(name='UserId', description='The user ID.', example='1974526429******'),
  }(name='SmartJobInfo', description='The information about the intelligent job.'),
  state?: string(name='State', description='The job state.

Valid values:

*   Finished
*   Failed
*   Executing
*   Created', example='Finished'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"user":"data"}'),
}

model GetSmartHandleJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSmartHandleJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about an intelligent job and the execution results of the job based the job ID. You can call this operation to query only intelligent jobs created within the past year.
 *
 * @param request GetSmartHandleJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetSmartHandleJobResponse
 */
async function getSmartHandleJobWithOptions(request: GetSmartHandleJobRequest, runtime: Util.RuntimeOptions): GetSmartHandleJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetSmartHandleJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about an intelligent job and the execution results of the job based the job ID. You can call this operation to query only intelligent jobs created within the past year.
 *
 * @param request GetSmartHandleJobRequest
 * @return GetSmartHandleJobResponse
 */
async function getSmartHandleJob(request: GetSmartHandleJobRequest): GetSmartHandleJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSmartHandleJobWithOptions(request, runtime);
}

model GetSnapshotJobRequest {
  jobId?: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****d80e4e4044975745c14b****'),
}

model GetSnapshotJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  snapshotJob?: {
    async?: boolean(name='Async', description='Indicates whether the snapshots were captured in asynchronous mode. Default value: true.', example='true'),
    code?: string(name='Code', description='Error codes', example='ResourceNotFound'),
    count?: int32(name='Count', description='The number of snapshots.', example='8'),
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
    input?: {
      media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://test-bucket/object.mp4'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='object.mp4'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
    message?: string(name='Message', description='The error message that is returned.', example='The specified resource for "Pipeline" could not be found.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
    name?: string(name='Name', description='The name of the job.'),
    output?: {
      media?: string(name='Media', description='The output file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS. If multiple static snapshots were captured, the object must contain the "{Count}" placeholder. In the case of a sprite, the object must contain the "{TileCount}" placeholder. The suffix of the WebVTT snapshot objects must be ".vtt".', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/output-{Count}.jpg'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='output-{Count}.jpg'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.', example='OSS'),
    }(name='Output', description='The output of the job.'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****d80e4e4044975745c14b****'),
    status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
    templateConfig?: string(name='TemplateConfig', description='The snapshot template configuration.', example='{"Type":"Normal","FrameType":"normal","Time":0,"Count":10}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****d80e4e4044975745c14b****'),
    triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
    type?: string(name='Type', description='Snapshot types

Valid values:

*   WebVtt
*   Sprite
*   Normal', example='Sprite'),
    userData?: string(name='UserData', description='The user-defined parameters.', example='{"test parameter": "test value"}'),
  }(name='SnapshotJob', description='The information about the snapshot job.'),
}

model GetSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSnapshotJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a snapshot job.
 *
 * @param request GetSnapshotJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetSnapshotJobResponse
 */
async function getSnapshotJobWithOptions(request: GetSnapshotJobRequest, runtime: Util.RuntimeOptions): GetSnapshotJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetSnapshotJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a snapshot job.
 *
 * @param request GetSnapshotJobRequest
 * @return GetSnapshotJobResponse
 */
async function getSnapshotJob(request: GetSnapshotJobRequest): GetSnapshotJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSnapshotJobWithOptions(request, runtime);
}

model GetSnapshotUrlsRequest {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values: Asc and Desc.

- Asc

- Desc', example='Asc'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 30. Default value: 10.', example='10'),
  timeout?: long(name='Timeout', description='The authentication timeout period. Unit: seconds Default value: 3600. Maximum value: 129600 (36 hours).', example='3600'),
}

model GetSnapshotUrlsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  snapshotUrls?: [ string ](name='SnapshotUrls', description='The list of snapshot URLs.'),
  total?: int32(name='Total', description='The total number of snapshots.', example='30'),
  webVTTUrl?: string(name='WebVTTUrl', description='The URL of the WebVTT file.', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/ouoput.vtt'),
}

model GetSnapshotUrlsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSnapshotUrlsResponseBody(name='body'),
}

/**
 * @summary Queries the accessible URLs of the output images of a snapshot job.
 *
 * @param request GetSnapshotUrlsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetSnapshotUrlsResponse
 */
async function getSnapshotUrlsWithOptions(request: GetSnapshotUrlsRequest, runtime: Util.RuntimeOptions): GetSnapshotUrlsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.timeout)) {
    query['Timeout'] = request.timeout;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetSnapshotUrls',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the accessible URLs of the output images of a snapshot job.
 *
 * @param request GetSnapshotUrlsRequest
 * @return GetSnapshotUrlsResponse
 */
async function getSnapshotUrls(request: GetSnapshotUrlsRequest): GetSnapshotUrlsResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSnapshotUrlsWithOptions(request, runtime);
}

model GetStorageListRequest {
  appId?: string(name='AppId', example='app-****'),
  status?: string(name='Status', example='Normal'),
  storageType?: string(name='StorageType', example='vod_oss_bucket'),
}

model GetStorageListResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='******73-8B78-5D86-A50C-49B96C******'),
  storageInfoList?: [ 
    {
      appId?: string(name='AppId', example='app-****'),
      creationTime?: string(name='CreationTime', example='2024-06-06T01:55:07Z'),
      defaultStorage?: boolean(name='DefaultStorage', example='true'),
      editingTempFileStorage?: boolean(name='EditingTempFileStorage', example='false'),
      modifiedTime?: string(name='ModifiedTime', example='2024-06-06T03:07:07Z'),
      path?: string(name='Path', example='your-path/'),
      status?: string(name='Status', example='Normal'),
      storageLocation?: string(name='StorageLocation', example='your-bucket'),
      storageType?: string(name='StorageType', example='vod_oss_bucket'),
    }
  ](name='StorageInfoList'),
}

model GetStorageListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetStorageListResponseBody(name='body'),
}

/**
 * @summary 获取存储地址列表
 *
 * @param request GetStorageListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetStorageListResponse
 */
async function getStorageListWithOptions(request: GetStorageListRequest, runtime: Util.RuntimeOptions): GetStorageListResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.appId)) {
    query['AppId'] = request.appId;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  if (!Util.isUnset(request.storageType)) {
    query['StorageType'] = request.storageType;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetStorageList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 获取存储地址列表
 *
 * @param request GetStorageListRequest
 * @return GetStorageListResponse
 */
async function getStorageList(request: GetStorageListRequest): GetStorageListResponse {
  var runtime = new Util.RuntimeOptions{};
  return getStorageListWithOptions(request, runtime);
}

model GetSystemTemplateRequest {
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='S00000001-100060'),
}

model GetSystemTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  systemTemplate?: {
    status?: string(name='Status', description='The template state.', example='Normal'),
    subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='1'),
    subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='Normal'),
    templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Container":{"Format":"m3u8"},"TransConfig":{"TransMode":"onepass"},"Video":{"Codec":"H.264","Maxrate":8000,"Preset":"medium","PixFmt":"yuv420p","Width":2048,"Bitrate":3500},"Audio":{"Codec":"aac","Bitrate":160,"Samplerate":44100,"Channels":2}}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='S00000001-100060'),
    templateName?: string(name='TemplateName', description='The template name.', example='M3U8-2K'),
    type?: int32(name='Type', description='The type ID of the template.', example='1'),
    typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
  }(name='SystemTemplate', description='The template information.'),
}

model GetSystemTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSystemTemplateResponseBody(name='body'),
}

/**
 * @summary Queries the information about a system template.
 *
 * @param request GetSystemTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetSystemTemplateResponse
 */
async function getSystemTemplateWithOptions(request: GetSystemTemplateRequest, runtime: Util.RuntimeOptions): GetSystemTemplateResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetSystemTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a system template.
 *
 * @param request GetSystemTemplateRequest
 * @return GetSystemTemplateResponse
 */
async function getSystemTemplate(request: GetSystemTemplateRequest): GetSystemTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSystemTemplateWithOptions(request, runtime);
}

model GetTemplateRequest {
  relatedMediaidFlag?: string(name='RelatedMediaidFlag', description='Specifies whether to return the information about the associated materials. Default value: 0. Valid values: 0 and 1. A value of 1 specifies that the information about the associated materials is returned. This parameter is valid only for regular templates.', example='0'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  template?: {
    clipsParam?: string(name='ClipsParam', description='The clip parameters for submitting a video production job. You can replace mediaId and text with real values to submit a job. References:

*   [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html)
*   [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html)', example='{"Media1":"mediaId","Text1":"text"}'),
    config?: string(name='Config', description='The template configurations.

*   For more information about the configurations of a regular template, see [Config object of a regular template](https://help.aliyun.com/document_detail/456193.html).
*   For more information about the configurations of an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).', example='参考Timeline模板配置详解'),
    coverURL?: string(name='CoverURL', description='The thumbnail URL.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
    createSource?: string(name='CreateSource', description='The source from which the template was created. Valid values:

*   AliyunConsole
*   OpenAPI
*   WebSDK', example='OpenAPI'),
    creationTime?: string(name='CreationTime', description='The time when the template was created.', example='2020-12-26T04:11:10Z'),
    modifiedSource?: string(name='ModifiedSource', description='The source from which the template was modified. Valid values:

*   AliyunConsole
*   OpenAPI
*   WebSDK', example='OpenAPI'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2020-12-26T04:11:10Z'),
    name?: string(name='Name', description='The template name.', example='视频添加水印模板'),
    previewMedia?: string(name='PreviewMedia', description='The preview media asset.', example='****20b48fb04483915d4f2cd8ac****'),
    previewMediaStatus?: string(name='PreviewMediaStatus', description='The state of the preview media asset. Valid values:

*   Init: the initial state, which indicates that the source file is not ready.
*   Preparing: The source file is being prepared. For example, the file is being uploaded or edited.
*   PrepareFail: The source file failed to be prepared. For example, the information about the source file failed to be obtained.
*   Normal: The source file is ready.', example='Normal'),
    relatedMediaids?: string(name='RelatedMediaids', description='The IDs of the materials associated with the template for use by the regular template editor.', example='{"video":["******c04f1d4a06996144cc1a******"],"audio":["******c04f1d4a06996144cc1a******"],"image":["******c04f1d4a06996144cc1a******"]}'),
    status?: string(name='Status', description='The template state. Valid values:

*   Available
*   Created
*   Uploading
*   Processing
*   UploadFailed
*   ProcessFailed', example='Available'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
    type?: string(name='Type', description='The template type. Valid values:

*   Timeline
*   VETemplate', example='Timeline'),
  }(name='Template', description='The template information.'),
}

model GetTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTemplateResponseBody(name='body'),
}

/**
 * @summary Queries the information about a template based on the template ID. You can call this operation to query the information about an advanced template if the template is in the Available state.
 *
 * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
 * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request GetTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetTemplateResponse
 */
async function getTemplateWithOptions(request: GetTemplateRequest, runtime: Util.RuntimeOptions): GetTemplateResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.relatedMediaidFlag)) {
    query['RelatedMediaidFlag'] = request.relatedMediaidFlag;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a template based on the template ID. You can call this operation to query the information about an advanced template if the template is in the Available state.
 *
 * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
 * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request GetTemplateRequest
 * @return GetTemplateResponse
 */
async function getTemplate(request: GetTemplateRequest): GetTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return getTemplateWithOptions(request, runtime);
}

model GetTemplateMaterialsRequest {
  fileList?: string(name='FileList', description='The materials that you want to query.', example='["music.mp3","config.json","assets/1.jpg"]'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetTemplateMaterialsResponseBody = {
  materialUrls?: string(name='MaterialUrls', description='The URLs of the associated materials.', example='{"music.mp3":"https://bucket.oss-cn-shanghai.aliyuncs.com/music.mp3?sign=xxx","config.json":"https://bucket.oss-cn-shanghai.aliyuncs.com/config.json?sign=xxx","assets/1.jpg":"https://bucket.oss-cn-shanghai.aliyuncs.com/assets/1.jpg?sign=xxx"}'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetTemplateMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTemplateMaterialsResponseBody(name='body'),
}

/**
 * @summary Queries the URLs of materials associated with an advanced template for use by the advanced template editor. The URLs expire in 30 minutes. FileList is an array of materials that you want to query. If you do not specify this parameter, the URLs of all materials are returned. A maximum of 400 URLs can be returned.
 *
 * @param request GetTemplateMaterialsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetTemplateMaterialsResponse
 */
async function getTemplateMaterialsWithOptions(request: GetTemplateMaterialsRequest, runtime: Util.RuntimeOptions): GetTemplateMaterialsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.fileList)) {
    query['FileList'] = request.fileList;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetTemplateMaterials',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the URLs of materials associated with an advanced template for use by the advanced template editor. The URLs expire in 30 minutes. FileList is an array of materials that you want to query. If you do not specify this parameter, the URLs of all materials are returned. A maximum of 400 URLs can be returned.
 *
 * @param request GetTemplateMaterialsRequest
 * @return GetTemplateMaterialsResponse
 */
async function getTemplateMaterials(request: GetTemplateMaterialsRequest): GetTemplateMaterialsResponse {
  var runtime = new Util.RuntimeOptions{};
  return getTemplateMaterialsWithOptions(request, runtime);
}

model GetTemplateParamsRequest {
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetTemplateParamsResponseBody = {
  paramList?: [ 
    {
      content?: string(name='Content', description='The original subtitle content.'),
      coverUrl?: string(name='CoverUrl', description='The thumbnail URL of the original material.'),
      key?: string(name='Key', description='The parameter name.', example='video1'),
      mediaUrl?: string(name='MediaUrl', description='The URL of the original material.'),
      type?: string(name='Type', description='The material type.

Valid values:

*   Video
*   Text
*   Image', example='Image'),
    }
  ](name='ParamList', description='The queried parameters.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
  templateId?: string(name='TemplateId', description='The template ID.', example='******419c8741c1b4325f035b******'),
}

model GetTemplateParamsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTemplateParamsResponseBody(name='body'),
}

/**
 * @summary Queries the parameters for replaceable materials in a template, including the parameter names, default values, and material thumbnails. Only advanced templates are supported.
 *
 * @param request GetTemplateParamsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetTemplateParamsResponse
 */
async function getTemplateParamsWithOptions(request: GetTemplateParamsRequest, runtime: Util.RuntimeOptions): GetTemplateParamsResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetTemplateParams',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the parameters for replaceable materials in a template, including the parameter names, default values, and material thumbnails. Only advanced templates are supported.
 *
 * @param request GetTemplateParamsRequest
 * @return GetTemplateParamsResponse
 */
async function getTemplateParams(request: GetTemplateParamsRequest): GetTemplateParamsResponse {
  var runtime = new Util.RuntimeOptions{};
  return getTemplateParamsWithOptions(request, runtime);
}

model GetTranscodeJobRequest {
  parentJobId?: string(name='ParentJobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
}

model GetTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='9EDC30DC-0050-5459-B788-F761B2BE359B'),
  transcodeParentJob?: {
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    inputGroup?: [ 
      {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
      }
    ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
    jobCount?: int32(name='JobCount', description='The number of subjobs.', example='1'),
    name?: string(name='Name', description='The job name.', example='transcode-job'),
    outputGroup?: [ 
      {
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          outputUrl?: string(name='OutputUrl', description='The URL of the output stream.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex?: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex?: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HLS encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The endpoint of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='The encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The position of the watermark on the x-axis.', example='10'),
                dy?: string(name='Dy', description='The position of the watermark on the y-axis.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the output video.', example='32'),
                referPos?: string(name='ReferPos', description='The reference position of the watermark. Valid values: TopLeft, TopRight, BottomLeft, and BottomRight. Default value: TopLeft.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The duration of the stream. Valid values: the number of seconds or "ToEND".', example='ToEND'),
                  start?: string(name='Start', description='The start time of the stream.', example='00:00:05'),
                }(name='Timeline', description='The timeline settings.'),
                width?: string(name='Width', description='The width of the output video.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Indicates whether the text size was adjusted based on the output video dimensions. Valid values: true and false. Default value: false.', example='false'),
                borderColor?: string(name='BorderColor', description='The border color.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The border width.', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the watermark.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.', example='16'),
                left?: string(name='Left', description='The distance of the watermark from the left edge.', example='10'),
                top?: string(name='Top', description='The distance of the watermark from the top edge.', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Indicates whether the audio stream is deleted.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100.
*   Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum ABR. This parameter takes effect only for Narrowband HD 1.0.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.
*   If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values: border: automatically detects and removes black bars. A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Indicates whether the auto-rotate screen feature is enabled.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Indicates whether the video was removed.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The job processing configuration.'),
      }
    ](name='OutputGroup', description='The output group of the job.'),
    parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
    percent?: int32(name='Percent', description='The completion percentage of the job.', example='0'),
    requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the snapshot job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling configuration of the job.'),
    status?: string(name='Status', description='The state of the job.

*   Success: At least one of the subjobs is successful.
*   Fail: All subjobs failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    transcodeJobList?: [ 
      {
        createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-01-12T08:49:41Z'),
        finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
        inputGroup?: [ 
          {
            inputUrl?: string(name='InputUrl', description='The URL of the media asset. This parameter is specified only when the media asset is transcoded.', example='oss://bucket/path/to/video.mp4'),
            media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
            type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
          }
        ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
        jobId?: string(name='JobId', description='The subjob ID.', example='7d6a7e0d4db2457a8d45ff5d43e1bf0a'),
        jobIndex?: int32(name='JobIndex', description='The index number of the subjob in the entire job.', example='0'),
        name?: string(name='Name', description='The job name.', example='transcode-job'),
        outFileMeta?: {
          audioStreamInfoList?: [ 
            {
              bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
              channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
              channels?: string(name='Channels', description='The number of sound channels.', example='2'),
              codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
              codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
              codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
              codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
              codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              index?: string(name='Index', description='The sequence number of the stream.', example='1'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
              sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
              startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
              timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
            }
          ](name='AudioStreamInfoList', description='The information about the audio stream.'),
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
            duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
            fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
            fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
            fileType?: string(name='FileType', description='The file type. Valid values: source_file and transcode_file.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
            formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
            height?: string(name='Height', description='The height of the output video.', example='478'),
            mediaId?: string(name='MediaId', description='The ID of the media asset.', example='486c2890096871edba6f81848c016303'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width of the output video.', example='848'),
          }(name='FileBasicInfo', description='The basic file information.'),
          videoStreamInfoList?: [ 
            {
              avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
              bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
              codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
              codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
              codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
              codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
              codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
              dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              fps?: string(name='Fps', description='The frame rate.', example='25.0'),
              hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
              height?: string(name='Height', description='The height of the output video.', example='478'),
              index?: string(name='Index', description='The sequence number of the stream.', example='0'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              level?: string(name='Level', description='The codec level.', example='31'),
              numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
              pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
              profile?: string(name='Profile', description='The encoder profile.', example='High'),
              rotate?: string(name='Rotate', description='The rotation angle of the video image. Valid values: 0, 90, 180, and 270. Default value: 0.', example='0'),
              sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
              startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
              timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
              width?: string(name='Width', description='The width of the output video.', example='848'),
            }
          ](name='VideoStreamInfoList', description='The information about the video stream.'),
        }(name='OutFileMeta', description='The media information about the video generated by the job.'),
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          outputUrl?: string(name='OutputUrl', description='The path of the transcoded output stream. This parameter is required only when the output is a media asset.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex?: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex?: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HTTP Live Streaming (HLS) encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The endpoint of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='The encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The position of the watermark on the x-axis.', example='10'),
                dy?: string(name='Dy', description='The position of the watermark on the y-axis.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the output video.', example='32'),
                referPos?: string(name='ReferPos', description='The reference position of the watermark. Valid values: TopLeft, TopRight, BottomLeft, and BottomRight. Default value: TopLeft.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The duration of the stream. Valid values: the number of seconds or "ToEND".', example='ToEND'),
                  start?: string(name='Start', description='The start time of the stream.', example='00:00:05'),
                }(name='Timeline', description='The timeline settings.'),
                width?: string(name='Width', description='The width of the output video.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          isInheritTags?: boolean(name='IsInheritTags', description='Indicates whether the tags of the input stream are inherited in the output stream. This parameter does not take effect when the input is not a media asset. Default value: false.', example='true'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Indicates whether the text size was adjusted based on the output video dimensions. Valid values: true and false. Default value: false.', example='false'),
                borderColor?: string(name='BorderColor', description='The border color.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The border width.', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the watermark.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.', example='16'),
                left?: string(name='Left', description='The distance of the watermark from the left edge.', example='10'),
                top?: string(name='Top', description='The distance of the watermark from the top edge.', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Indicates whether the audio stream is deleted.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100. Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              tags?: map[string]string(name='Tags'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.

For more information about examples, see How do I set the resolution for an output video?', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum adaptive bitrate (ABR). This parameter takes effect only for Narrowband HD 1.0.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: Kbit/s.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.

If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60]. The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.

Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Indicates whether the auto-rotate screen feature is enabled.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video. Format: width:height:left:top.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Indicates whether the video was removed.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.

Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The transcoding configuration.'),
        requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
        scheduleConfig?: {
          pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the snapshot job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
          priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
        }(name='ScheduleConfig', description='The scheduling information about the job.'),
        status?: string(name='Status', description='The state of the transcoding job. Valid values: Init (the job is submitted), Success (the job is successful), Fail (the job failed), and Deleted (the job is deleted).', example='Init'),
        submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission result.', example='{}'),
        submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
        userData?: string(name='UserData', description='The user data.', example='user-data'),
      }
    ](name='TranscodeJobList', description='The list of subjobs.'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='TranscodeParentJob', description='TranscodeParentJobWithSubJobDTO'),
}

model GetTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTranscodeJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a transcoding job.
 *
 * @param request GetTranscodeJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetTranscodeJobResponse
 */
async function getTranscodeJobWithOptions(request: GetTranscodeJobRequest, runtime: Util.RuntimeOptions): GetTranscodeJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.parentJobId)) {
    query['ParentJobId'] = request.parentJobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetTranscodeJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a transcoding job.
 *
 * @param request GetTranscodeJobRequest
 * @return GetTranscodeJobResponse
 */
async function getTranscodeJob(request: GetTranscodeJobRequest): GetTranscodeJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return getTranscodeJobWithOptions(request, runtime);
}

model GetUrlUploadInfosRequest {
  jobIds?: string(name='JobIds', description='The IDs of the upload jobs. You can specify one or more job IDs. You can obtain the job IDs from the response parameter JobId of the [UploadMediaByURL](https://help.aliyun.com/document_detail/86311.html) operation.

*   You can specify a maximum of 10 job IDs.
*   Separate the job IDs with commas (,).

>  You must specify either JobIds or UploadURLs. If you specify both parameters, only the value of JobIds takes effect.', example='df2ac80b481346daa1db6a7c40edc7f8'),
  uploadURLs?: string(name='UploadURLs', description='The upload URLs of the source files. You can specify a maximum of 10 URLs. Separate the URLs with commas (,).

> 

*   The URLs must be encoded.

*   If a media file is uploaded multiple times, we recommend that you specify the URL of the media file only once in this parameter.

*   You must specify either JobIds or UploadURLs. If you specify both parameters, only the value of JobIds takes effect.', example='https://media.w3.org/2010/05/sintel/trailer.mp4'),
}

model GetUrlUploadInfosResponseBody = {
  nonExists?: [ string ](name='NonExists', description='The job IDs or upload URLs that do not exist.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  URLUploadInfoList?: [ 
    {
      completeTime?: string(name='CompleteTime', description='The time when the upload job was complete. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2021-11-26 21:47:37'),
      creationTime?: string(name='CreationTime', description='The time when the upload job was created. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2021-11-07T10:03:37Z'),
      errorCode?: string(name='ErrorCode', description='The error code returned if the upload job failed.', example='200'),
      errorMessage?: string(name='ErrorMessage', description='The error message returned if the upload job failed.', example='Success'),
      fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='64610'),
      jobId?: string(name='JobId', description='The ID of the upload job.', example='3829500c0fef429fa4ec1680b122d***'),
      mediaId?: string(name='MediaId', description='The ID of the uploaded media file.', example='5014ca70f08171ecbf940764a0fd6***'),
      status?: string(name='Status', description='The status of the upload job. For more information about the valid values of the parameter, see the "Status: the status of a URL-based upload job" section of the [Basic data types](https://help.aliyun.com/document_detail/52839.html) topic.', example='Normal'),
      uploadURL?: string(name='UploadURL', description='The upload URL of the source file.

>  A maximum of 100 URLs can be returned.', example='http://****.mp4'),
      userData?: string(name='UserData', description='The user data. The value is a JSON string.', example='{"MessageCallback":"{"CallbackURL":"http://example.aliyundoc.com"}", "Extend":"{"localId":"***", "test":"www"}"}'),
    }
  ](name='URLUploadInfoList', description='The details about URL-based upload jobs.'),
}

model GetUrlUploadInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetUrlUploadInfosResponseBody(name='body'),
}

/**
 * @summary Queries the information about URL-based upload jobs.
 *
 * @description You can call this operation to query the information, including the upload status, user data, creation time, and completion time, about URL-based upload jobs based on the returned job IDs or the URLs used during the upload.
 * If an upload job fails, you can view the error code and error message. If an upload job is successful, you can obtain the video ID.
 *
 * @param request GetUrlUploadInfosRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetUrlUploadInfosResponse
 */
async function getUrlUploadInfosWithOptions(request: GetUrlUploadInfosRequest, runtime: Util.RuntimeOptions): GetUrlUploadInfosResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobIds)) {
    query['JobIds'] = request.jobIds;
  }
  if (!Util.isUnset(request.uploadURLs)) {
    query['UploadURLs'] = request.uploadURLs;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetUrlUploadInfos',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about URL-based upload jobs.
 *
 * @description You can call this operation to query the information, including the upload status, user data, creation time, and completion time, about URL-based upload jobs based on the returned job IDs or the URLs used during the upload.
 * If an upload job fails, you can view the error code and error message. If an upload job is successful, you can obtain the video ID.
 *
 * @param request GetUrlUploadInfosRequest
 * @return GetUrlUploadInfosResponse
 */
async function getUrlUploadInfos(request: GetUrlUploadInfosRequest): GetUrlUploadInfosResponse {
  var runtime = new Util.RuntimeOptions{};
  return getUrlUploadInfosWithOptions(request, runtime);
}

model GetVideoListRequest {
  cateId?: long(name='CateId', description='The ID of the category.', example='781111'),
  endTime?: string(name='EndTime', description='The end of the time range to query. The end time must be later than the start time. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-01-11T12:59:00Z'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='20'),
  sortBy?: string(name='SortBy', description='The sorting method of the results. Valid values:

*   CreationTime:Desc (default): sorts results in reverse chronological order.
*   CreationTime:Asc: sorts results in chronological order.', example='CreationTime:Asc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-01-11T12:00:00Z'),
  status?: string(name='Status', description='The status of the video. You can specify multiple video statuses and separate them with commas (,).

Valid values:

*   PrepareFail: The file is abnormal.
*   UploadFail: The video failed to be uploaded.
*   UploadSucc: The video is uploaded.
*   Transcoding: The video is being transcoded.
*   TranscodeFail: The video failed to be transcoded.
*   ProduceFail: The video failed to be produced.
*   Normal: The video is normal.
*   Uploading: The video is being uploaded.
*   Preparing: The file is being generated.
*   Blocked: The video is blocked.
*   checking: The video is being reviewed.', example='Uploading,Normal'),
}

model GetVideoListResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaList?: [ 
    {
      appId?: string(name='AppId', description='The ID of the application. Default value: app-1000000.', example='app-1000000'),
      cateId?: long(name='CateId', description='The ID of the category.', example='3679'),
      cateName?: string(name='CateName', description='The name of the category.'),
      coverUrl?: string(name='CoverUrl', description='The URL of the thumbnail.', example='http://example.aliyundoc.com/snapshot/****.jpg?auth_key=1498476426-0-0-f00b9455c49a423ce69cf4e27333****'),
      creationTime?: string(name='CreationTime', description='The time when the audio or video file was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:15:50Z'),
      description?: string(name='Description', description='The description of the audio or video file.'),
      duration?: float(name='Duration', description='The duration. Unit: seconds.', example='135.6'),
      mediaId?: string(name='MediaId', description='The ID of the audio or video file.', example='1c6ce34007d571ed94667630a6bc****'),
      modificationTime?: string(name='ModificationTime', description='The time when the audio or video file was updated. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:16:50Z'),
      size?: long(name='Size', description='The size of the source file. Unit: bytes.', example='10897890'),
      snapshots?: [ string ](name='Snapshots', description='The array of video snapshot URLs.'),
      status?: string(name='Status', description='The status of the video.

Valid values:

*   PrepareFail: The file is abnormal.
*   UploadFail: The video failed to be uploaded.
*   UploadSucc: The video is uploaded.
*   Transcoding: The video is being transcoded.
*   TranscodeFail: The video failed to be transcoded.
*   ProduceFail: The video failed to be produced.
*   Normal: The video is normal.
*   Uploading: The video is being uploaded.
*   Preparing: The file is being generated.
*   Blocked: The video is blocked.
*   checking: The video is being reviewed.', example='Normal'),
      storageLocation?: string(name='StorageLocation', description='The storage address.', example='out-****.oss-cn-shanghai.aliyuncs.com'),
      tags?: string(name='Tags', description='The tags of the audio or video file.'),
      title?: string(name='Title', description='The title of the audio or video file.'),
    }
  ](name='MediaList', description='The information about the audio and video files.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request is successful. Valid values:

*   true
*   false', example='true'),
  total?: long(name='Total', description='The total number of audio and video files that meet the conditions.', example='163'),
}

model GetVideoListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetVideoListResponseBody(name='body'),
}

/**
 * @summary Queries information about video and audio files.
 *
 * @description You can call this operation to query information about up to the first 5,000 audio and video files based on the filter condition, such as the status or category ID of the file. We recommend that you set the StartTime and EndTime parameters to narrow down the time range and perform multiple queries to obtain data.
 *
 * @param request GetVideoListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetVideoListResponse
 */
async function getVideoListWithOptions(request: GetVideoListRequest, runtime: Util.RuntimeOptions): GetVideoListResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.cateId)) {
    query['CateId'] = request.cateId;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetVideoList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries information about video and audio files.
 *
 * @description You can call this operation to query information about up to the first 5,000 audio and video files based on the filter condition, such as the status or category ID of the file. We recommend that you set the StartTime and EndTime parameters to narrow down the time range and perform multiple queries to obtain data.
 *
 * @param request GetVideoListRequest
 * @return GetVideoListResponse
 */
async function getVideoList(request: GetVideoListRequest): GetVideoListResponse {
  var runtime = new Util.RuntimeOptions{};
  return getVideoListWithOptions(request, runtime);
}

model GetWorkflowTaskRequest {
  taskId?: string(name='TaskId', description='The ID of the workflow task.', example='******4215e042b3966ca5441e******'),
}

model GetWorkflowTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******0C-7870-15FE-B96F-8880BB******'),
  workflowTask?: {
    activityResults?: string(name='ActivityResults', description='The results for all nodes of the workflow task.'),
    createTime?: string(name='CreateTime', description='The time when the task was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-01-04T02:05:17Z'),
    finishTime?: string(name='FinishTime', description='The time when the task was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-01-04T02:06:19Z'),
    status?: string(name='Status', description='The task state.

Valid values:

*   Init: The task is being initialized.
*   Failed: The task failed.
*   Canceled: The task is canceled.
*   Processing: The task is in progress.
*   Succeed: The task is successful.', example='Succeed'),
    taskId?: string(name='TaskId', description='The ID of the workflow task.', example='******4215e042b3966ca5441e******'),
    taskInput?: string(name='TaskInput', description='The input of the workflow task.', example='{
      "Type": "Media",
      "Media": "******30706071edbfe290b488******"
}'),
    userData?: string(name='UserData', description='The user-defined field that was specified when the workflow task was submitted.', example='{"NotifyAddress":"http://xx.xx.xxx"}'),
    workflow?: {
      createTime?: string(name='CreateTime', description='The time when the workflow was created.', example='2022-11-27T10:02:12Z'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the workflow was last modified.', example='2022-11-29T02:06:19Z'),
      name?: string(name='Name', description='The workflow name.'),
      status?: string(name='Status', description='The workflow state.

Valid values:

*   Active
*   Inactive', example='Active'),
      type?: string(name='Type', description='The workflow type.

Valid values:

*   Customize: custom workflow.
*   System: system workflow.
*   Common: user-created workflow.', example='Common'),
      workflowId?: string(name='WorkflowId', description='The workflow ID.', example='******63dca94c609de02ac0d1******'),
    }(name='Workflow', description='The workflow Information.'),
  }(name='WorkflowTask', description='The information about the workflow task.'),
}

model GetWorkflowTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkflowTaskResponseBody(name='body'),
}

/**
 * @summary Queries the information about a workflow task by task ID, including the workflow ID and the status and result of the task. You can query only the workflow task data of the last year.
 *
 * @param request GetWorkflowTaskRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetWorkflowTaskResponse
 */
async function getWorkflowTaskWithOptions(request: GetWorkflowTaskRequest, runtime: Util.RuntimeOptions): GetWorkflowTaskResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.taskId)) {
    query['TaskId'] = request.taskId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetWorkflowTask',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a workflow task by task ID, including the workflow ID and the status and result of the task. You can query only the workflow task data of the last year.
 *
 * @param request GetWorkflowTaskRequest
 * @return GetWorkflowTaskResponse
 */
async function getWorkflowTask(request: GetWorkflowTaskRequest): GetWorkflowTaskResponse {
  var runtime = new Util.RuntimeOptions{};
  return getWorkflowTaskWithOptions(request, runtime);
}

model InsertMediaToSearchLibRequest {
  input?: string(name='Input', description='The URL of the video, audio, or image file that you want to import to the search library.

Note: Make sure that you specify a correct file name and the bucket in which the file resides is in the same region where this operation is called. Otherwise, the file cannot be found or the operation may fail.

Specify an Object Storage Service (OSS) URL in the following format: oss://[Bucket name]/[File path]. For example, you can specify oss://[example-bucket-****]/[object_path-****].

Specify an HTTP URL in the following format: public endpoint. For example, you can specify http://example-test-\\\\*\\\\*\\\\*\\\\*.mp4.

This parameter is required.', example='http://example-test-****.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. Each media ID is unique. If you leave this parameter empty, a media ID is automatically generated for this parameter.', example='411bed50018971edb60b0764a0ec6***'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

*   video (default)
*   image
*   audio', example='video'),
  msgBody?: string(name='MsgBody', description='The message body.', example='{}'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1'),
}

model InsertMediaToSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model InsertMediaToSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: InsertMediaToSearchLibResponseBody(name='body'),
}

/**
 * @summary Adds a media asset in a search library. Before you call this operation, you must create a search library.
 *
 * @param request InsertMediaToSearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return InsertMediaToSearchLibResponse
 */
async function insertMediaToSearchLibWithOptions(request: InsertMediaToSearchLibRequest, runtime: Util.RuntimeOptions): InsertMediaToSearchLibResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.input)) {
    query['Input'] = request.input;
  }
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!Util.isUnset(request.msgBody)) {
    query['MsgBody'] = request.msgBody;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'InsertMediaToSearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Adds a media asset in a search library. Before you call this operation, you must create a search library.
 *
 * @param request InsertMediaToSearchLibRequest
 * @return InsertMediaToSearchLibResponse
 */
async function insertMediaToSearchLib(request: InsertMediaToSearchLibRequest): InsertMediaToSearchLibResponse {
  var runtime = new Util.RuntimeOptions{};
  return insertMediaToSearchLibWithOptions(request, runtime);
}

model ListAIAgentInstanceRequest {
  AIAgentId?: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4***'),
  endTime?: string(name='EndTime', example='2023-01-02T00:00:00Z'),
  pageNumber?: long(name='PageNumber', example='1'),
  pageSize?: long(name='PageSize', example='10'),
  startTime?: string(name='StartTime', example='2023-01-01T00:00:00Z'),
}

model ListAIAgentInstanceResponseBody = {
  instances?: [ 
    {
      callLogUrl?: string(name='CallLogUrl', example='https://example.com/call_logs/12345.json'),
      runtimeConfig?: AIAgentRuntimeConfig(name='RuntimeConfig', example='{"VoiceChat":{"AgentUserId":"voice_agent_001","ChannelId":"voice_channel_001","AuthToken":"your_voice_chat_auth_token"}}'),
      status?: string(name='Status', example='Finished'),
      templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', example='{"VoiceChat": {"VoiceId": "zhixiaoxia"}}'),
      userData?: string(name='UserData', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
    }
  ](name='Instances'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model ListAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAIAgentInstanceResponseBody(name='body'),
}

/**
 * @summary 列出实例
 *
 * @param request ListAIAgentInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListAIAgentInstanceResponse
 */
async function listAIAgentInstanceWithOptions(request: ListAIAgentInstanceRequest, runtime: Util.RuntimeOptions): ListAIAgentInstanceResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.AIAgentId)) {
    query['AIAgentId'] = request.AIAgentId;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListAIAgentInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 列出实例
 *
 * @param request ListAIAgentInstanceRequest
 * @return ListAIAgentInstanceResponse
 */
async function listAIAgentInstance(request: ListAIAgentInstanceRequest): ListAIAgentInstanceResponse {
  var runtime = new Util.RuntimeOptions{};
  return listAIAgentInstanceWithOptions(request, runtime);
}

model ListAllPublicMediaTagsRequest {
  businessType?: string(name='BusinessType', description='The business type of the media asset.', example='"sticker"'),
  entityId?: string(name='EntityId', description='The entity ID, which is used to distinguish between media assets of different types in the public domain.

Set this parameter to Copyright_Music, which indicates music in the public domain.', example='Copyright_Music'),
}

model ListAllPublicMediaTagsResponseBody = {
  mediaTagList?: [ 
    {
      mediaTagId?: string(name='MediaTagId', description='The ID of the media tag.', example='sticker-gif'),
      mediaTagNameChinese?: string(name='MediaTagNameChinese', description='The name of the media tag in Chinese.', example='Gif'),
      mediaTagNameEnglish?: string(name='MediaTagNameEnglish', description='The name of the material tag in English.'),
      options?: [ 
        {
          optionChineseName?: string(name='OptionChineseName', description='The option name in Chinese.'),
          optionEnglishName?: string(name='OptionEnglishName', description='The option name in English.', example='Angry'),
          optionId?: string(name='OptionId', description='The option ID.', example='Angry'),
        }
      ](name='Options', description='The options.'),
    }
  ](name='MediaTagList', description='The tags of media assets in the public media library.'),
  requestId?: string(name='RequestId', description='The request ID.', example='B45F83B7-7F87-4792-BFE9-63CD2137CAF0'),
}

model ListAllPublicMediaTagsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAllPublicMediaTagsResponseBody(name='body'),
}

/**
 * @summary Queries a list of tags of media assets in the public media library.
 *
 * @param request ListAllPublicMediaTagsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListAllPublicMediaTagsResponse
 */
async function listAllPublicMediaTagsWithOptions(request: ListAllPublicMediaTagsRequest, runtime: Util.RuntimeOptions): ListAllPublicMediaTagsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.businessType)) {
    query['BusinessType'] = request.businessType;
  }
  if (!Util.isUnset(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListAllPublicMediaTags',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'Anonymous',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of tags of media assets in the public media library.
 *
 * @param request ListAllPublicMediaTagsRequest
 * @return ListAllPublicMediaTagsResponse
 */
async function listAllPublicMediaTags(request: ListAllPublicMediaTagsRequest): ListAllPublicMediaTagsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listAllPublicMediaTagsWithOptions(request, runtime);
}

model ListAvatarTrainingJobsRequest {
  pageNo?: int32(name='PageNo', description='*   The page number.
*   Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='*   The number of entries per page.
*   Default value: 10.
*   Valid values: 1 to 100.', example='10'),
  status?: string(name='Status', description='*   The job state.
*   Valid values: Init, Queuing, Training, Success, and Fail.', example='Success'),
}

model ListAvatarTrainingJobsResponseBody = {
  data?: {
    avatarTrainingJobList?: [ 
      {
        avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
        avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXX'),
        avatarName?: string(name='AvatarName', description='The name of the digital human.'),
        avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
        createTime?: string(name='CreateTime', description='*   The time when the job was created.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
        firstTrainingTime?: string(name='FirstTrainingTime', description='*   The time when the first training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
        jobId?: string(name='JobId', description='The ID of the digital human training job.', example='*****aded114489ea02e0addf93*****'),
        lastTrainingTime?: string(name='LastTrainingTime', description='*   The time when the last training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
        message?: string(name='Message', description='The status description.'),
        portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='*****aded114489ea02e0addf93*****'),
        status?: string(name='Status', description='The state of the digital human training job.', example='Normal'),
      }
    ](name='AvatarTrainingJobList', description='The list of digital human training jobs.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='3'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model ListAvatarTrainingJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAvatarTrainingJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of digital human training jobs.
 *
 * @param request ListAvatarTrainingJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListAvatarTrainingJobsResponse
 */
async function listAvatarTrainingJobsWithOptions(request: ListAvatarTrainingJobsRequest, runtime: Util.RuntimeOptions): ListAvatarTrainingJobsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListAvatarTrainingJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of digital human training jobs.
 *
 * @param request ListAvatarTrainingJobsRequest
 * @return ListAvatarTrainingJobsResponse
 */
async function listAvatarTrainingJobs(request: ListAvatarTrainingJobsRequest): ListAvatarTrainingJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listAvatarTrainingJobsWithOptions(request, runtime);
}

model ListAvatarsRequest {
  avatarType?: string(name='AvatarType', description='*   The type of the digital human.
*   2DAvatar', example='2DAvatar'),
  pageNo?: int32(name='PageNo', description='*   The page number.
*   Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='*   The number of entries per page.
*   Default value: 10.', example='10'),
}

model ListAvatarsResponseBody = {
  data?: {
    avatarList?: [ 
      {
        avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
        avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXX'),
        avatarName?: string(name='AvatarName', description='The name of the digital human.'),
        avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
        portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='****571c704445f9a0ee011406c2****'),
        thumbnail?: string(name='Thumbnail', description='The thumbnail URL.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
        transparent?: boolean(name='Transparent', description='Indicates whether the digital human image supports the alpha channels.', example='true'),
      }
    ](name='AvatarList', description='The queried digital humans.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model ListAvatarsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAvatarsResponseBody(name='body'),
}

/**
 * @summary Queries a list of trained digital humans.
 *
 * @param request ListAvatarsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListAvatarsResponse
 */
async function listAvatarsWithOptions(request: ListAvatarsRequest, runtime: Util.RuntimeOptions): ListAvatarsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.avatarType)) {
    query['AvatarType'] = request.avatarType;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListAvatars',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of trained digital humans.
 *
 * @param request ListAvatarsRequest
 * @return ListAvatarsResponse
 */
async function listAvatars(request: ListAvatarsRequest): ListAvatarsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listAvatarsWithOptions(request, runtime);
}

model ListBatchMediaProducingJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2023-06-05T15:59:59Z'),
  jobId?: string(name='JobId', description='The ID of the quick video production job.', example='****d80e4e4044975745c14b****'),
  jobType?: string(name='JobType', description='The job type.

Valid values:

*   Script: script-based editing job that mixes media assets.
*   Smart_Mix: intelligent editing job that mixes media assets.', example='Script'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.', example='100'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='mRZkKAovub0xWVfH14he4Q=='),
  sortBy?: string(name='SortBy', description='The sorting parameter. Valid values:

*   desc (default): sorted by creation time in descending order.
*   asc: sorted by creation time in ascending order.

<!---->', example='desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-02-02T00:00:00Z'),
  status?: string(name='Status', description='The job state.

Valid values:

*   Finished
*   Init
*   Failed
*   Processing', example='Finished'),
}

model ListBatchMediaProducingJobsResponseBody = {
  editingBatchJobList?: [ 
    {
      completeTime?: string(name='CompleteTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2023-06-09T06:38:09Z'),
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-06-09T06:36:48Z'),
      editingConfig?: string(name='EditingConfig', description='The editing configurations. For more information, see [EditingConfig](~~2692547#1be9bba03b7qu~~).', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}'),
      extend?: string(name='Extend', description='The extended information of the job.', example='{}'),
      inputConfig?: string(name='InputConfig', description='The input configurations.'),
      jobId?: string(name='JobId', description='The ID of the quick video production job.', example='******7ecbee4c6d9b8474498e******'),
      jobType?: string(name='JobType', description='The job type.

Valid values:

*   Script: script-based editing job that mixes media assets.
*   Smart_Mix: intelligent editing job that mixes media assets.', example='Script'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2023-06-09T06:37:58Z'),
      outputConfig?: string(name='OutputConfig', description='The output configurations. For more information, see [OutputConfig](~~2692547#447b928fcbuoa~~).', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 20,
  "MaxDuration": 15,
  "Width": 1080,
  "Height": 1920,
  "Video": {"Crf": 27}
}'),
      status?: string(name='Status', description='The job state.

Valid values:

*   Finished
*   Init
*   Failed
*   Processing', example='Finished'),
      userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).'),
    }
  ](name='EditingBatchJobList', description='The queried quick video production jobs.'),
  maxResults?: int32(name='MaxResults', description='The number of entries per page. Valid values: 1 to 100.

Default value: 10.', example='100'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model ListBatchMediaProducingJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListBatchMediaProducingJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of quick video production jobs based on conditions such as the job type and state.
 *
 * @param request ListBatchMediaProducingJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListBatchMediaProducingJobsResponse
 */
async function listBatchMediaProducingJobsWithOptions(request: ListBatchMediaProducingJobsRequest, runtime: Util.RuntimeOptions): ListBatchMediaProducingJobsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.jobType)) {
    query['JobType'] = request.jobType;
  }
  if (!Util.isUnset(request.maxResults)) {
    query['MaxResults'] = request.maxResults;
  }
  if (!Util.isUnset(request.nextToken)) {
    query['NextToken'] = request.nextToken;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListBatchMediaProducingJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of quick video production jobs based on conditions such as the job type and state.
 *
 * @param request ListBatchMediaProducingJobsRequest
 * @return ListBatchMediaProducingJobsResponse
 */
async function listBatchMediaProducingJobs(request: ListBatchMediaProducingJobsRequest): ListBatchMediaProducingJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listBatchMediaProducingJobsWithOptions(request, runtime);
}

model ListCustomTemplatesRequest {
  name?: string(name='Name', description='The template name.', example='test-template'),
  orderBy?: string(name='OrderBy', description='The order in which the entries are sorted. Valid values:

*   CreateTimeDesc: sorted by creation time in descending order.
*   CreateTimeAsc: sorted by creation time in ascending order.', example='CreateTimeDesc'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='20'),
  subtype?: string(name='Subtype', description='The subtype ID of the template.

*   Valid values for transcoding templates:

    *   1 (Normal): regular template.
    *   2 (AudioTranscode): audio transcoding template.
    *   3 (Remux): container format conversion template.
    *   4 (NarrowBandV1): Narrowband HD 1.0 template.
    *   5 (NarrowBandV2): Narrowband HD 2.0 template.

*   Valid values for snapshot templates:

    *   1 (Normal): regular template.
    *   2 (Sprite): sprite template.
    *   3 (WebVtt): WebVTT template.

*   Valid values for AI-assisted content moderation templates:

    *   1 (Video): video moderation template.
    *   2 (Audio): audio moderation template.
    *   3 (Image): image moderation template.

*   Valid values for AI-assisted intelligent erasure templates:

    *   1 (VideoDelogo): logo erasure template.
    *   2 (VideoDetext): subtitle erasure template.', example='2'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
  type?: string(name='Type', description='The template type. Valid values:

*   1: transcoding template.
*   2: snapshot template.
*   3: animated image template.
*   4\\\\. image watermark template.
*   5: text watermark template.
*   6: subtitle template.
*   7: AI-assisted content moderation template.
*   8: AI-assisted intelligent thumbnail template.
*   9: AI-assisted intelligent erasure template.

This parameter is required.', example='1'),
}

model ListCustomTemplatesResponseBody = {
  customTemplateList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
      frontendHint?: {
        transcodeTemplateHint?: {
          bitrateControlType?: string(name='BitrateControlType'),
        }(name='TranscodeTemplateHint'),
      }(name='FrontendHint'),
      isDefault?: boolean(name='IsDefault', description='Indicates whether the template is the default template.

Valid values:

*   true
*   false', example='true'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
      status?: string(name='Status', description='The template state.

Valid values:

*   Normal', example='Normal'),
      subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='2'),
      subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='AudioTranscode'),
      templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Container":{"Format":"mp3"},"Audio":{"Codec":"mp3","Bitrate":"64","Samplerate":"22050","Channels":"2"}}'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
      templateName?: string(name='TemplateName', description='The template name.', example='test-template'),
      type?: int32(name='Type', description='The type ID of the template.', example='1'),
      typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
    }
  ](name='CustomTemplateList', description='The queried templates.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  total?: int32(name='Total', description='The total number of templates.', example='20'),
}

model ListCustomTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCustomTemplatesResponseBody(name='body'),
}

/**
 * @summary Queries a list of custom templates.
 *
 * @param request ListCustomTemplatesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListCustomTemplatesResponse
 */
async function listCustomTemplatesWithOptions(request: ListCustomTemplatesRequest, runtime: Util.RuntimeOptions): ListCustomTemplatesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.subtype)) {
    query['Subtype'] = request.subtype;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListCustomTemplates',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of custom templates.
 *
 * @param request ListCustomTemplatesRequest
 * @return ListCustomTemplatesResponse
 */
async function listCustomTemplates(request: ListCustomTemplatesRequest): ListCustomTemplatesResponse {
  var runtime = new Util.RuntimeOptions{};
  return listCustomTemplatesWithOptions(request, runtime);
}

model ListCustomizedVoiceJobsRequest {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10'),
  type?: string(name='Type', description='The type of the human voice cloning job. Valid values:

*   Basic
*   Standard

> : If you do not specify this parameter, the default value Basic is used.', example='Standard'),
}

model ListCustomizedVoiceJobsResponseBody = {
  data?: {
    customizedVoiceJobList?: [ 
      {
        createTime?: string(name='CreateTime', description='*   The time when the job was created.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-04-01T06:23:59Z'),
        gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
        gmtCreate?: string(name='GmtCreate', description='The time when the job was created.', example='2022-06-27T02:42:28Z'),
        jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='2245ab99a7fd4116a4fd3f499b7a56c5'),
        message?: string(name='Message', description='The returned message.'),
        scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation', example='story'),
        status?: string(name='Status', description='The job state. Valid values:

*   Initialization
*   AudioDetecting
*   PreTraining
*   Training
*   Success
*   Fail', example='Success'),
        type?: string(name='Type', description='*   The voice type. Valid values:

    *   Basic
    *   Standard', example='Standard'),
        voiceDesc?: string(name='VoiceDesc', description='The voice description.

*   The description can be up to 256 characters in length.'),
        voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
        voiceName?: string(name='VoiceName', description='The voice name.

*   The name can be up to 32 characters in length.'),
      }
    ](name='CustomizedVoiceJobList', description='The queried human voice cloning jobs.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='271'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
}

model ListCustomizedVoiceJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCustomizedVoiceJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of human voice cloning jobs.
 *
 * @param request ListCustomizedVoiceJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListCustomizedVoiceJobsResponse
 */
async function listCustomizedVoiceJobsWithOptions(request: ListCustomizedVoiceJobsRequest, runtime: Util.RuntimeOptions): ListCustomizedVoiceJobsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListCustomizedVoiceJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of human voice cloning jobs.
 *
 * @param request ListCustomizedVoiceJobsRequest
 * @return ListCustomizedVoiceJobsResponse
 */
async function listCustomizedVoiceJobs(request: ListCustomizedVoiceJobsRequest): ListCustomizedVoiceJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listCustomizedVoiceJobsWithOptions(request, runtime);
}

model ListCustomizedVoicesRequest {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10'),
  type?: string(name='Type', description='*   The voice type. Valid values:

    *   Basic
    *   Standard

*   If you do not specify this parameter, the default value Basic is used.', example='Standard'),
}

model ListCustomizedVoicesResponseBody = {
  data?: {
    customizedVoiceList?: [ 
      {
        demoAudioMediaId?: string(name='DemoAudioMediaId', description='The media asset ID of the sample audio file.', example='****4d5e829d498aaf966b119348****'),
        gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='male'),
        scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation', example='story'),
        type?: string(name='Type', description='*   The voice type. Valid values:

    *   Basic
    *   Standard', example='Standard'),
        voiceDesc?: string(name='VoiceDesc', description='The voice description.'),
        voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
        voiceName?: string(name='VoiceName', description='The voice name.'),
      }
    ](name='CustomizedVoiceList', description='The queried personalized human voices.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='41'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model ListCustomizedVoicesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCustomizedVoicesResponseBody(name='body'),
}

/**
 * @summary Queries a list of personalized human voices.
 *
 * @param request ListCustomizedVoicesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListCustomizedVoicesResponse
 */
async function listCustomizedVoicesWithOptions(request: ListCustomizedVoicesRequest, runtime: Util.RuntimeOptions): ListCustomizedVoicesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListCustomizedVoices',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of personalized human voices.
 *
 * @param request ListCustomizedVoicesRequest
 * @return ListCustomizedVoicesResponse
 */
async function listCustomizedVoices(request: ListCustomizedVoicesRequest): ListCustomizedVoicesResponse {
  var runtime = new Util.RuntimeOptions{};
  return listCustomizedVoicesWithOptions(request, runtime);
}

model ListDNADBRequest {
  DBIds?: string(name='DBIds', description='The IDs of the media fingerprint libraries. We recommend that you query at most 10 libraries at a time. Separate multiple library IDs with commas (,).', example='2288c6ca184c0e47098a5b665e2a12****,78dc866518b843259669df58ed30****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model ListDNADBResponseBody = {
  DBList?: [ 
    {
      DBId?: string(name='DBId', description='The ID of the media fingerprint library.', example='88c6ca184c0e47098a5b665e2a12****'),
      description?: string(name='Description', description='The description of the media fingerprint library.'),
      model?: string(name='Model', description='The model of the media fingerprint library. Valid values:

*   **Video**
*   **Audio**
*   **Image**
*   **Text** (supported only in the China (Shanghai) region)', example='Video'),
      name?: string(name='Name', description='The name of the media fingerprint library.', example='example-name'),
      status?: string(name='Status', description='The state of the media fingerprint library. Default value: **offline**. ****Valid values:

*   **offline**: The media fingerprint library is offline.
*   **active**: The media fingerprint library is online.
*   **deleted**: The media fingerprint library is deleted.', example='active'),
    }
  ](name='DBList', description='The queried media fingerprint libraries.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model ListDNADBResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDNADBResponseBody(name='body'),
}

/**
 * @summary Queries a list of media fingerprint libraries.
 *
 * @param request ListDNADBRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListDNADBResponse
 */
async function listDNADBWithOptions(request: ListDNADBRequest, runtime: Util.RuntimeOptions): ListDNADBResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBIds)) {
    query['DBIds'] = request.DBIds;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListDNADB',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of media fingerprint libraries.
 *
 * @param request ListDNADBRequest
 * @return ListDNADBResponse
 */
async function listDNADB(request: ListDNADBRequest): ListDNADBResponse {
  var runtime = new Util.RuntimeOptions{};
  return listDNADBWithOptions(request, runtime);
}

model ListDNAFilesRequest {
  DBId?: string(name='DBId', description='The ID of the media fingerprint library.

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='ae0fd49c0840e14daf0d66a75b83****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model ListDNAFilesResponseBody = {
  fileList?: [ 
    {
      inputFile?: {
        bucket?: string(name='Bucket', description='The name of the OSS bucket in which the input file is stored.', example='example-bucket'),
        location?: string(name='Location', description='The OSS region in which the input file resides.', example='oss-cn-beijing'),
        object?: string(name='Object', description='The name of the OSS object that is used as the input file.', example='example-****.mp4'),
      }(name='InputFile', description='The Object Storage Service (OSS) information about the input file.'),
      primaryKey?: string(name='PrimaryKey', description='The primary key of the file.', example='ae0fd49c0840e14daf0d66a75b83****'),
    }
  ](name='FileList', description='The queried files.'),
  nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='ae0fd49c0840e14daf0d66a75b83****'),
  requestId?: string(name='RequestId', description='The request ID.', example='2AE89FA5-E620-56C7-9B80-75D09757385A'),
}

model ListDNAFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDNAFilesResponseBody(name='body'),
}

/**
 * @summary Queries a list of files in a media fingerprint library.
 *
 * @description You can call this operation to query files in a media fingerprint library based on the library ID. The queried results can be paginated.
 *
 * @param request ListDNAFilesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListDNAFilesResponse
 */
async function listDNAFilesWithOptions(request: ListDNAFilesRequest, runtime: Util.RuntimeOptions): ListDNAFilesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBId)) {
    query['DBId'] = request.DBId;
  }
  if (!Util.isUnset(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListDNAFiles',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of files in a media fingerprint library.
 *
 * @description You can call this operation to query files in a media fingerprint library based on the library ID. The queried results can be paginated.
 *
 * @param request ListDNAFilesRequest
 * @return ListDNAFilesResponse
 */
async function listDNAFiles(request: ListDNAFilesRequest): ListDNAFilesResponse {
  var runtime = new Util.RuntimeOptions{};
  return listDNAFilesWithOptions(request, runtime);
}

model ListDynamicImageJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created.', example='2022-07-14T00:00:00Z'),
  jobId?: string(name='JobId', description='The job ID.', example='****cdb3e74639973036bc84****'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='cdb3e74639973036bc84'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

1.  CreateTimeAsc: sorts the jobs by creation time in ascending order.
2.  CreateTimeDesc: sorts the jobs by creation time in descending order.', example='CreateTimeDesc'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Maximum value: 100.', example='20'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created.', example='2022-07-12T00:00:00Z'),
  status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
}

model ListDynamicImageJobsResponseBody = {
  jobs?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
      input?: {
        media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[regionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://bucket/object'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.

*
*', example='OSS'),
      }(name='Input', description='The input of the job.'),
      jobId?: string(name='JobId', description='The job ID.', example='****cdb3e74639973036bc84****'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
      name?: string(name='Name', description='The name of the job.', example='SampleJob'),
      output?: {
        media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='****cdb3e74639973036bc84****'),
        type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

*
*', example='Media'),
      }(name='Output', description='The output of the job.'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****cdb3e74639973036bc84****'),
      status?: string(name='Status', description='The state of the job.

*   **Success**: The job is successful.
*   **Fail**: The job failed.
*   **Init**: The job is submitted.', example='Success'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****cdb3e74639973036bc84****'),
      triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
    }
  ](name='Jobs', description='The list of jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****cdb3e74639973036bc84****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListDynamicImageJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDynamicImageJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of image animation jobs.
 *
 * @param request ListDynamicImageJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListDynamicImageJobsResponse
 */
async function listDynamicImageJobsWithOptions(request: ListDynamicImageJobsRequest, runtime: Util.RuntimeOptions): ListDynamicImageJobsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.endOfCreateTime)) {
    query['EndOfCreateTime'] = request.endOfCreateTime;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!Util.isUnset(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.startOfCreateTime)) {
    query['StartOfCreateTime'] = request.startOfCreateTime;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListDynamicImageJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of image animation jobs.
 *
 * @param request ListDynamicImageJobsRequest
 * @return ListDynamicImageJobsResponse
 */
async function listDynamicImageJobs(request: ListDynamicImageJobsRequest): ListDynamicImageJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listDynamicImageJobsWithOptions(request, runtime);
}

model ListEditingProjectsRequest {
  createSource?: string(name='CreateSource', description='The method for creating the online editing project. Valid values:

\\\\- OpenAPI

\\\\- AliyunConsole

\\\\- WebSDK', example='OpenAPI'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-02-02T23:59:59Z'),
  keyword?: string(name='Keyword', description='The search keyword. You can search by job ID.', example='******6f36bc45d09a9d5cde49******'),
  maxResults?: string(name='MaxResults', description='The number of entries per page. A maximum of 100 entries can be returned on each page.

Default value: 10.', example='10'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  projectType?: string(name='ProjectType', description='The type of the editing project. Valid values:

*   EditingProject: a regular editing project.
*   LiveEditingProject: a live stream editing project.', example='EditingProject'),
  sortBy?: string(name='SortBy', description='The order of sorting of the results. Valid values:

*   CreationTime:Desc (default): sorts the results in reverse chronological order.
*   CreationTime:Asc: sorts the results in chronological order.', example='CreationTime:Desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-12-21T08:00:01Z'),
  status?: string(name='Status', description='The status of the online editing project. By default, online editing projects in all states are queried.', example='Produced'),
  templateType?: string(name='TemplateType', description='The template type. This parameter is required if you create a template-based online editing project. Default value: Timeline.

*
*

Valid values:

*   Timeline: a regular template.
*   VETemplate: an advanced template.
*   None: general editing.', example='None'),
}

model ListEditingProjectsResponseBody = {
  maxResults?: int32(name='MaxResults', description='The maximum number of entries returned.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.

This parameter is required.', example='Nzv3rcKla9wHUGua9YXHNA=='),
  projectList?: [ 
    {
      businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{}'),
      businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects.', example='{}'),
      coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='https://xxx.com/cover/xxx.jpg'),
      createSource?: string(name='CreateSource', description='The method for editing the online editing project. Valid values:

\\\\- OpenAPI

\\\\- AliyunConsole

\\\\- WebSDK', example='OpenAPI'),
      createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2017-01-11T12:00:00Z'),
      description?: string(name='Description', description='The description of the online editing project.'),
      errorCode?: string(name='ErrorCode', description='The error code returned if the production of the online editing project failed.', example='InvalidParameter'),
      errorMessage?: string(name='ErrorMessage', description='The error message returned if the production of the online editing project failed.', example='The specified parameter \\\\"LiveStreamConfig\\\\" is not valid. specified parameter example is not valid.'),
      modifiedSource?: string(name='ModifiedSource', description='The method for modifying the online editing project last time.', example='OpenAPI'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last modified.', example='2017-01-11T12:00:00Z'),
      projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fddd7748b58bf1d47e95****'),
      projectType?: string(name='ProjectType', description='The type of the editing project. Valid values:

*   EditingProject: a regular editing project.
*   LiveEditingProject: a live stream editing project.', example='EditingProject'),
      status?: string(name='Status', description='The status of the online editing project. Valid values:

\\\\- Draft

\\\\- Editing

\\\\- Producing

\\\\- Produced

\\\\- ProduceFailed', example='Produced'),
      templateType?: string(name='TemplateType', description='The template type. Valid values:

*   Timeline: a regular template.
*   VETemplate: an advanced template.', example='Timeline'),
      title?: string(name='Title', description='The title of the online editing project.'),
    }
  ](name='ProjectList', description='The queried online editing projects.'),
  requestId?: string(name='RequestId', description='The request ID.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
}

model ListEditingProjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListEditingProjectsResponseBody(name='body'),
}

/**
 * @summary Queries a list of projects that meet the specified conditions. You can filter projects by project creation time.
 *
 * @param request ListEditingProjectsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListEditingProjectsResponse
 */
async function listEditingProjectsWithOptions(request: ListEditingProjectsRequest, runtime: Util.RuntimeOptions): ListEditingProjectsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.createSource)) {
    query['CreateSource'] = request.createSource;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!Util.isUnset(request.maxResults)) {
    query['MaxResults'] = request.maxResults;
  }
  if (!Util.isUnset(request.nextToken)) {
    query['NextToken'] = request.nextToken;
  }
  if (!Util.isUnset(request.projectType)) {
    query['ProjectType'] = request.projectType;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  if (!Util.isUnset(request.templateType)) {
    query['TemplateType'] = request.templateType;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListEditingProjects',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of projects that meet the specified conditions. You can filter projects by project creation time.
 *
 * @param request ListEditingProjectsRequest
 * @return ListEditingProjectsResponse
 */
async function listEditingProjects(request: ListEditingProjectsRequest): ListEditingProjectsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listEditingProjectsWithOptions(request, runtime);
}

model ListLiveRecordFilesRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. The maximum time range to query is four days. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-12-22T08:00:00Z'),
  jobIds?: [ string ](name='JobIds', description='The list of job IDs.'),
  pageNo?: int32(name='PageNo', description='The page number of the page to return. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 5 to 30. Default value: 10.', example='10'),
  recordFormat?: string(name='RecordFormat', description='The format of the recording file. Valid values:

M3U8, FLV, and MP4', example='m3u8'),
  sortBy?: string(name='SortBy', description='The sorting order of the index files by creation time. Valid values:

asc: The query results are displayed in ascending order. This is the default value.

desc: The query results are displayed in descending order.', example='asc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-12-21T08:00:01Z'),
}

model ListLiveRecordFilesResponseBody = {
  files?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the file was created in UTC.', example='2016-05-27T09:40:56Z'),
      duration?: float(name='Duration', description='The recording length. Unit: seconds.', example='100.0'),
      endTime?: string(name='EndTime', description='The end of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2015-12-01T07:36:10Z'),
      format?: string(name='Format', description='The format of the recording file.', example='m3u8'),
      height?: int32(name='Height', description='The height of the video.', example='640'),
      jobId?: string(name='JobId', description='The ID of the recording job.', example='c4d7f0a4-b506-43f9-8de3-07732c3f****'),
      jobName?: string(name='JobName', description='The name of the recording job.', example='LiveRecordJob***'),
      recordId?: string(name='RecordId', description='The ID of the index file.', example='c4d7f0a4-b506-43f9-8de3-07732c3f****'),
      recordOutput?: string(name='RecordOutput', description='The storage information about the recording file.', example='{ "Type": "oss", "Endpoint":"oss-cn-shanghai.aliyuncs.com", "Bucket": "test-bucket" }'),
      recordUrl?: string(name='RecordUrl', description='The URL of the index file.'),
      startTime?: string(name='StartTime', description='The beginning of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2015-12-01T07:36:00Z'),
      streamUrl?: string(name='StreamUrl', description='The name of the live stream.', example='LiveStream***'),
      width?: int32(name='Width', description='The width of the video.', example='480'),
    }
  ](name='Files', description='The list of index files.'),
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='DE24625C-7C0F-4020-8448-****'),
  sortBy?: string(name='SortBy', description='The sorting order of the index files by creation time.', example='asc'),
  totalCount?: string(name='TotalCount', description='The total number of files that meet the specified conditions.', example='100'),
}

model ListLiveRecordFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveRecordFilesResponseBody(name='body'),
}

/**
 * @summary Queries all recording index files in the specified period of time.
 *
 * @param request ListLiveRecordFilesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveRecordFilesResponse
 */
async function listLiveRecordFilesWithOptions(request: ListLiveRecordFilesRequest, runtime: Util.RuntimeOptions): ListLiveRecordFilesResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListLiveRecordFiles',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries all recording index files in the specified period of time.
 *
 * @param request ListLiveRecordFilesRequest
 * @return ListLiveRecordFilesResponse
 */
async function listLiveRecordFiles(request: ListLiveRecordFilesRequest): ListLiveRecordFilesResponse {
  var runtime = new Util.RuntimeOptions{};
  return listLiveRecordFilesWithOptions(request, runtime);
}

model ListLiveRecordJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. The maximum time range between EndTime and StartTime cannot exceed 30 days. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-11T08:00:00Z'),
  keyword?: string(name='Keyword', description='The search keyword. You can use the job ID or name as the keyword to search for jobs.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='20'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results in ascending order.
*   desc: sorts the query results in descending order.', example='desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-15T08:00:00Z'),
  status?: string(name='Status', description='The state of the job. By default, the state is not filtered.

Valid values:

*   paused: The job is paused.
*   initial: The job is not started.
*   started: The job is in progress.', example='started'),
}

model ListLiveRecordJobsResponseBody = {
  liveRecordJobs?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
      jobId?: string(name='JobId', description='The ID of the recording job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
      name?: string(name='Name', description='The name of the recording job.'),
      notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify'),
      recordOutput?: {
        bucket?: string(name='Bucket', description='The bucket name.', example='imsbucket1'),
        endpoint?: string(name='Endpoint', description='The endpoint of the storage service.', example='oss-cn-hangzhou.aliyuncs.com'),
        type?: string(name='Type', description='The type of the storage address.

Valid values:

*   vod
*   oss', example='oss'),
      }(name='RecordOutput', description='The storage address of the recording.'),
      status?: string(name='Status', description='The state of the recording job.', example='paused'),
      streamInput?: {
        type?: string(name='Type', description='The type of the live stream URL.', example='rtmp'),
        url?: string(name='Url', description='The URL of the live stream.', example='rtmp://example-live.com/live/stream1'),
      }(name='StreamInput', description='The URL of the live stream.'),
      templateId?: string(name='TemplateId', description='The ID of the recording template.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
      templateName?: string(name='TemplateName', description='The name of the recording template.', example='test template'),
    }
  ](name='LiveRecordJobs', description='The list of live stream recording jobs.'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='20'),
  requestId?: string(name='RequestId', description='The request ID.', example='A27DFFA4-F272-5563-8363-CB0BC42740BA'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='180'),
}

model ListLiveRecordJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveRecordJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream recording jobs by page.
 *
 * @param request ListLiveRecordJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveRecordJobsResponse
 */
async function listLiveRecordJobsWithOptions(request: ListLiveRecordJobsRequest, runtime: Util.RuntimeOptions): ListLiveRecordJobsResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListLiveRecordJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of live stream recording jobs by page.
 *
 * @param request ListLiveRecordJobsRequest
 * @return ListLiveRecordJobsResponse
 */
async function listLiveRecordJobs(request: ListLiveRecordJobsRequest): ListLiveRecordJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listLiveRecordJobsWithOptions(request, runtime);
}

model ListLiveRecordTemplatesRequest {
  keyword?: string(name='Keyword', description='The search keyword. You can use the template ID or name as the keyword to search for templates. If you search for templates by name, fuzzy match is supported.', example='test template'),
  pageNo?: long(name='PageNo', description='The page number. Minimum value: 1. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results in ascending order.
*   desc: sorts the query results in descending order.', example='desc'),
  templateIds?: [ string ](name='TemplateIds'),
  type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
}

model ListLiveRecordTemplatesResponseBody = {
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
  recordTemplateList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T02:48:58Z'),
      lastModified?: string(name='LastModified', description='The time when the template was last modified.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
      name?: string(name='Name', description='The template name.', example='test template'),
      recordFormatList?: [ 
        {
          cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds.', example='21600'),
          format?: string(name='Format', description='The output file format.', example='m3u8'),
          ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording file that is stored in Object Storage Service (OSS).', example='record/{JobId}/{Sequence}_{EscapedStartTime}_{EscapedEndTime}'),
          sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds.', example='30'),
          sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
        }
      ](name='RecordFormatList', description='The list of recording formats.'),
      templateId?: string(name='TemplateId', description='The template ID.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
      type?: string(name='Type', description='The type of the template.', example='custom'),
    }
  ](name='RecordTemplateList', description='The list of recording templates.'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results in ascending order.
*   desc: sorts the query results in descending order.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='5'),
}

model ListLiveRecordTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveRecordTemplatesResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream recording templates.
 *
 * @param request ListLiveRecordTemplatesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveRecordTemplatesResponse
 */
async function listLiveRecordTemplatesWithOptions(request: ListLiveRecordTemplatesRequest, runtime: Util.RuntimeOptions): ListLiveRecordTemplatesResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListLiveRecordTemplates',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of live stream recording templates.
 *
 * @param request ListLiveRecordTemplatesRequest
 * @return ListLiveRecordTemplatesResponse
 */
async function listLiveRecordTemplates(request: ListLiveRecordTemplatesRequest): ListLiveRecordTemplatesResponse {
  var runtime = new Util.RuntimeOptions{};
  return listLiveRecordTemplatesWithOptions(request, runtime);
}

model ListLiveSnapshotFilesRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

*   The maximum time range that can be specified is one day.

This parameter is required.', example='2022-02-02T23:59:59Z'),
  jobId?: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
  limit?: int32(name='Limit', description='The number of results to return each time. Valid values: 1 to 100. Default value: 10.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting order. Default value: asc.

Valid values:

*   asc: sorts the query results by creation time in ascending order.
*   desc: sorts the query results by creation time in descending order.', example='desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

This parameter is required.', example='2022-02-02T00:00:00Z'),
}

model ListLiveSnapshotFilesResponseBody = {
  fileList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-02-02T22:22:22Z'),
      createTimestamp?: long(name='CreateTimestamp', description='The creation timestamp that is used as an input parameter for a delete API operation.', example='1619503516000'),
      isOverlay?: boolean(name='IsOverlay', description='Specifies whether to overlay snapshots.', example='true'),
      ossBucket?: string(name='OssBucket', description='The OSS bucket.', example='testbucket'),
      ossEndpoint?: string(name='OssEndpoint', description='The Object Storage Service (OSS) domain name.', example='oss-cn-shanghai.aliyuncs.com'),
      ossObject?: string(name='OssObject', description='The location in which the OSS object is stored.'),
    }
  ](name='FileList', description='The list of files.'),
  nextStartTime?: string(name='NextStartTime', description='The start time of the next page. If no value is returned, the pagination ends.', example='2022-02-02T22:22:22Z'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListLiveSnapshotFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveSnapshotFilesResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream snapshot files by page.
 *
 * @param request ListLiveSnapshotFilesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveSnapshotFilesResponse
 */
async function listLiveSnapshotFilesWithOptions(request: ListLiveSnapshotFilesRequest, runtime: Util.RuntimeOptions): ListLiveSnapshotFilesResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListLiveSnapshotFiles',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of live stream snapshot files by page.
 *
 * @param request ListLiveSnapshotFilesRequest
 * @return ListLiveSnapshotFilesResponse
 */
async function listLiveSnapshotFiles(request: ListLiveSnapshotFilesRequest): ListLiveSnapshotFilesResponse {
  var runtime = new Util.RuntimeOptions{};
  return listLiveSnapshotFilesWithOptions(request, runtime);
}

model ListLiveSnapshotJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

*   By default, EndTime is seven days later than StartTime.
*   The time range specified by the StartTime and EndTime parameters cannot exceed 30 days.', example='2022-02-02T23:59:59Z'),
  pageNo?: int32(name='PageNo', description='The page number. Valid values: [1,n). Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10'),
  searchKeyWord?: string(name='SearchKeyWord', description='The search keyword. You can use the job ID or name as the keyword to search for jobs. If you search for jobs by name, fuzzy match is supported.

*   It cannot exceed 128 characters in length.', example='****a046-263c-3560-978a-fb287782****'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results by creation time in ascending order.
*   desc: sorts the query results by creation time in descending order.', example='desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

*   The default value is seven days ago.
*   The time range specified by the StartTime and EndTime parameters cannot exceed 30 days.', example='2022-02-02T00:00:00Z'),
  status?: string(name='Status', description='The job state filter. By default, all jobs are queried.

Valid values:

*   init: The job is not started.
*   paused: The job is paused.
*   started: The job is in progress.'),
}

model ListLiveSnapshotJobsResponseBody = {
  jobList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-20T02:48:58Z'),
      jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287782****'),
      jobName?: string(name='JobName', description='The name of the job.'),
      snapshotOutput?: {
        bucket?: string(name='Bucket', description='The bucket of the output endpoint. If the storage type is set to oss, the OSS bucket is returned.', example='testbucket'),
        endpoint?: string(name='Endpoint', description='The output endpoint. If the storage type is set to oss, the Object Storage Service (OSS) domain name is returned.', example='oss-cn-shanghai.aliyuncs.com'),
        storageType?: string(name='StorageType', description='The storage type. The value can only be oss.', example='oss'),
      }(name='SnapshotOutput', description='The output information.'),
      status?: string(name='Status', description='The state of the job.

Valid values:

*   init: The job is not started.
*   paused: The job is paused.
*   started: The job is in progress.', example='started'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287666****'),
      templateName?: string(name='TemplateName', description='The template name.'),
      timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.', example='5'),
    }
  ](name='JobList', description='The list of jobs.'),
  pageNo?: int32(name='PageNo', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the jobs by creation time.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveSnapshotJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveSnapshotJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream snapshot jobs by page.
 *
 * @param request ListLiveSnapshotJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveSnapshotJobsResponse
 */
async function listLiveSnapshotJobsWithOptions(request: ListLiveSnapshotJobsRequest, runtime: Util.RuntimeOptions): ListLiveSnapshotJobsResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListLiveSnapshotJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of live stream snapshot jobs by page.
 *
 * @param request ListLiveSnapshotJobsRequest
 * @return ListLiveSnapshotJobsResponse
 */
async function listLiveSnapshotJobs(request: ListLiveSnapshotJobsRequest): ListLiveSnapshotJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listLiveSnapshotJobsWithOptions(request, runtime);
}

model ListLiveSnapshotTemplatesRequest {
  pageNo?: int32(name='PageNo', description='The page number. Valid values: [1,n). Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10'),
  searchKeyWord?: string(name='SearchKeyWord', description='The search keyword. You can use the template ID or name as the keyword to search for templates. If you search for templates by name, fuzzy match is supported.

*   It cannot exceed 128 characters in length.', example='****a046-263c-3560-978a-fb287782****'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results by creation time in ascending order.
*   desc: sorts the query results by creation time in descending order.', example='desc'),
  templateIds?: [ string ](name='TemplateIds', description='The template IDs.

*   If you specify the SearchKeyWord parameter, this condition does not take effect.
*   The maximum length of the array is 200.'),
  type?: string(name='Type', description='The type of the template. By default, all types are queried.

Valid values:

*   system
*   custom', example='custom'),
}

model ListLiveSnapshotTemplatesResponseBody = {
  pageNo?: int32(name='PageNo', description='The number of the returned page.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the results by creation time.', example='desc'),
  templateList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T02:48:58Z'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287782****'),
      templateName?: string(name='TemplateName', description='The template name.'),
      timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.', example='10'),
      type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
    }
  ](name='TemplateList', description='The list of the templates.'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveSnapshotTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveSnapshotTemplatesResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream snapshot templates by page.
 *
 * @param request ListLiveSnapshotTemplatesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveSnapshotTemplatesResponse
 */
async function listLiveSnapshotTemplatesWithOptions(request: ListLiveSnapshotTemplatesRequest, runtime: Util.RuntimeOptions): ListLiveSnapshotTemplatesResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListLiveSnapshotTemplates',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of live stream snapshot templates by page.
 *
 * @param request ListLiveSnapshotTemplatesRequest
 * @return ListLiveSnapshotTemplatesResponse
 */
async function listLiveSnapshotTemplates(request: ListLiveSnapshotTemplatesRequest): ListLiveSnapshotTemplatesResponse {
  var runtime = new Util.RuntimeOptions{};
  return listLiveSnapshotTemplatesWithOptions(request, runtime);
}

model ListLiveTranscodeJobsRequest {
  keyWord?: string(name='KeyWord', description='The search keyword. You can use the job ID or name as the keyword to search for jobs. If you search for jobs by name, fuzzy match is supported.', example='24ecbb5c-4f98-4194-9400-f17102e27fc5'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='20'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values:

*   asc
*   desc', example='asc'),
  startMode?: int32(name='StartMode', description='The start mode of the transcoding job.

*   0: The transcoding job immediately starts.
*   1: The transcoding job starts at the scheduled time.', example='0'),
  status?: int32(name='Status', description='The state of the job.

0: The job is not started. 1: The job is in progress. 2: The job is stopped.', example='1'),
  type?: string(name='Type', description='The type of the template used by the transcoding job.

*   normal
*   narrow-band
*   audio-only
*   origin', example='normal'),
}

model ListLiveTranscodeJobsResponseBody = {
  jobList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T02:48:58Z'),
      jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287782****'),
      name?: string(name='Name', description='The name of the transcoding job.', example='mytask'),
      outputStream?: {
        streamInfos?: [ 
          {
            outputUrl?: string(name='OutputUrl', description='The URL of the output stream.', example='rtmp://mydomain/app/mytranscode1'),
            type?: string(name='Type', description='The type of the output stream protocol. Only the RTMP protocol is supported.', example='rtmp'),
          }
        ](name='StreamInfos', description='The list of stream URLs.'),
      }(name='OutputStream', description='The information about the output stream.'),
      startMode?: int32(name='StartMode', description='The start mode of the job.', example='0'),
      status?: int32(name='Status', description='The state of the job.', example='1'),
      streamInput?: {
        inputUrl?: string(name='InputUrl', description='The URL of the input stream.', example='rtmp://mydomain/app/stream1'),
        type?: string(name='Type', description='The type of the input stream.', example='rtmp'),
      }(name='StreamInput', description='The information about the input stream.'),
      templateId?: string(name='TemplateId', description='The ID of the transcoding template used by the transcoding job.', example='****a046-263c-3560-978a-fb287666****'),
      templateName?: string(name='TemplateName', description='The template name.'),
      templateType?: string(name='TemplateType', description='The type of the transcoding template used by the transcoding job.', example='normal'),
    }
  ](name='JobList', description='The list of transcoding jobs.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveTranscodeJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveTranscodeJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream transcoding jobs.
 *
 * @param request ListLiveTranscodeJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveTranscodeJobsResponse
 */
async function listLiveTranscodeJobsWithOptions(request: ListLiveTranscodeJobsRequest, runtime: Util.RuntimeOptions): ListLiveTranscodeJobsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.keyWord)) {
    query['KeyWord'] = request.keyWord;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!Util.isUnset(request.startMode)) {
    query['StartMode'] = request.startMode;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListLiveTranscodeJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of live stream transcoding jobs.
 *
 * @param request ListLiveTranscodeJobsRequest
 * @return ListLiveTranscodeJobsResponse
 */
async function listLiveTranscodeJobs(request: ListLiveTranscodeJobsRequest): ListLiveTranscodeJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listLiveTranscodeJobsWithOptions(request, runtime);
}

model ListLiveTranscodeTemplatesRequest {
  category?: string(name='Category', description='The category of the template. Valid values:

*   system
*   customized', example='customized'),
  keyWord?: string(name='KeyWord', description='The search keyword. You can use the template ID or name as the keyword to search for templates. If you search for templates by name, fuzzy match is supported.', example='my_template'),
  pageNo?: int32(name='PageNo', description='The page number of the page to return. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='20'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values:

*   asc
*   desc', example='asc'),
  type?: string(name='Type', description='The type of the template. Valid values:

*   normal
*   narrow-band
*   audio-only
*   origin', example='normal'),
  videoCodec?: string(name='VideoCodec', description='The video codec. Valid values:

*   H.264
*   H.265', example='H.264'),
}

model ListLiveTranscodeTemplatesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  templateContentList?: [ 
    {
      category?: string(name='Category', description='The category of the template. Valid values:', example='system'),
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T03:26:36Z'),
      name?: string(name='Name', description='The template name.', example='my_template'),
      templateConfig?: {
        audioParams?: {
          bitrate?: string(name='Bitrate', description='The audio bitrate.', example='1000'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codec?: string(name='Codec', description='The audio codec.', example='AAC'),
          profile?: string(name='Profile', description='The encoding profile.', example='aac_low'),
          samplerate?: string(name='Samplerate', description='The audio sampling rate.', example='44100'),
        }(name='AudioParams', description='The audio parameters.'),
        videoParams?: {
          bitrate?: string(name='Bitrate', description='The video bitrate.', example='2500'),
          codec?: string(name='Codec', description='The encoding format.', example='264'),
          fps?: string(name='Fps', description='The video frame rate.', example='30'),
          gop?: string(name='Gop', description='The group of pictures (GOP) of the output video. Unit: frame.', example='1000'),
          height?: string(name='Height', description='The vertical resolution of the video.', example='1280'),
          profile?: string(name='Profile', description='The encoding profile.', example='3'),
          width?: string(name='Width', description='The horizontal resolution of the video.', example='720'),
        }(name='VideoParams', description='The video parameters.'),
      }(name='TemplateConfig', description='The configuration of the template.'),
      templateId?: string(name='TemplateId', description='The template ID.', example='9b1571b513cb44f7a1ba6ae561ff46f7'),
      type?: string(name='Type', description='The type of the template.', example='normal'),
    }
  ](name='TemplateContentList', description='The list of transcoding templates.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveTranscodeTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveTranscodeTemplatesResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream transcoding templates.
 *
 * @param request ListLiveTranscodeTemplatesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveTranscodeTemplatesResponse
 */
async function listLiveTranscodeTemplatesWithOptions(request: ListLiveTranscodeTemplatesRequest, runtime: Util.RuntimeOptions): ListLiveTranscodeTemplatesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.category)) {
    query['Category'] = request.category;
  }
  if (!Util.isUnset(request.keyWord)) {
    query['KeyWord'] = request.keyWord;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  if (!Util.isUnset(request.videoCodec)) {
    query['VideoCodec'] = request.videoCodec;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListLiveTranscodeTemplates',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of live stream transcoding templates.
 *
 * @param request ListLiveTranscodeTemplatesRequest
 * @return ListLiveTranscodeTemplatesResponse
 */
async function listLiveTranscodeTemplates(request: ListLiveTranscodeTemplatesRequest): ListLiveTranscodeTemplatesResponse {
  var runtime = new Util.RuntimeOptions{};
  return listLiveTranscodeTemplatesWithOptions(request, runtime);
}

model ListMediaBasicInfosRequest {
  businessType?: string(name='BusinessType', description='The business type of the media asset. Valid values:

\\\\- subtitles

\\\\- watermark

\\\\- opening

\\\\- ending

\\\\- general', example='opening'),
  endTime?: string(name='EndTime', description='The end time of utcCreated.

\\\\- The value is the end of the left-open right-closed interval.

\\\\- Specify the time in the ISO 8601 standard in the YYYY-MM-DDThh:mm:ssZ format. For example, 2017-01-11T12:00:00Z indicates 20:00:00 on January 11, 2017 (UTC +8).', example='2020-12-20T13:00:00Z'),
  includeFileBasicInfo?: boolean(name='IncludeFileBasicInfo', description='Specifies whether to return the basic information of the source file.', example='true'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.

Maximum value: 100. Default value: 10.', example='5'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

\\\\- image

\\\\- video

\\\\- audio

\\\\- text', example='video'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='pSa1SQ0wCe5pzVrQ6mWZEw=='),
  sortBy?: string(name='SortBy', description='The order of sorting by utcCreated. Default value: desc. Valid values:

\\\\- desc

\\\\- asc', example='desc'),
  source?: string(name='Source', description='The source of the media asset. Valid values:

\\\\- oss: Object Storage Service (OSS).

\\\\- vod: ApsaraVideo VOD.

\\\\- live: ApsaraVideo Live.

\\\\- general: other sources. This is the default value.', example='oss'),
  startTime?: string(name='StartTime', description='The start time of utcCreated.

\\\\- The value is the beginning of a left-open right-closed interval.

\\\\- Specify the time in the ISO 8601 standard in the YYYY-MM-DDThh:mm:ssZ format. For example, 2017-01-11T12:00:00Z indicates 20:00:00 on January 11, 2017 (UTC +8).', example='2020-12-20T12:00:00Z'),
  status?: string(name='Status', description='The status of the media asset. Valid values:

\\\\- Init: the initial state, which indicates that the source file is not ready.

\\\\- Preparing: The source file is being prepared. For example, the file is being uploaded or edited.

\\\\- PrepareFail: The source file failed to be prepared. For example, the information of the source file failed to be obtained.

\\\\- Normal: The source file is ready.', example='Normal'),
}

model ListMediaBasicInfosResponseBody = {
  maxResults?: int32(name='MaxResults', description='The maximum number of entries returned in the query.', example='2'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1912.13'),
            createTime?: string(name='CreateTime', description='The time when the file was created.', example='2021-01-08T16:52:04Z'),
            duration?: string(name='Duration', description='The duration.', example='60.00000'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='14340962'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The OSS URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example2.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='720'),
            modifiedTime?: string(name='ModifiedTime', description='The time when the file was last modified.', example='2021-01-08T16:52:07Z'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='1280'),
          }(name='FileBasicInfo', description='The basic information of the file, including the duration and size.'),
        }
      ](name='FileInfoList', description='FileInfos'),
      mediaBasicInfo?: {
        biz?: string(name='Biz', description='The service to which the media asset belongs.', example='ICE'),
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='opening'),
        cateId?: long(name='CateId', description='The category ID.', example='3049'),
        category?: string(name='Category', description='The category of the media asset.'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2021-01-08T16:52:04Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2021-01-08T16:52:07Z'),
        description?: string(name='Description', description='The description of the media asset.'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='tags,tags2'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2021-01-08T16:52:07Z'),
        referenceId?: string(name='ReferenceId', description='The custom ID of the media asset. The ID is a string that contains 6 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are supported. The ID is unique among users.', example='123-123'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='[{"bucket":"example-bucket","count":"3","iceJobId":"******f48f0e4154976b2b8c45******","location":"oss-cn-beijing","snapshotRegular":"example.jpg","templateId":"******e6a6440b29eb60bd7c******"}]'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite.', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        uploadSource?: string(name='UploadSource', description='The upload source of the media asset.', example='general'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='BasicInfo'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******B7-7F87-4792-BFE9-63CD21******'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='4'),
}

model ListMediaBasicInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaBasicInfosResponseBody(name='body'),
}

/**
 * @summary Queries the basic information of all media assets that meet the specified conditions.
 *
 * @description If includeFileBasicInfo is set to true, the basic information, such as the duration and file size, of the source file is also returned. At most the first 100 entries that meet the specified conditions are returned. All media assets must exactly match all non-empty fields. The fields that support exact match include MediaType, Source, BusinessType, Category, and Status. If all information cannot be returned at a time, you can use NextToken to initiate a request to retrieve a new page of results.
 *
 * @param request ListMediaBasicInfosRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListMediaBasicInfosResponse
 */
async function listMediaBasicInfosWithOptions(request: ListMediaBasicInfosRequest, runtime: Util.RuntimeOptions): ListMediaBasicInfosResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.businessType)) {
    query['BusinessType'] = request.businessType;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.includeFileBasicInfo)) {
    query['IncludeFileBasicInfo'] = request.includeFileBasicInfo;
  }
  if (!Util.isUnset(request.maxResults)) {
    query['MaxResults'] = request.maxResults;
  }
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!Util.isUnset(request.nextToken)) {
    query['NextToken'] = request.nextToken;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!Util.isUnset(request.source)) {
    query['Source'] = request.source;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListMediaBasicInfos',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the basic information of all media assets that meet the specified conditions.
 *
 * @description If includeFileBasicInfo is set to true, the basic information, such as the duration and file size, of the source file is also returned. At most the first 100 entries that meet the specified conditions are returned. All media assets must exactly match all non-empty fields. The fields that support exact match include MediaType, Source, BusinessType, Category, and Status. If all information cannot be returned at a time, you can use NextToken to initiate a request to retrieve a new page of results.
 *
 * @param request ListMediaBasicInfosRequest
 * @return ListMediaBasicInfosResponse
 */
async function listMediaBasicInfos(request: ListMediaBasicInfosRequest): ListMediaBasicInfosResponse {
  var runtime = new Util.RuntimeOptions{};
  return listMediaBasicInfosWithOptions(request, runtime);
}

model ListMediaInfoJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-15T00:00:00Z'),
  jobId?: string(name='JobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb11cbe'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='ab4802364a2e49208c99efab82dfa8e8'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

*   CreateTimeDesc: sorts the query results by creation time in descending order.
*   CreateTimeAsc: sorts the query results by creation time in ascending order.', example='CreateTimeDesc'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-01T00:00:00Z'),
  status?: string(name='Status', description='The state of the job. Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
}

model ListMediaInfoJobsResponseBody = {
  jobs?: [ 
    {
      async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      input?: {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
      }(name='Input', description='The input of the job.'),
      jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
      mediaInfoProperty?: {
        audioStreamInfoList?: [ 
          {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
            channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
            channels?: string(name='Channels', description='The number of sound channels.', example='2'),
            codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
            codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
            codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
            codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
            duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
            index?: string(name='Index', description='The sequence number of the stream.', example='1'),
            lang?: string(name='Lang', description='The language of the stream.', example='cn'),
            sampleFmt?: string(name='SampleFmt', description='The sampling format.', example='fltp'),
            sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
            startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
            timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
          }
        ](name='AudioStreamInfoList', description='The information about the audio stream.'),
        fileBasicInfo?: {
          bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
          duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
          fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
          fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
          fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
          fileType?: string(name='FileType', description='The file type. Valid values: source_file and transcode_file.', example='source_file'),
          fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
          formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
          height?: string(name='Height', description='The height.', example='478'),
          mediaId?: string(name='MediaId', description='The ID of the media asset.', example='4765337007f571edbfdf81848c016303'),
          region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
          width?: string(name='Width', description='The width.', example='848'),
        }(name='FileBasicInfo', description='The basic file information.'),
        videoStreamInfoList?: [ 
          {
            avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
            bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
            codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
            codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
            codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
            codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
            codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
            dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
            duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
            fps?: string(name='Fps', description='The frame rate.', example='25.0'),
            hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
            height?: string(name='Height', description='The height.', example='478'),
            index?: string(name='Index', description='The sequence number of the stream.', example='0'),
            lang?: string(name='Lang', description='The language of the stream.', example='cn'),
            level?: string(name='Level', description='The codec level.', example='31'),
            numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
            pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
            profile?: string(name='Profile', description='The encoder profile.', example='High'),
            rotate?: string(name='Rotate', description='The rotation angle of the video image.

*   Valid values: 0, 90, 180, and 270.
*   Default value: 0.', example='0'),
            sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
            startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
            timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
            width?: string(name='Width', description='The width.', example='848'),
          }
        ](name='VideoStreamInfoList', description='The information about the video stream.'),
      }(name='MediaInfoProperty', description='The details of the media information.'),
      name?: string(name='Name', description='The job name.', example='job-name'),
      requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
      scheduleConfig?: {
        pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
        priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
      }(name='ScheduleConfig', description='The scheduling information.'),
      status?: string(name='Status', description='The state of the job. Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Init'),
      submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
      userData?: string(name='UserData', description='The user data.', example='user-data'),
    }
  ](name='Jobs', description='The list of media information analysis jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. The token of the next page is returned after you call this operation for the first time.', example='019daf5780f74831b0e1a767c9f1c178'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model ListMediaInfoJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaInfoJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of media information analysis jobs.
 *
 * @param request ListMediaInfoJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListMediaInfoJobsResponse
 */
async function listMediaInfoJobsWithOptions(request: ListMediaInfoJobsRequest, runtime: Util.RuntimeOptions): ListMediaInfoJobsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.endOfCreateTime)) {
    query['EndOfCreateTime'] = request.endOfCreateTime;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!Util.isUnset(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.startOfCreateTime)) {
    query['StartOfCreateTime'] = request.startOfCreateTime;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListMediaInfoJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of media information analysis jobs.
 *
 * @param request ListMediaInfoJobsRequest
 * @return ListMediaInfoJobsResponse
 */
async function listMediaInfoJobs(request: ListMediaInfoJobsRequest): ListMediaInfoJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listMediaInfoJobsWithOptions(request, runtime);
}

model ListMediaMarksRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The mark ID. You can specify multiple IDs separated with commas (,). This parameter is discontinued.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
}

model ListMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  mediaMarks?: string(name='MediaMarks', description='The marks of the media asset, in the JSONArray format.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaMarksResponseBody(name='body'),
}

/**
 * @summary Queries a list of marks of a media asset.
 *
 * @param request ListMediaMarksRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListMediaMarksResponse
 */
async function listMediaMarksWithOptions(request: ListMediaMarksRequest, runtime: Util.RuntimeOptions): ListMediaMarksResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.mediaMarkIds)) {
    query['MediaMarkIds'] = request.mediaMarkIds;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListMediaMarks',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of marks of a media asset.
 *
 * @param request ListMediaMarksRequest
 * @return ListMediaMarksResponse
 */
async function listMediaMarks(request: ListMediaMarksRequest): ListMediaMarksResponse {
  var runtime = new Util.RuntimeOptions{};
  return listMediaMarksWithOptions(request, runtime);
}

model ListMediaProducingJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. The maximum time range between EndTime and StartTime cannot exceed 30 days. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-02-02T23:59:59Z'),
  jobType?: string(name='JobType', description='The job type.

Valid values:

*   LiveEditingJob: live editing job.
*   EditingJob: regular template-based editing job
*   VETemplateJob: advanced template-based editing job.', example='EditingJob'),
  keyword?: string(name='Keyword', description='The search keyword. For example, you can use a job ID as the keyword to search for jobs.', example='****20b48fb04483915d4f2cd8ac****'),
  masterJobId?: string(name='MasterJobId', description='The ID of the quick video production job. If this parameter is specified, the subjobs of the quick video production job are queried.', example='******8750b54e3c976a47da6f******'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.

Default value: 10. Valid values: 1 to 100.', example='100'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='******927cfb53d05b96c1bfe1******'),
  sortBy?: string(name='SortBy', description='The sorting parameter. By default, the query results are sorted by creation time in descending order.

Valid values:

*   CreationTime:Asc: sorted by creation time in ascending order.
*   CreationTime:Desc: sorted by creation time in descending order.', example='CreationTime:Desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-01-11T12:00:00Z'),
  status?: string(name='Status', description='The job state.

Valid values:

*   Init: The job is initialized.
*   Failed: The job failed.
*   Success: The job is successful.
*   Processing: The job is in progress.', example='Success'),
}

model ListMediaProducingJobsResponseBody = {
  maxResults?: string(name='MaxResults', description='The maximum number of entries returned.

Default value: 10. Valid values: 1 to 100.', example='100'),
  mediaProducingJobList?: [ 
    {
      clipsParam?: string(name='ClipsParam', description='The template material parameters.', example='{"Text1":"text","Text0":"text","Media1":"mediaId","Media0":"mediaId"}'),
      code?: string(name='Code', description='The response code.', example='Success'),
      completeTime?: string(name='CompleteTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-03-21T16:40:30Z'),
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-03-21T16:40:00Z'),
      duration?: float(name='Duration', description='The duration of the output file. Unit: seconds.', example='15.5'),
      jobId?: string(name='JobId', description='The ID of the online editing job.', example='******8750b54e3c976a47da6f******'),
      mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='0ce4ea70f52471edab61f7e7d6786302'),
      mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://your-bucket.oss-cn-shanghai.aliyuncs.com/your-video.mp4'),
      message?: string(name='Message', description='The returned message. Note: Pay attention to this parameter if the job failed.', example='The resource operated InputFile is bad'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-03-21T16:41:00Z'),
      projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='******faa3b542f5a6135217e3******'),
      status?: string(name='Status', description='The job state.', example='Sucess'),
      templateId?: string(name='TemplateId', description='The ID of the online editing template.', example='cb786a39c5d44cecb23d8c864facffc1'),
      userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"key":"value"}'),
    }
  ](name='MediaProducingJobList', description='The queried media editing and production jobs.'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListMediaProducingJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaProducingJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of media editing and production jobs that meet the specified conditions. You can query the jobs based on the job state and type.
 *
 * @param request ListMediaProducingJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListMediaProducingJobsResponse
 */
async function listMediaProducingJobsWithOptions(request: ListMediaProducingJobsRequest, runtime: Util.RuntimeOptions): ListMediaProducingJobsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.jobType)) {
    query['JobType'] = request.jobType;
  }
  if (!Util.isUnset(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!Util.isUnset(request.masterJobId)) {
    query['MasterJobId'] = request.masterJobId;
  }
  if (!Util.isUnset(request.maxResults)) {
    query['MaxResults'] = request.maxResults;
  }
  if (!Util.isUnset(request.nextToken)) {
    query['NextToken'] = request.nextToken;
  }
  if (!Util.isUnset(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListMediaProducingJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of media editing and production jobs that meet the specified conditions. You can query the jobs based on the job state and type.
 *
 * @param request ListMediaProducingJobsRequest
 * @return ListMediaProducingJobsResponse
 */
async function listMediaProducingJobs(request: ListMediaProducingJobsRequest): ListMediaProducingJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listMediaProducingJobsWithOptions(request, runtime);
}

model ListPackageJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-15T00:00:00Z'),
  jobId?: string(name='JobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb11cbe'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='ab4802364a2e49208c99efab82dfa8e8'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

*   CreateTimeDesc: sorts the jobs by creation time in descending order.
*   CreateTimeAsc: sorts the jobs by creation time in ascending order.', example='CreateTimeDesc'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 0 to 100. Default value: 20.', example='10'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-01T00:00:00Z'),
  status?: string(name='Status', description='The state of the job.

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
}

model ListPackageJobsResponseBody = {
  packageJobList?: {
    nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. The token of the next page is returned after you call this operation for the first time.', example='019daf5780f74831b0e1a767c9f1c178'),
    packageJobs?: [ 
      {
        code?: string(name='Code', description='The error code returned if the job fails.', example='InvalidParameter'),
        createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T14:00:32Z'),
        finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T15:00:32Z'),
        inputs?: [ 
          {
            input?: {
              media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
              type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
            }(name='Input', description='The information about the input stream file.'),
          }
        ](name='Inputs', description='The input of the job.'),
        jobId?: string(name='JobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb11cbe'),
        message?: string(name='Message', description='The error message that is returned.', example='Resource content bad.'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T15:00:32Z'),
        name?: string(name='Name', description='The name of the job.', example='job-name'),
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output of the job.'),
        pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='5b40833e4c3e4d4e95a866abb9a42510'),
        priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority. Default value: 6.', example='6'),
        status?: string(name='Status', description='The state of the job.', example='Success'),
        submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T14:00:32Z'),
        triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
        userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}'),
      }
    ](name='PackageJobs', description='The list of packaging jobs.'),
  }(name='PackageJobList', description='The list of packaging jobs.'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model ListPackageJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPackageJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of packaging jobs.
 *
 * @param request ListPackageJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListPackageJobsResponse
 */
async function listPackageJobsWithOptions(request: ListPackageJobsRequest, runtime: Util.RuntimeOptions): ListPackageJobsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.endOfCreateTime)) {
    query['EndOfCreateTime'] = request.endOfCreateTime;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!Util.isUnset(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.startOfCreateTime)) {
    query['StartOfCreateTime'] = request.startOfCreateTime;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListPackageJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of packaging jobs.
 *
 * @param request ListPackageJobsRequest
 * @return ListPackageJobsResponse
 */
async function listPackageJobs(request: ListPackageJobsRequest): ListPackageJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listPackageJobsWithOptions(request, runtime);
}

model ListPipelinesRequest {
  speed?: string(name='Speed', description='The type of the MPS queue.

Valid values:

*   Boost: MPS queue with transcoding speed boosted.
*   Standard: standard MPS queue.
*   NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.', example='Standard'),
}

model ListPipelinesResponseBody = {
  pipelineList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
      name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.', example='****20b48fb04483915d4f2cd8ac****'),
      priority?: int32(name='Priority', description='The priority of the MPS queue.', example='6'),
      speed?: string(name='Speed', description='The type of the MPS queue.', example='Standard'),
      status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Active'),
    }
  ](name='PipelineList', description='The queried MPS queues.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListPipelinesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPipelinesResponseBody(name='body'),
}

/**
 * @summary Queries a list of ApsaraVideo Media Processing (MPS) queues.
 *
 * @param request ListPipelinesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListPipelinesResponse
 */
async function listPipelinesWithOptions(request: ListPipelinesRequest, runtime: Util.RuntimeOptions): ListPipelinesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.speed)) {
    query['Speed'] = request.speed;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListPipelines',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of ApsaraVideo Media Processing (MPS) queues.
 *
 * @param request ListPipelinesRequest
 * @return ListPipelinesResponse
 */
async function listPipelines(request: ListPipelinesRequest): ListPipelinesResponse {
  var runtime = new Util.RuntimeOptions{};
  return listPipelinesWithOptions(request, runtime);
}

model ListPublicMediaBasicInfosRequest {
  businessType?: string(name='BusinessType', description='The business type of the media asset. Valid values:

*   sticker
*   bgm
*   bgi', example='sticker'),
  includeFileBasicInfo?: boolean(name='IncludeFileBasicInfo', description='Specifies whether to return the basic information of the media asset.', example='true'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.

Maximum value: 100. Default value: 10.', example='5'),
  mediaTagId?: string(name='MediaTagId', description='The media tag. All media assets that contain the specified media tag are returned. Valid values:

*   Sticker tags:

    *   sticker-atmosphere
    *   sticker-bubble
    *   sticker-cute
    *   sticker-daily
    *   sticker-expression
    *   sticker-gif

*   Background music (BGM) tags:

    *   bgm-romantic
    *   bgm-cuisine
    *   bgm-chinese-style
    *   bgm-upbeat
    *   bgm-dynamic
    *   bgm-relaxing
    *   bgm-quirky
    *   bgm-beauty

*   Background image (BGI) tags:

    *   bgi-grad
    *   bgi-solid
    *   bgi-pic', example='ticker-atmosphere'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='pSa1SQ0wCe5pzVrQ6mWZEw=='),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10'),
}

model ListPublicMediaBasicInfosResponseBody = {
  maxResults?: int32(name='MaxResults', description='The maximum number of entries returned.', example='2'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='270112.12'),
            duration?: string(name='Duration', description='The duration.', example='10.040000'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='338990717'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='1080'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='1920'),
          }(name='FileBasicInfo', description='The basic information of the file, such as the duration and size.'),
        }
      ](name='FileInfoList', description='The file information of the media asset.'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.', example='video'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2021-01-08T16:52:04Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2021-01-08T16:52:04Z'),
        description?: string(name='Description', description='The description of the media asset.', example='description'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='sticker-daily'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2021-01-08T16:52:04Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='null'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information of the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******B7-7F87-4792-BFE9-63CD21******'),
  totalCount?: long(name='TotalCount', description='The total number of media assets that meet the specified conditions.', example='2'),
}

model ListPublicMediaBasicInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPublicMediaBasicInfosResponseBody(name='body'),
}

/**
 * @summary Queries a list of media assets in the public media library that meet the specified conditions. A maximum of 100 media assets can be returned.
 *
 * @param request ListPublicMediaBasicInfosRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListPublicMediaBasicInfosResponse
 */
async function listPublicMediaBasicInfosWithOptions(request: ListPublicMediaBasicInfosRequest, runtime: Util.RuntimeOptions): ListPublicMediaBasicInfosResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.businessType)) {
    query['BusinessType'] = request.businessType;
  }
  if (!Util.isUnset(request.includeFileBasicInfo)) {
    query['IncludeFileBasicInfo'] = request.includeFileBasicInfo;
  }
  if (!Util.isUnset(request.maxResults)) {
    query['MaxResults'] = request.maxResults;
  }
  if (!Util.isUnset(request.mediaTagId)) {
    query['MediaTagId'] = request.mediaTagId;
  }
  if (!Util.isUnset(request.nextToken)) {
    query['NextToken'] = request.nextToken;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListPublicMediaBasicInfos',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'Anonymous',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of media assets in the public media library that meet the specified conditions. A maximum of 100 media assets can be returned.
 *
 * @param request ListPublicMediaBasicInfosRequest
 * @return ListPublicMediaBasicInfosResponse
 */
async function listPublicMediaBasicInfos(request: ListPublicMediaBasicInfosRequest): ListPublicMediaBasicInfosResponse {
  var runtime = new Util.RuntimeOptions{};
  return listPublicMediaBasicInfosWithOptions(request, runtime);
}

model ListSearchLibRequest {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10'),
}

model ListSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  searchLibInfoList?: [ 
    {
      indexInfo?: [ 
        {
          indexReadiness?: string(name='IndexReadiness'),
          indexStatus?: string(name='IndexStatus'),
          indexType?: string(name='IndexType'),
        }
      ](name='IndexInfo'),
      searchLibName?: string(name='SearchLibName', description='The search library.', example='faceSearchLib'),
      status?: string(name='Status', description='The status of the search library.

*   normal
*   deleting
*   deleteFail', example='normal'),
    }
  ](name='SearchLibInfoList', description='Information about search libraries.'),
  success?: string(name='Success', description='Indicates whether the request was successful.', example='true'),
  total?: long(name='Total', description='总数。', example='8'),
}

model ListSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSearchLibResponseBody(name='body'),
}

/**
 * @summary Queries the information about search libraries.
 *
 * @param request ListSearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSearchLibResponse
 */
async function listSearchLibWithOptions(request: ListSearchLibRequest, runtime: Util.RuntimeOptions): ListSearchLibResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListSearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about search libraries.
 *
 * @param request ListSearchLibRequest
 * @return ListSearchLibResponse
 */
async function listSearchLib(request: ListSearchLibRequest): ListSearchLibResponse {
  var runtime = new Util.RuntimeOptions{};
  return listSearchLibWithOptions(request, runtime);
}

model ListSmartJobsRequest {
  jobState?: string(name='JobState', description='The job state.

Valid values:

*   Finished: The job is complete.
*   Failed: The job failed.
*   Executing: The job is in progress.
*   Created: The job is created.', example='Finished'),
  jobType?: string(name='JobType', description='The job type.

Valid values:

*   ASR: automatic speech recognition(job) job.
*   DynamicChart: dynamic chart job.
*   VideoTranslation: video translation job.
*   TextToSpeech: intelligent audio production job.', example='ASR'),
  maxResults?: long(name='MaxResults', description='The maximum number of entries to return.

Default value: 10. Valid values: 1 to 100.', example='10'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****73f33c91-d59383e8280b****'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting parameter. By default, the query results are sorted by creation time in descending order.

Valid values:

*   CreationTime:Asc: sorted by creation time in ascending order.
*   CreationTime:Desc: sorted by creation time in descending order.', example='CreationTime:Desc'),
}

model ListSmartJobsResponseBody = {
  maxResults?: string(name='MaxResults', description='The maximum number of entries returned on a single page. The value is set to the maximum number of entries returned on each page except for the last page. Valid example: 10,10,5. Invalid example: 10,5,10.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='CBB6BC61D08'),
  requestId?: string(name='RequestId', description='The request ID.', example='****9262E3DA-07FA-4862-FCBB6BC61D08*****'),
  smartJobList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2020-12-26T04:11:10Z'),
      description?: string(name='Description', description='The job description.', example='测试描述'),
      editingConfig?: string(name='EditingConfig', description='The editing configurations.', example='{"AudioConfig":{},"InputConfig":""}'),
      inputConfig?: {
        inputFile?: string(name='InputFile', description='The information about the input file.', example='oss://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        keyword?: string(name='Keyword', description='The keyword information.', example='测试关键词'),
      }(name='InputConfig', description='The input configurations.'),
      jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
      jobState?: string(name='JobState', description='The job state.

Valid values:

*   Finished: The job is complete.
*   Failed: The job failed.
*   Executing: The job is in progress.
*   Created: The job is created.', example='Finished'),
      jobType?: string(name='JobType', description='The job type.

Valid values:

*   ASR: ASR job.
*   DynamicChart: dynamic chart job.
*   TextToSpeech: intelligent audio production job.', example='ASR'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2020-12-26T04:11:10Z'),
      outputConfig?: {
        bucket?: string(name='Bucket', description='The Object Storage Service (OSS) bucket.', example='test-bucket'),
        object?: string(name='Object', description='The OSS object.', example='test-object'),
      }(name='OutputConfig', description='The output configurations.'),
      title?: string(name='Title', description='The job title.', example='测试标题'),
      userData?: string(name='UserData', description='The user-defined data.', example='{"user":"data"}'),
      userId?: long(name='UserId', description='The user ID.', example='1084506228******'),
    }
  ](name='SmartJobList', description='The queried intelligent jobs.'),
  totalCount?: string(name='TotalCount', description='Optional. The total number of entries returned. By default, this parameter is not returned.', example='110'),
}

model ListSmartJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSmartJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of intelligent jobs based on specified parameters.
 *
 * @param request ListSmartJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSmartJobsResponse
 */
async function listSmartJobsWithOptions(request: ListSmartJobsRequest, runtime: Util.RuntimeOptions): ListSmartJobsResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListSmartJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of intelligent jobs based on specified parameters.
 *
 * @param request ListSmartJobsRequest
 * @return ListSmartJobsResponse
 */
async function listSmartJobs(request: ListSmartJobsRequest): ListSmartJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listSmartJobsWithOptions(request, runtime);
}

model ListSmartSysAvatarModelsRequest {
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10'),
  sdkVersion?: string(name='SdkVersion'),
}

model ListSmartSysAvatarModelsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  smartSysAvatarModelList?: [ 
    {
      avatarId?: string(name='AvatarId', description='The ID of the digital human. The ID is required to submit a separate digital human rendering job or use the digital human image in an intelligent timeline.', example='yunqiao'),
      avatarName?: string(name='AvatarName', description='The name of the digital human.'),
      bitrate?: int32(name='Bitrate', description='The video bitrate.', example='4000'),
      coverUrl?: string(name='CoverUrl', description='The sample thumbnail URL of the digital human.', example='http://ice-pub-media.myalicdn.com/smart/avatarModel/coverDemo/yunqiao.mp4'),
      height?: int32(name='Height', description='The video height.', example='1920'),
      outputMask?: boolean(name='OutputMask', description='Indicates whether portrait mask rendering is supported.', example='false'),
      videoUrl?: string(name='VideoUrl', description='The sample video URL of the digital human.', example='http://ice-pub-media.myalicdn.com/smart/avatarModel/videoDemo/yunqiao.mp4'),
      width?: int32(name='Width', description='The video width.', example='1080'),
    }
  ](name='SmartSysAvatarModelList', description='The queried digital humans.'),
  totalCount?: int32(name='TotalCount', description='The total number of system digital human images returned.', example='4'),
}

model ListSmartSysAvatarModelsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSmartSysAvatarModelsResponseBody(name='body'),
}

/**
 * @summary Queries a list of system digital humans. This operation supports paged queries.
 *
 * @param request ListSmartSysAvatarModelsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSmartSysAvatarModelsResponse
 */
async function listSmartSysAvatarModelsWithOptions(request: ListSmartSysAvatarModelsRequest, runtime: Util.RuntimeOptions): ListSmartSysAvatarModelsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.sdkVersion)) {
    query['SdkVersion'] = request.sdkVersion;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListSmartSysAvatarModels',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of system digital humans. This operation supports paged queries.
 *
 * @param request ListSmartSysAvatarModelsRequest
 * @return ListSmartSysAvatarModelsResponse
 */
async function listSmartSysAvatarModels(request: ListSmartSysAvatarModelsRequest): ListSmartSysAvatarModelsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listSmartSysAvatarModelsWithOptions(request, runtime);
}

model ListSmartVoiceGroupsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='627B30EB-1D0A-5C6D-8467-431626E0FA10'),
  voiceGroups?: [ 
    {
      type?: string(name='Type', description='The name of the speaker group.'),
      voiceList?: [ 
        {
          desc?: string(name='Desc', description='The speaker description.'),
          name?: string(name='Name', description='The speaker name.'),
          remark?: string(name='Remark', description='The remarks of the speaker.'),
          supportSampleRate?: string(name='SupportSampleRate'),
          tag?: string(name='Tag', description='The tag of the speaker type.'),
          voice?: string(name='Voice', description='The speaker ID.', example='zhitian'),
          voiceType?: string(name='VoiceType', description='The speaker type.

Valid values:

*   Male
*   Female
*   Boy
*   Girl', example='Female'),
          voiceUrl?: string(name='VoiceUrl', description='The URL of the sample audio file.', example='https://***.com/zhiqing.mp3'),
        }
      ](name='VoiceList', description='The speakers.'),
    }
  ](name='VoiceGroups', description='The queried speaker groups.'),
}

model ListSmartVoiceGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSmartVoiceGroupsResponseBody(name='body'),
}

/**
 * @summary Queries a list of speaker groups, including the name, gender, and sample audio of each speaker. The list is grouped by scenario.
 *
 * @param request ListSmartVoiceGroupsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSmartVoiceGroupsResponse
 */
async function listSmartVoiceGroupsWithOptions(runtime: Util.RuntimeOptions): ListSmartVoiceGroupsResponse {
  var req = new OpenApi.OpenApiRequest{};
  var params = new OpenApi.Params{
    action = 'ListSmartVoiceGroups',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of speaker groups, including the name, gender, and sample audio of each speaker. The list is grouped by scenario.
 *
 * @return ListSmartVoiceGroupsResponse
 */
async function listSmartVoiceGroups(): ListSmartVoiceGroupsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listSmartVoiceGroupsWithOptions(runtime);
}

model ListSnapshotJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created.', example='2022-07-14T00:00:00Z'),
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****20b48fb04483915d4f2cd8ac****'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results.

1.  CreateTimeDesc
2.  CreateTimeAsc

Valid values:

*   CreateTimeDesc: sorts the jobs by creation time in descending order
*   CreateTimeAsc: sorts the jobs by creation time in ascending order.', example='CreateTimeDesc'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Maximum value: 100.', example='20'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created.', example='2022-07-12T00:00:00Z'),
  status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
}

model ListSnapshotJobsResponseBody = {
  jobs?: [ 
    {
      async?: boolean(name='Async', description='Indicates whether the snapshots were captured in asynchronous mode.', example='true'),
      count?: int32(name='Count', description='The number of snapshots.', example='10'),
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
      input?: {
        media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats: 1. OSS://bucket/object 2. http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://bucket/object.mp4'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
      }(name='Input', description='The input of the job.'),
      jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
      name?: string(name='Name', description='The name of the job.', example='SampleJob'),
      output?: {
        media?: string(name='Media', description='The output file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS. If multiple static snapshots were captured, the object must contain the "{Count}" placeholder. In the case of a sprite, the object must contain the "{TileCount}" placeholder. The suffix of the WebVTT snapshot objects must be ".vtt".', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/output-{Count}.jpg'),
        type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.', example='OSS'),
      }(name='Output', description='The output of the job.'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****20b48fb04483915d4f2cd8ac****'),
      status?: string(name='Status', description='The state of the job.

*   **Success**: The job is successful.
*   **Fail**: The job failed.
*   **Init**: The job is submitted.', example='Success'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
      triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
      type?: string(name='Type', description='The type of the job.

Valid values:

*   WebVtt
*   Sprite
*   Normal', example='Sprite'),
    }
  ](name='Jobs', description='The list of jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListSnapshotJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSnapshotJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of snapshot jobs.
 *
 * @param request ListSnapshotJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSnapshotJobsResponse
 */
async function listSnapshotJobsWithOptions(request: ListSnapshotJobsRequest, runtime: Util.RuntimeOptions): ListSnapshotJobsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.endOfCreateTime)) {
    query['EndOfCreateTime'] = request.endOfCreateTime;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!Util.isUnset(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.startOfCreateTime)) {
    query['StartOfCreateTime'] = request.startOfCreateTime;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListSnapshotJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of snapshot jobs.
 *
 * @param request ListSnapshotJobsRequest
 * @return ListSnapshotJobsResponse
 */
async function listSnapshotJobs(request: ListSnapshotJobsRequest): ListSnapshotJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listSnapshotJobsWithOptions(request, runtime);
}

model ListSystemTemplatesRequest {
  name?: string(name='Name', description='The template name.', example='SampleTemplate'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20 Valid values: 1 to 100.', example='20'),
  status?: string(name='Status', description='The template state. Valid values: Normal, Invisible, and All.', example='Normal'),
  subtype?: string(name='Subtype', description='The subtype ID of the template.', example='1'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
  type?: string(name='Type', description='The template type. Separate multiple types with commas (,).

This parameter is required.', example='1,2'),
}

model ListSystemTemplatesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  systemTemplateList?: [ 
    {
      status?: string(name='Status', description='The template state.', example='Normal'),
      subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='1'),
      subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='Remux'),
      templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Container":{"Format":"flv"},"Video":{},"Audio":{}}'),
      templateId?: string(name='TemplateId', description='The template ID.', example='S00000001-000000'),
      templateName?: string(name='TemplateName', description='The template name.', example='FLV-COPY'),
      type?: int32(name='Type', description='The type ID of the template.', example='1'),
      typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
    }
  ](name='SystemTemplateList', description='The queried templates.'),
  total?: int32(name='Total', description='The total number of templates.', example='20'),
}

model ListSystemTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSystemTemplatesResponseBody(name='body'),
}

/**
 * @summary Queries a list of system templates.
 *
 * @description Template types:
 * 1.  1: transcoding template.
 * 2.  2: snapshot template.
 * 3.  3: animated image template.
 * 4.  4\\. image watermark template.
 * 5.  5: text watermark template.
 * 6.  6: subtitle template.
 * 7.  7: AI-assisted content moderation template.
 * 8.  8: AI-assisted intelligent thumbnail template.
 * 9.  9: AI-assisted intelligent erasure template.
 * Subtypes of transcoding templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (AudioTranscode): audio transcoding template.
 * 3.  3 (Remux): container format conversion template.
 * 4.  4 (NarrowBandV1): Narrowband HD 1.0 template.
 * 5.  5 (NarrowBandV2): Narrowband HD 2.0 template.
 * Subtypes of snapshot templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (Sprite): sprite template.
 * 3.  3 (WebVtt): WebVTT template.
 * Subtypes of AI-assisted content moderation templates:
 * 1.  1 (Video): video moderation template.
 * 2.  2 (Audio): audio moderation template.
 * 3.  3 (Image): image moderation template.
 * Subtypes of AI-assisted intelligent erasure templates:
 * 1.  1 (VideoDelogo): logo erasure template.
 * 2.  2 (VideoDetext): subtitle erasure template.
 *
 * @param request ListSystemTemplatesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSystemTemplatesResponse
 */
async function listSystemTemplatesWithOptions(request: ListSystemTemplatesRequest, runtime: Util.RuntimeOptions): ListSystemTemplatesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  if (!Util.isUnset(request.subtype)) {
    query['Subtype'] = request.subtype;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListSystemTemplates',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of system templates.
 *
 * @description Template types:
 * 1.  1: transcoding template.
 * 2.  2: snapshot template.
 * 3.  3: animated image template.
 * 4.  4\\. image watermark template.
 * 5.  5: text watermark template.
 * 6.  6: subtitle template.
 * 7.  7: AI-assisted content moderation template.
 * 8.  8: AI-assisted intelligent thumbnail template.
 * 9.  9: AI-assisted intelligent erasure template.
 * Subtypes of transcoding templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (AudioTranscode): audio transcoding template.
 * 3.  3 (Remux): container format conversion template.
 * 4.  4 (NarrowBandV1): Narrowband HD 1.0 template.
 * 5.  5 (NarrowBandV2): Narrowband HD 2.0 template.
 * Subtypes of snapshot templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (Sprite): sprite template.
 * 3.  3 (WebVtt): WebVTT template.
 * Subtypes of AI-assisted content moderation templates:
 * 1.  1 (Video): video moderation template.
 * 2.  2 (Audio): audio moderation template.
 * 3.  3 (Image): image moderation template.
 * Subtypes of AI-assisted intelligent erasure templates:
 * 1.  1 (VideoDelogo): logo erasure template.
 * 2.  2 (VideoDetext): subtitle erasure template.
 *
 * @param request ListSystemTemplatesRequest
 * @return ListSystemTemplatesResponse
 */
async function listSystemTemplates(request: ListSystemTemplatesRequest): ListSystemTemplatesResponse {
  var runtime = new Util.RuntimeOptions{};
  return listSystemTemplatesWithOptions(request, runtime);
}

model ListTemplatesRequest {
  createSource?: string(name='CreateSource', description='The source from which the template was created.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
  keyword?: string(name='Keyword', description='The search keyword. You can use the template ID or title as the keyword to search for templates.', example='****20b48fb04483915d4f2cd8ac****'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='20'),
  sortType?: string(name='SortType', description='The sorting parameter. By default, the query results are sorted by creation time in descending order.

Valid values:

*   CreationTime:Asc: sorted by creation time in ascending order.
*   CreationTime:Desc: sorted by creation time in descending order.', example='CreationTime:Desc'),
  status?: string(name='Status', description='The template state.

Valid values:

*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.
*   Available: The template is available.
*   Uploading: The video is being uploaded.
*   Created: The template is created but not ready for use.
*   Processing: The advanced template is being processed.', example='Available'),
  type?: string(name='Type', description='The template type.

Valid values:

*   Timeline
*   VETemplate', example='Timeline'),
}

model ListTemplatesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  templates?: [ 
    {
      clipsParam?: string(name='ClipsParam', description='The clip parameters.', example='{"Media1":"mediaId","Text1":"text"}'),
      config?: string(name='Config', description='The template configurations.', example='参考Timeline模板配置详解'),
      coverURL?: string(name='CoverURL', description='The thumbnail URL.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
      createSource?: string(name='CreateSource', description='The source from which the template was created.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
      creationTime?: string(name='CreationTime', description='The time when the template was created.', example='2020-12-26T04:11:10Z'),
      modifiedSource?: string(name='ModifiedSource', description='The source from which the template was modified.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2020-12-26T04:11:10Z'),
      name?: string(name='Name', description='The template name.', example='视频添加水印模板'),
      previewMedia?: string(name='PreviewMedia', description='The preview media asset.', example='****20b48fb04483915d4f2cd8ac****'),
      previewMediaStatus?: string(name='PreviewMediaStatus', description='The state of the preview media asset.

Valid values:

*   PrepareFail
*   Init
*   Normal
*   Preparing', example='Normal'),
      status?: string(name='Status', description='The template state.

Valid values:

*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.
*   Available: The template is available.
*   Uploading: The video is being uploaded.
*   Created: The template is created but not ready for use.
*   Processing: The advanced template is being processed.', example='Available'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
      type?: string(name='Type', description='The template type.

Valid values:

*   Timeline: regular template.
*   VETemplate: advanced template.', example='Timeline'),
    }
  ](name='Templates', description='The queried templates.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTemplatesResponseBody(name='body'),
}

/**
 * @summary Queries a list of templates that meet the specified conditions. You can query templates based on information such as the template status and creation source.
 *
 * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
 * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request ListTemplatesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListTemplatesResponse
 */
async function listTemplatesWithOptions(request: ListTemplatesRequest, runtime: Util.RuntimeOptions): ListTemplatesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.createSource)) {
    query['CreateSource'] = request.createSource;
  }
  if (!Util.isUnset(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.sortType)) {
    query['SortType'] = request.sortType;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListTemplates',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of templates that meet the specified conditions. You can query templates based on information such as the template status and creation source.
 *
 * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
 * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request ListTemplatesRequest
 * @return ListTemplatesResponse
 */
async function listTemplates(request: ListTemplatesRequest): ListTemplatesResponse {
  var runtime = new Util.RuntimeOptions{};
  return listTemplatesWithOptions(request, runtime);
}

model ListTranscodeJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-15T00:00:00Z'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='ab4802364a2e49208c99efab82dfa8e8'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

*   CreateTimeDesc: sorts the query results by creation time in descending order.
*   CreateTimeAsc: sorts the query results by creation time in ascending order.', example='CreateTimeDesc'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 0 to 100. Default value: 20.', example='10'),
  parentJobId?: string(name='ParentJobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb1****'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-01T00:00:00Z'),
  status?: string(name='Status', description='The state of the job.

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
}

model ListTranscodeJobsResponseBody = {
  jobs?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      inputGroup?: [ 
        {
          inputUrl?: string(name='InputUrl', description='The URL of the media asset. This parameter is specified only when the media asset is transcoded.', example='oss://bucket/path/to/video.mp4'),
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
        }
      ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
      jobCount?: int32(name='JobCount', description='The number of subjobs.', example='1'),
      name?: string(name='Name', description='The job name.', example='transcode-job'),
      outputGroup?: [ 
        {
          output?: {
            media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
            outputUrl?: string(name='OutputUrl', description='The URL of the transcoded output stream. This parameter is required only when the output is a media asset.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
            type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
          }(name='Output', description='The output file configuration.'),
          processConfig?: {
            combineConfigs?: [ 
              {
                audioIndex?: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
                duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
                start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
                videoIndex?: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
              }
            ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
            encryption?: {
              cipherText?: string(name='CipherText', description='The ciphertext of HTTP Live Streaming (HLS) encryption.', example='MTYi00NDU0LTg5O****'),
              decryptKeyUri?: string(name='DecryptKeyUri', description='The endpoint of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
              encryptType?: string(name='EncryptType', description='The encryption type.', example='PrivateEncryption'),
            }(name='Encryption', description='The encryption settings.'),
            imageWatermarks?: [ 
              {
                overwriteParams?: {
                  dx?: string(name='Dx', description='The position of the watermark on the x-axis.', example='10'),
                  dy?: string(name='Dy', description='The position of the watermark on the y-axis.', example='10'),
                  file?: {
                    media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                    type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                  }(name='File', description='The watermark image file.'),
                  height?: string(name='Height', description='The height of the output video.', example='32'),
                  referPos?: string(name='ReferPos', description='The reference position of the watermark. Valid values: TopLeft, TopRight, BottomLeft, and BottomRight. Default value: TopLeft.', example='TopLeft'),
                  timeline?: {
                    duration?: string(name='Duration', description='The duration of the stream. Valid values: the number of seconds or "ToEND".', example='ToEND'),
                    start?: string(name='Start', description='The beginning of the time range for which data was queried.', example='00:00:05'),
                  }(name='Timeline', description='The timeline settings.'),
                  width?: string(name='Width', description='The width of the output video.', example='32'),
                }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
                templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
              }
            ](name='ImageWatermarks', description='The watermark configuration for an image.'),
            isInheritTags?: boolean(name='IsInheritTags', description='Indicates whether the tags of the input stream are inherited in the output stream. This parameter does not take effect when the input is not a media asset. Default value: false.'),
            subtitles?: [ 
              {
                overwriteParams?: {
                  charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                  file?: {
                    media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                    type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                  }(name='File', description='The subtitle file.'),
                  format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
                }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
                templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
              }
            ](name='Subtitles', description='The subtitle configuration.'),
            textWatermarks?: [ 
              {
                overwriteParams?: {
                  adaptive?: string(name='Adaptive', description='Indicates whether the text size was adjusted based on the output video dimensions. true / false, default: false', example='false'),
                  borderColor?: string(name='BorderColor', description='The border color.', example='#006400'),
                  borderWidth?: int32(name='BorderWidth', description='The border width.', example='0'),
                  content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                  fontAlpha?: string(name='FontAlpha', description='The transparency of the watermark.', example='1.0'),
                  fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                  fontName?: string(name='FontName', description='The font of the text.', example='SimSun'),
                  fontSize?: int32(name='FontSize', description='The size of the text.', example='16'),
                  left?: string(name='Left', description='The distance of the watermark from the left edge.', example='10'),
                  top?: string(name='Top', description='The distance of the watermark from the top edge.', example='10'),
                }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
                templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
              }
            ](name='TextWatermarks', description='The configurations of the text watermarks.'),
            transcode?: {
              overwriteParams?: {
                audio?: {
                  bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                  channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                  codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                  profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                  remove?: string(name='Remove', description='Indicates whether the audio stream is deleted.', example='false'),
                  samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100.
*   Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                  volume?: {
                    integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                    loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                    method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                    truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                  }(name='Volume', description='The volume configurations.'),
                }(name='Audio', description='The audio settings.'),
                container?: {
                  format?: string(name='Format', description='The container format.', example='mp4'),
                }(name='Container', description='The encapsulation format settings.'),
                muxConfig?: {
                  segment?: {
                    duration?: string(name='Duration', description='The segment length.', example='10'),
                    forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                  }(name='Segment', description='The segment settings.'),
                }(name='MuxConfig', description='The encapsulation settings.'),
                tags?: map[string]string(name='Tags'),
                video?: {
                  abrMax?: string(name='AbrMax', description='The maximum adaptive bitrate (ABR). This parameter takes effect only for Narrowband HD 1.0. Valid values: [10,50000]. Unit: Kbit/s.', example='6000'),
                  bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                  bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                  codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                  crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.

If this parameter is set, the value of Bitrate becomes invalid.', example='23'),
                  crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                  fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                  gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                  height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                  longShortMode?: string(name='LongShortMode', description='Indicates whether the auto-rotate screen feature is enabled.', example='false'),
                  maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video. Valid values: [10,50000]. Unit: Kbit/s.', example='9000'),
                  pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                  pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                  preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                  profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                  remove?: string(name='Remove', description='Indicates whether the video was removed.', example='false'),
                  scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                  width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
                }(name='Video', description='The video settings.'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }(name='Transcode', description='The transcoding configuration.'),
          }(name='ProcessConfig', description='The job processing configuration.'),
        }
      ](name='OutputGroup', description='The output group of the job.'),
      parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
      percent?: int32(name='Percent', description='The completion percentage of the job.', example='0'),
      requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
      scheduleConfig?: {
        pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
        priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
      }(name='ScheduleConfig', description='The scheduling configuration of the job.'),
      status?: string(name='Status', description='The state of the job.

*   Success: At least one of the subjobs is successful.
*   Fail: All subjobs failed.', example='Success'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
      userData?: string(name='UserData', description='The user data.', example='user-data'),
    }
  ](name='Jobs', description='The list of jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. The token of the next page is returned after you call this operation for the first time.', example='019daf5780f74831b0e1a767c9f1c178'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model ListTranscodeJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTranscodeJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of transcoding jobs.
 *
 * @param request ListTranscodeJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListTranscodeJobsResponse
 */
async function listTranscodeJobsWithOptions(request: ListTranscodeJobsRequest, runtime: Util.RuntimeOptions): ListTranscodeJobsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.endOfCreateTime)) {
    query['EndOfCreateTime'] = request.endOfCreateTime;
  }
  if (!Util.isUnset(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!Util.isUnset(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.parentJobId)) {
    query['ParentJobId'] = request.parentJobId;
  }
  if (!Util.isUnset(request.startOfCreateTime)) {
    query['StartOfCreateTime'] = request.startOfCreateTime;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListTranscodeJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of transcoding jobs.
 *
 * @param request ListTranscodeJobsRequest
 * @return ListTranscodeJobsResponse
 */
async function listTranscodeJobs(request: ListTranscodeJobsRequest): ListTranscodeJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listTranscodeJobsWithOptions(request, runtime);
}

model QueryCopyrightExtractJobRequest {
  jobId?: string(name='JobId', description='This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****'),
}

model QueryCopyrightExtractJobResponseBody = {
  data?: {
    message?: string(name='Message'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  statusCode?: long(name='StatusCode', example='200'),
}

model QueryCopyrightExtractJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryCopyrightExtractJobResponseBody(name='body'),
}

/**
 * @summary 查询版权水印提取任务
 *
 * @param request QueryCopyrightExtractJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryCopyrightExtractJobResponse
 */
async function queryCopyrightExtractJobWithOptions(request: QueryCopyrightExtractJobRequest, runtime: Util.RuntimeOptions): QueryCopyrightExtractJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'QueryCopyrightExtractJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 查询版权水印提取任务
 *
 * @param request QueryCopyrightExtractJobRequest
 * @return QueryCopyrightExtractJobResponse
 */
async function queryCopyrightExtractJob(request: QueryCopyrightExtractJobRequest): QueryCopyrightExtractJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return queryCopyrightExtractJobWithOptions(request, runtime);
}

model QueryCopyrightJobListRequest {
  createTimeEnd?: long(name='CreateTimeEnd', example='1627357325'),
  createTimeStart?: long(name='CreateTimeStart', example='1627357322'),
  jobId?: string(name='JobId', example='****cdb3e74639973036bc84****'),
  level?: long(name='Level', example='0'),
  pageNumber?: long(name='PageNumber', example='0'),
  pageSize?: long(name='PageSize', example='10'),
}

model QueryCopyrightJobListResponseBody = {
  data?: [ 
    {
      gmtCreate?: long(name='GmtCreate', example='1627357322'),
      gmtModified?: long(name='GmtModified', example='1627357322'),
      input?: {
        media?: string(name='Media', example='oss://bucket/object'),
        type?: string(name='Type', example='OSS'),
      }(name='Input'),
      jobId?: string(name='JobId', example='bfb786c639894f4d80648792021****'),
      level?: long(name='Level', example='2'),
      message?: string(name='Message', example='test'),
      output?: {
        media?: string(name='Media', example='oss://bucket/object'),
        type?: string(name='Type', example='OSS'),
      }(name='Output'),
      result?: string(name='Result', example='{"Code":"success","Message":"ok"}'),
      status?: string(name='Status', example='success'),
      userData?: string(name='UserData', example='123'),
      userId?: long(name='UserId', example='1346693***'),
    }
  ](name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='******36-3C1E-4417-BDB2-1E034F******'),
  statusCode?: long(name='StatusCode', example='200'),
}

model QueryCopyrightJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryCopyrightJobListResponseBody(name='body'),
}

/**
 * @summary 查询视频版权水印任务列表
 *
 * @param request QueryCopyrightJobListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryCopyrightJobListResponse
 */
async function queryCopyrightJobListWithOptions(request: QueryCopyrightJobListRequest, runtime: Util.RuntimeOptions): QueryCopyrightJobListResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.createTimeEnd)) {
    query['CreateTimeEnd'] = request.createTimeEnd;
  }
  if (!Util.isUnset(request.createTimeStart)) {
    query['CreateTimeStart'] = request.createTimeStart;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.level)) {
    query['Level'] = request.level;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'QueryCopyrightJobList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 查询视频版权水印任务列表
 *
 * @param request QueryCopyrightJobListRequest
 * @return QueryCopyrightJobListResponse
 */
async function queryCopyrightJobList(request: QueryCopyrightJobListRequest): QueryCopyrightJobListResponse {
  var runtime = new Util.RuntimeOptions{};
  return queryCopyrightJobListWithOptions(request, runtime);
}

model QueryDNAJobListRequest {
  jobIds?: string(name='JobIds', description='The IDs of the media fingerprint analysis jobs that you want to query. We recommend that you query at most 10 jobs at a time. Separate multiple job IDs with commas (,).', example='88c6ca184c0e47098a5b665e2a12****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model QueryDNAJobListResponseBody = {
  jobList?: [ 
    {
      code?: string(name='Code', description='The response code.', example='"InvalidParameter.ResourceNotFound"'),
      config?: string(name='Config', description='The configurations of the media fingerprint analysis job.', example='{"SaveType": "save","MediaType"":"video"}'),
      creationTime?: string(name='CreationTime', description='The time when the job was created.', example='2022-12-28T03:21:37Z'),
      DBId?: string(name='DBId', description='The ID of the media fingerprint library.', example='2288c6ca184c0e47098a5b665e2a12****'),
      DNAResult?: string(name='DNAResult', description='The URL of the media fingerprint analysis result.', example='http://test_bucket.oss-cn-shanghai.aliyuncs.com/fingerprint/video/search_result/5/5.txt'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-12-28T03:21:44Z'),
      id?: string(name='Id', description='The job ID.', example='88c6ca184c0e47098a5b665e2a12****'),
      input?: {
        media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. The path of an OSS object can be in one of the following formats:

1\\\\. oss://bucket/object

2\\\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the preceding paths, bucket indicates an OSS bucket that resides in the same region as the current project, and object indicates the path of the object in the bucket.', example='1b1b9cd148034739af413150fded****'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: Object Storage Service (OSS) object.
2.  Media: media asset.', example='Media'),
      }(name='Input', description='The details of the input file.'),
      message?: string(name='Message', description='The returned message.', example='"The resource operated \\\\"a887d0b***d805ef6f7f6786302\\\\" cannot be found"'),
      primaryKey?: string(name='PrimaryKey', description='The primary key of the video. You must make sure that each primary key is unique.', example='3ca84a39a9024f19853b21be9cf9****'),
      status?: string(name='Status', description='The job state. Valid values:

*   **Queuing**: The job is waiting in the queue.
*   **Analysing**: The job is in progress.
*   **Success**: The job is successful.
*   **Fail**: The job failed.', example='Queuing'),
      userData?: string(name='UserData', description='The user-defined data.', example='testdna'),
    }
  ](name='JobList', description='The queried media fingerprint analysis jobs.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model QueryDNAJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryDNAJobListResponseBody(name='body'),
}

/**
 * @summary Queries a list of media fingerprint analysis jobs.
 *
 * @param request QueryDNAJobListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryDNAJobListResponse
 */
async function queryDNAJobListWithOptions(request: QueryDNAJobListRequest, runtime: Util.RuntimeOptions): QueryDNAJobListResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobIds)) {
    query['JobIds'] = request.jobIds;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'QueryDNAJobList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of media fingerprint analysis jobs.
 *
 * @param request QueryDNAJobListRequest
 * @return QueryDNAJobListResponse
 */
async function queryDNAJobList(request: QueryDNAJobListRequest): QueryDNAJobListResponse {
  var runtime = new Util.RuntimeOptions{};
  return queryDNAJobListWithOptions(request, runtime);
}

model QueryIProductionJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.'),
  jobId?: string(name='JobId', description='The ID of the intelligent production job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model QueryIProductionJobResponseBody = {
  createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-07T07:16:11Z'),
  finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2021-11-26T14:50:25Z'),
  functionName?: string(name='FunctionName', description='The name of the algorithm that you want to use for the job. Valid values:

*   **Cover**: This algorithm intelligently generates a thumbnail image for a video.
*   **VideoClip**: This algorithm intelligently generates a summary for a video.
*   **VideoDelogo**: This algorithm removes logos from a video.
*   **VideoDetext**: This algorithm removes captions from a video.', example='Cover'),
  input?: {
    media?: string(name='Media', description='The input file. If Type is set to OSS, set this parameter to the path of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.', example='oss://bucket/object'),
    type?: string(name='Type', description='The media type. Valid values:

1.  OSS: Object Storage Service (OSS) object
2.  Media: media asset', example='OSS'),
  }(name='Input', description='The input file.'),
  jobId?: string(name='JobId', description='The ID of the intelligent production job.', example='****20b48fb04483915d4f2cd8ac****'),
  jobParams?: string(name='JobParams', description='The algorithm-specific parameters. The parameters are specified as JSON objects and vary based on the algorithm.', example='{"Model":"gif"}'),
  name?: string(name='Name', description='The name of the intelligent production job.'),
  output?: {
    media?: string(name='Media', description='The output file. If Type is set to OSS, set this parameter to the path of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.', example='oss://bucket/object'),
    type?: string(name='Type', description='The media type. Valid values:

*   OSS: OSS object
*   Media: media asset', example='OSS'),
  }(name='Output', description='The output file.'),
  outputFiles?: [ string ](name='OutputFiles', description='The output files.'),
  outputUrls?: [ string ](name='OutputUrls', description='The URLs of the output files.'),
  requestId?: string(name='RequestId', description='The ID of the request.'),
  result?: string(name='Result', description='The output of the algorithm. The output is in JSON format and varies based on the algorithm. For more information, see the "Parameters of Result" section of this topic.', example='{}'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue.', example='a54fdc9c9aab413caef0d1150f565e86'),
    priority?: int32(name='Priority', description='The priority of the job in the MPS queue to which the job is added.

*   A value of 10 indicates the highest priority.
*   Default value: **6**.', example='6'),
  }(name='ScheduleConfig', description='The scheduling configuration.'),
  status?: string(name='Status', description='The status of the job. Valid values:

*   Queuing: The job is waiting in the queue.
*   Analysing: The job is in progress.
*   Fail: The job failed.
*   Success: The job was successful.', example='Success'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
  userData?: string(name='UserData', description='The user-defined data that is returned in the response.', example='{"test":1}'),
}

model QueryIProductionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryIProductionJobResponseBody(name='body'),
}

/**
 * @summary Queries the status and result of an intelligent production job.
 *
 * @param request QueryIProductionJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryIProductionJobResponse
 */
async function queryIProductionJobWithOptions(request: QueryIProductionJobRequest, runtime: Util.RuntimeOptions): QueryIProductionJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'QueryIProductionJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the status and result of an intelligent production job.
 *
 * @param request QueryIProductionJobRequest
 * @return QueryIProductionJobResponse
 */
async function queryIProductionJob(request: QueryIProductionJobRequest): QueryIProductionJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return queryIProductionJobWithOptions(request, runtime);
}

model QueryMediaCensorJobDetailRequest {
  jobId?: string(name='JobId', description='The ID of the content moderation job. You can obtain the job ID from the response parameters of the [SubmitMediaCensorJob](https://help.aliyun.com/document_detail/444848.html) operation.

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****'),
  maximumPageSize?: long(name='MaximumPageSize', description='The number of entries per page.

*   Default value: **30**.
*   Valid values: **1 to 300**.', example='30'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='ae0fd49c0840e14daf0d66a75b83****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model QueryMediaCensorJobDetailResponseBody = {
  mediaCensorJobDetail?: {
    barrageCensorResult?: {
      label?: string(name='Label', description='The label of the moderation result. Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='normal'),
      rate?: string(name='Rate', description='The score.', example='99.91'),
      scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
    }(name='BarrageCensorResult', description='The moderation results of live comments.'),
    code?: string(name='Code', description='The error code returned if the job failed. This parameter is not returned if the job is successful.', example='InvalidParameter.ResourceNotFound'),
    coverImageCensorResults?: {
      coverImageCensorResult?: [ 
      {
        bucket?: string(name='Bucket', description='The OSS bucket in which the thumbnail is stored.', example='bucket-out-test-****'),
        location?: string(name='Location', description='The OSS region in which the thumbnail resides.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The Object Storage Service (OSS) object that is used as the thumbnail.', example='test/ai/censor/v2/vme-****.jpg'),
        results?: {
          result?: [ 
          {
            label?: string(name='Label', description='The label of the moderation result.

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live broadcasting in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='Normal'),
            rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
            scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='Antispam'),
            suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
          }
        ](name='Result')
        }(name='Results', description='The moderation results.'),
      }
    ](name='CoverImageCensorResult')
    }(name='CoverImageCensorResults', description='The moderation results of thumbnails.'),
    creationTime?: string(name='CreationTime', description='The time when the content moderation job was created.', example='2018-09-13T16:32:24Z'),
    descCensorResult?: {
      label?: string(name='Label', description='The label of the moderation result. Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='terrorism'),
      rate?: string(name='Rate', description='The score.', example='100'),
      scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='review'),
    }(name='DescCensorResult', description='The moderation results of descriptions.'),
    finishTime?: string(name='FinishTime', description='The time when the content moderation job was complete.', example='2018-09-13T16:38:24Z'),
    input?: {
      bucket?: string(name='Bucket', description='The name of the OSS bucket in which the input file is stored.', example='bucket-test-in-****'),
      location?: string(name='Location', description='The OSS region in which the input file resides.', example='oss-cn-shanghai'),
      object?: string(name='Object', description='The name of the OSS object that is used as the input file.', example='test/ai/censor/test-****.mp4'),
    }(name='Input', description='The information about the job input.'),
    jobId?: string(name='JobId', description='The ID of the content moderation job.', example='f8f166eea7a44e9bb0a4aecf9543****'),
    message?: string(name='Message', description='The error message returned if the job failed. This parameter is not returned if the job is successful.', example='The resource operated cannot be found'),
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the job was submitted.', example='c5b30b7c0d0e4a0abde1d5f9e751****'),
    state?: string(name='State', description='The job state.', example='Success'),
    suggestion?: string(name='Suggestion', description='The overall result of the content moderation job. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.

>  If the moderation result of any type of content is review, the overall result is review. If the moderation result of any type of content is block, the overall result is block.', example='block'),
    titleCensorResult?: {
      label?: string(name='Label', description='The label of the moderation result. Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='meaningless'),
      rate?: string(name='Rate', description='The score.', example='99.91'),
      scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
    }(name='TitleCensorResult', description='The moderation results of titles.'),
    userData?: string(name='UserData', description='The user-defined data.', example='example userdata ****'),
    vensorCensorResult?: {
      censorResults?: {
        censorResult?: [ 
        {
          label?: string(name='Label', description='The label of the moderation result.

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live broadcasting in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='meaningless'),
          rate?: string(name='Rate', description='The score.', example='100'),
          scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='terrorism'),
          suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='review'),
        }
      ](name='CensorResult')
      }(name='CensorResults', description='A collection of moderation results. The information includes the summary about various scenarios such as pornographic content moderation and terrorist content moderation.'),
      nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='ea04afcca7cd4e80b9ece8fbb251****'),
      videoTimelines?: {
        videoTimeline?: [ 
        {
          censorResults?: {
            censorResult?: [ 
            {
              label?: string(name='Label', description='The label of the moderation result.

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live broadcasting in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='flood'),
              rate?: string(name='Rate', description='The score.', example='99.99'),
              scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='porn'),
              suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
            }
          ](name='CensorResult')
          }(name='CensorResults', description='The moderation results that include information such as labels and scores.'),
          object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg`, `output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
          timestamp?: string(name='Timestamp', description='The position in the video. Format: `hh:mm:ss[.SSS]`.', example='00:02:59.999'),
        }
      ](name='VideoTimeline')
      }(name='VideoTimelines', description='The moderation results that are sorted in ascending order by time.'),
    }(name='VensorCensorResult', description='The moderation results of videos.'),
    videoCensorConfig?: {
      bizType?: string(name='BizType', description='The custom business type. Default value: common.', example='common'),
      outputFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket in which the output snapshot is stored.', example='test-bucket-****'),
        location?: string(name='Location', description='The OSS region in which the output snapshot resides.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg`, `output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
      }(name='OutputFile', description='The information about output snapshots.'),
      videoCensor?: string(name='VideoCensor', description='Indicates whether the video content needs to be moderated. Default value: **true**. Valid values:

*   **true**: The video content needs to be moderated.
*   **false**: The video content does not need to be moderated.', example='true'),
    }(name='VideoCensorConfig', description='The video moderation configurations.'),
  }(name='MediaCensorJobDetail', description='The results of the content moderation job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='B42299E6-F71F-465F-8FE9-4FC2E3D3C2CA'),
}

model QueryMediaCensorJobDetailResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryMediaCensorJobDetailResponseBody(name='body'),
}

/**
 * @summary Queries the information about a content moderation job.
 *
 * @description In the content moderation results, the moderation results of the video are sorted in ascending order by time into a timeline. If the video is long, the content moderation results are paginated, and the first page is returned. You can call this operation again to query the remaining moderation results of the video.
 *
 * @param request QueryMediaCensorJobDetailRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryMediaCensorJobDetailResponse
 */
async function queryMediaCensorJobDetailWithOptions(request: QueryMediaCensorJobDetailRequest, runtime: Util.RuntimeOptions): QueryMediaCensorJobDetailResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.maximumPageSize)) {
    query['MaximumPageSize'] = request.maximumPageSize;
  }
  if (!Util.isUnset(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'QueryMediaCensorJobDetail',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a content moderation job.
 *
 * @description In the content moderation results, the moderation results of the video are sorted in ascending order by time into a timeline. If the video is long, the content moderation results are paginated, and the first page is returned. You can call this operation again to query the remaining moderation results of the video.
 *
 * @param request QueryMediaCensorJobDetailRequest
 * @return QueryMediaCensorJobDetailResponse
 */
async function queryMediaCensorJobDetail(request: QueryMediaCensorJobDetailRequest): QueryMediaCensorJobDetailResponse {
  var runtime = new Util.RuntimeOptions{};
  return queryMediaCensorJobDetailWithOptions(request, runtime);
}

model QueryMediaCensorJobListRequest {
  endOfJobCreatedTimeRange?: string(name='EndOfJobCreatedTimeRange', description='The end of the time range to query.

*   Specify the time in the ISO 8601 standard. The time must be in UTC.
*   Format: yyyy-MM-ddTHH:mm:ssZ.', example='2022-02-14T02:16:07Z'),
  jobIds?: string(name='JobIds', description='The IDs of the content moderation jobs. You can obtain the ID of a content moderation job from the response parameters of the SubmitMediaCensorJob operation. Separate multiple IDs with commas (,).', example='fa9c34be3bcf42919ac4d1775239****,78dc866518b843259669df58ed30****'),
  maximumPageSize?: long(name='MaximumPageSize', description='The number of entries per page.

*   Default value: **30**.
*   Valid values: **1 to 300**.', example='20'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='79aff3eee82242e092899db5f669'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the jobs were submitted.', example='c5b30b7c0d0e4a0abde1d5f9e751****'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
  startOfJobCreatedTimeRange?: string(name='StartOfJobCreatedTimeRange', description='The beginning of the time range to query.

*   Specify the time in the ISO 8601 standard. The time must be in UTC.
*   Format: yyyy-MM-ddTHH:mm:ssZ.', example='2021-12-22T03:48:05Z'),
  state?: string(name='State', description='The state of the jobs that you want to query. Valid values:

*   **All**: all jobs.
*   **Queuing**: the jobs that are waiting in the queue.
*   **Analysing**: the jobs that are in progress.
*   **Fail**: failed jobs.
*   **Success**: successful jobs.', example='All'),
}

model QueryMediaCensorJobListResponseBody = {
  mediaCensorJobList?: {
    mediaCensorJob?: [ 
    {
      barrageCensorResult?: {
        label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,). Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='normal'),
        rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='99.91'),
        scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
        suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
      }(name='BarrageCensorResult', description='The moderation results of live comments.'),
      code?: string(name='Code', description='The error code returned if the job failed. This parameter is not returned if the job is successful.', example='InvalidParameter.ResourceNotFound'),
      coverImageCensorResults?: {
        coverImageCensorResult?: [ 
        {
          bucket?: string(name='Bucket', description='The OSS bucket in which the thumbnail is stored.', example='example-Bucket-****'),
          location?: string(name='Location', description='The OSS region in which the thumbnail resides.', example='oss-cn-shanghai'),
          object?: string(name='Object', description='The Object Storage Service (OSS) object that is used as the thumbnail.', example='test/ai/censor/v2/vme-****.jpg'),
          results?: {
            result?: [ 
            {
              label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,).

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live streaming in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='normal'),
              rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
              scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='live'),
              suggestion?: string(name='Suggestion', description='The overall result of the moderation job. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.

>  If the moderation result of any type of content is review, the overall result is review. If the moderation result of any type of content is block, the overall result is block.', example='pass'),
            }
          ](name='Result')
          }(name='Results', description='The moderation results.'),
        }
      ](name='CoverImageCensorResult')
      }(name='CoverImageCensorResults', description='The moderation results of thumbnails.'),
      creationTime?: string(name='CreationTime', description='The time when the content moderation job was created.', example='2021-11-04T07:25:48Z'),
      descCensorResult?: {
        label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,). Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='normal'),
        rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
        scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
        suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
      }(name='DescCensorResult', description='The moderation results of descriptions.'),
      finishTime?: string(name='FinishTime', description='The time when the content moderation job was complete.', example='2021-11-04T07:25:50Z'),
      input?: {
        bucket?: string(name='Bucket', description='The name of the OSS bucket in which the input file is stored.', example='bucket-test-in-****'),
        location?: string(name='Location', description='The OSS region in which the input file resides.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The name of the OSS object that is used as the input file.', example='test/ai/censor/test-****.mp4'),
      }(name='Input', description='The information about the job input.'),
      jobId?: string(name='JobId', description='The ID of the content moderation job.', example='f8f166eea7a44e9bb0a4aecf9543'),
      message?: string(name='Message', description='The error message returned if the job failed. This parameter is not returned if the job is successful.', example='The resource operated cannot be found'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='c5b30b7c0d0e4a0abde1d5f9e751****'),
      state?: string(name='State', description='The job state.', example='Success'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
      titleCensorResult?: {
        label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,). Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='meaningless'),
        rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
        scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
        suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
      }(name='TitleCensorResult', description='The moderation results of titles.'),
      userData?: string(name='UserData', description='The user-defined data.', example='example userdata ****'),
      vensorCensorResult?: {
        censorResults?: {
          censorResult?: [ 
          {
            label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,).

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live streaming in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='meaningless'),
            rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
            scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='ad'),
            suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
          }
        ](name='CensorResult')
        }(name='CensorResults', description='A collection of moderation results. The information includes the summary about various scenarios such as pornographic content moderation and terrorist content moderation.'),
        nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='ea04afcca7cd4e80b9ece8fbb251'),
        videoTimelines?: {
          videoTimeline?: [ 
          {
            censorResults?: {
              censorResult?: [ 
              {
                label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,).

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live streaming in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='normal'),
                rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
                scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='porn'),
                suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
              }
            ](name='CensorResult')
            }(name='CensorResults', description='The moderation results that include information such as labels and scores.'),
            object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg`, `output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
            timestamp?: string(name='Timestamp', description='The position in the video. Format: `hh:mm:ss[.SSS]`.', example='00:02:59.999'),
          }
        ](name='VideoTimeline')
        }(name='VideoTimelines', description='The moderation results that are sorted in ascending order by time.'),
      }(name='VensorCensorResult', description='The moderation results of videos.'),
      videoCensorConfig?: {
        bizType?: string(name='BizType', description='The moderation template. Default value: common. The default value indicates that the default template is used.

>  If the moderation template is not specified, the default value common is returned. If a custom moderation template that is created by submitting a ticket is specified, the UID of the template is returned.', example='common'),
        outputFile?: {
          bucket?: string(name='Bucket', description='The OSS bucket in which the output snapshot is stored.', example='test-bucket-****'),
          location?: string(name='Location', description='The ID of the region in which the output snapshot resides.', example='oss-cn-shanghai'),
          object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg, output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
        }(name='OutputFile', description='The information about output snapshots.'),
        videoCensor?: string(name='VideoCensor', description='Indicates whether the video content needs to be moderated. Default value: **true**. Valid values:

*   **true**: The video content needs to be moderated.
*   **false**: The video content does not need to be moderated.', example='true'),
      }(name='VideoCensorConfig', description='The video moderation configurations.'),
    }
  ](name='MediaCensorJob')
  }(name='MediaCensorJobList', description='The queried content moderation jobs.'),
  nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. The value is 32-character UUID. If the returned query results cannot be displayed within one page, this parameter is returned. The value of this parameter is updated for each query.', example='9b1a42bc6e8d46e6a1383b7e7f01****'),
  nonExistIds?: {
    string?: [ string ](name='String')
  }(name='NonExistIds', description='The IDs of the jobs that do not exist. This parameter is not returned if all the specified jobs are found.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D1D5C080-8E2F-5030-8AB4-13092F17631B'),
}

model QueryMediaCensorJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryMediaCensorJobListResponseBody(name='body'),
}

/**
 * @summary Queries a list of content moderation jobs.
 *
 * @description You can call this operation to query only the content moderation jobs within the most recent three months.
 *
 * @param request QueryMediaCensorJobListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryMediaCensorJobListResponse
 */
async function queryMediaCensorJobListWithOptions(request: QueryMediaCensorJobListRequest, runtime: Util.RuntimeOptions): QueryMediaCensorJobListResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.endOfJobCreatedTimeRange)) {
    query['EndOfJobCreatedTimeRange'] = request.endOfJobCreatedTimeRange;
  }
  if (!Util.isUnset(request.jobIds)) {
    query['JobIds'] = request.jobIds;
  }
  if (!Util.isUnset(request.maximumPageSize)) {
    query['MaximumPageSize'] = request.maximumPageSize;
  }
  if (!Util.isUnset(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.pipelineId)) {
    query['PipelineId'] = request.pipelineId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  if (!Util.isUnset(request.startOfJobCreatedTimeRange)) {
    query['StartOfJobCreatedTimeRange'] = request.startOfJobCreatedTimeRange;
  }
  if (!Util.isUnset(request.state)) {
    query['State'] = request.state;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'QueryMediaCensorJobList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries a list of content moderation jobs.
 *
 * @description You can call this operation to query only the content moderation jobs within the most recent three months.
 *
 * @param request QueryMediaCensorJobListRequest
 * @return QueryMediaCensorJobListResponse
 */
async function queryMediaCensorJobList(request: QueryMediaCensorJobListRequest): QueryMediaCensorJobListResponse {
  var runtime = new Util.RuntimeOptions{};
  return queryMediaCensorJobListWithOptions(request, runtime);
}

model QueryMediaIndexJobRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='c2e77390f75271ec802f0674a2ce6***'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1'),
}

model QueryMediaIndexJobResponseBody = {
  code?: string(name='Code', description='The response code.', example='200'),
  indexJobInfoList?: [ 
    {
      gmtFinish?: string(name='GmtFinish', description='The end time of the indexing job.', example='2023-11-21 11:33:51'),
      gmtSubmit?: string(name='GmtSubmit', description='The time when the index job was submitted.', example='2023-11-21 11:33:50'),
      indexType?: string(name='IndexType', description='The index type. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.', example='mm'),
      status?: string(name='Status', description='The job status. Valid values:

*   Running
*   Success
*   Fail', example='Success'),
    }
  ](name='IndexJobInfoList', description='The indexing jobs enabled for the media asset.'),
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model QueryMediaIndexJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryMediaIndexJobResponseBody(name='body'),
}

/**
 * @summary Queries the indexing jobs enabled for a media asset.
 *
 * @param request QueryMediaIndexJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryMediaIndexJobResponse
 */
async function queryMediaIndexJobWithOptions(request: QueryMediaIndexJobRequest, runtime: Util.RuntimeOptions): QueryMediaIndexJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'QueryMediaIndexJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the indexing jobs enabled for a media asset.
 *
 * @param request QueryMediaIndexJobRequest
 * @return QueryMediaIndexJobResponse
 */
async function queryMediaIndexJob(request: QueryMediaIndexJobRequest): QueryMediaIndexJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return queryMediaIndexJobWithOptions(request, runtime);
}

model QuerySearchIndexRequest {
  indexType?: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.

This parameter is required.', example='mm'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

*   If you leave this parameter empty, the search index is created in the default search library of Intelligent Media Service (IMS). Default value: ims-default-search-lib.
*   To query information about an existing search library, call the [QuerySearchLib](https://help.aliyun.com/document_detail/2584455.html) API operation.', example='test1'),
}

model QuerySearchIndexResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  indexStatus?: string(name='IndexStatus', description='The state of the index. Valid values:

*   active: the index is enabled.
*   Deactive: the index is not enabled.', example='Active'),
  indexType?: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.', example='mm'),
  mediaTotal?: string(name='MediaTotal', description='The total number of media assets.', example='12'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model QuerySearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QuerySearchIndexResponseBody(name='body'),
}

/**
 * @summary Queries the details of a search index.
 *
 * @param request QuerySearchIndexRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QuerySearchIndexResponse
 */
async function querySearchIndexWithOptions(request: QuerySearchIndexRequest, runtime: Util.RuntimeOptions): QuerySearchIndexResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.indexType)) {
    query['IndexType'] = request.indexType;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'QuerySearchIndex',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the details of a search index.
 *
 * @param request QuerySearchIndexRequest
 * @return QuerySearchIndexResponse
 */
async function querySearchIndex(request: QuerySearchIndexRequest): QuerySearchIndexResponse {
  var runtime = new Util.RuntimeOptions{};
  return querySearchIndexWithOptions(request, runtime);
}

model QuerySearchLibRequest {
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

This parameter is required.', example='test1'),
}

model QuerySearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  indexInfo?: [ 
    {
      indexReadiness?: string(name='IndexReadiness'),
      indexStatus?: string(name='IndexStatus'),
      indexType?: string(name='IndexType'),
    }
  ](name='IndexInfo'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
  status?: string(name='Status', description='The status of the search library.

Valid values:

*   normal
*   deleting
*   deleteFail', example='normal'),
  success?: string(name='Success', description='Indicates whether the call was successful. Valid values:

*   true
*   false', example='true'),
}

model QuerySearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QuerySearchLibResponseBody(name='body'),
}

/**
 * @summary Queries the information about a search library.
 *
 * @param request QuerySearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QuerySearchLibResponse
 */
async function querySearchLibWithOptions(request: QuerySearchLibRequest, runtime: Util.RuntimeOptions): QuerySearchLibResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'QuerySearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a search library.
 *
 * @param request QuerySearchLibRequest
 * @return QuerySearchLibResponse
 */
async function querySearchLib(request: QuerySearchLibRequest): QuerySearchLibResponse {
  var runtime = new Util.RuntimeOptions{};
  return querySearchLibWithOptions(request, runtime);
}

model QuerySmarttagJobRequest {
  jobId?: string(name='JobId', description='The ID of the smart tagging job that you want to query. You can obtain the job ID from the response parameters of the SubmitSmarttagJob operation.

This parameter is required.', example='88c6ca184c0e47098a5b665e2****'),
  params?: string(name='Params', description='The extra parameters that you want to query in the request. The value is a JSON string. Example: {"labelResultType":"auto"}. The value of labelResultType is of the STRING type. Valid values:

*   auto: machine tagging
*   hmi: tagging by human and machine', example='{"labelResultType":"auto"}'),
}

model QuerySmarttagJobResponseBody = {
  jobStatus?: string(name='JobStatus', description='The status of the job. Valid values:

*   **Success**: The job was successful.
*   **Fail**: The job failed.
*   **Processing**: The job is in progress.
*   **Submitted**: The job is submitted and waiting to be processed.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  results?: {
    result?: [ 
    {
      data?: string(name='Data', description='The details of the analysis result. The value is a JSON string. For more information about the parameters of different result types, see the "Parameters of different result types" section of this topic.', example='{"title":"example-title-****"}'),
      type?: string(name='Type', description='The type of the analysis result.

*   The type of the analysis result based on Smart tagging V1.0. Valid values:

1.  TextLabel: the text tag.
2.  VideoLabel: the video tag.
3.  ASR: the original result of automatic speech recognition (ASR). By default, this type of result is not returned.
4.  OCR: the original result of optical character recognition (OCR). By default, this type of result is not returned.
5.  NLP: the natural language processing (NLP)-based result. By default, this type of result is not returned.

*   The type of the analysis result based on Smart tagging V2.0. Valid values:

1.  CPVLabel
2.  Meta: the information about the video file, such as the title of the video. By default, this type of information is not returned.

*   The type of the analysis result based on Smart tagging V2.0-custom. Valid values:

1.  CPVLabel
2.  Meta: the information about the video file, such as the title of the video. By default, this type of information is not returned.', example='Meta'),
    }
  ](name='Result')
  }(name='Results', description='The analysis results of the smart tagging job. The value is an array.'),
  userData?: string(name='UserData', description='The content of callback messages that are sent to Simple Message Queue (SMQ) when the information of the smart tagging job changes. For more information about the parameters contained in the callback message, see the "Callback parameters" section of this topic.', example='{"userId":"123432412831"}'),
}

model QuerySmarttagJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QuerySmarttagJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a smart tagging job.
 *
 * @param request QuerySmarttagJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QuerySmarttagJobResponse
 */
async function querySmarttagJobWithOptions(request: QuerySmarttagJobRequest, runtime: Util.RuntimeOptions): QuerySmarttagJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.params)) {
    query['Params'] = request.params;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'QuerySmarttagJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about a smart tagging job.
 *
 * @param request QuerySmarttagJobRequest
 * @return QuerySmarttagJobResponse
 */
async function querySmarttagJob(request: QuerySmarttagJobRequest): QuerySmarttagJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return querySmarttagJobWithOptions(request, runtime);
}

model QueryTraceAbJobListRequest {
  createTimeEnd?: long(name='CreateTimeEnd', example='1627357325'),
  createTimeStart?: long(name='CreateTimeStart', example='1627357322'),
  jobId?: string(name='JobId', example='****d80e4e4044975745c14b****'),
  pageNumber?: long(name='PageNumber', example='0'),
  pageSize?: long(name='PageSize', example='10'),
  traceMediaId?: string(name='TraceMediaId', example='****437bd2b51105d07b12a9****'),
}

model QueryTraceAbJobListResponseBody = {
  data?: [ 
    {
      gmtCreate?: long(name='GmtCreate', example='1627357322'),
      gmtModified?: long(name='GmtModified', example='1627357322'),
      input?: {
        media?: string(name='Media', example='oss://bucket/object'),
        type?: string(name='Type', example='OSS'),
      }(name='Input'),
      jobId?: string(name='JobId', example='bfb786c639894f4d80648792021eff90'),
      level?: long(name='Level', example='2'),
      output?: {
        media?: string(name='Media', example='oss://bucket/dir/'),
        type?: string(name='Type', example='OSS'),
      }(name='Output'),
      result?: string(name='Result', example='{"Code":"success","Message":"ok"}'),
      status?: string(name='Status', example='success'),
      traceMediaId?: string(name='TraceMediaId', example='****437bd2b51105d07b12a9****'),
      userData?: string(name='UserData', example='123'),
      userId?: long(name='UserId', example='13466932****'),
    }
  ](name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='******11-DB8D-4A9A-875B-275798******'),
  statusCode?: long(name='StatusCode', example='200'),
}

model QueryTraceAbJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryTraceAbJobListResponseBody(name='body'),
}

/**
 * @summary 查询视频溯源水印ab流任务
 *
 * @param request QueryTraceAbJobListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryTraceAbJobListResponse
 */
async function queryTraceAbJobListWithOptions(request: QueryTraceAbJobListRequest, runtime: Util.RuntimeOptions): QueryTraceAbJobListResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.createTimeEnd)) {
    query['CreateTimeEnd'] = request.createTimeEnd;
  }
  if (!Util.isUnset(request.createTimeStart)) {
    query['CreateTimeStart'] = request.createTimeStart;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.traceMediaId)) {
    query['TraceMediaId'] = request.traceMediaId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'QueryTraceAbJobList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 查询视频溯源水印ab流任务
 *
 * @param request QueryTraceAbJobListRequest
 * @return QueryTraceAbJobListResponse
 */
async function queryTraceAbJobList(request: QueryTraceAbJobListRequest): QueryTraceAbJobListResponse {
  var runtime = new Util.RuntimeOptions{};
  return queryTraceAbJobListWithOptions(request, runtime);
}

model QueryTraceExtractJobRequest {
  jobId?: string(name='JobId', description='This parameter is required.', example='31fa3c9ca8134fb4b0b0f7878301****'),
}

model QueryTraceExtractJobResponseBody = {
  data?: {
    trace?: string(name='Trace'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  statusCode?: long(name='StatusCode', example='200'),
}

model QueryTraceExtractJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryTraceExtractJobResponseBody(name='body'),
}

/**
 * @summary 查询溯源水印提取任务
 *
 * @param request QueryTraceExtractJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryTraceExtractJobResponse
 */
async function queryTraceExtractJobWithOptions(request: QueryTraceExtractJobRequest, runtime: Util.RuntimeOptions): QueryTraceExtractJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'QueryTraceExtractJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 查询溯源水印提取任务
 *
 * @param request QueryTraceExtractJobRequest
 * @return QueryTraceExtractJobResponse
 */
async function queryTraceExtractJob(request: QueryTraceExtractJobRequest): QueryTraceExtractJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return queryTraceExtractJobWithOptions(request, runtime);
}

model QueryTraceM3u8JobListRequest {
  createTimeEnd?: long(name='CreateTimeEnd', example='1627357325'),
  createTimeStart?: long(name='CreateTimeStart', example='1627357322'),
  jobId?: string(name='JobId', example='****20b48fb04483915d4f2cd8ac****'),
  pageNumber?: long(name='PageNumber', example='0'),
  pageSize?: long(name='PageSize', example='10'),
}

model QueryTraceM3u8JobListResponseBody = {
  data?: [ 
    {
      gmtCreate?: long(name='GmtCreate', example='1627357322'),
      gmtModified?: long(name='GmtModified', example='1627357322'),
      jobId?: string(name='JobId', example='****d718e2ff4f018ccf419a7b71****'),
      output?: {
        media?: string(name='Media', example='oss://bucket/object'),
        type?: string(name='Type', example='OSS'),
      }(name='Output'),
      status?: string(name='Status', example='success'),
      trace?: string(name='Trace', example='test'),
      traceMediaId?: string(name='TraceMediaId', example='****437bd2b105d07b12a9a82****'),
      userData?: string(name='UserData', example='112'),
      userId?: long(name='UserId', example='1346693276****'),
    }
  ](name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='******11-DB8D-4A9A-875B-275798******'),
  statusCode?: long(name='StatusCode', example='200'),
}

model QueryTraceM3u8JobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryTraceM3u8JobListResponseBody(name='body'),
}

/**
 * @summary 查询视频溯源水印m3u8任务
 *
 * @param request QueryTraceM3u8JobListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryTraceM3u8JobListResponse
 */
async function queryTraceM3u8JobListWithOptions(request: QueryTraceM3u8JobListRequest, runtime: Util.RuntimeOptions): QueryTraceM3u8JobListResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.createTimeEnd)) {
    query['CreateTimeEnd'] = request.createTimeEnd;
  }
  if (!Util.isUnset(request.createTimeStart)) {
    query['CreateTimeStart'] = request.createTimeStart;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'QueryTraceM3u8JobList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 查询视频溯源水印m3u8任务
 *
 * @param request QueryTraceM3u8JobListRequest
 * @return QueryTraceM3u8JobListResponse
 */
async function queryTraceM3u8JobList(request: QueryTraceM3u8JobListRequest): QueryTraceM3u8JobListResponse {
  var runtime = new Util.RuntimeOptions{};
  return queryTraceM3u8JobListWithOptions(request, runtime);
}

model RefreshUploadMediaRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***'),
}

model RefreshUploadMediaResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='c2e77390f75271ec802f0674a2ce6***'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  uploadAddress?: string(name='UploadAddress', description='The upload URL.

>  The returned upload URL is a Base64-encoded URL. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAddress only if you use Object Storage Service (OSS) SDK or call an OSS API operation to upload media files.', example='eyJFbmRwb2ludCI6Imh0dHBzOi8vb3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbSIsIkJ1Y2tldCI6InN6aGQtdmlkZW8iLCJGaWxlTmFtZSI6InZvZC0yOTYzMWEvc3YvNTBmYTJlODQtMTgxMjdhZGRiMTcvNTBmYTJlODQtMTgxMjdhZGRiM***'),
  uploadAuth?: string(name='UploadAuth', description='The upload credential.

>  The returned upload credential is a Base64-encoded value. You must decode the Base64-encoded upload credential before you use an SDK or call an API operation to upload media files. You need to parse UploadAuth only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJBY2Nlc3NLZXlJZCI6IkxUQUk0Rm53bTk1dHdxQjMxR3IzSE5hRCIsIkFjY2Vzc0tleVNlY3JldCI6Ik9lWllKR0dTMTlkNkZaM1E3UVpJQmdmSVdnM3BPaiIsIkV4cGlyYXRpb24iOiI***'),
}

model RefreshUploadMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RefreshUploadMediaResponseBody(name='body'),
}

/**
 * @summary Obtain a new upload credential for a media asset after its upload credential expires.
 *
 * @description You can also call this operation to overwrite media files. After you obtain the upload URL of a media file, you can upload the media file again without changing the audio or video ID.
 *
 * @param request RefreshUploadMediaRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return RefreshUploadMediaResponse
 */
async function refreshUploadMediaWithOptions(request: RefreshUploadMediaRequest, runtime: Util.RuntimeOptions): RefreshUploadMediaResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'RefreshUploadMedia',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Obtain a new upload credential for a media asset after its upload credential expires.
 *
 * @description You can also call this operation to overwrite media files. After you obtain the upload URL of a media file, you can upload the media file again without changing the audio or video ID.
 *
 * @param request RefreshUploadMediaRequest
 * @return RefreshUploadMediaResponse
 */
async function refreshUploadMedia(request: RefreshUploadMediaRequest): RefreshUploadMediaResponse {
  var runtime = new Util.RuntimeOptions{};
  return refreshUploadMediaWithOptions(request, runtime);
}

model RegisterMediaInfoRequest {
  businessType?: string(name='BusinessType', description='The business type of the media asset. Valid values:

*   subtitles
*   watermark
*   opening
*   ending
*   general', example='opening'),
  cateId?: long(name='CateId', description='The category ID.', example='3048'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request. The value must be a UUID that contains 32 characters.', example='****0311a423d11a5f7dee713535****'),
  coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png'),
  description?: string(name='Description', description='The description of the media asset.

*   The value can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultDescription'),
  inputURL?: string(name='InputURL', description='The URL of the media asset in another service. The URL is associated with the ID of the media asset in IMS. The URL cannot be modified once registered. The following types of URLs are supported:

*   OSS URL in one of the following formats:

http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4

oss://example-bucket/example.mp4: In this format, it is considered by default that the region of the OSS bucket in which the media asset resides is the same as the region in which IMS is activated.

*   URL of an ApsaraVideo VOD media asset

vod://\\\\*\\\\*\\\\*20b48fb04483915d4f2cd8ac\\\\*\\\\*\\\\*\\\\*

This parameter is required.'),
  mediaTags?: string(name='MediaTags', description='The tags of the media asset.

*   Up to 16 tags are supported.
*   Separate multiple tags with commas (,).
*   Each tag can be up to 32 bytes in length.
*   The value must be encoded in UTF-8.', example='tag1,tag2'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

*   image
*   video
*   audio
*   text

We recommend that you specify this parameter based on your business requirements. If you set InputURL to an OSS URL, the media asset type can be automatically determined based on the file name extension. For more information
<props="china">, see [File formats](https://help.aliyun.com/document_detail/466207.html).', example='video'),
  overwrite?: boolean(name='Overwrite', description='Specifies whether to overwrite the media asset that has been registered by using the same URL. Default value: false. Valid values:

\\\\- true: If a media asset has been registered by using the same URL, the original media asset is deleted and the new media asset is registered.

\\\\- false: If a media asset has been registered by using the same URL, the new media asset is not registered. A URL cannot be used to register multiple media assets.', example='true'),
  referenceId?: string(name='ReferenceId', description='The custom ID. The ID can be 6 to 64 characters in length and can contain only letters, digits, hyphens (-), and underscores (_). Make sure that the ID is unique among users.', example='123-123'),
  registerConfig?: string(name='RegisterConfig', description='The registration configurations.

By default, a sprite is generated for the media asset. You can set NeedSprite to false to disable automatic sprite generation.

By default, a snapshot is generated for the media asset. You can set NeedSnapshot to false to disable automatic snapshot generation.', example='{
      "NeedSprite": "false"
}'),
  smartTagTemplateId?: string(name='SmartTagTemplateId', description='The ID of the smart tagging template. Valid values:

*   S00000101-300080: the system template that supports natural language processing (NLP) for content recognition.
*   S00000103-000001: the system template that supports NLP for content recognition and all tagging capabilities.
*   S00000103-000002: the system template that supports all tagging capabilities but does not support NLP for content recognition.

After you configure this parameter, a smart tag analysis task is automatically initiated after the media asset is registered. For more information about the billable items<props="china">, see [Smart tagging](https://help.aliyun.com/zh/ims/media-ai-billing?spm=a2c4g.11186623.0.0.3147392dWwlSjL#p-k38-3rb-dug).', example='S00000101-300080'),
  title?: string(name='Title', description='The title. If you do not specify this parameter, a default title is automatically generated based on the date.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultTitle'),
  userData?: string(name='UserData', description='The user data. You can specify a custom callback URL. For more information<props="china"> ,see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).

*   The value can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.
*   The value must be in the JSON format.'),
  workflowId?: string(name='WorkflowId', description='The workflow ID.', example='******b4fb044839815d4f2cd8******'),
}

model RegisterMediaInfoResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset in IMS.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The request ID.', example='******5A-CAAC-4850-A3AF-B74606******'),
}

model RegisterMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RegisterMediaInfoResponseBody(name='body'),
}

/**
 * @summary Registers a media asset with Intelligent Media Services (IMS). IMS assigns an ID to the media asset. This operation asynchronously accesses the media asset service in which the media asset is stored to obtain the file information of the media asset based on the input URL. You can also specify basic information, such as the title, tags, and description, for the media asset. This operation returns the ID of the media asset. You can call the GetMediaInfo operation based on the ID to query the details of the media asset. You can set InputURL only to the URL of an Object Storage Service (OSS) file or an ApsaraVideo VOD media asset.
 *
 * @description Registering a media asset is an asynchronous job that takes 2 to 3 seconds. When the operation returns the ID of the media asset, the registration may have not be completed. If you call the GetMediaInfo operation at this time, you may fail to obtain the information about the media asset.
 *
 * @param request RegisterMediaInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return RegisterMediaInfoResponse
 */
async function registerMediaInfoWithOptions(request: RegisterMediaInfoRequest, runtime: Util.RuntimeOptions): RegisterMediaInfoResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.businessType)) {
    query['BusinessType'] = request.businessType;
  }
  if (!Util.isUnset(request.cateId)) {
    query['CateId'] = request.cateId;
  }
  if (!Util.isUnset(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!Util.isUnset(request.coverURL)) {
    query['CoverURL'] = request.coverURL;
  }
  if (!Util.isUnset(request.description)) {
    query['Description'] = request.description;
  }
  if (!Util.isUnset(request.inputURL)) {
    query['InputURL'] = request.inputURL;
  }
  if (!Util.isUnset(request.mediaTags)) {
    query['MediaTags'] = request.mediaTags;
  }
  if (!Util.isUnset(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!Util.isUnset(request.overwrite)) {
    query['Overwrite'] = request.overwrite;
  }
  if (!Util.isUnset(request.referenceId)) {
    query['ReferenceId'] = request.referenceId;
  }
  if (!Util.isUnset(request.registerConfig)) {
    query['RegisterConfig'] = request.registerConfig;
  }
  if (!Util.isUnset(request.smartTagTemplateId)) {
    query['SmartTagTemplateId'] = request.smartTagTemplateId;
  }
  if (!Util.isUnset(request.title)) {
    query['Title'] = request.title;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  if (!Util.isUnset(request.workflowId)) {
    query['WorkflowId'] = request.workflowId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'RegisterMediaInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Registers a media asset with Intelligent Media Services (IMS). IMS assigns an ID to the media asset. This operation asynchronously accesses the media asset service in which the media asset is stored to obtain the file information of the media asset based on the input URL. You can also specify basic information, such as the title, tags, and description, for the media asset. This operation returns the ID of the media asset. You can call the GetMediaInfo operation based on the ID to query the details of the media asset. You can set InputURL only to the URL of an Object Storage Service (OSS) file or an ApsaraVideo VOD media asset.
 *
 * @description Registering a media asset is an asynchronous job that takes 2 to 3 seconds. When the operation returns the ID of the media asset, the registration may have not be completed. If you call the GetMediaInfo operation at this time, you may fail to obtain the information about the media asset.
 *
 * @param request RegisterMediaInfoRequest
 * @return RegisterMediaInfoResponse
 */
async function registerMediaInfo(request: RegisterMediaInfoRequest): RegisterMediaInfoResponse {
  var runtime = new Util.RuntimeOptions{};
  return registerMediaInfoWithOptions(request, runtime);
}

model RegisterMediaStreamRequest {
  inputURL?: string(name='InputURL', description='The URL of the media asset in another service. The URL is associated with the ID of the media asset in IMS. The URL cannot be modified once registered.

Set this parameter to the OSS URL of the media asset. The following formats are supported:

http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4

oss://example-bucket/example.mp4: In this format, it is considered by default that the region of the OSS bucket in which the media asset resides is the same as the region in which IMS is activated.'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='5e778ec0027b71ed80a8909598506***'),
  userData?: string(name='UserData', description='The user data.', example='{"MessageCallback":{"CallbackURL":"http://test.test.com"}, "Extend":{"localId":"xxx","test":"www"}}'),
}

model RegisterMediaStreamResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='5e778ec0027b71ed80a8909598506302'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model RegisterMediaStreamResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RegisterMediaStreamResponseBody(name='body'),
}

/**
 * @summary Registers a media stream.
 *
 * @description You can call this operation to register a media stream file in an Object Storage Service (OSS) bucket with Intelligent Media Services (IMS) and associate the media stream with the specified media asset ID.
 *
 * @param request RegisterMediaStreamRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return RegisterMediaStreamResponse
 */
async function registerMediaStreamWithOptions(request: RegisterMediaStreamRequest, runtime: Util.RuntimeOptions): RegisterMediaStreamResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.inputURL)) {
    query['InputURL'] = request.inputURL;
  }
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'RegisterMediaStream',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Registers a media stream.
 *
 * @description You can call this operation to register a media stream file in an Object Storage Service (OSS) bucket with Intelligent Media Services (IMS) and associate the media stream with the specified media asset ID.
 *
 * @param request RegisterMediaStreamRequest
 * @return RegisterMediaStreamResponse
 */
async function registerMediaStream(request: RegisterMediaStreamRequest): RegisterMediaStreamResponse {
  var runtime = new Util.RuntimeOptions{};
  return registerMediaStreamWithOptions(request, runtime);
}

model SearchEditingProjectRequest {
  createSource?: string(name='CreateSource', description='The source of the project.

\\\\-OpenAPI

\\\\-AliyunConsole

\\\\-WebSDK

Valid values:

*   AliyunConsole: The project is created in the Alibaba Cloud console.
*   WebSDK: The project is created by using the SDK for Web.
*   OpenAPI: The project is created by calling API operations.', example='WebSDK'),
  endTime?: string(name='EndTime', description='The end of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-01-11T12:00:00Z'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10'),
  projectType?: string(name='ProjectType', description='The type of the editing project. Default value: EditingProject. Valid values:

*   EditingProject: a regular editing project.
*   LiveEditingProject: a live stream editing project.', example='EditingProject'),
  sortBy?: string(name='SortBy', description='The sorting rule of results. Valid values:

\\\\- CreationTime:Desc (default): The results are sorted in reverse chronological order based on the creation time.

\\\\- CreationTime:Asc: The results are sorted in chronological order based on the creation time.', example='CreationTime:Desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-01-11T12:00:00Z'),
  status?: string(name='Status', description='The status of the online editing project. Separate multiple values with commas (,). By default, all online editing projects are queried.

Valid values:

\\\\-Draft

\\\\-Producing

\\\\-Produced

\\\\-ProduceFailed', example='Producing'),
  templateType?: string(name='TemplateType', description='The template type. Valid values:

\\\\-Timeline

\\\\-VETemplate

Valid values:

*   Timeline: regular template.
*   VETemplate: advanced template.
*   None: No template is used.', example='Timeline'),
}

model SearchEditingProjectResponseBody = {
  maxResults?: long(name='MaxResults', description='The maximum number of entries returned on a single page. The value is set to the maximum number of entries returned on each page except for the last page.

Examples:

Valid example: 10,10,5. Invalid example: 10,5,10.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='null'),
  projectList?: [ 
    {
      businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{ "OutputMediaConfig" : { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path" }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
      businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

Valid values:

*   BroadCasting:
*   ReservationCanceled
*   LiveFinished
*   LoadingFailed
*   Reserving', example='Reserving'),
      coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example-cover.jpg'),
      createSource?: string(name='CreateSource', description='The method for editing the online editing project.

\\\\-OpenAPI

\\\\-AliyunConsole

\\\\-WebSDK

Valid values:

*   AliyunConsole: The project is created in the Alibaba Cloud console.
*   WebSDK: The project is created by using the SDK for Web.
*   OpenAPI: The project is created by calling API operations.', example='OpenAPI'),
      createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2017-01-11T12:00:00Z'),
      description?: string(name='Description', description='The description of the online editing project.', example='sample description'),
      duration?: long(name='Duration', description='The total length of the online editing project. Unit: seconds.', example='30.100000'),
      errorCode?: string(name='ErrorCode', description='The error code returned if the production of the online editing project failed.', example='InvalidParameter'),
      errorMessage?: string(name='ErrorMessage', description='The error message returned if the production of the online editing project failed.', example='"EventTime":"2021-08-12T10:04:15Z","ErrorCode":"InvalidParameter","ErrorMessage":"The specified parameter \\\\"LiveStreamConfig\\\\" is not valid. specified parameter example is not valid.'),
      modifiedSource?: string(name='ModifiedSource', description='The method used when the online editing project was last modified.', example='2017-01-11T12:00:00Z'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last modified.', example='2017-01-11T12:00:00Z'),
      projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fddd7748b58bf1d47e95****'),
      projectType?: string(name='ProjectType', description='The type of the editing project.

Valid values:

*   LiveEditingProject: a live stream editing project.
*   EditingProject: a regular editing project.', example='EditingProject'),
      status?: string(name='Status', description='The status of the online editing project. Valid values:

\\\\-Draft

\\\\-Editing

\\\\-Producing

\\\\-Produced

\\\\-ProduceFailed

Valid values:

*   Draft
*   Produced
*   Editing
*   Producing
*   ProduceFailed', example='PRODUCE_FAILED'),
      templateType?: string(name='TemplateType', description='The type of the template.', example='Timeline'),
      timeline?: string(name='Timeline', description='The timeline of the online editing project.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
      title?: string(name='Title', description='The title of the online editing project.', example='title'),
    }
  ](name='ProjectList', description='The queried online editing projects.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****9262E3DA-07FA-4862-FCBB6BC61D08*****'),
  totalCount?: long(name='TotalCount', description='Optional. The total number of entries returned. By default, this parameter is not returned.', example='110'),
}

model SearchEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchEditingProjectResponseBody(name='body'),
}

/**
 * @summary Queries online editing projects by creation time and status.
 *
 * @param request SearchEditingProjectRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchEditingProjectResponse
 */
async function searchEditingProjectWithOptions(request: SearchEditingProjectRequest, runtime: Util.RuntimeOptions): SearchEditingProjectResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.createSource)) {
    query['CreateSource'] = request.createSource;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.projectType)) {
    query['ProjectType'] = request.projectType;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  if (!Util.isUnset(request.templateType)) {
    query['TemplateType'] = request.templateType;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SearchEditingProject',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries online editing projects by creation time and status.
 *
 * @param request SearchEditingProjectRequest
 * @return SearchEditingProjectResponse
 */
async function searchEditingProject(request: SearchEditingProjectRequest): SearchEditingProjectResponse {
  var runtime = new Util.RuntimeOptions{};
  return searchEditingProjectWithOptions(request, runtime);
}

model SearchIndexJobRerunRequest {
  mediaIds?: string(name='MediaIds', description='The ID of the media asset. Separate multiple IDs with commas (,).

This parameter is required.', example='******b48fb04483915d4f2cd8******,******c48fb37407365d4f2cd8******'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='test-1'),
  task?: string(name='Task', description='The type of the job. Separate multiple types with commas (,).

*   aiLabel: smart tagging.
*   face: face recognition.
*   mm: large visual model.', example='AiLabel,Face,Mm'),
}

model SearchIndexJobRerunResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  data?: {
    mediaIdsNoExist?: [ string ](name='MediaIdsNoExist', description='The media asset IDs that do not exist.'),
  }(name='Data', description='The response data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request is successful. Valid values:

*   true
*   false', example='true'),
}

model SearchIndexJobRerunResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchIndexJobRerunResponseBody(name='body'),
}

/**
 * @summary Re-analyzes the search index jobs of media assets. You can re-run the search index jobs of up to 20 media assets in each request.
 *
 * @param request SearchIndexJobRerunRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchIndexJobRerunResponse
 */
async function searchIndexJobRerunWithOptions(request: SearchIndexJobRerunRequest, runtime: Util.RuntimeOptions): SearchIndexJobRerunResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaIds)) {
    query['MediaIds'] = request.mediaIds;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  if (!Util.isUnset(request.task)) {
    query['Task'] = request.task;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SearchIndexJobRerun',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Re-analyzes the search index jobs of media assets. You can re-run the search index jobs of up to 20 media assets in each request.
 *
 * @param request SearchIndexJobRerunRequest
 * @return SearchIndexJobRerunResponse
 */
async function searchIndexJobRerun(request: SearchIndexJobRerunRequest): SearchIndexJobRerunResponse {
  var runtime = new Util.RuntimeOptions{};
  return searchIndexJobRerunWithOptions(request, runtime);
}

model SearchMediaRequest {
  entityId?: string(name='EntityId', description='The ID of the entity.', example='2d3bf1e35a1e42b5ab338d701efa7603'),
  match?: string(name='Match', description='The filter conditions. For more information about the parameter syntax
<props="china">, see [Media asset search protocols](https://help.aliyun.com/document_detail/2584256.html).'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='20'),
  scrollToken?: string(name='ScrollToken', description='The pagination identifier. The value can be up to 32 characters in length. The first time you call this operation for each new search, you do not need to specify this parameter. The value of this parameter is returned each time data records that meet the specified filter condition are found. The value is used to record the current position of queried data. Record the returned parameter value and set this parameter according to the following requirements during the next search: If you need to traverse all data that meets the filter criteria, you must set the ScrollToken parameter. If the value of the PageNo parameter exceeds 200, we recommend that you set this parameter to optimize search performance. You can only page backward. You can page a maximum of 1,000 entries in an operation.', example='F8C4F642184DBDA5D93907A70AAE****'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='test-1'),
  sortBy?: string(name='SortBy', description='The sort field and order. Separate multiple parameters with commas (,).', example='utcCreate:Desc, utcModified:Desc'),
}

model SearchMediaResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaInfoList?: [ 
    {
      aiData?: {
        aiLabelInfo?: [ 
          {
            category?: string(name='Category', description='The category.'),
            faceId?: string(name='FaceId', description='The face ID.', example='5FE19530C7A422197535FE74F5DB2B9F'),
            labelId?: string(name='LabelId', description='The ID of the entity.', example='10310250338'),
            labelName?: string(name='LabelName', description='The name of the entity.'),
            labelType?: string(name='LabelType', description='The type of the tag.'),
            occurrences?: [ 
              {
                content?: string(name='Content', description='The text content.'),
                finegrainId?: string(name='FinegrainId', description='The fine-grained ID of the entity.', example='10310250338'),
                finegrainName?: string(name='FinegrainName', description='The fine-grained name of the entity.'),
                from?: double(name='From', description='The start time of the clip.', example='1.4'),
                image?: string(name='Image', description='The optimal face image encoded in Base64.', example='99C64F6287'),
                score?: double(name='Score', description='The score.', example='0.75287705'),
                tableBatchSeqId?: string(name='TableBatchSeqId', description='The sequence ID of the vector table.', example='85010D1'),
                to?: double(name='To', description='The end time of the clip.', example='2.5'),
                tracks?: [ 
                  {
                    position?: string(name='Position', description='The coordinates of the bounding box.', example='468.0;67.0;615.0;267.0'),
                    size?: double(name='Size', description='The size of the bounding box.', example='50.2'),
                    timestamp?: double(name='Timestamp', description='The timestamp of the track.', example='1.4'),
                  }
                ](name='Tracks', description='The track sequence.'),
                clipId?: string(name='clipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB2B9F'),
              }
            ](name='Occurrences', description='The clips.'),
            source?: string(name='Source', description='The source.', example='vision'),
          }
        ](name='AiLabelInfo', description='The tags of the intelligent AI job.'),
        asrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB2B9F'),
            content?: string(name='Content', description='The text content.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='AsrInfo', description='The information about audio files.'),
        ocrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB2B9F'),
            content?: string(name='Content', description='The text content.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='OcrInfo', description='The subtitles.'),
      }(name='AiData', description='The details of the intelligent AI job.'),
      aiRoughData?: {
        aiCategory?: string(name='AiCategory', description='TV Series', example='TV series'),
        aiJobId?: string(name='AiJobId', description='The ID of the AI job.', example='cd35b0b0025f71edbfcb472190a9xxxx'),
        result?: string(name='Result', description='The results of the AI job.', example='http://xxxx.json'),
        saveType?: string(name='SaveType', description='The save type.', example='TEXT'),
        status?: string(name='Status', description='The data status.', example='SaveSuccess'),
      }(name='AiRoughData', description='The description of the AI job.'),
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate of the file.', example='1912.13'),
            createTime?: string(name='CreateTime', description='The time when the file was created.', example='2022-05-30T02:02:17Z'),
            duration?: string(name='Duration', description='The duration of the file.', example='60.00000'),
            fileName?: string(name='FileName', description='The name of the file.', example='164265080291300080527050.wav'),
            fileSize?: string(name='FileSize', description='The size of the file in bytes.', example='324784'),
            fileStatus?: string(name='FileStatus', description='The status of the file.', example='Normal'),
            fileType?: string(name='FileType', description='The type of the file.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='https://outin-d3f4681ddfd911ec99a600163e1403e7.oss-cn-shanghai.aliyuncs.com/sv/23d5cdd1-18180984899/23d5cdd1-18180984899.mp4'),
            formatName?: string(name='FormatName', description='The encapsulation format of the file.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height of the file.', example='480'),
            modifiedTime?: string(name='ModifiedTime', description='The time when the file was last modified.', example='2021-12-10T12:19Z'),
            region?: string(name='Region', description='The region in which the file is stored.', example='cn-beijing'),
            width?: string(name='Width', description='The width of the file.', example='1920'),
          }(name='FileBasicInfo', description='The basic information about the file, such as the duration and size.'),
        }
      ](name='FileInfoList', description='The information about the files.'),
      indexStatusList?: [ 
        {
          indexStatus?: string(name='IndexStatus', example='Success'),
          indexType?: string(name='IndexType', example='mm'),
        }
      ](name='IndexStatusList'),
      mediaBasicInfo?: {
        biz?: string(name='Biz', description='The business to which the media asset belongs.', example='IMS'),
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='opening'),
        cateId?: long(name='CateId', description='The ID of the category.', example='44'),
        cateName?: string(name='CateName', description='The name of the category.'),
        category?: string(name='Category', description='The category of the media asset.', example='image'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='https://dtlive-bj.oss-cn-beijing.aliyuncs.com/cover/e694372e-4f5b-4821-ae09-efd064f27b63_large_cover_url.jpg'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-01T19:48Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-01T19:48Z'),
        description?: string(name='Description', description='The description of the media asset.'),
        inputURL?: string(name='InputURL', description='The address of the media asset that is waiting to be registered.', example='oss://clipres/longvideo/material/voice/prod/20220418/07d7c799f6054dc3bbef250854cf84981650248140427'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='132bd600fc3c71ec99476732a78f6402'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='tags,tags2'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was modified.', example='2020-12-01T19:48Z'),
        referenceId?: string(name='ReferenceId', description='The custom ID of the media asset. The ID is a string that contains 6 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are supported. Each custom ID is unique.', example='123-123'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='[{"bucket":"example-bucket","count":"3","iceJobId":"******f48f0e4154976b2b8c45******","location":"oss-cn-beijing","snapshotRegular":"example.jpg","templateId":"******e6a6440b29eb60bd7c******"}]'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The image sprite of the media asset', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
        status?: string(name='Status', description='The state of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        uploadSource?: string(name='UploadSource', description='The upload source of the media asset.', example='general'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information about the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='3b187b3620c8490886cfc2a9578c3ce6'),
    }
  ](name='MediaInfoList', description='The media assets that meet the requirements.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='6F61C357-ACC0-57FB-876E-D58795335E59'),
  scrollToken?: string(name='ScrollToken', description='The pagination identifier.', example='F8C4F642184DBDA5D93907A70AAE****'),
  success?: string(name='Success', description='Indicates whether the request was successful.', example='True'),
  total?: long(name='Total', description='The total number of media assets that meet the conditions.', example='163'),
}

model SearchMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaResponseBody(name='body'),
}

/**
 * @summary Queries information about media assets based on the request parameters.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchMediaResponse
 */
async function searchMediaWithOptions(request: SearchMediaRequest, runtime: Util.RuntimeOptions): SearchMediaResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  if (!Util.isUnset(request.match)) {
    query['Match'] = request.match;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.scrollToken)) {
    query['ScrollToken'] = request.scrollToken;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SearchMedia',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries information about media assets based on the request parameters.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaRequest
 * @return SearchMediaResponse
 */
async function searchMedia(request: SearchMediaRequest): SearchMediaResponse {
  var runtime = new Util.RuntimeOptions{};
  return searchMediaWithOptions(request, runtime);
}

model SearchMediaByAILabelRequest {
  matchingMode?: string(name='MatchingMode'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. This parameter is required if you want to query media asset clips.', example='****c469e944b5a856828dc2****'),
  mediaType?: string(name='MediaType', description='The type of the media assets. Valid values:

*   image
*   video
*   audio', example='video'),
  multimodalSearchType?: string(name='MultimodalSearchType', description='The type of query. Valid values:

*   PersonName: queries media assets based on character names.
*   Ocr: queries media assets based on subtitles.
*   AiCategory: queries media assets based on AI categories.
*   FullSearch (default): queries all media assets.', example='Ocr'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='20'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test-1'),
  sortBy?: string(name='SortBy', description='The sorting method of the results. Valid values:

*   CreationTime:Desc (default): sorts results in reverse chronological order.
*   CreationTime:Asc: sorts results in chronological order.', example='CreationTime:Desc'),
  specificSearch?: boolean(name='SpecificSearch', description='Specifies whether to query media asset clips. Valid values:

*   true
*   false', example='true'),
  text?: string(name='Text', description='The content that you want to query.'),
}

model SearchMediaByAILabelResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaList?: [ 
    {
      aiData?: {
        aiLabelInfo?: [ 
          {
            category?: string(name='Category', description='The category.'),
            faceId?: string(name='FaceId', description='The ID of the face.', example='5FE19530C7A422197535FE74F5DB****'),
            labelId?: string(name='LabelId', description='The ID of the entity.', example='103102503**'),
            labelName?: string(name='LabelName', description='The name of the entity.'),
            labelType?: string(name='LabelType', description='The type of the tag.'),
            occurrences?: [ 
              {
                clipId?: string(name='ClipId', description='The ID of the clip.', example='158730355E4B82257D8AA1583A58****'),
                content?: string(name='Content', description='The content of the text.'),
                finegrainId?: string(name='FinegrainId', description='The fine-grained ID of the entity.', example='103102503**'),
                finegrainName?: string(name='FinegrainName', description='The fine-grained name of the entity.'),
                from?: double(name='From', description='The start time of the clip.', example='1.4'),
                image?: string(name='Image', description='The image that contains the most face information.', example='https://service-****-public.oss-cn-hangzhou.aliyuncs.com/1563457****438522/service-image/f788974f-9595-43b2-a478-7c7a1afb****.jpg'),
                score?: double(name='Score', description='The score.', example='0.75287705'),
                tableBatchSeqId?: string(name='TableBatchSeqId', description='The sequence ID of the vector table.', example='85010D1**'),
                to?: double(name='To', description='The end time of the clip.', example='2.5'),
                tracks?: [ 
                  {
                    position?: string(name='Position', description='The coordinates of the bounding box.', example='468.0;67.0;615.0;267.0'),
                    size?: double(name='Size', description='The size of the bounding box.', example='50'),
                    timestamp?: double(name='Timestamp', description='The timestamp of the track.', example='1.4'),
                  }
                ](name='Tracks', description='The tracks.'),
              }
            ](name='Occurrences', description='The information about the clips.'),
            source?: string(name='Source', description='The source.', example='vision'),
          }
        ](name='AiLabelInfo', description='The tags of the AI job.'),
        asrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB****'),
            content?: string(name='Content', description='The content of the audio.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='AsrInfo', description='The information about audio files.'),
        ocrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB****'),
            content?: string(name='Content', description='The content of the text.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='OcrInfo', description='The information about subtitle files.'),
      }(name='AiData', description='The details of the AI job.'),
      appId?: string(name='AppId', description='The ID of the application. Default value: app-1000000.', example='app-1000000'),
      coverUrl?: string(name='CoverUrl', description='The URL of the thumbnail.', example='http://example.aliyundoc.com/snapshot/****.jpg?auth_key=1498476426-0-0-f00b9455c49a423ce69cf4e27333****'),
      creationTime?: string(name='CreationTime', description='The time when the media asset was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:15:50Z'),
      description?: string(name='Description', description='The description of the media asset.'),
      duration?: float(name='Duration', description='The duration. Unit: seconds.', example='12.2'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='1c6ce34007d571ed94667630a6bc****'),
      modificationTime?: string(name='ModificationTime', description='The time when the media asset was updated. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:15:50Z'),
      size?: long(name='Size', description='The size of the source file. Unit: bytes.', example='10897890'),
      snapshots?: [ string ](name='Snapshots', description='The array of video snapshot URLs.'),
      status?: string(name='Status', description='The status of the video.

Valid values:

*   PrepareFail
*   UploadFail
*   Init
*   UploadSucc
*   Transcoding
*   TranscodeFail
*   Deleted
*   Normal
*   Uploading
*   Preparing
*   Blocked
*   Checking', example='Normal'),
      storageLocation?: string(name='StorageLocation', description='The storage address.', example='out-****.oss-cn-shanghai.aliyuncs.com'),
      tags?: string(name='Tags', description='The tags of the media asset.'),
      title?: string(name='Title', description='The title of the media asset.'),
    }
  ](name='MediaList', description='The media assets that contain the specified content.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request was successful.', example='true'),
  total?: long(name='Total', description='The total number of audio and video files that meet the conditions.', example='30'),
}

model SearchMediaByAILabelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByAILabelResponseBody(name='body'),
}

/**
 * @summary Queries media assets based on character names, subtitles, or AI categories.
 *
 * @description You can call this operation to query media assets or media asset clips based on character names, subtitles, or AI categories.
 *
 * @param request SearchMediaByAILabelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchMediaByAILabelResponse
 */
async function searchMediaByAILabelWithOptions(request: SearchMediaByAILabelRequest, runtime: Util.RuntimeOptions): SearchMediaByAILabelResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.matchingMode)) {
    query['MatchingMode'] = request.matchingMode;
  }
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!Util.isUnset(request.multimodalSearchType)) {
    query['MultimodalSearchType'] = request.multimodalSearchType;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!Util.isUnset(request.specificSearch)) {
    query['SpecificSearch'] = request.specificSearch;
  }
  if (!Util.isUnset(request.text)) {
    query['Text'] = request.text;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SearchMediaByAILabel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries media assets based on character names, subtitles, or AI categories.
 *
 * @description You can call this operation to query media assets or media asset clips based on character names, subtitles, or AI categories.
 *
 * @param request SearchMediaByAILabelRequest
 * @return SearchMediaByAILabelResponse
 */
async function searchMediaByAILabel(request: SearchMediaByAILabelRequest): SearchMediaByAILabelResponse {
  var runtime = new Util.RuntimeOptions{};
  return searchMediaByAILabelWithOptions(request, runtime);
}

model SearchMediaByFaceRequest {
  entityId?: string(name='EntityId', description='The ID of the entity.', example='2d3bf1e35a1e42b5ab338d701efa****'),
  faceSearchToken?: string(name='FaceSearchToken', description='The token that is used to identify the query. You can use this parameter in the SearchMediaClipByFace operation to specify the same query conditions.

This parameter is required.', example='zxtest-huangxuan-2023-3-7-V1'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

*   image
*   video', example='video'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10'),
  personImageUrl?: string(name='PersonImageUrl', description='The URL of the face image.

This parameter is required.', example='https://****.oss-cn-shanghai.aliyuncs.com/input/huangxuan****.jpg'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
}

model SearchMediaByFaceResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaInfoList?: [ 
    {
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='3b187b3620c8490886cfc2a9578c****'),
    }
  ](name='MediaInfoList', description='The media assets that meet the conditions.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='7CA7D615-CFB1-5437-9A12-2D185C3EE6CB'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
  total?: long(name='Total', description='The total number of data records that meet the specified filter condition.', example='163'),
}

model SearchMediaByFaceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByFaceResponseBody(name='body'),
}

/**
 * @summary Queries the information about media assets that are related to a specific face.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaByFaceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchMediaByFaceResponse
 */
async function searchMediaByFaceWithOptions(request: SearchMediaByFaceRequest, runtime: Util.RuntimeOptions): SearchMediaByFaceResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  if (!Util.isUnset(request.faceSearchToken)) {
    query['FaceSearchToken'] = request.faceSearchToken;
  }
  if (!Util.isUnset(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.personImageUrl)) {
    query['PersonImageUrl'] = request.personImageUrl;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SearchMediaByFace',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about media assets that are related to a specific face.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaByFaceRequest
 * @return SearchMediaByFaceResponse
 */
async function searchMediaByFace(request: SearchMediaByFaceRequest): SearchMediaByFaceResponse {
  var runtime = new Util.RuntimeOptions{};
  return searchMediaByFaceWithOptions(request, runtime);
}

model SearchMediaByHybridRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset. The details of the media asset are returned.', example='****c469e944b5a856828dc2****'),
  mediaType?: string(name='MediaType', example='video'),
  pageNo?: int32(name='PageNo', example='1'),
  pageSize?: int32(name='PageSize', example='20'),
  searchLibName?: string(name='SearchLibName', example='test-1'),
  text?: string(name='Text'),
}

model SearchMediaByHybridResponseBody = {
  code?: string(name='Code', example='200'),
  mediaList?: [ 
    {
      clipInfo?: [ 
        {
          from?: double(name='From', example='2'),
          score?: double(name='Score', example='0.99'),
          to?: double(name='To', example='4'),
        }
      ](name='ClipInfo'),
      mediaId?: string(name='MediaId', example='a18936e0e28771edb59ae6f6f47a****'),
    }
  ](name='MediaList'),
  requestId?: string(name='RequestId', example='******3B-0E1A-586A-AC29-742247******'),
  success?: string(name='Success', example='true'),
  total?: long(name='Total', example='30'),
}

model SearchMediaByHybridResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByHybridResponseBody(name='body'),
}

/**
 * @summary Queries media assets by using the hybrid search feature. This operation allows you to search for media assets by using natural language based on intelligent tag text search and the search capabilities of large language models (LLMs). This implements multimodal retrieval.
 *
 * @param request SearchMediaByHybridRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchMediaByHybridResponse
 */
async function searchMediaByHybridWithOptions(request: SearchMediaByHybridRequest, runtime: Util.RuntimeOptions): SearchMediaByHybridResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  if (!Util.isUnset(request.text)) {
    query['Text'] = request.text;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SearchMediaByHybrid',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries media assets by using the hybrid search feature. This operation allows you to search for media assets by using natural language based on intelligent tag text search and the search capabilities of large language models (LLMs). This implements multimodal retrieval.
 *
 * @param request SearchMediaByHybridRequest
 * @return SearchMediaByHybridResponse
 */
async function searchMediaByHybrid(request: SearchMediaByHybridRequest): SearchMediaByHybridResponse {
  var runtime = new Util.RuntimeOptions{};
  return searchMediaByHybridWithOptions(request, runtime);
}

model SearchMediaByMultimodalRequest {
  mediaType?: string(name='MediaType', description='The type of the media assets.

Valid values:

*   image
*   video (default)', example='video'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='test-1'),
  text?: string(name='Text', description='The content that you want to query. You can describe the content in natural language.'),
}

model SearchMediaByMultimodalResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaList?: [ 
    {
      clipInfo?: [ 
        {
          from?: double(name='From', description='The start time of the clip.', example='2'),
          score?: double(name='Score', description='The score.', example='1.2'),
          to?: double(name='To', description='The end time of the clip.', example='4'),
        }
      ](name='ClipInfo', description='The information about the clip.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='a18936e0e28771edb59ae6f6f47a****'),
    }
  ](name='MediaList', description='The media assets that contain the specified content.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
  total?: long(name='Total', description='The total number of data records that meet the specified filter condition.', example='20'),
}

model SearchMediaByMultimodalResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByMultimodalResponseBody(name='body'),
}

/**
 * @summary Queries media assets by using the large visual model. You can use natural language for the query.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaByMultimodalRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchMediaByMultimodalResponse
 */
async function searchMediaByMultimodalWithOptions(request: SearchMediaByMultimodalRequest, runtime: Util.RuntimeOptions): SearchMediaByMultimodalResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  if (!Util.isUnset(request.text)) {
    query['Text'] = request.text;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SearchMediaByMultimodal',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries media assets by using the large visual model. You can use natural language for the query.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaByMultimodalRequest
 * @return SearchMediaByMultimodalResponse
 */
async function searchMediaByMultimodal(request: SearchMediaByMultimodalRequest): SearchMediaByMultimodalResponse {
  var runtime = new Util.RuntimeOptions{};
  return searchMediaByMultimodalWithOptions(request, runtime);
}

model SearchMediaClipByFaceRequest {
  entityId?: string(name='EntityId', description='The ID of the entity.', example='2d3bf1e35a1e42b5ab338d701efa****'),
  faceSearchToken?: string(name='FaceSearchToken', description='The value of this parameter is the same as that of the FaceSearchToken parameter in the SearchMediaByFace request. This specifies to return media asset clips that meet the same query conditions.

This parameter is required.', example='zxtest-huangxuan-2023-3-7-V1'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='3b187b3620c8490886cfc2a9578c****'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
}

model SearchMediaClipByFaceResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaClipList?: [ 
    {
      category?: string(name='Category', description='The type of the character. Valid values: celebrity sensitive politician custom unknown', example='celebrity'),
      entityId?: string(name='EntityId', description='The ID of the entity, which is the same as the entity ID returned in tag analysis.', example='1031025****'),
      labelName?: string(name='LabelName', description='The name of the entity.'),
      occurrencesInfos?: [ 
        {
          endTime?: float(name='EndTime', description='The end time of the clip. Unit: seconds. The value is of the Float type.', example='69.06635'),
          expression?: string(name='Expression'),
          startTime?: float(name='StartTime', description='The start time of the clip. Unit: seconds. The value is of the Float type.', example='61.066353'),
          trackData?: [ 
            {
              boxPosition?: {
                h?: int32(name='H', description='The height of the rectangle frame. Unit: pixels.', example='168'),
                w?: int32(name='W', description='The width of the rectangle frame. Unit: pixels.', example='128'),
                x?: int32(name='X', description='The x-axis coordinate of the upper-left corner. Unit: pixels.', example='517'),
                y?: int32(name='Y', description='The y-axis coordinate of the upper-left corner. Unit: pixels.', example='409'),
              }(name='BoxPosition', description='The coordinates of the face.'),
              timestamp?: float(name='Timestamp', description='The timestamp when the face appears in the clip. Unit: seconds. The value is of the Float type.', example='62.03302'),
            }
          ](name='TrackData', description='The information about the face in the clip.'),
        }
      ](name='OccurrencesInfos', description='The information about clips related to the face.'),
      score?: float(name='Score', description='The score of the clip. The value is of the Float type. The value is in the range of [0,1].', example='0.99041677'),
    }
  ](name='MediaClipList', description='The media asset clips that meet the requirements.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='E44FFACD-9E90-555A-A09A-6FD3B7335E39'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values: true and false.', example='true'),
  total?: long(name='Total', description='The total number of media asset clips that meet the conditions.', example='5'),
}

model SearchMediaClipByFaceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaClipByFaceResponseBody(name='body'),
}

/**
 * @summary Queries the information about media asset clips that are related to a specific face based on the response to the SearchMediaByFace operation.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaClipByFaceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchMediaClipByFaceResponse
 */
async function searchMediaClipByFaceWithOptions(request: SearchMediaClipByFaceRequest, runtime: Util.RuntimeOptions): SearchMediaClipByFaceResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  if (!Util.isUnset(request.faceSearchToken)) {
    query['FaceSearchToken'] = request.faceSearchToken;
  }
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SearchMediaClipByFace',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Queries the information about media asset clips that are related to a specific face based on the response to the SearchMediaByFace operation.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaClipByFaceRequest
 * @return SearchMediaClipByFaceResponse
 */
async function searchMediaClipByFace(request: SearchMediaClipByFaceRequest): SearchMediaClipByFaceResponse {
  var runtime = new Util.RuntimeOptions{};
  return searchMediaClipByFaceWithOptions(request, runtime);
}

model SearchPublicMediaInfoRequest {
  authorized?: boolean(name='Authorized', example='true'),
  dynamicMetaDataMatchFields?: string(name='DynamicMetaDataMatchFields', example='"ApprovalStatus=\\\\"Available\\\\"&amp;MaterialBags=\\\\"boutiquemusic\\\\"&amp;Mood=\\\\"Nervous\\\\""'),
  entityId?: string(name='EntityId', example='Copyright_Music'),
  favorite?: boolean(name='Favorite', example='true'),
  mediaIds?: string(name='MediaIds', example='****20b48fb04483915d4f2cd8ac****,****15d4a4b0448391508f2cb486****'),
  pageNo?: int32(name='PageNo', example='1'),
  pageSize?: int32(name='PageSize', example='10'),
  sortBy?: string(name='SortBy', example='UsageCount:Desc,UnitPrice:Asc'),
}

model SearchPublicMediaInfoResponseBody = {
  publicMediaInfos?: [ 
    {
      authorized?: boolean(name='Authorized', example='true'),
      favorite?: boolean(name='Favorite', example='true'),
      mediaInfo?: {
        dynamicMetaData?: {
          data?: string(name='Data', example='"{\\\\"AuditionUrl\\\\": \\\\"http://xxx\\\\", \\\\"AuditionCount\\\\": 3...}"'),
          type?: string(name='Type', example='system'),
        }(name='DynamicMetaData'),
        mediaBasicInfo?: {
          businessType?: string(name='BusinessType', example='general'),
          category?: string(name='Category', example='category'),
          coverURL?: string(name='CoverURL', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
          createTime?: string(name='CreateTime', example='2020-12-26T06:04:49Z'),
          deletedTime?: string(name='DeletedTime', example='2020-12-29T06:04:49Z'),
          description?: string(name='Description', example='description'),
          mediaId?: string(name='MediaId', description='MediaId', example='icepublic-****87b921bb4a55908a72a0537e****'),
          mediaTags?: string(name='MediaTags'),
          mediaType?: string(name='MediaType', example='audio'),
          modifiedTime?: string(name='ModifiedTime', example='2020-12-26T06:04:50Z'),
          source?: string(name='Source', example='oss'),
          spriteImages?: string(name='SpriteImages', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
          status?: string(name='Status', example='Normal'),
          title?: string(name='Title', example='title'),
          userData?: string(name='UserData', example='userDataTest'),
        }(name='MediaBasicInfo', description='BasicInfo'),
        mediaId?: string(name='MediaId', example='icepublic-****87b921bb4a55908a72a0537e****'),
      }(name='MediaInfo'),
      remainingAuthTime?: string(name='RemainingAuthTime', example='100'),
    }
  ](name='PublicMediaInfos'),
  requestId?: string(name='RequestId', example='****3CFB-2767-54FD-B311-BD15A4C1****'),
  totalCount?: long(name='TotalCount', example='100'),
}

model SearchPublicMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchPublicMediaInfoResponseBody(name='body'),
}

/**
 * @summary 搜索公共媒资信息
 *
 * @param request SearchPublicMediaInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchPublicMediaInfoResponse
 */
async function searchPublicMediaInfoWithOptions(request: SearchPublicMediaInfoRequest, runtime: Util.RuntimeOptions): SearchPublicMediaInfoResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.authorized)) {
    query['Authorized'] = request.authorized;
  }
  if (!Util.isUnset(request.dynamicMetaDataMatchFields)) {
    query['DynamicMetaDataMatchFields'] = request.dynamicMetaDataMatchFields;
  }
  if (!Util.isUnset(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  if (!Util.isUnset(request.favorite)) {
    query['Favorite'] = request.favorite;
  }
  if (!Util.isUnset(request.mediaIds)) {
    query['MediaIds'] = request.mediaIds;
  }
  if (!Util.isUnset(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SearchPublicMediaInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 搜索公共媒资信息
 *
 * @param request SearchPublicMediaInfoRequest
 * @return SearchPublicMediaInfoResponse
 */
async function searchPublicMediaInfo(request: SearchPublicMediaInfoRequest): SearchPublicMediaInfoResponse {
  var runtime = new Util.RuntimeOptions{};
  return searchPublicMediaInfoWithOptions(request, runtime);
}

model SendAIAgentDataChannelMessageRequest {
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  message?: string(name='Message', description='This parameter is required.', example='{"key":"value"}'),
}

model SendAIAgentDataChannelMessageResponseBody = {
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model SendAIAgentDataChannelMessageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendAIAgentDataChannelMessageResponseBody(name='body'),
}

/**
 * @summary 向智能体通话发送datachannel消息
 *
 * @param request SendAIAgentDataChannelMessageRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SendAIAgentDataChannelMessageResponse
 */
async function sendAIAgentDataChannelMessageWithOptions(request: SendAIAgentDataChannelMessageRequest, runtime: Util.RuntimeOptions): SendAIAgentDataChannelMessageResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  if (!Util.isUnset(request.message)) {
    query['Message'] = request.message;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SendAIAgentDataChannelMessage',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 向智能体通话发送datachannel消息
 *
 * @param request SendAIAgentDataChannelMessageRequest
 * @return SendAIAgentDataChannelMessageResponse
 */
async function sendAIAgentDataChannelMessage(request: SendAIAgentDataChannelMessageRequest): SendAIAgentDataChannelMessageResponse {
  var runtime = new Util.RuntimeOptions{};
  return sendAIAgentDataChannelMessageWithOptions(request, runtime);
}

model SendAIAgentSpeechRequest {
  enableInterrupt?: boolean(name='EnableInterrupt', example='true'),
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  text?: string(name='Text', description='This parameter is required.'),
}

model SendAIAgentSpeechResponseBody = {
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model SendAIAgentSpeechResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendAIAgentSpeechResponseBody(name='body'),
}

/**
 * @summary 用来立即让某个智能体实例播报指定的文本。
 *
 * @param request SendAIAgentSpeechRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SendAIAgentSpeechResponse
 */
async function sendAIAgentSpeechWithOptions(request: SendAIAgentSpeechRequest, runtime: Util.RuntimeOptions): SendAIAgentSpeechResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.enableInterrupt)) {
    query['EnableInterrupt'] = request.enableInterrupt;
  }
  if (!Util.isUnset(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  if (!Util.isUnset(request.text)) {
    query['Text'] = request.text;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SendAIAgentSpeech',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 用来立即让某个智能体实例播报指定的文本。
 *
 * @param request SendAIAgentSpeechRequest
 * @return SendAIAgentSpeechResponse
 */
async function sendAIAgentSpeech(request: SendAIAgentSpeechRequest): SendAIAgentSpeechResponse {
  var runtime = new Util.RuntimeOptions{};
  return sendAIAgentSpeechWithOptions(request, runtime);
}

model SendLiveSnapshotJobCommandRequest {
  command?: string(name='Command', description='The operation command.

Valid values:

*   stop
*   restart
*   start

This parameter is required.', example='start'),
  jobId?: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model SendLiveSnapshotJobCommandResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SendLiveSnapshotJobCommandResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendLiveSnapshotJobCommandResponseBody(name='body'),
}

/**
 * @summary Sends a command to process a live stream snapshot job.
 *
 * @param request SendLiveSnapshotJobCommandRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SendLiveSnapshotJobCommandResponse
 */
async function sendLiveSnapshotJobCommandWithOptions(request: SendLiveSnapshotJobCommandRequest, runtime: Util.RuntimeOptions): SendLiveSnapshotJobCommandResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.command)) {
    body['Command'] = request.command;
  }
  if (!Util.isUnset(request.jobId)) {
    body['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'SendLiveSnapshotJobCommand',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Sends a command to process a live stream snapshot job.
 *
 * @param request SendLiveSnapshotJobCommandRequest
 * @return SendLiveSnapshotJobCommandResponse
 */
async function sendLiveSnapshotJobCommand(request: SendLiveSnapshotJobCommandRequest): SendLiveSnapshotJobCommandResponse {
  var runtime = new Util.RuntimeOptions{};
  return sendLiveSnapshotJobCommandWithOptions(request, runtime);
}

model SendLiveTranscodeJobCommandRequest {
  command?: string(name='Command', description='The operation command. Only the stop command is supported. This command is used to stop a transcoding job.

This parameter is required.', example='stop'),
  jobId?: string(name='JobId', description='The ID of the transcoding job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model SendLiveTranscodeJobCommandResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model SendLiveTranscodeJobCommandResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendLiveTranscodeJobCommandResponseBody(name='body'),
}

/**
 * @summary Sends a command to process a live stream transcoding job.
 *
 * @param request SendLiveTranscodeJobCommandRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SendLiveTranscodeJobCommandResponse
 */
async function sendLiveTranscodeJobCommandWithOptions(request: SendLiveTranscodeJobCommandRequest, runtime: Util.RuntimeOptions): SendLiveTranscodeJobCommandResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.command)) {
    query['Command'] = request.command;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SendLiveTranscodeJobCommand',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Sends a command to process a live stream transcoding job.
 *
 * @param request SendLiveTranscodeJobCommandRequest
 * @return SendLiveTranscodeJobCommandResponse
 */
async function sendLiveTranscodeJobCommand(request: SendLiveTranscodeJobCommandRequest): SendLiveTranscodeJobCommandResponse {
  var runtime = new Util.RuntimeOptions{};
  return sendLiveTranscodeJobCommandWithOptions(request, runtime);
}

model SetContentAnalyzeConfigRequest {
  auto?: boolean(name='Auto', example='true'),
  saveType?: string(name='SaveType', example='TEXT,FACE'),
  templateId?: string(name='TemplateId', example='S00000101-100070'),
}

model SetContentAnalyzeConfigResponseBody = {
  requestId?: string(name='RequestId', example='953CFD27-4A2C-54AD-857F-B79EF3A338E0'),
  success?: boolean(name='Success', example='true'),
}

model SetContentAnalyzeConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetContentAnalyzeConfigResponseBody(name='body'),
}

/**
 * @summary 设置内容分析搜索配置
 *
 * @param request SetContentAnalyzeConfigRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SetContentAnalyzeConfigResponse
 */
async function setContentAnalyzeConfigWithOptions(request: SetContentAnalyzeConfigRequest, runtime: Util.RuntimeOptions): SetContentAnalyzeConfigResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.auto)) {
    query['Auto'] = request.auto;
  }
  if (!Util.isUnset(request.saveType)) {
    query['SaveType'] = request.saveType;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SetContentAnalyzeConfig',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 设置内容分析搜索配置
 *
 * @param request SetContentAnalyzeConfigRequest
 * @return SetContentAnalyzeConfigResponse
 */
async function setContentAnalyzeConfig(request: SetContentAnalyzeConfigRequest): SetContentAnalyzeConfigResponse {
  var runtime = new Util.RuntimeOptions{};
  return setContentAnalyzeConfigWithOptions(request, runtime);
}

model SetDefaultCustomTemplateRequest {
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****d80e4e4044975745c14b****'),
}

model SetDefaultCustomTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model SetDefaultCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetDefaultCustomTemplateResponseBody(name='body'),
}

/**
 * @summary Sets a custom template as the default template.
 *
 * @param request SetDefaultCustomTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SetDefaultCustomTemplateResponse
 */
async function setDefaultCustomTemplateWithOptions(request: SetDefaultCustomTemplateRequest, runtime: Util.RuntimeOptions): SetDefaultCustomTemplateResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SetDefaultCustomTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Sets a custom template as the default template.
 *
 * @param request SetDefaultCustomTemplateRequest
 * @return SetDefaultCustomTemplateResponse
 */
async function setDefaultCustomTemplate(request: SetDefaultCustomTemplateRequest): SetDefaultCustomTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return setDefaultCustomTemplateWithOptions(request, runtime);
}

model SetDefaultStorageLocationRequest {
  bucket?: string(name='Bucket', example='oss-test-bucket'),
  path?: string(name='Path', example='ims/dir'),
  storageType?: string(name='StorageType', example='user_oss_bucket'),
}

model SetDefaultStorageLocationResponseBody = {
  requestId?: string(name='RequestId', example='******5A-CAAC-4850-A3AF-B74606******'),
  success?: boolean(name='Success', example='true'),
}

model SetDefaultStorageLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetDefaultStorageLocationResponseBody(name='body'),
}

/**
 * @summary 设置默认存储路径
 *
 * @param request SetDefaultStorageLocationRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SetDefaultStorageLocationResponse
 */
async function setDefaultStorageLocationWithOptions(request: SetDefaultStorageLocationRequest, runtime: Util.RuntimeOptions): SetDefaultStorageLocationResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.bucket)) {
    query['Bucket'] = request.bucket;
  }
  if (!Util.isUnset(request.path)) {
    query['Path'] = request.path;
  }
  if (!Util.isUnset(request.storageType)) {
    query['StorageType'] = request.storageType;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SetDefaultStorageLocation',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 设置默认存储路径
 *
 * @param request SetDefaultStorageLocationRequest
 * @return SetDefaultStorageLocationResponse
 */
async function setDefaultStorageLocation(request: SetDefaultStorageLocationRequest): SetDefaultStorageLocationResponse {
  var runtime = new Util.RuntimeOptions{};
  return setDefaultStorageLocationWithOptions(request, runtime);
}

model SetEventCallbackRequest {
  authKey?: string(name='AuthKey', description='The authentication key. The key can be up to 32 characters in length and must contain uppercase letters, lowercase letters, and digits. This parameter takes effect only if you set CallbackType to **HTTP**.', example='TestKey001'),
  authSwitch?: string(name='AuthSwitch', description='Specifies whether to enable callback authentication. This parameter takes effect only if you set CallbackType to **HTTP**. Valid values:

*   **on**
*   **off**', example='on'),
  callbackQueueName?: string(name='CallbackQueueName', description='The name of the Simple Message Queue (SMQ) queue in the region. The name must start with ice-callback-.', example='ice-callback-queue'),
  callbackType?: string(name='CallbackType', description='The callback method. Valid values:

*   **HTTP**
*   **MNS**', example='HTTP'),
  callbackURL?: string(name='CallbackURL', description='The callback URL. This parameter is required if you set CallbackType to **HTTP**. The callback URL cannot exceed 256 bytes in length. You can specify only one callback URL.', example='http://xxx.yyy/callback'),
  eventTypeList?: string(name='EventTypeList', description='The type of the callback event. You can specify multiple values separated with commas (,). ProduceMediaComplete: indicates that the editing and production task is complete.', example='ProduceMediaComplete'),
}

model SetEventCallbackResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the configuration was successful. Valid values: true and false.', example='true'),
}

model SetEventCallbackResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetEventCallbackResponseBody(name='body'),
}

/**
 * @summary Configures a callback method for one or more events.
 *
 * @param request SetEventCallbackRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SetEventCallbackResponse
 */
async function setEventCallbackWithOptions(request: SetEventCallbackRequest, runtime: Util.RuntimeOptions): SetEventCallbackResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.authKey)) {
    query['AuthKey'] = request.authKey;
  }
  if (!Util.isUnset(request.authSwitch)) {
    query['AuthSwitch'] = request.authSwitch;
  }
  if (!Util.isUnset(request.callbackQueueName)) {
    query['CallbackQueueName'] = request.callbackQueueName;
  }
  if (!Util.isUnset(request.callbackType)) {
    query['CallbackType'] = request.callbackType;
  }
  if (!Util.isUnset(request.callbackURL)) {
    query['CallbackURL'] = request.callbackURL;
  }
  if (!Util.isUnset(request.eventTypeList)) {
    query['EventTypeList'] = request.eventTypeList;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SetEventCallback',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Configures a callback method for one or more events.
 *
 * @param request SetEventCallbackRequest
 * @return SetEventCallbackResponse
 */
async function setEventCallback(request: SetEventCallbackRequest): SetEventCallbackResponse {
  var runtime = new Util.RuntimeOptions{};
  return setEventCallbackWithOptions(request, runtime);
}

model SetNotifyConfigRequest {
  AIAgentId?: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  callbackUrl?: string(name='CallbackUrl', example='http://customer.com/callback'),
  enableNotify?: boolean(name='EnableNotify', description='This parameter is required.', example='true'),
  eventTypes?: string(name='EventTypes', example='agent_start,agent_stop,error'),
  token?: string(name='Token', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx'),
}

model SetNotifyConfigResponseBody = {
  requestId?: string(name='RequestId', example='771A1414-27BF-53E6-AB73-EFCB*****ACF'),
}

model SetNotifyConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetNotifyConfigResponseBody(name='body'),
}

/**
 * @summary 更新回调配置
 *
 * @param request SetNotifyConfigRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SetNotifyConfigResponse
 */
async function setNotifyConfigWithOptions(request: SetNotifyConfigRequest, runtime: Util.RuntimeOptions): SetNotifyConfigResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.AIAgentId)) {
    query['AIAgentId'] = request.AIAgentId;
  }
  if (!Util.isUnset(request.callbackUrl)) {
    query['CallbackUrl'] = request.callbackUrl;
  }
  if (!Util.isUnset(request.enableNotify)) {
    query['EnableNotify'] = request.enableNotify;
  }
  if (!Util.isUnset(request.eventTypes)) {
    query['EventTypes'] = request.eventTypes;
  }
  if (!Util.isUnset(request.token)) {
    query['Token'] = request.token;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SetNotifyConfig',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 更新回调配置
 *
 * @param request SetNotifyConfigRequest
 * @return SetNotifyConfigResponse
 */
async function setNotifyConfig(request: SetNotifyConfigRequest): SetNotifyConfigResponse {
  var runtime = new Util.RuntimeOptions{};
  return setNotifyConfigWithOptions(request, runtime);
}

model StartAIAgentInstanceRequest {
  AIAgentId?: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  runtimeConfig?: AIAgentRuntimeConfig(name='RuntimeConfig', description='This parameter is required.'),
  templateConfig?: AIAgentTemplateConfig(name='TemplateConfig'),
  userData?: string(name='UserData', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
}

model StartAIAgentInstanceShrinkRequest {
  AIAgentId?: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  runtimeConfigShrink?: string(name='RuntimeConfig', description='This parameter is required.'),
  templateConfigShrink?: string(name='TemplateConfig'),
  userData?: string(name='UserData', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
}

model StartAIAgentInstanceResponseBody = {
  instanceId?: string(name='InstanceId', example='39f8e0bc005e4f309379701645f4****'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model StartAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartAIAgentInstanceResponseBody(name='body'),
}

/**
 * @summary 启动一个智能体实例，并加入通话。
 *
 * @param tmpReq StartAIAgentInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StartAIAgentInstanceResponse
 */
async function startAIAgentInstanceWithOptions(tmpReq: StartAIAgentInstanceRequest, runtime: Util.RuntimeOptions): StartAIAgentInstanceResponse {
  Util.validateModel(tmpReq);
  var request = new StartAIAgentInstanceShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.runtimeConfig)) {
    request.runtimeConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.runtimeConfig, 'RuntimeConfig', 'json');
  }
  if (!Util.isUnset(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.AIAgentId)) {
    query['AIAgentId'] = request.AIAgentId;
  }
  if (!Util.isUnset(request.runtimeConfigShrink)) {
    query['RuntimeConfig'] = request.runtimeConfigShrink;
  }
  if (!Util.isUnset(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'StartAIAgentInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 启动一个智能体实例，并加入通话。
 *
 * @param request StartAIAgentInstanceRequest
 * @return StartAIAgentInstanceResponse
 */
async function startAIAgentInstance(request: StartAIAgentInstanceRequest): StartAIAgentInstanceResponse {
  var runtime = new Util.RuntimeOptions{};
  return startAIAgentInstanceWithOptions(request, runtime);
}

model StartRtcRobotInstanceRequest {
  authToken?: string(name='AuthToken', description='This parameter is required.', example='**********'),
  channelId?: string(name='ChannelId', description='This parameter is required.', example='testId'),
  config?: {
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt', example='true'),
    greeting?: string(name='Greeting'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    voiceId?: string(name='VoiceId', example='zhixiaoxia'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
  }(name='Config'),
  robotId?: string(name='RobotId', description='This parameter is required.', example='ca28b08ad3464ebcb42e5c0f7c6d2e89'),
  userData?: string(name='UserData', example='{}'),
  userId?: string(name='UserId', description='This parameter is required.', example='my-robot'),
}

model StartRtcRobotInstanceShrinkRequest {
  authToken?: string(name='AuthToken', description='This parameter is required.', example='**********'),
  channelId?: string(name='ChannelId', description='This parameter is required.', example='testId'),
  configShrink?: string(name='Config'),
  robotId?: string(name='RobotId', description='This parameter is required.', example='ca28b08ad3464ebcb42e5c0f7c6d2e89'),
  userData?: string(name='UserData', example='{}'),
  userId?: string(name='UserId', description='This parameter is required.', example='my-robot'),
}

model StartRtcRobotInstanceResponseBody = {
  instanceId?: string(name='InstanceId', example='727dc0e296014bb58670940a3da95592'),
  requestId?: string(name='RequestId', description='Id of the request', example='11DE0AB3-603B-5055-8A72-9C424854F983'),
}

model StartRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartRtcRobotInstanceResponseBody(name='body'),
}

/**
 * @summary 开启一个机器人实例
 *
 * @param tmpReq StartRtcRobotInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StartRtcRobotInstanceResponse
 */
async function startRtcRobotInstanceWithOptions(tmpReq: StartRtcRobotInstanceRequest, runtime: Util.RuntimeOptions): StartRtcRobotInstanceResponse {
  Util.validateModel(tmpReq);
  var request = new StartRtcRobotInstanceShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.config)) {
    request.configShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.config, 'Config', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.authToken)) {
    query['AuthToken'] = request.authToken;
  }
  if (!Util.isUnset(request.channelId)) {
    query['ChannelId'] = request.channelId;
  }
  if (!Util.isUnset(request.configShrink)) {
    query['Config'] = request.configShrink;
  }
  if (!Util.isUnset(request.robotId)) {
    query['RobotId'] = request.robotId;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  if (!Util.isUnset(request.userId)) {
    query['UserId'] = request.userId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'StartRtcRobotInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 开启一个机器人实例
 *
 * @param request StartRtcRobotInstanceRequest
 * @return StartRtcRobotInstanceResponse
 */
async function startRtcRobotInstance(request: StartRtcRobotInstanceRequest): StartRtcRobotInstanceResponse {
  var runtime = new Util.RuntimeOptions{};
  return startRtcRobotInstanceWithOptions(request, runtime);
}

model StartWorkflowRequest {
  taskInput?: string(name='TaskInput', description='The workflow input. Only media assets are supported.', example='{
      "Type": "Media",
      "Media": "******30706071edbfe290b488******"
}'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which cannot be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).'),
  workflowId?: string(name='WorkflowId', description='The ID of the workflow template. To view the template ID, log on to the [IMS console](https://ims.console.aliyun.com/settings/workflow/list) and choose Configurations > Workflow Template.', example='******f0e54971ecbffd472190******'),
}

model StartWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******42-E8E1-4FBB-8E52-F4225C******'),
  taskId?: string(name='TaskId', description='The ID of the workflow task.', example='******22dad741d086a50325f9******'),
}

model StartWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartWorkflowResponseBody(name='body'),
}

/**
 * @summary Submits a workflow task. You can submit a workflow task to implement automated media processing based on a workflow template.
 *
 * @description *   Only media assets from Intelligent Media Services (IMS) or ApsaraVideo VOD can be used as the input of a workflow.
 * *   When you submit a workflow task, you must specify a workflow template. You can create a workflow template in the [IMS console](https://ims.console.aliyun.com/settings/workflow/list) or use a preset workflow template.
 *
 * @param request StartWorkflowRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StartWorkflowResponse
 */
async function startWorkflowWithOptions(request: StartWorkflowRequest, runtime: Util.RuntimeOptions): StartWorkflowResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.taskInput)) {
    query['TaskInput'] = request.taskInput;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  if (!Util.isUnset(request.workflowId)) {
    query['WorkflowId'] = request.workflowId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'StartWorkflow',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a workflow task. You can submit a workflow task to implement automated media processing based on a workflow template.
 *
 * @description *   Only media assets from Intelligent Media Services (IMS) or ApsaraVideo VOD can be used as the input of a workflow.
 * *   When you submit a workflow task, you must specify a workflow template. You can create a workflow template in the [IMS console](https://ims.console.aliyun.com/settings/workflow/list) or use a preset workflow template.
 *
 * @param request StartWorkflowRequest
 * @return StartWorkflowResponse
 */
async function startWorkflow(request: StartWorkflowRequest): StartWorkflowResponse {
  var runtime = new Util.RuntimeOptions{};
  return startWorkflowWithOptions(request, runtime);
}

model StopAIAgentInstanceRequest {
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
}

model StopAIAgentInstanceResponseBody = {
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model StopAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopAIAgentInstanceResponseBody(name='body'),
}

/**
 * @summary 停止一个智能体实例。
 *
 * @param request StopAIAgentInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StopAIAgentInstanceResponse
 */
async function stopAIAgentInstanceWithOptions(request: StopAIAgentInstanceRequest, runtime: Util.RuntimeOptions): StopAIAgentInstanceResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'StopAIAgentInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 停止一个智能体实例。
 *
 * @param request StopAIAgentInstanceRequest
 * @return StopAIAgentInstanceResponse
 */
async function stopAIAgentInstance(request: StopAIAgentInstanceRequest): StopAIAgentInstanceResponse {
  var runtime = new Util.RuntimeOptions{};
  return stopAIAgentInstanceWithOptions(request, runtime);
}

model StopRtcRobotInstanceRequest {
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='727dc0e296014bb58670940a3da95592'),
}

model StopRtcRobotInstanceResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='AC84E5DD-AB56-56C0-A992-07ECB82008CA'),
}

model StopRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopRtcRobotInstanceResponseBody(name='body'),
}

/**
 * @summary 停止一个机器人实例
 *
 * @param request StopRtcRobotInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StopRtcRobotInstanceResponse
 */
async function stopRtcRobotInstanceWithOptions(request: StopRtcRobotInstanceRequest, runtime: Util.RuntimeOptions): StopRtcRobotInstanceResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'StopRtcRobotInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 停止一个机器人实例
 *
 * @param request StopRtcRobotInstanceRequest
 * @return StopRtcRobotInstanceResponse
 */
async function stopRtcRobotInstance(request: StopRtcRobotInstanceRequest): StopRtcRobotInstanceResponse {
  var runtime = new Util.RuntimeOptions{};
  return stopRtcRobotInstanceWithOptions(request, runtime);
}

model SubmitASRJobRequest {
  description?: string(name='Description', description='The job description, which can up to 128 bytes in length.', example='测试描述'),
  duration?: string(name='Duration', description='The speech duration.', example='00:00:10'),
  inputFile?: string(name='InputFile', description='The input file. You can specify an Object Storage Service (OSS) URL or the ID of a media asset in the media asset library.', example='oss://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4 或 ****20b48fb04483915d4f2cd8ac****'),
  startTime?: string(name='StartTime', description='The start time of the speech to recognize.', example='00:00:00'),
  title?: string(name='Title', description='The job title, which can be up to 128 bytes in length.', example='测试标题'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format. You can specify your business information, such as the business environment and job information.', example='{
      "user": "data",
      "env": "prod"
}'),
}

model SubmitASRJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  state?: string(name='State', description='The job state. Valid values:

*   Created
*   Executing
*   Finished
*   Failed', example='Finished'),
}

model SubmitASRJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitASRJobResponseBody(name='body'),
}

/**
 * @summary Submits an automatic speech recognition (ASR) job to extract the start and end time and the corresponding text information of a speech in a video.
 *
 * @param request SubmitASRJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitASRJobResponse
 */
async function submitASRJobWithOptions(request: SubmitASRJobRequest, runtime: Util.RuntimeOptions): SubmitASRJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.description)) {
    query['Description'] = request.description;
  }
  if (!Util.isUnset(request.duration)) {
    query['Duration'] = request.duration;
  }
  if (!Util.isUnset(request.inputFile)) {
    query['InputFile'] = request.inputFile;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.title)) {
    query['Title'] = request.title;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitASRJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits an automatic speech recognition (ASR) job to extract the start and end time and the corresponding text information of a speech in a video.
 *
 * @param request SubmitASRJobRequest
 * @return SubmitASRJobResponse
 */
async function submitASRJob(request: SubmitASRJobRequest): SubmitASRJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitASRJobWithOptions(request, runtime);
}

model SubmitAudioProduceJobRequest {
  description?: string(name='Description', description='The job description.

*   The job description can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.', example='任务描述  长度不超过1024字节  UTF8编码'),
  editingConfig?: string(name='EditingConfig', description='The audio editing configurations.

*   voice: the [voice type](https://help.aliyun.com/document_detail/449563.html).
*   customizedVoice: the ID of the personalized human voice.
*   format: the format of the output file. Valid values: PCM, WAV, and MP3.
*   volume: the volume. Default value: 50. Valid values: 0 to 100.
*   speech_rate: the speech tempo. Default value: 0. Value range: -500 to 500.
*   pitch_rate: the intonation. Default value: 0. Value range: -500 to 500.

>  If you specify both voice and customizedVoice, customizedVoice takes precedence over voice.

This parameter is required.', example='{"voice":"Siqi","format":"MP3","volume":50}'),
  inputConfig?: string(name='InputConfig', description='The text content. A maximum of 2,000 characters are supported. The [Speech Synthesis Markup Language (SSML)](https://help.aliyun.com/document_detail/2672807.html) is supported.

This parameter is required.', example='测试文本'),
  outputConfig?: string(name='OutputConfig', description='The output audio configurations.

This parameter is required.', example='{"bucket":"bucket","object":"objeck"}'),
  overwrite?: boolean(name='Overwrite', description='Specifies whether to overwrite the existing Object Storage Service (OSS) object.', example='true'),
  title?: string(name='Title', description='The job title. If you do not specify this parameter, the system generates a title based on the current date.

*   The job title can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='任务标题。若不提供，根据日期自动生成默认title  长度不超过128字节  UTF8编码'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).', example='{"user":"data"}'),
}

model SubmitAudioProduceJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****2bcbfcfa30fccb36f72dca22****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  state?: string(name='State', description='The job state. Valid values:

*   Created
*   Executing
*   Finished
*   Failed', example='Created'),
}

model SubmitAudioProduceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitAudioProduceJobResponseBody(name='body'),
}

/**
 * @summary Submits an audio production job that converts text into an audio file.
 *
 * @param request SubmitAudioProduceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitAudioProduceJobResponse
 */
async function submitAudioProduceJobWithOptions(request: SubmitAudioProduceJobRequest, runtime: Util.RuntimeOptions): SubmitAudioProduceJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.description)) {
    query['Description'] = request.description;
  }
  if (!Util.isUnset(request.editingConfig)) {
    query['EditingConfig'] = request.editingConfig;
  }
  if (!Util.isUnset(request.inputConfig)) {
    query['InputConfig'] = request.inputConfig;
  }
  if (!Util.isUnset(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!Util.isUnset(request.overwrite)) {
    query['Overwrite'] = request.overwrite;
  }
  if (!Util.isUnset(request.title)) {
    query['Title'] = request.title;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitAudioProduceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits an audio production job that converts text into an audio file.
 *
 * @param request SubmitAudioProduceJobRequest
 * @return SubmitAudioProduceJobResponse
 */
async function submitAudioProduceJob(request: SubmitAudioProduceJobRequest): SubmitAudioProduceJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitAudioProduceJobWithOptions(request, runtime);
}

model SubmitAvatarTrainingJobRequest {
  jobId?: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model SubmitAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****29faef8144638ba42eb8e037****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model SubmitAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitAvatarTrainingJobResponseBody(name='body'),
}

/**
 * @summary Submits a digital human training job. You can call this operation to submit a job the first time or submit a job again with updated parameters if the training failed.
 *
 * @param request SubmitAvatarTrainingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitAvatarTrainingJobResponse
 */
async function submitAvatarTrainingJobWithOptions(request: SubmitAvatarTrainingJobRequest, runtime: Util.RuntimeOptions): SubmitAvatarTrainingJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitAvatarTrainingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a digital human training job. You can call this operation to submit a job the first time or submit a job again with updated parameters if the training failed.
 *
 * @param request SubmitAvatarTrainingJobRequest
 * @return SubmitAvatarTrainingJobResponse
 */
async function submitAvatarTrainingJob(request: SubmitAvatarTrainingJobRequest): SubmitAvatarTrainingJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitAvatarTrainingJobWithOptions(request, runtime);
}

model SubmitAvatarVideoJobRequest {
  description?: string(name='Description', example='测试描述'),
  editingConfig?: string(name='EditingConfig', example='{"AvatarId":"yunqiao"}'),
  inputConfig?: string(name='InputConfig', description='The input configurations of the video rendering job for an avatar. You can specify text, the Object Storage Service (OSS) URL of an audio file, or the ID of a media asset. The audio file must be in the MP3 or WAV format.

>  The text must be at least five words in length.'),
  outputConfig?: string(name='OutputConfig', example='{"MediaURL":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/xxx.mp4","Width":1920,"Height":1080}'),
  title?: string(name='Title', example='测试标题'),
  userData?: string(name='UserData', example='{"user":"data","env":"prod"}'),
}

model SubmitAvatarVideoJobResponseBody = {
  jobId?: string(name='JobId', example='****20b48fb04483915d4f2cd8ac****'),
  mediaId?: string(name='MediaId', example='******70dcc471edaf00e6f6f4******'),
  requestId?: string(name='RequestId', description='Id of the request', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitAvatarVideoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitAvatarVideoJobResponseBody(name='body'),
}

/**
 * @summary Submits a video rendering job for a digitized virtual human based on text or an audio file of a human voice.
 *
 * @param request SubmitAvatarVideoJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitAvatarVideoJobResponse
 */
async function submitAvatarVideoJobWithOptions(request: SubmitAvatarVideoJobRequest, runtime: Util.RuntimeOptions): SubmitAvatarVideoJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.description)) {
    query['Description'] = request.description;
  }
  if (!Util.isUnset(request.editingConfig)) {
    query['EditingConfig'] = request.editingConfig;
  }
  if (!Util.isUnset(request.inputConfig)) {
    query['InputConfig'] = request.inputConfig;
  }
  if (!Util.isUnset(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!Util.isUnset(request.title)) {
    query['Title'] = request.title;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitAvatarVideoJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a video rendering job for a digitized virtual human based on text or an audio file of a human voice.
 *
 * @param request SubmitAvatarVideoJobRequest
 * @return SubmitAvatarVideoJobResponse
 */
async function submitAvatarVideoJob(request: SubmitAvatarVideoJobRequest): SubmitAvatarVideoJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitAvatarVideoJobWithOptions(request, runtime);
}

model SubmitBatchMediaProducingJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****'),
  editingConfig?: string(name='EditingConfig', description='The editing configurations. For more information, see [EditingConfig](~~2692547#1be9bba03b7qu~~).', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}'),
  inputConfig?: string(name='InputConfig', description='The input configurations. For more information, see [InputConfig](~~2692547#2faed1559549n~~).'),
  outputConfig?: string(name='OutputConfig', description='The output configurations. For more information, see [OutputConfig](~~2692547#447b928fcbuoa~~).', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 20,
  "MaxDuration": 15,
  "Width": 1080,
  "Height": 1920,
  "Video": {"Crf": 27}
}'),
  userData?: string(name='UserData', description='The user-defined data, including the business and callback configurations. For more information, see [UserData](https://help.aliyun.com/document_detail/357745.html).'),
}

model SubmitBatchMediaProducingJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the quick video production job.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model SubmitBatchMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitBatchMediaProducingJobResponseBody(name='body'),
}

/**
 * @summary Submits a quick video production job that intelligently edits multiple video, audio, and image assets to generate multiple videos at a time.
 *
 * @param request SubmitBatchMediaProducingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitBatchMediaProducingJobResponse
 */
async function submitBatchMediaProducingJobWithOptions(request: SubmitBatchMediaProducingJobRequest, runtime: Util.RuntimeOptions): SubmitBatchMediaProducingJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!Util.isUnset(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.editingConfig)) {
    body['EditingConfig'] = request.editingConfig;
  }
  if (!Util.isUnset(request.inputConfig)) {
    body['InputConfig'] = request.inputConfig;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'SubmitBatchMediaProducingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a quick video production job that intelligently edits multiple video, audio, and image assets to generate multiple videos at a time.
 *
 * @param request SubmitBatchMediaProducingJobRequest
 * @return SubmitBatchMediaProducingJobResponse
 */
async function submitBatchMediaProducingJob(request: SubmitBatchMediaProducingJobRequest): SubmitBatchMediaProducingJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitBatchMediaProducingJobWithOptions(request, runtime);
}

model SubmitCopyrightExtractJobRequest {
  input?: {
    media?: string(name='Media', description='This parameter is required.', example='oss://bucket/object'),
    type?: string(name='Type', description='This parameter is required.', example='OSS'),
  }(name='Input', description='This parameter is required.'),
  params?: string(name='Params', example='{"algoType":"v2"}'),
  userData?: string(name='UserData', example='123'),
}

model SubmitCopyrightExtractJobShrinkRequest {
  inputShrink?: string(name='Input', description='This parameter is required.'),
  params?: string(name='Params', example='{"algoType":"v2"}'),
  userData?: string(name='UserData', example='123'),
}

model SubmitCopyrightExtractJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', example='bfb786c63****4d80648792021eff90'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
  statusCode?: long(name='StatusCode', example='200'),
}

model SubmitCopyrightExtractJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitCopyrightExtractJobResponseBody(name='body'),
}

/**
 * @summary 提交版权水印提取作业
 *
 * @param tmpReq SubmitCopyrightExtractJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitCopyrightExtractJobResponse
 */
async function submitCopyrightExtractJobWithOptions(tmpReq: SubmitCopyrightExtractJobRequest, runtime: Util.RuntimeOptions): SubmitCopyrightExtractJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitCopyrightExtractJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!Util.isUnset(request.params)) {
    query['Params'] = request.params;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitCopyrightExtractJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 提交版权水印提取作业
 *
 * @param request SubmitCopyrightExtractJobRequest
 * @return SubmitCopyrightExtractJobResponse
 */
async function submitCopyrightExtractJob(request: SubmitCopyrightExtractJobRequest): SubmitCopyrightExtractJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitCopyrightExtractJobWithOptions(request, runtime);
}

model SubmitCopyrightJobRequest {
  description?: string(name='Description'),
  input?: {
    media?: string(name='Media', description='This parameter is required.'),
    type?: string(name='Type', description='This parameter is required.'),
  }(name='Input', description='This parameter is required.', example='{"Bucket":"example-bucket","Location":"oss-cn-shanghai","Object":"example.mp4"}'),
  level?: long(name='Level', example='0'),
  message?: string(name='Message', description='This parameter is required.'),
  output?: {
    media?: string(name='Media', description='This parameter is required.'),
    type?: string(name='Type', description='This parameter is required.'),
  }(name='Output', description='This parameter is required.', example='{"Bucket":"example-bucket","Location":"oss-cn-shanghai","Object":"example_result.mp4"}'),
  params?: string(name='Params', example='{"algoType":"v2"}'),
  startTime?: string(name='StartTime', example='0'),
  totalTime?: string(name='TotalTime', example='10'),
  userData?: string(name='UserData', example='123'),
}

model SubmitCopyrightJobShrinkRequest {
  description?: string(name='Description'),
  inputShrink?: string(name='Input', description='This parameter is required.', example='{"Bucket":"example-bucket","Location":"oss-cn-shanghai","Object":"example.mp4"}'),
  level?: long(name='Level', example='0'),
  message?: string(name='Message', description='This parameter is required.'),
  outputShrink?: string(name='Output', description='This parameter is required.', example='{"Bucket":"example-bucket","Location":"oss-cn-shanghai","Object":"example_result.mp4"}'),
  params?: string(name='Params', example='{"algoType":"v2"}'),
  startTime?: string(name='StartTime', example='0'),
  totalTime?: string(name='TotalTime', example='10'),
  userData?: string(name='UserData', example='123'),
}

model SubmitCopyrightJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', example='bfb786c63****f4d80648792021eff90'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='FA258E67-09B8-4EAA-8F33-BA567834A2C3'),
  statusCode?: long(name='StatusCode', example='200'),
}

model SubmitCopyrightJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitCopyrightJobResponseBody(name='body'),
}

/**
 * @summary 提交版权水印任务
 *
 * @param tmpReq SubmitCopyrightJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitCopyrightJobResponse
 */
async function submitCopyrightJobWithOptions(tmpReq: SubmitCopyrightJobRequest, runtime: Util.RuntimeOptions): SubmitCopyrightJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitCopyrightJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!Util.isUnset(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.description)) {
    query['Description'] = request.description;
  }
  if (!Util.isUnset(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!Util.isUnset(request.level)) {
    query['Level'] = request.level;
  }
  if (!Util.isUnset(request.message)) {
    query['Message'] = request.message;
  }
  if (!Util.isUnset(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!Util.isUnset(request.params)) {
    query['Params'] = request.params;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.totalTime)) {
    query['TotalTime'] = request.totalTime;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitCopyrightJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 提交版权水印任务
 *
 * @param request SubmitCopyrightJobRequest
 * @return SubmitCopyrightJobResponse
 */
async function submitCopyrightJob(request: SubmitCopyrightJobRequest): SubmitCopyrightJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitCopyrightJobWithOptions(request, runtime);
}

model SubmitCustomizedVoiceJobRequest {
  demoAudioMediaURL?: string(name='DemoAudioMediaURL', description='The URL of the sample audio file.

*   If this parameter is specified, a sample audio file is generated at the specified Object Storage Service (OSS) URL after the training is complete.

*   If this parameter is not specified, no sample audio file is generated.

    **

    **Note**: The URL must be a valid public OSS URL within your Alibaba Cloud account.', example='https://your-bucket.oss-cn-shanghai.aliyuncs.com/demo.MP3'),
  voiceId?: string(name='VoiceId', description='The voice ID.

This parameter is required.', example='xiaozhuan'),
}

model SubmitCustomizedVoiceJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****d718e2ff4f018ccf419a7b71****'),
    voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model SubmitCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Submits a human voice cloning job. The value of VoiceId must be the one used during audio check. The system uses this ID to find the cached audio file for training. After you call this operation, the JobId is returned. The training process is asynchronous. During training, you can call the GetCustomizedVoiceJob operation to query information such as the job state.
 *
 * @param request SubmitCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitCustomizedVoiceJobResponse
 */
async function submitCustomizedVoiceJobWithOptions(request: SubmitCustomizedVoiceJobRequest, runtime: Util.RuntimeOptions): SubmitCustomizedVoiceJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.demoAudioMediaURL)) {
    query['DemoAudioMediaURL'] = request.demoAudioMediaURL;
  }
  if (!Util.isUnset(request.voiceId)) {
    query['VoiceId'] = request.voiceId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a human voice cloning job. The value of VoiceId must be the one used during audio check. The system uses this ID to find the cached audio file for training. After you call this operation, the JobId is returned. The training process is asynchronous. During training, you can call the GetCustomizedVoiceJob operation to query information such as the job state.
 *
 * @param request SubmitCustomizedVoiceJobRequest
 * @return SubmitCustomizedVoiceJobResponse
 */
async function submitCustomizedVoiceJob(request: SubmitCustomizedVoiceJobRequest): SubmitCustomizedVoiceJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitCustomizedVoiceJobWithOptions(request, runtime);
}

model SubmitDNAJobRequest {
  config?: string(name='Config', description='The configurations of the media fingerprint analysis job. The value is a JSON object. If you specify this parameter, the template parameters are overwritten.', example='{"SaveType": "save","MediaType"":"video"}'),
  DBId?: string(name='DBId', description='The ID of the media fingerprint library. If you do not specify this parameter, the default media fingerprint library is used. For more information about how to create a media fingerprint library, see [CreateDNADB](https://help.aliyun.com/document_detail/479275.html).

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****'),
  input?: {
    media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. You can specify the path of an OSS object in one of the following formats:

1\\\\. oss://bucket/object

2\\\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the preceding paths, bucket indicates an OSS bucket that resides in the same region as the current project, and object indicates the path of the object in the bucket.

This parameter is required.', example='1b1b9cd148034739af413150fded****'),
    type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: Object Storage Service (OSS) object.
2.  Media: media asset.

This parameter is required.', example='Media'),
  }(name='Input', description='The input file for media fingerprint analysis.

This parameter is required.'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the media fingerprint analysis job is submitted.', example='5246b8d12a62433ab77845074039****'),
  primaryKey?: string(name='PrimaryKey', description='The primary key of the video. You must make sure that each primary key is unique.

This parameter is required.', example='3ca84a39a9024f19853b21be9cf9****'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
  templateId?: string(name='TemplateId', description='The template ID.', example='S00000101-100060'),
  userData?: string(name='UserData', description='The user-defined data. The data can be up to 128 bytes in length.', example='userData'),
}

model SubmitDNAJobShrinkRequest {
  config?: string(name='Config', description='The configurations of the media fingerprint analysis job. The value is a JSON object. If you specify this parameter, the template parameters are overwritten.', example='{"SaveType": "save","MediaType"":"video"}'),
  DBId?: string(name='DBId', description='The ID of the media fingerprint library. If you do not specify this parameter, the default media fingerprint library is used. For more information about how to create a media fingerprint library, see [CreateDNADB](https://help.aliyun.com/document_detail/479275.html).

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****'),
  inputShrink?: string(name='Input', description='The input file for media fingerprint analysis.

This parameter is required.'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the media fingerprint analysis job is submitted.', example='5246b8d12a62433ab77845074039****'),
  primaryKey?: string(name='PrimaryKey', description='The primary key of the video. You must make sure that each primary key is unique.

This parameter is required.', example='3ca84a39a9024f19853b21be9cf9****'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
  templateId?: string(name='TemplateId', description='The template ID.', example='S00000101-100060'),
  userData?: string(name='UserData', description='The user-defined data. The data can be up to 128 bytes in length.', example='userData'),
}

model SubmitDNAJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the media fingerprint analysis job. We recommend that you save this ID for subsequent calls of other operations.', example='88c6ca184c0e47098a5b665e2****'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model SubmitDNAJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitDNAJobResponseBody(name='body'),
}

/**
 * @summary Submits a media fingerprint analysis job.
 *
 * @description *   SubmitDNAJob is an asynchronous operation. After a request is sent, the system returns a request ID and a job ID and runs the task in the background.
 * *   You can call this operation only in the China (Beijing), China (Hangzhou), and China (Shanghai) regions.
 * *   You can submit a text fingerprint analysis job only in the China (Shanghai) region.
 *
 * @param tmpReq SubmitDNAJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitDNAJobResponse
 */
async function submitDNAJobWithOptions(tmpReq: SubmitDNAJobRequest, runtime: Util.RuntimeOptions): SubmitDNAJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitDNAJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.config)) {
    query['Config'] = request.config;
  }
  if (!Util.isUnset(request.DBId)) {
    query['DBId'] = request.DBId;
  }
  if (!Util.isUnset(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.pipelineId)) {
    query['PipelineId'] = request.pipelineId;
  }
  if (!Util.isUnset(request.primaryKey)) {
    query['PrimaryKey'] = request.primaryKey;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitDNAJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a media fingerprint analysis job.
 *
 * @description *   SubmitDNAJob is an asynchronous operation. After a request is sent, the system returns a request ID and a job ID and runs the task in the background.
 * *   You can call this operation only in the China (Beijing), China (Hangzhou), and China (Shanghai) regions.
 * *   You can submit a text fingerprint analysis job only in the China (Shanghai) region.
 *
 * @param request SubmitDNAJobRequest
 * @return SubmitDNAJobResponse
 */
async function submitDNAJob(request: SubmitDNAJobRequest): SubmitDNAJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitDNAJobWithOptions(request, runtime);
}

model SubmitDynamicChartJobRequest {
  axisParams?: string(name='AxisParams', example='{"FontFile":"Microsoft YaHei","XAxisFontSize":"30","YAxisFontSize":"30","XAxisFontInterval":"30","AxisColor":"30"}'),
  background?: string(name='Background', example='{"Color":"#000000","ImageUrl":"http://your-bucket.oss-cn-shanghai.aliyuncs.com/obj.jpg"}'),
  chartConfig?: string(name='ChartConfig', example='{"Style":"Normal","TitleStartTime":"3000","ChartStartTime":"3000","VideoDuration":"15000"}'),
  chartTitle?: string(name='ChartTitle'),
  chartType?: string(name='ChartType', description='This parameter is required.', example='Line'),
  dataSource?: string(name='DataSource'),
  description?: string(name='Description'),
  input?: string(name='Input', description='This parameter is required.', example='{"XlsFile":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/obj.xls"}'),
  outputConfig?: string(name='OutputConfig', description='This parameter is required.', example='{"MediaURL":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/obj.mp4","Bitrate":2000,"Width":800,"Height":680}'),
  subtitle?: string(name='Subtitle'),
  title?: string(name='Title'),
  unit?: string(name='Unit'),
  userData?: string(name='UserData', example='{"user":"data"}'),
}

model SubmitDynamicChartJobResponseBody = {
  jobId?: string(name='JobId', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitDynamicChartJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitDynamicChartJobResponseBody(name='body'),
}

/**
 * @summary 提交动态图表任务
 *
 * @param request SubmitDynamicChartJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitDynamicChartJobResponse
 */
async function submitDynamicChartJobWithOptions(request: SubmitDynamicChartJobRequest, runtime: Util.RuntimeOptions): SubmitDynamicChartJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.axisParams)) {
    query['AxisParams'] = request.axisParams;
  }
  if (!Util.isUnset(request.background)) {
    query['Background'] = request.background;
  }
  if (!Util.isUnset(request.chartConfig)) {
    query['ChartConfig'] = request.chartConfig;
  }
  if (!Util.isUnset(request.chartTitle)) {
    query['ChartTitle'] = request.chartTitle;
  }
  if (!Util.isUnset(request.chartType)) {
    query['ChartType'] = request.chartType;
  }
  if (!Util.isUnset(request.dataSource)) {
    query['DataSource'] = request.dataSource;
  }
  if (!Util.isUnset(request.description)) {
    query['Description'] = request.description;
  }
  if (!Util.isUnset(request.input)) {
    query['Input'] = request.input;
  }
  if (!Util.isUnset(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!Util.isUnset(request.subtitle)) {
    query['Subtitle'] = request.subtitle;
  }
  if (!Util.isUnset(request.title)) {
    query['Title'] = request.title;
  }
  if (!Util.isUnset(request.unit)) {
    query['Unit'] = request.unit;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitDynamicChartJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 提交动态图表任务
 *
 * @param request SubmitDynamicChartJobRequest
 * @return SubmitDynamicChartJobResponse
 */
async function submitDynamicChartJob(request: SubmitDynamicChartJobRequest): SubmitDynamicChartJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitDynamicChartJobWithOptions(request, runtime);
}

model SubmitDynamicImageJobRequest {
  input?: {
    media?: string(name='Media', description='The input file. If Type is set to OSS, set this parameter to the URL of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

This parameter is required.', example='oss://bucket/object.mp4'),
    type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The name of the job.', example='SampleJob'),
  output?: {
    media?: string(name='Media', description='The output file. The file can be an OSS object or a media asset. The URL of an OSS object can be in one of the following formats:

*   oss://bucket/object
*   http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the IMS console.

This parameter is required.', example='****96e8864746a0b6f3****'),
    type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

This parameter is required.', example='Media'),
  }(name='Output', description='The output of the job.

This parameter is required.'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****96e8864746a0b6f3****'),
    priority?: int32(name='Priority', description='The priority. Valid values: 1 to 10. Default value: 6. A greater value specifies a higher priority.', example='6'),
  }(name='ScheduleConfig', description='The scheduling settings.'),
  templateConfig?: {
    overwriteParams?: {
      format?: string(name='Format', description='The format of the animated image. Valid values:

*   **gif**
*   **webp**', example='gif'),
      fps?: int32(name='Fps', description='The frame rate. Valid values: [1,60].', example='15'),
      height?: int32(name='Height', description='The height of the animated image. Valid values: [128,4096].', example='720'),
      longShortMode?: boolean(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature. Valid values:

*   **true**
*   **false**

Default value: **true**.

>  If this feature is enabled, the width of the output video corresponds to the long side of the input video, which is the height of the input video in portrait mode. The height of the output video corresponds to the short side of the input video, which is the width of the input video in portrait mode.', example='false'),
      scanMode?: string(name='ScanMode', description='The scan mode. Valid values:

*   **interlaced**
*   **progressive** This is the default value.', example='progressive'),
      timeSpan?: {
        duration?: string(name='Duration', description='The length of the clip.

*   Format: `hh:mm:ss[.SSS]` or `sssss[.SSS]`.
*   Valid values: `[00:00:00.000,23:59:59.999]` or `[0.000,86399.999]`.', example='01:59:59.999 or 32000.23'),
        end?: string(name='End', description='The length of the ending part of the original clip to be cropped out. If you specify this parameter, the Duration parameter becomes invalid.

*   Format: `hh:mm:ss[.SSS]` or `sssss[.SSS]`.
*   Valid values: `[00:00:00.000,23:59:59.999]` or `[0.000,86399.999]`.', example='01:59:59.999 or 32000.23'),
        seek?: string(name='Seek', description='The start point of the clip.

*   Format: `hh:mm:ss[.SSS]` or `sssss[.SSS]`.
*   Valid values: `[00:00:00.000,23:59:59.999]` or `[0.000,86399.999]`.', example='01:59:59.999 or 32000.23'),
      }(name='TimeSpan', description='The timeline parameters.'),
      width?: int32(name='Width', description='The width of the animated image. Valid values: [128,4096].', example='1024'),
    }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters.'),
    templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
  }(name='TemplateConfig', description='The snapshot template configuration.

This parameter is required.'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"SampleKey": "SampleValue"}'),
}

model SubmitDynamicImageJobShrinkRequest {
  inputShrink?: string(name='Input', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The name of the job.', example='SampleJob'),
  outputShrink?: string(name='Output', description='The output of the job.

This parameter is required.'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling settings.'),
  templateConfigShrink?: string(name='TemplateConfig', description='The snapshot template configuration.

This parameter is required.'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"SampleKey": "SampleValue"}'),
}

model SubmitDynamicImageJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitDynamicImageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitDynamicImageJobResponseBody(name='body'),
}

/**
 * @summary Submits an image animation job.
 *
 * @param tmpReq SubmitDynamicImageJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitDynamicImageJobResponse
 */
async function submitDynamicImageJobWithOptions(tmpReq: SubmitDynamicImageJobRequest, runtime: Util.RuntimeOptions): SubmitDynamicImageJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitDynamicImageJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!Util.isUnset(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  if (!Util.isUnset(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  if (!Util.isUnset(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!Util.isUnset(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!Util.isUnset(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitDynamicImageJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits an image animation job.
 *
 * @param request SubmitDynamicImageJobRequest
 * @return SubmitDynamicImageJobResponse
 */
async function submitDynamicImageJob(request: SubmitDynamicImageJobRequest): SubmitDynamicImageJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitDynamicImageJobWithOptions(request, runtime);
}

model SubmitIProductionJobRequest {
  functionName?: string(name='FunctionName', description='The name of the algorithm that you want to use for the job. Valid values:

*   **Cover**: This algorithm intelligently generates a thumbnail image for a video.
*   **VideoClip**: This algorithm intelligently generates a summary for a video.
*   **VideoDelogo**: This algorithm removes logos from a video.
*   **VideoDetext**: This algorithm removes captions from a video.
*   **CaptionExtraction**: This algorithm extracts captions from a video and generates the caption file.
*   **VideoGreenScreenMatting**: This algorithm performs green-screen image matting on a video and generates a new video.
*   **FaceBeauty**: This algorithm performs video retouching.
*   **VideoH2V**: This algorithm transforms a video from the landscape mode to the portrait mode.
*   **MusicSegmentDetect**: This algorithm detects the chorus of a song.
*   **AudioBeatDetection**: This algorithm detects rhythms.
*   **AudioQualityAssessment**: This algorithm assesses the audio quality.
*   **SpeechDenoise**: This algorithm performs noise reduction.
*   **AudioMixing**: This algorithm mixes audio streams.

This parameter is required.', example='Cover'),
  input?: {
    media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[regionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.

This parameter is required.', example='oss://bucket/object'),
    type?: string(name='Type', description='The media type. Valid values:

*   OSS: OSS object
*   Media: media asset

This parameter is required.', example='OSS'),
  }(name='Input', description='The input file. The file can be an Object Storage Service (OSS) object or a media asset.

This parameter is required.'),
  jobParams?: string(name='JobParams', description='The algorithm-specific parameters. The parameters are specified as JSON objects and vary based on the algorithm. For more information, see the "Parameters of JobParams" section of this topic.', example='{"Model":"gif"}'),
  modelId?: string(name='ModelId'),
  name?: string(name='Name', description='The name of the intelligent production job. The name can be up to 100 characters in length.'),
  output?: {
    media?: string(name='Media', description='The output file. If Type is set to OSS, set this parameter to the path of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.

This parameter is required.', example='oss://bucket/object'),
    type?: string(name='Type', description='The media type. Valid values:

*   OSS: OSS object
*   Media: media asset

This parameter is required.', example='OSS'),
  }(name='Output', description='The output file. The file can be an OSS object or a media asset.

This parameter is required.'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue.', example='5246b8d12a62433ab77845074039c3dc'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. A smaller value indicates a higher priority.', example='6'),
  }(name='ScheduleConfig', description='The scheduling configuration.'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
  userData?: string(name='UserData', description='The user-defined data that is returned in the response. The value can be up to 1,024 bytes in length.', example='{"test":1}'),
}

model SubmitIProductionJobShrinkRequest {
  functionName?: string(name='FunctionName', description='The name of the algorithm that you want to use for the job. Valid values:

*   **Cover**: This algorithm intelligently generates a thumbnail image for a video.
*   **VideoClip**: This algorithm intelligently generates a summary for a video.
*   **VideoDelogo**: This algorithm removes logos from a video.
*   **VideoDetext**: This algorithm removes captions from a video.
*   **CaptionExtraction**: This algorithm extracts captions from a video and generates the caption file.
*   **VideoGreenScreenMatting**: This algorithm performs green-screen image matting on a video and generates a new video.
*   **FaceBeauty**: This algorithm performs video retouching.
*   **VideoH2V**: This algorithm transforms a video from the landscape mode to the portrait mode.
*   **MusicSegmentDetect**: This algorithm detects the chorus of a song.
*   **AudioBeatDetection**: This algorithm detects rhythms.
*   **AudioQualityAssessment**: This algorithm assesses the audio quality.
*   **SpeechDenoise**: This algorithm performs noise reduction.
*   **AudioMixing**: This algorithm mixes audio streams.

This parameter is required.', example='Cover'),
  inputShrink?: string(name='Input', description='The input file. The file can be an Object Storage Service (OSS) object or a media asset.

This parameter is required.'),
  jobParams?: string(name='JobParams', description='The algorithm-specific parameters. The parameters are specified as JSON objects and vary based on the algorithm. For more information, see the "Parameters of JobParams" section of this topic.', example='{"Model":"gif"}'),
  modelId?: string(name='ModelId'),
  name?: string(name='Name', description='The name of the intelligent production job. The name can be up to 100 characters in length.'),
  outputShrink?: string(name='Output', description='The output file. The file can be an OSS object or a media asset.

This parameter is required.'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling configuration.'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
  userData?: string(name='UserData', description='The user-defined data that is returned in the response. The value can be up to 1,024 bytes in length.', example='{"test":1}'),
}

model SubmitIProductionJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the intelligent production job.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='C1849434-FC47-5DC1-92B6-F7EAAFE3851E'),
}

model SubmitIProductionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitIProductionJobResponseBody(name='body'),
}

/**
 * @summary Submits an intelligent production job.
 *
 * @param tmpReq SubmitIProductionJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitIProductionJobResponse
 */
async function submitIProductionJobWithOptions(tmpReq: SubmitIProductionJobRequest, runtime: Util.RuntimeOptions): SubmitIProductionJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitIProductionJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!Util.isUnset(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  if (!Util.isUnset(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.functionName)) {
    query['FunctionName'] = request.functionName;
  }
  if (!Util.isUnset(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!Util.isUnset(request.jobParams)) {
    query['JobParams'] = request.jobParams;
  }
  if (!Util.isUnset(request.modelId)) {
    query['ModelId'] = request.modelId;
  }
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!Util.isUnset(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitIProductionJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits an intelligent production job.
 *
 * @param request SubmitIProductionJobRequest
 * @return SubmitIProductionJobResponse
 */
async function submitIProductionJob(request: SubmitIProductionJobRequest): SubmitIProductionJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitIProductionJobWithOptions(request, runtime);
}

model SubmitLiveEditingJobRequest {
  clips?: string(name='Clips', description='The clips in the JSON array format. The output video is created by merging these clips sequentially.

Each clip has a start time and an end time. If no live stream parameters are specified, the outer live stream configurations apply. The start and end timestamps are in UTC. For more information about the parameters, see the "Clip" section of this topic.

This parameter is required.', example='[{\\\\"StartTime\\\\": \\\\" 2021-06-21T08:01:00Z\\\\",  \\\\"EndTime\\\\": \\\\" 2021-06-21T08:03:00Z\\\\" ,  "AppName": "app", "DomainName": "domain.com", "StreamName": "stream"},  {\\\\"StartTime\\\\": \\\\" 2021-06-21T08:05:00Z\\\\",  \\\\"EndTime\\\\": \\\\" 2021-06-21T08:09:00Z\\\\" }]'),
  liveStreamConfig?: string(name='LiveStreamConfig', description='The live stream configurations, in the JSON format. The configurations must include the following parameters:

*   AppName: the name of the application to which the live stream belongs.
*   DomainName: the domain name of the application.
*   StreamName: the name of the live stream.', example='{ "AppName": "app", "DomainName": "domain.com", "StreamName": "stream"  }'),
  mediaProduceConfig?: string(name='MediaProduceConfig', description='The production configurations, in the JSON format. Mode specifies the editing mode. Valid values:

*   **AccurateFast** (default): fast editing. It is faster than the Accurate mode. The resolution of the output file is the same as that of the source stream. You cannot specify the width and height of the output file.
*   **Accurate**: accurate editing. In this mode, you can specify the width and height of the output file.
*   **Rough**: rough editing. The minimum precision is one TS segment. The output file comprises all segments within the specified time range. You can specify the width and height of the output file.
*   **RoughFast**: fast rough editing. It is faster than the Accurate mode. The minimum precision is one TS segment. The output file comprises all segments within the specified time range. The resolution of the output file is the same as that of the source stream. You cannot specify the width and height of the output file.', example='{ "Mode": "AccurateFast"}'),
  outputMediaConfig?: string(name='OutputMediaConfig', description='The configurations of the output file, in the JSON format. You can specify an OSS URL or a storage location in a storage bucket of ApsaraVideo VOD.

*   To store the output file in OSS, you must specify MediaURL.
*   To store the output file in ApsaraVideo VOD, you must specify StorageLocation and FileName.'),
  outputMediaTarget?: string(name='OutputMediaTarget', description='The type of the output file. Valid values:

*   oss-object: OSS object in an OSS bucket.
*   vod-media: media asset in Alibaba Cloud VOD.', example='oss-object'),
  projectId?: string(name='ProjectId', description='The ID of the live editing project. If this parameter is specified, the system reads the storage configurations of the project. If this parameter is not specified, the specified storage configurations take precedence.', example='****fddd7748b58bf1d47e95****'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length.', example='{"key": "value"}'),
}

model SubmitLiveEditingJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the live editing job.', example='****d80e4e4044975745c14b****'),
  mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****c469e944b5a856828dc2****'),
  mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://test-bucket.cn-shanghai.aliyuncs.com/test.mp4'),
  projectId?: string(name='ProjectId', description='The ID of the live editing project.', example='****fddd7748b58bf1d47e95****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
  vodMediaId?: string(name='VodMediaId', description='The media asset ID of the output file in ApsaraVideo VOD if the output file is stored in ApsaraVideo VOD.', example='****d7578s4h75ci945c14b****'),
}

model SubmitLiveEditingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveEditingJobResponseBody(name='body'),
}

/**
 * @summary Submits a live editing job to merge one or more live stream clips into one video. After a live editing job is submitted, the job is queued in the background for asynchronous processing. You can call the GeLiveEditingJob operation to query the state of the job based on the job ID. You can also call the GetMediaInfo operation to query the information about the generated media asset based on the media asset ID.
 *
 * @description Live editing is supported for live streams that are recorded and stored in Object Storage Service (OSS) and ApsaraVideo VOD. If multiple live streams are involved in a single job, only those recorded within the same application are supported for mixed editing. The streams must all be recorded either in OSS or ApsaraVideo VOD.
 *
 * @param request SubmitLiveEditingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitLiveEditingJobResponse
 */
async function submitLiveEditingJobWithOptions(request: SubmitLiveEditingJobRequest, runtime: Util.RuntimeOptions): SubmitLiveEditingJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.clips)) {
    query['Clips'] = request.clips;
  }
  if (!Util.isUnset(request.liveStreamConfig)) {
    query['LiveStreamConfig'] = request.liveStreamConfig;
  }
  if (!Util.isUnset(request.mediaProduceConfig)) {
    query['MediaProduceConfig'] = request.mediaProduceConfig;
  }
  if (!Util.isUnset(request.outputMediaConfig)) {
    query['OutputMediaConfig'] = request.outputMediaConfig;
  }
  if (!Util.isUnset(request.outputMediaTarget)) {
    query['OutputMediaTarget'] = request.outputMediaTarget;
  }
  if (!Util.isUnset(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitLiveEditingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a live editing job to merge one or more live stream clips into one video. After a live editing job is submitted, the job is queued in the background for asynchronous processing. You can call the GeLiveEditingJob operation to query the state of the job based on the job ID. You can also call the GetMediaInfo operation to query the information about the generated media asset based on the media asset ID.
 *
 * @description Live editing is supported for live streams that are recorded and stored in Object Storage Service (OSS) and ApsaraVideo VOD. If multiple live streams are involved in a single job, only those recorded within the same application are supported for mixed editing. The streams must all be recorded either in OSS or ApsaraVideo VOD.
 *
 * @param request SubmitLiveEditingJobRequest
 * @return SubmitLiveEditingJobResponse
 */
async function submitLiveEditingJob(request: SubmitLiveEditingJobRequest): SubmitLiveEditingJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitLiveEditingJobWithOptions(request, runtime);
}

model SubmitLiveRecordJobRequest {
  name?: string(name='Name', description='The name of the recording job.

This parameter is required.', example='live stream record 1'),
  notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify'),
  recordOutput?: {
    bucket?: string(name='Bucket', description='The bucket name.', example='imsbucket1'),
    endpoint?: string(name='Endpoint', description='The endpoint of the storage service.', example='oss-cn-hangzhou.aliyuncs.com'),
    type?: string(name='Type', description='The type of the storage address.

This parameter is required.', example='oss'),
  }(name='RecordOutput', description='The storage address of the recording.

This parameter is required.'),
  streamInput?: {
    type?: string(name='Type', description='The type of the live stream URL. The value can only be rtmp.

This parameter is required.', example='rtmp'),
    url?: string(name='Url', description='The URL of the live stream.', example='rtmp://example.com/live/stream1'),
  }(name='StreamInput', description='The URL of the live stream.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The ID of the recording template.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
}

model SubmitLiveRecordJobShrinkRequest {
  name?: string(name='Name', description='The name of the recording job.

This parameter is required.', example='live stream record 1'),
  notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify'),
  recordOutputShrink?: string(name='RecordOutput', description='The storage address of the recording.

This parameter is required.'),
  streamInputShrink?: string(name='StreamInput', description='The URL of the live stream.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The ID of the recording template.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
}

model SubmitLiveRecordJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the recording job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
}

model SubmitLiveRecordJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveRecordJobResponseBody(name='body'),
}

/**
 * @summary Submits a live stream recording job.
 *
 * @description You can call this operation to record live streams of ApsaraVideo Live or third-party Real-Time Messaging Protocol (RTMP) live streams. We recommend that you ingest a stream before you call this operation to submit a recording job. If no stream is pulled from the streaming URL, the job attempts to pull a stream for 3 minutes. If the attempt times out, the recording service stops.
 * Before you submit a recording job, you must prepare an Object Storage Service (OSS) or ApsaraVideo VOD bucket. We recommend that you use a storage address configured in Intelligent Media Services (IMS) to facilitate the management and processing of generated recording files.
 * If the preset recording template does not meet your requirements, you can create a custom recording template.
 *
 * @param tmpReq SubmitLiveRecordJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitLiveRecordJobResponse
 */
async function submitLiveRecordJobWithOptions(tmpReq: SubmitLiveRecordJobRequest, runtime: Util.RuntimeOptions): SubmitLiveRecordJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitLiveRecordJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.recordOutput)) {
    request.recordOutputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.recordOutput, 'RecordOutput', 'json');
  }
  if (!Util.isUnset(tmpReq.streamInput)) {
    request.streamInputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.streamInput, 'StreamInput', 'json');
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.name)) {
    body['Name'] = request.name;
  }
  if (!Util.isUnset(request.notifyUrl)) {
    body['NotifyUrl'] = request.notifyUrl;
  }
  if (!Util.isUnset(request.recordOutputShrink)) {
    body['RecordOutput'] = request.recordOutputShrink;
  }
  if (!Util.isUnset(request.streamInputShrink)) {
    body['StreamInput'] = request.streamInputShrink;
  }
  if (!Util.isUnset(request.templateId)) {
    body['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'SubmitLiveRecordJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a live stream recording job.
 *
 * @description You can call this operation to record live streams of ApsaraVideo Live or third-party Real-Time Messaging Protocol (RTMP) live streams. We recommend that you ingest a stream before you call this operation to submit a recording job. If no stream is pulled from the streaming URL, the job attempts to pull a stream for 3 minutes. If the attempt times out, the recording service stops.
 * Before you submit a recording job, you must prepare an Object Storage Service (OSS) or ApsaraVideo VOD bucket. We recommend that you use a storage address configured in Intelligent Media Services (IMS) to facilitate the management and processing of generated recording files.
 * If the preset recording template does not meet your requirements, you can create a custom recording template.
 *
 * @param request SubmitLiveRecordJobRequest
 * @return SubmitLiveRecordJobResponse
 */
async function submitLiveRecordJob(request: SubmitLiveRecordJobRequest): SubmitLiveRecordJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitLiveRecordJobWithOptions(request, runtime);
}

model SubmitLiveSnapshotJobRequest {
  callbackUrl?: string(name='CallbackUrl', description='The snapshot callback URL.

*   It cannot exceed 255 characters in length.
*   Both HTTP and HTTPS URLs are supported.', example='http://www.aliyun.com/snapshot/callback'),
  jobName?: string(name='JobName', description='The name of the job.

*   It cannot exceed 128 characters in length.

This parameter is required.'),
  snapshotOutput?: {
    bucket?: string(name='Bucket', description='The bucket of the snapshot output endpoint.

This parameter is required.', example='testbucket'),
    endpoint?: string(name='Endpoint', description='The output endpoint of the snapshot.

This parameter is required.', example='oss-cn-shanghai.aliyuncs.com'),
    storageType?: string(name='StorageType', description='The storage type of the snapshot. The value can only be oss.

This parameter is required.', example='oss'),
  }(name='SnapshotOutput', description='The information about the output snapshot.

This parameter is required.'),
  streamInput?: {
    type?: string(name='Type', description='The type of the input stream. The value can only be rtmp.

This parameter is required.', example='rtmp'),
    url?: string(name='Url', description='The URL of the input stream.

*   It cannot exceed 255 characters in length.

This parameter is required.', example='rtmp://www.aliyun.com/stream'),
  }(name='StreamInput', description='The information about the input stream.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model SubmitLiveSnapshotJobShrinkRequest {
  callbackUrl?: string(name='CallbackUrl', description='The snapshot callback URL.

*   It cannot exceed 255 characters in length.
*   Both HTTP and HTTPS URLs are supported.', example='http://www.aliyun.com/snapshot/callback'),
  jobName?: string(name='JobName', description='The name of the job.

*   It cannot exceed 128 characters in length.

This parameter is required.'),
  snapshotOutputShrink?: string(name='SnapshotOutput', description='The information about the output snapshot.

This parameter is required.'),
  streamInputShrink?: string(name='StreamInput', description='The information about the input stream.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model SubmitLiveSnapshotJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287666****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitLiveSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveSnapshotJobResponseBody(name='body'),
}

/**
 * @summary Submits a live stream snapshot job. If the job is submitted during stream ingest, it automatically starts in asynchronous mode. Otherwise, it does not start.
 *
 * @param tmpReq SubmitLiveSnapshotJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitLiveSnapshotJobResponse
 */
async function submitLiveSnapshotJobWithOptions(tmpReq: SubmitLiveSnapshotJobRequest, runtime: Util.RuntimeOptions): SubmitLiveSnapshotJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitLiveSnapshotJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.snapshotOutput)) {
    request.snapshotOutputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.snapshotOutput, 'SnapshotOutput', 'json');
  }
  if (!Util.isUnset(tmpReq.streamInput)) {
    request.streamInputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.streamInput, 'StreamInput', 'json');
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.callbackUrl)) {
    body['CallbackUrl'] = request.callbackUrl;
  }
  if (!Util.isUnset(request.jobName)) {
    body['JobName'] = request.jobName;
  }
  if (!Util.isUnset(request.snapshotOutputShrink)) {
    body['SnapshotOutput'] = request.snapshotOutputShrink;
  }
  if (!Util.isUnset(request.streamInputShrink)) {
    body['StreamInput'] = request.streamInputShrink;
  }
  if (!Util.isUnset(request.templateId)) {
    body['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'SubmitLiveSnapshotJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a live stream snapshot job. If the job is submitted during stream ingest, it automatically starts in asynchronous mode. Otherwise, it does not start.
 *
 * @param request SubmitLiveSnapshotJobRequest
 * @return SubmitLiveSnapshotJobResponse
 */
async function submitLiveSnapshotJob(request: SubmitLiveSnapshotJobRequest): SubmitLiveSnapshotJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitLiveSnapshotJobWithOptions(request, runtime);
}

model SubmitLiveTranscodeJobRequest {
  name?: string(name='Name', description='The name of the transcoding job.

This parameter is required.', example='task1'),
  startMode?: int32(name='StartMode', description='The start mode of the transcoding job.

*   0: The transcoding job immediately starts.
*   1: The transcoding job starts at the scheduled time.

This parameter is required.', example='0'),
  streamInput?: {
    inputUrl?: string(name='InputUrl', description='The URL of the input stream.

This parameter is required.', example='rtmp://mydomain/app/stream1'),
    type?: string(name='Type', description='The type of the input stream. The value can only be rtmp.

This parameter is required.', example='rtmp'),
  }(name='StreamInput', description='The information about the input stream.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
  timedConfig?: {
    endTime?: string(name='EndTime', description='The stop time of the transcoding job. Note: The time span between the stop time and the current time cannot exceed seven days.', example='2022-07-20T08:20:32Z'),
    startTime?: string(name='StartTime', description='The start time of the transcoding job. Note: The time span between the start time and the current time cannot exceed seven days.', example='2022-02-21T00:00:00Z'),
  }(name='TimedConfig', description='The configuration of a timed transcoding job. This parameter is required if you set StartMode to 1.'),
  transcodeOutput?: {
    domainName?: string(name='DomainName', description='The streaming domain name of ApsaraVideo Live.', example='mydomain'),
    type?: string(name='Type', description='The type of the output stream. A value of LiveCenter indicates that the URL of the output stream is generated based on the domain name of ApsaraVideo Live. The value can only be LiveCenter.

This parameter is required.', example='LiveCenter'),
  }(name='TranscodeOutput', description='The information about the transcoding output.

This parameter is required.'),
}

model SubmitLiveTranscodeJobShrinkRequest {
  name?: string(name='Name', description='The name of the transcoding job.

This parameter is required.', example='task1'),
  startMode?: int32(name='StartMode', description='The start mode of the transcoding job.

*   0: The transcoding job immediately starts.
*   1: The transcoding job starts at the scheduled time.

This parameter is required.', example='0'),
  streamInputShrink?: string(name='StreamInput', description='The information about the input stream.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
  timedConfigShrink?: string(name='TimedConfig', description='The configuration of a timed transcoding job. This parameter is required if you set StartMode to 1.'),
  transcodeOutputShrink?: string(name='TranscodeOutput', description='The information about the transcoding output.

This parameter is required.'),
}

model SubmitLiveTranscodeJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the transcoding job.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model SubmitLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveTranscodeJobResponseBody(name='body'),
}

/**
 * @summary Submits a live stream transcoding job.
 *
 * @description *   When you submit a transcoding job that immediately takes effect, make sure that the input stream can be streamed.
 * *   When you submit a timed transcoding job, make sure that the input stream can be streamed before the specified time.
 *
 * @param tmpReq SubmitLiveTranscodeJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitLiveTranscodeJobResponse
 */
async function submitLiveTranscodeJobWithOptions(tmpReq: SubmitLiveTranscodeJobRequest, runtime: Util.RuntimeOptions): SubmitLiveTranscodeJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitLiveTranscodeJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.streamInput)) {
    request.streamInputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.streamInput, 'StreamInput', 'json');
  }
  if (!Util.isUnset(tmpReq.timedConfig)) {
    request.timedConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.timedConfig, 'TimedConfig', 'json');
  }
  if (!Util.isUnset(tmpReq.transcodeOutput)) {
    request.transcodeOutputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.transcodeOutput, 'TranscodeOutput', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.startMode)) {
    query['StartMode'] = request.startMode;
  }
  if (!Util.isUnset(request.streamInputShrink)) {
    query['StreamInput'] = request.streamInputShrink;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!Util.isUnset(request.timedConfigShrink)) {
    query['TimedConfig'] = request.timedConfigShrink;
  }
  if (!Util.isUnset(request.transcodeOutputShrink)) {
    query['TranscodeOutput'] = request.transcodeOutputShrink;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitLiveTranscodeJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a live stream transcoding job.
 *
 * @description *   When you submit a transcoding job that immediately takes effect, make sure that the input stream can be streamed.
 * *   When you submit a timed transcoding job, make sure that the input stream can be streamed before the specified time.
 *
 * @param request SubmitLiveTranscodeJobRequest
 * @return SubmitLiveTranscodeJobResponse
 */
async function submitLiveTranscodeJob(request: SubmitLiveTranscodeJobRequest): SubmitLiveTranscodeJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitLiveTranscodeJobWithOptions(request, runtime);
}

model SubmitMediaAiAnalysisJobRequest {
  analysisParams?: string(name='AnalysisParams', description='The analysis parameters.', example='{"nlpParams":{"sourceLanguage":"cn","diarizationEnabled":true,"speakerCount":0,"summarizationEnabled":false,"translationEnabled":false}}'),
  input?: string(name='Input', description='The media asset that you want to analyze. You can specify an Object Storage Service (OSS) URL, a media asset ID, or an external URL.', example='{"MediaType":"video","Media":"https://xxx.com/your_movie.mp4"}'),
  userData?: string(name='UserData'),
}

model SubmitMediaAiAnalysisJobResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model SubmitMediaAiAnalysisJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaAiAnalysisJobResponseBody(name='body'),
}

/**
 * @summary Submits a structural analysis job for a media asset. For example, you can submit a job to analyze the speaker, translate the video, and obtain the paragraph summary.
 *
 * @param request SubmitMediaAiAnalysisJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitMediaAiAnalysisJobResponse
 */
async function submitMediaAiAnalysisJobWithOptions(request: SubmitMediaAiAnalysisJobRequest, runtime: Util.RuntimeOptions): SubmitMediaAiAnalysisJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.analysisParams)) {
    query['AnalysisParams'] = request.analysisParams;
  }
  if (!Util.isUnset(request.input)) {
    query['Input'] = request.input;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitMediaAiAnalysisJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a structural analysis job for a media asset. For example, you can submit a job to analyze the speaker, translate the video, and obtain the paragraph summary.
 *
 * @param request SubmitMediaAiAnalysisJobRequest
 * @return SubmitMediaAiAnalysisJobResponse
 */
async function submitMediaAiAnalysisJob(request: SubmitMediaAiAnalysisJobRequest): SubmitMediaAiAnalysisJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitMediaAiAnalysisJobWithOptions(request, runtime);
}

model SubmitMediaCensorJobRequest {
  barrages?: string(name='Barrages', description='The live comments of the video.

>  If this parameter is specified, the system checks the live comments specified by this parameter instead of the live comments of the input file specified by Media.', example='hello world'),
  coverImages?: string(name='CoverImages', description='The Object Storage Service (OSS) objects that are used as the thumbnails. Specify the thumbnails in a JSON array. A maximum of five thumbnails are supported.

>  If this parameter is specified, the system checks the thumbnails specified by this parameter instead of the thumbnails of the input file specified by **Media**.', example='[{"Bucket":"example-bucket-****","Location":"oss-cn-shanghai","Object":"example-****.jpeg","RoleArn":"acs:ram::1997018457688683:role/AliyunICEDefaultRole"}]'),
  description?: string(name='Description', description='The video description, which can be up to 128 bytes in length.

>  If this parameter is specified, the system checks the description specified by this parameter instead of the description of the input file specified by Media.', example='example description'),
  input?: {
    media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. You can specify the path of an OSS object in one of the following formats:

1\\\\. oss://bucket/object

2\\\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the preceding paths, bucket indicates an OSS bucket that resides in the same region as the current project, and object indicates the path of the object in the bucket.', example='1b1b9cd148034739af413150fded****'),
    type?: string(name='Type', description='The type of the input file. Valid values:

OSS: OSS object.

Media: media asset.', example='Media'),
  }(name='Input', description='The information about the file to be moderated.'),
  notifyUrl?: string(name='NotifyUrl', description='The callback URL. Simple Message Queue (SMQ, formerly MNS) and HTTP callbacks are supported.', example='mns://125340688170****.oss-cn-shanghai.aliyuncs.com/queues/example-pipeline'),
  output?: string(name='Output', description='The output snapshots. The moderation job generates output snapshots and the result JSON file in the path corresponding to the input file.

*   File name format of output snapshots: oss://bucket/snapshot-{Count}.jpg. In the path, bucket indicates an OSS bucket that resides in the same region as the current project, and {Count} is the sequence number of the snapshot.
*   The detailed moderation results are stored in the {jobId}.output file in the same OSS folder as the output snapshots. For more information about the parameters in the output file, see [Output parameters of media moderation jobs](https://help.aliyun.com/document_detail/609211.html).', example='oss://sashimi-cn-shanghai/censor/snapshot-{Count}.jpg'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the job is submitted.', example='5246b8d12a62433ab77845074039****'),
    priority?: int32(name='Priority', description='The job priority. A larger value indicates a higher priority. Valid values: 1 to 10.', example='6'),
  }(name='ScheduleConfig', description='The scheduling configurations.'),
  templateId?: string(name='TemplateId', description='The template ID. If this parameter is not specified, the default template is used for moderation.', example='S00000001-100060'),
  title?: string(name='Title', description='The video title, which can be up to 64 bytes in length.

>  If this parameter is specified, the system checks the title specified by this parameter instead of the title of the input file specified by Media.', example='Hello World'),
  userData?: string(name='UserData', description='The user-defined data, which can be up to 128 bytes in length.', example='UserDatatestid-001-****'),
}

model SubmitMediaCensorJobShrinkRequest {
  barrages?: string(name='Barrages', description='The live comments of the video.

>  If this parameter is specified, the system checks the live comments specified by this parameter instead of the live comments of the input file specified by Media.', example='hello world'),
  coverImages?: string(name='CoverImages', description='The Object Storage Service (OSS) objects that are used as the thumbnails. Specify the thumbnails in a JSON array. A maximum of five thumbnails are supported.

>  If this parameter is specified, the system checks the thumbnails specified by this parameter instead of the thumbnails of the input file specified by **Media**.', example='[{"Bucket":"example-bucket-****","Location":"oss-cn-shanghai","Object":"example-****.jpeg","RoleArn":"acs:ram::1997018457688683:role/AliyunICEDefaultRole"}]'),
  description?: string(name='Description', description='The video description, which can be up to 128 bytes in length.

>  If this parameter is specified, the system checks the description specified by this parameter instead of the description of the input file specified by Media.', example='example description'),
  inputShrink?: string(name='Input', description='The information about the file to be moderated.'),
  notifyUrl?: string(name='NotifyUrl', description='The callback URL. Simple Message Queue (SMQ, formerly MNS) and HTTP callbacks are supported.', example='mns://125340688170****.oss-cn-shanghai.aliyuncs.com/queues/example-pipeline'),
  output?: string(name='Output', description='The output snapshots. The moderation job generates output snapshots and the result JSON file in the path corresponding to the input file.

*   File name format of output snapshots: oss://bucket/snapshot-{Count}.jpg. In the path, bucket indicates an OSS bucket that resides in the same region as the current project, and {Count} is the sequence number of the snapshot.
*   The detailed moderation results are stored in the {jobId}.output file in the same OSS folder as the output snapshots. For more information about the parameters in the output file, see [Output parameters of media moderation jobs](https://help.aliyun.com/document_detail/609211.html).', example='oss://sashimi-cn-shanghai/censor/snapshot-{Count}.jpg'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling configurations.'),
  templateId?: string(name='TemplateId', description='The template ID. If this parameter is not specified, the default template is used for moderation.', example='S00000001-100060'),
  title?: string(name='Title', description='The video title, which can be up to 64 bytes in length.

>  If this parameter is specified, the system checks the title specified by this parameter instead of the title of the input file specified by Media.', example='Hello World'),
  userData?: string(name='UserData', description='The user-defined data, which can be up to 128 bytes in length.', example='UserDatatestid-001-****'),
}

model SubmitMediaCensorJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the content moderation job. We recommend that you save this ID for subsequent calls of other operations.', example='88c6ca184c0e47098a5b665e2****'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model SubmitMediaCensorJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaCensorJobResponseBody(name='body'),
}

/**
 * @summary Submits a content moderation job.
 *
 * @description The job that you submit by calling this operation is run in asynchronous mode. The job is added to an ApsaraVideo Media Processing (MPS) queue to be scheduled and run. You can call the [QueryMediaCensorJobDetail](https://help.aliyun.com/document_detail/444847.html) operation or configure an asynchronous notification to obtain the job results.
 *
 * @param tmpReq SubmitMediaCensorJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitMediaCensorJobResponse
 */
async function submitMediaCensorJobWithOptions(tmpReq: SubmitMediaCensorJobRequest, runtime: Util.RuntimeOptions): SubmitMediaCensorJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitMediaCensorJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!Util.isUnset(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.barrages)) {
    query['Barrages'] = request.barrages;
  }
  if (!Util.isUnset(request.coverImages)) {
    query['CoverImages'] = request.coverImages;
  }
  if (!Util.isUnset(request.description)) {
    query['Description'] = request.description;
  }
  if (!Util.isUnset(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!Util.isUnset(request.notifyUrl)) {
    query['NotifyUrl'] = request.notifyUrl;
  }
  if (!Util.isUnset(request.output)) {
    query['Output'] = request.output;
  }
  if (!Util.isUnset(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!Util.isUnset(request.title)) {
    query['Title'] = request.title;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitMediaCensorJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a content moderation job.
 *
 * @description The job that you submit by calling this operation is run in asynchronous mode. The job is added to an ApsaraVideo Media Processing (MPS) queue to be scheduled and run. You can call the [QueryMediaCensorJobDetail](https://help.aliyun.com/document_detail/444847.html) operation or configure an asynchronous notification to obtain the job results.
 *
 * @param request SubmitMediaCensorJobRequest
 * @return SubmitMediaCensorJobResponse
 */
async function submitMediaCensorJob(request: SubmitMediaCensorJobRequest): SubmitMediaCensorJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitMediaCensorJobWithOptions(request, runtime);
}

model SubmitMediaInfoJobRequest {
  input?: {
    media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
    type?: string(name='Type', description='The type of the media object. Valid values: OSS and Media. A value of OSS indicates an Object Storage Service (OSS) object. A value of Media indicates a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The job name.', example='job-name'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling parameters.'),
  userData?: string(name='UserData', description='The user data.', example='user-data'),
}

model SubmitMediaInfoJobShrinkRequest {
  inputShrink?: string(name='Input', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The job name.', example='job-name'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling parameters.'),
  userData?: string(name='UserData', description='The user data.', example='user-data'),
}

model SubmitMediaInfoJobResponseBody = {
  mediaInfoJob?: {
    async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
    input?: {
      media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values: OSS and Media. A value of OSS indicates an OSS object. A value of Media indicates a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    mediaInfoProperty?: {
      audioStreamInfoList?: [ 
        {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
          channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
          codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
          codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
          codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
          codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
          duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
          index?: string(name='Index', description='The sequence number of the stream.', example='1'),
          lang?: string(name='Lang', description='The language of the stream.', example='us'),
          sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
          sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
          startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
          timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
        }
      ](name='AudioStreamInfoList', description='The information about the audio stream.'),
      fileBasicInfo?: {
        bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
        duration?: string(name='Duration', description='The duration of the video.', example='403.039999'),
        fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
        fileSize?: string(name='FileSize', description='The file size.', example='31737'),
        fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
        fileType?: string(name='FileType', description='The file type.', example='source_file'),
        fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
        formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
        height?: string(name='Height', description='The height of the output video.', example='478'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='2b36bd19c13f4145b094c0cad80dbce5'),
        region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
        width?: string(name='Width', description='The width of the output video.', example='848'),
      }(name='FileBasicInfo', description='The basic file information.'),
      videoStreamInfoList?: [ 
        {
          avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
          bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
          codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
          codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
          codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
          codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
          codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
          dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          fps?: string(name='Fps', description='The frame rate.', example='25.0'),
          hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
          height?: string(name='Height', description='The height of the output video.', example='478'),
          index?: string(name='Index', description='The sequence number of the stream.', example='0'),
          lang?: string(name='Lang', description='The language of the stream.', example='zh'),
          level?: string(name='Level', description='The codec level.', example='31'),
          numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
          pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
          profile?: string(name='Profile', description='The encoder profile.', example='High'),
          rotate?: string(name='Rotate', description='The rotation angle of the video image.', example='0'),
          sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
          startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
          timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
          width?: string(name='Width', description='The width of the output video.', example='848'),
        }
      ](name='VideoStreamInfoList', description='The information about the video stream.'),
    }(name='MediaInfoProperty', description='The details of the media information.'),
    name?: string(name='Name', description='The job name.', example='job-name'),
    requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling information.'),
    status?: string(name='Status', description='The state of the job. Valid values: Init (the job is submitted), Success (the job is successful), and Fail (the job failed).', example='Init'),
    submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.', example='{}'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='MediaInfoJob', description='MediaInfoJobDTO'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model SubmitMediaInfoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaInfoJobResponseBody(name='body'),
}

/**
 * @summary Submits a media information analysis job in asynchronous mode.
 *
 * @description You can call this operation to analyze an input media file by using a callback mechanism or initiating subsequent queries. This operation is suitable for scenarios in which real-time performance is less critical and high concurrency is expected.
 *
 * @param tmpReq SubmitMediaInfoJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitMediaInfoJobResponse
 */
async function submitMediaInfoJobWithOptions(tmpReq: SubmitMediaInfoJobRequest, runtime: Util.RuntimeOptions): SubmitMediaInfoJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitMediaInfoJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!Util.isUnset(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitMediaInfoJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a media information analysis job in asynchronous mode.
 *
 * @description You can call this operation to analyze an input media file by using a callback mechanism or initiating subsequent queries. This operation is suitable for scenarios in which real-time performance is less critical and high concurrency is expected.
 *
 * @param request SubmitMediaInfoJobRequest
 * @return SubmitMediaInfoJobResponse
 */
async function submitMediaInfoJob(request: SubmitMediaInfoJobRequest): SubmitMediaInfoJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitMediaInfoJobWithOptions(request, runtime);
}

model SubmitMediaProducingJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****'),
  clipsParam?: string(name='ClipsParam', description='The material parameters of the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified. For more information, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html) and [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).'),
  editingProduceConfig?: string(name='EditingProduceConfig', description='The parameters for editing and production. For more information, see [EditingProduceConfig](https://help.aliyun.com/document_detail/357745.html).

>  If no thumbnail is specified in EditingProduceConfig, the first frame of the video is used as the thumbnail.

*   AutoRegisterInputVodMedia: specifies whether to automatically register the ApsaraVideo VOD media assets in your timeline with IMS. Default value: true.
*   OutputWebmTransparentChannel: specifies whether the output video contains alpha channels. Default value: false.
*   CoverConfig: the custom thumbnail parameters.
*', example='{
      "AutoRegisterInputVodMedia": "true",
      "OutputWebmTransparentChannel": "true"
}'),
  mediaMetadata?: string(name='MediaMetadata', description='The metadata of the produced video, in the JSON format. For more information about the parameters, see [MediaMetadata](https://help.aliyun.com/document_detail/357745.html).', example='{
      "Title":"test-title",
      "Tags":"test-tags1,tags2"
}'),
  outputMediaConfig?: string(name='OutputMediaConfig', description='The configurations of the output file, in the JSON format. You can specify an OSS URL or a storage location in a storage bucket of ApsaraVideo VOD.

To store the output file in OSS, you must specify MediaURL. To store the output file in ApsaraVideo VOD, you must specify StorageLocation and FileName.

For more information, see [OutputMediaConfig](https://help.aliyun.com/document_detail/357745.html).

This parameter is required.', example='{"MediaURL":"https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4"}'),
  outputMediaTarget?: string(name='OutputMediaTarget', description='The type of the output file. Valid values:

*   oss-object: OSS object in an OSS bucket.
*   vod-media: media asset in ApsaraVideo VOD.
*   S3: output file based on the Amazon Simple Storage Service (S3) protocol.', example='oss-object'),
  projectId?: string(name='ProjectId', description='The ID of the editing project.

> : You must specify one of ProgectId, Timeline, and TempalteId and leave the other two parameters empty.', example='xxxxxfb2101cb318xxxxx'),
  projectMetadata?: string(name='ProjectMetadata', description='The metadata of the editing project, in the JSON format. For more information about the parameters, see [ProjectMetadata](https://help.aliyun.com/document_detail/357745.html).'),
  source?: string(name='Source', description='The source of the editing and production request. Valid values:

*   OpenAPI
*   AliyunConsole
*   WebSDK', example='OPENAPI'),
  templateId?: string(name='TemplateId', description='The template ID. The template is used to build a timeline with ease.

> : You must specify one of ProgectId, Timeline, and TempalteId and leave the other two parameters empty. If TemplateId is specified, ClipsParam must also be specified.', example='****96e8864746a0b6f3****'),
  timeline?: string(name='Timeline'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).', example='{"NotifyAddress":"https://xx.com/xx","RegisterMediaNotifyAddress":"https://xxx.com/xx"}'),
}

model SubmitMediaProducingJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
  mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****c469e944b5a856828dc2****'),
  projectId?: string(name='ProjectId', description='The ID of the editing project.', example='****b4549d46c88681030f6e****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
  vodMediaId?: string(name='VodMediaId', description='The media asset ID of the output file in ApsaraVideo VOD if the output file is stored in ApsaraVideo VOD.', example='****d8s4h75ci975745c14b****'),
}

model SubmitMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaProducingJobResponseBody(name='body'),
}

/**
 * @summary Submits a media editing and production job. If you need to perform any form of post-production such as editing and production on video or audio materials, you can call this operation to automate the process.
 *
 * @description *   This operation returns only the submission result of a media editing and production job. When the submission result is returned, the job may still be in progress. After a media editing and production job is submitted, the job is queued in the background for asynchronous processing.
 * *   The materials referenced in the timeline of an online editing project can be media assets in the media asset library or Object Storage Service (OSS) objects. External URLs or Alibaba Cloud Content Delivery Network (CDN) URLs are not supported. To use an OSS object as a material, you must set MediaUrl to an OSS URL, such as https://your-bucket.oss-region-name.aliyuncs.com/your-object.ext.
 * *   After the production is complete, the output file is automatically registered as a media asset. The media asset first needs to be analyzed. After the media asset is analyzed, you can query the duration and resolution information based on the media asset ID.
 * ## [](#)Limits
 * *   The throttling threshold of this operation is 30 queries per second (QPS).
 *     **
 *     **Note** If the threshold is exceeded, a "Throttling.User" error is returned when you submit an editing job. For more information about how to resolve this issue, see the [FAQ](https://help.aliyun.com/document_detail/453484.html).
 * *   You can create up to 100 video tracks, 100 image tracks, and 100 subtitle tracks in a project.
 * *   The total size of material files cannot exceed 1 TB.
 * *   The OSS buckets in which the materials reside and where the output media assets are stored must be in the same region as the region in which Intelligent Media Services (IMS) is activated.
 * *   An output video must meet the following requirements:
 *     *   Both the width and height must be at least 128 pixels.
 *     *   Both the width and height cannot exceed 4,096 pixels.
 *     *   The shorter side of the video cannot exceed 2,160 pixels.
 *
 * @param request SubmitMediaProducingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitMediaProducingJobResponse
 */
async function submitMediaProducingJobWithOptions(request: SubmitMediaProducingJobRequest, runtime: Util.RuntimeOptions): SubmitMediaProducingJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!Util.isUnset(request.clipsParam)) {
    query['ClipsParam'] = request.clipsParam;
  }
  if (!Util.isUnset(request.editingProduceConfig)) {
    query['EditingProduceConfig'] = request.editingProduceConfig;
  }
  if (!Util.isUnset(request.mediaMetadata)) {
    query['MediaMetadata'] = request.mediaMetadata;
  }
  if (!Util.isUnset(request.outputMediaConfig)) {
    query['OutputMediaConfig'] = request.outputMediaConfig;
  }
  if (!Util.isUnset(request.outputMediaTarget)) {
    query['OutputMediaTarget'] = request.outputMediaTarget;
  }
  if (!Util.isUnset(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  if (!Util.isUnset(request.projectMetadata)) {
    query['ProjectMetadata'] = request.projectMetadata;
  }
  if (!Util.isUnset(request.source)) {
    query['Source'] = request.source;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.timeline)) {
    body['Timeline'] = request.timeline;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'SubmitMediaProducingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a media editing and production job. If you need to perform any form of post-production such as editing and production on video or audio materials, you can call this operation to automate the process.
 *
 * @description *   This operation returns only the submission result of a media editing and production job. When the submission result is returned, the job may still be in progress. After a media editing and production job is submitted, the job is queued in the background for asynchronous processing.
 * *   The materials referenced in the timeline of an online editing project can be media assets in the media asset library or Object Storage Service (OSS) objects. External URLs or Alibaba Cloud Content Delivery Network (CDN) URLs are not supported. To use an OSS object as a material, you must set MediaUrl to an OSS URL, such as https://your-bucket.oss-region-name.aliyuncs.com/your-object.ext.
 * *   After the production is complete, the output file is automatically registered as a media asset. The media asset first needs to be analyzed. After the media asset is analyzed, you can query the duration and resolution information based on the media asset ID.
 * ## [](#)Limits
 * *   The throttling threshold of this operation is 30 queries per second (QPS).
 *     **
 *     **Note** If the threshold is exceeded, a "Throttling.User" error is returned when you submit an editing job. For more information about how to resolve this issue, see the [FAQ](https://help.aliyun.com/document_detail/453484.html).
 * *   You can create up to 100 video tracks, 100 image tracks, and 100 subtitle tracks in a project.
 * *   The total size of material files cannot exceed 1 TB.
 * *   The OSS buckets in which the materials reside and where the output media assets are stored must be in the same region as the region in which Intelligent Media Services (IMS) is activated.
 * *   An output video must meet the following requirements:
 *     *   Both the width and height must be at least 128 pixels.
 *     *   Both the width and height cannot exceed 4,096 pixels.
 *     *   The shorter side of the video cannot exceed 2,160 pixels.
 *
 * @param request SubmitMediaProducingJobRequest
 * @return SubmitMediaProducingJobResponse
 */
async function submitMediaProducingJob(request: SubmitMediaProducingJobRequest): SubmitMediaProducingJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitMediaProducingJobWithOptions(request, runtime);
}

model SubmitPackageJobRequest {
  inputs?: [ 
    {
      input?: {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
      }(name='Input', description='The information about the input stream file.

This parameter is required.'),
    }
  ](name='Inputs', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The name of the job.', example='job-name'),
  output?: {
    media?: string(name='Media', description='The media object. If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
    type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Output', description='The output of the job.

This parameter is required.'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling settings.'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}'),
}

model SubmitPackageJobShrinkRequest {
  inputsShrink?: string(name='Inputs', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The name of the job.', example='job-name'),
  outputShrink?: string(name='Output', description='The output of the job.

This parameter is required.'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling settings.'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}'),
}

model SubmitPackageJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='2d705f385b704ee5b*******a36d93e0'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model SubmitPackageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitPackageJobResponseBody(name='body'),
}

/**
 * @summary Submits a packaging job.
 *
 * @param tmpReq SubmitPackageJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitPackageJobResponse
 */
async function submitPackageJobWithOptions(tmpReq: SubmitPackageJobRequest, runtime: Util.RuntimeOptions): SubmitPackageJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitPackageJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.inputs)) {
    request.inputsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.inputs, 'Inputs', 'json');
  }
  if (!Util.isUnset(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  if (!Util.isUnset(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.inputsShrink)) {
    query['Inputs'] = request.inputsShrink;
  }
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!Util.isUnset(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitPackageJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a packaging job.
 *
 * @param request SubmitPackageJobRequest
 * @return SubmitPackageJobResponse
 */
async function submitPackageJob(request: SubmitPackageJobRequest): SubmitPackageJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitPackageJobWithOptions(request, runtime);
}

model SubmitScreenMediaHighlightsJobRequest {
  editingConfig?: string(name='EditingConfig', example='{
	"MediaConfig": {
		"Volume": 1
	},
	"ProcessConfig": {
		"AllowTransition": true,
		"TransitionList": ["fadecolor"]
	}
}'),
  inputConfig?: string(name='InputConfig', example='{
	"MediaArray": [
		"****9d46c886b45481030f6e****",
		"****6c886b4549d481030f6e****"
	]
}'),
  outputConfig?: string(name='OutputConfig', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 1,
  "Width": 1080,
  "Height": 1920
}'),
  userData?: string(name='UserData'),
}

model SubmitScreenMediaHighlightsJobResponseBody = {
  jobId?: string(name='JobId', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model SubmitScreenMediaHighlightsJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitScreenMediaHighlightsJobResponseBody(name='body'),
}

/**
 * @summary 提交高燃混剪任务
 *
 * @param request SubmitScreenMediaHighlightsJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitScreenMediaHighlightsJobResponse
 */
async function submitScreenMediaHighlightsJobWithOptions(request: SubmitScreenMediaHighlightsJobRequest, runtime: Util.RuntimeOptions): SubmitScreenMediaHighlightsJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.editingConfig)) {
    body['EditingConfig'] = request.editingConfig;
  }
  if (!Util.isUnset(request.inputConfig)) {
    body['InputConfig'] = request.inputConfig;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'SubmitScreenMediaHighlightsJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 提交高燃混剪任务
 *
 * @param request SubmitScreenMediaHighlightsJobRequest
 * @return SubmitScreenMediaHighlightsJobResponse
 */
async function submitScreenMediaHighlightsJob(request: SubmitScreenMediaHighlightsJobRequest): SubmitScreenMediaHighlightsJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitScreenMediaHighlightsJobWithOptions(request, runtime);
}

model SubmitSmarttagJobRequest {
  content?: string(name='Content', description='The video description. The description can contain letters, digits, and hyphens (-) and cannot start with a special character. The description can be up to 1 KB in length.', example='example content ****'),
  contentAddr?: string(name='ContentAddr', description='This parameter is discontinued.', example='http://123.com/testVideo.mp4'),
  contentType?: string(name='ContentType', description='This parameter is discontinued.', example='application/zip'),
  input?: {
    media?: string(name='Media', description='If Type is set to OSS, specify an OSS path. Example: OSS://test-bucket/video/202208/test.mp4.

If Type is set to Media, specify a media asset ID. Example: c5c62d8f0361337cab312dce8e77dc6d.

If Type is set to URL, specify an HTTP URL. Example: https://zc-test.oss-cn-shanghai.aliyuncs.com/test/unknowFace.mp4.', example='c5c62d8f0361337cab312dce8e77dc6d'),
    type?: string(name='Type', description='The media type. Valid values:

*   OSS
*   Media
*   URL', example='Media'),
  }(name='Input', description='The job input.'),
  notifyUrl?: string(name='NotifyUrl', description='The URL for receiving callbacks. Set the value to an HTTP URL or an HTTPS URL.', example='https://example.com/endpoint/aliyun/ai?id=76401125000***'),
  params?: string(name='Params', description='The additional request parameters. The value is a JSON string. Example: {"needAsrData":true, "needOcrData":false}. The following parameters are supported:

*   needAsrData: specifies whether to query the automatic speech recognition (ASR) data. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   needOcrData: specifies whether to query the optical character recognition (OCR) data. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   needMetaData: specifies whether to query the metadata. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   nlpParams: the input parameters of the natural language processing (NLP) operator. The value is a JSON object. This parameter is empty by default, which indicates that the NLP operator is not used. For more information, see the "nlpParams" section of this topic.', example='{"needAsrData":true, "needOcrData":false}'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which you want to submit the smart tagging job. The MPS queue is bound to an SMQ queue. This parameter specifies the default MPS queue. By default, an MPS queue can process a maximum of two concurrent smart tagging jobs. To increase the limit, submit a ticket.', example='acdbfe4323bcfdae'),
    priority?: string(name='Priority', description='The job priority. This parameter is not implemented. You can leave this parameter empty or enter a random value.', example='4'),
  }(name='ScheduleConfig', description='The scheduling configurations.'),
  templateId?: string(name='TemplateId', description='The ID of the template that specifies the analysis algorithms. For more information about template operations, see [Configure templates](https://help.aliyun.com/document_detail/445702.html).', example='39f8e0bc005e4f309379701645f4'),
  title?: string(name='Title', description='The video title. The title can contain letters, digits, and hyphens (-) and cannot start with a special character. The title can be up to 256 bytes in length.', example='example-title-****'),
  userData?: string(name='UserData', description='The data to be passed through Simple Message Queue (SMQ, formerly MNS) during callbacks. The data can be up to 1 KB in length. For more information about how to specify an SMQ queue for receiving callbacks, see UpdatePipeline.', example='{“a”:"test"}'),
}

model SubmitSmarttagJobShrinkRequest {
  content?: string(name='Content', description='The video description. The description can contain letters, digits, and hyphens (-) and cannot start with a special character. The description can be up to 1 KB in length.', example='example content ****'),
  contentAddr?: string(name='ContentAddr', description='This parameter is discontinued.', example='http://123.com/testVideo.mp4'),
  contentType?: string(name='ContentType', description='This parameter is discontinued.', example='application/zip'),
  inputShrink?: string(name='Input', description='The job input.'),
  notifyUrl?: string(name='NotifyUrl', description='The URL for receiving callbacks. Set the value to an HTTP URL or an HTTPS URL.', example='https://example.com/endpoint/aliyun/ai?id=76401125000***'),
  params?: string(name='Params', description='The additional request parameters. The value is a JSON string. Example: {"needAsrData":true, "needOcrData":false}. The following parameters are supported:

*   needAsrData: specifies whether to query the automatic speech recognition (ASR) data. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   needOcrData: specifies whether to query the optical character recognition (OCR) data. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   needMetaData: specifies whether to query the metadata. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   nlpParams: the input parameters of the natural language processing (NLP) operator. The value is a JSON object. This parameter is empty by default, which indicates that the NLP operator is not used. For more information, see the "nlpParams" section of this topic.', example='{"needAsrData":true, "needOcrData":false}'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling configurations.'),
  templateId?: string(name='TemplateId', description='The ID of the template that specifies the analysis algorithms. For more information about template operations, see [Configure templates](https://help.aliyun.com/document_detail/445702.html).', example='39f8e0bc005e4f309379701645f4'),
  title?: string(name='Title', description='The video title. The title can contain letters, digits, and hyphens (-) and cannot start with a special character. The title can be up to 256 bytes in length.', example='example-title-****'),
  userData?: string(name='UserData', description='The data to be passed through Simple Message Queue (SMQ, formerly MNS) during callbacks. The data can be up to 1 KB in length. For more information about how to specify an SMQ queue for receiving callbacks, see UpdatePipeline.', example='{“a”:"test"}'),
}

model SubmitSmarttagJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the smart tagging job. We recommend that you save this ID for subsequent calls of other operations.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitSmarttagJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSmarttagJobResponseBody(name='body'),
}

/**
 * @summary Submits a smart tagging job.
 *
 * @description Before you call this operation to submit a smart tagging job, you must add a smart tagging template and specify the analysis types that you want to use in the template. For more information, see CreateCustomTemplate. You can use the smart tagging feature only in the China (Beijing), China (Shanghai), and China (Hangzhou) regions. By default, an ApsaraVideo Media Processing (MPS) queue can process a maximum of two concurrent smart tagging jobs. If you need to process more concurrent smart tagging jobs, submit a ticket to contact Alibaba Cloud Technical Support for evaluation and configuration.
 *
 * @param tmpReq SubmitSmarttagJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitSmarttagJobResponse
 */
async function submitSmarttagJobWithOptions(tmpReq: SubmitSmarttagJobRequest, runtime: Util.RuntimeOptions): SubmitSmarttagJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitSmarttagJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!Util.isUnset(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.content)) {
    query['Content'] = request.content;
  }
  if (!Util.isUnset(request.contentAddr)) {
    query['ContentAddr'] = request.contentAddr;
  }
  if (!Util.isUnset(request.contentType)) {
    query['ContentType'] = request.contentType;
  }
  if (!Util.isUnset(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!Util.isUnset(request.notifyUrl)) {
    query['NotifyUrl'] = request.notifyUrl;
  }
  if (!Util.isUnset(request.params)) {
    query['Params'] = request.params;
  }
  if (!Util.isUnset(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!Util.isUnset(request.title)) {
    query['Title'] = request.title;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitSmarttagJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a smart tagging job.
 *
 * @description Before you call this operation to submit a smart tagging job, you must add a smart tagging template and specify the analysis types that you want to use in the template. For more information, see CreateCustomTemplate. You can use the smart tagging feature only in the China (Beijing), China (Shanghai), and China (Hangzhou) regions. By default, an ApsaraVideo Media Processing (MPS) queue can process a maximum of two concurrent smart tagging jobs. If you need to process more concurrent smart tagging jobs, submit a ticket to contact Alibaba Cloud Technical Support for evaluation and configuration.
 *
 * @param request SubmitSmarttagJobRequest
 * @return SubmitSmarttagJobResponse
 */
async function submitSmarttagJob(request: SubmitSmarttagJobRequest): SubmitSmarttagJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitSmarttagJobWithOptions(request, runtime);
}

model SubmitSnapshotJobRequest {
  input?: {
    media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

This parameter is required.', example='oss://bucket/object.mp4'),
    type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.

This parameter is required.', example='Media'),
  }(name='Input', description='The snapshot input.

This parameter is required.'),
  name?: string(name='Name', description='The name of the job.', example='SampleJob'),
  output?: {
    media?: string(name='Media', description='The output file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS. If multiple static snapshots were captured, the object must contain the "{Count}" placeholder. In the case of a sprite, the object must contain the "{TileCount}" placeholder. The suffix of the WebVTT snapshot objects must be ".vtt".

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the IMS console.

This parameter is required.', example='oss://test-bucket/output-{Count}.jpg'),
    type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Output', description='The snapshot output.

This parameter is required.'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='****96e8864746a0b6f3****'),
  }(name='ScheduleConfig', description='The scheduling settings.'),
  templateConfig?: {
    overwriteParams?: {
      blackLevel?: int32(name='BlackLevel', description='The threshold that is used to filter out black frames for the first snapshot to be captured. This feature is available if you request the system to capture multiple snapshots.', example='30'),
      count?: long(name='Count', description='The number of snapshots.', example='5'),
      frameType?: string(name='FrameType', description='The type of the frame.', example='intra'),
      height?: int32(name='Height', description='The height of a captured snapshot.', example='480'),
      interval?: long(name='Interval', description='The interval at which snapshots are captured.', example='10'),
      isSptFrag?: boolean(name='IsSptFrag', description='The WebVTT snapshot configuration that specifies whether to merge the output snapshots.', example='true'),
      pixelBlackThreshold?: int32(name='PixelBlackThreshold', description='The color value threshold that determines whether a pixel is black.', example='70'),
      spriteSnapshotConfig?: {
        cellHeight?: int32(name='CellHeight', description='The height of a single snapshot before tiling. The default value is the height of the output snapshot.', example='480'),
        cellWidth?: int32(name='CellWidth', description='The width of a single snapshot before tiling. The default value is the width of the output snapshot.', example='720'),
        color?: string(name='Color', description='The background color.', example='#000000'),
        columns?: int32(name='Columns', description='The number of columns that the image sprite contains.', example='20'),
        lines?: int32(name='Lines', description='The number of rows that the image sprite contains.', example='20'),
        margin?: int32(name='Margin', description='The width of the frame. Default value: 0. Unit: pixels.', example='20'),
        padding?: int32(name='Padding', description='The spacing between two adjacent snapshots. Default value: 0. Unit: pixels.', example='20'),
      }(name='SpriteSnapshotConfig', description='The configuration of the sprite snapshot.'),
      time?: long(name='Time', description='The point in time at which the system starts to capture snapshots in the input video.', example='1000'),
      type?: string(name='Type', description='The snapshot type. Valid values:', example='Sprite'),
      width?: int32(name='Width', description='The width of a captured snapshot.', example='720'),
    }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters.'),
    templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
  }(name='TemplateConfig', description='The snapshot template configuration.

This parameter is required.'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"test parameter": "test value"}'),
}

model SubmitSnapshotJobShrinkRequest {
  inputShrink?: string(name='Input', description='The snapshot input.

This parameter is required.'),
  name?: string(name='Name', description='The name of the job.', example='SampleJob'),
  outputShrink?: string(name='Output', description='The snapshot output.

This parameter is required.'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling settings.'),
  templateConfigShrink?: string(name='TemplateConfig', description='The snapshot template configuration.

This parameter is required.'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"test parameter": "test value"}'),
}

model SubmitSnapshotJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSnapshotJobResponseBody(name='body'),
}

/**
 * @summary Submits a snapshot job.
 *
 * @param tmpReq SubmitSnapshotJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitSnapshotJobResponse
 */
async function submitSnapshotJobWithOptions(tmpReq: SubmitSnapshotJobRequest, runtime: Util.RuntimeOptions): SubmitSnapshotJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitSnapshotJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!Util.isUnset(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  if (!Util.isUnset(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  if (!Util.isUnset(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!Util.isUnset(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!Util.isUnset(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitSnapshotJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a snapshot job.
 *
 * @param request SubmitSnapshotJobRequest
 * @return SubmitSnapshotJobResponse
 */
async function submitSnapshotJob(request: SubmitSnapshotJobRequest): SubmitSnapshotJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitSnapshotJobWithOptions(request, runtime);
}

model SubmitSportsHighlightsJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****'),
  inputConfig?: string(name='InputConfig', description='The input configurations.'),
  outputConfig?: string(name='OutputConfig', description='The output configurations.', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 1,
  "Width": 1080,
  "Height": 1920
}'),
  userData?: string(name='UserData', description='The user-defined data.'),
}

model SubmitSportsHighlightsJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the sports highlights job.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model SubmitSportsHighlightsJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSportsHighlightsJobResponseBody(name='body'),
}

/**
 * @summary Submits a sports highlights job to generate a highlights video of an event based on event materials that contain commentary.
 *
 * @param request SubmitSportsHighlightsJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitSportsHighlightsJobResponse
 */
async function submitSportsHighlightsJobWithOptions(request: SubmitSportsHighlightsJobRequest, runtime: Util.RuntimeOptions): SubmitSportsHighlightsJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!Util.isUnset(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.inputConfig)) {
    body['InputConfig'] = request.inputConfig;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'SubmitSportsHighlightsJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a sports highlights job to generate a highlights video of an event based on event materials that contain commentary.
 *
 * @param request SubmitSportsHighlightsJobRequest
 * @return SubmitSportsHighlightsJobResponse
 */
async function submitSportsHighlightsJob(request: SubmitSportsHighlightsJobRequest): SubmitSportsHighlightsJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitSportsHighlightsJobWithOptions(request, runtime);
}

model SubmitStandardCustomizedVoiceJobRequest {
  audios?: string(name='Audios', description='*   The material assets IDs of the materials for training.
*   Separate multiple media IDs with commas (,).

> : The total duration of all materials must be within 15 to 30 minutes. The duration of each material must be greater than 1 minute.', example='****571c704445f9a0ee011406c2****,****571c704445f9a0ee011406c2****,****571c704445f9a0ee011406c2****'),
  authentication?: string(name='Authentication', description='*   The media asset ID of the authentication audio.

*   Upload an audio file for identity authentication. If the voiceprint extracted from the uploaded file differs from that of the training file, the job fails.

    **

    **Note**: Clearly read and record the following text: I confirm to customize human voice cloning and provide audio files that contain my voice for training. I promise that I am responsible for the customized content and that the content complies with laws and regulations.', example='****571c704445f9a0ee011406c2****'),
  demoAudioMediaURL?: string(name='DemoAudioMediaURL', description='The URL of the sample audio file.

*   If this parameter is specified, a sample audio file is generated at the specified Object Storage Service (OSS) URL after the training is complete.

*   If this parameter is not specified, no sample audio file is generated.

    **

    **Note**: The URL must be a valid public OSS URL within your Alibaba Cloud account.', example='https://your-bucket.oss-cn-shanghai.aliyuncs.com/demo.mp3'),
  gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
  voiceName?: string(name='VoiceName', description='The voice name.

*   The name can be up to 32 characters in length.'),
}

model SubmitStandardCustomizedVoiceJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model SubmitStandardCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitStandardCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Submits a standard human voice cloning job. After you call this operation, the JobId is returned. The training process is asynchronous. During training, you can call the GetCustomizedVoiceJob operation to query information such as the job state.
 *
 * @param request SubmitStandardCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitStandardCustomizedVoiceJobResponse
 */
async function submitStandardCustomizedVoiceJobWithOptions(request: SubmitStandardCustomizedVoiceJobRequest, runtime: Util.RuntimeOptions): SubmitStandardCustomizedVoiceJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.audios)) {
    query['Audios'] = request.audios;
  }
  if (!Util.isUnset(request.authentication)) {
    query['Authentication'] = request.authentication;
  }
  if (!Util.isUnset(request.demoAudioMediaURL)) {
    query['DemoAudioMediaURL'] = request.demoAudioMediaURL;
  }
  if (!Util.isUnset(request.gender)) {
    query['Gender'] = request.gender;
  }
  if (!Util.isUnset(request.voiceName)) {
    query['VoiceName'] = request.voiceName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitStandardCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a standard human voice cloning job. After you call this operation, the JobId is returned. The training process is asynchronous. During training, you can call the GetCustomizedVoiceJob operation to query information such as the job state.
 *
 * @param request SubmitStandardCustomizedVoiceJobRequest
 * @return SubmitStandardCustomizedVoiceJobResponse
 */
async function submitStandardCustomizedVoiceJob(request: SubmitStandardCustomizedVoiceJobRequest): SubmitStandardCustomizedVoiceJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitStandardCustomizedVoiceJobWithOptions(request, runtime);
}

model SubmitSyncMediaInfoJobRequest {
  input?: {
    media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
    type?: string(name='Type', description='The type of the media object.

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The job name.', example='job-name'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling parameters. This parameter is optional.'),
  userData?: string(name='UserData', description='The user data.', example='user-data'),
}

model SubmitSyncMediaInfoJobShrinkRequest {
  inputShrink?: string(name='Input', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The job name.', example='job-name'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling parameters. This parameter is optional.'),
  userData?: string(name='UserData', description='The user data.', example='user-data'),
}

model SubmitSyncMediaInfoJobResponseBody = {
  mediaInfoJob?: {
    async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    input?: {
      media?: string(name='Media', description='The media object. If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    mediaInfoProperty?: {
      audioStreamInfoList?: [ 
        {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
          channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
          codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
          codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
          codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
          codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          index?: string(name='Index', description='The sequence number of the stream.', example='1'),
          lang?: string(name='Lang', description='The language of the stream.', example='us'),
          sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
          sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
          startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
          timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
        }
      ](name='AudioStreamInfoList', description='The information about the audio stream.'),
      fileBasicInfo?: {
        bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
        duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
        fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
        fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
        fileStatus?: string(name='FileStatus', description='The state of the file. Valid values:

*   Normal', example='Normal'),
        fileType?: string(name='FileType', description='The file type.', example='source_file'),
        fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
        formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
        height?: string(name='Height', description='The height of the output video.', example='478'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='999e68259c924f52a6be603cbb3f91cc'),
        region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
        width?: string(name='Width', description='The width of the output video.', example='848'),
      }(name='FileBasicInfo', description='The basic file information.'),
      videoStreamInfoList?: [ 
        {
          avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
          bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
          codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
          codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
          codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
          codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
          codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
          dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          fps?: string(name='Fps', description='The frame rate.', example='25.0'),
          hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
          height?: string(name='Height', description='The height of the output video.', example='478'),
          index?: string(name='Index', description='The sequence number of the stream.', example='0'),
          lang?: string(name='Lang', description='The language of the stream.', example='zh'),
          level?: string(name='Level', description='The codec level.', example='31'),
          numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
          pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
          profile?: string(name='Profile', description='The encoder profile.', example='High'),
          rotate?: string(name='Rotate', description='The rotation angle of the video image.', example='0'),
          sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
          startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
          timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
          width?: string(name='Width', description='The width of the output video.', example='848'),
        }
      ](name='VideoStreamInfoList', description='The information about the video stream.'),
    }(name='MediaInfoProperty', description='The details of the media information.'),
    name?: string(name='Name', description='The job name.', example='job-name'),
    requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling information.'),
    status?: string(name='Status', description='The state of the job. Valid values: Init (the job is submitted), Success (the job is successful), and Fail (the job failed).', example='Init'),
    submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.', example='{}'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='MediaInfoJob', description='MediaInfoJobDTO'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model SubmitSyncMediaInfoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSyncMediaInfoJobResponseBody(name='body'),
}

/**
 * @summary Submits a media file in synchronous mode for media information analysis.
 *
 * @description You can call this operation to analyze an input media file in synchronous mode. This operation is suitable for scenarios that require high real-time performance and low concurrency. If it takes an extended period of time to obtain the media information about the input media file, the request may time out or the obtained information may be inaccurate. We recommend that you call the [SubmitMediaInfoJob](https://help.aliyun.com/document_detail/441222.html) operation to obtain media information.
 *
 * @param tmpReq SubmitSyncMediaInfoJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitSyncMediaInfoJobResponse
 */
async function submitSyncMediaInfoJobWithOptions(tmpReq: SubmitSyncMediaInfoJobRequest, runtime: Util.RuntimeOptions): SubmitSyncMediaInfoJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitSyncMediaInfoJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!Util.isUnset(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitSyncMediaInfoJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a media file in synchronous mode for media information analysis.
 *
 * @description You can call this operation to analyze an input media file in synchronous mode. This operation is suitable for scenarios that require high real-time performance and low concurrency. If it takes an extended period of time to obtain the media information about the input media file, the request may time out or the obtained information may be inaccurate. We recommend that you call the [SubmitMediaInfoJob](https://help.aliyun.com/document_detail/441222.html) operation to obtain media information.
 *
 * @param request SubmitSyncMediaInfoJobRequest
 * @return SubmitSyncMediaInfoJobResponse
 */
async function submitSyncMediaInfoJob(request: SubmitSyncMediaInfoJobRequest): SubmitSyncMediaInfoJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitSyncMediaInfoJobWithOptions(request, runtime);
}

model SubmitTextGenerateJobRequest {
  description?: string(name='Description', description='The job description, which can be up to 1,024 bytes in length and must be encoded in UTF-8.'),
  generateConfig?: string(name='GenerateConfig', description='The text generation configurations, including keywords and the requirements for the word count and number of output copies.'),
  title?: string(name='Title', description='The job title.

The job title can be up to 128 bytes in length.

The value must be encoded in UTF-8.'),
  type?: string(name='Type', description='The job type.

Valid values:

*   MarketingCopy: the marketing copy.
*   Title: the short video title.', example='MarketingCopy'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).'),
}

model SubmitTextGenerateJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitTextGenerateJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTextGenerateJobResponseBody(name='body'),
}

/**
 * @summary Submits a text generation job to generate marketing copies based on keywords and the requirements for the word count and number of output copies. The word count of the output copies may differ from the specified word count. After the job is submitted, you can call the GetSmartHandleJob operation to obtain the job state and result based on the job ID.
 *
 * @param request SubmitTextGenerateJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitTextGenerateJobResponse
 */
async function submitTextGenerateJobWithOptions(request: SubmitTextGenerateJobRequest, runtime: Util.RuntimeOptions): SubmitTextGenerateJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.description)) {
    query['Description'] = request.description;
  }
  if (!Util.isUnset(request.generateConfig)) {
    query['GenerateConfig'] = request.generateConfig;
  }
  if (!Util.isUnset(request.title)) {
    query['Title'] = request.title;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitTextGenerateJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a text generation job to generate marketing copies based on keywords and the requirements for the word count and number of output copies. The word count of the output copies may differ from the specified word count. After the job is submitted, you can call the GetSmartHandleJob operation to obtain the job state and result based on the job ID.
 *
 * @param request SubmitTextGenerateJobRequest
 * @return SubmitTextGenerateJobResponse
 */
async function submitTextGenerateJob(request: SubmitTextGenerateJobRequest): SubmitTextGenerateJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitTextGenerateJobWithOptions(request, runtime);
}

model SubmitTraceAbJobRequest {
  cipherBase64ed?: string(name='CipherBase64ed', example='Qh6OdgIMcliQSI1fReOw****'),
  input?: {
    media?: string(name='Media', description='This parameter is required.', example='oss://bucket/object'),
    type?: string(name='Type', description='This parameter is required.', example='OSS'),
  }(name='Input', description='This parameter is required.'),
  level?: long(name='Level', example='0'),
  output?: {
    media?: string(name='Media', description='This parameter is required.', example='oss://bucket/dir/'),
    type?: string(name='Type', description='This parameter is required.', example='OSS'),
  }(name='Output', description='This parameter is required.'),
  startTime?: string(name='StartTime', example='0'),
  totalTime?: string(name='TotalTime', example='360'),
  userData?: string(name='UserData', example='123'),
}

model SubmitTraceAbJobShrinkRequest {
  cipherBase64ed?: string(name='CipherBase64ed', example='Qh6OdgIMcliQSI1fReOw****'),
  inputShrink?: string(name='Input', description='This parameter is required.'),
  level?: long(name='Level', example='0'),
  outputShrink?: string(name='Output', description='This parameter is required.'),
  startTime?: string(name='StartTime', example='0'),
  totalTime?: string(name='TotalTime', example='360'),
  userData?: string(name='UserData', example='123'),
}

model SubmitTraceAbJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', example='bfb786c639894f4d80648792021e****'),
    traceMediaId?: string(name='TraceMediaId', example='bf53333264f4d80648792021e****'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='******36-3C1E-4417-BDB2-1E034F******'),
  statusCode?: long(name='StatusCode', example='200'),
}

model SubmitTraceAbJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTraceAbJobResponseBody(name='body'),
}

/**
 * @summary 提交视频溯源水印ab流任务
 *
 * @param tmpReq SubmitTraceAbJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitTraceAbJobResponse
 */
async function submitTraceAbJobWithOptions(tmpReq: SubmitTraceAbJobRequest, runtime: Util.RuntimeOptions): SubmitTraceAbJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitTraceAbJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!Util.isUnset(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.cipherBase64ed)) {
    query['CipherBase64ed'] = request.cipherBase64ed;
  }
  if (!Util.isUnset(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!Util.isUnset(request.level)) {
    query['Level'] = request.level;
  }
  if (!Util.isUnset(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.totalTime)) {
    query['TotalTime'] = request.totalTime;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitTraceAbJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 提交视频溯源水印ab流任务
 *
 * @param request SubmitTraceAbJobRequest
 * @return SubmitTraceAbJobResponse
 */
async function submitTraceAbJob(request: SubmitTraceAbJobRequest): SubmitTraceAbJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitTraceAbJobWithOptions(request, runtime);
}

model SubmitTraceExtractJobRequest {
  input?: {
    media?: string(name='Media', description='This parameter is required.', example='oss://bucket/object'),
    type?: string(name='Type', description='This parameter is required.', example='OSS'),
  }(name='Input', description='This parameter is required.'),
  params?: string(name='Params', example='{"m3u8Type":"v1"}'),
  userData?: string(name='UserData', example='123'),
}

model SubmitTraceExtractJobShrinkRequest {
  inputShrink?: string(name='Input', description='This parameter is required.'),
  params?: string(name='Params', example='{"m3u8Type":"v1"}'),
  userData?: string(name='UserData', example='123'),
}

model SubmitTraceExtractJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', example='bfb786c639894f4d80648792021e****'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  statusCode?: long(name='StatusCode', example='200'),
}

model SubmitTraceExtractJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTraceExtractJobResponseBody(name='body'),
}

/**
 * @summary 提交溯源水印提取任务
 *
 * @param tmpReq SubmitTraceExtractJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitTraceExtractJobResponse
 */
async function submitTraceExtractJobWithOptions(tmpReq: SubmitTraceExtractJobRequest, runtime: Util.RuntimeOptions): SubmitTraceExtractJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitTraceExtractJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!Util.isUnset(request.params)) {
    query['Params'] = request.params;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitTraceExtractJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 提交溯源水印提取任务
 *
 * @param request SubmitTraceExtractJobRequest
 * @return SubmitTraceExtractJobResponse
 */
async function submitTraceExtractJob(request: SubmitTraceExtractJobRequest): SubmitTraceExtractJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitTraceExtractJobWithOptions(request, runtime);
}

model SubmitTraceM3u8JobRequest {
  keyUri?: string(name='KeyUri', example='https://cipher.abc.com'),
  output?: {
    media?: string(name='Media', description='This parameter is required.', example='oss://bucket/object'),
    type?: string(name='Type', description='This parameter is required.', example='OSS'),
  }(name='Output', description='This parameter is required.'),
  params?: string(name='Params', example='{"m3u8Type":"v1"}'),
  trace?: string(name='Trace'),
  traceMediaId?: string(name='TraceMediaId', example='437bd2b516ffda105d07b12a9a82****'),
}

model SubmitTraceM3u8JobShrinkRequest {
  keyUri?: string(name='KeyUri', example='https://cipher.abc.com'),
  outputShrink?: string(name='Output', description='This parameter is required.'),
  params?: string(name='Params', example='{"m3u8Type":"v1"}'),
  trace?: string(name='Trace'),
  traceMediaId?: string(name='TraceMediaId', example='437bd2b516ffda105d07b12a9a82****'),
}

model SubmitTraceM3u8JobResponseBody = {
  data?: {
    jobId?: string(name='JobId', example='bfb786c639894f4d8064879202****'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitTraceM3u8JobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTraceM3u8JobResponseBody(name='body'),
}

/**
 * @summary 提交视频溯源水印m3u8文件任务
 *
 * @param tmpReq SubmitTraceM3u8JobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitTraceM3u8JobResponse
 */
async function submitTraceM3u8JobWithOptions(tmpReq: SubmitTraceM3u8JobRequest, runtime: Util.RuntimeOptions): SubmitTraceM3u8JobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitTraceM3u8JobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.keyUri)) {
    query['KeyUri'] = request.keyUri;
  }
  if (!Util.isUnset(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!Util.isUnset(request.params)) {
    query['Params'] = request.params;
  }
  if (!Util.isUnset(request.trace)) {
    query['Trace'] = request.trace;
  }
  if (!Util.isUnset(request.traceMediaId)) {
    query['TraceMediaId'] = request.traceMediaId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitTraceM3u8Job',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 提交视频溯源水印m3u8文件任务
 *
 * @param request SubmitTraceM3u8JobRequest
 * @return SubmitTraceM3u8JobResponse
 */
async function submitTraceM3u8Job(request: SubmitTraceM3u8JobRequest): SubmitTraceM3u8JobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitTraceM3u8JobWithOptions(request, runtime);
}

model SubmitTranscodeJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****'),
  inputGroup?: [ 
    {
      inputUrl?: string(name='InputUrl', description='The URL of the input stream.

*   This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an input.
*   The system checks whether the input URL exists within the media asset.', example='oss://bucket/path/to/video.mp4'),
      media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
    }
  ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.

This parameter is required.', example='job-name'),
  name?: string(name='Name', description='The job name.', example='job-name'),
  outputGroup?: [ 
    {
      output?: {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the IMS console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
        outputUrl?: string(name='OutputUrl', description='The URL of the output stream.\\\\
This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an output.\\\\
Supported placeholders:

*   {MediaId}: the ID of the media asset.
*   {JobId}: the ID of the transcoding subjob.
*   {MediaBucket}: the bucket to which the media asset belongs.
*   {ExtName}: the file suffix, which uses the output format of the transcoding template.
*   {DestMd5}: the MD5 value of the transcoded output file.\\\\
    Notes:

1.  This parameter must contain the {MediaId} and {JobId} placeholders.
2.  The output bucket is the same as the bucket to which the media asset belongs.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
      }(name='Output', description='The output file configuration.

This parameter is required.'),
      processConfig?: {
        combineConfigs?: [ 
          {
            audioIndex?: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
            duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
            start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
            videoIndex?: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
          }
        ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
        encryption?: {
          cipherText?: string(name='CipherText', description='The ciphertext of HTTP Live Streaming (HLS) encryption.', example='MTYi00NDU0LTg5O****'),
          decryptKeyUri?: string(name='DecryptKeyUri', description='The address of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
          encryptType?: string(name='EncryptType', description='Specifies the encryption type. Valid values:

*   PrivateEncryption: Alibaba Cloud proprietary cryptography
*   HLSEncryption: HTTP Live Streaming (HLS) encryption', example='PrivateEncryption'),
          keyServiceType?: string(name='KeyServiceType', description='The key service type for HLS encryption. Valid values:

*   KMS
*   Base64', example='KMS'),
        }(name='Encryption', description='The encryption settings.'),
        imageWatermarks?: [ 
          {
            overwriteParams?: {
              dx?: string(name='Dx', description='The horizontal offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the horizontal offset to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
              dy?: string(name='Dy', description='The vertical offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the vertical offset to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
              file?: {
                media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
              }(name='File', description='The watermark image file.'),
              height?: string(name='Height', description='The height of the watermark image in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark height.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark height to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
              referPos?: string(name='ReferPos', description='The position of the watermark.

*   Valid values: TopRight, TopLeft, BottomRight, and BottomLeft.
*   Default value: TopRight.', example='TopLeft'),
              timeline?: {
                duration?: string(name='Duration', description='The time range in which the watermark is displayed.

*   Valid values: integers and ToEND.
*   Default value: ToEND.', example='ToEND'),
                start?: string(name='Start', description='The beginning of the time range in which the watermark is displayed.

*   Unit: seconds.
*   Value values: integers.
*   Default value: 0.', example='00:00:05'),
              }(name='Timeline', description='The time settings of the dynamic watermark.'),
              width?: string(name='Width', description='The width of the watermark in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark width.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark width to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }
        ](name='ImageWatermarks', description='The watermark configuration of an image.'),
        subtitles?: [ 
          {
            overwriteParams?: {
              charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
              file?: {
                media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
              }(name='File', description='The subtitle file.'),
              format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }
        ](name='Subtitles', description='The subtitle configuration.'),
        textWatermarks?: [ 
          {
            overwriteParams?: {
              adaptive?: string(name='Adaptive', description='Specifies whether to the font size based on the output video dimensions. true / false, default: false', example='false'),
              borderColor?: string(name='BorderColor', description='The outline color of the text watermark. Default value: black. For more information, see BorderColor.', example='#006400'),
              borderWidth?: int32(name='BorderWidth', description='The outline width of the text watermark.

*   Default value: 0.
*   Valid values: (0,4096].', example='0'),
              content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
              fontAlpha?: string(name='FontAlpha', description='The transparency of the text.

*   Valid values: (0,1].
*   Default value: 1.', example='1.0'),
              fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
              fontName?: string(name='FontName', description='The font of the text. Default value: SimSun.', example='SimSun'),
              fontSize?: int32(name='FontSize', description='The size of the text.

*   Default value: 16.
*   Valid values: (4,120).', example='16'),
              left?: string(name='Left', description='The left margin of the text watermark.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
              top?: string(name='Top', description='The top margin of the text.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }
        ](name='TextWatermarks', description='The configurations of the text watermark.'),
        transcode?: {
          overwriteParams?: {
            audio?: {
              bitrate?: string(name='Bitrate', description='The audio bitrate of the output file. Valid values: [8,1000]. Unit: Kbit/s. Default value: 128.', example='128'),
              channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
              codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
              profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
              remove?: string(name='Remove', description='Specifies whether to delete the audio stream.', example='false'),
              samplerate?: string(name='Samplerate', description='The sampling rate. Valid values: 22050, 32000, 44100, 48000, and 96000. Default value: 44100. Unit: Hz.', example='44100'),
              volume?: {
                integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
              }(name='Volume', description='The volume configurations.'),
            }(name='Audio', description='The audio settings.'),
            container?: {
              format?: string(name='Format', description='The container format.', example='mp4'),
            }(name='Container', description='The encapsulation format settings.'),
            muxConfig?: {
              segment?: {
                duration?: string(name='Duration', description='The segment length.', example='10'),
                forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
              }(name='Segment', description='The segment settings.'),
            }(name='MuxConfig', description='The encapsulation settings.'),
            transConfig?: {
              adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
              isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false: does not check the video resolution.

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
              isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckReso?: string(name='IsCheckReso', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckResoFail?: string(name='IsCheckResoFail', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
            }(name='TransConfig', description='The conditional transcoding configurations.'),
            video?: {
              abrMax?: string(name='AbrMax', description='The maximum adaptive bitrate (ABR). This parameter takes effect only for Narrowband HD 1.0. Valid values: [10,50000]. Unit: Kbit/s.', example='6000'),
              bitrate?: string(name='Bitrate', description='The average video bitrate. Valid values: [10,50000]. Unit: Kbit/s.', example='3000'),
              bufsize?: string(name='Bufsize', description='The buffer size. Valid values: [1000,128000]. Default value: 6000. Unit: KB.', example='6000'),
              codec?: string(name='Codec', description='The encoding format.', example='H.264'),
              crf?: string(name='Crf', description='The constant rate factor (CRF). Valid values: [0,51]. Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.

>  If this parameter is specified, the setting of the bitrate becomes invalid.', example='23'),
              crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
              fps?: string(name='Fps', description='The frame rate. Valid values:(0,60]. Default value: the frame rate of the input file.

>  The value is 60 if the frame rate of the input file exceeds 60.', example='25'),
              gop?: string(name='Gop', description='The maximum number of frames between keyframes. Valid values: [1,1080000]. Default value: 250.', example='250'),
              height?: string(name='Height', description='The height of the video. Valid values: [128,4096]. Unit: pixels. Default value: the original height of the video.', example='1080'),
              longShortMode?: string(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature.', example='false'),
              maxrate?: string(name='Maxrate', description='The maximum bitrate of the video. Valid values: [10,50000]. Unit: Kbit/s.', example='9000'),
              pad?: string(name='Pad', description='The black bars added to the video. Format: width:height:left:top. Example: 1280:800:0:140.', example='1280:800:0:140'),
              pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
              preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
              profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
              remove?: string(name='Remove', description='Specifies whether to remove the video.', example='false'),
              scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
              width?: string(name='Width', description='The width of the video. Valid values: [128,4096]. Unit: pixels. Default value: the original width of the video.', example='1920'),
            }(name='Video', description='The video settings.'),
          }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
          templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
        }(name='Transcode', description='The transcoding configuration.

This parameter is required.'),
      }(name='ProcessConfig', description='The job processing configuration.

This parameter is required.'),
    }
  ](name='OutputGroup', description='The output group of the job.

This parameter is required.', example='user-data'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling information about the job.', example='job-name'),
  userData?: string(name='UserData', description='The custom settings. The value must be in the JSON format and can be up to 512 bytes in length. You can specify a [custom callback URL](https://help.aliyun.com/document_detail/451631.html).', example='user-data'),
}

model SubmitTranscodeJobShrinkRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****'),
  inputGroupShrink?: string(name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.

This parameter is required.', example='job-name'),
  name?: string(name='Name', description='The job name.', example='job-name'),
  outputGroupShrink?: string(name='OutputGroup', description='The output group of the job.

This parameter is required.', example='user-data'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling information about the job.', example='job-name'),
  userData?: string(name='UserData', description='The custom settings. The value must be in the JSON format and can be up to 512 bytes in length. You can specify a [custom callback URL](https://help.aliyun.com/document_detail/451631.html).', example='user-data'),
}

model SubmitTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
  transcodeParentJob?: {
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    inputGroup?: [ 
      {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
      }
    ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
    jobCount?: int32(name='JobCount', description='The number of subjobs.', example='1'),
    name?: string(name='Name', description='The job name.', example='transcode-job'),
    outputGroup?: [ 
      {
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex?: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex?: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HLS encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The address of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='Specifies the encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The horizontal offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the horizontal offset to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                dy?: string(name='Dy', description='The vertical offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the vertical offset to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the watermark image in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark height.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark height to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
                referPos?: string(name='ReferPos', description='The position of the watermark.

*   Valid values: TopRight, TopLeft, BottomRight, and BottomLeft.
*   Default value: TopRight.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The time range in which the watermark is displayed.

*   Valid values: integers and ToEND.
*   Default value: ToEND.', example='ToEND'),
                  start?: string(name='Start', description='The beginning of the time range in which the watermark is displayed.

*   Unit: seconds.
*   Value values: integers.
*   Default value: 0.', example='00:00:05'),
                }(name='Timeline', description='The time settings of the dynamic watermark.'),
                width?: string(name='Width', description='The width of the watermark in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark width.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark width to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object. If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Specifies whether to the font size based on the output video dimensions.

*   true: false
*   default: false', example='false'),
                borderColor?: string(name='BorderColor', description='The outline color of the text watermark. Default value: black. For more information, see BorderColor.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The outline width of the text watermark.

*   Default value: 0.
*   Valid values: (0,4096].', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the text.

*   Valid values: (0,1].
*   Default value: 1.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text. Default value: SimSun.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.

*   Default value: 16.
*   Valid values: (4,120).', example='16'),
                left?: string(name='Left', description='The left margin of the text watermark.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
                top?: string(name='Top', description='The top margin of the text.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Specifies whether to delete the audio stream.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Valid values: 22050, 32000, 44100, 48000, and 96000. Default value: 44100.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false: does not check the video resolution.

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum ABR. This parameter takes effect only for Narrowband HD 1.0.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or Default value when the Codec parameter is set to H.265: 26.

If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Specifies whether to remove the video.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The job processing configuration.'),
      }
    ](name='OutputGroup', description='The output group of the job.'),
    parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
    percent?: int32(name='Percent', description='The completion percentage of the job.', example='0'),
    requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling configuration of the job.'),
    status?: string(name='Status', description='The state of the job. Success: At least one of the subjobs is successful. Fail: All subjobs failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    transcodeJobList?: [ 
      {
        createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-01-12T08:49:41Z'),
        finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
        inputGroup?: [ 
          {
            inputUrl?: string(name='InputUrl', description='The URL of the input stream:

*   This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an input.
*   The system checks whether the input URL exists within the media asset.', example='oss://bucket/path/to/video.mp4'),
            media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
            type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
          }
        ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
        jobId?: string(name='JobId', description='The subjob ID.', example='7d6a7e0d4db2457a8d45ff5d43e1bf0a'),
        jobIndex?: int32(name='JobIndex', description='The index number of the subjob in the entire job.', example='0'),
        name?: string(name='Name', description='The job name.', example='transcode-job'),
        outFileMeta?: {
          audioStreamInfoList?: [ 
            {
              bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
              channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
              channels?: string(name='Channels', description='The number of sound channels.', example='2'),
              codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
              codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
              codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
              codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
              codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              index?: string(name='Index', description='The sequence number of the stream.', example='1'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
              sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
              startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
              timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
            }
          ](name='AudioStreamInfoList', description='The information about the audio stream.'),
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
            duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
            fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
            fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
            fileType?: string(name='FileType', description='The file type. Valid values: source_file and transcode_file.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
            formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
            height?: string(name='Height', description='The height of the output video.', example='478'),
            mediaId?: string(name='MediaId', description='The ID of the media asset.', example='73e07de0f77171eca3fc7035d0b26402'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width of the output video.', example='848'),
          }(name='FileBasicInfo', description='The basic file information.'),
          videoStreamInfoList?: [ 
            {
              avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
              bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
              codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
              codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
              codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
              codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
              codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
              dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              fps?: string(name='Fps', description='The frame rate.', example='25.0'),
              hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
              height?: string(name='Height', description='The height of the output video.', example='478'),
              index?: string(name='Index', description='The sequence number of the stream.', example='0'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              level?: string(name='Level', description='The codec level.', example='31'),
              numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
              pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
              profile?: string(name='Profile', description='The encoder profile.', example='High'),
              rotate?: string(name='Rotate', description='The rotation angle of the video image. Valid values: 0, 90, 180, and 270. Default value: 0.', example='0'),
              sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
              startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
              timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
              width?: string(name='Width', description='The width of the output video.', example='848'),
            }
          ](name='VideoStreamInfoList', description='The information about the video stream.'),
        }(name='OutFileMeta', description='The media information about the video generated by the job.'),
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
          outputUrl?: string(name='OutputUrl', description='The URL of the output stream.\\\\
This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an output.\\\\
Supported placeholders:

*   {MediaId}: the ID of the media asset.
*   {JobId}: the ID of the transcoding subjob.
*   {MediaBucket}: the bucket to which the media asset belongs.
*   {ExtName}: the file suffix, which uses the output format of the transcoding template.
*   {DestMd5}: the MD5 value of the transcoded output file.\\\\
    Notes:

1.  This parameter must contain the {MediaId} and {JobId} placeholders.
2.  The output bucket is the same as the bucket to which the media asset belongs.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex?: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex?: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HLS encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The address of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='Specifies the encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The horizontal offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the horizontal offset to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                dy?: string(name='Dy', description='The vertical offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the vertical offset to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the watermark image in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark height.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark height to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
                referPos?: string(name='ReferPos', description='The position of the watermark.

*   Valid values: TopRight, TopLeft, BottomRight, and BottomLeft.
*   Default value: TopRight.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The time range in which the watermark is displayed.

*   Valid values: integers and ToEND.
*   Default value: ToEND.', example='ToEND'),
                  start?: string(name='Start', description='The beginning of the time range in which the watermark is displayed.

*   Unit: seconds.
*   Value values: integers.
*   Default value: 0.', example='00:00:05'),
                }(name='Timeline', description='The time settings of the dynamic watermark.'),
                width?: string(name='Width', description='The width of the watermark in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark width.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark width to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Specifies whether to the font size based on the output video dimensions. true / false, default: false', example='false'),
                borderColor?: string(name='BorderColor', description='The outline color of the text watermark. Default value: black. For more information, see BorderColor.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The outline width of the text watermark.

*   Default value: 0.
*   Valid values: (0,4096].', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the text.

*   Valid values: (0,1].
*   Default value: 1.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text. Default value: SimSun.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.

*   Default value: 16.
*   Valid values: (4,120).', example='16'),
                left?: string(name='Left', description='The left margin of the text watermark.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
                top?: string(name='Top', description='The top margin of the text.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Specifies whether to delete the audio stream.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100.
*   Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false: does not check the video resolution.

Default values:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution. This is the default value.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. This is the default value. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum ABR. This parameter takes effect only for Narrowband HD 1.0. Valid values: [10,50000]. Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or Default value when the Codec parameter is set to H.265: 26.

If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video. Valid values: [10,50000]. Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Specifies whether to remove the video.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The transcoding configuration.'),
        requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
        scheduleConfig?: {
          pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
          priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
        }(name='ScheduleConfig', description='The scheduling information about the job.'),
        status?: string(name='Status', description='The state of the transcoding job. Valid values:

*   Init: The job is submitted.
*   Processing: The job is in progress.
*   Success: The job is successful.
*   Fail: The job failed.
*   Deleted: The job is deleted.', example='Init'),
        submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission result.', example='{}'),
        submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
        userData?: string(name='UserData', description='The user data.', example='user-data'),
      }
    ](name='TranscodeJobList', description='The list of subjobs.'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='TranscodeParentJob', description='TranscodeParentJobWithSubJobDTO'),
}

model SubmitTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTranscodeJobResponseBody(name='body'),
}

/**
 * @summary Submits a transcoding job.
 *
 * @param tmpReq SubmitTranscodeJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitTranscodeJobResponse
 */
async function submitTranscodeJobWithOptions(tmpReq: SubmitTranscodeJobRequest, runtime: Util.RuntimeOptions): SubmitTranscodeJobResponse {
  Util.validateModel(tmpReq);
  var request = new SubmitTranscodeJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.inputGroup)) {
    request.inputGroupShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.inputGroup, 'InputGroup', 'json');
  }
  if (!Util.isUnset(tmpReq.outputGroup)) {
    request.outputGroupShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.outputGroup, 'OutputGroup', 'json');
  }
  if (!Util.isUnset(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!Util.isUnset(request.inputGroupShrink)) {
    query['InputGroup'] = request.inputGroupShrink;
  }
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.outputGroupShrink)) {
    query['OutputGroup'] = request.outputGroupShrink;
  }
  if (!Util.isUnset(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitTranscodeJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a transcoding job.
 *
 * @param request SubmitTranscodeJobRequest
 * @return SubmitTranscodeJobResponse
 */
async function submitTranscodeJob(request: SubmitTranscodeJobRequest): SubmitTranscodeJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitTranscodeJobWithOptions(request, runtime);
}

model SubmitVideoTranslationJobRequest {
  clientToken?: string(name='ClientToken', description='*   The client token.'),
  description?: string(name='Description', description='*   The job description.'),
  editingConfig?: string(name='EditingConfig', description='*   The configuration parameters of the video translation job.
*   The value must be in the JSON format.', example='{"SourceLanguage":"zh","TargetLanguage":"en","DetextArea":"Auto"}'),
  inputConfig?: string(name='InputConfig', description='*   The input parameters of the video translation job.
*   A video translation job takes a video or subtitle file as the input.
*   The value must be in the JSON format.', example='{"Type":"Video","Media":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/xxx.mp4"}'),
  outputConfig?: string(name='OutputConfig', description='*   The output parameters of the video translation job.
*   A video translation job can generate a video or subtitle file as the output.', example='{"MediaURL": "https://your-bucket.oss-cn-shanghai.aliyuncs.com/your-object.mp4"}'),
  title?: string(name='Title', description='*   The job title.'),
  userData?: string(name='UserData', description='*   The user-defined data.
*   The data must be in the JSON format, and can be up to 512 characters in length.', example='{"NotifyAddress":"http://xx.xx.xxx"}'),
}

model SubmitVideoTranslationJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the video translation job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.

Valid values:

*   true
*   false', example='true'),
}

model SubmitVideoTranslationJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitVideoTranslationJobResponseBody(name='body'),
}

/**
 * @summary Submits a video translation job. You can call this operation to translate subtitles in a video and audio to a specific language. Lip-sync adaptation will be supported in the future.
 *
 * @description After you call this operation to submit a video translation job, the system returns a job ID. You can call the GetSmartHandleJob operation based on the job ID to obtain the status and result information of the job.
 *
 * @param request SubmitVideoTranslationJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitVideoTranslationJobResponse
 */
async function submitVideoTranslationJobWithOptions(request: SubmitVideoTranslationJobRequest, runtime: Util.RuntimeOptions): SubmitVideoTranslationJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!Util.isUnset(request.description)) {
    query['Description'] = request.description;
  }
  if (!Util.isUnset(request.editingConfig)) {
    query['EditingConfig'] = request.editingConfig;
  }
  if (!Util.isUnset(request.inputConfig)) {
    query['InputConfig'] = request.inputConfig;
  }
  if (!Util.isUnset(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!Util.isUnset(request.title)) {
    query['Title'] = request.title;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'SubmitVideoTranslationJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Submits a video translation job. You can call this operation to translate subtitles in a video and audio to a specific language. Lip-sync adaptation will be supported in the future.
 *
 * @description After you call this operation to submit a video translation job, the system returns a job ID. You can call the GetSmartHandleJob operation based on the job ID to obtain the status and result information of the job.
 *
 * @param request SubmitVideoTranslationJobRequest
 * @return SubmitVideoTranslationJobResponse
 */
async function submitVideoTranslationJob(request: SubmitVideoTranslationJobRequest): SubmitVideoTranslationJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitVideoTranslationJobWithOptions(request, runtime);
}

model TakeoverAIAgentCallRequest {
  humanAgentUserId?: string(name='HumanAgentUserId', example='uid2'),
  instanceId?: string(name='InstanceId', example='39f8e0bc005e4f309379701645f4****'),
  requireToken?: boolean(name='RequireToken', example='false'),
}

model TakeoverAIAgentCallResponseBody = {
  channelId?: string(name='ChannelId', example='70f22d5784194938a7e387052f2b3208'),
  humanAgentUserId?: string(name='HumanAgentUserId', example='uid2'),
  requestId?: string(name='RequestId', example='******3B-0E1A-586A-AC29-742247******'),
  token?: string(name='Token', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx'),
}

model TakeoverAIAgentCallResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: TakeoverAIAgentCallResponseBody(name='body'),
}

/**
 * @summary 切换真人客服接管模式
 *
 * @param request TakeoverAIAgentCallRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return TakeoverAIAgentCallResponse
 */
async function takeoverAIAgentCallWithOptions(request: TakeoverAIAgentCallRequest, runtime: Util.RuntimeOptions): TakeoverAIAgentCallResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.humanAgentUserId)) {
    query['HumanAgentUserId'] = request.humanAgentUserId;
  }
  if (!Util.isUnset(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  if (!Util.isUnset(request.requireToken)) {
    query['RequireToken'] = request.requireToken;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'TakeoverAIAgentCall',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 切换真人客服接管模式
 *
 * @param request TakeoverAIAgentCallRequest
 * @return TakeoverAIAgentCallResponse
 */
async function takeoverAIAgentCall(request: TakeoverAIAgentCallRequest): TakeoverAIAgentCallResponse {
  var runtime = new Util.RuntimeOptions{};
  return takeoverAIAgentCallWithOptions(request, runtime);
}

model UpdateAIAgentInstanceRequest {
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  templateConfig?: AIAgentTemplateConfig(name='TemplateConfig'),
  userData?: string(name='UserData'),
}

model UpdateAIAgentInstanceShrinkRequest {
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  templateConfigShrink?: string(name='TemplateConfig'),
  userData?: string(name='UserData'),
}

model UpdateAIAgentInstanceResponseBody = {
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model UpdateAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAIAgentInstanceResponseBody(name='body'),
}

/**
 * @summary 修改实例的配置
 *
 * @param tmpReq UpdateAIAgentInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateAIAgentInstanceResponse
 */
async function updateAIAgentInstanceWithOptions(tmpReq: UpdateAIAgentInstanceRequest, runtime: Util.RuntimeOptions): UpdateAIAgentInstanceResponse {
  Util.validateModel(tmpReq);
  var request = new UpdateAIAgentInstanceShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  if (!Util.isUnset(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UpdateAIAgentInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 修改实例的配置
 *
 * @param request UpdateAIAgentInstanceRequest
 * @return UpdateAIAgentInstanceResponse
 */
async function updateAIAgentInstance(request: UpdateAIAgentInstanceRequest): UpdateAIAgentInstanceResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateAIAgentInstanceWithOptions(request, runtime);
}

model UpdateAvatarTrainingJobRequest {
  avatarDescription?: string(name='AvatarDescription', description='*   The description of the digital human.
*   The description can be up to 1,000 characters in length.'),
  avatarName?: string(name='AvatarName', description='*   The name of the digital human.
*   The name can be up to seven characters in length.'),
  jobId?: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****cdb3e74639973036bc84****'),
  portrait?: string(name='Portrait', description='*   The media asset ID of the portrait image.
*   The value must be 32 characters in length.', example='****571c704445f9a0ee011406c2****'),
  thumbnail?: string(name='Thumbnail', description='*   The thumbnail URL.
*   After the digital human is trained, the thumbnail is uploaded to this URL.
*   The URL must be a valid public Object Storage Service (OSS) URL.
*   The URL can be up to 512 characters in length.
*   The URL cannot be updated after the digital human is trained.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
  transparent?: boolean(name='Transparent', description='*   Indicates whether the input video supports alpha channels.

*   You can modify this parameter only if the job is in the Init or Fail state.

    **

    **Note**: Make sure that the current settings are consistent with those of the submitted training video. Otherwise, the digital human may malfunction.', example='True'),
  video?: string(name='Video', description='*   The ID of the video used for training.
*   The value must be 32 characters in length.
*   Supported formats: MP4, MOV, and WebM.
*   The duration of the video must be 5 to 15 minutes.
*   The resolution of the video must be 1920×1080 or 1080×1920.', example='****571c704445f9a0ee011406c2****'),
}

model UpdateAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAvatarTrainingJobResponseBody(name='body'),
}

/**
 * @summary Modifies a digital human training job. You can modify the basic information or update parameters such as Video and Transparent for retraining if the training failed.
 *
 * @param request UpdateAvatarTrainingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateAvatarTrainingJobResponse
 */
async function updateAvatarTrainingJobWithOptions(request: UpdateAvatarTrainingJobRequest, runtime: Util.RuntimeOptions): UpdateAvatarTrainingJobResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.avatarDescription)) {
    query['AvatarDescription'] = request.avatarDescription;
  }
  if (!Util.isUnset(request.avatarName)) {
    query['AvatarName'] = request.avatarName;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.portrait)) {
    query['Portrait'] = request.portrait;
  }
  if (!Util.isUnset(request.thumbnail)) {
    query['Thumbnail'] = request.thumbnail;
  }
  if (!Util.isUnset(request.transparent)) {
    query['Transparent'] = request.transparent;
  }
  if (!Util.isUnset(request.video)) {
    query['Video'] = request.video;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UpdateAvatarTrainingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Modifies a digital human training job. You can modify the basic information or update parameters such as Video and Transparent for retraining if the training failed.
 *
 * @param request UpdateAvatarTrainingJobRequest
 * @return UpdateAvatarTrainingJobResponse
 */
async function updateAvatarTrainingJob(request: UpdateAvatarTrainingJobRequest): UpdateAvatarTrainingJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateAvatarTrainingJobWithOptions(request, runtime);
}

model UpdateCategoryRequest {
  cateId?: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of CateId returned by the AddCategory operation that you called to create a category.
*   View the value of CateId returned by the GetCategories operation that you called to query a category.

This parameter is required.', example='43'),
  cateName?: string(name='CateName', description='The category name.

This parameter is required.'),
}

model UpdateCategoryResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
}

model UpdateCategoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateCategoryResponseBody(name='body'),
}

/**
 * @summary Updates a category.
 *
 * @description After you create a media asset category, you can call this operation to find the category based on the category ID and change the name of the category.
 *
 * @param request UpdateCategoryRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateCategoryResponse
 */
async function updateCategoryWithOptions(request: UpdateCategoryRequest, runtime: Util.RuntimeOptions): UpdateCategoryResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.cateId)) {
    query['CateId'] = request.cateId;
  }
  if (!Util.isUnset(request.cateName)) {
    query['CateName'] = request.cateName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UpdateCategory',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Updates a category.
 *
 * @description After you create a media asset category, you can call this operation to find the category based on the category ID and change the name of the category.
 *
 * @param request UpdateCategoryRequest
 * @return UpdateCategoryResponse
 */
async function updateCategory(request: UpdateCategoryRequest): UpdateCategoryResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateCategoryWithOptions(request, runtime);
}

model UpdateCustomTemplateRequest {
  name?: string(name='Name', description='The template name.', example='test-template'),
  templateConfig?: string(name='TemplateConfig', description='The [template parameters](https://help.aliyun.com/document_detail/448291.html).', example='{"param": "sample"}'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
}

model UpdateCustomTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateCustomTemplateResponseBody(name='body'),
}

/**
 * @summary Updates a custom template.
 *
 * @param request UpdateCustomTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateCustomTemplateResponse
 */
async function updateCustomTemplateWithOptions(request: UpdateCustomTemplateRequest, runtime: Util.RuntimeOptions): UpdateCustomTemplateResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.templateConfig)) {
    query['TemplateConfig'] = request.templateConfig;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UpdateCustomTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Updates a custom template.
 *
 * @param request UpdateCustomTemplateRequest
 * @return UpdateCustomTemplateResponse
 */
async function updateCustomTemplate(request: UpdateCustomTemplateRequest): UpdateCustomTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateCustomTemplateWithOptions(request, runtime);
}

model UpdateCustomizedVoiceRequest {
  demoAudioMediaId?: string(name='DemoAudioMediaId', description='The media asset ID of the sample audio file.', example='****4d5e829d498aaf966b119348****'),
  voiceId?: string(name='VoiceId', description='The voice ID.

This parameter is required.', example='xiaozhuan'),
}

model UpdateCustomizedVoiceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateCustomizedVoiceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateCustomizedVoiceResponseBody(name='body'),
}

/**
 * @summary Updates a personalized human voice. Only the media asset ID of the sample audio file can be modified.
 *
 * @param request UpdateCustomizedVoiceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateCustomizedVoiceResponse
 */
async function updateCustomizedVoiceWithOptions(request: UpdateCustomizedVoiceRequest, runtime: Util.RuntimeOptions): UpdateCustomizedVoiceResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.demoAudioMediaId)) {
    query['DemoAudioMediaId'] = request.demoAudioMediaId;
  }
  if (!Util.isUnset(request.voiceId)) {
    query['VoiceId'] = request.voiceId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UpdateCustomizedVoice',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Updates a personalized human voice. Only the media asset ID of the sample audio file can be modified.
 *
 * @param request UpdateCustomizedVoiceRequest
 * @return UpdateCustomizedVoiceResponse
 */
async function updateCustomizedVoice(request: UpdateCustomizedVoiceRequest): UpdateCustomizedVoiceResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateCustomizedVoiceWithOptions(request, runtime);
}

model UpdateEditingProjectRequest {
  businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

*   Reserving
*   ReservationCanceled', example='Reserving'),
  clipsParam?: string(name='ClipsParam', description='The material parameter corresponding to the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified.'),
  coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='https://****.com/6AB4D0E1E1C7446888****.png'),
  description?: string(name='Description', description='The description of the online editing project.', example='testtimeline001desciption'),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='****4ee4b97e27b525142a6b2****'),
  templateId?: string(name='TemplateId', description='The template ID. This parameter is used to quickly build a timeline with ease. Note: Only one of ProjectId, Timeline, and TemplateId can be specified. If TemplateId is specified, ClipsParam must also be specified.', example='****96e8864746a0b6f3****'),
  timeline?: string(name='Timeline'),
  title?: string(name='Title', description='The title of the online editing project.', example='testtimeline'),
}

model UpdateEditingProjectResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****25818875-5F78-4AF6-D7393642CA58****'),
}

model UpdateEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateEditingProjectResponseBody(name='body'),
}

/**
 * @summary Modifies an online editing project. You can call this operation to modify the configurations such as the title, timeline, and thumbnail of an online editing project.
 *
 * @param request UpdateEditingProjectRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateEditingProjectResponse
 */
async function updateEditingProjectWithOptions(request: UpdateEditingProjectRequest, runtime: Util.RuntimeOptions): UpdateEditingProjectResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.businessStatus)) {
    query['BusinessStatus'] = request.businessStatus;
  }
  if (!Util.isUnset(request.clipsParam)) {
    query['ClipsParam'] = request.clipsParam;
  }
  if (!Util.isUnset(request.coverURL)) {
    query['CoverURL'] = request.coverURL;
  }
  if (!Util.isUnset(request.description)) {
    query['Description'] = request.description;
  }
  if (!Util.isUnset(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!Util.isUnset(request.title)) {
    query['Title'] = request.title;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.timeline)) {
    body['Timeline'] = request.timeline;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'UpdateEditingProject',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Modifies an online editing project. You can call this operation to modify the configurations such as the title, timeline, and thumbnail of an online editing project.
 *
 * @param request UpdateEditingProjectRequest
 * @return UpdateEditingProjectResponse
 */
async function updateEditingProject(request: UpdateEditingProjectRequest): UpdateEditingProjectResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateEditingProjectWithOptions(request, runtime);
}

model UpdateLiveRecordTemplateRequest {
  name?: string(name='Name', description='The template name.

This parameter is required.', example='test template'),
  recordFormat?: [ 
    {
      cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds If you do not specify this parameter, the default value 6 hours is used.

> 

*   If a live stream is interrupted during a recording cycle but is resumed within 3 minutes, the stream is recorded in the same recording before and after the interruption.

*   If a live stream is interrupted for more than 3 minutes, a new recording is generated. To change the default stream interruption time, submit a ticket.', example='3600'),
      format?: string(name='Format', description='The format of recording files.

>  If you set this parameter to m3u8, you must also specify the SliceOssObjectPrefix and SliceDuration parameters.

This parameter is required.', example='m3u8'),
      ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording that is stored in Object Storage Service (OSS).

*   The name must be less than 256 bytes in length and can contain the {JobId}, {Sequence}, {StartTime}, {EndTime}, {EscapedStartTime}, and {EscapedEndTime} variables.
*   The name must contain the {StartTime} and {EndTime} variables or the {EscapedStartTime} and {EscapedEndTime} variables.', example='record/{JobId}/{Sequence}_{EscapedStartTime}_{EscapedEndTime}'),
      sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds

>  This parameter takes effect only if you set Format to m3u8.

If you do not specify this parameter, the default value 30 seconds is used. Valid values: 5 to 30.', example='30'),
      sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.

>  This parameter is required only if you set Format to m3u8. By default, the duration of a segment is 30 seconds. The segment name must be less than 256 bytes in length and can contain the {JobId}, {UnixTimestamp}, and {Sequence} variables.

The segment name must contain the {UnixTimestamp} and {Sequence} variables.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
    }
  ](name='RecordFormat', description='The list of recording formats.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
}

model UpdateLiveRecordTemplateShrinkRequest {
  name?: string(name='Name', description='The template name.

This parameter is required.', example='test template'),
  recordFormatShrink?: string(name='RecordFormat', description='The list of recording formats.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
}

model UpdateLiveRecordTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0F3D5C03-4B6E-5F40-B7F6-B1956776E7D3'),
}

model UpdateLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveRecordTemplateResponseBody(name='body'),
}

/**
 * @summary Updates the information about a live stream recording template.
 *
 * @description Only user-created templates can be updated. The preset template cannot be updated.
 *
 * @param tmpReq UpdateLiveRecordTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateLiveRecordTemplateResponse
 */
async function updateLiveRecordTemplateWithOptions(tmpReq: UpdateLiveRecordTemplateRequest, runtime: Util.RuntimeOptions): UpdateLiveRecordTemplateResponse {
  Util.validateModel(tmpReq);
  var request = new UpdateLiveRecordTemplateShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.recordFormat)) {
    request.recordFormatShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.recordFormat, 'RecordFormat', 'json');
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.name)) {
    body['Name'] = request.name;
  }
  if (!Util.isUnset(request.recordFormatShrink)) {
    body['RecordFormat'] = request.recordFormatShrink;
  }
  if (!Util.isUnset(request.templateId)) {
    body['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'UpdateLiveRecordTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Updates the information about a live stream recording template.
 *
 * @description Only user-created templates can be updated. The preset template cannot be updated.
 *
 * @param request UpdateLiveRecordTemplateRequest
 * @return UpdateLiveRecordTemplateResponse
 */
async function updateLiveRecordTemplate(request: UpdateLiveRecordTemplateRequest): UpdateLiveRecordTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateLiveRecordTemplateWithOptions(request, runtime);
}

model UpdateLiveSnapshotTemplateRequest {
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   The value cannot exceed 255 characters in length.
*   The {JobId} placeholder is supported. It specifies the ID of the snapshot job.
*   Placeholders such as {UnixTimestamp}, {Sequence}, and {Date} are not allowed.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}.jpg'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   The value cannot exceed 255 characters in length.
*   The {JobId}, {Date}, {UnixTimestamp}, and {Sequence} placeholders are supported. {JobId} specifies the ID of the snapshot job. {Date} specifies the date on which the snapshot is captured. {UnixTimestamp} specifies the timestamp of the snapshot. {Sequence} specifies the sequence number of the snapshot. You must specify at least one of the {UnixTimestamp} and {Sequence} placeholders.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}/{UnixTimestamp}.jpg'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
  templateName?: string(name='TemplateName', description='The name of the template.

*   It cannot exceed 128 characters in length.

This parameter is required.'),
  timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.

*   Valid values: [5,3600].

This parameter is required.', example='5'),
}

model UpdateLiveSnapshotTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveSnapshotTemplateResponseBody(name='body'),
}

/**
 * @summary Updates the information about a live stream snapshot template.
 *
 * @param request UpdateLiveSnapshotTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateLiveSnapshotTemplateResponse
 */
async function updateLiveSnapshotTemplateWithOptions(request: UpdateLiveSnapshotTemplateRequest, runtime: Util.RuntimeOptions): UpdateLiveSnapshotTemplateResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.overwriteFormat)) {
    body['OverwriteFormat'] = request.overwriteFormat;
  }
  if (!Util.isUnset(request.sequenceFormat)) {
    body['SequenceFormat'] = request.sequenceFormat;
  }
  if (!Util.isUnset(request.templateId)) {
    body['TemplateId'] = request.templateId;
  }
  if (!Util.isUnset(request.templateName)) {
    body['TemplateName'] = request.templateName;
  }
  if (!Util.isUnset(request.timeInterval)) {
    body['TimeInterval'] = request.timeInterval;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'UpdateLiveSnapshotTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Updates the information about a live stream snapshot template.
 *
 * @param request UpdateLiveSnapshotTemplateRequest
 * @return UpdateLiveSnapshotTemplateResponse
 */
async function updateLiveSnapshotTemplate(request: UpdateLiveSnapshotTemplateRequest): UpdateLiveSnapshotTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateLiveSnapshotTemplateWithOptions(request, runtime);
}

model UpdateLiveTranscodeJobRequest {
  jobId?: string(name='JobId', description='The job ID.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
  name?: string(name='Name', description='The name of the job.', example='mytest3'),
  streamInput?: {
    inputUrl?: string(name='InputUrl', description='The URL of the input stream.

This parameter is required.', example='rtmp://mydomain/app/stream1'),
    type?: string(name='Type', description='The type of the input stream. The value can only be rtmp.

This parameter is required.', example='rtmp'),
  }(name='StreamInput', description='The information about the input stream.'),
  timedConfig?: {
    endTime?: string(name='EndTime', description='The stop time of the transcoding job. Note: The time span between the stop time and the current time cannot exceed seven days.', example='2022-08-05T06:08:31Z'),
    startTime?: string(name='StartTime', description='The start time of the transcoding job. Note: The time span between the start time and the current time cannot exceed seven days.', example='2022-06-19T02:16:41Z'),
  }(name='TimedConfig', description='The configuration of a timed transcoding job.'),
  transcodeOutput?: {
    domainName?: string(name='DomainName', description='The streaming domain name of ApsaraVideo Live.

This parameter is required.', example='mydomain'),
    type?: string(name='Type', description='The type of the output stream. A value of LiveCenter indicates that the URL of the output stream is generated based on the domain name of ApsaraVideo Live. The value can only be LiveCenter.

This parameter is required.', example='LiveCenter'),
  }(name='TranscodeOutput', description='The information about the transcoding output.'),
}

model UpdateLiveTranscodeJobShrinkRequest {
  jobId?: string(name='JobId', description='The job ID.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
  name?: string(name='Name', description='The name of the job.', example='mytest3'),
  streamInputShrink?: string(name='StreamInput', description='The information about the input stream.'),
  timedConfigShrink?: string(name='TimedConfig', description='The configuration of a timed transcoding job.'),
  transcodeOutputShrink?: string(name='TranscodeOutput', description='The information about the transcoding output.'),
}

model UpdateLiveTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model UpdateLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveTranscodeJobResponseBody(name='body'),
}

/**
 * @summary Updates the information about a live stream transcoding job.
 *
 * @description *   For a non-timed transcoding job, you can modify the Name parameter of the job, regardless of the job state.
 * *   For a timed job, you can modify the Name, StreamInput, TranscodeOutput, and TimedConfig parameters. However, the StreamInput, TranscodeOutput, and TimedConfig parameters can be modified only when the job is not started.
 *
 * @param tmpReq UpdateLiveTranscodeJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateLiveTranscodeJobResponse
 */
async function updateLiveTranscodeJobWithOptions(tmpReq: UpdateLiveTranscodeJobRequest, runtime: Util.RuntimeOptions): UpdateLiveTranscodeJobResponse {
  Util.validateModel(tmpReq);
  var request = new UpdateLiveTranscodeJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.streamInput)) {
    request.streamInputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.streamInput, 'StreamInput', 'json');
  }
  if (!Util.isUnset(tmpReq.timedConfig)) {
    request.timedConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.timedConfig, 'TimedConfig', 'json');
  }
  if (!Util.isUnset(tmpReq.transcodeOutput)) {
    request.transcodeOutputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.transcodeOutput, 'TranscodeOutput', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.streamInputShrink)) {
    query['StreamInput'] = request.streamInputShrink;
  }
  if (!Util.isUnset(request.timedConfigShrink)) {
    query['TimedConfig'] = request.timedConfigShrink;
  }
  if (!Util.isUnset(request.transcodeOutputShrink)) {
    query['TranscodeOutput'] = request.transcodeOutputShrink;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UpdateLiveTranscodeJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Updates the information about a live stream transcoding job.
 *
 * @description *   For a non-timed transcoding job, you can modify the Name parameter of the job, regardless of the job state.
 * *   For a timed job, you can modify the Name, StreamInput, TranscodeOutput, and TimedConfig parameters. However, the StreamInput, TranscodeOutput, and TimedConfig parameters can be modified only when the job is not started.
 *
 * @param request UpdateLiveTranscodeJobRequest
 * @return UpdateLiveTranscodeJobResponse
 */
async function updateLiveTranscodeJob(request: UpdateLiveTranscodeJobRequest): UpdateLiveTranscodeJobResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateLiveTranscodeJobWithOptions(request, runtime);
}

model UpdateLiveTranscodeTemplateRequest {
  name?: string(name='Name', description='The template name.'),
  templateConfig?: {
    audioParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output audio. Unit: Kbit/s. Valid values: 1 to 1000.', example='100'),
      channels?: string(name='Channels', description='The number of sound channels. Valid values: 1: mono 2: binaural', example='2'),
      codec?: string(name='Codec', description='The audio codec. Valid values: AAC MP3', example='AAC'),
      profile?: string(name='Profile', description='The audio codec profile. Valid values when the Codec parameter is set to AAC:

*   aac_low
*   aac_he
*   aac_he_v2
*   aac_ld', example='aac_low'),
      samplerate?: string(name='Samplerate', description='The audio sampling rate. Valid values: 22050 to 96000.

Note If you set AudioProfile to aac_ld, the audio sampling rate cannot exceed 44100.', example='44100'),
    }(name='AudioParams', description='The audio parameters.'),
    videoParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output video. Unit: Kbit/s. Valid values: 1 to 6000.', example='2500'),
      codec?: string(name='Codec', description='The encoding type. Valid values:

*   H.264
*   H.265', example='H.264'),
      fps?: string(name='Fps', description='The frame rate of the output video. Unit: frames per second (FPS). Valid values: 1 to 60.', example='30'),
      gop?: string(name='Gop', description='The group of pictures (GOP) of the output video. Unit: frame. Valid values: 1 to 3000.', example='1000'),
      height?: string(name='Height', description='The height of the output video. Valid values:

*   Height ≥ 128
*   max (Height,Width) ≤ 2560
*   min（Height,Width）≤ 1440

>  The resolution of a video transcoded by using the H.265 Narrowband HD template cannot exceed 1,280 × 720 pixels.', example='720'),
      profile?: string(name='Profile', description='The video encoding profile. The profile determines how a video is encoded. In most cases, a greater value indicates better image quality and higher resource consumption. Valid values:

*   1: baseline. This value is suitable for mobile devices.
*   2: main. This value is suitable for standard-definition devices.
*   3: high. This value is suitable for high-definition devices.', example='2'),
      width?: string(name='Width', description='The width of the output video. Valid values:

*   Width ≥ 128
*   max (Height,Width) ≤ 2560
*   min（Height,Width）≤ 1440

>  The resolution of a video transcoded by using the H.265 Narrowband HD template cannot exceed 1,280 × 720 pixels.', example='1280'),
    }(name='VideoParams', description='The video parameters.'),
  }(name='TemplateConfig', description='The configuration of the template.'),
  templateId?: string(name='TemplateId', description='The template ID. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com/summary), choose Real-time Media Processing > Template Management, and then click the Transcoding tab. Alternatively, find the ID from the response parameters of the [CreateLiveTranscodeTemplate](https://help.aliyun.com/document_detail/449217.html) operation.

This parameter is required.', example='****96e8864746a0b6f3****'),
}

model UpdateLiveTranscodeTemplateShrinkRequest {
  name?: string(name='Name', description='The template name.'),
  templateConfigShrink?: string(name='TemplateConfig', description='The configuration of the template.'),
  templateId?: string(name='TemplateId', description='The template ID. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com/summary), choose Real-time Media Processing > Template Management, and then click the Transcoding tab. Alternatively, find the ID from the response parameters of the [CreateLiveTranscodeTemplate](https://help.aliyun.com/document_detail/449217.html) operation.

This parameter is required.', example='****96e8864746a0b6f3****'),
}

model UpdateLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model UpdateLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveTranscodeTemplateResponseBody(name='body'),
}

/**
 * @summary Updates the information about a live stream transcoding template.
 *
 * @param tmpReq UpdateLiveTranscodeTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateLiveTranscodeTemplateResponse
 */
async function updateLiveTranscodeTemplateWithOptions(tmpReq: UpdateLiveTranscodeTemplateRequest, runtime: Util.RuntimeOptions): UpdateLiveTranscodeTemplateResponse {
  Util.validateModel(tmpReq);
  var request = new UpdateLiveTranscodeTemplateShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UpdateLiveTranscodeTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Updates the information about a live stream transcoding template.
 *
 * @param request UpdateLiveTranscodeTemplateRequest
 * @return UpdateLiveTranscodeTemplateResponse
 */
async function updateLiveTranscodeTemplate(request: UpdateLiveTranscodeTemplateRequest): UpdateLiveTranscodeTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateLiveTranscodeTemplateWithOptions(request, runtime);
}

model UpdateMediaInfoRequest {
  appendTags?: boolean(name='AppendTags', description='Specifies whether to append tags. Default value: false. Valid values:

*   true: updates the MediaTags parameter by appending new tags.
*   false: updates the MediaTags parameter by overwriting existing tags with new tags.', example='true'),
  businessType?: string(name='BusinessType', description='The business type. Valid values:

*   subtitles
*   watermark
*   opening
*   ending
*   general', example='video'),
  cateId?: long(name='CateId', description='The category ID.', example='3048'),
  category?: string(name='Category', description='The category.

*   The value can be up to 64 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultCategory'),
  coverURL?: string(name='CoverURL', description='The URL of the thumbnail.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png'),
  description?: string(name='Description', description='The content description.

*   The value can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultDescription'),
  inputURL?: string(name='InputURL', description='The input URL of the media asset in another service. The URL must be bound to the ID of the media asset in IMS. The URL cannot be modified once registered.

For a media asset from Object Storage Service (OSS), the URL may have one of the following formats:

1\\\\. http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4

2\\\\. oss://example-bucket/example.mp4. This format indicates that the region in which the OSS bucket of the media asset resides is the same as the region in which OSS is activated.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. If this parameter is left empty, you must specify the input URL of the media asset, which has been registered in the IMS content library.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaTags?: string(name='MediaTags', description='The tags.

*   Up to 16 tags are supported.
*   Separate multiple tags with commas (,).
*   Each tag can be up to 32 bytes in length.
*   The value must be encoded in UTF-8.', example='updateTags1,updateTags2'),
  referenceId?: string(name='ReferenceId', description='The custom ID. The ID can be 6 to 64 characters in length and can contain only letters, digits, hyphens (-), and underscores (_). Make sure that the ID is unique among users.', example='123-123'),
  title?: string(name='Title', description='The title.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultTitle'),
  userData?: string(name='UserData', description='The user data. It can be up to 1,024 bytes in size.', example='userData'),
}

model UpdateMediaInfoResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset in IMS.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaInfoResponseBody(name='body'),
}

/**
 * @summary Updates information about a media asset based on the ID of the media asset in Intelligent Media Services (IMS) or the input URL of the media asset.
 *
 * @description If the MediaId parameter is specified, the MediaId parameter is preferentially used for the query. If the MediaId parameter is left empty, the InputURL parameter must be specified. The request ID and media asset ID are returned. You cannot modify the input URL of a media asset by specifying the ID of the media asset.
 *
 * @param request UpdateMediaInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateMediaInfoResponse
 */
async function updateMediaInfoWithOptions(request: UpdateMediaInfoRequest, runtime: Util.RuntimeOptions): UpdateMediaInfoResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.appendTags)) {
    query['AppendTags'] = request.appendTags;
  }
  if (!Util.isUnset(request.businessType)) {
    query['BusinessType'] = request.businessType;
  }
  if (!Util.isUnset(request.cateId)) {
    query['CateId'] = request.cateId;
  }
  if (!Util.isUnset(request.category)) {
    query['Category'] = request.category;
  }
  if (!Util.isUnset(request.coverURL)) {
    query['CoverURL'] = request.coverURL;
  }
  if (!Util.isUnset(request.description)) {
    query['Description'] = request.description;
  }
  if (!Util.isUnset(request.inputURL)) {
    query['InputURL'] = request.inputURL;
  }
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.mediaTags)) {
    query['MediaTags'] = request.mediaTags;
  }
  if (!Util.isUnset(request.referenceId)) {
    query['ReferenceId'] = request.referenceId;
  }
  if (!Util.isUnset(request.title)) {
    query['Title'] = request.title;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UpdateMediaInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Updates information about a media asset based on the ID of the media asset in Intelligent Media Services (IMS) or the input URL of the media asset.
 *
 * @description If the MediaId parameter is specified, the MediaId parameter is preferentially used for the query. If the MediaId parameter is left empty, the InputURL parameter must be specified. The request ID and media asset ID are returned. You cannot modify the input URL of a media asset by specifying the ID of the media asset.
 *
 * @param request UpdateMediaInfoRequest
 * @return UpdateMediaInfoResponse
 */
async function updateMediaInfo(request: UpdateMediaInfoRequest): UpdateMediaInfoResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateMediaInfoWithOptions(request, runtime);
}

model UpdateMediaMarksRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='53afdf003a******6a16b5feac6402'),
  mediaMarks?: string(name='MediaMarks', description='The marks of the media asset.

This parameter is required.'),
}

model UpdateMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='53afdf003a******6a16b5feac6402'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The IDs of the successfully modified marks.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaMarksResponseBody(name='body'),
}

/**
 * @summary Modifies the marks of a media asset.
 *
 * @param request UpdateMediaMarksRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateMediaMarksResponse
 */
async function updateMediaMarksWithOptions(request: UpdateMediaMarksRequest, runtime: Util.RuntimeOptions): UpdateMediaMarksResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.mediaMarks)) {
    query['MediaMarks'] = request.mediaMarks;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UpdateMediaMarks',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Modifies the marks of a media asset.
 *
 * @param request UpdateMediaMarksRequest
 * @return UpdateMediaMarksResponse
 */
async function updateMediaMarks(request: UpdateMediaMarksRequest): UpdateMediaMarksResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateMediaMarksWithOptions(request, runtime);
}

model UpdateMediaToSearchLibRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='****019b82e24b37a1c2958dec38****'),
  msgBody?: string(name='MsgBody', description='The message body.

This parameter is required.', example='{}'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1'),
}

model UpdateMediaToSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateMediaToSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaToSearchLibResponseBody(name='body'),
}

/**
 * @summary Updates the media asset information in a search library.
 *
 * @param request UpdateMediaToSearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateMediaToSearchLibResponse
 */
async function updateMediaToSearchLibWithOptions(request: UpdateMediaToSearchLibRequest, runtime: Util.RuntimeOptions): UpdateMediaToSearchLibResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.msgBody)) {
    query['MsgBody'] = request.msgBody;
  }
  if (!Util.isUnset(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UpdateMediaToSearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Updates the media asset information in a search library.
 *
 * @param request UpdateMediaToSearchLibRequest
 * @return UpdateMediaToSearchLibResponse
 */
async function updateMediaToSearchLib(request: UpdateMediaToSearchLibRequest): UpdateMediaToSearchLibResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateMediaToSearchLibWithOptions(request, runtime);
}

model UpdatePipelineRequest {
  name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
  pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.

This parameter is required.', example='****d80e4e4044975745c14b****'),
  priority?: int32(name='Priority', description='The priority of the MPS queue. Valid values: 1 to 10.', example='6'),
  status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Paused'),
}

model UpdatePipelineResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdatePipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdatePipelineResponseBody(name='body'),
}

/**
 * @summary Updates the information about an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request UpdatePipelineRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdatePipelineResponse
 */
async function updatePipelineWithOptions(request: UpdatePipelineRequest, runtime: Util.RuntimeOptions): UpdatePipelineResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.pipelineId)) {
    query['PipelineId'] = request.pipelineId;
  }
  if (!Util.isUnset(request.priority)) {
    query['Priority'] = request.priority;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UpdatePipeline',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Updates the information about an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request UpdatePipelineRequest
 * @return UpdatePipelineResponse
 */
async function updatePipeline(request: UpdatePipelineRequest): UpdatePipelineResponse {
  var runtime = new Util.RuntimeOptions{};
  return updatePipelineWithOptions(request, runtime);
}

model UpdateRtcRobotInstanceRequest {
  config?: {
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt', example='false'),
    greeting?: string(name='Greeting'),
    voiceId?: string(name='VoiceId', example='zhixiaoxia'),
  }(name='Config'),
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='727dc0e296014bb58670940a3da95592'),
}

model UpdateRtcRobotInstanceShrinkRequest {
  configShrink?: string(name='Config'),
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='727dc0e296014bb58670940a3da95592'),
}

model UpdateRtcRobotInstanceResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='7707F0A2-C6FD-5959-87EB-7C4D02384FD4'),
}

model UpdateRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateRtcRobotInstanceResponseBody(name='body'),
}

/**
 * @summary 修改实例的配置
 *
 * @param tmpReq UpdateRtcRobotInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateRtcRobotInstanceResponse
 */
async function updateRtcRobotInstanceWithOptions(tmpReq: UpdateRtcRobotInstanceRequest, runtime: Util.RuntimeOptions): UpdateRtcRobotInstanceResponse {
  Util.validateModel(tmpReq);
  var request = new UpdateRtcRobotInstanceShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.config)) {
    request.configShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.config, 'Config', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.configShrink)) {
    query['Config'] = request.configShrink;
  }
  if (!Util.isUnset(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UpdateRtcRobotInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary 修改实例的配置
 *
 * @param request UpdateRtcRobotInstanceRequest
 * @return UpdateRtcRobotInstanceResponse
 */
async function updateRtcRobotInstance(request: UpdateRtcRobotInstanceRequest): UpdateRtcRobotInstanceResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateRtcRobotInstanceWithOptions(request, runtime);
}

model UpdateTemplateRequest {
  config?: string(name='Config', example='参见模板Config文档'),
  coverUrl?: string(name='CoverUrl', description='The URL of the template thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
  name?: string(name='Name', description='The name of the online editing template.', example='视频添加水印模板'),
  previewMedia?: string(name='PreviewMedia', description='The ID of the preview video.', example='****20b48fb04483915d4f2cd8ac****'),
  relatedMediaids?: string(name='RelatedMediaids', description='The IDs of the materials associated with the template for use by the regular template editor.', example='{"video":["******c04f1d4a06996144cc1a******","******cb7db64841b159b4f2ea******"],"audio":["******c04f1d4a06996144cc1a******"],"image":["******c04f1d4a06996144cc1a******"]}'),
  source?: string(name='Source', description='The source from which the template is modified. Default value: OpenAPI. Valid values:

*   AliyunConsole
*   OpenAPI
*   WebSDK', example='OpenAPI'),
  status?: string(name='Status', description='The template state. Valid values:

*   Available: The template is available.
*   Created: The template is created but not ready for use.
*   Uploading: The video is being uploaded.
*   Processing: The advanced template is being processed.
*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.

>  After an advanced template is created, it enters the Processing state. In this case, the template is unavailable. The template can be used only when it is in the Available state. The time required for template processing varies based on the size of the template file. Generally, it ranges from 10 seconds to 5 minutes.', example='Available'),
  templateId?: string(name='TemplateId', description='The ID of the online editing template. You can obtain the template ID in the [Intelligent Media Services (IMS) console](https://ice.console.aliyun.com/production/template/list/common) or the response parameters of the [AddTemplate](https://help.aliyun.com/document_detail/441161.html) operation.', example='****20b48fb04483915d4f2cd8ac****'),
}

model UpdateTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateTemplateResponseBody(name='body'),
}

/**
 * @summary Modifies an online editing template. You can modify the template title and template configurations.
 *
 * @description *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request UpdateTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateTemplateResponse
 */
async function updateTemplateWithOptions(request: UpdateTemplateRequest, runtime: Util.RuntimeOptions): UpdateTemplateResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.coverUrl)) {
    query['CoverUrl'] = request.coverUrl;
  }
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  if (!Util.isUnset(request.previewMedia)) {
    query['PreviewMedia'] = request.previewMedia;
  }
  if (!Util.isUnset(request.relatedMediaids)) {
    query['RelatedMediaids'] = request.relatedMediaids;
  }
  if (!Util.isUnset(request.source)) {
    query['Source'] = request.source;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  if (!Util.isUnset(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.config)) {
    body['Config'] = request.config;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'UpdateTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Modifies an online editing template. You can modify the template title and template configurations.
 *
 * @description *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request UpdateTemplateRequest
 * @return UpdateTemplateResponse
 */
async function updateTemplate(request: UpdateTemplateRequest): UpdateTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateTemplateWithOptions(request, runtime);
}

model UploadMediaByURLRequest {
  appId?: string(name='AppId', description='The application ID.', example='app-1000000'),
  entityId?: string(name='EntityId', description='The entity ID. You can call the CreateEntity operation to create an entity and specify a dynamic metadata structure.', example='d67281da3c8743b8823ad12976187***'),
  mediaMetaData?: string(name='MediaMetaData', description='The metadata of the media file that you want to upload. The value must be a JSON string.

*   This parameter takes effect only if its value matches a URL that is specified in UploadURLs.
*   You must convert the JSON-formatted data, such as [UploadMetadata, UploadMetadata,…], into a JSON string.
*   For more information, see the "UploadMetadata" section of this topic.', example='[{"SourceURL":"https://example.aliyundoc.com/video01.mp4","Title":"urlUploadTest"}]'),
  postProcessConfig?: string(name='PostProcessConfig', description='The postprocessing configurations. You can specify this parameter if Type is set to video or audio.

Set ProcessType to Workflow.', example='{"ProcessType": "Workflow","ProcessID":"b72a06c6beeb4dcdb898feef067b1***"}'),
  uploadTargetConfig?: string(name='UploadTargetConfig', description='The destination storage address.

Set StorageType to oss.

Set StorageLocation to an address in ApsaraVideo VOD. You cannot set this field to an OSS URL.', example='{"StorageType":"oss","StorageLocation":"outin-***.oss-cn-shanghai.aliyuncs.com"}'),
  uploadURLs?: string(name='UploadURLs', description='The URL of the source file.

*   The URL must contain a file name extension, such as mp4 in `https://****.mp4`.

    *   If the URL does not contain a file name extension, you can specify one by setting `FileExtension` in `UploadMetadata`.
    *   If the URL contains a file name extension and `FileExtension` is also specified, the value of `FileExtension` prevails.

*   URL encoding is required. Separate multiple URLs with commas (,). You can specify a maximum of 20 URLs.

*   Special characters may cause upload failures. Therefore, you must encode URLs before you separate them with commas (,).', example='https://diffurl.mp4'),
  userData?: string(name='UserData', description='The user data. The value must be a JSON string. You can configure settings such as message callbacks.', example='{"MessageCallback":{"CallbackURL":"http://example.aliyundoc.com"},"Extend":{"localId":"xxx","test":"www"}}'),
}

model UploadMediaByURLResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****83B7-7F87-4792-BFE9-63CD2137****'),
  uploadJobs?: [ 
    {
      jobId?: string(name='JobId', description='The ID of the upload job.', example='20ce1e05dba64576b96e9683879f0***'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='f476988629f54a7b8a4ba90d1a6c7***'),
      sourceURL?: string(name='SourceURL', description='The URL of the source file that is uploaded in the upload job.', example='http://example****.mp4'),
    }
  ](name='UploadJobs', description='The information about upload jobs.'),
}

model UploadMediaByURLResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UploadMediaByURLResponseBody(name='body'),
}

/**
 * @summary Uploads an audio or video file based on the URL of the source file. You can upload multiple media files at a time.
 *
 * @description *   If a callback is configured, you will receive an UploadByURLComplete event notification after the file is uploaded. You can query the upload status by calling the GetURLUploadInfos operation.
 * *   After a request is submitted, the upload job is queued as an asynchronous job in the cloud. You can query the status of the upload job based on information such as the URL and media asset ID that are returned in the event notification.
 * *   You can call this operation to upload media files that are not stored on a local server or device and must be uploaded by using URLs that are accessible over the Internet.
 * *   You can call this operation to upload media files only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media file to an OSS bucket, pull the file to a local directory, use [OSS SDK](https://help.aliyun.com/document_detail/32006.html) to upload the file to an OSS bucket, and then call the [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html) operation to register the file in the OSS bucket with the media asset library.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 * *   You can call this operation to upload only audio and video files.
 *
 * @param request UploadMediaByURLRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UploadMediaByURLResponse
 */
async function uploadMediaByURLWithOptions(request: UploadMediaByURLRequest, runtime: Util.RuntimeOptions): UploadMediaByURLResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.appId)) {
    query['AppId'] = request.appId;
  }
  if (!Util.isUnset(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  if (!Util.isUnset(request.mediaMetaData)) {
    query['MediaMetaData'] = request.mediaMetaData;
  }
  if (!Util.isUnset(request.postProcessConfig)) {
    query['PostProcessConfig'] = request.postProcessConfig;
  }
  if (!Util.isUnset(request.uploadTargetConfig)) {
    query['UploadTargetConfig'] = request.uploadTargetConfig;
  }
  if (!Util.isUnset(request.uploadURLs)) {
    query['UploadURLs'] = request.uploadURLs;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UploadMediaByURL',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Uploads an audio or video file based on the URL of the source file. You can upload multiple media files at a time.
 *
 * @description *   If a callback is configured, you will receive an UploadByURLComplete event notification after the file is uploaded. You can query the upload status by calling the GetURLUploadInfos operation.
 * *   After a request is submitted, the upload job is queued as an asynchronous job in the cloud. You can query the status of the upload job based on information such as the URL and media asset ID that are returned in the event notification.
 * *   You can call this operation to upload media files that are not stored on a local server or device and must be uploaded by using URLs that are accessible over the Internet.
 * *   You can call this operation to upload media files only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media file to an OSS bucket, pull the file to a local directory, use [OSS SDK](https://help.aliyun.com/document_detail/32006.html) to upload the file to an OSS bucket, and then call the [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html) operation to register the file in the OSS bucket with the media asset library.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 * *   You can call this operation to upload only audio and video files.
 *
 * @param request UploadMediaByURLRequest
 * @return UploadMediaByURLResponse
 */
async function uploadMediaByURL(request: UploadMediaByURLRequest): UploadMediaByURLResponse {
  var runtime = new Util.RuntimeOptions{};
  return uploadMediaByURLWithOptions(request, runtime);
}

model UploadStreamByURLRequest {
  definition?: string(name='Definition', description='The quality of the media stream. Valid values:

*   FD: low definition.
*   LD: standard definition.
*   SD: high definition.
*   HD: ultra-high definition.
*   OD: original quality.
*   2K: 2K resolution.
*   4K: 4K resolution.
*   SQ: standard sound quality.
*   HQ: high sound quality.', example='HD'),
  fileExtension?: string(name='FileExtension', description='The file name extension of the media stream.', example='mp4'),
  HDRType?: string(name='HDRType', description='The high dynamic range (HDR) format of the transcoded stream. Valid values:

*   HDR
*   HDR10
*   HLG
*   DolbyVision
*   HDRVivid
*   SDR+

> 

*   The value is not case-sensitive,

*   You can leave this parameter empty for non-HDR streams.', example='HDR10'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***'),
  streamURL?: string(name='StreamURL', description='The URL of the transcoded stream file.

If the URL of the transcoded stream requires authentication, you must specify the authentication parameters in the stream URL and make sure that the URL can be accessed over the Internet.', example='https://example.com/sample-stream.mp4'),
  userData?: string(name='UserData', description='The user data.', example='{"MessageCallback":{"CallbackURL":"http://test.test.com"}, "Extend":{"localId":"xxx","test":"www"}}'),
}

model UploadStreamByURLResponseBody = {
  fileURL?: string(name='FileURL', description='The OSS URL of the file.', example='http://outin-***.oss-cn-shanghai.aliyuncs.com/stream/48555e8b-181dd5a8c07/48555e8b-181dd5a8c07.mp4'),
  jobId?: string(name='JobId', description='The ID of the upload job.', example='****cdb3e74639973036bc84****'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***'),
  requestId?: string(name='RequestId', description='The request ID.', example='******89-C21D-4B78-AE24-3788B8******'),
  sourceURL?: string(name='SourceURL', description='The URL of the source file that is uploaded in the upload job.', example='https://example.com/sample-stream.mp4'),
}

model UploadStreamByURLResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UploadStreamByURLResponseBody(name='body'),
}

/**
 * @summary Uploads a media stream file based on the URL of the source file.
 *
 * @description *   You can call this operation to pull a media stream file based on a URL and upload the file. After the media stream file is uploaded, the media stream is associated with the specified media asset ID.
 * *   You can call this operation to upload media stream files only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media stream file to an OSS bucket, pull the file to a local directory, use [OSS SDK](https://help.aliyun.com/document_detail/32006.html) to upload the file to an OSS bucket, and then call the [RegisterMediaStream](https://help.aliyun.com/document_detail/440765.html) operation to associate the media stream with the specified media asset ID.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 *
 * @param request UploadStreamByURLRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UploadStreamByURLResponse
 */
async function uploadStreamByURLWithOptions(request: UploadStreamByURLRequest, runtime: Util.RuntimeOptions): UploadStreamByURLResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.definition)) {
    query['Definition'] = request.definition;
  }
  if (!Util.isUnset(request.fileExtension)) {
    query['FileExtension'] = request.fileExtension;
  }
  if (!Util.isUnset(request.HDRType)) {
    query['HDRType'] = request.HDRType;
  }
  if (!Util.isUnset(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!Util.isUnset(request.streamURL)) {
    query['StreamURL'] = request.streamURL;
  }
  if (!Util.isUnset(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UploadStreamByURL',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Uploads a media stream file based on the URL of the source file.
 *
 * @description *   You can call this operation to pull a media stream file based on a URL and upload the file. After the media stream file is uploaded, the media stream is associated with the specified media asset ID.
 * *   You can call this operation to upload media stream files only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media stream file to an OSS bucket, pull the file to a local directory, use [OSS SDK](https://help.aliyun.com/document_detail/32006.html) to upload the file to an OSS bucket, and then call the [RegisterMediaStream](https://help.aliyun.com/document_detail/440765.html) operation to associate the media stream with the specified media asset ID.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 *
 * @param request UploadStreamByURLRequest
 * @return UploadStreamByURLResponse
 */
async function uploadStreamByURL(request: UploadStreamByURLRequest): UploadStreamByURLResponse {
  var runtime = new Util.RuntimeOptions{};
  return uploadStreamByURLWithOptions(request, runtime);
}

