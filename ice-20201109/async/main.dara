/**
  *
  */
import BaseClientBuilder;
import TeaAsyncHandler;
import TeaRequest;
import AsyncRequestBody;
import RequestBody;
import AsyncResponseHandler;
import ClientConfiguration;
import ClientExecutionParams;
extends BaseClientBuilder;
type @product = string
type @version = string
type @endpointRule = string
type @endpointMap = map[string]string
type @REQUEST = TeaRequest
type @handler = TeaAsyncHandler

init(configuration: ClientConfiguration){
  @handler = new TeaAsyncHandler(configuration);
  @product = 'ICE';
  @version = '2020-11-09';
  @endpointRule = 'regional';
  @endpointMap = {
    'ap-northeast-1' = 'ice.aliyuncs.com',
    'ap-northeast-2-pop' = 'ice.aliyuncs.com',
    'ap-south-1' = 'ice.aliyuncs.com',
    'ap-southeast-1' = 'ice.aliyuncs.com',
    'ap-southeast-2' = 'ice.aliyuncs.com',
    'ap-southeast-3' = 'ice.aliyuncs.com',
    'ap-southeast-5' = 'ice.aliyuncs.com',
    'cn-beijing' = 'ice.aliyuncs.com',
    'cn-beijing-finance-1' = 'ice.aliyuncs.com',
    'cn-beijing-finance-pop' = 'ice.aliyuncs.com',
    'cn-beijing-gov-1' = 'ice.aliyuncs.com',
    'cn-beijing-nu16-b01' = 'ice.aliyuncs.com',
    'cn-chengdu' = 'ice.aliyuncs.com',
    'cn-edge-1' = 'ice.aliyuncs.com',
    'cn-fujian' = 'ice.aliyuncs.com',
    'cn-haidian-cm12-c01' = 'ice.aliyuncs.com',
    'cn-hangzhou' = 'ice.aliyuncs.com',
    'cn-hangzhou-bj-b01' = 'ice.aliyuncs.com',
    'cn-hangzhou-finance' = 'ice.aliyuncs.com',
    'cn-hangzhou-internal-prod-1' = 'ice.aliyuncs.com',
    'cn-hangzhou-internal-test-1' = 'ice.aliyuncs.com',
    'cn-hangzhou-internal-test-2' = 'ice.aliyuncs.com',
    'cn-hangzhou-internal-test-3' = 'ice.aliyuncs.com',
    'cn-hangzhou-test-306' = 'ice.aliyuncs.com',
    'cn-hongkong' = 'ice.aliyuncs.com',
    'cn-hongkong-finance-pop' = 'ice.aliyuncs.com',
    'cn-huhehaote' = 'ice.aliyuncs.com',
    'cn-huhehaote-nebula-1' = 'ice.aliyuncs.com',
    'cn-north-2-gov-1' = 'ice.aliyuncs.com',
    'cn-qingdao' = 'ice.aliyuncs.com',
    'cn-qingdao-nebula' = 'ice.aliyuncs.com',
    'cn-shanghai-et15-b01' = 'ice.aliyuncs.com',
    'cn-shanghai-et2-b01' = 'ice.aliyuncs.com',
    'cn-shanghai-finance-1' = 'ice.aliyuncs.com',
    'cn-shanghai-inner' = 'ice.aliyuncs.com',
    'cn-shanghai-internal-test-1' = 'ice.aliyuncs.com',
    'cn-shenzhen' = 'ice.aliyuncs.com',
    'cn-shenzhen-finance-1' = 'ice.aliyuncs.com',
    'cn-shenzhen-inner' = 'ice.aliyuncs.com',
    'cn-shenzhen-st4-d01' = 'ice.aliyuncs.com',
    'cn-shenzhen-su18-b01' = 'ice.aliyuncs.com',
    'cn-wuhan' = 'ice.aliyuncs.com',
    'cn-wulanchabu' = 'ice.aliyuncs.com',
    'cn-yushanfang' = 'ice.aliyuncs.com',
    'cn-zhangbei' = 'ice.aliyuncs.com',
    'cn-zhangbei-na61-b01' = 'ice.aliyuncs.com',
    'cn-zhangjiakou' = 'ice.aliyuncs.com',
    'cn-zhangjiakou-na62-a01' = 'ice.aliyuncs.com',
    'cn-zhengzhou-nebula-1' = 'ice.aliyuncs.com',
    'eu-central-1' = 'ice.aliyuncs.com',
    'eu-west-1' = 'ice.aliyuncs.com',
    'eu-west-1-oxs' = 'ice.aliyuncs.com',
    'me-east-1' = 'ice.aliyuncs.com',
    'rus-west-1-pop' = 'ice.aliyuncs.com',
    'us-east-1' = 'ice.aliyuncs.com',
    'us-west-1' = 'ice.aliyuncs.com',
  };
}

function close(): void {
  @handler.close();
}

model AIAgentRuntimeConfig {
  avatarChat3D?: {
    agentUserId?: string(name='AgentUserId'),
    authToken?: string(name='AuthToken'),
    channelId?: string(name='ChannelId'),
  }(name='AvatarChat3D'),
  visionChat?: {
    agentUserId?: string(name='AgentUserId'),
    authToken?: string(name='AuthToken'),
    channelId?: string(name='ChannelId'),
  }(name='VisionChat'),
  voiceChat?: {
    agentUserId?: string(name='AgentUserId'),
    authToken?: string(name='AuthToken'),
    channelId?: string(name='ChannelId'),
  }(name='VoiceChat'),
}

model AIAgentTemplateConfig {
  avatarChat3D?: {
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    avatarId?: string(name='AvatarId'),
    bailianAppParams?: string(name='BailianAppParams'),
    enablePushToTalk?: boolean(name='EnablePushToTalk'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    gracefulShutdown?: boolean(name='GracefulShutdown'),
    greeting?: string(name='Greeting'),
    maxIdleTime?: int32(name='MaxIdleTime'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    voiceId?: string(name='VoiceId'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
    workflowOverrideParams?: string(name='WorkflowOverrideParams'),
  }(name='AvatarChat3D'),
  visionChat?: {
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    bailianAppParams?: string(name='BailianAppParams'),
    enableIntelligentSegment?: boolean(name='EnableIntelligentSegment'),
    enablePushToTalk?: boolean(name='EnablePushToTalk'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    gracefulShutdown?: boolean(name='GracefulShutdown'),
    greeting?: string(name='Greeting'),
    maxIdleTime?: int32(name='MaxIdleTime'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    voiceId?: string(name='VoiceId'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
    workflowOverrideParams?: string(name='WorkflowOverrideParams'),
  }(name='VisionChat'),
  voiceChat?: {
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    avatarUrl?: string(name='AvatarUrl'),
    avatarUrlType?: string(name='AvatarUrlType'),
    bailianAppParams?: string(name='BailianAppParams'),
    enablePushToTalk?: boolean(name='EnablePushToTalk'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    gracefulShutdown?: boolean(name='GracefulShutdown'),
    greeting?: string(name='Greeting'),
    maxIdleTime?: int32(name='MaxIdleTime'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    voiceId?: string(name='VoiceId'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
    workflowOverrideParams?: string(name='WorkflowOverrideParams'),
  }(name='VoiceChat'),
}

model AppInfoDTO {
  appName?: string(name='AppName'),
  appType?: int32(name='AppType', example='1-普通应用，2-内嵌SDK.'),
  gmtCreate?: string(name='GmtCreate'),
  itemId?: string(name='ItemId'),
  platforms?: [ 
    {
      itemId?: string(name='ItemId'),
      licenseItemIds?: [ string ](name='LicenseItemIds'),
      pkgName?: string(name='PkgName'),
      pkgSignature?: string(name='PkgSignature'),
      platformType?: long(name='PlatformType'),
      type?: long(name='Type'),
    }
  ](name='Platforms'),
  userId?: long(name='UserId'),
}

model LicenseInstanceAppDTO {
  appId?: string(name='AppId'),
  beginOn?: string(name='BeginOn'),
  contractNo?: string(name='ContractNo'),
  creationTime?: string(name='CreationTime'),
  expiredOn?: string(name='ExpiredOn'),
  instanceId?: string(name='InstanceId'),
  itemId?: string(name='ItemId'),
  licenseConfigs?: [ 
    {
      businessType?: string(name='BusinessType'),
      featureIds?: string(name='FeatureIds'),
      sdkId?: int32(name='SdkId'),
      sdkName?: string(name='SdkName'),
      subscription?: string(name='Subscription'),
      subscriptionImp?: string(name='SubscriptionImp'),
      subscriptionPkg?: string(name='SubscriptionPkg'),
    }
  ](name='LicenseConfigs'),
  modificationTime?: string(name='ModificationTime'),
  status?: string(name='Status'),
  userId?: long(name='UserId'),
}

model AddCategoryRequest {
  regionId?: string(name='RegionId', position='Host'),
  cateName: string(name='CateName', description='The category name.

*   The value can be up to 64 bytes in length.
*   The value must be encoded in UTF-8.

This parameter is required.', position='Query'),
  parentId?: long(name='ParentId', description='The ID of the parent category.', example='5', position='Query'),
  type?: string(name='Type', description='The type of the category. Valid values:

*   default: audio, video, and image files. This is the default value.
*   material: short video materials.', example='default', position='Query'),
}

model AddCategoryResponseBody = {
  category?: {
    cateId?: long(name='CateId', description='The ID of the created category.', example='45'),
    cateName?: string(name='CateName', description='The category name.'),
    level?: long(name='Level', description='The level of the category. A value of **0** indicates a level-1 category, a value of **1** indicates a level-2 category, and a value of **2** indicates a level-3 category.', example='0'),
    parentId?: long(name='ParentId', description='The ID of the parent category. By default, if ParentId is left empty or less than 1, -1 is returned, which indicates that the created category is the root directory.', example='-1'),
    type?: string(name='Type', description='The type of the category. Valid values:

*   **default**: audio, video, and image files. This is the default value.
*   **material**: short video materials.', example='default'),
  }(name='Category', description='The information about the category.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model AddCategoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddCategoryResponseBody(name='body'),
}

/**
  * @description You can create at most three levels of categories. Each category level can contain a maximum of 100 subcategories.
  * @param request  the request parameters of AddCategory  AddCategoryRequest
  * @return AddCategoryResponse
 */
async function addCategory(request: AddCategoryRequest): AddCategoryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddCategory', 'POST', '/', 'json', false, 'json', request);
}

model AddEditingProjectMaterialsRequest {
  materialMaps: string(name='MaterialMaps', description='The material ID. Separate multiple material IDs with commas (,). Each type supports up to 10 material IDs. The following material types are supported:

*   video
*   audio
*   image
*   liveStream
*   editingProject

This parameter is required.', example='{"video":"*****2e057304fcd9b145c5cafc*****", "image":"****8021a8d493da643c8acd98*****,*****cb6307a4edea614d8b3f3c*****", "liveStream": "[{\\"appName\\":\\"testrecord\\",\\"domainName\\":\\"test.alivecdn.com\\",\\"liveUrl\\":\\"rtmp://test.alivecdn.com/testrecord/teststream\\",\\"streamName\\":\\"teststream\\"}]", "editingProject": "*****9b145c5cafc2e057304fcd*****"}', position='Query'),
  projectId: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='*****b2101cb318c*****', position='Query'),
}

model AddEditingProjectMaterialsResponseBody = {
  liveMaterials?: [ 
    {
      appName?: string(name='AppName', description='The application name of the live stream.', example='testrecord'),
      domainName?: string(name='DomainName', description='The domain name of the live stream.', example='test.alivecdn.com'),
      liveUrl?: string(name='LiveUrl', description='The URL of the live stream.', example='rtmp://test.alivecdn.com/testrecord/teststream'),
      streamName?: string(name='StreamName', description='The name of the live stream.', example='teststream'),
    }
  ](name='LiveMaterials', description='The materials associated with the live stream.'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
            duration?: string(name='Duration', description='The duration.', example='216.206667'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
            fileStatus?: string(name='FileStatus', description='The file status.

\\-Uploading

\\-Normal

\\-UploadFail

\\-Disable

\\-Deleted', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='540'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='960'),
          }(name='FileBasicInfo', description='The basic information of the file, including the duration and size.'),
        }
      ](name='FileInfoList', description='FileInfos'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.', example='audio'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-23T03:32:59Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-23T03:32:59Z'),
        description?: string(name='Description', description='The description of the media asset.', example='sample_description'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/file.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****5cb2e35433198daae94a72*****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='sample_tag'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='Video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-23T03:32:59Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='null'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite of the media asset.', example='http://outin-example.oss-cn-shanghai.aliyuncs.com/test.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        status?: string(name='Status', description='The status of the media asset. Valid values:

\\- Init

\\- Preparing

\\- PrepareFail

\\- Normal', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.', example='default_title_2020-12-23T03:32:59Z'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information of the media assets.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****5cb2e35433198daae94a72*****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='*****67ae06542b9b93e0d1c387*****'),
  projectMaterials?: [ string ](name='ProjectMaterials', description='The materials associated with the editing project. A live stream editing project will be associated with a regular editing project after the live streaming ends.', example='*****9b145c5cafc2e057304fcd*****'),
  requestId?: string(name='RequestId', description='The request ID.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
}

model AddEditingProjectMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddEditingProjectMaterialsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AddEditingProjectMaterials  AddEditingProjectMaterialsRequest
  * @return AddEditingProjectMaterialsResponse
 */
async function addEditingProjectMaterials(request: AddEditingProjectMaterialsRequest): AddEditingProjectMaterialsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddEditingProjectMaterials', 'POST', '/', 'json', false, 'json', request);
}

model AddFavoritePublicMediaRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaIds?: string(name='MediaIds', example='icepublic-****7213c6050cbc66750b469701****,icepublic-****0b4697017213c6050cbc6675****', position='Query'),
}

model AddFavoritePublicMediaResponseBody = {
  ignoredList?: [ string ](name='IgnoredList'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model AddFavoritePublicMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddFavoritePublicMediaResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AddFavoritePublicMedia  AddFavoritePublicMediaRequest
  * @return AddFavoritePublicMediaResponse
 */
async function addFavoritePublicMedia(request: AddFavoritePublicMediaRequest): AddFavoritePublicMediaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddFavoritePublicMedia', 'POST', '/', 'json', false, 'json', request);
}

model AddMediaMarksRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='53afdf003a2171ed9c6a16b5feac6402', position='Query'),
  mediaMarks: string(name='MediaMarks', description='The mark information. The value must be a JSONArray.

This parameter is required.', position='Query'),
}

model AddMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='53afdf003a******6a16b5feac6402'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The IDs of the marks that are added.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
  requestId?: string(name='RequestId', description='The request ID.', example='771A1414-27BF-53E6-AB73-EFCB*****ACF'),
}

model AddMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddMediaMarksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AddMediaMarks  AddMediaMarksRequest
  * @return AddMediaMarksResponse
 */
async function addMediaMarks(request: AddMediaMarksRequest): AddMediaMarksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddMediaMarks', 'POST', '/', 'json', false, 'json', request);
}

model AddTemplateRequest {
  config?: string(name='Config', example='参见Timeline模板Config文档', position='Body'),
  coverUrl?: string(name='CoverUrl', description='The URL of the template thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg', position='Query'),
  name?: string(name='Name', description='The name of the custom template.', example='视频添加水印模板', position='Query'),
  previewMedia?: string(name='PreviewMedia', description='The ID of the template preview video.', example='****01bf24bf41c78b2754cb3187****', position='Query'),
  relatedMediaids?: string(name='RelatedMediaids', description='The IDs of the materials associated with the template for use by the regular template editor.', example='{"video":["1805a0c6ca544fb395a06ca683619655"]}', position='Query'),
  source?: string(name='Source', description='The source from which the template is created. Valid values:

*   OpenAPI
*   AliyunConsole
*   WebSDK

<!---->

*
*
*', example='OpenAPI', position='Query'),
  status?: string(name='Status', description='The template state. Valid values:

*   Available: The template is available.
*   Created: The template is created but not ready for use.
*   Uploading: The video is being uploaded.
*   Processing: The advanced template is being processed.
*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.

<!---->

*
*
*
*
*
*', example='Available', position='Query'),
  type?: string(name='Type', description='The template type. Valid values:

*   Timeline: a regular template created based on the timeline of a video editing project, in which multiple materials are arranged in sequence across multiple layers. It can be used to convert text and images into videos, create photo albums, add opening and closing parts, and apply the default watermark.
*   VETemplate: an advanced template created using effects of Adobe After Effects (AE). It can be used to produce complex animations and advanced media effects.

<!---->

*
*', example='Timeline', position='Query'),
}

model AddTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
  template?: {
    config?: string(name='Config', description='The template configurations.', example='参见Timeline模板Config文档'),
    coverUrl?: string(name='CoverUrl', description='The URL of the template thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
    createSource?: string(name='CreateSource', description='The source from which the template was created.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
    modifiedSource?: string(name='ModifiedSource', description='The source from which the template was modified.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
    name?: string(name='Name', description='The template name.', example='视频添加水印模板'),
    previewMedia?: string(name='PreviewMedia', description='The ID of the preview video.', example='****01bf24bf41c78b2754cb3187****'),
    status?: string(name='Status', description='The template state.

Valid values:

*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.
*   Available: The template is available.
*   Uploading: The video is being uploaded.
*   Created: The template is created but not ready for use.
*   Processing: The advanced template is being processed.', example='Available'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****01bf24bf41c78b2754cb3187****'),
    type?: string(name='Type', description='The template type.

Valid values:

*   Timeline: regular template.
*   VETemplate: advanced template.', example='Timeline'),
  }(name='Template', description='The template information.'),
}

model AddTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddTemplateResponseBody(name='body'),
}

/**
  * @description *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/270942.html).
  * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/291418.html).
  * *   After an advanced template is created, it enters the Processing state. In this case, the template is unavailable. The template can be used only when it is in the Available state. The time required for template processing varies based on the size of the template file. Generally, it ranges from 10 seconds to 5 minutes.
  * @param request  the request parameters of AddTemplate  AddTemplateRequest
  * @return AddTemplateResponse
 */
async function addTemplate(request: AddTemplateRequest): AddTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddTemplate', 'POST', '/', 'json', true, 'form', request);
}

model AlterSearchIndexRequest {
  regionId?: string(name='RegionId', position='Host'),
  indexConfig?: string(name='IndexConfig', description='The configurations of the index.

>  You must specify either IndexStatus or IndexConfig.', example='{}', position='Query'),
  indexStatus?: string(name='IndexStatus', description='The state of the index. Valid values:

*   active (default): the index is enabled.
*   Deactive: the index is not enabled.

>  You must specify either IndexStatus or IndexConfig.', example='Active', position='Query'),
  indexType: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.

This parameter is required.', example='mm', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

*   If you leave this parameter empty, the search index is created in the default search library of Intelligent Media Service (IMS). Default value: ims-default-search-lib.
*   To query information about an existing search library, call the [QuerySearchLib](https://help.aliyun.com/document_detail/2584455.html) API operation.', example='test1', position='Query'),
}

model AlterSearchIndexResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model AlterSearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AlterSearchIndexResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AlterSearchIndex  AlterSearchIndexRequest
  * @return AlterSearchIndexResponse
 */
async function alterSearchIndex(request: AlterSearchIndexRequest): AlterSearchIndexResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AlterSearchIndex', 'POST', '/', 'json', false, 'json', request);
}

model BatchGetMediaInfosRequest {
  regionId?: string(name='RegionId', position='Host'),
  additionType?: string(name='AdditionType', description='The additional information that you want to query about the media assets. By default, only BasicInfo is returned. The following additional information can be queried:

\\- FileInfo

\\- DynamicMetaData', example='FileInfo,DynamicMetaData', position='Query'),
  mediaIds?: string(name='MediaIds', description='The IDs of the media assets that you want to query. Separate the IDs with commas (,).', example='******b48fb04483915d4f2cd8******,******c48fb37407365d4f2cd8******', position='Query'),
}

model BatchGetMediaInfosResponseBody = {
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
            duration?: string(name='Duration', description='The duration.', example='200'),
            fileName?: string(name='FileName', description='The file name.', example='example'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='1080'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='1920'),
          }(name='FileBasicInfo', description='The basic information of the file, including the duration and size.'),
        }
      ](name='FileInfoList', description='FileInfos'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-26T04:11:10Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-26T04:11:10Z'),
        description?: string(name='Description', description='The description of the media asset.'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        mediaId?: string(name='MediaId', description='MediaId', example='******c48fb37407365d4f2cd8******'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.'),
        mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

\\- image

\\- video

\\- audio

\\- text', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-26T04:11:12Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='[{"bucket":"example-bucket","count":"3","iceJobId":"******f48f0e4154976b2b8c45******","location":"oss-cn-beijing","snapshotRegular":"example.jpg","templateId":"******e6a6440b29eb60bd7c******"}]'),
        source?: string(name='Source', description='The source of the media asset. Valid values:

\\- oss

\\- vod', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite.', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userDataTest'),
      }(name='MediaBasicInfo', description='The basic information of the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******c48fb37407365d4f2cd8******'),
    }
  ](name='MediaInfos', description='The queried media assets.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model BatchGetMediaInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: BatchGetMediaInfosResponseBody(name='body'),
}

/**
  * @param request  the request parameters of BatchGetMediaInfos  BatchGetMediaInfosRequest
  * @return BatchGetMediaInfosResponse
 */
async function batchGetMediaInfos(request: BatchGetMediaInfosRequest): BatchGetMediaInfosResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'BatchGetMediaInfos', 'POST', '/', 'json', false, 'json', request);
}

model CancelDNAJobRequest {
  jobId: string(name='JobId', description='The ID of the media fingerprint analysis job that you want to cancel.

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model CancelDNAJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='2288c6ca184c0e47098a5b665e2a12****'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model CancelDNAJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CancelDNAJobResponseBody(name='body'),
}

/**
  * @description *   You can cancel a media fingerprint analysis job only if the job is in the Queuing state.
  * *   We recommend that you call the **UpdatePipeline** operation to set the status of the ApsaraVideo Media Processing (MPS) queue to Paused before you cancel a job. This suspends job scheduling in the MPS queue. After the job is canceled, you must set the status of the MPS queue back to Active so that the other jobs in the MPS queue can be scheduled.
  * @param request  the request parameters of CancelDNAJob  CancelDNAJobRequest
  * @return CancelDNAJobResponse
 */
async function cancelDNAJob(request: CancelDNAJobRequest): CancelDNAJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CancelDNAJob', 'POST', '/', 'json', false, 'json', request);
}

model CancelFavoritePublicMediaRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaIds?: string(name='MediaIds', example='icepublic-****7213c6050cbc66750b469701****,icepublic-****0b4697017213c6050cbc6675****', position='Query'),
}

model CancelFavoritePublicMediaResponseBody = {
  ignoredList?: [ string ](name='IgnoredList'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model CancelFavoritePublicMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CancelFavoritePublicMediaResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CancelFavoritePublicMedia  CancelFavoritePublicMediaRequest
  * @return CancelFavoritePublicMediaResponse
 */
async function cancelFavoritePublicMedia(request: CancelFavoritePublicMediaRequest): CancelFavoritePublicMediaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CancelFavoritePublicMedia', 'POST', '/', 'json', false, 'json', request);
}

model CreateAuditRequest {
  regionId?: string(name='RegionId', position='Host'),
  auditContent: string(name='AuditContent', description='The review results. You can specify the results for a maximum of 20 videos at a time. The value must be converted to a string. For more information about the parameters in AuditContent, see the "AuditContent" section of this topic.

This parameter is required.', example='[
      {
            "MediaId": "93ab850b4f*****b54b6e91d24d81d4",
            "Status": "Normal"
      },
      {
            "MediaId": "f867fbfb58*****8bbab65c4480ae1d",
            "Status": "Blocked",
            "Reason": "xxxx",
            "Comment": "xxxx"
      }
]', position='Query'),
}

model CreateAuditResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateAuditResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateAuditResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateAudit  CreateAuditRequest
  * @return CreateAuditResponse
 */
async function createAudit(request: CreateAuditRequest): CreateAuditResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateAudit', 'POST', '/', 'json', false, 'json', request);
}

model CreateAvatarTrainingJobRequest {
  avatarDescription?: string(name='AvatarDescription', description='*   The description of the digital human.
*   The description can be up to 1,000 characters in length.', maxLength=1027, position='Query'),
  avatarName: string(name='AvatarName', description='*   The name of the digital human.
*   The name can be up to seven characters in length.

This parameter is required.', maxLength=7, position='Query'),
  avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar', position='Query'),
  portrait?: string(name='Portrait', description='*   The media asset ID of the portrait image.
*   The value must be 32 characters in length.', example='****571c704445f9a0ee011406c2****', minLength=32, maxLength=32, position='Query'),
  thumbnail?: string(name='Thumbnail', description='*   The thumbnail URL.
*   After the digital human is trained, the thumbnail is uploaded to this URL.
*   The URL must be a valid public Object Storage Service (OSS) URL.
*   The URL can be up to 512 characters in length.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png', maxLength=512, position='Query'),
  transparent?: boolean(name='Transparent', description='*   Specifies whether the training video supports alpha channels.

    **

    **Note**: Make sure that the current settings are consistent with those of the submitted training video. Otherwise, the digital human may malfunction.', example='True', position='Query'),
  video?: string(name='Video', description='*   The ID of the video used for training.
*   The value must be 32 characters in length.
*   Supported formats: MP4, MOV, and WebM.
*   The duration of the video must be 5 to 15 minutes.
*   The resolution of the video must be 1920×1080 or 1080×1920.', example='****571c704445f9a0ee011406c2****', minLength=32, maxLength=32, position='Query'),
}

model CreateAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateAvatarTrainingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateAvatarTrainingJob  CreateAvatarTrainingJobRequest
  * @return CreateAvatarTrainingJobResponse
 */
async function createAvatarTrainingJob(request: CreateAvatarTrainingJobRequest): CreateAvatarTrainingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateAvatarTrainingJob', 'POST', '/', 'json', false, 'json', request);
}

model CreateCustomTemplateRequest {
  name: string(name='Name', description='The template name.

This parameter is required.', example='test-template', position='Query'),
  subtype?: int32(name='Subtype', description='The template subtype.

Valid values for transcoding templates:

*   1 (Normal): regular template.
*   2 (AudioTranscode): audio transcoding template.
*   3 (Remux): container format conversion template.
*   4 (NarrowBandV1): Narrowband HD 1.0 template.
*   5 (NarrowBandV2): Narrowband HD 2.0 template.

Valid values for snapshot templates:

*   1 (Normal): regular template.
*   2 (Sprite): sprite template.
*   3 (WebVtt): WebVTT template.

Valid values for AI-assisted content moderation templates:

*   1 (Video): video moderation template.
*   2 (Audio): audio moderation template.
*   3 (Image): image moderation template.

Valid values for AI-assisted intelligent erasure templates.

*   1 (VideoDelogo): logo erasure template.
*   2 (VideoDetext): subtitle erasure template.', example='1', position='Query'),
  templateConfig: string(name='TemplateConfig', description='The template configurations. For more information, see [Template parameters](https://help.aliyun.com/document_detail/448291.html).

This parameter is required.', example='{"Container":{"Format":"flv"},"Video":{},"Audio":{}}', position='Query'),
  type: int32(name='Type', description='The template type. Valid values:

*   1: transcoding template.
*   2: snapshot template.
*   3: animated image template.
*   4\\. image watermark template.
*   5: text watermark template.
*   6: subtitle template.
*   7: AI-assisted content moderation template.
*   8: AI-assisted intelligent thumbnail template.
*   9: AI-assisted intelligent erasure template.
*   10: AI-assisted media fingerprint analysis template.
*   11: AI-assisted smart tagging template.

This parameter is required.', example='1', position='Query'),
}

model CreateCustomTemplateResponseBody = {
  customTemplate?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-04-19T02:04:31Z'),
    isDefault?: boolean(name='IsDefault', description='Indicates whether the template is the default template.', example='true'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-04-19T02:04:31Z'),
    status?: string(name='Status', description='The template state.', example='Normal'),
    subtype?: string(name='Subtype', description='The subtype name of the template.', example='Remux'),
    templateConfig?: string(name='TemplateConfig', description='The template configurations.', example='{"Container":{"Format":"flv"},"Video":{},"Audio":{}}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
    templateName?: string(name='TemplateName', description='The template name.', example='test-template'),
    type?: int32(name='Type', description='The type ID of the template.', example='1'),
    typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
  }(name='CustomTemplate', description='The template information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateCustomTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateCustomTemplate  CreateCustomTemplateRequest
  * @return CreateCustomTemplateResponse
 */
async function createCustomTemplate(request: CreateCustomTemplateRequest): CreateCustomTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateCustomTemplate', 'POST', '/', 'json', false, 'json', request);
}

model CreateCustomizedVoiceJobRequest {
  gender: string(name='Gender', description='The gender. Valid values:

*   female
*   male

This parameter is required.', example='female', position='Query'),
  scenario: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation

This parameter is required.', example='story', position='Query'),
  voiceDesc?: string(name='VoiceDesc', description='The voice description.

*   The description can be up to 256 characters in length.', maxLength=256, position='Query'),
  voiceId: string(name='VoiceId', description='The voice ID. It can be the English name or Chinese Pinyin of the voice.

*   The value must be a unique ID that is not used by other custom voices.
*   The ID can be up to 32 characters in length.
*   Only letters and digits are supported.

This parameter is required.', example='xiaozhuan', maxLength=32, position='Query'),
  voiceName?: string(name='VoiceName', description='The voice name.

*   The name can be up to 32 characters in length.', maxLength=32, position='Query'),
}

model CreateCustomizedVoiceJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****29faef8144638ba42eb8e037****'),
    voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
}

model CreateCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateCustomizedVoiceJob  CreateCustomizedVoiceJobRequest
  * @return CreateCustomizedVoiceJobResponse
 */
async function createCustomizedVoiceJob(request: CreateCustomizedVoiceJobRequest): CreateCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model CreateDNADBRequest {
  description?: string(name='Description', description='The description of the media fingerprint library.', position='Query'),
  model?: string(name='Model', description='The model of the media fingerprint library. Valid values:

*   **Video**
*   **Audio**
*   **Image**
*   **Text** (supported only in the China (Shanghai) region)', example='Video', position='Query'),
  name: string(name='Name', description='The name of the media fingerprint library.

This parameter is required.', example='example name', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model CreateDNADBResponseBody = {
  DBInfo?: {
    DBId?: string(name='DBId', description='The ID of the media fingerprint library. We recommend that you save this ID for subsequent calls of other operations.', example='88c6ca184c0e47098a5b665e2a12****'),
    description?: string(name='Description', description='The description of the media fingerprint library.'),
    model?: string(name='Model', description='The model of the media fingerprint library.', example='Video'),
    name?: string(name='Name', description='The name of the media fingerprint library.', example='example name'),
    status?: string(name='Status', description='The state of the media fingerprint library. After a media fingerprint library is created, it enters the offline state. After the media fingerprint library is processed at the backend, it enters the active state.', example='offline'),
  }(name='DBInfo', description='The details of the media fingerprint library.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model CreateDNADBResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDNADBResponseBody(name='body'),
}

/**
  * @description *   You can create up to five media fingerprint libraries within an account. To increase the quota, submit a ticket. You can call the DeleteDNADB operation to delete the fingerprint libraries that you no longer need.
  * @param request  the request parameters of CreateDNADB  CreateDNADBRequest
  * @return CreateDNADBResponse
 */
async function createDNADB(request: CreateDNADBRequest): CreateDNADBResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDNADB', 'POST', '/', 'json', false, 'json', request);
}

model CreateEditingProjectRequest {
  businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.

For a live stream editing project, observe the following rules: OutputMediaConfig.StorageLocation is required. OutputMediaConfig.Path is optional. If you do not specify this option, the live streaming clips are stored in the root directory by default.

Valid values of OutputMediaTarget include vod-media and oss-object. If you do not specify OutputMediaTarget, the default value oss-object is used.

If you set OutputMediaTarget to vod-media, the setting of OutputMediaConfig.Path does not take effect.', example='{ "OutputMediaConfig" : { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path" }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }', position='Query'),
  clipsParam?: string(name='ClipsParam', description='The material parameter corresponding to the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified. For more information<props="china">, see [Create and use a regular template](https://help.aliyun.com/document_detail/328557.html) and [Create and use an advanced template](https://help.aliyun.com/document_detail/291418.html).', position='Query'),
  coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='https://example.com/example.png', position='Query'),
  description?: string(name='Description', description='The description of the online editing project.', example='描述', position='Query'),
  materialMaps?: string(name='MaterialMaps', description='The material associated with the project. Separate multiple material IDs with commas (,). Each type supports up to 10 material IDs.', example='{"video":"*****2e057304fcd9b145c5cafc*****", "image":"****8021a8d493da643c8acd98*****,*****cb6307a4edea614d8b3f3c*****", "liveStream": "[{\\"appName\\":\\"testrecord\\",\\"domainName\\":\\"test.alivecdn.com\\",\\"liveUrl\\":\\"rtmp://test.alivecdn.com/testrecord/teststream\\",\\"streamName\\":\\"teststream\\"}]", "editingProject": "*****9b145c5cafc2e057304fcd*****"}', position='Query'),
  projectType?: string(name='ProjectType', description='The type of the editing project. Valid values: EditingProject and LiveEditingProject. A value of EditingProject indicates a regular editing project, and a value of LiveEditingProject indicates a live stream editing project.', example='LiveEditingProject', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID. This parameter is used to quickly build a timeline with ease. Note: Only one of Timeline and TemplateId can be specified. If TemplateId is specified, ClipsParam must also be specified.', example='****96e8864746a0b6f3****', position='Query'),
  templateType?: string(name='TemplateType', description='The template type. This parameter is required if you create a template-based online editing project. Default value: Timeline. Valid values:

*   Timeline: a regular template.
*   VETemplate: an advanced template.', example='Timeline', position='Query'),
  timeline?: string(name='Timeline', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}', position='Body'),
  title: string(name='Title', description='The title of the online editing project.

This parameter is required.', example='example', position='Query'),
}

model CreateEditingProjectResponseBody = {
  project?: {
    businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{ "OutputMediaConfig" :    { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path"   }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
    businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

*   Reserving
*   ReservationCanceled
*   BroadCasting
*   LoadingFailed
*   LiveFinished', example='Reserving'),
    clipsParam?: string(name='ClipsParam', description='The template material parameters.'),
    coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
    createSource?: string(name='CreateSource', description='The method for creating the online editing project. Valid values:

\\- OpenAPI

\\- AliyunConsole

\\- WebSDK

\\- LiveEditingOpenAPI

\\- LiveEditingConsole', example='WebSDK'),
    createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2021-01-08T16:52:07Z'),
    description?: string(name='Description', description='The description of the online editing project.', example='example_description'),
    duration?: float(name='Duration', description='The duration of the online editing project.', example='3.4200000'),
    modifiedSource?: string(name='ModifiedSource', description='The method for editing the online editing project. Valid values:

\\- OpenAPI

\\- AliyunConsole

\\- WebSDK

\\- LiveEditingOpenAPI

\\- LiveEditingConsole', example='WebSDK'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last edited.', example='2021-01-08T16:52:07Z'),
    projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****01bf24bf41c78b2754cb3187****'),
    projectType?: string(name='ProjectType', description='The type of the editing project. Default value: EditingProject. Valid values:

\\- EditingProject: a regular editing project.

\\- LiveEditingProject: a live stream editing project.', example='LiveEditingProject'),
    status?: long(name='Status', description='The status of the online editing project.

Valid values:

\\- 1: Draft

\\- 2: Editing

\\- 3: Producing

\\- 4: Produced

\\- 5: ProduceFailed

\\- 7: Deleted', example='2'),
    statusName?: string(name='StatusName', description='The status of the online editing project. For more information, see the status list.', example='Editing'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
    templateType?: string(name='TemplateType', description='The template type of the online editing project. Valid values:

\\- Timeline

\\- VETemplate', example='Timeline'),
    timeline?: string(name='Timeline', description='The timeline of the online editing project, in the JSON format.<props="china">For more information about objects in a timeline, see [Timeline configurations](https://help.aliyun.com/document_detail/198823.htm?spm=a2c4g.11186623.2.9.90dc653dF67srN#topic-2024662).  If you leave this parameter empty, an empty timeline is created and the duration of the online editing project is zero.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
    title?: string(name='Title', description='The title of the online editing project.', example='example_title'),
  }(name='Project', description='The information about the online editing project.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model CreateEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateEditingProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateEditingProject  CreateEditingProjectRequest
  * @return CreateEditingProjectResponse
 */
async function createEditingProject(request: CreateEditingProjectRequest): CreateEditingProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateEditingProject', 'POST', '/', 'json', true, 'form', request);
}

model CreateLiveRecordTemplateRequest {
  name: string(name='Name', description='The name of the template.

This parameter is required.', position='Body'),
  recordFormat: [ 
    {
      cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds. If you do not specify this parameter, the default value 6 hours is used.

> 

*   If a live stream is interrupted during a recording cycle but is resumed within 3 minutes, the stream is recorded in the same recording before and after the interruption.

*   If a live stream is interrupted for more than 3 minutes, a new recording is generated. To change the default stream interruption time, submit a ticket.', example='3600'),
      format: string(name='Format', description='The format.

>  If you set this parameter to m3u8, you must also specify the SliceOssObjectPrefix and SliceDuration parameters.

This parameter is required.', example='m3u8'),
      ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording file that is stored in Object Storage Service (OSS).

*   The name must be less than 256 bytes in length and can contain the {JobId}, {Sequence}, {StartTime}, {EndTime}, {EscapedStartTime}, and {EscapedEndTime} variables.
*   The name must contain the {StartTime} and {EndTime} variables or the {EscapedStartTime} and {EscapedEndTime} variables.', example='record/{JobId}/{Sequence}_{EscapedStartTime}_{EscapedEndTime}'),
      sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds.

>  This parameter takes effect only if you set Format to m3u8.

If you do not specify this parameter, the default value 30 seconds is used. Valid values: 5 to 30.', example='30'),
      sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.

>  This parameter is required only if you set Format to m3u8.

*   By default, the duration of a segment is 30 seconds. The segment name must be less than 256 bytes in length and can contain the {JobId}, {UnixTimestamp}, and {Sequence} variables.
*   The segment name must contain the {UnixTimestamp} and {Sequence} variables.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
    }
  ](name='RecordFormat', description='The list of recording formats.

This parameter is required.', shrink='json', position='Body'),
}

model CreateLiveRecordTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
}

model CreateLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLiveRecordTemplateResponseBody(name='body'),
}

/**
  * @description You must specify a recording template for live stream recording. You can configure information such as the format and duration of a recording in a recording template. The recording format can be M3U8, MP4, or FLV.
  * @param request  the request parameters of CreateLiveRecordTemplate  CreateLiveRecordTemplateRequest
  * @return CreateLiveRecordTemplateResponse
 */
async function createLiveRecordTemplate(request: CreateLiveRecordTemplateRequest): CreateLiveRecordTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateLiveRecordTemplate', 'POST', '/', 'json', true, 'form', request);
}

model CreateLiveSnapshotTemplateRequest {
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   It cannot exceed 255 characters in length.
*   The {JobId} placeholder is supported. It specifies the ID of the snapshot job.
*   Placeholders such as {UnixTimestamp}, {Sequence}, and {Date} are not allowed.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}.jpg', position='Body'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   It cannot exceed 255 characters in length.
*   The {JobId}, {Date}, {UnixTimestamp}, and {Sequence} placeholders are supported. {JobId} specifies the ID of the snapshot job. {Date} specifies the date on which the snapshot is captured. {UnixTimestamp} specifies the timestamp of the snapshot. {Sequence} specifies the sequence number of the snapshot. You must specify at least one of the {UnixTimestamp} and {Sequence} placeholders.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}/{UnixTimestamp}.jpg', position='Body'),
  templateName: string(name='TemplateName', description='The name of the template.

*   It cannot exceed 128 characters in length.

This parameter is required.', position='Body'),
  timeInterval: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.

*   Valid values: [5,3600].

This parameter is required.', example='5', position='Body'),
}

model CreateLiveSnapshotTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287782****'),
}

model CreateLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLiveSnapshotTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateLiveSnapshotTemplate  CreateLiveSnapshotTemplateRequest
  * @return CreateLiveSnapshotTemplateResponse
 */
async function createLiveSnapshotTemplate(request: CreateLiveSnapshotTemplateRequest): CreateLiveSnapshotTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateLiveSnapshotTemplate', 'POST', '/', 'json', true, 'form', request);
}

model CreateLiveTranscodeTemplateRequest {
  name: string(name='Name', description='The name of the template.

This parameter is required.', example='my template', minLength=1, maxLength=20, position='Query'),
  templateConfig?: {
    audioParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output audio. Unit: Kbit/s. Valid values: 1 to 1000.', example='100'),
      channels?: string(name='Channels', description='The number of sound channels. Valid values: 1: mono 2: binaural', example='2'),
      codec?: string(name='Codec', description='The audio codec. Valid values:

*   AAC
*   MP3', example='AAC'),
      profile?: string(name='Profile', description='The audio codec profile. Valid values when the Codec parameter is set to AAC:

*   aac_low
*   aac_he
*   aac_he_v2
*   aac_ld', example='aaclow'),
      samplerate?: string(name='Samplerate', description='The audio sampling rate. Valid values: 22050 to 96000.

Note: If you set AudioProfile to aac_ld, the audio sampling rate cannot exceed 44,100.', example='44100'),
    }(name='AudioParams', description='The audio parameters.'),
    videoParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output video. Unit: Kbit/s. Valid values: 1 to 6000.', example='2500'),
      codec?: string(name='Codec', description='The encoding type. Valid values:

*   H.264
*   H.265', example='H.264'),
      fps?: string(name='Fps', description='The frame rate of the output video. Unit: frames per second (FPS). Valid values: 1 to 60.', example='25'),
      gop?: string(name='Gop', description='The group of pictures (GOP) of the output video. Unit: frame. Valid values: 1 to 3000.', example='1000'),
      height?: string(name='Height', description='The height of the output video. Valid values: Height ≥ 128 max (Height,Width) ≤ 2560 min (Height,Width) ≤ 1440

Note: The resolution of the output video that is transcoded by using the H.265 Narrowband HD transcoding template cannot exceed 1280 × 720 pixels.', example='720'),
      profile?: string(name='Profile', description='The encoding profile. The profile determines how a video is encoded. In most cases, a greater value indicates better image quality and higher resource consumption. Valid values: 1: baseline. This value is suitable for mobile devices. 2: main. This value is suitable for standard-definition devices. 3: high. This value is suitable for high-definition devices.', example='2'),
      width?: string(name='Width', description='The width of the output video. Valid values: Width ≥ 128 max (Height,Width) ≤ 2560 min (Height,Width) ≤ 1440

Note: The resolution of the output video that is transcoded by using the H.265 Narrowband HD transcoding template cannot exceed 1280 × 720 pixels.', example='1280'),
    }(name='VideoParams', description='The video parameters.'),
  }(name='TemplateConfig', description='The configuration of the template.', shrink='json', position='Query'),
  type: string(name='Type', description='The type of the template. Valid values:

*   normal
*   narrow-band
*   audio-only
*   origin

This parameter is required.', example='normal', position='Query'),
}

model CreateLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  templateId?: string(name='TemplateId', description='The ID of the template.', example='****20b48fb04483915d4f2cd8ac****'),
}

model CreateLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLiveTranscodeTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateLiveTranscodeTemplate  CreateLiveTranscodeTemplateRequest
  * @return CreateLiveTranscodeTemplateResponse
 */
async function createLiveTranscodeTemplate(request: CreateLiveTranscodeTemplateRequest): CreateLiveTranscodeTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateLiveTranscodeTemplate', 'POST', '/', 'json', false, 'json', request);
}

model CreatePipelineRequest {
  name: string(name='Name', description='The name of the MPS queue.

This parameter is required.', example='test-pipeline', position='Query'),
  priority?: int32(name='Priority', description='The priority. Default value: 6. Valid values: 1 to 10. A greater value specifies a higher priority.', example='6', position='Query'),
  speed: string(name='Speed', description='The type of the MPS queue. Valid values:

1.  Standard: standard MPS queue.
2.  Boost: MPS queue with transcoding speed boosted.
3.  NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.

This parameter is required.', example='Standard', position='Query'),
}

model CreatePipelineResponseBody = {
  pipeline?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
    name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.', example='****20b48fb04483915d4f2cd8ac****'),
    priority?: int32(name='Priority', description='The priority of the MPS queue.', example='6'),
    speed?: string(name='Speed', description='The type of the MPS queue.

Valid values:

*   Boost: MPS queue with transcoding speed boosted.
*   Standard: standard MPS queue.
*   NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.', example='Standard'),
    status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Active'),
  }(name='Pipeline', description='The information about the MPS queue.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreatePipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreatePipelineResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreatePipeline  CreatePipelineRequest
  * @return CreatePipelineResponse
 */
async function createPipeline(request: CreatePipelineRequest): CreatePipelineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreatePipeline', 'POST', '/', 'json', false, 'json', request);
}

model CreateSearchIndexRequest {
  regionId?: string(name='RegionId', position='Host'),
  indexConfig?: string(name='IndexConfig', example='{}', position='Query'),
  indexStatus?: string(name='IndexStatus', example='Active', position='Query'),
  indexType: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model. You can use this model to describe complex visual features and identify and search for specific actions, movements, and events in videos, such as when athletes score a goal or get injured.

>  This feature is in the public preview phase. You can use this feature for free for 1,000 hours of videos.

*   face: face recognition. You can use the face recognition technology to describe face characteristics and automatically mark or search for faces in videos.
*   aiLabel: smart tagging. The smart tagging category is used to describe content such as subtitles and audio in videos. You can use the speech recognition technology to automatically extract, mark, and search for subtitles and dialog content from videos. This helps you quickly locate the video content that is related to specific topics or keywords.

This parameter is required.', example='mm', position='Query'),
  searchLibName?: string(name='SearchLibName', example='test1', position='Query'),
}

model CreateSearchIndexResponseBody = {
  code?: string(name='Code', example='200'),
  requestId?: string(name='RequestId', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  success?: string(name='Success', example='true'),
}

model CreateSearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSearchIndexResponseBody(name='body'),
}

/**
  * @description The large visual model feature is still in the public preview phase. You can use this feature for free for 1,000 hours of videos.
  * @param request  the request parameters of CreateSearchIndex  CreateSearchIndexRequest
  * @return CreateSearchIndexResponse
 */
async function createSearchIndex(request: CreateSearchIndexRequest): CreateSearchIndexResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateSearchIndex', 'POST', '/', 'json', false, 'json', request);
}

model CreateSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  searchLibName: string(name='SearchLibName', description='The name of the search library. The name can contain letters and digits and must start with a letter.

This parameter is required.', example='test1', position='Query'),
}

model CreateSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model CreateSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateSearchLib  CreateSearchLibRequest
  * @return CreateSearchLibResponse
 */
async function createSearchLib(request: CreateSearchLibRequest): CreateSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model CreateUploadMediaRequest {
  regionId?: string(name='RegionId', position='Host'),
  appId?: string(name='AppId', description='The application ID. Default value: app-1000000.', example='app-1000000', position='Query'),
  entityId?: string(name='EntityId', description='The entity ID. You can call the CreateEntity operation to create an entity and specify a dynamic metadata structure.', example='9e177cac2fb44f8b8c67b199fcc7bffd', position='Query'),
  fileInfo?: string(name='FileInfo', description='The file information, which is in the JSON format and contains the following fields:

*   Type: required. The file type. Valid values: video, image, audio, text, and other.
*   Name: required. The file name without the extension.
*   Size: optional. The file size.
*   Ext: required. The file name extension.', example='{\\"Type\\":\\"video\\",\\"Name\\":\\"test.mp4\\",\\"Size\\":108078336,\\"Ext\\":\\"mp4\\"}', position='Query'),
  mediaMetaData?: string(name='MediaMetaData', description='The metadata of the media asset, which is a JSON string that contains the following fields:

Title: required.

*   The value can be up to 128 characters in length.
*   The value must be encoded in UTF-8.

Description: optional.

*   The value can be up to 1,024 characters in length.
*   The value must be encoded in UTF-8.

CateId: optional.

Tags: optional.

BusinessType: required. Valid values:

*   opening or ending if Type is set to video
*   default or cover if Type is set to image
*   subtitles or font if Type is set to text
*   watermark if Type is set to material
*   general CoverURL: optional.

DynamicMetaData: The value is a string.', example='{\\"Title\\": \\"UploadTest\\", \\"Description\\": \\"UploadImageTest\\", \\"Tags\\": \\"tag1,tag2\\",\\"BusinessType\\":\\"cover\\"}', position='Query'),
  postProcessConfig?: string(name='PostProcessConfig', description='The postprocessing configurations. You can specify this parameter if Type is set to video or audio.

Set ProcessType to Workflow.', example='{\\"ProcessType\\":\\"Workflow\\",\\"ProcessID\\":\\"74ba870f1a4873a3ba238e0bf6fa9***\\"}', position='Query'),
  uploadTargetConfig?: string(name='UploadTargetConfig', description='The destination storage address.

Set StorageType to oss.

Set StorageLocation to an address in ApsaraVideo VOD. You cannot set this field to an OSS URL.', example='{\\"StorageType\\":\\"oss\\",\\"StorageLocation\\":\\"outin-***.oss-cn-shanghai.aliyuncs.com\\"}', position='Query'),
  userData?: string(name='UserData', description='The user data. The value must be a JSON string. You can configure settings such as message callbacks.', example='{"MessageCallback":{"CallbackURL":"http://example.aliyundoc.com"},"Extend":{"localId":"*****","test":"www"}}', position='Query'),
}

model CreateUploadMediaResponseBody = {
  fileURL?: string(name='FileURL', description='The OSS URL of the file. The URL does not contain the information used for authentication.', example='http://outin-***.oss-cn-north-2-gov-1.aliyuncs.com/sv/40360f05-181f63c3110-0004-cd8e-27f-de3c9.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaURL?: string(name='MediaURL', description='The URL of the media asset.

>  If a domain name for Alibaba Cloud CDN (CDN) is specified, a CDN URL is returned. Otherwise, an OSS URL is returned. If the HTTP status code 403 is returned when you access the URL from your browser, the URL authentication feature of ApsaraVideo VOD is enabled. To resolve this issue, disable URL authentication or generate an authentication signature.', example='https://xxq-live-playback.oss-cn-shanghai.aliyuncs.com/capture/5d96d2b4-111b-4e5d-a0e5-20f44405bb55.mp4'),
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  uploadAddress?: string(name='UploadAddress', description='The upload URL.

>  The returned upload URL is a Base64-encoded URL. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAddress only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJFbmRwb2ludCI6Imh0dHBzOi8vb3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbSIsIkJ1Y2tldCI6InN6aGQtdmlkZW8iLCJGaWxlTmFtZSI6InZvZC0yOTYzMWEvc3YvNTBmYTJlODQtMTgxMjdhZGRiMTcvNTBmYTJlODQtMTgxMjdhZGRiM***'),
  uploadAuth?: string(name='UploadAuth', description='The upload credential.

>  The returned upload credential is a Base64-encoded value. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAuth only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJBY2Nlc3NLZXlJZCI6IkxUQUk0Rm53bTk1dHdxQjMxR3IzSE5hRCIsIkFjY2Vzc0tleVNlY3JldCI6Ik9lWllKR0dTMTlkNkZaM1E3UVpJQmdmSVdnM3BPaiIsIkV4cGlyYXRpb24iOiI***'),
}

model CreateUploadMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateUploadMediaResponseBody(name='body'),
}

/**
  * @description *   You can call this operation to obtain the upload URLs and credentials of audio and video files. You can also call this operation to obtain the upload URLs and credentials of images and auxiliary media assets.
  * *   Obtaining an upload URL and credential is essential for Intelligent Media Services (IMS) and is required in each upload operation.
  * *   If the video upload credential expires, you can call the RefreshUploadMedia operation to obtain a new upload credential. The default validity period of a video upload credential is 3,000 seconds.
  * *   After you upload a media asset, you can configure a callback to receive upload event notifications or call the GetMediaInfo operation to determine whether the media asset is uploaded based on the returned status.
  * *   The MediaId parameter returned by this operation can be used for media asset lifecycle management or media processing.
  * *   You can call this operation to upload media assets only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media asset to your own OSS bucket, you can upload the file to your OSS bucket by using [OSS SDK](https://help.aliyun.com/document_detail/32006.html), and then call the [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html) operation to register the file in the OSS bucket with the media asset library.
  * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
  * @param request  the request parameters of CreateUploadMedia  CreateUploadMediaRequest
  * @return CreateUploadMediaResponse
 */
async function createUploadMedia(request: CreateUploadMediaRequest): CreateUploadMediaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateUploadMedia', 'POST', '/', 'json', false, 'json', request);
}

model CreateUploadStreamRequest {
  regionId?: string(name='RegionId', position='Host'),
  definition?: string(name='Definition', description='The quality of the media stream. Valid values:

*   FD: low definition.
*   LD: standard definition.
*   SD: high definition.
*   HD: ultra-high definition.
*   OD: original quality.
*   2K: 2K resolution.
*   4K: 4K resolution.
*   SQ: standard sound quality.
*   HQ: high sound quality.', example='HD', position='Query'),
  fileExtension?: string(name='FileExtension', description='The file name extension of the media stream.', example='MP4', position='Query'),
  HDRType?: string(name='HDRType', description='The high dynamic range (HDR) format of the transcoded stream. Valid values:

*   HDR
*   HDR10
*   HLG
*   DolbyVision
*   HDRVivid
*   SDR+

> 

*   The value is not case-sensitive,

*   You can leave this parameter empty for non-HDR streams.', example='HDR10', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  userData?: string(name='UserData', description='The user data.', example='{"MessageCallback":{"CallbackURL":"http://aliyundoc.com"}, "Extend":{"localId":"xxx","test":"www"}}', position='Query'),
}

model CreateUploadStreamResponseBody = {
  fileURL?: string(name='FileURL', description='The Object Storage Service (OSS) URL of the file. The URL does not contain the information used for authentication.', example='http://outin-***.oss-cn-shanghai.aliyuncs.com/stream/48555e8b-181dd5a8c07/48555e8b-181dd5a8c07.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****c469e944b5a856828dc2****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  uploadAddress?: string(name='UploadAddress', description='The upload URL.

>  The returned upload URL is a Base64-encoded URL. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAddress only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJFbmRwb2ludCI6Imh0dHBzOi8vb3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbSIsIkJ1Y2tldCI6InN6aGQtdmlkZW8iLCJGaWxlTmFtZSI6InZvZC0yOTYzMWEvc3YvNTBmYTJlODQtMTgxMjdhZGRiMTcvNTBmYTJlODQtMTgxMjdhZGRiM***'),
  uploadAuth?: string(name='UploadAuth', description='The upload credential.

>  The returned upload credential is a Base64-encoded value. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAuth only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJBY2Nlc3NLZXlJZCI6IkxUQUk0Rm53bTk1dHdxQjMxR3IzSE5hRCIsIkFjY2Vzc0tleVNlY3JldCI6Ik9lWllKR0dTMTlkNkZaM1E3UVpJQmdmSVdnM3BPaiIsIkV4cGlyYXRpb24iOiI***'),
}

model CreateUploadStreamResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateUploadStreamResponseBody(name='body'),
}

/**
  * @description *   You can call this operation to upload only a local media stream. After the media stream is uploaded, it is associated with the specified media asset ID.
  * *   You can call this operation to upload media streams only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media stream to your own OSS bucket, you can upload the file to your OSS bucket by using [OSS SDK](https://help.aliyun.com/document_detail/32006.html), and then call the [RegisterMediaStream](https://help.aliyun.com/document_detail/440765.html) operation to associate the media stream with the specified media asset ID.
  * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
  * @param request  the request parameters of CreateUploadStream  CreateUploadStreamRequest
  * @return CreateUploadStreamResponse
 */
async function createUploadStream(request: CreateUploadStreamRequest): CreateUploadStreamResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateUploadStream', 'POST', '/', 'json', false, 'json', request);
}

model DecryptKMSDataKeyRequest {
  ciphertextBlob: string(name='CiphertextBlob', description='The ciphertext that you want to decrypt.

This parameter is required.', example='ODZhOWVmZDktM2QxNi00ODk0LWJkNGYtMWZjNDNmM2YyYWJmS7FmDBBQ0BkKsQrtRnidtPwirmDcS0ZuJCU41xxAAWk4Z8qsADfbV0b+i6kQmlvj79dJdGOvtX69Uycs901qOjop4bTS****', position='Query'),
}

model DecryptKMSDataKeyResponseBody = {
  dataKey?: {
    keyId?: string(name='KeyId', description='The ID of the customer master key (CMK) that was used to decrypt the ciphertext.', example='202b9877-5a25-46e3-a763-e20791b5****'),
    plaintext?: string(name='Plaintext', description='The plaintext that is generated after decryption.', example='tRYXuCwgja12xxO1N/gZERDDCLw9doZEQiPDk/Bv****'),
  }(name='DataKey', description='The information about the decryption result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DecryptKMSDataKeyResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DecryptKMSDataKeyResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DecryptKMSDataKey  DecryptKMSDataKeyRequest
  * @return DecryptKMSDataKeyResponse
 */
async function decryptKMSDataKey(request: DecryptKMSDataKeyRequest): DecryptKMSDataKeyResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DecryptKMSDataKey', 'POST', '/', 'json', false, 'json', request);
}

model DeleteAvatarTrainingJobRequest {
  jobId: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model DeleteAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteAvatarTrainingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteAvatarTrainingJob  DeleteAvatarTrainingJobRequest
  * @return DeleteAvatarTrainingJobResponse
 */
async function deleteAvatarTrainingJob(request: DeleteAvatarTrainingJobRequest): DeleteAvatarTrainingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteAvatarTrainingJob', 'POST', '/', 'json', false, 'json', request);
}

model DeleteCategoryRequest {
  regionId?: string(name='RegionId', position='Host'),
  cateId: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of CateId returned by the AddCategory operation that you called to create a category.
*   View the value of CateId returned by the GetCategories operation that you called to query a category.

This parameter is required.', example='46', position='Query'),
}

model DeleteCategoryResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model DeleteCategoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCategoryResponseBody(name='body'),
}

/**
  * @description This operation also deletes the subcategories, including the level-2 and level-3 categories, of the category.
  * @param request  the request parameters of DeleteCategory  DeleteCategoryRequest
  * @return DeleteCategoryResponse
 */
async function deleteCategory(request: DeleteCategoryRequest): DeleteCategoryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteCategory', 'POST', '/', 'json', false, 'json', request);
}

model DeleteCustomTemplateRequest {
  templateId: string(name='TemplateId', description='The ID of the custom template.

This parameter is required.', example='****96e8864746a0b6f3****', position='Query'),
}

model DeleteCustomTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCustomTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteCustomTemplate  DeleteCustomTemplateRequest
  * @return DeleteCustomTemplateResponse
 */
async function deleteCustomTemplate(request: DeleteCustomTemplateRequest): DeleteCustomTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteCustomTemplate', 'POST', '/', 'json', false, 'json', request);
}

model DeleteCustomizedVoiceJobRequest {
  jobId: string(name='JobId', description='The ID of the human voice cloning job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model DeleteCustomizedVoiceJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteCustomizedVoiceJob  DeleteCustomizedVoiceJobRequest
  * @return DeleteCustomizedVoiceJobResponse
 */
async function deleteCustomizedVoiceJob(request: DeleteCustomizedVoiceJobRequest): DeleteCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDNADBRequest {
  DBId: string(name='DBId', description='The ID of the media fingerprint library that you want to delete.

This parameter is required.', example='fb712a6890464059b1b2ea7c8647****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model DeleteDNADBResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model DeleteDNADBResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDNADBResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDNADB  DeleteDNADBRequest
  * @return DeleteDNADBResponse
 */
async function deleteDNADB(request: DeleteDNADBRequest): DeleteDNADBResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDNADB', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDNAFilesRequest {
  DBId: string(name='DBId', description='The ID of the media fingerprint library from which you want to delete files.

This parameter is required.', example='fb712a6890464059b1b2ea7c8647****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  primaryKeys: string(name='PrimaryKeys', description='The primary key values of the files that you want to delete. Separate multiple values with commas (,). You can delete up to 50 files at a time.

This parameter is required.', example='41e6536e4f2250e2e9bf26cdea19****', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model DeleteDNAFilesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model DeleteDNAFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDNAFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDNAFiles  DeleteDNAFilesRequest
  * @return DeleteDNAFilesResponse
 */
async function deleteDNAFiles(request: DeleteDNAFilesRequest): DeleteDNAFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDNAFiles', 'POST', '/', 'json', false, 'json', request);
}

model DeleteEditingProjectMaterialsRequest {
  materialIds: string(name='MaterialIds', description='The material ID. Separate multiple material IDs with commas (,). You can specify up to 10 IDs.

This parameter is required.', example='*****cbd721b418a89a7dafb1dc*****,*****86f5d534c95997c55c96f*****', position='Query'),
  materialType: string(name='MaterialType', description='The material type. Valid values:

\\- video

\\- image

\\- audio

\\- subtitle

\\- text

This parameter is required.', example='video', position='Query'),
  projectId: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='*****fb2101cb318*****', position='Query'),
}

model DeleteEditingProjectMaterialsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******36-3C1E-4417-BDB2-1E034F******'),
}

model DeleteEditingProjectMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteEditingProjectMaterialsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteEditingProjectMaterials  DeleteEditingProjectMaterialsRequest
  * @return DeleteEditingProjectMaterialsResponse
 */
async function deleteEditingProjectMaterials(request: DeleteEditingProjectMaterialsRequest): DeleteEditingProjectMaterialsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteEditingProjectMaterials', 'POST', '/', 'json', false, 'json', request);
}

model DeleteEditingProjectsRequest {
  projectIds?: string(name='ProjectIds', description='The ID of the online editing project. You can specify multiple IDs separated with commas (,).', example='****fb2101bf24bf41cb318787dc****,****87dcfb2101bf24bf41cb3187****', position='Query'),
}

model DeleteEditingProjectsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****25818875-5F78-4AF6-D7393642CA58****'),
}

model DeleteEditingProjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteEditingProjectsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteEditingProjects  DeleteEditingProjectsRequest
  * @return DeleteEditingProjectsResponse
 */
async function deleteEditingProjects(request: DeleteEditingProjectsRequest): DeleteEditingProjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteEditingProjects', 'POST', '/', 'json', false, 'json', request);
}

model DeleteLiveRecordFilesRequest {
  recordIds: [ string ](name='RecordIds', description='The collection of IDs of recording files.

This parameter is required.', position='Query'),
  removeFile?: boolean(name='RemoveFile', description='Specifies whether to delete the original files in OSS.', example='true', position='Query'),
}

model DeleteLiveRecordFilesResponseBody = {
  deleteFileInfoList?: [ 
    {
      code?: string(name='Code', description='The code that identifies the result of the deletion.', example='OK'),
      message?: string(name='Message', description='The result of deletion.', example='OK'),
      recordId?: string(name='RecordId', description='The ID of the deleted recording file.', example='13cbb83e-043c-4728-ac35-*****'),
    }
  ](name='DeleteFileInfoList', description='The list of files deleted.'),
  message?: string(name='Message', description='The description of the state returned.', example='OK'),
  requestId?: string(name='RequestId', description='Id of the request', example='13cbb83e-043c-4728-ac35-*****'),
}

model DeleteLiveRecordFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveRecordFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLiveRecordFiles  DeleteLiveRecordFilesRequest
  * @return DeleteLiveRecordFilesResponse
 */
async function deleteLiveRecordFiles(request: DeleteLiveRecordFilesRequest): DeleteLiveRecordFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLiveRecordFiles', 'POST', '/', 'json', false, 'json', request);
}

model DeleteLiveRecordTemplateRequest {
  templateId: string(name='TemplateId', description='The ID of the template to be deleted. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ice.console.aliyun.com/live-processing/template/list/record), choose Real-time Media Processing > Template Management, and then click the Recording tab. Alternatively, find the ID from the response parameters of the [CreateLiveRecordTemplate](https://help.aliyun.com/document_detail/448213.html) operation.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66', position='Query'),
}

model DeleteLiveRecordTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='3E5330CF-B4C8-5BEF-AA6B-8E70BD20FAEE'),
}

model DeleteLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveRecordTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLiveRecordTemplate  DeleteLiveRecordTemplateRequest
  * @return DeleteLiveRecordTemplateResponse
 */
async function deleteLiveRecordTemplate(request: DeleteLiveRecordTemplateRequest): DeleteLiveRecordTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLiveRecordTemplate', 'POST', '/', 'json', false, 'json', request);
}

model DeleteLiveSnapshotFilesRequest {
  createTimestampList: [ long ](name='CreateTimestampList', description='The list of timestamps when the jobs were created. The values are UNIX timestamps representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC. A maximum of 200 jobs can be deleted at a time.

This parameter is required.', shrink='json', position='Query'),
  deleteOriginalFile?: boolean(name='DeleteOriginalFile', description='Specifies whether to delete the original files at the same time. Default value: false.', example='true', position='Query'),
  jobId: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Query'),
}

model DeleteLiveSnapshotFilesResponseBody = {
  deleteFileResultList?: [ 
    {
      createTimestamp?: long(name='CreateTimestamp', description='The time when the file was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1660638613798'),
      result?: string(name='Result', description='The result of deletion. A value of OK indicates that the file is deleted. Other values indicate that the file failed to be deleted.

Valid values:

*   OK: The file was deleted.
*   NotFound: The file was not found.', example='OK'),
    }
  ](name='DeleteFileResultList', description='The list of deleted files.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
}

model DeleteLiveSnapshotFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveSnapshotFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLiveSnapshotFiles  DeleteLiveSnapshotFilesRequest
  * @return DeleteLiveSnapshotFilesResponse
 */
async function deleteLiveSnapshotFiles(request: DeleteLiveSnapshotFilesRequest): DeleteLiveSnapshotFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLiveSnapshotFiles', 'POST', '/', 'json', false, 'json', request);
}

model DeleteLiveSnapshotTemplateRequest {
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Body'),
}

model DeleteLiveSnapshotTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveSnapshotTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLiveSnapshotTemplate  DeleteLiveSnapshotTemplateRequest
  * @return DeleteLiveSnapshotTemplateResponse
 */
async function deleteLiveSnapshotTemplate(request: DeleteLiveSnapshotTemplateRequest): DeleteLiveSnapshotTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLiveSnapshotTemplate', 'POST', '/', 'json', true, 'form', request);
}

model DeleteLiveTranscodeJobRequest {
  jobId: string(name='JobId', description='The ID of the transcoding job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model DeleteLiveTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model DeleteLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveTranscodeJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLiveTranscodeJob  DeleteLiveTranscodeJobRequest
  * @return DeleteLiveTranscodeJobResponse
 */
async function deleteLiveTranscodeJob(request: DeleteLiveTranscodeJobRequest): DeleteLiveTranscodeJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLiveTranscodeJob', 'POST', '/', 'json', false, 'json', request);
}

model DeleteLiveTranscodeTemplateRequest {
  templateId: string(name='TemplateId', description='The template ID. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ice.console.aliyun.com/summary), choose Real-time Media Processing > Template Management, and then click the Transcoding tab. Alternatively, find the ID from the response parameters of the [CreateLiveTranscodeTemplate](https://help.aliyun.com/document_detail/449217.html) operation.

This parameter is required.', example='****d80e4e4044975745c14b****', position='Query'),
}

model DeleteLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model DeleteLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveTranscodeTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLiveTranscodeTemplate  DeleteLiveTranscodeTemplateRequest
  * @return DeleteLiveTranscodeTemplateResponse
 */
async function deleteLiveTranscodeTemplate(request: DeleteLiveTranscodeTemplateRequest): DeleteLiveTranscodeTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLiveTranscodeTemplate', 'POST', '/', 'json', false, 'json', request);
}

model DeleteMediaFromSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  msgBody?: string(name='MsgBody', description='The message body.', example='{}', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1', position='Query'),
}

model DeleteMediaFromSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteMediaFromSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaFromSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteMediaFromSearchLib  DeleteMediaFromSearchLibRequest
  * @return DeleteMediaFromSearchLibResponse
 */
async function deleteMediaFromSearchLib(request: DeleteMediaFromSearchLibRequest): DeleteMediaFromSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMediaFromSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model DeleteMediaInfosRequest {
  regionId?: string(name='RegionId', position='Host'),
  deletePhysicalFiles?: boolean(name='DeletePhysicalFiles', description='Specifies whether to delete the physical file of the media asset.

If the media asset is stored in your own OSS bucket, you must authorize the service role AliyunICEDefaultRole in advance. For more information<props="china">, see [Authorize IMS to delete recording files in OSS](https://help.aliyun.com/zh/ims/user-guide/record?spm=a2c4g.11186623.0.i8#0737d9c437bmn).', example='false', position='Query'),
  inputURLs?: string(name='InputURLs', description='The URL of the media asset that you want to delete. The file corresponding to the URL must be registered with IMS. Separate multiple URLs with commas (,). The following two formats are supported:

1.  http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?
2.  OSS://example-bucket/example.mp4?\\
    In this format, it is considered by default that the region of the OSS bucket in which the media asset resides is the same as the region in which IMS is activated.', position='Query'),
  mediaIds?: string(name='MediaIds', description='The ID of the media asset that you want to delete from Intelligent Media Services (IMS).

*   Separate multiple IDs with commas (,).

If you leave MediaIds empty, you must specify InputURLs.', example='****20b48fb04483915d4f2cd8ac****,****15d4a4b0448391508f2cb486****', position='Query'),
}

model DeleteMediaInfosResponseBody = {
  forbiddenList?: [ string ](name='ForbiddenList', description='The IDs or URLs of media assets that cannot be deleted. Generally, media assets cannot be deleted if you do not have the required permissions.'),
  ignoredList?: [ string ](name='IgnoredList', description='The IDs or URLs of ignored media assets. An error occurred while obtaining such media assets.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
}

model DeleteMediaInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaInfosResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteMediaInfos  DeleteMediaInfosRequest
  * @return DeleteMediaInfosResponse
 */
async function deleteMediaInfos(request: DeleteMediaInfosRequest): DeleteMediaInfosResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMediaInfos', 'POST', '/', 'json', false, 'json', request);
}

model DeleteMediaMarksRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****c469e944b5a856828dc2****', position='Query'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The mark ID. You can specify multiple mark IDs separated with commas (,).

If you do not specify MediaMarkIds, all the marks of the media asset are deleted.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60', position='Query'),
}

model DeleteMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The IDs of the deleted marks separated with commas (,).', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaMarksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteMediaMarks  DeleteMediaMarksRequest
  * @return DeleteMediaMarksResponse
 */
async function deleteMediaMarks(request: DeleteMediaMarksRequest): DeleteMediaMarksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMediaMarks', 'POST', '/', 'json', false, 'json', request);
}

model DeletePipelineRequest {
  pipelineId: string(name='PipelineId', description='The ID of the MPS queue.

This parameter is required.', example='****96e8864746a0b6f3****', position='Query'),
}

model DeletePipelineResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeletePipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeletePipelineResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeletePipeline  DeletePipelineRequest
  * @return DeletePipelineResponse
 */
async function deletePipeline(request: DeletePipelineRequest): DeletePipelineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeletePipeline', 'POST', '/', 'json', false, 'json', request);
}

model DeletePlayInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  deletePhysicalFiles?: boolean(name='DeletePhysicalFiles', description='Specifies whether to delete the physical file of the media stream.

If the media asset is stored in your own Object Storage Service (OSS) bucket, you must authorize the service role AliyunICEDefaultRole in advance. <props="china">For more information, see [Authorize IMS to delete recording files in OSS](https://help.aliyun.com/document_detail/449331.html#p-ko2-wc7-iad).

You can delete only the physical files of transcoded streams, but not the physical files of source files.', example='false', position='Query'),
  fileURLs?: string(name='FileURLs', description='The URL of the media stream file that you want to delete. Separate multiple URLs with commas (,).', example='https://ice-test001.oss-cn-shanghai.aliyuncs.com/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95/%E5%B0%8F%E7%8C%AA%E4%BD%A9%E5%A5%87640*360.mp4', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='1d3518e0027d71ed80cd909598416303', position='Query'),
}

model DeletePlayInfoResponseBody = {
  forbiddenList?: [ string ](name='ForbiddenList', description='The URLs of the media streams that cannot be deleted. Generally, media streams cannot be deleted if you do not have the required permissions.'),
  ignoredList?: [ string ](name='IgnoredList', description='The URLs of ignored media streams. An error occurred while obtaining such media assets because the IDs or URLs of the media assets do not exist.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeletePlayInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeletePlayInfoResponseBody(name='body'),
}

/**
  * @description You can call this operation to delete multiple media streams at a time.
  * @param request  the request parameters of DeletePlayInfo  DeletePlayInfoRequest
  * @return DeletePlayInfoResponse
 */
async function deletePlayInfo(request: DeletePlayInfoRequest): DeletePlayInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeletePlayInfo', 'POST', '/', 'json', false, 'json', request);
}

model DeleteSmartJobRequest {
  jobId?: string(name='JobId', description='The IDs of the jobs to delete. Separate multiple IDs with commas (,).', example='******b48fb04483915d4f2cd8******,******042d5e4db6866f6289d1******', position='Query'),
}

model DeleteSmartJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteSmartJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteSmartJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteSmartJob  DeleteSmartJobRequest
  * @return DeleteSmartJobResponse
 */
async function deleteSmartJob(request: DeleteSmartJobRequest): DeleteSmartJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteSmartJob', 'POST', '/', 'json', false, 'json', request);
}

model DeleteTemplateRequest {
  templateIds?: string(name='TemplateIds', description='The IDs of the templates that you want to delete. Separate multiple IDs with commas (,).', example='****20b48fb04483915d4f2cd8ac****,****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model DeleteTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteTemplateResponseBody(name='body'),
}

/**
  * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
  * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/270942.html).
  * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/291418.html).
  * @param request  the request parameters of DeleteTemplate  DeleteTemplateRequest
  * @return DeleteTemplateResponse
 */
async function deleteTemplate(request: DeleteTemplateRequest): DeleteTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteTemplate', 'GET', '/', 'json', false, 'json', request);
}

model DescribeAIAgentInstanceRequest {
  instanceId: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
}

model DescribeAIAgentInstanceResponseBody = {
  instance?: {
    callLogUrl?: string(name='CallLogUrl', example='https://example.com/call_logs/12345'),
    runtimeConfig?: AIAgentRuntimeConfig(name='RuntimeConfig', example='{"VoiceChat":{"AgentUserId":"voice_agent_001","ChannelId":"voice_channel_001","AuthToken":"your_voice_chat_auth_token"}}'),
    status?: string(name='Status', example='Finished'),
    templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', example='{"VoiceChat": {"AppId": "your_voice_chat_app_id"}}'),
    userData?: string(name='UserData', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
  }(name='Instance'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model DescribeAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAIAgentInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeAIAgentInstance  DescribeAIAgentInstanceRequest
  * @return DescribeAIAgentInstanceResponse
 */
async function describeAIAgentInstance(request: DescribeAIAgentInstanceRequest): DescribeAIAgentInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAIAgentInstance', 'POST', '/', 'json', false, 'json', request);
}

model DescribeMeterImsEditUsageRequest {
  endTs: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1656995036', position='Query'),
  interval: long(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='86400', position='Query'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai', position='Query'),
  startTs: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1654403036', position='Query'),
}

model DescribeMeterImsEditUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='1.23'),
      profile?: string(name='Profile', description='The video profile.', example='1080P'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
    }
  ](name='Data', description='The usage statistics of IMS on VOD editing.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7F3AE2C6-5CC6-5712-BAC5-5A735A157687'),
}

model DescribeMeterImsEditUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsEditUsageResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeMeterImsEditUsage  DescribeMeterImsEditUsageRequest
  * @return DescribeMeterImsEditUsageResponse
 */
async function describeMeterImsEditUsage(request: DescribeMeterImsEditUsageRequest): DescribeMeterImsEditUsageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeMeterImsEditUsage', 'POST', '/', 'json', false, 'json', request);
}

model DescribeMeterImsMediaConvertUHDUsageRequest {
  endTs: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1656995036', position='Query'),
  interval: string(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='3600', position='Query'),
  regionId?: string(name='RegionId', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai', position='Query'),
  startTs: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1654403036', position='Query'),
}

model DescribeMeterImsMediaConvertUHDUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='308028'),
      specification?: string(name='Specification', description='The transcoding specifications.', example='SuperResolution.Standard.1080P'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
    }
  ](name='Data', description='The usage statistics of IMS on UHD transcoding of MPS.'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
}

model DescribeMeterImsMediaConvertUHDUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsMediaConvertUHDUsageResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeMeterImsMediaConvertUHDUsage  DescribeMeterImsMediaConvertUHDUsageRequest
  * @return DescribeMeterImsMediaConvertUHDUsageResponse
 */
async function describeMeterImsMediaConvertUHDUsage(request: DescribeMeterImsMediaConvertUHDUsageRequest): DescribeMeterImsMediaConvertUHDUsageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeMeterImsMediaConvertUHDUsage', 'POST', '/', 'json', false, 'json', request);
}

model DescribeMeterImsMediaConvertUsageRequest {
  endTs: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp. The maximum query range is 31 days. The duration between StartTs and EndTs cannot exceed 31 days.

This parameter is required.', example='1656995036', position='Query'),
  interval: long(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='86400', position='Query'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai', position='Query'),
  startTs: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp. You can query data within the last 90 days.

This parameter is required.', example='1654403036', position='Query'),
}

model DescribeMeterImsMediaConvertUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='20'),
      specification?: string(name='Specification', description='The transcoding specifications.', example='H264.HD'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
    }
  ](name='Data', description='The usage statistics of IMS on VOD transcoding.'),
  requestId?: string(name='RequestId', description='The request ID.', example='FBBB5210-2B78-58FB-A6FE-9DD887BB2C61'),
}

model DescribeMeterImsMediaConvertUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsMediaConvertUsageResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeMeterImsMediaConvertUsage  DescribeMeterImsMediaConvertUsageRequest
  * @return DescribeMeterImsMediaConvertUsageResponse
 */
async function describeMeterImsMediaConvertUsage(request: DescribeMeterImsMediaConvertUsageRequest): DescribeMeterImsMediaConvertUsageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeMeterImsMediaConvertUsage', 'POST', '/', 'json', false, 'json', request);
}

model DescribeMeterImsMpsAiUsageRequest {
  endTs: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp. The maximum query range is 31 days. The duration between StartTs and EndTs cannot exceed 31 days.

This parameter is required.', example='1656995036', position='Query'),
  interval: long(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='86400', position='Query'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai', position='Query'),
  startTs: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp. You can query data within the last 90 days.

This parameter is required.', example='1654403036', position='Query'),
}

model DescribeMeterImsMpsAiUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='644'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
      type?: string(name='Type', description='The AI type. Valid values:'),
    }
  ](name='Data', description='The usage statistics of IMS on AI processing of MPS.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
}

model DescribeMeterImsMpsAiUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsMpsAiUsageResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeMeterImsMpsAiUsage  DescribeMeterImsMpsAiUsageRequest
  * @return DescribeMeterImsMpsAiUsageResponse
 */
async function describeMeterImsMpsAiUsage(request: DescribeMeterImsMpsAiUsageRequest): DescribeMeterImsMpsAiUsageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeMeterImsMpsAiUsage', 'POST', '/', 'json', false, 'json', request);
}

model DescribeMeterImsSummaryRequest {
  endTs: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1656995036', position='Query'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai', position='Query'),
  startTs: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1654403036', position='Query'),
}

model DescribeMeterImsSummaryResponseBody = {
  data?: [ 
    {
      editingDuration?: string(name='EditingDuration', description='The duration of video editing.', example='8722'),
      liveEditDuration?: string(name='LiveEditDuration', description='The duration of live editing.', example='2000'),
      liveRecordDuration?: string(name='LiveRecordDuration', description='The duration of live stream recording.', example='100'),
      liveSnapshotCount?: string(name='LiveSnapshotCount', description='The number of live stream snapshots.', example='100'),
      liveTranscodeDuration?: long(name='LiveTranscodeDuration', description='The duration of live stream transcoding.', example='12356'),
      mpsAiDuration?: long(name='MpsAiDuration', description='The duration of AI processing.', example='0'),
      mpsTranscodeDuration?: long(name='MpsTranscodeDuration', description='The duration of video-on-demand (VOD) transcoding.', example='17337'),
      mpsTranscodeUHDDuration?: long(name='MpsTranscodeUHDDuration', description='The duration of audio and video enhancement.', example='300'),
    }
  ](name='Data', description='The usage statistics of IMS.'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
}

model DescribeMeterImsSummaryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsSummaryResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeMeterImsSummary  DescribeMeterImsSummaryRequest
  * @return DescribeMeterImsSummaryResponse
 */
async function describeMeterImsSummary(request: DescribeMeterImsSummaryRequest): DescribeMeterImsSummaryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeMeterImsSummary', 'POST', '/', 'json', false, 'json', request);
}

model DescribeNotifyConfigRequest {
  AIAgentId: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
}

model DescribeNotifyConfigResponseBody = {
  callbackUrl?: string(name='CallbackUrl', example='http://customer.com/callback'),
  enableNotify?: boolean(name='EnableNotify', example='true'),
  eventTypes?: string(name='EventTypes', example='agent_start,agent_stop,error'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
  token?: string(name='Token', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx'),
}

model DescribeNotifyConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeNotifyConfigResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeNotifyConfig  DescribeNotifyConfigRequest
  * @return DescribeNotifyConfigResponse
 */
async function describeNotifyConfig(request: DescribeNotifyConfigRequest): DescribeNotifyConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeNotifyConfig', 'POST', '/', 'json', false, 'json', request);
}

model DescribePlayListRequest {
  beginTs: string(name='BeginTs', description='This parameter is required.', example='1676170500011', position='Query'),
  endTs: string(name='EndTs', description='This parameter is required.', example='1682474405173', position='Query'),
  orderName?: string(name='OrderName', example='FirstFrameDuration', position='Query'),
  orderType?: string(name='OrderType', example='DESC', position='Query'),
  pageNo: int32(name='PageNo', description='This parameter is required.', example='1', position='Query'),
  pageSize: int32(name='PageSize', description='This parameter is required.', example='10', position='Query'),
  playType?: string(name='PlayType', example='vod', position='Query'),
  status?: string(name='Status', example='complete', position='Query'),
  traceId?: string(name='TraceId', example='0bc5e70516766285805381012d271e', position='Query'),
}

model DescribePlayListResponseBody = {
  pageNum?: long(name='PageNum', example='1'),
  pageSize?: long(name='PageSize', example='10'),
  playList?: [ 
    {
      firstFrameDuration?: string(name='FirstFrameDuration', example='200'),
      playDuration?: string(name='PlayDuration', example='1000'),
      playTs?: string(name='PlayTs', example='1675922209572'),
      playType?: string(name='PlayType', example='vod'),
      sessionId?: string(name='SessionId', example='91488be2-8381-40c9-8494-e8afe22c4a2d'),
      status?: string(name='Status', example='complete'),
      stuckDuration?: string(name='StuckDuration', example='20'),
      traceId?: string(name='TraceId', example='0b736abf16724820210842673d9543'),
      videoDuration?: string(name='VideoDuration', example='2000'),
      videoId?: string(name='VideoId', example='250314203f0171eebff17035d0b20102'),
    }
  ](name='PlayList'),
  requestId?: string(name='RequestId', description='Id', example='B960580D-26FA-5547-8AFC-3CDC812DBF27'),
  totalNum?: long(name='TotalNum', example='49'),
}

model DescribePlayListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribePlayListResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribePlayList  DescribePlayListRequest
  * @return DescribePlayListResponse
 */
async function describePlayList(request: DescribePlayListRequest): DescribePlayListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribePlayList', 'POST', '/', 'json', false, 'json', request);
}

model DescribeRtcRobotInstanceRequest {
  instanceId?: string(name='InstanceId', example='727dc0e296014bb58670940a3da95592', position='Query'),
}

model DescribeRtcRobotInstanceResponseBody = {
  authToken?: string(name='AuthToken', example='**********'),
  channelId?: string(name='ChannelId', example='testId'),
  config?: {
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt', example='true'),
    greeting?: string(name='Greeting'),
    voiceId?: string(name='VoiceId', example='zhixiaoxia'),
  }(name='Config'),
  requestId?: string(name='RequestId', description='Id of the request', example='20B3A1B6-4BD2-5DE6-BCBC-098C9B4F4E91'),
  status?: string(name='Status', example='Executing'),
  userData?: string(name='UserData', example='{}'),
  userId?: string(name='UserId', example='my-robot'),
}

model DescribeRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeRtcRobotInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeRtcRobotInstance  DescribeRtcRobotInstanceRequest
  * @return DescribeRtcRobotInstanceResponse
 */
async function describeRtcRobotInstance(request: DescribeRtcRobotInstanceRequest): DescribeRtcRobotInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeRtcRobotInstance', 'POST', '/', 'json', false, 'json', request);
}

model DetectAudioForCustomizedVoiceJobRequest {
  audioRecordId: int32(name='AudioRecordId', description='The sequence number of the recording file.

This parameter is required.', example='1', minimum=1, maximum=20, position='Query'),
  recordUrl: string(name='RecordUrl', description='The URL of the recording file.

> : The URL must be an Object Storage Service (OSS) URL within your Alibaba Cloud account. The OSS bucket must be in the same region in which IMS is activated.

> : The audio file must be in the WAV or PCM format and must be a 16-bit mono audio file at 48000 Hz.

This parameter is required.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/record1.wav', position='Query'),
  voiceId: string(name='VoiceId', description='The voice ID.

This parameter is required.', example='xiaozhuan', position='Query'),
}

model DetectAudioForCustomizedVoiceJobResponseBody = {
  data?: {
    pass?: boolean(name='Pass', description='Indicates whether the audio file passes the check. Valid values:

*   true
*   false', example='false'),
    reason?: string(name='Reason', description='The reason returned if the audio file failed to pass the check.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
}

model DetectAudioForCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DetectAudioForCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DetectAudioForCustomizedVoiceJob  DetectAudioForCustomizedVoiceJobRequest
  * @return DetectAudioForCustomizedVoiceJobResponse
 */
async function detectAudioForCustomizedVoiceJob(request: DetectAudioForCustomizedVoiceJobRequest): DetectAudioForCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DetectAudioForCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model DropSearchIndexRequest {
  regionId?: string(name='RegionId', position='Host'),
  indexType: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.

This parameter is required.', example='mm', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

*   If you leave this parameter empty, the search index is created in the default search library of Intelligent Media Service (IMS). Default value: ims-default-search-lib.
*   To query information about an existing search library, call the [QuerySearchLib](https://help.aliyun.com/document_detail/2584455.html) API operation.', example='test1', position='Query'),
}

model DropSearchIndexResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DropSearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DropSearchIndexResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DropSearchIndex  DropSearchIndexRequest
  * @return DropSearchIndexResponse
 */
async function dropSearchIndex(request: DropSearchIndexRequest): DropSearchIndexResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DropSearchIndex', 'POST', '/', 'json', false, 'json', request);
}

model DropSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  searchLibName: string(name='SearchLibName', description='The name of the search library.

This parameter is required.', example='test1', position='Query'),
}

model DropSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DropSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DropSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DropSearchLib  DropSearchLibRequest
  * @return DropSearchLibResponse
 */
async function dropSearchLib(request: DropSearchLibRequest): DropSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DropSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model GenerateAIAgentCallRequest {
  AIAgentId: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
  expire?: long(name='Expire', example='3600', position='Query'),
  templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', shrink='json', position='Query'),
  userData?: string(name='UserData', position='Query'),
  userId?: string(name='UserId', example='877ae632caae49b1afc81c2e8194ffb4', position='Query'),
}

model GenerateAIAgentCallResponseBody = {
  AIAgentUserId?: string(name='AIAgentUserId', example='877ae632caae49b1afc81c2e8194ffb4'),
  channelId?: string(name='ChannelId', example='70f22d5784194938a7e387052f2b3208'),
  instanceId?: string(name='InstanceId', example='39f8e0bc005e4f309379701645f4****'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
  token?: string(name='Token', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx'),
  userId?: string(name='UserId', example='user123'),
}

model GenerateAIAgentCallResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GenerateAIAgentCallResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GenerateAIAgentCall  GenerateAIAgentCallRequest
  * @return GenerateAIAgentCallResponse
 */
async function generateAIAgentCall(request: GenerateAIAgentCallRequest): GenerateAIAgentCallResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GenerateAIAgentCall', 'POST', '/', 'json', false, 'json', request);
}

model GenerateKMSDataKeyRequest {
}

model GenerateKMSDataKeyResponseBody = {
  dataKey?: {
    ciphertextBlob?: string(name='CiphertextBlob', description='The ciphertext of the encrypted data key. This parameter is used as CipherText when you create a transcoding job.', example='ODZhOWVmZDktM2QxNi00ODk0LWJkNGYtMWZjNDNmM2YyYWJmS7FmDBBQ0BkKsQrtRnidtPwirmDcS0ZuJCU41xxAAWk4Z8qsADfbV0b+i6kQmlvj79dJdGOvtX69Uycs901qOjop4bTS****'),
    keyId?: string(name='KeyId', description='The ID of the customer master key (CMK). The ID must be globally unique.', example='7906979c-8e06-46a2-be2d-68e3ccbc****'),
    plaintext?: string(name='Plaintext', description='The Base64-encoded plaintext of the data key.', example='QmFzZTY0IGVuY29kZWQgcGxhaW50****'),
  }(name='DataKey', description='The information about the data key.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GenerateKMSDataKeyResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GenerateKMSDataKeyResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GenerateKMSDataKey  GenerateKMSDataKeyRequest
  * @return GenerateKMSDataKeyResponse
 */
async function generateKMSDataKey(request: GenerateKMSDataKeyRequest): GenerateKMSDataKeyResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GenerateKMSDataKey', 'POST', '/', 'json', false, 'json', request);
}

model GetAvatarRequest {
  avatarId: string(name='AvatarId', description='*   The ID of the digital human.

This parameter is required.', example='Avatar-XXXX', position='Query'),
}

model GetAvatarResponseBody = {
  data?: {
    avatar?: {
      avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
      avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXXX'),
      avatarName?: string(name='AvatarName', description='The name of the digital human.'),
      avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
      height?: int32(name='Height', description='The height of the digital human image in pixels.', example='1920'),
      portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='****571c704445f9a0ee011406c2****'),
      thumbnail?: string(name='Thumbnail', description='The thumbnail URL.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
      transparent?: boolean(name='Transparent', description='Indicates whether the digital human supports alpha channels.', example='true'),
      width?: int32(name='Width', description='The width of the digital human image in pixels.', example='1080'),
    }(name='Avatar', description='The information about the digital human.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetAvatarResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAvatarResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetAvatar  GetAvatarRequest
  * @return GetAvatarResponse
 */
async function getAvatar(request: GetAvatarRequest): GetAvatarResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAvatar', 'POST', '/', 'json', false, 'json', request);
}

model GetAvatarTrainingJobRequest {
  jobId: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetAvatarTrainingJobResponseBody = {
  data?: {
    avatarTrainingJob?: {
      avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
      avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXXX'),
      avatarName?: string(name='AvatarName', description='The name of the digital human.'),
      avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
      firstTrainingTime?: string(name='FirstTrainingTime', description='*   The time when the first training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
      jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****55d86f7f4587943ce7734d6b****'),
      lastTrainingTime?: string(name='LastTrainingTime', description='*   The time when the last training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
      message?: string(name='Message', description='The status description.'),
      portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='****571c704445f9a0ee011406c2****'),
      status?: string(name='Status', description='*   The state of the digital human training job.
*   Valid values: Init, Queuing, Training, Success, and Fail.', example='Success'),
      thumbnail?: string(name='Thumbnail', description='The thumbnail URL.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
      transparent?: boolean(name='Transparent', description='Indicates whether the input video supports alpha channels.', example='true'),
      video?: string(name='Video', description='The ID of the video used for training.', example='****571c704445f9a0ee011406c2****'),
    }(name='AvatarTrainingJob', description='The information about the digital human training job.'),
  }(name='Data', description='The data returned if the request was successful.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAvatarTrainingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetAvatarTrainingJob  GetAvatarTrainingJobRequest
  * @return GetAvatarTrainingJobResponse
 */
async function getAvatarTrainingJob(request: GetAvatarTrainingJobRequest): GetAvatarTrainingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAvatarTrainingJob', 'POST', '/', 'json', false, 'json', request);
}

model GetBatchMediaProducingJobRequest {
  jobId?: string(name='JobId', description='The ID of the quick video production job.', example='****b4549d46c88681030f6e****', position='Query'),
}

model GetBatchMediaProducingJobResponseBody = {
  editingBatchJob?: {
    completeTime?: string(name='CompleteTime', description='The time when the job was complete.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:57:07Z'),
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:47:07Z'),
    editingConfig?: string(name='EditingConfig', description='The editing configurations. For more information, see [EditingConfig](~~2692547#1be9bba03b7qu~~).', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}'),
    extend?: string(name='Extend', description='The extended information. This parameter contains the following fields:

ErrorCode: the error code of the main job.

ErrorMessage: the error message of the main job.', example='{
	"ErrorCode": "InvalidMaterial.NotFound",
	"ErrorMessage": "The specified clips id not found:[\\"****30d0b5e871eebb2ff7f6c75a****\\"]"
}'),
    inputConfig?: string(name='InputConfig', description='The input configurations. For more information, see [InputConfig](~~2692547#2faed1559549n~~).'),
    jobId?: string(name='JobId', description='The job ID.', example='****b6b2750d4308892ac3330238****'),
    jobType?: string(name='JobType'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:57:07Z'),
    outputConfig?: string(name='OutputConfig', description='The output configurations. For more information, see [OutputConfig](~~2692547#447b928fcbuoa~~).', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 20,
  "MaxDuration": 15,
  "Width": 1080,
  "Height": 1920,
  "Video": {"Crf": 27}
}'),
    status?: string(name='Status', description='The job state. Valid values:

Init: The job is initialized.

Processing: The job is in progress.

Finished: The job is complete.', example='Finished'),
    subJobList?: [ 
      {
        errorCode?: string(name='ErrorCode', description='The error code that is returned if the subjob failed. This parameter is not returned if the subjob is successful.', example='InvalidMaterial.NotFound'),
        errorMessage?: string(name='ErrorMessage', description='The error message that is returned if the subjob failed. This parameter is not returned if the subjob is successful.', example='The specified clips id not found:["****30d0b5e871eebb2ff7f6c75a****"]'),
        jobId?: string(name='JobId', description='The subjob ID.', example='****8e81933d44e3ae69e2f81485****'),
        mediaId?: string(name='MediaId', description='The ID of the output media asset.', example='****1470b11171ee9d19e7e6c66a****'),
        mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http:/xxx.oss-cn-shanghai.aliyuncs.com/xxx_0.mp4'),
        projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****7cc47fe04eaa81bd853acb6a****'),
        status?: string(name='Status', description='The subjob state. Valid values:

Init: The subjob is initialized.

Processing: The subjob is in progress.

Success: The subjob is successful.

Failed: The subjob failed.', example='Success'),
      }
    ](name='SubJobList', description='The quick video production subjobs.'),
    userData?: string(name='UserData', description='The user-defined data, including the business and callback configurations. For more information, see [UserData](https://help.aliyun.com/document_detail/357745.html?spm=a2c4g.439285.0.i1#section-urj-v3f-0s1).', example='{"NotifyAddress":"http://xx.xx.xxx"}'),
  }(name='EditingBatchJob', description='The information about the quick video production job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model GetBatchMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetBatchMediaProducingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetBatchMediaProducingJob  GetBatchMediaProducingJobRequest
  * @return GetBatchMediaProducingJobResponse
 */
async function getBatchMediaProducingJob(request: GetBatchMediaProducingJobRequest): GetBatchMediaProducingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetBatchMediaProducingJob', 'POST', '/', 'json', false, 'json', request);
}

model GetCategoriesRequest {
  regionId?: string(name='RegionId', position='Host'),
  cateId?: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of CateId returned by the AddCategory operation that you called to create a category.
*   View the value of CateId returned by the GetCategories operation that you called to query a category.', example='33', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values: 10 to 100.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting rule of results. Valid values:

\\- CreationTime:Desc (default): The results are sorted in reverse chronological order based on the creation time.

\\- CreationTime:Asc: The results are sorted in chronological order based on the creation time.', example='CreationTime:Desc', position='Query'),
  type?: string(name='Type', description='The type of the category. Valid values: default and material. A value of default indicates audio, video, and image files. This is the default value. A value of material indicates short video materials.', example='default', position='Query'),
}

model GetCategoriesResponseBody = {
  category?: {
    cateId?: long(name='CateId', description='The category ID.', example='46'),
    cateName?: string(name='CateName', description='The category name.'),
    level?: long(name='Level', description='The level of the category. A value of **0** indicates a level-1 category, a value of **1** indicates a level-2 category, and a value of **2** indicates a level-3 category.', example='0'),
    parentId?: long(name='ParentId', description='The ID of the parent category.', example='-1'),
    type?: string(name='Type', description='The type of the category. Valid values:

*   **default**: audio, video, and image files. This is the default value.
*   **material**: short video materials.', example='default'),
  }(name='Category', description='The information about the category.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  subCategories?: {
    category?: [ 
    {
      cateId?: long(name='CateId', description='The category ID.', example='129'),
      cateName?: string(name='CateName', description='The category name.

*   The value can be up to 64 bytes in length.
*   The value is encoded in UTF-8.'),
      level?: long(name='Level', description='The level of the category. A value of **0** indicates a level-1 category, a value of **1** indicates a level-2 category, and a value of **2** indicates a level-3 category.', example='1'),
      parentId?: long(name='ParentId', description='The ID of the parent category.', example='46'),
      subTotal?: long(name='SubTotal', description='The total number of subcategories.', example='100'),
      type?: string(name='Type', description='The type of the category. Valid values:

*   **default**: audio, video, and image files. This is the default value.
*   **material**: short video materials.', example='default'),
    }
  ](name='Category')
  }(name='SubCategories', description='The subcategories in the category.'),
  subTotal?: long(name='SubTotal', description='The total number of subcategories.', example='100'),
}

model GetCategoriesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCategoriesResponseBody(name='body'),
}

/**
  * @description You can call this operation to query the information about a category and its subcategories based on the category ID and category type.
  * @param request  the request parameters of GetCategories  GetCategoriesRequest
  * @return GetCategoriesResponse
 */
async function getCategories(request: GetCategoriesRequest): GetCategoriesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCategories', 'POST', '/', 'json', false, 'json', request);
}

model GetContentAnalyzeConfigRequest {
  regionId?: string(name='RegionId', position='Host'),
}

model GetContentAnalyzeConfigResponseBody = {
  contentAnalyzeConfig?: {
    auto?: boolean(name='Auto', example='true'),
    saveType?: string(name='SaveType', example='TEXT,FACE'),
    templateId?: string(name='TemplateId', example='S00000101-100070'),
  }(name='ContentAnalyzeConfig'),
  requestId?: string(name='RequestId', example='31FEC819-2344-5771-9366-9172DB0D26C9'),
}

model GetContentAnalyzeConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetContentAnalyzeConfigResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetContentAnalyzeConfig  GetContentAnalyzeConfigRequest
  * @return GetContentAnalyzeConfigResponse
 */
async function getContentAnalyzeConfig(request: GetContentAnalyzeConfigRequest): GetContentAnalyzeConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetContentAnalyzeConfig', 'POST', '/', 'json', false, 'json', request);
}

model GetCustomTemplateRequest {
  subtype?: int32(name='Subtype', description='The template subtype.', example='1', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****', position='Query'),
  type?: int32(name='Type', description='The ID of the template type that is used to query the default template. This parameter is required if TemplateId is not specified.', example='1', position='Query'),
}

model GetCustomTemplateResponseBody = {
  customTemplate?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-01-01T10:00:00Z'),
    frontendHint?: {
      transcodeTemplateHint?: {
        bitrateControlType?: string(name='BitrateControlType'),
      }(name='TranscodeTemplateHint'),
    }(name='FrontendHint'),
    isDefault?: boolean(name='IsDefault', description='Indicates whether the template is the default template.', example='true'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-01-01T11:00:00Z'),
    status?: string(name='Status', description='The template state.', example='Normal'),
    subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='1'),
    subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='Normal'),
    templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Type":"Normal","FrameType":"normal","Time":0,"Count":10}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
    templateName?: string(name='TemplateName', description='The template name.', example='测试转码模板'),
    type?: int32(name='Type', description='The type ID of the template.', example='2'),
    typeName?: string(name='TypeName', description='The type name of the template.', example='SnapshotTemplate'),
  }(name='CustomTemplate', description='The template information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCustomTemplateResponseBody(name='body'),
}

/**
  * @description You can call this operation to query the information about a template with the ID specified by the TemplateId parameter. You can also query the information about the default template. If TemplateId is specified, other parameters are ignored and the template whose ID is specified is queried. If TemplateId is not specified, the default template is queried based on other parameters. In this case, Type is required.
  * Template types:
  * 1.  1: transcoding template.
  * 2.  2: snapshot template.
  * 3.  3: animated image template.
  * 4.  4\\. image watermark template.
  * 5.  5: text watermark template.
  * 6.  6: subtitle template.
  * 7.  7: AI-assisted content moderation template.
  * 8.  8: AI-assisted intelligent thumbnail template.
  * 9.  9: AI-assisted intelligent erasure template.
  * Subtypes of transcoding templates:
  * 1.  1 (Normal): regular template.
  * 2.  2 (AudioTranscode): audio transcoding template.
  * 3.  3 (Remux): container format conversion template.
  * 4.  4 (NarrowBandV1): Narrowband HD 1.0 template.
  * 5.  5 (NarrowBandV2): Narrowband HD 2.0 template.
  * Subtypes of snapshot templates:
  * 1.  1 (Normal): regular template.
  * 2.  2 (Sprite): sprite template.
  * 3.  3 (WebVtt): WebVTT template.
  * Subtypes of AI-assisted content moderation templates:
  * 1.  1 (Video): video moderation template.
  * 2.  2 (Audio): audio moderation template.
  * 3.  3 (Image): image moderation template.
  * Subtypes of AI-assisted intelligent erasure templates:
  * 1.  1 (VideoDelogo): logo erasure template.
  * 2.  2 (VideoDetext): subtitle erasure template.
  * @param request  the request parameters of GetCustomTemplate  GetCustomTemplateRequest
  * @return GetCustomTemplateResponse
 */
async function getCustomTemplate(request: GetCustomTemplateRequest): GetCustomTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCustomTemplate', 'POST', '/', 'json', false, 'json', request);
}

model GetCustomizedVoiceRequest {
  voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan', position='Query'),
}

model GetCustomizedVoiceResponseBody = {
  data?: {
    customizedVoice?: {
      demoAudioMediaId?: string(name='DemoAudioMediaId', description='The media asset ID of the sample audio file.', example='****42d3c312402982be65975f5b****'),
      gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
      scenario?: string(name='Scenario', description='The demonstration scenario.

Valid values:

*   **story**
*   **interaction**
*   **navigation**', example='interaction'),
      voiceDesc?: string(name='VoiceDesc', description='The voice description.'),
      voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
      voiceName?: string(name='VoiceName', description='The voice name.'),
    }(name='CustomizedVoice', description='The personalized human voice.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetCustomizedVoiceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCustomizedVoiceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetCustomizedVoice  GetCustomizedVoiceRequest
  * @return GetCustomizedVoiceResponse
 */
async function getCustomizedVoice(request: GetCustomizedVoiceRequest): GetCustomizedVoiceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCustomizedVoice', 'POST', '/', 'json', false, 'json', request);
}

model GetCustomizedVoiceJobRequest {
  jobId: string(name='JobId', description='The ID of the human voice cloning job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetCustomizedVoiceJobResponseBody = {
  data?: {
    customizedVoiceJob?: {
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-06-07T02:27:08Z'),
      gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
      jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****571c704445f9a0ee011406c2****'),
      message?: string(name='Message', description='The status description.'),
      scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation', example='story'),
      status?: string(name='Status', description='The job state. Valid values:

*   Initialization
*   AudioDetecting
*   PreTraining
*   Training
*   Success
*   Fail', example='Fail'),
      type?: string(name='Type', description='The type of the human voice cloning job. Valid values:

*   Basic
*   Standard', example='Standard'),
      voiceDesc?: string(name='VoiceDesc', description='The voice description.', example='This is an exclusive voice'),
      voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
      voiceName?: string(name='VoiceName', description='The voice name.', example='Xiaozhuan'),
    }(name='CustomizedVoiceJob', description='The information about the human voice cloning job.'),
  }(name='Data', description='The data returned if the request was successful.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetCustomizedVoiceJob  GetCustomizedVoiceJobRequest
  * @return GetCustomizedVoiceJobResponse
 */
async function getCustomizedVoiceJob(request: GetCustomizedVoiceJobRequest): GetCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model GetDefaultStorageLocationRequest {
  regionId?: string(name='RegionId', position='Host'),
}

model GetDefaultStorageLocationResponseBody = {
  bucket?: string(name='Bucket', example='oss-test-bucket'),
  path?: string(name='Path', example='ice/dir'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
  status?: string(name='Status', example='normal'),
  storageType?: string(name='StorageType', example='user_oss_bucket'),
}

model GetDefaultStorageLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDefaultStorageLocationResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDefaultStorageLocation  GetDefaultStorageLocationRequest
  * @return GetDefaultStorageLocationResponse
 */
async function getDefaultStorageLocation(request: GetDefaultStorageLocationRequest): GetDefaultStorageLocationResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDefaultStorageLocation', 'POST', '/', 'json', false, 'json', request);
}

model GetDemonstrationForCustomizedVoiceJobRequest {
  scenario: string(name='Scenario', description='The demonstration scenario.

Valid values:

*   **story**
*   **interaction**
*   **navigation**

This parameter is required.', example='story', position='Query'),
}

model GetDemonstrationForCustomizedVoiceJobResponseBody = {
  data?: {
    demonstrationList?: [ 
      {
        audioId?: int32(name='AudioId', description='The sequence number of the text, which corresponds to the AduioRecordId parameter to be passed during audio check.', example='2'),
        demoAudio?: string(name='DemoAudio', description='The URL of the sample audio.

*   The value is an Object Storage Service (OSS) URL.

    **

    **Note**: The URL expires in 12 hours.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/1.wav'),
        text?: string(name='Text', description='The text content to be read.'),
      }
    ](name='DemonstrationList', description='A list of 20 text entries to be read and the corresponding sample audio.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetDemonstrationForCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDemonstrationForCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDemonstrationForCustomizedVoiceJob  GetDemonstrationForCustomizedVoiceJobRequest
  * @return GetDemonstrationForCustomizedVoiceJobResponse
 */
async function getDemonstrationForCustomizedVoiceJob(request: GetDemonstrationForCustomizedVoiceJobRequest): GetDemonstrationForCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDemonstrationForCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model GetDynamicImageJobRequest {
  jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****', position='Query'),
}

model GetDynamicImageJobResponseBody = {
  dynamicImageJob?: {
    code?: string(name='Code', description='Error codes', example='ResourceNotFound'),
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
    input?: {
      media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://test-bucket/sample-input.mp4'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='sample-input.mp4'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
    message?: string(name='Message', description='The error message that is returned.', example='The specified resource for "CustomTemplate" could not be found.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
    name?: string(name='Name', description='The name of the job.', example='SampleJob'),
    output?: {
      media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='****d80e4e4044975745c14b****'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='sample-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='path/to/object'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the input file. Valid values: OSS: an OSS object. Media: a media asset.', example='Media'),
    }(name='Output', description='The output of the job.'),
    outputUrl?: string(name='OutputUrl', description='The URL of the output animated image.', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/output.gif'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****d80e4e4044975745c14b****'),
    status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
    templateConfig?: string(name='TemplateConfig', description='The animation template configuration.', example='{"Format":"gif","Fps":5,"Height":1080,"Width":1920}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****d80e4e4044975745c14b****'),
    triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
    userData?: string(name='UserData', description='The user-defined data.', example='{"sampleParam": "sampleValue"}'),
  }(name='DynamicImageJob', description='The information about the snapshot job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******36-3C1E-4417-BDB2-1E034F******'),
}

model GetDynamicImageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDynamicImageJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDynamicImageJob  GetDynamicImageJobRequest
  * @return GetDynamicImageJobResponse
 */
async function getDynamicImageJob(request: GetDynamicImageJobRequest): GetDynamicImageJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDynamicImageJob', 'POST', '/', 'json', false, 'json', request);
}

model GetEditingProjectRequest {
  regionId?: string(name='RegionId', position='Host'),
  projectId: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='****fb2101bf24b2754cb318787dc****', position='Query'),
  requestSource?: string(name='RequestSource', description='The ID of the request source. Valid values:

\\- OpenAPI (default): Timeline conversion is not performed.

\\- WebSDK: If you specify this value, the project timeline is automatically converted into the frontend style, and the materials in the timeline are associated with the project to enable preview by using frontend web SDKs.', example='WebSDK', position='Query'),
}

model GetEditingProjectResponseBody = {
  project?: {
    businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{ "OutputMediaConfig" : { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path" }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
    businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

Reserving

ReservationCanceled

BroadCasting

LoadingFailed

LiveFinished', example='Reserving'),
    clipsParam?: string(name='ClipsParam', description='The material parameter corresponding to the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified. For more information<props="china">, see [Create and use a regular template](https://help.aliyun.com/document_detail/328557.html) and [Create and use an advanced template](https://help.aliyun.com/document_detail/291418.html).'),
    coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='oss://example-bucket/example.jpg'),
    createSource?: string(name='CreateSource', description='The method for creating the online editing project. Valid values:

\\- OpenAPI

\\- AliyunConsole

\\- WebSDK

\\- LiveEditingOpenAPI

\\- LiveEditingConsole', example='OpenAPI'),
    createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2020-12-20T12:00:00Z'),
    description?: string(name='Description', description='The description of the online editing project.'),
    duration?: long(name='Duration', description='The total duration of the online editing project.', example='24.120000'),
    modifiedSource?: string(name='ModifiedSource', description='The method for editing the online editing project. Valid values:

\\- OpenAPI

\\- AliyunConsole

\\- WebSDK

\\- LiveEditingOpenAPI

\\- LiveEditingConsole', example='OpenAPI'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last modified.', example='2020-12-20T13:00:00Z'),
    projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fb2101bf24b2754cb318787dc****'),
    projectType?: string(name='ProjectType', description='The type of the editing project. Default value: EditingProject. Valid values:

\\- EditingProject: a regular editing project.

\\- LiveEditingProject: a live stream editing project.', example='EditingProject'),
    status?: string(name='Status', description='The status of the online editing project. Valid values:

\\- Draft

\\- Editing

\\- Producing

\\- Produced

\\- ProduceFailed

\\- Deleted', example='Editing'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
    templateType?: string(name='TemplateType', description='The template type of the online editing project. Valid values:

\\- Timeline

\\- VETemplate', example='Timeline'),
    timeline?: string(name='Timeline', description='The timeline of the online editing project.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****9b4d7cf14dc7b83b0e801cbe****"},{"MediaId":"****9b4d7cf14dc7b83b0e801cbe****"},{"MediaId":"****1656bca4474999c961a6d2a2****"}]}]}'),
    timelineConvertErrorMessage?: string(name='TimelineConvertErrorMessage', description='The error message returned if the project conversion failed. The error message displays the detailed information about the failure, and is returned only if the value of TimelineConvertStatus is ConvertFailed.', example='The StorageLocation must be in the same division(apiRegion) as ICE service access point.'),
    timelineConvertStatus?: string(name='TimelineConvertStatus', description='The project conversion status. Conversion of an API-style timeline into a frontend-style timeline is an asynchronous process and takes effect only if RequestSource:WebSDK is specified.

\\- Unconverted

\\- Converting

\\- Converted

\\- ConvertFailed', example='Converted'),
    title?: string(name='Title', description='The title of the online editing project.'),
  }(name='Project', description='The information about the online editing project.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model GetEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEditingProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetEditingProject  GetEditingProjectRequest
  * @return GetEditingProjectResponse
 */
async function getEditingProject(request: GetEditingProjectRequest): GetEditingProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetEditingProject', 'POST', '/', 'json', false, 'json', request);
}

model GetEditingProjectMaterialsRequest {
  regionId?: string(name='RegionId', position='Host'),
  projectId: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='*****fb2101cb318*****', position='Query'),
}

model GetEditingProjectMaterialsResponseBody = {
  liveMaterials?: [ 
    {
      appName?: string(name='AppName', description='The application name of the live stream.', example='testrecord'),
      domainName?: string(name='DomainName', description='The domain name of the live stream.', example='test.alivecdn.com'),
      liveUrl?: string(name='LiveUrl', description='The URL of the live stream.', example='rtmp://test.alivecdn.com/testrecord/teststream'),
      streamName?: string(name='StreamName', description='The name of the live stream.', example='testrecord'),
    }
  ](name='LiveMaterials', description='The materials associated with the live stream.'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
            duration?: string(name='Duration', description='The duration.', example='216.206667'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='540'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='960'),
          }(name='FileBasicInfo', description='The basic information of the file, such as the duration and size.'),
        }
      ](name='FileInfoList', description='The information about the file.'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.', example='video'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://sample-bucket.oss-cn-shanghai.aliyuncs.com/sample-corver.jpg?Expires=1628670610&OSSAccessKeyId=AK&Signature=signature'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-26T04:11:08Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-26T04:11:08Z'),
        description?: string(name='Description', description='The description of the media asset.', example='sample_description'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/file.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****64623a94eca8516569c8f*****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-26T04:11:08Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='null'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite of the media asset', example='null'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.', example='file.mp4'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.

Valid values:

*   TranscodeSuccess: transcoding completed.
*   TranscodeFailed: transcoding failed.
*   Init: initializing.
*   Transcoding: transcoding in progress.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information of the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****64623a94eca8516569c8fe*****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  projectId?: string(name='ProjectId', description='The project ID.', example='*****67ae06542b9b93e0d1c387*****'),
  projectMaterials?: [ string ](name='ProjectMaterials', description='The materials associated with the editing project. A live stream editing project will be associated with a regular editing project after the live streaming ends.', example='*****9b145c5cafc2e057304fcd*****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******89-C21D-4B78-AE24-3788B8******'),
}

model GetEditingProjectMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEditingProjectMaterialsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetEditingProjectMaterials  GetEditingProjectMaterialsRequest
  * @return GetEditingProjectMaterialsResponse
 */
async function getEditingProjectMaterials(request: GetEditingProjectMaterialsRequest): GetEditingProjectMaterialsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetEditingProjectMaterials', 'POST', '/', 'json', false, 'json', request);
}

model GetEventCallbackRequest {
  regionId?: string(name='RegionId', position='Host'),
}

model GetEventCallbackResponseBody = {
  authKey?: string(name='AuthKey', description='The authentication key. This parameter is returned only for HTTP callbacks.', example='TestKey001'),
  authSwitch?: string(name='AuthSwitch', description='Specifies whether callback authentication is enabled. This parameter is returned only for **HTTP** callbacks. Valid values:

*   **on**
*   **off**', example='on'),
  callbackQueueName?: string(name='CallbackQueueName', description='The name of the Simple Message Queue (SMQ) queue to which callback messages are sent.', example='ice-callback-queue'),
  callbackType?: string(name='CallbackType', description='The callback method. Valid values:

*   **HTTP**
*   **MNS**', example='HTTP'),
  callbackURL?: string(name='CallbackURL', description='The callback URL to which event notifications are sent.', example='http://xxx.yyy/callback'),
  eventTypeList?: string(name='EventTypeList', description='The type of the callback event. Multiple values are separated with commas (,). For more information about callback event types, see [Event notification content](https://help.aliyun.com/document_detail/441362.html).', example='ProduceMediaComplete,TranscodeComplete'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetEventCallbackResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEventCallbackResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetEventCallback  GetEventCallbackRequest
  * @return GetEventCallbackResponse
 */
async function getEventCallback(request: GetEventCallbackRequest): GetEventCallbackResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetEventCallback', 'POST', '/', 'json', false, 'json', request);
}

model GetLiveEditingIndexFileRequest {
  appName?: string(name='AppName', description='The application name of the live stream.', example='testrecord', position='Query'),
  domainName?: string(name='DomainName', description='The domain name of the live stream.', example='test.alivecdn.com', position='Query'),
  projectId?: string(name='ProjectId', description='The ID of the live stream editing project.', example='*****cb6307a4edea614d8b3f3c*****', position='Query'),
  streamName?: string(name='StreamName', description='The name of the live stream.', example='teststream', position='Query'),
}

model GetLiveEditingIndexFileResponseBody = {
  indexFile?: string(name='IndexFile', description='The URL of the index file.'),
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
}

model GetLiveEditingIndexFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveEditingIndexFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveEditingIndexFile  GetLiveEditingIndexFileRequest
  * @return GetLiveEditingIndexFileResponse
 */
async function getLiveEditingIndexFile(request: GetLiveEditingIndexFileRequest): GetLiveEditingIndexFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveEditingIndexFile', 'POST', '/', 'json', false, 'json', request);
}

model GetLiveEditingJobRequest {
  jobId?: string(name='JobId', description='The ID of the live editing job.', example='****d80e4e4044975745c14b****', position='Query'),
}

model GetLiveEditingJobResponseBody = {
  liveEditingJob?: {
    clips?: string(name='Clips', description='The clips.', example='[{\\"StartTime\\": \\" 2021-06-21T08:01:00Z\\",  \\"EndTime\\": \\" 2021-06-21T08:03:00Z\\" }]'),
    code?: string(name='Code', description='The response code. Note: Pay attention to this parameter if the job failed.', example='InvalidParameter'),
    completeTime?: string(name='CompleteTime', description='The time when the live editing job was completed. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:52Z'),
    creationTime?: string(name='CreationTime', description='The time when the live editing job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
    jobId?: string(name='JobId', description='The ID of the live editing job.', example='****cdb3e74639973036bc84****'),
    liveStreamConfig?: {
      appName?: string(name='AppName', description='The name of the application to which the live stream belongs.', example='app'),
      domainName?: string(name='DomainName', description='The domain name of the live stream.', example='domain.com'),
      streamName?: string(name='StreamName', description='The name of the live stream.', example='streamName'),
    }(name='LiveStreamConfig', description='The live editing configurations.'),
    mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****0cc6ba49eab379332c5b****'),
    mediaProduceConfig?: {
      mode?: string(name='Mode', description='The editing mode. Default value: Accurate.', example='Accurate'),
    }(name='MediaProduceConfig', description='The production configurations.'),
    mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example2.mp4'),
    message?: string(name='Message', description='The returned message. Note: Pay attention to this parameter if the job failed.', example='The specific parameter LiveStreamConfig is not valid.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the live editing job was last modified. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:49Z'),
    outputMediaConfig?: {
      bitrate?: long(name='Bitrate', description='The bitrate of the output file. Unit: Kbit/s. You can leave this parameter empty. The default value is the maximum bitrate of the input materials.', example='1000'),
      fileName?: string(name='FileName', description='If OutputMediaTarget is set to vod-media, this parameter indicates the file name of the output file. The value contains the file name extension but not the path.', example='test.mp4'),
      height?: int32(name='Height', description='The height of the output file. You can leave this parameter empty. The default value is the maximum height of the input materials.', example='480'),
      mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='https://testice-testbucket.oss-cn-shanghai.aliyuncs.com/test.mp4'),
      storageLocation?: string(name='StorageLocation', description='If OutputMediaTarget is set to vod-media, this parameter indicates the storage location of the media asset in ApsaraVideo VOD. The storage location is the path of the file in ApsaraVideo VOD, excluding the prefix http://. Example: outin-xxxxxx.oss-cn-shanghai.aliyuncs.com.', example='outin-xxxxxx.oss-cn-shanghai.aliyuncs.com'),
      vodTemplateGroupId?: string(name='VodTemplateGroupId', description='The ID of the VOD transcoding template group. If VOD transcoding is not required, set the value to VOD_NO_TRANSCODE.', example='VOD_NO_TRANSCODE'),
      width?: int32(name='Width', description='The width of the output file. You can leave this parameter empty. The default value is the maximum width of the input materials.', example='640'),
    }(name='OutputMediaConfig', description='The storage configurations of the output file.'),
    projectId?: string(name='ProjectId', description='The ID of the live editing project.', example='****fddd7748b58bf1d47e95****'),
    status?: string(name='Status', description='The state of the live editing job. Valid values: Init, Queuing, Processing, Success, and Failed.', example='Success'),
    userData?: string(name='UserData', description='The user-defined data.', example='{"key": "value\\"}'),
  }(name='LiveEditingJob', description='The information about the live editing job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model GetLiveEditingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveEditingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveEditingJob  GetLiveEditingJobRequest
  * @return GetLiveEditingJobResponse
 */
async function getLiveEditingJob(request: GetLiveEditingJobRequest): GetLiveEditingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveEditingJob', 'POST', '/', 'json', false, 'json', request);
}

model GetLiveRecordJobRequest {
  jobId: string(name='JobId', description='The ID of the recording job.

This parameter is required.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66', position='Query'),
}

model GetLiveRecordJobResponseBody = {
  recordJob?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T02:48:58Z'),
    jobId?: string(name='JobId', description='The ID of the recording job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
    name?: string(name='Name', description='The name of the recording job.'),
    notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify'),
    recordOutput?: {
      bucket?: string(name='Bucket', description='The bucket name.', example='imsbucket1'),
      endpoint?: string(name='Endpoint', description='The endpoint of the storage service.', example='oss-cn-shanghai.aliyuncs.com'),
      type?: string(name='Type', description='The type of the storage address.

Valid values:

*   vod
*   oss', example='oss'),
    }(name='RecordOutput', description='The storage address of the recording.'),
    status?: string(name='Status', description='The state of the recording job.

Valid values:

*   paused: The job is paused.
*   initial: The job is not started.
*   started: The job is in progress.', example='paused'),
    streamInput?: {
      type?: string(name='Type', description='The type of the live stream. The value can only be rtmp.', example='rtmp'),
      url?: string(name='Url', description='The URL of the live stream.', example='rtmp://example.com/app/stream'),
    }(name='StreamInput', description='The URL of the live stream.'),
    templateId?: string(name='TemplateId', description='The ID of the recording template.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
    templateName?: string(name='TemplateName', description='The name of the recording template.', example='test template'),
  }(name='RecordJob', description='The details of the recording job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='B57A046C-CE33-5FBB-B57A-D2B89ACF6907'),
}

model GetLiveRecordJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveRecordJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveRecordJob  GetLiveRecordJobRequest
  * @return GetLiveRecordJobResponse
 */
async function getLiveRecordJob(request: GetLiveRecordJobRequest): GetLiveRecordJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveRecordJob', 'GET', '/', 'json', false, 'json', request);
}

model GetLiveRecordTemplateRequest {
  jobId?: string(name='JobId', description='The ID of the recording job. You can specify the JobId parameter to retrieve the snapshot of the template used by the job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66', position='Query'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66', position='Query'),
}

model GetLiveRecordTemplateResponseBody = {
  recordTemplate?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
    lastModified?: string(name='LastModified', description='The time when the template was last modified.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
    name?: string(name='Name', description='The template name.', example='test template'),
    recordFormatList?: [ 
      {
        cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds. If you do not specify this parameter, the default value 6 hours is used.', example='7200'),
        format?: string(name='Format', description='The output file format.', example='m3u8'),
        ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording file that is stored in Object Storage Service (OSS).', example='record/{JobId}/{Sequence}{EscapedStartTime}{EscapedEndTime}'),
        sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds.', example='30'),
        sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
      }
    ](name='RecordFormatList', description='The list of recording formats.'),
    templateId?: string(name='TemplateId', description='The template ID.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
    type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
  }(name='RecordTemplate', description='The recording template.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C892855F-95DF-50D6-A28C-279ABDB76810'),
}

model GetLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveRecordTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveRecordTemplate  GetLiveRecordTemplateRequest
  * @return GetLiveRecordTemplateResponse
 */
async function getLiveRecordTemplate(request: GetLiveRecordTemplateRequest): GetLiveRecordTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveRecordTemplate', 'GET', '/', 'json', false, 'json', request);
}

model GetLiveSnapshotJobRequest {
  jobId: string(name='JobId', description='The job ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Query'),
}

model GetLiveSnapshotJobResponseBody = {
  callbackUrl?: string(name='CallbackUrl', description='The snapshot callback URL.', example='http://www.aliyun.com/snapshot/callback'),
  createTime?: string(name='CreateTime', description='The time when the file was created.', example='2022-02-02T22:22:22Z'),
  jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287782****'),
  jobName?: string(name='JobName', description='The name of the job.'),
  lastModified?: string(name='LastModified', description='The time when the file was last modified.', example='2022-02-02T22:22:22Z'),
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.', example='snapshot/{JobId}.jpg'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.', example='snapshot/{JobId}/{UnixTimestamp}.jpg'),
  snapshotOutput?: {
    bucket?: string(name='Bucket', description='The bucket of the output endpoint. If the storage type is set to oss, the OSS bucket is returned.', example='testbucket'),
    endpoint?: string(name='Endpoint', description='The output endpoint. If the storage type is set to oss, the Object Storage Service (OSS) domain name is returned.', example='oss-cn-shanghai.aliyuncs.com'),
    storageType?: string(name='StorageType', description='The storage type. The value can only be oss.', example='oss'),
  }(name='SnapshotOutput', description='The output information.'),
  status?: string(name='Status', description='The state of the job.

Valid values:

*   init: The job is not started.
*   paused: The job is paused.
*   started: The job is in progress.', example='started'),
  streamInput?: {
    type?: string(name='Type', description='The type of the input stream. The value can only be rtmp.', example='rtmp'),
    url?: string(name='Url', description='The URL of the input stream.', example='rtmp://www.aliyun.com/stream'),
  }(name='StreamInput', description='The input information.'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287666****'),
  templateName?: string(name='TemplateName', description='The name of the template.'),
  timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots.', example='5'),
}

model GetLiveSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveSnapshotJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveSnapshotJob  GetLiveSnapshotJobRequest
  * @return GetLiveSnapshotJobResponse
 */
async function getLiveSnapshotJob(request: GetLiveSnapshotJobRequest): GetLiveSnapshotJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveSnapshotJob', 'GET', '/', 'json', false, 'json', request);
}

model GetLiveSnapshotTemplateRequest {
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Query'),
}

model GetLiveSnapshotTemplateResponseBody = {
  createTime?: string(name='CreateTime', description='The time when the configuration was modified.', example='2022-02-02T22:22:22Z'),
  lastModified?: string(name='LastModified', description='The time when the template was created.', example='2022-02-02T22:22:22Z'),
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.', example='snapshot/{JobId}.jpg'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.', example='snapshot/{JobId}/{UnixTimestamp}.jpg'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287782****'),
  templateName?: string(name='TemplateName', description='The template name.'),
  timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots.', example='5'),
  type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
}

model GetLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveSnapshotTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveSnapshotTemplate  GetLiveSnapshotTemplateRequest
  * @return GetLiveSnapshotTemplateResponse
 */
async function getLiveSnapshotTemplate(request: GetLiveSnapshotTemplateRequest): GetLiveSnapshotTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveSnapshotTemplate', 'GET', '/', 'json', false, 'json', request);
}

model GetLiveTranscodeJobRequest {
  jobId: string(name='JobId', description='The ID of the transcoding job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetLiveTranscodeJobResponseBody = {
  job?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T02:48:58Z'),
    jobId?: string(name='JobId', description='The ID of the transcoding job.', example='****20b48fb04483915d4f2cd8ac****'),
    name?: string(name='Name', description='The name of the transcoding job.', example='task1'),
    outputStream?: {
      streamInfos?: [ 
        {
          outputUrl?: string(name='OutputUrl', description='The URL of the output stream.', example='rtmp://mydomain/app/mytranscode1'),
          type?: string(name='Type', description='The type of the output stream protocol. Only the RTMP protocol is supported.', example='rtmp'),
        }
      ](name='StreamInfos', description='The information about the output stream.'),
    }(name='OutputStream', description='The information about the output stream.'),
    startMode?: int32(name='StartMode', description='The start mode of the job.', example='0'),
    status?: int32(name='Status', description='The state of the job.

*   0: The job is not started.
*   1: The job is in progress.
*   2: The job is stopped.', example='1'),
    streamInput?: {
      inputUrl?: string(name='InputUrl', description='The URL of the input stream.', example='rtmp://mydomain/app/stream1'),
      type?: string(name='Type', description='The type of the input stream.', example='rtmp'),
    }(name='StreamInput', description='The information about the input stream.'),
    templateId?: string(name='TemplateId', description='The template ID.', example='b6491d5b3e514b7d895d14b5453ea119'),
    templateName?: string(name='TemplateName', description='The template name.', example='basic'),
    templateType?: string(name='TemplateType', description='The type of the template.', example='normal'),
  }(name='Job', description='The information about the transcoding job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model GetLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveTranscodeJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveTranscodeJob  GetLiveTranscodeJobRequest
  * @return GetLiveTranscodeJobResponse
 */
async function getLiveTranscodeJob(request: GetLiveTranscodeJobRequest): GetLiveTranscodeJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveTranscodeJob', 'POST', '/', 'json', false, 'json', request);
}

model GetLiveTranscodeTemplateRequest {
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287666****', position='Query'),
}

model GetLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  templateContent?: {
    category?: string(name='Category', description='The category of the template. Valid values:

*   system
*   customized', example='customized'),
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-25T06:15:14Z'),
    name?: string(name='Name', description='The name of the template.', example='my-template'),
    templateConfig?: {
      audioParams?: {
        bitrate?: string(name='Bitrate', description='The bitrate of the output audio.', example='1000'),
        channels?: string(name='Channels', description='The number of sound channels.', example='2'),
        codec?: string(name='Codec', description='The audio codec.', example='AAC'),
        profile?: string(name='Profile', description='The audio codec profile.', example='1'),
        samplerate?: string(name='Samplerate', description='The audio sampling rate.', example='44100'),
      }(name='AudioParams', description='The audio parameters.'),
      videoParams?: {
        bitrate?: string(name='Bitrate', description='The bitrate of the output video.', example='2500'),
        codec?: string(name='Codec', description='The encoding type.', example='H.264'),
        fps?: string(name='Fps', description='The frame rate of the output video.', example='30'),
        gop?: string(name='Gop', description='The group of pictures (GOP) of the output video.', example='1000'),
        height?: string(name='Height', description='The height of the output video.', example='720'),
        profile?: string(name='Profile', description='The encoding profile.', example='2'),
        width?: string(name='Width', description='The width of the output video.', example='1280'),
      }(name='VideoParams', description='The video parameters.'),
    }(name='TemplateConfig', description='The configuration of the template.'),
    templateId?: string(name='TemplateId', description='The template ID.', example='bcfa57950bc649b2abfb476ecd36ea4f'),
    type?: string(name='Type', description='The type of the template.', example='normal'),
  }(name='TemplateContent', description='The content of the template.'),
}

model GetLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveTranscodeTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveTranscodeTemplate  GetLiveTranscodeTemplateRequest
  * @return GetLiveTranscodeTemplateResponse
 */
async function getLiveTranscodeTemplate(request: GetLiveTranscodeTemplateRequest): GetLiveTranscodeTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveTranscodeTemplate', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  inputURL?: string(name='InputURL', description='The input URL of the media asset in another service. The URL must be registered in the IMS content library and bound to the ID of the media asset in IMS.

*   For a media asset from Object Storage Service (OSS), the URL may have one of the following formats:

http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4 or

oss://example-bucket/example.mp4. The second format indicates that the region in which the OSS bucket of the media asset resides is the same as the region in which OSS is activated.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset in IMS. If this parameter is left empty, the InputURL parameter must be specified.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  outputType?: string(name='OutputType', description='The type of the URL of the media asset to return in the response. Valid values:

*   oss (default): an OSS URL.
*   cdn: a CDN URL. A CDN URL is returned only if the media asset is imported from ApsaraVideo VOD and the relevant domain name is an accelerated domain name in ApsaraVideo VOD.', example='cdn', position='Query'),
  returnDetailedInfo?: string(name='ReturnDetailedInfo', description='Specifies whether to return detailed information for specific media asset attributes. Supported attributes: AiRoughData.StandardSmartTagJob, which specifies whether to return detailed tag information if a tagging job has been submitted for the media asset. Valid values for the attribute:

*   false (default): The job result is returned as a URL.
*   true: The job result is returned as text.', example='{"AiRoughData.StandardSmartTagJob": false}', position='Query'),
}

model GetMediaInfoResponseBody = {
  mediaInfo?: {
    aiRoughData?: {
      aiCategory?: string(name='AiCategory', description='The AI category. Valid values:

*   Life
*   Good-looking
*   Cute pets
*   News
*   Ads
*   Environmental resources
*   Automobile'),
      aiJobId?: string(name='AiJobId', description='The ID of the AI task.', example='****483915d4f2cd8ac20b48fb04****'),
      result?: string(name='Result', description='The analysis result.', example='https://sample-bucket.cn-shanghai.aliyuncs.com/result.json'),
      saveType?: string(name='SaveType', description='The storage type. This parameter indicates the library in which the analysis data is stored. Valid values:

*   TEXT: the text library.', example='TEXT'),
      standardSmartTagJob?: {
        aiJobId?: string(name='AiJobId', description='The ID of the AI task.', example='****483915d4f2cd8ac20b48fb04****'),
        resultUrl?: string(name='ResultUrl', description='The URL of the tagging result.', example='http://xx.oss-cn-shanghai.aliyuncs.com/result2.txt'),
        results?: [ 
          {
            data?: string(name='Data', description='The result data. The value is a JSON string. For information about the data structures of different data types<props="china">, see [Description of the Results parameter](https://help.aliyun.com/zh/ims/developer-reference/api-ice-2020-11-09-querysmarttagjob?spm=a2c4g.11186623.0.0.521d48b7KfapOL#api-detail-40).', example='{"autoChapters": [...]}'),
            type?: string(name='Type', description='The tagging type. Valid values:

*   NLP: natural language processing (NLP)-based tagging', example='NLP'),
          }
        ](name='Results', description='The recognized tags.'),
        status?: string(name='Status', description='The analysis status. Valid values:

*   Analyzing
*   AnalyzeSuccess
*   AnalyzeFailed', example='Analyzing'),
      }(name='StandardSmartTagJob', description='The information about the tagging job.'),
      status?: string(name='Status', description='The analysis status. Valid values:

*   Analyzing
*   AnalyzeSuccess
*   AnalyzeFailed
*   Saving
*   SaveSuccess
*   SaveFailed
*   Deleting
*   DeleteSuccess
*   DeleteFailed', example='Analyzing'),
    }(name='AiRoughData', description='The original AI analysis data.'),
    fileInfoList?: [ 
      {
        audioStreamInfoList?: [ 
          {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='127.794'),
            channelLayout?: string(name='ChannelLayout', description='The output layout of sound channels.', example='stereo'),
            channels?: string(name='Channels', description='The number of sound channels.', example='2'),
            codecLongName?: string(name='CodecLongName', description='The full name of the codec.', example='AAC (Advanced Audio Coding)'),
            codecName?: string(name='CodecName', description='The short name of the codec.', example='aac'),
            codecTag?: string(name='CodecTag', description='The tag of the codec.', example='0x6134706d'),
            codecTagString?: string(name='CodecTagString', description='The tag string of the codec.', example='mp4a'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the codec.', example='1/24000'),
            duration?: string(name='Duration', description='The duration.', example='16.200998'),
            fps?: string(name='Fps', description='The audio frame rate.', example='8'),
            index?: string(name='Index', description='The sequence number of the audio track.', example='1'),
            lang?: string(name='Lang', description='The language.', example='und'),
            numFrames?: string(name='NumFrames', description='The number of frames.', example='10'),
            profile?: string(name='Profile', description='The codec profile.', example='High'),
            sampleFmt?: string(name='SampleFmt', description='The sampling format.', example='fltp'),
            sampleRate?: string(name='SampleRate', description='The sampling rate.', example='44100'),
            startTime?: string(name='StartTime', description='The start time.', example='0.000000'),
            timebase?: string(name='Timebase', description='The time base.', example='1/44100'),
          }
        ](name='AudioStreamInfoList', description='The information about the audio tracks. A media asset may have multiple audio tracks.'),
        fileBasicInfo?: {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
          createTime?: string(name='CreateTime', description='The time when the file was created.', example='2020-12-26T04:11:08Z'),
          duration?: string(name='Duration', description='The duration.', example='216.206667'),
          fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
          fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
          fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
          fileType?: string(name='FileType', description='The file type.', example='source_file'),
          fileUrl?: string(name='FileUrl', description='The OSS URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
          formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
          height?: string(name='Height', description='The height.', example='540'),
          modifiedTime?: string(name='ModifiedTime', description='The time when the file was last modified.', example='2020-12-26T04:11:10Z'),
          region?: string(name='Region', description='The region in which the file is stored.', example='cn-shanghai'),
          width?: string(name='Width', description='The width.', example='960'),
        }(name='FileBasicInfo', description='The basic information about the file, including the duration and size.'),
        subtitleStreamInfoList?: [ 
          {
            codecLongName?: string(name='CodecLongName', description='The full name of the codec.', example='SubRip Text'),
            codecName?: string(name='CodecName', description='The short name of the codec.', example='srt'),
            codecTag?: string(name='CodecTag', description='The tag of the codec.', example='unicode'),
            codecTagString?: string(name='CodecTagString', description='The tag string of the codec.', example='unicode'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the codec.', example='29.97'),
            duration?: string(name='Duration', description='The duration.', example='1'),
            index?: string(name='Index', description='The sequence number of the subtitle track.', example='1'),
            lang?: string(name='Lang', description='The language.', example='und'),
            startTime?: string(name='StartTime', description='The start time.', example='0'),
            timebase?: string(name='Timebase', description='The time base.', example='30'),
          }
        ](name='SubtitleStreamInfoList', description='The information about the subtitle tracks. A media asset may have multiple subtitle tracks.'),
        videoStreamInfoList?: [ 
          {
            avgFPS?: string(name='AvgFPS', description='The average video frame rate.', example='24.0'),
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1001.594'),
            codecLongName?: string(name='CodecLongName', description='The full name of the codec.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
            codecName?: string(name='CodecName', description='The short name of the codec.', example='h264'),
            codecTag?: string(name='CodecTag', description='The tag of the codec.', example='0x0000'),
            codecTagString?: string(name='CodecTagString', description='The tag string of the codec.', example='[0][0][0][0]'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the codec.', example='1/48'),
            dar?: string(name='Dar', description='The display aspect ratio (DAR).', example='0:1'),
            duration?: string(name='Duration', description='The duration.', example='216.206706'),
            fps?: string(name='Fps', description='The video frame rate.', example='24.0'),
            hasBFrames?: string(name='HasBFrames', description='Indicates whether the video track contains bidirectional frames (B-frames).', example='2'),
            height?: string(name='Height', description='The height.', example='540'),
            index?: string(name='Index', description='The sequence number of the video track.', example='0'),
            lang?: string(name='Lang', description='The language.', example='und'),
            level?: string(name='Level', description='The codec level.', example='30'),
            nbFrames?: string(name='Nb_frames', description='The total number of frames.', example='5184'),
            numFrames?: string(name='NumFrames', description='The number of frames.', example='5184'),
            pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
            profile?: string(name='Profile', description='The codec profile.', example='High'),
            rotate?: string(name='Rotate', description='The rotation angle.', example='0'),
            sar?: string(name='Sar', description='The sample aspect ratio (SAR).', example='0:1'),
            startTime?: string(name='StartTime', description='The start time.', example='0.081706'),
            timebase?: string(name='Timebase', description='The time base.', example='1/12288'),
            width?: string(name='Width', description='The width.', example='960'),
          }
        ](name='VideoStreamInfoList', description='The information about the video tracks. A media asset may have multiple video tracks.'),
      }
    ](name='FileInfoList', description='The file information.'),
    mediaBasicInfo?: {
      biz?: string(name='Biz', description='The service to which the media asset belongs.', example='ICE'),
      businessType?: string(name='BusinessType', description='The business type.', example='general'),
      cateId?: long(name='CateId', description='The category ID.', example='3048'),
      cateName?: string(name='CateName', description='The category name.', example='cateName'),
      category?: string(name='Category', description='The category.'),
      coverURL?: string(name='CoverURL', description='The URL of the thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
      createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-26T04:11:08Z'),
      deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-26T04:11:15Z'),
      description?: string(name='Description', description='The content description.'),
      inputURL?: string(name='InputURL', description='The input URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
      mediaTags?: string(name='MediaTags', description='The tags.'),
      mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-26T04:11:10Z'),
      referenceId?: string(name='ReferenceId', description='The custom ID. The ID can be 6 to 64 characters in length and can contain only letters, digits, hyphens (-), and underscores (_). The ID is unique among users.', example='123-1234'),
      snapshots?: string(name='Snapshots', description='The snapshots.', example='[
    "http://example-bucket.oss-cn-shanghai.aliyuncs.com/snapshot-00001.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>",
    "http://example-bucket.oss-cn-shanghai.aliyuncs.com/snapshot-00002.jpg?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>",
    "http://example-bucket.oss-cn-shanghai.aliyuncs.com/snapshot-00003.jpg?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>"
]'),
      source?: string(name='Source', description='The source.', example='oss'),
      spriteImages?: string(name='SpriteImages', description='The sprite.', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
      status?: string(name='Status', description='The resource status.', example='Normal'),
      title?: string(name='Title', description='The title.'),
      uploadSource?: string(name='UploadSource', description='The upload source of the media asset.', example='general'),
      userData?: string(name='UserData', description='The user data.', example='userDataTest'),
    }(name='MediaBasicInfo', description='The basic information about the media asset.'),
    mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  }(name='MediaInfo', description='The information about the media asset.'),
  requestId?: string(name='RequestId', description='The request ID.', example='2FDE2411-DB8D-4A9A-875B-275798F14A5E'),
}

model GetMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaInfoResponseBody(name='body'),
}

/**
  * @description If the MediaId parameter is specified, the MediaId parameter is preferentially used for the query. If the MediaId parameter is left empty, the InputURL parameter must be specified.
  * @param request  the request parameters of GetMediaInfo  GetMediaInfoRequest
  * @return GetMediaInfoResponse
 */
async function getMediaInfo(request: GetMediaInfoRequest): GetMediaInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaInfo', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaInfoJobRequest {
  jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8', position='Query'),
}

model GetMediaInfoJobResponseBody = {
  mediaInfoJob?: {
    async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
    input?: {
      media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    mediaInfoProperty?: {
      audioStreamInfoList?: [ 
        {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
          channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
          codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
          codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
          codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
          codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
          duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
          index?: string(name='Index', description='The sequence number of the stream.', example='1'),
          lang?: string(name='Lang', description='The language of the stream.', example='us'),
          sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
          sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
          startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
          timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
        }
      ](name='AudioStreamInfoList', description='The information about the audio stream.'),
      fileBasicInfo?: {
        bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
        duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
        fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
        fileSize?: string(name='FileSize', description='The file size.', example='31737'),
        fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
        fileType?: string(name='FileType', description='The file type.', example='source_file'),
        fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
        formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
        height?: string(name='Height', description='The height of the output video.', example='478'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='e520090207114cc7a392d44f0b211574'),
        region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
        width?: string(name='Width', description='The width of the output video.', example='848'),
      }(name='FileBasicInfo', description='The basic file information.'),
      videoStreamInfoList?: [ 
        {
          avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
          bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
          codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
          codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
          codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
          codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
          codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
          dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          fps?: string(name='Fps', description='The frame rate.', example='25.0'),
          hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
          height?: string(name='Height', description='The height of the output video.', example='478'),
          index?: string(name='Index', description='The sequence number of the stream.', example='0'),
          lang?: string(name='Lang', description='The language of the stream.', example='zh'),
          level?: string(name='Level', description='The codec level.', example='31'),
          numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
          pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
          profile?: string(name='Profile', description='The encoder profile.', example='High'),
          rotate?: string(name='Rotate', description='The rotation angle of the video image.', example='0'),
          sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
          startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
          timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
          width?: string(name='Width', description='The width of the output video.', example='848'),
        }
      ](name='VideoStreamInfoList', description='The information about the video stream.'),
    }(name='MediaInfoProperty', description='The details of the media information.'),
    name?: string(name='Name', description='The job name.', example='job-name'),
    requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling information.'),
    status?: string(name='Status', description='The state of the job. Valid values: Init (the job is submitted), Success (the job is successful), and Fail (the job failed).', example='Init'),
    submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='MediaInfoJob', description='MediaInfoJobDTO'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model GetMediaInfoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaInfoJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetMediaInfoJob  GetMediaInfoJobRequest
  * @return GetMediaInfoJobResponse
 */
async function getMediaInfoJob(request: GetMediaInfoJobRequest): GetMediaInfoJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaInfoJob', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaMarksRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The mark ID. You can specify multiple mark IDs separated with commas (,).', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60', position='Query'),
}

model GetMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaMarks?: string(name='MediaMarks', description='The queried marks.

*   The value is in the JSONArray format.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaMarksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetMediaMarks  GetMediaMarksRequest
  * @return GetMediaMarksResponse
 */
async function getMediaMarks(request: GetMediaMarksRequest): GetMediaMarksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaMarks', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaProducingJobRequest {
  jobId?: string(name='JobId', description='The ID of the media editing and production job.', example='****cdb3e74639973036bc84****', position='Query'),
}

model GetMediaProducingJobResponseBody = {
  mediaProducingJob?: {
    clipsParam?: string(name='ClipsParam', description='The template parameters of the media editing and production job.', example='{"VideoArray":["****05512043f49f697f7425****","****05512043f49f697f7425****","****05512043f49f697f7425****"]}'),
    code?: string(name='Code', description='The response code

Note: Pay attention to this parameter if the job failed.', example='ExceededMaximumValue'),
    completeTime?: string(name='CompleteTime', description='The time when the media editing and production job was complete.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:52Z'),
    createTime?: string(name='CreateTime', description='The time when the media editing and production job was created.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
    duration?: float(name='Duration', description='The duration of the output file.

Note: This parameter has a value if the job is successful and the output file is an audio or video file.', example='30.500000'),
    jobId?: string(name='JobId', description='The ID of the media editing and production job.', example='****cdb3e74639973036bc84****'),
    mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****0cc6ba49eab379332c5b****'),
    mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example2.mp4'),
    message?: string(name='Message', description='The returned message.

Note: Pay attention to this parameter if the job failed.', example='The specified "Width_Height" has exceeded maximum value.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the media editing and production job was last modified.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:49Z'),
    progress?: int32(name='Progress'),
    projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fddd7748b58bf1d47e95****'),
    status?: string(name='Status', description='The state of the media editing and production job. Valid values:

Init

Queuing

Processing

Success

Failed', example='Failed'),
    subJobMaterials?: string(name='SubJobMaterials', description='The materials of the media editing and production job if the job is a subjob of a quick video production job, including the broadcast text and title.', example='{"Title": "Title", "SpeechText": "Broadcast text of a quick video production job"}'),
    templateId?: string(name='TemplateId', description='The ID of the template used by the media editing and production job.', example='****6e76134d739cc3e85d3e****'),
    timeline?: string(name='Timeline', description='The timeline of the media editing and production job.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
    userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"NotifyAddress":"http://xx.xx.xxx","Key":"Valuexxx"}'),
    vodMediaId?: string(name='VodMediaId', description='The media asset ID of the output file in ApsaraVideo VOD if the output file is stored in ApsaraVideo VOD.', example='****332c5b0cc6ba49eab379****'),
  }(name='MediaProducingJob', description='The information about the online editing project.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****83B7-7F87-4792-BFE9-63CD2137****'),
}

model GetMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaProducingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetMediaProducingJob  GetMediaProducingJobRequest
  * @return GetMediaProducingJobResponse
 */
async function getMediaProducingJob(request: GetMediaProducingJobRequest): GetMediaProducingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaProducingJob', 'GET', '/', 'json', false, 'json', request);
}

model GetPackageJobRequest {
  jobId: string(name='JobId', description='The job ID. You can obtain the job ID from the response parameters of the [SubmitPackageJob](https://help.aliyun.com/document_detail/461964.html) operation.

This parameter is required.', example='ab4802364a2e49208c99efab82dfa8e8', position='Query'),
}

model GetPackageJobResponseBody = {
  packageJob?: {
    code?: string(name='Code', description='The error code returned if the job fails.', example='InvalidParameter'),
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:34:05Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:44:05Z'),
    inputs?: [ 
      {
        input?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
        }(name='Input', description='The information about the input stream file.'),
      }
    ](name='Inputs', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    message?: string(name='Message', description='The error message that is returned.', example='Resource content bad.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:44:05Z'),
    name?: string(name='Name', description='The name of the job.', example='job-name'),
    output?: {
      media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.m3u8'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
    }(name='Output', description='The output of the job.'),
    outputUrl?: string(name='OutputUrl', description='The URL of the output file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/output.m3u8'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='36f3fee40aa047c0b067d0fb85edc12b'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='6'),
    status?: string(name='Status', description='The state of the job.', example='Init'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:34:05Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
    userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}'),
  }(name='PackageJob', description='The information about the packaging job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model GetPackageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPackageJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetPackageJob  GetPackageJobRequest
  * @return GetPackageJobResponse
 */
async function getPackageJob(request: GetPackageJobRequest): GetPackageJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPackageJob', 'POST', '/', 'json', false, 'json', request);
}

model GetPipelineRequest {
  pipelineId: string(name='PipelineId', description='The ID of the MPS queue.

This parameter is required.', example='****96e8864746a0b6f3****', position='Query'),
}

model GetPipelineResponseBody = {
  pipeline?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
    name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.', example='****20b48fb04483915d4f2cd8ac****'),
    priority?: int32(name='Priority', description='The priority of the MPS queue. Valid values: 1 to 10.', example='6'),
    speed?: string(name='Speed', description='The type of the MPS queue.

Valid values:

*   Standard: standard MPS queue.
*   Boost: MPS queue with transcoding speed boosted.
*   NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.', example='Standard'),
    status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Active'),
  }(name='Pipeline', description='The information about the MPS queue.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetPipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPipelineResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetPipeline  GetPipelineRequest
  * @return GetPipelineResponse
 */
async function getPipeline(request: GetPipelineRequest): GetPipelineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPipeline', 'POST', '/', 'json', false, 'json', request);
}

model GetPlayInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  inputURL?: string(name='InputURL', description='The input URL that you specified for the media asset when you registered the media asset. For more information, see [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html).

>  You must specify at least one of the MediaId and InputURL parameters.', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.

>  You must specify at least one of the MediaId and InputURL parameters.', example='86434e152b7d4f20be480574439fe***', position='Query'),
}

model GetPlayInfoResponseBody = {
  mediaBase?: {
    cateId?: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of the CateId parameter returned by the AddCategory operation that you called to create a category.
*   View the value of the CateId parameter returned by the GetCategories operation that you called to query a category.', example='4220'),
    coverURL?: string(name='CoverURL', description='The URL of the thumbnail.', example='https://***.oss-cn-shanghai.aliyuncs.com/cover/281c64d6-b5fb-4c57-97cd-84da56a8b151_large_cover_url.jpg'),
    creationTime?: string(name='CreationTime', description='The time when the media asset was created.', example='2021-09-22T10:07:31+08:00'),
    description?: string(name='Description', description='The content description.', example='desc'),
    mediaId?: string(name='MediaId', description='The ID of the media asset.', example='2eea77a61c7b4ddd95bec34a6f65b***'),
    mediaTags?: string(name='MediaTags', description='The tags.

*   Up to 16 tags are supported.
*   Multiple tags are separated by commas (,).
*   Each tag can be up to 32 bytes in length.
*   The value is encoded in UTF-8.', example='test,ccc'),
    mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

video audio', example='video'),
    status?: string(name='Status', description='The resource status. Valid values:

Init: the initial state, which indicates that the source file is not ready.

Preparing: The source file is being prepared. For example, the file is being uploaded or edited.

PrepareFail: The source file failed to be prepared. For example, the information of the source file failed to be obtained.

Normal: The source file is ready.', example='Normal'),
    title?: string(name='Title', description='The title.', example='testTitle'),
  }(name='MediaBase', description='The information about the media asset.'),
  playInfoList?: [ 
    {
      bitDepth?: int32(name='BitDepth', description='The color depth.', example='8'),
      bitrate?: string(name='Bitrate', description='The bitrate of the media stream. Unit: Kbit/s.', example='20'),
      creationTime?: string(name='CreationTime', description='The time when the media stream was created. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2022-05-10T02:28:49Z'),
      definition?: string(name='Definition', description='The quality of the media stream. Valid values:

*   **FD**: low definition
*   **LD**: standard definition
*   **SD**: high definition
*   **HD**: ultra-high definition
*   **OD**: original definition
*   **2K**
*   **4K**
*   **SQ**: standard sound quality
*   **HQ**: high sound quality
*   **AUTO**: adaptive bitrate', example='HD'),
      duration?: string(name='Duration', description='The duration of the media stream. Unit: seconds.', example='9.0464'),
      encrypt?: long(name='Encrypt', description='Indicates whether the media stream is encrypted. Valid values:

*   **0**: The media stream is not encrypted.
*   **1**: The media stream is encrypted.', example='0'),
      encryptType?: string(name='EncryptType', description='The encryption type of the media stream. Valid values:

*   **AliyunVoDEncryption**: Alibaba Cloud proprietary cryptography
*   **HLSEncryption**: HTTP Live Streaming (HLS) encryption

>  If the encryption type is AliyunVoDEncryption, only ApsaraVideo Player SDK can be used to play videos.', example='AliyunVoDEncryption'),
      fileURL?: string(name='FileURL', description='The OSS URL of the file.', example='http://outin-***.oss-cn-shanghai.aliyuncs.com/sv/43a68ee9-181809b6aba/43a68ee9-181809b6aba.mpeg'),
      format?: string(name='Format', description='The format of the media stream.

*   If the media asset is a video file, the valid values are **mp4** and **m3u8**.
*   If the media asset is an audio-only file, the value is **mp3**.', example='mp4'),
      fps?: string(name='Fps', description='The frame rate of the media stream. Unit: frames per second (FPS).', example='25'),
      HDRType?: string(name='HDRType', description='The high dynamic range (HDR) type of the media stream. Valid values:

*   HDR
*   HDR10
*   HLG
*   DolbyVision
*   HDRVivid
*   SDR+', example='HDR'),
      height?: long(name='Height', description='The height of the media stream. Unit: pixels.', example='1080'),
      jobId?: string(name='JobId', description='The task ID.', example='36c9d38e70bf43ed9f7f8f48d6356***'),
      modificationTime?: string(name='ModificationTime', description='The time when the media stream was updated. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2022-05-13T11:39:41.714+08:00'),
      narrowBandType?: string(name='NarrowBandType', description='The type of Narrowband HD™ transcoding. Valid values:

*   **0**: standard transcoding
*   **1.0**: Narrowband HD™ 1.0 transcoding
*   **2.0**: Narrowband HD™ 2.0 transcoding

This parameter is returned only when a definition that is available in the built-in Narrowband HD™ 1.0 transcoding template is specified. For more information, see the [Definition parameter in TranscodeTemplate](https://help.aliyun.com/document_detail/52839.html) table.', example='0'),
      playURL?: string(name='PlayURL', description='The playback URL of the media stream.', example='https://***.aliyuncdn.com/sv/756bee1-17f980f0945/756bee1-17f980f0945.mp4'),
      size?: long(name='Size', description='The size of the media stream. Unit: bytes.', example='418112'),
      status?: string(name='Status', description='The status of the media stream. Valid values:

*   **Normal**
*   **Invisible**', example='Normal'),
      streamTags?: string(name='StreamTags', description='The tags of the media stream, which are used to identify the transcoding type.', example='"{\\"ims.audioServiceType\\": \\"AudioEnhancement\\"}"'),
      streamType?: string(name='StreamType', description='The type of the media stream. If the media stream is a video stream, the value is **video**. If the media stream is an audio-only stream, the value is **audio**.', example='video'),
      transTemplateType?: string(name='TransTemplateType', description='The type of the transcoding template. Valid values:

*   Normal: standard transcoding
*   AudioTranscode: audio transcoding
*   Remux: container format conversion
*   NarrowBandV1: Narrowband HD™ 1.0
*   NarrowBandV2: Narrowband HD™ 2.0
*   UHD: audio and video enhancement (ultra-high definition)', example='Normal'),
      watermarkId?: string(name='WatermarkId', description='The ID of the watermark that is associated with the media stream.', example='5bed88672b1e2520ead228935ed51***'),
      width?: long(name='Width', description='The width of the media stream. Unit: pixels.', example='1024'),
    }
  ](name='PlayInfoList', description='The information about the audio or video stream.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetPlayInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPlayInfoResponseBody(name='body'),
}

/**
  * @description You use the ID of a video or audio file to query the playback URL of the file. Then, you can use the playback URL to play the audio or video in ApsaraVideo Player SDK (for URL-based playback) or a third-party player.
  * @param request  the request parameters of GetPlayInfo  GetPlayInfoRequest
  * @return GetPlayInfoResponse
 */
async function getPlayInfo(request: GetPlayInfoRequest): GetPlayInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPlayInfo', 'POST', '/', 'json', false, 'json', request);
}

model GetPublicMediaInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId?: string(name='MediaId', example='icepublic-****14e501538aeef0a3140176f6****', position='Query'),
}

model GetPublicMediaInfoResponseBody = {
  mediaInfo?: {
    dynamicMetaData?: {
      data?: string(name='Data', example='{"AuditionUrl": "http://example-bucket.cdn.domain.com/example.mp4", "AuditionCount": 3}'),
      type?: string(name='Type', example='system'),
    }(name='DynamicMetaData'),
    fileInfoList?: [ 
      {
        audioStreamInfoList?: [ 
          {
            bitrate?: string(name='Bitrate', example='192.0'),
            channelLayout?: string(name='ChannelLayout', example='stereo'),
            channels?: string(name='Channels', example='2'),
            codecLongName?: string(name='CodecLongName', example='AAC (Advanced Audio Coding)'),
            codecName?: string(name='CodecName', example='aac'),
            codecTag?: string(name='CodecTag', example='0x6134706d'),
            codecTagString?: string(name='CodecTagString', example='mp4a'),
            codecTimeBase?: string(name='CodecTimeBase', example='1/44100'),
            duration?: string(name='Duration', example='16.2'),
            fps?: string(name='Fps', example='10'),
            index?: string(name='Index', example='1'),
            lang?: string(name='Lang', example='und'),
            numFrames?: string(name='NumFrames', example='162'),
            profile?: string(name='Profile', example='High'),
            sampleFmt?: string(name='SampleFmt', example='fltp'),
            sampleRate?: string(name='SampleRate', example='44100'),
            startTime?: string(name='StartTime', example='0.000000'),
            timebase?: string(name='Timebase', example='1/44100'),
          }
        ](name='AudioStreamInfoList'),
        fileBasicInfo?: {
          bitrate?: string(name='Bitrate', example='192.0'),
          duration?: string(name='Duration', example='16.2'),
          fileName?: string(name='FileName', example='example.mp4'),
          fileSize?: string(name='FileSize', example='27007'),
          fileStatus?: string(name='FileStatus', example='Normal'),
          fileType?: string(name='FileType', example='source_file'),
          fileUrl?: string(name='FileUrl', example='http://example-bucket.cdn.domain.com/example.mp4'),
          formatName?: string(name='FormatName', example='mp4'),
          height?: string(name='Height', example='0'),
          region?: string(name='Region', example='cn-shanghai'),
          width?: string(name='Width', example='0'),
        }(name='FileBasicInfo'),
        subtitleStreamInfoList?: [ 
          {
            codecLongName?: string(name='CodecLongName', example='SubRip Text'),
            codecName?: string(name='CodecName', example='srt'),
            codecTag?: string(name='CodecTag', example='unicode'),
            codecTagString?: string(name='CodecTagString', example='unicode'),
            codecTimeBase?: string(name='CodecTimeBase', example='29.97'),
            duration?: string(name='Duration', example='1'),
            index?: string(name='Index', example='1'),
            lang?: string(name='Lang', example='und'),
            startTime?: string(name='StartTime', example='0'),
            timebase?: string(name='Timebase', example='30'),
          }
        ](name='SubtitleStreamInfoList'),
        videoStreamInfoList?: [ 
          {
            avgFPS?: string(name='AvgFPS', example='24.0'),
            bitrate?: string(name='Bitrate', example='1001.594'),
            codecLongName?: string(name='CodecLongName', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
            codecName?: string(name='CodecName', example='h264'),
            codecTag?: string(name='CodecTag', example='0x0000'),
            codecTagString?: string(name='CodecTagString', example='[0][0][0][0]'),
            codecTimeBase?: string(name='CodecTimeBase', example='1/48'),
            dar?: string(name='Dar', example='0:1'),
            duration?: string(name='Duration', example='216.206706'),
            fps?: string(name='Fps', example='24.0'),
            hasBFrames?: string(name='HasBFrames', example='2'),
            height?: string(name='Height', example='540'),
            index?: string(name='Index', example='0'),
            lang?: string(name='Lang', example='und'),
            level?: string(name='Level', example='30'),
            nbFrames?: string(name='Nb_frames', example='5184'),
            numFrames?: string(name='NumFrames', example='5184'),
            pixFmt?: string(name='PixFmt', example='yuv420p'),
            profile?: string(name='Profile', example='High'),
            rotate?: string(name='Rotate', example='0'),
            sar?: string(name='Sar', example='0:1'),
            startTime?: string(name='StartTime', example='0.081706'),
            timebase?: string(name='Timebase', example='1/12288'),
            width?: string(name='Width', example='960'),
          }
        ](name='VideoStreamInfoList'),
      }
    ](name='FileInfoList', description='FileInfos'),
    mediaBasicInfo?: {
      businessType?: string(name='BusinessType', example='general'),
      category?: string(name='Category', example='category'),
      coverURL?: string(name='CoverURL', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
      createTime?: string(name='CreateTime', example='2020-12-26T04:11:08Z'),
      deletedTime?: string(name='DeletedTime', example='2020-12-26T04:11:15Z'),
      description?: string(name='Description', example='description'),
      mediaId?: string(name='MediaId', description='MediaId', example='icepublic-****14e501538aeef0a3140176f6****'),
      mediaTags?: string(name='MediaTags'),
      mediaType?: string(name='MediaType', example='video'),
      modifiedTime?: string(name='ModifiedTime', example='2020-12-26T04:11:10Z'),
      source?: string(name='Source', example='oss'),
      spriteImages?: string(name='SpriteImages', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
      status?: string(name='Status', example='Normal'),
      title?: string(name='Title', example='title'),
      userData?: string(name='UserData', example='{"key":"value"}'),
    }(name='MediaBasicInfo', description='BasicInfo'),
    mediaId?: string(name='MediaId', example='icepublic-****14e501538aeef0a3140176f6****'),
  }(name='MediaInfo'),
  requestId?: string(name='RequestId', description='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetPublicMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPublicMediaInfoResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetPublicMediaInfo  GetPublicMediaInfoRequest
  * @return GetPublicMediaInfoResponse
 */
async function getPublicMediaInfo(request: GetPublicMediaInfoRequest): GetPublicMediaInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPublicMediaInfo', 'POST', '/', 'json', false, 'json', request);
}

model GetSmartHandleJobRequest {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetSmartHandleJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  jobResult?: {
    aiResult?: string(name='AiResult', description='The AI analysis result.', example='Intelligent segmentation or tagging information'),
    mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
    usage?: string(name='Usage', description='The token usage. This parameter is returned only for keyword-based text generation jobs.', example='{"total_tokens":100}'),
  }(name='JobResult', description='The job results.'),
  output?: string(name='Output', description='The job results.', example='{}'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  smartJobInfo?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2020-12-26T04:11:10Z'),
    description?: string(name='Description', description='The job description.', example='测试描述'),
    inputConfig?: {
      inputFile?: string(name='InputFile', description='The OSS URL or the ID of the material in the media asset library.', example='oss://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4 或 ******11-DB8D-4A9A-875B-275798******'),
    }(name='InputConfig', description='The input configurations.'),
    jobType?: string(name='JobType', description='The job type.', example='ASR'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2020-12-26T04:11:10Z'),
    outputConfig?: {
      bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
      object?: string(name='Object', description='The OSS object.', example='test-object'),
    }(name='OutputConfig', description='The output configurations.'),
    title?: string(name='Title', description='The job title.', example='测试标题'),
    userId?: string(name='UserId', description='The user ID.', example='1974526429******'),
  }(name='SmartJobInfo', description='The information about the intelligent job.'),
  state?: string(name='State', description='The job state.

Valid values:

*   Finished
*   Failed
*   Executing
*   Created', example='Finished'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"user":"data"}'),
}

model GetSmartHandleJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSmartHandleJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetSmartHandleJob  GetSmartHandleJobRequest
  * @return GetSmartHandleJobResponse
 */
async function getSmartHandleJob(request: GetSmartHandleJobRequest): GetSmartHandleJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSmartHandleJob', 'POST', '/', 'json', false, 'json', request);
}

model GetSnapshotJobRequest {
  jobId: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****d80e4e4044975745c14b****', position='Query'),
}

model GetSnapshotJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  snapshotJob?: {
    async?: boolean(name='Async', description='Indicates whether the snapshots were captured in asynchronous mode. Default value: true.', example='true'),
    code?: string(name='Code', description='Error codes', example='ResourceNotFound'),
    count?: int32(name='Count', description='The number of snapshots.', example='8'),
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
    input?: {
      media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://test-bucket/object.mp4'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='object.mp4'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
    message?: string(name='Message', description='The error message that is returned.', example='The specified resource for "Pipeline" could not be found.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
    name?: string(name='Name', description='The name of the job.'),
    output?: {
      media?: string(name='Media', description='The output file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS. If multiple static snapshots were captured, the object must contain the "{Count}" placeholder. In the case of a sprite, the object must contain the "{TileCount}" placeholder. The suffix of the WebVTT snapshot objects must be ".vtt".', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/output-{Count}.jpg'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='output-{Count}.jpg'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.', example='OSS'),
    }(name='Output', description='The output of the job.'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****d80e4e4044975745c14b****'),
    status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
    templateConfig?: string(name='TemplateConfig', description='The snapshot template configuration.', example='{"Type":"Normal","FrameType":"normal","Time":0,"Count":10}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****d80e4e4044975745c14b****'),
    triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
    type?: string(name='Type', description='Snapshot types

Valid values:

*   WebVtt
*   Sprite
*   Normal', example='Sprite'),
    userData?: string(name='UserData', description='The user-defined parameters.', example='{"test parameter": "test value"}'),
  }(name='SnapshotJob', description='The information about the snapshot job.'),
}

model GetSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSnapshotJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetSnapshotJob  GetSnapshotJobRequest
  * @return GetSnapshotJobResponse
 */
async function getSnapshotJob(request: GetSnapshotJobRequest): GetSnapshotJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSnapshotJob', 'POST', '/', 'json', false, 'json', request);
}

model GetSnapshotUrlsRequest {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values: Asc and Desc.

*
*', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 30. Default value: 10.', example='10', position='Query'),
  timeout?: long(name='Timeout', description='The authentication timeout period. Unit: seconds Default value: 3600. Maximum value: 129600 (36 hours).', example='3600', position='Query'),
}

model GetSnapshotUrlsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  snapshotUrls?: [ string ](name='SnapshotUrls', description='The list of snapshot URLs.'),
  total?: int32(name='Total', description='The total number of snapshots.', example='30'),
  webVTTUrl?: string(name='WebVTTUrl', description='The URL of the WebVTT file.', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/ouoput.vtt'),
}

model GetSnapshotUrlsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSnapshotUrlsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetSnapshotUrls  GetSnapshotUrlsRequest
  * @return GetSnapshotUrlsResponse
 */
async function getSnapshotUrls(request: GetSnapshotUrlsRequest): GetSnapshotUrlsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSnapshotUrls', 'POST', '/', 'json', false, 'json', request);
}

model GetStorageListRequest {
  regionId?: string(name='RegionId', position='Host'),
  appId?: string(name='AppId', example='app-****', position='Query'),
  status?: string(name='Status', example='Normal', position='Query'),
  storageType?: string(name='StorageType', example='vod_oss_bucket', position='Query'),
}

model GetStorageListResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='******73-8B78-5D86-A50C-49B96C******'),
  storageInfoList?: [ 
    {
      appId?: string(name='AppId', example='app-****'),
      creationTime?: string(name='CreationTime', example='2024-06-06T01:55:07Z'),
      defaultStorage?: boolean(name='DefaultStorage', example='true'),
      editingTempFileStorage?: boolean(name='EditingTempFileStorage', example='false'),
      modifiedTime?: string(name='ModifiedTime', example='2024-06-06T03:07:07Z'),
      path?: string(name='Path', example='your-path/'),
      status?: string(name='Status', example='Normal'),
      storageLocation?: string(name='StorageLocation', example='your-bucket'),
      storageType?: string(name='StorageType', example='vod_oss_bucket'),
    }
  ](name='StorageInfoList'),
}

model GetStorageListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetStorageListResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetStorageList  GetStorageListRequest
  * @return GetStorageListResponse
 */
async function getStorageList(request: GetStorageListRequest): GetStorageListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetStorageList', 'POST', '/', 'json', false, 'json', request);
}

model GetSystemTemplateRequest {
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='S00000001-100060', position='Query'),
}

model GetSystemTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  systemTemplate?: {
    status?: string(name='Status', description='The template state.', example='Normal'),
    subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='1'),
    subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='Normal'),
    templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Container":{"Format":"m3u8"},"TransConfig":{"TransMode":"onepass"},"Video":{"Codec":"H.264","Maxrate":8000,"Preset":"medium","PixFmt":"yuv420p","Width":2048,"Bitrate":3500},"Audio":{"Codec":"aac","Bitrate":160,"Samplerate":44100,"Channels":2}}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='S00000001-100060'),
    templateName?: string(name='TemplateName', description='The template name.', example='M3U8-2K'),
    type?: int32(name='Type', description='The type ID of the template.', example='1'),
    typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
  }(name='SystemTemplate', description='The template information.'),
}

model GetSystemTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSystemTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetSystemTemplate  GetSystemTemplateRequest
  * @return GetSystemTemplateResponse
 */
async function getSystemTemplate(request: GetSystemTemplateRequest): GetSystemTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSystemTemplate', 'POST', '/', 'json', false, 'json', request);
}

model GetTemplateRequest {
  relatedMediaidFlag?: string(name='RelatedMediaidFlag', description='Specifies whether to return the information about the associated materials. Default value: 0. Valid values: 0 and 1. A value of 1 specifies that the information about the associated materials is returned. This parameter is valid only for regular templates.', example='0', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  template?: {
    clipsParam?: string(name='ClipsParam', description='The clip parameters for submitting a video production job. You can replace mediaId and text with real values to submit a job. References:

*   [Create and use a regular template](https://help.aliyun.com/document_detail/328557.html)
*   [Create and use advanced templates](https://help.aliyun.com/document_detail/291418.html)', example='{"Media1":"mediaId","Text1":"text"}'),
    config?: string(name='Config', description='The template configurations.

*   For more information about the configurations of a regular template, see [Config object of a regular template](https://help.aliyun.com/document_detail/277430.html).
*   For more information about the configurations of an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/291418.html#title-3tf-skt-eoi).', example='参考Timeline模板配置详解'),
    coverURL?: string(name='CoverURL', description='The thumbnail URL.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
    createSource?: string(name='CreateSource', description='The source from which the template was created. Valid values:

*   AliyunConsole
*   OpenAPI
*   WebSDK', example='OpenAPI'),
    creationTime?: string(name='CreationTime', description='The time when the template was created.', example='2020-12-26T04:11:10Z'),
    modifiedSource?: string(name='ModifiedSource', description='The source from which the template was modified. Valid values:

*   AliyunConsole
*   OpenAPI
*   WebSDK', example='OpenAPI'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2020-12-26T04:11:10Z'),
    name?: string(name='Name', description='The template name.', example='视频添加水印模板'),
    previewMedia?: string(name='PreviewMedia', description='The preview media asset.', example='****20b48fb04483915d4f2cd8ac****'),
    previewMediaStatus?: string(name='PreviewMediaStatus', description='The state of the preview media asset. Valid values:

*   Init: the initial state, which indicates that the source file is not ready.
*   Preparing: The source file is being prepared. For example, the file is being uploaded or edited.
*   PrepareFail: The source file failed to be prepared. For example, the information about the source file failed to be obtained.
*   Normal: The source file is ready.', example='Normal'),
    relatedMediaids?: string(name='RelatedMediaids', description='The IDs of the materials associated with the template for use by the regular template editor.', example='{"video":["******c04f1d4a06996144cc1a******"],"audio":["******c04f1d4a06996144cc1a******"],"image":["******c04f1d4a06996144cc1a******"]}'),
    status?: string(name='Status', description='The template state. Valid values:

*   Available
*   Created
*   Uploading
*   Processing
*   UploadFailed
*   ProcessFailed', example='Available'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
    type?: string(name='Type', description='The template type. Valid values:

*   Timeline
*   VETemplate', example='Timeline'),
  }(name='Template', description='The template information.'),
}

model GetTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTemplateResponseBody(name='body'),
}

/**
  * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
  * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/270942.html).
  * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/291418.html).
  * @param request  the request parameters of GetTemplate  GetTemplateRequest
  * @return GetTemplateResponse
 */
async function getTemplate(request: GetTemplateRequest): GetTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTemplate', 'POST', '/', 'json', false, 'json', request);
}

model GetTemplateMaterialsRequest {
  fileList?: string(name='FileList', description='The materials that you want to query.', example='["music.mp3","config.json","assets/1.jpg"]', position='Query'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetTemplateMaterialsResponseBody = {
  materialUrls?: string(name='MaterialUrls', description='The URLs of the associated materials.', example='{"music.mp3":"https://bucket.oss-cn-shanghai.aliyuncs.com/music.mp3?sign=xxx","config.json":"https://bucket.oss-cn-shanghai.aliyuncs.com/config.json?sign=xxx","assets/1.jpg":"https://bucket.oss-cn-shanghai.aliyuncs.com/assets/1.jpg?sign=xxx"}'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetTemplateMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTemplateMaterialsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTemplateMaterials  GetTemplateMaterialsRequest
  * @return GetTemplateMaterialsResponse
 */
async function getTemplateMaterials(request: GetTemplateMaterialsRequest): GetTemplateMaterialsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTemplateMaterials', 'POST', '/', 'json', false, 'json', request);
}

model GetTemplateParamsRequest {
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetTemplateParamsResponseBody = {
  paramList?: [ 
    {
      content?: string(name='Content', description='The original subtitle content.'),
      coverUrl?: string(name='CoverUrl', description='The thumbnail URL of the original material.'),
      key?: string(name='Key', description='The parameter name.', example='video1'),
      mediaUrl?: string(name='MediaUrl', description='The URL of the original material.'),
      type?: string(name='Type', description='The material type.

Valid values:

*   Video
*   Text
*   Image', example='Image'),
    }
  ](name='ParamList', description='The queried parameters.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
  templateId?: string(name='TemplateId', description='The template ID.', example='******419c8741c1b4325f035b******'),
}

model GetTemplateParamsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTemplateParamsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTemplateParams  GetTemplateParamsRequest
  * @return GetTemplateParamsResponse
 */
async function getTemplateParams(request: GetTemplateParamsRequest): GetTemplateParamsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTemplateParams', 'GET', '/', 'json', false, 'json', request);
}

model GetTranscodeJobRequest {
  parentJobId?: string(name='ParentJobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8', position='Query'),
}

model GetTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='9EDC30DC-0050-5459-B788-F761B2BE359B'),
  transcodeParentJob?: {
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    inputGroup?: [ 
      {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
      }
    ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
    jobCount?: int32(name='JobCount', description='The number of subjobs.', example='1'),
    name?: string(name='Name', description='The job name.', example='transcode-job'),
    outputGroup?: [ 
      {
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          outputUrl?: string(name='OutputUrl', description='The URL of the output stream.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HLS encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The endpoint of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='The encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The position of the watermark on the x-axis.', example='10'),
                dy?: string(name='Dy', description='The position of the watermark on the y-axis.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the output video.', example='32'),
                referPos?: string(name='ReferPos', description='The reference position of the watermark. Valid values: TopLeft, TopRight, BottomLeft, and BottomRight. Default value: TopLeft.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The duration of the stream. Valid values: the number of seconds or "ToEND".', example='ToEND'),
                  start?: string(name='Start', description='The start time of the stream.', example='00:00:05'),
                }(name='Timeline', description='The timeline settings.'),
                width?: string(name='Width', description='The width of the output video.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Indicates whether the text size was adjusted based on the output video dimensions. Valid values: true and false. Default value: false.', example='false'),
                borderColor?: string(name='BorderColor', description='The border color.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The border width.', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the watermark.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.', example='16'),
                left?: string(name='Left', description='The distance of the watermark from the left edge.', example='10'),
                top?: string(name='Top', description='The distance of the watermark from the top edge.', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Indicates whether the audio stream is deleted.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100.
*   Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum ABR. This parameter takes effect only for Narrowband HD 1.0.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.
*   If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values: border: automatically detects and removes black bars. A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Indicates whether the auto-rotate screen feature is enabled.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Indicates whether the video was removed.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The job processing configuration.'),
      }
    ](name='OutputGroup', description='The output group of the job.'),
    parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
    percent?: int32(name='Percent', description='The completion percentage of the job.', example='0'),
    requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the snapshot job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling configuration of the job.'),
    status?: string(name='Status', description='The state of the job.

*   Success: At least one of the subjobs is successful.
*   Fail: All subjobs failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    transcodeJobList?: [ 
      {
        createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-01-12T08:49:41Z'),
        finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
        inputGroup?: [ 
          {
            inputUrl?: string(name='InputUrl', description='The URL of the media asset. This parameter is specified only when the media asset is transcoded.', example='oss://bucket/path/to/video.mp4'),
            media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
            type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
          }
        ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
        jobId?: string(name='JobId', description='The subjob ID.', example='7d6a7e0d4db2457a8d45ff5d43e1bf0a'),
        jobIndex?: int32(name='JobIndex', description='The index number of the subjob in the entire job.', example='0'),
        name?: string(name='Name', description='The job name.', example='transcode-job'),
        outFileMeta?: {
          audioStreamInfoList?: [ 
            {
              bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
              channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
              channels?: string(name='Channels', description='The number of sound channels.', example='2'),
              codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
              codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
              codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
              codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
              codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              index?: string(name='Index', description='The sequence number of the stream.', example='1'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
              sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
              startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
              timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
            }
          ](name='AudioStreamInfoList', description='The information about the audio stream.'),
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
            duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
            fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
            fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
            fileType?: string(name='FileType', description='The file type. Valid values: source_file and transcode_file.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
            formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
            height?: string(name='Height', description='The height of the output video.', example='478'),
            mediaId?: string(name='MediaId', description='The ID of the media asset.', example='486c2890096871edba6f81848c016303'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width of the output video.', example='848'),
          }(name='FileBasicInfo', description='The basic file information.'),
          videoStreamInfoList?: [ 
            {
              avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
              bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
              codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
              codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
              codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
              codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
              codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
              dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              fps?: string(name='Fps', description='The frame rate.', example='25.0'),
              hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
              height?: string(name='Height', description='The height of the output video.', example='478'),
              index?: string(name='Index', description='The sequence number of the stream.', example='0'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              level?: string(name='Level', description='The codec level.', example='31'),
              numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
              pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
              profile?: string(name='Profile', description='The encoder profile.', example='High'),
              rotate?: string(name='Rotate', description='The rotation angle of the video image. Valid values: 0, 90, 180, and 270. Default value: 0.', example='0'),
              sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
              startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
              timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
              width?: string(name='Width', description='The width of the output video.', example='848'),
            }
          ](name='VideoStreamInfoList', description='The information about the video stream.'),
        }(name='OutFileMeta', description='The media information about the video generated by the job.'),
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          outputUrl?: string(name='OutputUrl', description='The path of the transcoded output stream. This parameter is required only when the output is a media asset.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HTTP Live Streaming (HLS) encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The endpoint of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='The encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The position of the watermark on the x-axis.', example='10'),
                dy?: string(name='Dy', description='The position of the watermark on the y-axis.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the output video.', example='32'),
                referPos?: string(name='ReferPos', description='The reference position of the watermark. Valid values: TopLeft, TopRight, BottomLeft, and BottomRight. Default value: TopLeft.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The duration of the stream. Valid values: the number of seconds or "ToEND".', example='ToEND'),
                  start?: string(name='Start', description='The start time of the stream.', example='00:00:05'),
                }(name='Timeline', description='The timeline settings.'),
                width?: string(name='Width', description='The width of the output video.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          isInheritTags?: boolean(name='IsInheritTags', description='Indicates whether the tags of the input stream are inherited in the output stream. This parameter does not take effect when the input is not a media asset. Default value: false.', example='true'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Indicates whether the text size was adjusted based on the output video dimensions. Valid values: true and false. Default value: false.', example='false'),
                borderColor?: string(name='BorderColor', description='The border color.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The border width.', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the watermark.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.', example='16'),
                left?: string(name='Left', description='The distance of the watermark from the left edge.', example='10'),
                top?: string(name='Top', description='The distance of the watermark from the top edge.', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Indicates whether the audio stream is deleted.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100. Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              tags?: map[string]string(name='Tags'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.

For more information about examples, see How do I set the resolution for an output video?', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum adaptive bitrate (ABR). This parameter takes effect only for Narrowband HD 1.0.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: Kbit/s.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.

If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60]. The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.

Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Indicates whether the auto-rotate screen feature is enabled.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video. Format: width:height:left:top.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Indicates whether the video was removed.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.

Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The transcoding configuration.'),
        requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
        scheduleConfig?: {
          pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the snapshot job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
          priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
        }(name='ScheduleConfig', description='The scheduling information about the job.'),
        status?: string(name='Status', description='The state of the transcoding job. Valid values: Init (the job is submitted), Success (the job is successful), Fail (the job failed), and Deleted (the job is deleted).', example='Init'),
        submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission result.', example='{}'),
        submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
        userData?: string(name='UserData', description='The user data.', example='user-data'),
      }
    ](name='TranscodeJobList', description='The list of subjobs.'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='TranscodeParentJob', description='TranscodeParentJobWithSubJobDTO'),
}

model GetTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTranscodeJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTranscodeJob  GetTranscodeJobRequest
  * @return GetTranscodeJobResponse
 */
async function getTranscodeJob(request: GetTranscodeJobRequest): GetTranscodeJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTranscodeJob', 'POST', '/', 'json', false, 'json', request);
}

model GetUrlUploadInfosRequest {
  regionId?: string(name='RegionId', position='Host'),
  jobIds?: string(name='JobIds', description='The IDs of the upload jobs. You can specify one or more job IDs. You can obtain the job IDs from the response parameter JobId of the [UploadMediaByURL](https://help.aliyun.com/document_detail/86311.html) operation.

*   You can specify a maximum of 10 job IDs.
*   Separate the job IDs with commas (,).

>  You must specify either JobIds or UploadURLs. If you specify both parameters, only the value of JobIds takes effect.', example='df2ac80b481346daa1db6a7c40edc7f8', position='Query'),
  uploadURLs?: string(name='UploadURLs', description='The upload URLs of the source files. You can specify a maximum of 10 URLs. Separate the URLs with commas (,).

> 

*   The URLs must be encoded.

*   If a media file is uploaded multiple times, we recommend that you specify the URL of the media file only once in this parameter.

*   You must specify either JobIds or UploadURLs. If you specify both parameters, only the value of JobIds takes effect.', example='https://media.w3.org/2010/05/sintel/trailer.mp4', position='Query'),
}

model GetUrlUploadInfosResponseBody = {
  nonExists?: [ string ](name='NonExists', description='The job IDs or upload URLs that do not exist.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  URLUploadInfoList?: [ 
    {
      completeTime?: string(name='CompleteTime', description='The time when the upload job was complete. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2021-11-26 21:47:37'),
      creationTime?: string(name='CreationTime', description='The time when the upload job was created. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2021-11-07T10:03:37Z'),
      errorCode?: string(name='ErrorCode', description='The error code returned if the upload job failed.', example='200'),
      errorMessage?: string(name='ErrorMessage', description='The error message returned if the upload job failed.', example='Success'),
      fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='64610'),
      jobId?: string(name='JobId', description='The ID of the upload job.', example='3829500c0fef429fa4ec1680b122d***'),
      mediaId?: string(name='MediaId', description='The ID of the uploaded media file.', example='5014ca70f08171ecbf940764a0fd6***'),
      status?: string(name='Status', description='The status of the upload job. For more information about the valid values of the parameter, see the "Status: the status of a URL-based upload job" section of the [Basic data types](https://help.aliyun.com/document_detail/52839.html) topic.', example='Normal'),
      uploadURL?: string(name='UploadURL', description='The upload URL of the source file.

>  A maximum of 100 URLs can be returned.', example='http://****.mp4'),
      userData?: string(name='UserData', description='The user data. The value is a JSON string.', example='{"MessageCallback":"{"CallbackURL":"http://example.aliyundoc.com"}", "Extend":"{"localId":"***", "test":"www"}"}'),
    }
  ](name='URLUploadInfoList', description='The details about URL-based upload jobs.'),
}

model GetUrlUploadInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetUrlUploadInfosResponseBody(name='body'),
}

/**
  * @description You can call this operation to query the information, including the upload status, user data, creation time, and completion time, about URL-based upload jobs based on the returned job IDs or the URLs used during the upload.
  * If an upload job fails, you can view the error code and error message. If an upload job is successful, you can obtain the video ID.
  * @param request  the request parameters of GetUrlUploadInfos  GetUrlUploadInfosRequest
  * @return GetUrlUploadInfosResponse
 */
async function getUrlUploadInfos(request: GetUrlUploadInfosRequest): GetUrlUploadInfosResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetUrlUploadInfos', 'POST', '/', 'json', false, 'json', request);
}

model GetVideoListRequest {
  regionId?: string(name='RegionId', position='Host'),
  cateId?: long(name='CateId', description='The ID of the category.', example='781111', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. The end time must be later than the start time. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-01-11T12:59:00Z', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='20', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting method of the results. Valid values:

*   CreationTime:Desc (default): sorts results in reverse chronological order.
*   CreationTime:Asc: sorts results in chronological order.', example='CreationTime:Asc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-01-11T12:00:00Z', position='Query'),
  status?: string(name='Status', description='The status of the video. You can specify multiple video statuses and separate them with commas (,).

Valid values:

*   PrepareFail: The file is abnormal.
*   UploadFail: The video failed to be uploaded.
*   UploadSucc: The video is uploaded.
*   Transcoding: The video is being transcoded.
*   TranscodeFail: The video failed to be transcoded.
*   ProduceFail: The video failed to be produced.
*   Normal: The video is normal.
*   Uploading: The video is being uploaded.
*   Preparing: The file is being generated.
*   Blocked: The video is blocked.
*   checking: The video is being reviewed.', example='Uploading,Normal', position='Query'),
}

model GetVideoListResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaList?: [ 
    {
      appId?: string(name='AppId', description='The ID of the application. Default value: app-1000000.', example='app-1000000'),
      cateId?: long(name='CateId', description='The ID of the category.', example='3679'),
      cateName?: string(name='CateName', description='The name of the category.'),
      coverUrl?: string(name='CoverUrl', description='The URL of the thumbnail.', example='http://example.aliyundoc.com/snapshot/****.jpg?auth_key=1498476426-0-0-f00b9455c49a423ce69cf4e27333****'),
      creationTime?: string(name='CreationTime', description='The time when the audio or video file was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:15:50Z'),
      description?: string(name='Description', description='The description of the audio or video file.'),
      duration?: float(name='Duration', description='The duration. Unit: seconds.', example='135.6'),
      mediaId?: string(name='MediaId', description='The ID of the audio or video file.', example='1c6ce34007d571ed94667630a6bc****'),
      modificationTime?: string(name='ModificationTime', description='The time when the audio or video file was updated. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:16:50Z'),
      size?: long(name='Size', description='The size of the source file. Unit: bytes.', example='10897890'),
      snapshots?: [ string ](name='Snapshots', description='The array of video snapshot URLs.'),
      status?: string(name='Status', description='The status of the video.

Valid values:

*   PrepareFail: The file is abnormal.
*   UploadFail: The video failed to be uploaded.
*   UploadSucc: The video is uploaded.
*   Transcoding: The video is being transcoded.
*   TranscodeFail: The video failed to be transcoded.
*   ProduceFail: The video failed to be produced.
*   Normal: The video is normal.
*   Uploading: The video is being uploaded.
*   Preparing: The file is being generated.
*   Blocked: The video is blocked.
*   checking: The video is being reviewed.', example='Normal'),
      storageLocation?: string(name='StorageLocation', description='The storage address.', example='out-****.oss-cn-shanghai.aliyuncs.com'),
      tags?: string(name='Tags', description='The tags of the audio or video file.'),
      title?: string(name='Title', description='The title of the audio or video file.'),
    }
  ](name='MediaList', description='The information about the audio and video files.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request is successful. Valid values:

*   true
*   false', example='true'),
  total?: long(name='Total', description='The total number of audio and video files that meet the conditions.', example='163'),
}

model GetVideoListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetVideoListResponseBody(name='body'),
}

/**
  * @description You can call this operation to query information about up to the first 5,000 audio and video files based on the filter condition, such as the status or category ID of the file. We recommend that you set the StartTime and EndTime parameters to narrow down the time range and perform multiple queries to obtain data.
  * @param request  the request parameters of GetVideoList  GetVideoListRequest
  * @return GetVideoListResponse
 */
async function getVideoList(request: GetVideoListRequest): GetVideoListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetVideoList', 'POST', '/', 'json', false, 'json', request);
}

model GetWorkflowTaskRequest {
  taskId?: string(name='TaskId', description='The ID of the workflow task.', example='******4215e042b3966ca5441e******', position='Query'),
}

model GetWorkflowTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******0C-7870-15FE-B96F-8880BB******'),
  workflowTask?: {
    activityResults?: string(name='ActivityResults', description='The results for all nodes of the workflow task.'),
    createTime?: string(name='CreateTime', description='The time when the task was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-01-04T02:05:17Z'),
    finishTime?: string(name='FinishTime', description='The time when the task was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-01-04T02:06:19Z'),
    status?: string(name='Status', description='The task state.

Valid values:

*   Init: The task is being initialized.
*   Failed: The task failed.
*   Canceled: The task is canceled.
*   Processing: The task is in progress.
*   Succeed: The task is successful.', example='Succeed'),
    taskId?: string(name='TaskId', description='The ID of the workflow task.', example='******4215e042b3966ca5441e******'),
    taskInput?: string(name='TaskInput', description='The input of the workflow task.', example='{
      "Type": "Media",
      "Media": "******30706071edbfe290b488******"
}'),
    userData?: string(name='UserData', description='The user-defined field that was specified when the workflow task was submitted.', example='{"NotifyAddress":"http://xx.xx.xxx"}'),
    workflow?: {
      createTime?: string(name='CreateTime', description='The time when the workflow was created.', example='2022-11-27T10:02:12Z'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the workflow was last modified.', example='2022-11-29T02:06:19Z'),
      name?: string(name='Name', description='The workflow name.'),
      status?: string(name='Status', description='The workflow state.

Valid values:

*   Active
*   Inactive', example='Active'),
      type?: string(name='Type', description='The workflow type.

Valid values:

*   Customize: custom workflow.
*   System: system workflow.
*   Common: user-created workflow.', example='Common'),
      workflowId?: string(name='WorkflowId', description='The workflow ID.', example='******63dca94c609de02ac0d1******'),
    }(name='Workflow', description='The workflow Information.'),
  }(name='WorkflowTask', description='The information about the workflow task.'),
}

model GetWorkflowTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkflowTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetWorkflowTask  GetWorkflowTaskRequest
  * @return GetWorkflowTaskResponse
 */
async function getWorkflowTask(request: GetWorkflowTaskRequest): GetWorkflowTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetWorkflowTask', 'POST', '/', 'json', false, 'json', request);
}

model InsertMediaToSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  input: string(name='Input', description='The URL of the video, audio, or image file that you want to import to the search library.

Note: Make sure that you specify a correct file name and the bucket in which the file resides is in the same region where this operation is called. Otherwise, the file cannot be found or the operation may fail.

Specify an Object Storage Service (OSS) URL in the following format: oss://[Bucket name]/[File path]. For example, you can specify oss://[example-bucket-****]/[object_path-****].

Specify an HTTP URL in the following format: public endpoint. For example, you can specify http://example-test-\\*\\*\\*\\*.mp4.

This parameter is required.', example='http://example-test-****.mp4', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. Each media ID is unique. If you leave this parameter empty, a media ID is automatically generated for this parameter.', example='411bed50018971edb60b0764a0ec6***', position='Query'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

*   video (default)
*   image
*   audio', example='video', position='Query'),
  msgBody?: string(name='MsgBody', description='The message body.', example='{}', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1', position='Query'),
}

model InsertMediaToSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model InsertMediaToSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: InsertMediaToSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of InsertMediaToSearchLib  InsertMediaToSearchLibRequest
  * @return InsertMediaToSearchLibResponse
 */
async function insertMediaToSearchLib(request: InsertMediaToSearchLibRequest): InsertMediaToSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'InsertMediaToSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model ListAIAgentInstanceRequest {
  AIAgentId: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4***', position='Query'),
  endTime?: string(name='EndTime', example='2023-01-02T00:00:00Z', position='Query'),
  pageNumber?: long(name='PageNumber', example='1', position='Query'),
  pageSize?: long(name='PageSize', example='10', position='Query'),
  startTime?: string(name='StartTime', example='2023-01-01T00:00:00Z', position='Query'),
}

model ListAIAgentInstanceResponseBody = {
  instances?: [ 
    {
      callLogUrl?: string(name='CallLogUrl', example='https://example.com/call_logs/12345.json'),
      runtimeConfig?: AIAgentRuntimeConfig(name='RuntimeConfig', example='{"VoiceChat":{"AgentUserId":"voice_agent_001","ChannelId":"voice_channel_001","AuthToken":"your_voice_chat_auth_token"}}'),
      status?: string(name='Status', example='Finished'),
      templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', example='{"VoiceChat": {"VoiceId": "zhixiaoxia"}}'),
      userData?: string(name='UserData', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
    }
  ](name='Instances'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model ListAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAIAgentInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAIAgentInstance  ListAIAgentInstanceRequest
  * @return ListAIAgentInstanceResponse
 */
async function listAIAgentInstance(request: ListAIAgentInstanceRequest): ListAIAgentInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAIAgentInstance', 'POST', '/', 'json', false, 'json', request);
}

model ListAllPublicMediaTagsRequest {
  regionId?: string(name='RegionId', position='Host'),
  businessType?: string(name='BusinessType', description='The business type of the media asset.', example='"sticker"', position='Query'),
  entityId?: string(name='EntityId', description='The entity ID, which is used to distinguish between media assets of different types in the public domain.

Set this parameter to Copyright_Music, which indicates music in the public domain.', example='Copyright_Music', position='Query'),
}

model ListAllPublicMediaTagsResponseBody = {
  mediaTagList?: [ 
    {
      mediaTagId?: string(name='MediaTagId', description='The ID of the media tag.', example='sticker-gif'),
      mediaTagNameChinese?: string(name='MediaTagNameChinese', description='The name of the media tag in Chinese.', example='Gif'),
      mediaTagNameEnglish?: string(name='MediaTagNameEnglish', description='The name of the material tag in English.'),
      options?: [ 
        {
          optionChineseName?: string(name='OptionChineseName', description='The option name in Chinese.'),
          optionEnglishName?: string(name='OptionEnglishName', description='The option name in English.', example='Angry'),
          optionId?: string(name='OptionId', description='The option ID.', example='Angry'),
        }
      ](name='Options', description='The options.'),
    }
  ](name='MediaTagList', description='The tags of media assets in the public media library.'),
  requestId?: string(name='RequestId', description='The request ID.', example='B45F83B7-7F87-4792-BFE9-63CD2137CAF0'),
}

model ListAllPublicMediaTagsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAllPublicMediaTagsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAllPublicMediaTags  ListAllPublicMediaTagsRequest
  * @return ListAllPublicMediaTagsResponse
 */
async function listAllPublicMediaTags(request: ListAllPublicMediaTagsRequest): ListAllPublicMediaTagsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAllPublicMediaTags', 'POST', '/', 'json', false, 'json', request);
}

model ListAvatarTrainingJobsRequest {
  pageNo?: int32(name='PageNo', description='*   The page number.
*   Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='*   The number of entries per page.
*   Default value: 10.
*   Valid values: 1 to 100.', example='10', maximum=100, position='Query'),
  status?: string(name='Status', description='*   The job state.
*   Valid values: Init, Queuing, Training, Success, and Fail.', example='Success', position='Query'),
}

model ListAvatarTrainingJobsResponseBody = {
  data?: {
    avatarTrainingJobList?: [ 
      {
        avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
        avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXX'),
        avatarName?: string(name='AvatarName', description='The name of the digital human.'),
        avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
        createTime?: string(name='CreateTime', description='*   The time when the job was created.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
        firstTrainingTime?: string(name='FirstTrainingTime', description='*   The time when the first training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
        jobId?: string(name='JobId', description='The ID of the digital human training job.', example='*****aded114489ea02e0addf93*****'),
        lastTrainingTime?: string(name='LastTrainingTime', description='*   The time when the last training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
        message?: string(name='Message', description='The status description.'),
        portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='*****aded114489ea02e0addf93*****'),
        status?: string(name='Status', description='The state of the digital human training job.', example='Normal'),
      }
    ](name='AvatarTrainingJobList', description='The list of digital human training jobs.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='3'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model ListAvatarTrainingJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAvatarTrainingJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAvatarTrainingJobs  ListAvatarTrainingJobsRequest
  * @return ListAvatarTrainingJobsResponse
 */
async function listAvatarTrainingJobs(request: ListAvatarTrainingJobsRequest): ListAvatarTrainingJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAvatarTrainingJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListAvatarsRequest {
  avatarType?: string(name='AvatarType', description='*   The type of the digital human.
*   2DAvatar', example='2DAvatar', position='Query'),
  pageNo?: int32(name='PageNo', description='*   The page number.
*   Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='*   The number of entries per page.
*   Default value: 10.', example='10', maximum=100, position='Query'),
}

model ListAvatarsResponseBody = {
  data?: {
    avatarList?: [ 
      {
        avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
        avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXX'),
        avatarName?: string(name='AvatarName', description='The name of the digital human.'),
        avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
        portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='****571c704445f9a0ee011406c2****'),
        thumbnail?: string(name='Thumbnail', description='The thumbnail URL.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
        transparent?: boolean(name='Transparent', description='Indicates whether the digital human image supports the alpha channels.', example='true'),
      }
    ](name='AvatarList', description='The queried digital humans.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model ListAvatarsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAvatarsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAvatars  ListAvatarsRequest
  * @return ListAvatarsResponse
 */
async function listAvatars(request: ListAvatarsRequest): ListAvatarsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAvatars', 'POST', '/', 'json', false, 'json', request);
}

model ListBatchMediaProducingJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2023-06-05T15:59:59Z', position='Query'),
  jobId?: string(name='JobId', description='The ID of the quick video production job.', example='****d80e4e4044975745c14b****', position='Query'),
  jobType?: string(name='JobType', description='The job type.

Valid values:

*   Script: script-based editing job that mixes media assets.
*   Smart_Mix: intelligent editing job that mixes media assets.', example='Script', position='Query'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.', example='100', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='mRZkKAovub0xWVfH14he4Q==', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting parameter. Valid values:

*   desc (default): sorted by creation time in descending order.
*   asc: sorted by creation time in ascending order.

<!---->

*
*', example='desc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-02-02T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The job state.

Valid values:

*   Finished
*   Init
*   Failed
*   Processing', example='Finished', position='Query'),
}

model ListBatchMediaProducingJobsResponseBody = {
  editingBatchJobList?: [ 
    {
      completeTime?: string(name='CompleteTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2023-06-09T06:38:09Z'),
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-06-09T06:36:48Z'),
      editingConfig?: string(name='EditingConfig', description='The editing configurations. For more information, see [EditingConfig](~~2692547#1be9bba03b7qu~~).', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}'),
      extend?: string(name='Extend', description='The extended information of the job.', example='{}'),
      inputConfig?: string(name='InputConfig', description='The input configurations.'),
      jobId?: string(name='JobId', description='The ID of the quick video production job.', example='******7ecbee4c6d9b8474498e******'),
      jobType?: string(name='JobType', description='The job type.

Valid values:

*   Script: script-based editing job that mixes media assets.
*   Smart_Mix: intelligent editing job that mixes media assets.', example='Script'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2023-06-09T06:37:58Z'),
      outputConfig?: string(name='OutputConfig', description='The output configurations. For more information, see [OutputConfig](~~2692547#447b928fcbuoa~~).', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 20,
  "MaxDuration": 15,
  "Width": 1080,
  "Height": 1920,
  "Video": {"Crf": 27}
}'),
      status?: string(name='Status', description='The job state.

Valid values:

*   Finished
*   Init
*   Failed
*   Processing', example='Finished'),
      userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/zh/ims/use-cases/to-configure-a-callback-when-a-clip-completes).'),
    }
  ](name='EditingBatchJobList', description='The queried quick video production jobs.'),
  maxResults?: int32(name='MaxResults', description='The number of entries per page. Valid values: 1 to 100.

Default value: 10.', example='100'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model ListBatchMediaProducingJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListBatchMediaProducingJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListBatchMediaProducingJobs  ListBatchMediaProducingJobsRequest
  * @return ListBatchMediaProducingJobsResponse
 */
async function listBatchMediaProducingJobs(request: ListBatchMediaProducingJobsRequest): ListBatchMediaProducingJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListBatchMediaProducingJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListCustomTemplatesRequest {
  name?: string(name='Name', description='The template name.', example='test-template', position='Query'),
  orderBy?: string(name='OrderBy', description='The order in which the entries are sorted. Valid values:

*   CreateTimeDesc: sorted by creation time in descending order.
*   CreateTimeAsc: sorted by creation time in ascending order.', example='CreateTimeDesc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='20', position='Query'),
  subtype?: string(name='Subtype', description='The subtype ID of the template.

*   Valid values for transcoding templates:

    *   1 (Normal): regular template.
    *   2 (AudioTranscode): audio transcoding template.
    *   3 (Remux): container format conversion template.
    *   4 (NarrowBandV1): Narrowband HD 1.0 template.
    *   5 (NarrowBandV2): Narrowband HD 2.0 template.

*   Valid values for snapshot templates:

    *   1 (Normal): regular template.
    *   2 (Sprite): sprite template.
    *   3 (WebVtt): WebVTT template.

*   Valid values for AI-assisted content moderation templates:

    *   1 (Video): video moderation template.
    *   2 (Audio): audio moderation template.
    *   3 (Image): image moderation template.

*   Valid values for AI-assisted intelligent erasure templates:

    *   1 (VideoDelogo): logo erasure template.
    *   2 (VideoDetext): subtitle erasure template.', example='2', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****', position='Query'),
  type: string(name='Type', description='The template type. Valid values:

*   1: transcoding template.
*   2: snapshot template.
*   3: animated image template.
*   4\\. image watermark template.
*   5: text watermark template.
*   6: subtitle template.
*   7: AI-assisted content moderation template.
*   8: AI-assisted intelligent thumbnail template.
*   9: AI-assisted intelligent erasure template.

This parameter is required.', example='1', position='Query'),
}

model ListCustomTemplatesResponseBody = {
  customTemplateList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
      frontendHint?: {
        transcodeTemplateHint?: {
          bitrateControlType?: string(name='BitrateControlType'),
        }(name='TranscodeTemplateHint'),
      }(name='FrontendHint'),
      isDefault?: boolean(name='IsDefault', description='Indicates whether the template is the default template.

Valid values:

*   true
*   false', example='true'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
      status?: string(name='Status', description='The template state.

Valid values:

*   Normal', example='Normal'),
      subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='2'),
      subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='AudioTranscode'),
      templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Container":{"Format":"mp3"},"Audio":{"Codec":"mp3","Bitrate":"64","Samplerate":"22050","Channels":"2"}}'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
      templateName?: string(name='TemplateName', description='The template name.', example='test-template'),
      type?: int32(name='Type', description='The type ID of the template.', example='1'),
      typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
    }
  ](name='CustomTemplateList', description='The queried templates.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  total?: int32(name='Total', description='The total number of templates.', example='20'),
}

model ListCustomTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCustomTemplatesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListCustomTemplates  ListCustomTemplatesRequest
  * @return ListCustomTemplatesResponse
 */
async function listCustomTemplates(request: ListCustomTemplatesRequest): ListCustomTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListCustomTemplates', 'POST', '/', 'json', false, 'json', request);
}

model ListCustomizedVoiceJobsRequest {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10', position='Query'),
  type?: string(name='Type', description='The type of the human voice cloning job. Valid values:

*   Basic
*   Standard

> : If you do not specify this parameter, the default value Basic is used.', example='Standard', position='Query'),
}

model ListCustomizedVoiceJobsResponseBody = {
  data?: {
    customizedVoiceJobList?: [ 
      {
        createTime?: string(name='CreateTime', description='*   The time when the job was created.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-04-01T06:23:59Z'),
        gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
        gmtCreate?: string(name='GmtCreate', description='The time when the job was created.', example='2022-06-27T02:42:28Z'),
        jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='2245ab99a7fd4116a4fd3f499b7a56c5'),
        message?: string(name='Message', description='The returned message.'),
        scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation', example='story'),
        status?: string(name='Status', description='The job state. Valid values:

*   Initialization
*   AudioDetecting
*   PreTraining
*   Training
*   Success
*   Fail', example='Success'),
        type?: string(name='Type', description='*   The voice type. Valid values:

    *   Basic
    *   Standard', example='Standard'),
        voiceDesc?: string(name='VoiceDesc', description='The voice description.

*   The description can be up to 256 characters in length.'),
        voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
        voiceName?: string(name='VoiceName', description='The voice name.

*   The name can be up to 32 characters in length.'),
      }
    ](name='CustomizedVoiceJobList', description='The queried human voice cloning jobs.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='271'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
}

model ListCustomizedVoiceJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCustomizedVoiceJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListCustomizedVoiceJobs  ListCustomizedVoiceJobsRequest
  * @return ListCustomizedVoiceJobsResponse
 */
async function listCustomizedVoiceJobs(request: ListCustomizedVoiceJobsRequest): ListCustomizedVoiceJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListCustomizedVoiceJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListCustomizedVoicesRequest {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10', position='Query'),
  type?: string(name='Type', description='*   The voice type. Valid values:

    *   Basic
    *   Standard

*   If you do not specify this parameter, the default value Basic is used.', example='Standard', position='Query'),
}

model ListCustomizedVoicesResponseBody = {
  data?: {
    customizedVoiceList?: [ 
      {
        demoAudioMediaId?: string(name='DemoAudioMediaId', description='The media asset ID of the sample audio file.', example='****4d5e829d498aaf966b119348****'),
        gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='male'),
        scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation', example='story'),
        type?: string(name='Type', description='*   The voice type. Valid values:

    *   Basic
    *   Standard', example='Standard'),
        voiceDesc?: string(name='VoiceDesc', description='The voice description.'),
        voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
        voiceName?: string(name='VoiceName', description='The voice name.'),
      }
    ](name='CustomizedVoiceList', description='The queried personalized human voices.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='41'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model ListCustomizedVoicesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCustomizedVoicesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListCustomizedVoices  ListCustomizedVoicesRequest
  * @return ListCustomizedVoicesResponse
 */
async function listCustomizedVoices(request: ListCustomizedVoicesRequest): ListCustomizedVoicesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListCustomizedVoices', 'POST', '/', 'json', false, 'json', request);
}

model ListDNADBRequest {
  DBIds?: string(name='DBIds', description='The IDs of the media fingerprint libraries. We recommend that you query at most 10 libraries at a time. Separate multiple library IDs with commas (,).', example='2288c6ca184c0e47098a5b665e2a12****,78dc866518b843259669df58ed30****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model ListDNADBResponseBody = {
  DBList?: [ 
    {
      DBId?: string(name='DBId', description='The ID of the media fingerprint library.', example='88c6ca184c0e47098a5b665e2a12****'),
      description?: string(name='Description', description='The description of the media fingerprint library.'),
      model?: string(name='Model', description='The model of the media fingerprint library. Valid values:

*   **Video**
*   **Audio**
*   **Image**
*   **Text** (supported only in the China (Shanghai) region)', example='Video'),
      name?: string(name='Name', description='The name of the media fingerprint library.', example='example-name'),
      status?: string(name='Status', description='The state of the media fingerprint library. Default value: **offline**. ****Valid values:

*   **offline**: The media fingerprint library is offline.
*   **active**: The media fingerprint library is online.
*   **deleted**: The media fingerprint library is deleted.', example='active'),
    }
  ](name='DBList', description='The queried media fingerprint libraries.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model ListDNADBResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDNADBResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDNADB  ListDNADBRequest
  * @return ListDNADBResponse
 */
async function listDNADB(request: ListDNADBRequest): ListDNADBResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDNADB', 'POST', '/', 'json', false, 'json', request);
}

model ListDNAFilesRequest {
  DBId: string(name='DBId', description='The ID of the media fingerprint library.

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='ae0fd49c0840e14daf0d66a75b83****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10', minimum=1, maximum=100, position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model ListDNAFilesResponseBody = {
  fileList?: [ 
    {
      inputFile?: {
        bucket?: string(name='Bucket', description='The name of the OSS bucket in which the input file is stored.', example='example-bucket'),
        location?: string(name='Location', description='The OSS region in which the input file resides.', example='oss-cn-beijing'),
        object?: string(name='Object', description='The name of the OSS object that is used as the input file.', example='example-****.mp4'),
      }(name='InputFile', description='The Object Storage Service (OSS) information about the input file.'),
      primaryKey?: string(name='PrimaryKey', description='The primary key of the file.', example='ae0fd49c0840e14daf0d66a75b83****'),
    }
  ](name='FileList', description='The queried files.'),
  nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='ae0fd49c0840e14daf0d66a75b83****'),
  requestId?: string(name='RequestId', description='The request ID.', example='2AE89FA5-E620-56C7-9B80-75D09757385A'),
}

model ListDNAFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDNAFilesResponseBody(name='body'),
}

/**
  * @description You can call this operation to query files in a media fingerprint library based on the library ID. The queried results can be paginated.
  * @param request  the request parameters of ListDNAFiles  ListDNAFilesRequest
  * @return ListDNAFilesResponse
 */
async function listDNAFiles(request: ListDNAFilesRequest): ListDNAFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDNAFiles', 'POST', '/', 'json', false, 'json', request);
}

model ListDynamicImageJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created.', example='2022-07-14T00:00:00Z', position='Query'),
  jobId?: string(name='JobId', description='The job ID.', example='****cdb3e74639973036bc84****', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='cdb3e74639973036bc84', position='Query'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

1.  CreateTimeAsc: sorts the jobs by creation time in ascending order.
2.  CreateTimeDesc: sorts the jobs by creation time in descending order.', example='CreateTimeDesc', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Maximum value: 100.', example='20', position='Query'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created.', example='2022-07-12T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success', position='Query'),
}

model ListDynamicImageJobsResponseBody = {
  jobs?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
      input?: {
        media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[regionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://bucket/object'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.

*
*', example='OSS'),
      }(name='Input', description='The input of the job.'),
      jobId?: string(name='JobId', description='The job ID.', example='****cdb3e74639973036bc84****'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
      name?: string(name='Name', description='The name of the job.', example='SampleJob'),
      output?: {
        media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='****cdb3e74639973036bc84****'),
        type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

*
*', example='Media'),
      }(name='Output', description='The output of the job.'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****cdb3e74639973036bc84****'),
      status?: string(name='Status', description='The state of the job.

*   **Success**: The job is successful.
*   **Fail**: The job failed.
*   **Init**: The job is submitted.', example='Success'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****cdb3e74639973036bc84****'),
      triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
    }
  ](name='Jobs', description='The list of jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****cdb3e74639973036bc84****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListDynamicImageJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDynamicImageJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDynamicImageJobs  ListDynamicImageJobsRequest
  * @return ListDynamicImageJobsResponse
 */
async function listDynamicImageJobs(request: ListDynamicImageJobsRequest): ListDynamicImageJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDynamicImageJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListEditingProjectsRequest {
  regionId?: string(name='RegionId', position='Host'),
  createSource?: string(name='CreateSource', description='The method for creating the online editing project. Valid values:

\\- OpenAPI

\\- AliyunConsole

\\- WebSDK', example='OpenAPI', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-02-02T23:59:59Z', position='Query'),
  keyword?: string(name='Keyword', description='The search keyword. You can search by job ID.', example='******6f36bc45d09a9d5cde49******', position='Query'),
  maxResults?: string(name='MaxResults', description='The number of entries per page. A maximum of 100 entries can be returned on each page.

Default value: 10.', example='10', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ==', position='Query'),
  projectType?: string(name='ProjectType', description='The type of the editing project. Valid values:

*   EditingProject: a regular editing project.
*   LiveEditingProject: a live stream editing project.', example='EditingProject', position='Query'),
  sortBy?: string(name='SortBy', description='The order of sorting of the results. Valid values:

*   CreationTime:Desc (default): sorts the results in reverse chronological order.
*   CreationTime:Asc: sorts the results in chronological order.', example='CreationTime:Desc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-12-21T08:00:01Z', position='Query'),
  status?: string(name='Status', description='The status of the online editing project. By default, online editing projects in all states are queried.', example='Produced', position='Query'),
  templateType?: string(name='TemplateType', description='The template type. This parameter is required if you create a template-based online editing project. Default value: Timeline.

*
*

Valid values:

*   Timeline: a regular template.
*   VETemplate: an advanced template.
*   None: general editing.', example='None', position='Query'),
}

model ListEditingProjectsResponseBody = {
  maxResults?: int32(name='MaxResults', description='The maximum number of entries returned.', example='10'),
  nextToken: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.

This parameter is required.', example='Nzv3rcKla9wHUGua9YXHNA=='),
  projectList?: [ 
    {
      businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{}'),
      businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects.', example='{}'),
      coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='https://xxx.com/cover/xxx.jpg'),
      createSource?: string(name='CreateSource', description='The method for editing the online editing project. Valid values:

\\- OpenAPI

\\- AliyunConsole

\\- WebSDK', example='OpenAPI'),
      createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2017-01-11T12:00:00Z'),
      description?: string(name='Description', description='The description of the online editing project.'),
      errorCode?: string(name='ErrorCode', description='The error code returned if the production of the online editing project failed.', example='InvalidParameter'),
      errorMessage?: string(name='ErrorMessage', description='The error message returned if the production of the online editing project failed.', example='The specified parameter \\"LiveStreamConfig\\" is not valid. specified parameter example is not valid.'),
      modifiedSource?: string(name='ModifiedSource', description='The method for modifying the online editing project last time.', example='OpenAPI'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last modified.', example='2017-01-11T12:00:00Z'),
      projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fddd7748b58bf1d47e95****'),
      projectType?: string(name='ProjectType', description='The type of the editing project. Valid values:

*   EditingProject: a regular editing project.
*   LiveEditingProject: a live stream editing project.', example='EditingProject'),
      status?: string(name='Status', description='The status of the online editing project. Valid values:

\\- Draft

\\- Editing

\\- Producing

\\- Produced

\\- ProduceFailed', example='Produced'),
      templateType?: string(name='TemplateType', description='The template type. Valid values:

*   Timeline: a regular template.
*   VETemplate: an advanced template.', example='Timeline'),
      title?: string(name='Title', description='The title of the online editing project.'),
    }
  ](name='ProjectList', description='The queried online editing projects.'),
  requestId?: string(name='RequestId', description='The request ID.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
}

model ListEditingProjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListEditingProjectsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListEditingProjects  ListEditingProjectsRequest
  * @return ListEditingProjectsResponse
 */
async function listEditingProjects(request: ListEditingProjectsRequest): ListEditingProjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListEditingProjects', 'POST', '/', 'json', false, 'json', request);
}

model ListLiveRecordFilesRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. The maximum time range to query is four days. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-12-22T08:00:00Z', position='Query'),
  jobIds?: [ string ](name='JobIds', description='The list of job IDs.', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number of the page to return. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 5 to 30. Default value: 10.', example='10', position='Query'),
  recordFormat?: string(name='RecordFormat', description='The format of the recording file. Valid values:

M3U8, FLV, and MP4', example='m3u8', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order of the index files by creation time. Valid values:

asc: The query results are displayed in ascending order. This is the default value.

desc: The query results are displayed in descending order.', example='asc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-12-21T08:00:01Z', position='Query'),
}

model ListLiveRecordFilesResponseBody = {
  files?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the file was created in UTC.', example='2016-05-27T09:40:56Z'),
      duration?: float(name='Duration', description='The recording length. Unit: seconds.', example='100.0'),
      endTime?: string(name='EndTime', description='The end of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2015-12-01T07:36:10Z'),
      format?: string(name='Format', description='The format of the recording file.', example='m3u8'),
      height?: int32(name='Height', description='The height of the video.', example='640'),
      jobId?: string(name='JobId', description='The ID of the recording job.', example='c4d7f0a4-b506-43f9-8de3-07732c3f****'),
      jobName?: string(name='JobName', description='The name of the recording job.', example='LiveRecordJob***'),
      recordId?: string(name='RecordId', description='The ID of the index file.', example='c4d7f0a4-b506-43f9-8de3-07732c3f****'),
      recordOutput?: string(name='RecordOutput', description='The storage information about the recording file.', example='{ "Type": "oss", "Endpoint":"oss-cn-shanghai.aliyuncs.com", "Bucket": "test-bucket" }'),
      recordUrl?: string(name='RecordUrl', description='The URL of the index file.'),
      startTime?: string(name='StartTime', description='The beginning of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2015-12-01T07:36:00Z'),
      streamUrl?: string(name='StreamUrl', description='The name of the live stream.', example='LiveStream***'),
      width?: int32(name='Width', description='The width of the video.', example='480'),
    }
  ](name='Files', description='The list of index files.'),
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='DE24625C-7C0F-4020-8448-****'),
  sortBy?: string(name='SortBy', description='The sorting order of the index files by creation time.', example='asc'),
  totalCount?: string(name='TotalCount', description='The total number of files that meet the specified conditions.', example='100'),
}

model ListLiveRecordFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveRecordFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveRecordFiles  ListLiveRecordFilesRequest
  * @return ListLiveRecordFilesResponse
 */
async function listLiveRecordFiles(request: ListLiveRecordFilesRequest): ListLiveRecordFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveRecordFiles', 'GET', '/', 'json', false, 'json', request);
}

model ListLiveRecordJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. The maximum time range between EndTime and StartTime cannot exceed 30 days. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-11T08:00:00Z', position='Query'),
  keyword?: string(name='Keyword', description='The search keyword. You can use the job ID or name as the keyword to search for jobs.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='20', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results in ascending order.
*   desc: sorts the query results in descending order.', example='desc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-15T08:00:00Z', position='Query'),
  status?: string(name='Status', description='The state of the job. By default, the state is not filtered.

Valid values:

*   paused: The job is paused.
*   initial: The job is not started.
*   started: The job is in progress.', example='started', position='Query'),
}

model ListLiveRecordJobsResponseBody = {
  liveRecordJobs?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
      jobId?: string(name='JobId', description='The ID of the recording job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
      name?: string(name='Name', description='The name of the recording job.'),
      notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify'),
      recordOutput?: {
        bucket?: string(name='Bucket', description='The bucket name.', example='imsbucket1'),
        endpoint?: string(name='Endpoint', description='The endpoint of the storage service.', example='oss-cn-hangzhou.aliyuncs.com'),
        type?: string(name='Type', description='The type of the storage address.

Valid values:

*   vod
*   oss', example='oss'),
      }(name='RecordOutput', description='The storage address of the recording.'),
      status?: string(name='Status', description='The state of the recording job.', example='paused'),
      streamInput?: {
        type?: string(name='Type', description='The type of the live stream URL.', example='rtmp'),
        url?: string(name='Url', description='The URL of the live stream.', example='rtmp://example-live.com/live/stream1'),
      }(name='StreamInput', description='The URL of the live stream.'),
      templateId?: string(name='TemplateId', description='The ID of the recording template.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
      templateName?: string(name='TemplateName', description='The name of the recording template.', example='test template'),
    }
  ](name='LiveRecordJobs', description='The list of live stream recording jobs.'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='20'),
  requestId?: string(name='RequestId', description='The request ID.', example='A27DFFA4-F272-5563-8363-CB0BC42740BA'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='180'),
}

model ListLiveRecordJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveRecordJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveRecordJobs  ListLiveRecordJobsRequest
  * @return ListLiveRecordJobsResponse
 */
async function listLiveRecordJobs(request: ListLiveRecordJobsRequest): ListLiveRecordJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveRecordJobs', 'GET', '/', 'json', false, 'json', request);
}

model ListLiveRecordTemplatesRequest {
  keyword?: string(name='Keyword', description='The search keyword. You can use the template ID or name as the keyword to search for templates. If you search for templates by name, fuzzy match is supported.', example='test template', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Minimum value: 1. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results in ascending order.
*   desc: sorts the query results in descending order.', example='desc', position='Query'),
  templateIds?: [ string ](name='TemplateIds', position='Query'),
  type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom', position='Query'),
}

model ListLiveRecordTemplatesResponseBody = {
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
  recordTemplateList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T02:48:58Z'),
      lastModified?: string(name='LastModified', description='The time when the template was last modified.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
      name?: string(name='Name', description='The template name.', example='test template'),
      recordFormatList?: [ 
        {
          cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds.', example='21600'),
          format?: string(name='Format', description='The output file format.', example='m3u8'),
          ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording file that is stored in Object Storage Service (OSS).', example='record/{JobId}/{Sequence}_{EscapedStartTime}_{EscapedEndTime}'),
          sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds.', example='30'),
          sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
        }
      ](name='RecordFormatList', description='The list of recording formats.'),
      templateId?: string(name='TemplateId', description='The template ID.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
      type?: string(name='Type', description='The type of the template.', example='custom'),
    }
  ](name='RecordTemplateList', description='The list of recording templates.'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results in ascending order.
*   desc: sorts the query results in descending order.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='5'),
}

model ListLiveRecordTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveRecordTemplatesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveRecordTemplates  ListLiveRecordTemplatesRequest
  * @return ListLiveRecordTemplatesResponse
 */
async function listLiveRecordTemplates(request: ListLiveRecordTemplatesRequest): ListLiveRecordTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveRecordTemplates', 'GET', '/', 'json', false, 'json', request);
}

model ListLiveSnapshotFilesRequest {
  endTime: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

*   The maximum time range that can be specified is one day.

This parameter is required.', example='2022-02-02T23:59:59Z', position='Query'),
  jobId: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Query'),
  limit?: int32(name='Limit', description='The number of results to return each time. Valid values: 1 to 100. Default value: 10.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. Default value: asc.

Valid values:

*   asc: sorts the query results by creation time in ascending order.
*   desc: sorts the query results by creation time in descending order.', example='desc', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

This parameter is required.', example='2022-02-02T00:00:00Z', position='Query'),
}

model ListLiveSnapshotFilesResponseBody = {
  fileList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-02-02T22:22:22Z'),
      createTimestamp?: long(name='CreateTimestamp', description='The creation timestamp that is used as an input parameter for a delete API operation.', example='1619503516000'),
      isOverlay?: boolean(name='IsOverlay', description='Specifies whether to overlay snapshots.', example='true'),
      ossBucket?: string(name='OssBucket', description='The OSS bucket.', example='testbucket'),
      ossEndpoint?: string(name='OssEndpoint', description='The Object Storage Service (OSS) domain name.', example='oss-cn-shanghai.aliyuncs.com'),
      ossObject?: string(name='OssObject', description='The location in which the OSS object is stored.'),
    }
  ](name='FileList', description='The list of files.'),
  nextStartTime?: string(name='NextStartTime', description='The start time of the next page. If no value is returned, the pagination ends.', example='2022-02-02T22:22:22Z'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListLiveSnapshotFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveSnapshotFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveSnapshotFiles  ListLiveSnapshotFilesRequest
  * @return ListLiveSnapshotFilesResponse
 */
async function listLiveSnapshotFiles(request: ListLiveSnapshotFilesRequest): ListLiveSnapshotFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveSnapshotFiles', 'GET', '/', 'json', false, 'json', request);
}

model ListLiveSnapshotJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

*   By default, EndTime is seven days later than StartTime.
*   The time range specified by the StartTime and EndTime parameters cannot exceed 30 days.', example='2022-02-02T23:59:59Z', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Valid values: [1,n). Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10', position='Query'),
  searchKeyWord?: string(name='SearchKeyWord', description='The search keyword. You can use the job ID or name as the keyword to search for jobs. If you search for jobs by name, fuzzy match is supported.

*   It cannot exceed 128 characters in length.', example='****a046-263c-3560-978a-fb287782****', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results by creation time in ascending order.
*   desc: sorts the query results by creation time in descending order.', example='desc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

*   The default value is seven days ago.
*   The time range specified by the StartTime and EndTime parameters cannot exceed 30 days.', example='2022-02-02T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The job state filter. By default, all jobs are queried.

Valid values:

*   init: The job is not started.
*   paused: The job is paused.
*   started: The job is in progress.', position='Query'),
}

model ListLiveSnapshotJobsResponseBody = {
  jobList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-20T02:48:58Z'),
      jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287782****'),
      jobName?: string(name='JobName', description='The name of the job.'),
      snapshotOutput?: {
        bucket?: string(name='Bucket', description='The bucket of the output endpoint. If the storage type is set to oss, the OSS bucket is returned.', example='testbucket'),
        endpoint?: string(name='Endpoint', description='The output endpoint. If the storage type is set to oss, the Object Storage Service (OSS) domain name is returned.', example='oss-cn-shanghai.aliyuncs.com'),
        storageType?: string(name='StorageType', description='The storage type. The value can only be oss.', example='oss'),
      }(name='SnapshotOutput', description='The output information.'),
      status?: string(name='Status', description='The state of the job.

Valid values:

*   init: The job is not started.
*   paused: The job is paused.
*   started: The job is in progress.', example='started'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287666****'),
      templateName?: string(name='TemplateName', description='The template name.'),
      timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.', example='5'),
    }
  ](name='JobList', description='The list of jobs.'),
  pageNo?: int32(name='PageNo', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the jobs by creation time.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveSnapshotJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveSnapshotJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveSnapshotJobs  ListLiveSnapshotJobsRequest
  * @return ListLiveSnapshotJobsResponse
 */
async function listLiveSnapshotJobs(request: ListLiveSnapshotJobsRequest): ListLiveSnapshotJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveSnapshotJobs', 'GET', '/', 'json', false, 'json', request);
}

model ListLiveSnapshotTemplatesRequest {
  pageNo?: int32(name='PageNo', description='The page number. Valid values: [1,n). Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10', position='Query'),
  searchKeyWord?: string(name='SearchKeyWord', description='The search keyword. You can use the template ID or name as the keyword to search for templates. If you search for templates by name, fuzzy match is supported.

*   It cannot exceed 128 characters in length.', example='****a046-263c-3560-978a-fb287782****', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results by creation time in ascending order.
*   desc: sorts the query results by creation time in descending order.', example='desc', position='Query'),
  templateIds?: [ string ](name='TemplateIds', description='The template IDs.

*   If you specify the SearchKeyWord parameter, this condition does not take effect.
*   The maximum length of the array is 200.', position='Query'),
  type?: string(name='Type', description='The type of the template. By default, all types are queried.

Valid values:

*   system
*   custom', example='custom', position='Query'),
}

model ListLiveSnapshotTemplatesResponseBody = {
  pageNo?: int32(name='PageNo', description='The number of the returned page.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the results by creation time.', example='desc'),
  templateList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T02:48:58Z'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287782****'),
      templateName?: string(name='TemplateName', description='The template name.'),
      timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.', example='10'),
      type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
    }
  ](name='TemplateList', description='The list of the templates.'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveSnapshotTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveSnapshotTemplatesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveSnapshotTemplates  ListLiveSnapshotTemplatesRequest
  * @return ListLiveSnapshotTemplatesResponse
 */
async function listLiveSnapshotTemplates(request: ListLiveSnapshotTemplatesRequest): ListLiveSnapshotTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveSnapshotTemplates', 'GET', '/', 'json', false, 'json', request);
}

model ListLiveTranscodeJobsRequest {
  keyWord?: string(name='KeyWord', description='The search keyword. You can use the job ID or name as the keyword to search for jobs. If you search for jobs by name, fuzzy match is supported.', example='24ecbb5c-4f98-4194-9400-f17102e27fc5', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='20', minimum=1, position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values:

*   asc
*   desc', example='asc', position='Query'),
  startMode?: int32(name='StartMode', description='The start mode of the transcoding job.

*   0: The transcoding job immediately starts.
*   1: The transcoding job starts at the scheduled time.', example='0', position='Query'),
  status?: int32(name='Status', description='The state of the job.

0: The job is not started. 1: The job is in progress. 2: The job is stopped.', example='1', position='Query'),
  type?: string(name='Type', description='The type of the template used by the transcoding job.

*   normal
*   narrow-band
*   audio-only
*   origin', example='normal', position='Query'),
}

model ListLiveTranscodeJobsResponseBody = {
  jobList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T02:48:58Z'),
      jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287782****'),
      name?: string(name='Name', description='The name of the transcoding job.', example='mytask'),
      outputStream?: {
        streamInfos?: [ 
          {
            outputUrl?: string(name='OutputUrl', description='The URL of the output stream.', example='rtmp://mydomain/app/mytranscode1'),
            type?: string(name='Type', description='The type of the output stream protocol. Only the RTMP protocol is supported.', example='rtmp'),
          }
        ](name='StreamInfos', description='The list of stream URLs.'),
      }(name='OutputStream', description='The information about the output stream.'),
      startMode?: int32(name='StartMode', description='The start mode of the job.', example='0'),
      status?: int32(name='Status', description='The state of the job.', example='1'),
      streamInput?: {
        inputUrl?: string(name='InputUrl', description='The URL of the input stream.', example='rtmp://mydomain/app/stream1'),
        type?: string(name='Type', description='The type of the input stream.', example='rtmp'),
      }(name='StreamInput', description='The information about the input stream.'),
      templateId?: string(name='TemplateId', description='The ID of the transcoding template used by the transcoding job.', example='****a046-263c-3560-978a-fb287666****'),
      templateName?: string(name='TemplateName', description='The template name.'),
      templateType?: string(name='TemplateType', description='The type of the transcoding template used by the transcoding job.', example='normal'),
    }
  ](name='JobList', description='The list of transcoding jobs.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveTranscodeJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveTranscodeJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveTranscodeJobs  ListLiveTranscodeJobsRequest
  * @return ListLiveTranscodeJobsResponse
 */
async function listLiveTranscodeJobs(request: ListLiveTranscodeJobsRequest): ListLiveTranscodeJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveTranscodeJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListLiveTranscodeTemplatesRequest {
  category?: string(name='Category', description='The category of the template. Valid values:

*   system
*   customized', example='customized', position='Query'),
  keyWord?: string(name='KeyWord', description='The search keyword. You can use the template ID or name as the keyword to search for templates. If you search for templates by name, fuzzy match is supported.', example='my_template', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number of the page to return. Default value: 1.', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='20', minimum=1, position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values:

*   asc
*   desc', example='asc', position='Query'),
  type?: string(name='Type', description='The type of the template. Valid values:

*   normal
*   narrow-band
*   audio-only
*   origin', example='normal', position='Query'),
  videoCodec?: string(name='VideoCodec', description='The video codec. Valid values:

*   H.264
*   H.265', example='H.264', position='Query'),
}

model ListLiveTranscodeTemplatesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  templateContentList?: [ 
    {
      category?: string(name='Category', description='The category of the template. Valid values:', example='system'),
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T03:26:36Z'),
      name?: string(name='Name', description='The template name.', example='my_template'),
      templateConfig?: {
        audioParams?: {
          bitrate?: string(name='Bitrate', description='The audio bitrate.', example='1000'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codec?: string(name='Codec', description='The audio codec.', example='AAC'),
          profile?: string(name='Profile', description='The encoding profile.', example='aac_low'),
          samplerate?: string(name='Samplerate', description='The audio sampling rate.', example='44100'),
        }(name='AudioParams', description='The audio parameters.'),
        videoParams?: {
          bitrate?: string(name='Bitrate', description='The video bitrate.', example='2500'),
          codec?: string(name='Codec', description='The encoding format.', example='264'),
          fps?: string(name='Fps', description='The video frame rate.', example='30'),
          gop?: string(name='Gop', description='The group of pictures (GOP) of the output video. Unit: frame.', example='1000'),
          height?: string(name='Height', description='The vertical resolution of the video.', example='1280'),
          profile?: string(name='Profile', description='The encoding profile.', example='3'),
          width?: string(name='Width', description='The horizontal resolution of the video.', example='720'),
        }(name='VideoParams', description='The video parameters.'),
      }(name='TemplateConfig', description='The configuration of the template.'),
      templateId?: string(name='TemplateId', description='The template ID.', example='9b1571b513cb44f7a1ba6ae561ff46f7'),
      type?: string(name='Type', description='The type of the template.', example='normal'),
    }
  ](name='TemplateContentList', description='The list of transcoding templates.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveTranscodeTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveTranscodeTemplatesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveTranscodeTemplates  ListLiveTranscodeTemplatesRequest
  * @return ListLiveTranscodeTemplatesResponse
 */
async function listLiveTranscodeTemplates(request: ListLiveTranscodeTemplatesRequest): ListLiveTranscodeTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveTranscodeTemplates', 'POST', '/', 'json', false, 'json', request);
}

model ListMediaBasicInfosRequest {
  regionId?: string(name='RegionId', position='Host'),
  businessType?: string(name='BusinessType', description='The business type of the media asset. Valid values:

\\- subtitles

\\- watermark

\\- opening

\\- ending

\\- general', example='opening', position='Query'),
  endTime?: string(name='EndTime', description='The end time of utcCreated.

\\- The value is the end of the left-open right-closed interval.

\\- Specify the time in the ISO 8601 standard in the YYYY-MM-DDThh:mm:ssZ format. For example, 2017-01-11T12:00:00Z indicates 20:00:00 on January 11, 2017 (UTC +8).', example='2020-12-20T13:00:00Z', position='Query'),
  includeFileBasicInfo?: boolean(name='IncludeFileBasicInfo', description='Specifies whether to return the basic information of the source file.', example='true', position='Query'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.

Maximum value: 100. Default value: 10.', example='5', minimum=1, maximum=100, position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****', position='Query'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

\\- image

\\- video

\\- audio

\\- text', example='video', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='pSa1SQ0wCe5pzVrQ6mWZEw==', position='Query'),
  sortBy?: string(name='SortBy', description='The order of sorting by utcCreated. Default value: desc. Valid values:

\\- desc

\\- asc', example='desc', position='Query'),
  source?: string(name='Source', description='The source of the media asset. Valid values:

\\- oss: Object Storage Service (OSS).

\\- vod: ApsaraVideo VOD.

\\- live: ApsaraVideo Live.

\\- general: other sources. This is the default value.', example='oss', position='Query'),
  startTime?: string(name='StartTime', description='The start time of utcCreated.

\\- The value is the beginning of a left-open right-closed interval.

\\- Specify the time in the ISO 8601 standard in the YYYY-MM-DDThh:mm:ssZ format. For example, 2017-01-11T12:00:00Z indicates 20:00:00 on January 11, 2017 (UTC +8).', example='2020-12-20T12:00:00Z', position='Query'),
  status?: string(name='Status', description='The status of the media asset. Valid values:

\\- Init: the initial state, which indicates that the source file is not ready.

\\- Preparing: The source file is being prepared. For example, the file is being uploaded or edited.

\\- PrepareFail: The source file failed to be prepared. For example, the information of the source file failed to be obtained.

\\- Normal: The source file is ready.', example='Normal', position='Query'),
}

model ListMediaBasicInfosResponseBody = {
  maxResults?: int32(name='MaxResults', description='The maximum number of entries returned in the query.', example='2'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1912.13'),
            createTime?: string(name='CreateTime', description='The time when the file was created.', example='2021-01-08T16:52:04Z'),
            duration?: string(name='Duration', description='The duration.', example='60.00000'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='14340962'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The OSS URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example2.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='720'),
            modifiedTime?: string(name='ModifiedTime', description='The time when the file was last modified.', example='2021-01-08T16:52:07Z'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='1280'),
          }(name='FileBasicInfo', description='The basic information of the file, including the duration and size.'),
        }
      ](name='FileInfoList', description='FileInfos'),
      mediaBasicInfo?: {
        biz?: string(name='Biz', description='The service to which the media asset belongs.', example='ICE'),
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='opening'),
        cateId?: long(name='CateId', description='The category ID.', example='3049'),
        category?: string(name='Category', description='The category of the media asset.'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2021-01-08T16:52:04Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2021-01-08T16:52:07Z'),
        description?: string(name='Description', description='The description of the media asset.'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='tags,tags2'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2021-01-08T16:52:07Z'),
        referenceId?: string(name='ReferenceId', description='The custom ID of the media asset. The ID is a string that contains 6 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are supported. The ID is unique among users.', example='123-123'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='[{"bucket":"example-bucket","count":"3","iceJobId":"******f48f0e4154976b2b8c45******","location":"oss-cn-beijing","snapshotRegular":"example.jpg","templateId":"******e6a6440b29eb60bd7c******"}]'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite.', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        uploadSource?: string(name='UploadSource', description='The upload source of the media asset.', example='general'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='BasicInfo'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******B7-7F87-4792-BFE9-63CD21******'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='4'),
}

model ListMediaBasicInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaBasicInfosResponseBody(name='body'),
}

/**
  * @description If includeFileBasicInfo is set to true, the basic information, such as the duration and file size, of the source file is also returned. At most the first 100 entries that meet the specified conditions are returned. All media assets must exactly match all non-empty fields. The fields that support exact match include MediaType, Source, BusinessType, Category, and Status. If all information cannot be returned at a time, you can use NextToken to initiate a request to retrieve a new page of results.
  * @param request  the request parameters of ListMediaBasicInfos  ListMediaBasicInfosRequest
  * @return ListMediaBasicInfosResponse
 */
async function listMediaBasicInfos(request: ListMediaBasicInfosRequest): ListMediaBasicInfosResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMediaBasicInfos', 'POST', '/', 'json', false, 'json', request);
}

model ListMediaInfoJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-15T00:00:00Z', position='Query'),
  jobId?: string(name='JobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb11cbe', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='ab4802364a2e49208c99efab82dfa8e8', position='Query'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

*   CreateTimeDesc: sorts the query results by creation time in descending order.
*   CreateTimeAsc: sorts the query results by creation time in ascending order.', example='CreateTimeDesc', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-01T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The state of the job. Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success', position='Query'),
}

model ListMediaInfoJobsResponseBody = {
  jobs?: [ 
    {
      async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      input?: {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
      }(name='Input', description='The input of the job.'),
      jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
      mediaInfoProperty?: {
        audioStreamInfoList?: [ 
          {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
            channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
            channels?: string(name='Channels', description='The number of sound channels.', example='2'),
            codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
            codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
            codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
            codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
            duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
            index?: string(name='Index', description='The sequence number of the stream.', example='1'),
            lang?: string(name='Lang', description='The language of the stream.', example='cn'),
            sampleFmt?: string(name='SampleFmt', description='The sampling format.', example='fltp'),
            sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
            startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
            timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
          }
        ](name='AudioStreamInfoList', description='The information about the audio stream.'),
        fileBasicInfo?: {
          bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
          duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
          fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
          fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
          fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
          fileType?: string(name='FileType', description='The file type. Valid values: source_file and transcode_file.', example='source_file'),
          fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
          formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
          height?: string(name='Height', description='The height.', example='478'),
          mediaId?: string(name='MediaId', description='The ID of the media asset.', example='4765337007f571edbfdf81848c016303'),
          region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
          width?: string(name='Width', description='The width.', example='848'),
        }(name='FileBasicInfo', description='The basic file information.'),
        videoStreamInfoList?: [ 
          {
            avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
            bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
            codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
            codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
            codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
            codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
            codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
            dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
            duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
            fps?: string(name='Fps', description='The frame rate.', example='25.0'),
            hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
            height?: string(name='Height', description='The height.', example='478'),
            index?: string(name='Index', description='The sequence number of the stream.', example='0'),
            lang?: string(name='Lang', description='The language of the stream.', example='cn'),
            level?: string(name='Level', description='The codec level.', example='31'),
            numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
            pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
            profile?: string(name='Profile', description='The encoder profile.', example='High'),
            rotate?: string(name='Rotate', description='The rotation angle of the video image.

*   Valid values: 0, 90, 180, and 270.
*   Default value: 0.', example='0'),
            sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
            startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
            timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
            width?: string(name='Width', description='The width.', example='848'),
          }
        ](name='VideoStreamInfoList', description='The information about the video stream.'),
      }(name='MediaInfoProperty', description='The details of the media information.'),
      name?: string(name='Name', description='The job name.', example='job-name'),
      requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
      scheduleConfig?: {
        pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
        priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
      }(name='ScheduleConfig', description='The scheduling information.'),
      status?: string(name='Status', description='The state of the job. Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Init'),
      submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
      userData?: string(name='UserData', description='The user data.', example='user-data'),
    }
  ](name='Jobs', description='The list of media information analysis jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. The token of the next page is returned after you call this operation for the first time.', example='019daf5780f74831b0e1a767c9f1c178'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model ListMediaInfoJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaInfoJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListMediaInfoJobs  ListMediaInfoJobsRequest
  * @return ListMediaInfoJobsResponse
 */
async function listMediaInfoJobs(request: ListMediaInfoJobsRequest): ListMediaInfoJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMediaInfoJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListMediaMarksRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***', position='Query'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The mark ID. You can specify multiple IDs separated with commas (,). This parameter is discontinued.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60', position='Query'),
}

model ListMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  mediaMarks?: string(name='MediaMarks', description='The marks of the media asset, in the JSONArray format.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaMarksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListMediaMarks  ListMediaMarksRequest
  * @return ListMediaMarksResponse
 */
async function listMediaMarks(request: ListMediaMarksRequest): ListMediaMarksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMediaMarks', 'POST', '/', 'json', false, 'json', request);
}

model ListMediaProducingJobsRequest {
  regionId?: string(name='RegionId', position='Host'),
  endTime?: string(name='EndTime', description='The end of the time range to query. The maximum time range between EndTime and StartTime cannot exceed 30 days. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-02-02T23:59:59Z', position='Query'),
  jobType?: string(name='JobType', description='The job type.

Valid values:

*   LiveEditingJob: live editing job.
*   EditingJob: regular template-based editing job
*   VETemplateJob: advanced template-based editing job.', example='EditingJob', position='Query'),
  keyword?: string(name='Keyword', description='The search keyword. For example, you can use a job ID as the keyword to search for jobs.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  masterJobId?: string(name='MasterJobId', description='The ID of the quick video production job. If this parameter is specified, the subjobs of the quick video production job are queried.', example='******8750b54e3c976a47da6f******', position='Query'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.

Default value: 10. Valid values: 1 to 100.', example='100', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ==', position='Query'),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='******927cfb53d05b96c1bfe1******', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting parameter. By default, the query results are sorted by creation time in descending order.

Valid values:

*   CreationTime:Asc: sorted by creation time in ascending order.
*   CreationTime:Desc: sorted by creation time in descending order.', example='CreationTime:Desc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-01-11T12:00:00Z', position='Query'),
  status?: string(name='Status', description='The job state.

Valid values:

*   Init: The job is initialized.
*   Failed: The job failed.
*   Success: The job is successful.
*   Processing: The job is in progress.', example='Success', position='Query'),
}

model ListMediaProducingJobsResponseBody = {
  maxResults?: string(name='MaxResults', description='The maximum number of entries returned.

Default value: 10. Valid values: 1 to 100.', example='100'),
  mediaProducingJobList?: [ 
    {
      clipsParam?: string(name='ClipsParam', description='The template material parameters.', example='{"Text1":"text","Text0":"text","Media1":"mediaId","Media0":"mediaId"}'),
      code?: string(name='Code', description='The response code.', example='Success'),
      completeTime?: string(name='CompleteTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-03-21T16:40:30Z'),
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-03-21T16:40:00Z'),
      duration?: float(name='Duration', description='The duration of the output file. Unit: seconds.', example='15.5'),
      jobId?: string(name='JobId', description='The ID of the online editing job.', example='******8750b54e3c976a47da6f******'),
      mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='0ce4ea70f52471edab61f7e7d6786302'),
      mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://your-bucket.oss-cn-shanghai.aliyuncs.com/your-video.mp4'),
      message?: string(name='Message', description='The returned message. Note: Pay attention to this parameter if the job failed.', example='The resource operated InputFile is bad'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-03-21T16:41:00Z'),
      projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='******faa3b542f5a6135217e3******'),
      status?: string(name='Status', description='The job state.', example='Sucess'),
      templateId?: string(name='TemplateId', description='The ID of the online editing template.', example='cb786a39c5d44cecb23d8c864facffc1'),
      userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"key":"value"}'),
    }
  ](name='MediaProducingJobList', description='The queried media editing and production jobs.'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListMediaProducingJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaProducingJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListMediaProducingJobs  ListMediaProducingJobsRequest
  * @return ListMediaProducingJobsResponse
 */
async function listMediaProducingJobs(request: ListMediaProducingJobsRequest): ListMediaProducingJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMediaProducingJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListPackageJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-15T00:00:00Z', position='Query'),
  jobId?: string(name='JobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb11cbe', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='ab4802364a2e49208c99efab82dfa8e8', position='Query'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

*   CreateTimeDesc: sorts the jobs by creation time in descending order.
*   CreateTimeAsc: sorts the jobs by creation time in ascending order.', example='CreateTimeDesc', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 0 to 100. Default value: 20.', example='10', position='Query'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-01T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The state of the job.

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success', position='Query'),
}

model ListPackageJobsResponseBody = {
  packageJobList?: {
    nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. The token of the next page is returned after you call this operation for the first time.', example='019daf5780f74831b0e1a767c9f1c178'),
    packageJobs?: [ 
      {
        code?: string(name='Code', description='The error code returned if the job fails.', example='InvalidParameter'),
        createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T14:00:32Z'),
        finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T15:00:32Z'),
        inputs?: [ 
          {
            input?: {
              media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
              type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
            }(name='Input', description='The information about the input stream file.'),
          }
        ](name='Inputs', description='The input of the job.'),
        jobId?: string(name='JobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb11cbe'),
        message?: string(name='Message', description='The error message that is returned.', example='Resource content bad.'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T15:00:32Z'),
        name?: string(name='Name', description='The name of the job.', example='job-name'),
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output of the job.'),
        pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='5b40833e4c3e4d4e95a866abb9a42510'),
        priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority. Default value: 6.', example='6'),
        status?: string(name='Status', description='The state of the job.', example='Success'),
        submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T14:00:32Z'),
        triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
        userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}'),
      }
    ](name='PackageJobs', description='The list of packaging jobs.'),
  }(name='PackageJobList', description='The list of packaging jobs.'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model ListPackageJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPackageJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListPackageJobs  ListPackageJobsRequest
  * @return ListPackageJobsResponse
 */
async function listPackageJobs(request: ListPackageJobsRequest): ListPackageJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListPackageJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListPipelinesRequest {
  speed?: string(name='Speed', description='The type of the MPS queue.

Valid values:

*   Boost: MPS queue with transcoding speed boosted.
*   Standard: standard MPS queue.
*   NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.', example='Standard', position='Query'),
}

model ListPipelinesResponseBody = {
  pipelineList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
      name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.', example='****20b48fb04483915d4f2cd8ac****'),
      priority?: int32(name='Priority', description='The priority of the MPS queue.', example='6'),
      speed?: string(name='Speed', description='The type of the MPS queue.', example='Standard'),
      status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Active'),
    }
  ](name='PipelineList', description='The queried MPS queues.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListPipelinesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPipelinesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListPipelines  ListPipelinesRequest
  * @return ListPipelinesResponse
 */
async function listPipelines(request: ListPipelinesRequest): ListPipelinesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListPipelines', 'POST', '/', 'json', false, 'json', request);
}

model ListPublicMediaBasicInfosRequest {
  regionId?: string(name='RegionId', position='Host'),
  businessType?: string(name='BusinessType', description='The business type of the media asset. Valid values:

*   sticker
*   bgm
*   bgi', example='sticker', position='Query'),
  includeFileBasicInfo?: boolean(name='IncludeFileBasicInfo', description='Specifies whether to return the basic information of the media asset.', example='true', position='Query'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.

Maximum value: 100. Default value: 10.', example='5', minimum=1, maximum=100, position='Query'),
  mediaTagId?: string(name='MediaTagId', description='The media tag. All media assets that contain the specified media tag are returned. Valid values:

*   Sticker tags:

    *   sticker-atmosphere
    *   sticker-bubble
    *   sticker-cute
    *   sticker-daily
    *   sticker-expression
    *   sticker-gif

*   Background music (BGM) tags:

    *   bgm-romantic
    *   bgm-cuisine
    *   bgm-chinese-style
    *   bgm-upbeat
    *   bgm-dynamic
    *   bgm-relaxing
    *   bgm-quirky
    *   bgm-beauty

*   Background image (BGI) tags:

    *   bgi-grad
    *   bgi-solid
    *   bgi-pic', example='ticker-atmosphere', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='pSa1SQ0wCe5pzVrQ6mWZEw==', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
}

model ListPublicMediaBasicInfosResponseBody = {
  maxResults?: int32(name='MaxResults', description='The maximum number of entries returned.', example='2'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='270112.12'),
            duration?: string(name='Duration', description='The duration.', example='10.040000'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='338990717'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='1080'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='1920'),
          }(name='FileBasicInfo', description='The basic information of the file, such as the duration and size.'),
        }
      ](name='FileInfoList', description='The file information of the media asset.'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.', example='video'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2021-01-08T16:52:04Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2021-01-08T16:52:04Z'),
        description?: string(name='Description', description='The description of the media asset.', example='description'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='sticker-daily'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2021-01-08T16:52:04Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='null'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information of the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******B7-7F87-4792-BFE9-63CD21******'),
  totalCount?: long(name='TotalCount', description='The total number of media assets that meet the specified conditions.', example='2'),
}

model ListPublicMediaBasicInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPublicMediaBasicInfosResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListPublicMediaBasicInfos  ListPublicMediaBasicInfosRequest
  * @return ListPublicMediaBasicInfosResponse
 */
async function listPublicMediaBasicInfos(request: ListPublicMediaBasicInfosRequest): ListPublicMediaBasicInfosResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListPublicMediaBasicInfos', 'POST', '/', 'json', false, 'json', request);
}

model ListSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  pageNo?: int32(name='PageNo', example='1', position='Query'),
  pageSize?: int32(name='PageSize', example='10', position='Query'),
}

model ListSearchLibResponseBody = {
  code?: string(name='Code', example='200'),
  requestId?: string(name='RequestId', example='******3B-0E1A-586A-AC29-742247******'),
  searchLibInfoList?: [ 
    {
      searchLibName?: string(name='SearchLibName', example='faceSearchLib'),
      status?: string(name='Status', example='normal'),
    }
  ](name='SearchLibInfoList'),
  success?: string(name='Success', example='true'),
}

model ListSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSearchLib  ListSearchLibRequest
  * @return ListSearchLibResponse
 */
async function listSearchLib(request: ListSearchLibRequest): ListSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model ListSmartJobsRequest {
  jobState?: string(name='JobState', description='The job state.

Valid values:

*   Finished: The job is complete.
*   Failed: The job failed.
*   Executing: The job is in progress.
*   Created: The job is created.', example='Finished', position='Query'),
  jobType?: string(name='JobType', description='The job type.

Valid values:

*   ASR: automatic speech recognition(job) job.
*   DynamicChart: dynamic chart job.
*   VideoTranslation: video translation job.
*   TextToSpeech: intelligent audio production job.', example='ASR', position='Query'),
  maxResults?: long(name='MaxResults', description='The maximum number of entries to return.

Default value: 10. Valid values: 1 to 100.', example='10', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****73f33c91-d59383e8280b****', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting parameter. By default, the query results are sorted by creation time in descending order.

Valid values:

*   CreationTime:Asc: sorted by creation time in ascending order.
*   CreationTime:Desc: sorted by creation time in descending order.', example='CreationTime:Desc', position='Query'),
}

model ListSmartJobsResponseBody = {
  maxResults?: string(name='MaxResults', description='The maximum number of entries returned on a single page. The value is set to the maximum number of entries returned on each page except for the last page. Valid example: 10,10,5. Invalid example: 10,5,10.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='CBB6BC61D08'),
  requestId?: string(name='RequestId', description='The request ID.', example='****9262E3DA-07FA-4862-FCBB6BC61D08*****'),
  smartJobList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2020-12-26T04:11:10Z'),
      description?: string(name='Description', description='The job description.', example='测试描述'),
      editingConfig?: string(name='EditingConfig', description='The editing configurations.', example='{"AudioConfig":{},"InputConfig":""}'),
      inputConfig?: {
        inputFile?: string(name='InputFile', description='The information about the input file.', example='oss://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        keyword?: string(name='Keyword', description='The keyword information.', example='测试关键词'),
      }(name='InputConfig', description='The input configurations.'),
      jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
      jobState?: string(name='JobState', description='The job state.

Valid values:

*   Finished: The job is complete.
*   Failed: The job failed.
*   Executing: The job is in progress.
*   Created: The job is created.', example='Finished'),
      jobType?: string(name='JobType', description='The job type.

Valid values:

*   ASR: ASR job.
*   DynamicChart: dynamic chart job.
*   TextToSpeech: intelligent audio production job.', example='ASR'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2020-12-26T04:11:10Z'),
      outputConfig?: {
        bucket?: string(name='Bucket', description='The Object Storage Service (OSS) bucket.', example='test-bucket'),
        object?: string(name='Object', description='The OSS object.', example='test-object'),
      }(name='OutputConfig', description='The output configurations.'),
      title?: string(name='Title', description='The job title.', example='测试标题'),
      userData?: string(name='UserData', description='The user-defined data.', example='{"user":"data"}'),
      userId?: long(name='UserId', description='The user ID.', example='1084506228******'),
    }
  ](name='SmartJobList', description='The queried intelligent jobs.'),
  totalCount?: string(name='TotalCount', description='Optional. The total number of entries returned. By default, this parameter is not returned.', example='110'),
}

model ListSmartJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSmartJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSmartJobs  ListSmartJobsRequest
  * @return ListSmartJobsResponse
 */
async function listSmartJobs(request: ListSmartJobsRequest): ListSmartJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSmartJobs', 'GET', '/', 'json', false, 'json', request);
}

model ListSmartSysAvatarModelsRequest {
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10', position='Query'),
  sdkVersion?: string(name='SdkVersion', position='Query'),
}

model ListSmartSysAvatarModelsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  smartSysAvatarModelList?: [ 
    {
      avatarId?: string(name='AvatarId', description='The ID of the digital human. The ID is required to submit a separate digital human rendering job or use the digital human image in an intelligent timeline.', example='yunqiao'),
      avatarName?: string(name='AvatarName', description='The name of the digital human.'),
      bitrate?: int32(name='Bitrate', description='The video bitrate.', example='4000'),
      coverUrl?: string(name='CoverUrl', description='The sample thumbnail URL of the digital human.', example='http://ice-pub-media.myalicdn.com/smart/avatarModel/coverDemo/yunqiao.mp4'),
      height?: int32(name='Height', description='The video height.', example='1920'),
      outputMask?: boolean(name='OutputMask', description='Indicates whether portrait mask rendering is supported.', example='false'),
      videoUrl?: string(name='VideoUrl', description='The sample video URL of the digital human.', example='http://ice-pub-media.myalicdn.com/smart/avatarModel/videoDemo/yunqiao.mp4'),
      width?: int32(name='Width', description='The video width.', example='1080'),
    }
  ](name='SmartSysAvatarModelList', description='The queried digital humans.'),
  totalCount?: int32(name='TotalCount', description='The total number of system digital human images returned.', example='4'),
}

model ListSmartSysAvatarModelsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSmartSysAvatarModelsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSmartSysAvatarModels  ListSmartSysAvatarModelsRequest
  * @return ListSmartSysAvatarModelsResponse
 */
async function listSmartSysAvatarModels(request: ListSmartSysAvatarModelsRequest): ListSmartSysAvatarModelsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSmartSysAvatarModels', 'POST', '/', 'json', false, 'json', request);
}

model ListSmartVoiceGroupsRequest {
}

model ListSmartVoiceGroupsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='627B30EB-1D0A-5C6D-8467-431626E0FA10'),
  voiceGroups?: [ 
    {
      type?: string(name='Type', description='The name of the speaker group.'),
      voiceList?: [ 
        {
          desc?: string(name='Desc', description='The speaker description.'),
          name?: string(name='Name', description='The speaker name.'),
          remark?: string(name='Remark', description='The remarks of the speaker.'),
          supportSampleRate?: string(name='SupportSampleRate'),
          tag?: string(name='Tag', description='The tag of the speaker type.'),
          voice?: string(name='Voice', description='The speaker ID.', example='zhitian'),
          voiceType?: string(name='VoiceType', description='The speaker type.

Valid values:

*   Male
*   Female
*   Boy
*   Girl', example='Female'),
          voiceUrl?: string(name='VoiceUrl', description='The URL of the sample audio file.', example='https://***.com/zhiqing.mp3'),
        }
      ](name='VoiceList', description='The speakers.'),
    }
  ](name='VoiceGroups', description='The queried speaker groups.'),
}

model ListSmartVoiceGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSmartVoiceGroupsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSmartVoiceGroups  ListSmartVoiceGroupsRequest
  * @return ListSmartVoiceGroupsResponse
 */
async function listSmartVoiceGroups(request: ListSmartVoiceGroupsRequest): ListSmartVoiceGroupsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSmartVoiceGroups', 'GET', '/', 'json', false, 'json', request);
}

model ListSnapshotJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created.', example='2022-07-14T00:00:00Z', position='Query'),
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results.

1.  CreateTimeDesc
2.  CreateTimeAsc

Valid values:

*   CreateTimeDesc: sorts the jobs by creation time in descending order
*   CreateTimeAsc: sorts the jobs by creation time in ascending order.', example='CreateTimeDesc', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Maximum value: 100.', example='20', position='Query'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created.', example='2022-07-12T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success', position='Query'),
}

model ListSnapshotJobsResponseBody = {
  jobs?: [ 
    {
      async?: boolean(name='Async', description='Indicates whether the snapshots were captured in asynchronous mode.', example='true'),
      count?: int32(name='Count', description='The number of snapshots.', example='10'),
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
      input?: {
        media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats: 1. OSS://bucket/object 2. http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://bucket/object.mp4'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
      }(name='Input', description='The input of the job.'),
      jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
      name?: string(name='Name', description='The name of the job.', example='SampleJob'),
      output?: {
        media?: string(name='Media', description='The output file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS. If multiple static snapshots were captured, the object must contain the "{Count}" placeholder. In the case of a sprite, the object must contain the "{TileCount}" placeholder. The suffix of the WebVTT snapshot objects must be ".vtt".', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/output-{Count}.jpg'),
        type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.', example='OSS'),
      }(name='Output', description='The output of the job.'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****20b48fb04483915d4f2cd8ac****'),
      status?: string(name='Status', description='The state of the job.

*   **Success**: The job is successful.
*   **Fail**: The job failed.
*   **Init**: The job is submitted.', example='Success'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
      triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
      type?: string(name='Type', description='The type of the job.

Valid values:

*   WebVtt
*   Sprite
*   Normal', example='Sprite'),
    }
  ](name='Jobs', description='The list of jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListSnapshotJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSnapshotJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSnapshotJobs  ListSnapshotJobsRequest
  * @return ListSnapshotJobsResponse
 */
async function listSnapshotJobs(request: ListSnapshotJobsRequest): ListSnapshotJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSnapshotJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListSystemTemplatesRequest {
  name?: string(name='Name', description='The template name.', example='SampleTemplate', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20 Valid values: 1 to 100.', example='20', position='Query'),
  status?: string(name='Status', description='The template state. Valid values: Normal, Invisible, and All.', example='Normal', position='Query'),
  subtype?: string(name='Subtype', description='The subtype ID of the template.', example='1', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****', position='Query'),
  type: string(name='Type', description='The template type. Separate multiple types with commas (,).

This parameter is required.', example='1,2', position='Query'),
}

model ListSystemTemplatesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  systemTemplateList?: [ 
    {
      status?: string(name='Status', description='The template state.', example='Normal'),
      subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='1'),
      subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='Remux'),
      templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Container":{"Format":"flv"},"Video":{},"Audio":{}}'),
      templateId?: string(name='TemplateId', description='The template ID.', example='S00000001-000000'),
      templateName?: string(name='TemplateName', description='The template name.', example='FLV-COPY'),
      type?: int32(name='Type', description='The type ID of the template.', example='1'),
      typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
    }
  ](name='SystemTemplateList', description='The queried templates.'),
  total?: int32(name='Total', description='The total number of templates.', example='20'),
}

model ListSystemTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSystemTemplatesResponseBody(name='body'),
}

/**
  * @description Template types:
  * 1.  1: transcoding template.
  * 2.  2: snapshot template.
  * 3.  3: animated image template.
  * 4.  4\\. image watermark template.
  * 5.  5: text watermark template.
  * 6.  6: subtitle template.
  * 7.  7: AI-assisted content moderation template.
  * 8.  8: AI-assisted intelligent thumbnail template.
  * 9.  9: AI-assisted intelligent erasure template.
  * Subtypes of transcoding templates:
  * 1.  1 (Normal): regular template.
  * 2.  2 (AudioTranscode): audio transcoding template.
  * 3.  3 (Remux): container format conversion template.
  * 4.  4 (NarrowBandV1): Narrowband HD 1.0 template.
  * 5.  5 (NarrowBandV2): Narrowband HD 2.0 template.
  * Subtypes of snapshot templates:
  * 1.  1 (Normal): regular template.
  * 2.  2 (Sprite): sprite template.
  * 3.  3 (WebVtt): WebVTT template.
  * Subtypes of AI-assisted content moderation templates:
  * 1.  1 (Video): video moderation template.
  * 2.  2 (Audio): audio moderation template.
  * 3.  3 (Image): image moderation template.
  * Subtypes of AI-assisted intelligent erasure templates:
  * 1.  1 (VideoDelogo): logo erasure template.
  * 2.  2 (VideoDetext): subtitle erasure template.
  * @param request  the request parameters of ListSystemTemplates  ListSystemTemplatesRequest
  * @return ListSystemTemplatesResponse
 */
async function listSystemTemplates(request: ListSystemTemplatesRequest): ListSystemTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSystemTemplates', 'POST', '/', 'json', false, 'json', request);
}

model ListTemplatesRequest {
  createSource?: string(name='CreateSource', description='The source from which the template was created.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI', position='Query'),
  keyword?: string(name='Keyword', description='The search keyword. You can use the template ID or title as the keyword to search for templates.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='20', position='Query'),
  sortType?: string(name='SortType', description='The sorting parameter. By default, the query results are sorted by creation time in descending order.

Valid values:

*   CreationTime:Asc: sorted by creation time in ascending order.
*   CreationTime:Desc: sorted by creation time in descending order.', example='CreationTime:Desc', position='Query'),
  status?: string(name='Status', description='The template state.

Valid values:

*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.
*   Available: The template is available.
*   Uploading: The video is being uploaded.
*   Created: The template is created but not ready for use.
*   Processing: The advanced template is being processed.', example='Available', position='Query'),
  type?: string(name='Type', description='The template type.

Valid values:

*   Timeline
*   VETemplate', example='Timeline', position='Query'),
}

model ListTemplatesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  templates?: [ 
    {
      clipsParam?: string(name='ClipsParam', description='The clip parameters.', example='{"Media1":"mediaId","Text1":"text"}'),
      config?: string(name='Config', description='The template configurations.', example='参考Timeline模板配置详解'),
      coverURL?: string(name='CoverURL', description='The thumbnail URL.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
      createSource?: string(name='CreateSource', description='The source from which the template was created.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
      creationTime?: string(name='CreationTime', description='The time when the template was created.', example='2020-12-26T04:11:10Z'),
      modifiedSource?: string(name='ModifiedSource', description='The source from which the template was modified.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2020-12-26T04:11:10Z'),
      name?: string(name='Name', description='The template name.', example='视频添加水印模板'),
      previewMedia?: string(name='PreviewMedia', description='The preview media asset.', example='****20b48fb04483915d4f2cd8ac****'),
      previewMediaStatus?: string(name='PreviewMediaStatus', description='The state of the preview media asset.

Valid values:

*   PrepareFail
*   Init
*   Normal
*   Preparing', example='Normal'),
      status?: string(name='Status', description='The template state.

Valid values:

*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.
*   Available: The template is available.
*   Uploading: The video is being uploaded.
*   Created: The template is created but not ready for use.
*   Processing: The advanced template is being processed.', example='Available'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
      type?: string(name='Type', description='The template type.

Valid values:

*   Timeline: regular template.
*   VETemplate: advanced template.', example='Timeline'),
    }
  ](name='Templates', description='The queried templates.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTemplatesResponseBody(name='body'),
}

/**
  * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
  * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/270942.html).
  * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/291418.html).
  * @param request  the request parameters of ListTemplates  ListTemplatesRequest
  * @return ListTemplatesResponse
 */
async function listTemplates(request: ListTemplatesRequest): ListTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTemplates', 'POST', '/', 'json', false, 'json', request);
}

model ListTranscodeJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-15T00:00:00Z', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='ab4802364a2e49208c99efab82dfa8e8', position='Query'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

*   CreateTimeDesc: sorts the query results by creation time in descending order.
*   CreateTimeAsc: sorts the query results by creation time in ascending order.', example='CreateTimeDesc', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 0 to 100. Default value: 20.', example='10', position='Query'),
  parentJobId?: string(name='ParentJobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb1****', position='Query'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-01T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The state of the job.

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success', position='Query'),
}

model ListTranscodeJobsResponseBody = {
  jobs?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      inputGroup?: [ 
        {
          inputUrl?: string(name='InputUrl', description='The URL of the media asset. This parameter is specified only when the media asset is transcoded.', example='oss://bucket/path/to/video.mp4'),
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
        }
      ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
      jobCount?: int32(name='JobCount', description='The number of subjobs.', example='1'),
      name?: string(name='Name', description='The job name.', example='transcode-job'),
      outputGroup?: [ 
        {
          output?: {
            media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
            outputUrl?: string(name='OutputUrl', description='The URL of the transcoded output stream. This parameter is required only when the output is a media asset.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
            type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
          }(name='Output', description='The output file configuration.'),
          processConfig?: {
            combineConfigs?: [ 
              {
                audioIndex: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
                duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
                start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
                videoIndex: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
              }
            ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
            encryption?: {
              cipherText?: string(name='CipherText', description='The ciphertext of HTTP Live Streaming (HLS) encryption.', example='MTYi00NDU0LTg5O****'),
              decryptKeyUri?: string(name='DecryptKeyUri', description='The endpoint of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
              encryptType?: string(name='EncryptType', description='The encryption type.', example='PrivateEncryption'),
            }(name='Encryption', description='The encryption settings.'),
            imageWatermarks?: [ 
              {
                overwriteParams?: {
                  dx?: string(name='Dx', description='The position of the watermark on the x-axis.', example='10'),
                  dy?: string(name='Dy', description='The position of the watermark on the y-axis.', example='10'),
                  file?: {
                    media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                    type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                  }(name='File', description='The watermark image file.'),
                  height?: string(name='Height', description='The height of the output video.', example='32'),
                  referPos?: string(name='ReferPos', description='The reference position of the watermark. Valid values: TopLeft, TopRight, BottomLeft, and BottomRight. Default value: TopLeft.', example='TopLeft'),
                  timeline?: {
                    duration?: string(name='Duration', description='The duration of the stream. Valid values: the number of seconds or "ToEND".', example='ToEND'),
                    start?: string(name='Start', description='The beginning of the time range for which data was queried.', example='00:00:05'),
                  }(name='Timeline', description='The timeline settings.'),
                  width?: string(name='Width', description='The width of the output video.', example='32'),
                }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
                templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
              }
            ](name='ImageWatermarks', description='The watermark configuration for an image.'),
            isInheritTags?: boolean(name='IsInheritTags', description='Indicates whether the tags of the input stream are inherited in the output stream. This parameter does not take effect when the input is not a media asset. Default value: false.'),
            subtitles?: [ 
              {
                overwriteParams?: {
                  charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                  file?: {
                    media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                    type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                  }(name='File', description='The subtitle file.'),
                  format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
                }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
                templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
              }
            ](name='Subtitles', description='The subtitle configuration.'),
            textWatermarks?: [ 
              {
                overwriteParams?: {
                  adaptive?: string(name='Adaptive', description='Indicates whether the text size was adjusted based on the output video dimensions. true / false, default: false', example='false'),
                  borderColor?: string(name='BorderColor', description='The border color.', example='#006400'),
                  borderWidth?: int32(name='BorderWidth', description='The border width.', example='0'),
                  content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                  fontAlpha?: string(name='FontAlpha', description='The transparency of the watermark.', example='1.0'),
                  fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                  fontName?: string(name='FontName', description='The font of the text.', example='SimSun'),
                  fontSize?: int32(name='FontSize', description='The size of the text.', example='16'),
                  left?: string(name='Left', description='The distance of the watermark from the left edge.', example='10'),
                  top?: string(name='Top', description='The distance of the watermark from the top edge.', example='10'),
                }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
                templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
              }
            ](name='TextWatermarks', description='The configurations of the text watermarks.'),
            transcode?: {
              overwriteParams?: {
                audio?: {
                  bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                  channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                  codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                  profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                  remove?: string(name='Remove', description='Indicates whether the audio stream is deleted.', example='false'),
                  samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100.
*   Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                  volume?: {
                    integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                    loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                    method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                    truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                  }(name='Volume', description='The volume configurations.'),
                }(name='Audio', description='The audio settings.'),
                container?: {
                  format?: string(name='Format', description='The container format.', example='mp4'),
                }(name='Container', description='The encapsulation format settings.'),
                muxConfig?: {
                  segment?: {
                    duration?: string(name='Duration', description='The segment length.', example='10'),
                    forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                  }(name='Segment', description='The segment settings.'),
                }(name='MuxConfig', description='The encapsulation settings.'),
                tags?: map[string]string(name='Tags'),
                video?: {
                  abrMax?: string(name='AbrMax', description='The maximum adaptive bitrate (ABR). This parameter takes effect only for Narrowband HD 1.0. Valid values: [10,50000]. Unit: Kbit/s.', example='6000'),
                  bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                  bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                  codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                  crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.

If this parameter is set, the value of Bitrate becomes invalid.', example='23'),
                  crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                  fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                  gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                  height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                  longShortMode?: string(name='LongShortMode', description='Indicates whether the auto-rotate screen feature is enabled.', example='false'),
                  maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video. Valid values: [10,50000]. Unit: Kbit/s.', example='9000'),
                  pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                  pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                  preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                  profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                  remove?: string(name='Remove', description='Indicates whether the video was removed.', example='false'),
                  scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                  width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
                }(name='Video', description='The video settings.'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }(name='Transcode', description='The transcoding configuration.'),
          }(name='ProcessConfig', description='The job processing configuration.'),
        }
      ](name='OutputGroup', description='The output group of the job.'),
      parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
      percent?: int32(name='Percent', description='The completion percentage of the job.', example='0'),
      requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
      scheduleConfig?: {
        pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
        priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
      }(name='ScheduleConfig', description='The scheduling configuration of the job.'),
      status?: string(name='Status', description='The state of the job.

*   Success: At least one of the subjobs is successful.
*   Fail: All subjobs failed.', example='Success'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
      userData?: string(name='UserData', description='The user data.', example='user-data'),
    }
  ](name='Jobs', description='The list of jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. The token of the next page is returned after you call this operation for the first time.', example='019daf5780f74831b0e1a767c9f1c178'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model ListTranscodeJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTranscodeJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListTranscodeJobs  ListTranscodeJobsRequest
  * @return ListTranscodeJobsResponse
 */
async function listTranscodeJobs(request: ListTranscodeJobsRequest): ListTranscodeJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTranscodeJobs', 'POST', '/', 'json', false, 'json', request);
}

model QueryDNAJobListRequest {
  jobIds?: string(name='JobIds', description='The IDs of the media fingerprint analysis jobs that you want to query. We recommend that you query at most 10 jobs at a time. Separate multiple job IDs with commas (,).', example='88c6ca184c0e47098a5b665e2a12****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model QueryDNAJobListResponseBody = {
  jobList?: [ 
    {
      code?: string(name='Code', description='The response code.', example='"InvalidParameter.ResourceNotFound"'),
      config?: string(name='Config', description='The configurations of the media fingerprint analysis job.', example='{"SaveType": "save","MediaType"":"video"}'),
      creationTime?: string(name='CreationTime', description='The time when the job was created.', example='2022-12-28T03:21:37Z'),
      DBId?: string(name='DBId', description='The ID of the media fingerprint library.', example='2288c6ca184c0e47098a5b665e2a12****'),
      DNAResult?: string(name='DNAResult', description='The URL of the media fingerprint analysis result.', example='http://test_bucket.oss-cn-shanghai.aliyuncs.com/fingerprint/video/search_result/5/5.txt'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-12-28T03:21:44Z'),
      id?: string(name='Id', description='The job ID.', example='88c6ca184c0e47098a5b665e2a12****'),
      input?: {
        media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. The path of an OSS object can be in one of the following formats:

1\\. oss://bucket/object

2\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the preceding paths, bucket indicates an OSS bucket that resides in the same region as the current project, and object indicates the path of the object in the bucket.', example='1b1b9cd148034739af413150fded****'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: Object Storage Service (OSS) object.
2.  Media: media asset.', example='Media'),
      }(name='Input', description='The details of the input file.'),
      message?: string(name='Message', description='The returned message.', example='"The resource operated \\"a887d0b***d805ef6f7f6786302\\" cannot be found"'),
      primaryKey?: string(name='PrimaryKey', description='The primary key of the video. You must make sure that each primary key is unique.', example='3ca84a39a9024f19853b21be9cf9****'),
      status?: string(name='Status', description='The job state. Valid values:

*   **Queuing**: The job is waiting in the queue.
*   **Analysing**: The job is in progress.
*   **Success**: The job is successful.
*   **Fail**: The job failed.', example='Queuing'),
      userData?: string(name='UserData', description='The user-defined data.', example='testdna'),
    }
  ](name='JobList', description='The queried media fingerprint analysis jobs.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model QueryDNAJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryDNAJobListResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QueryDNAJobList  QueryDNAJobListRequest
  * @return QueryDNAJobListResponse
 */
async function queryDNAJobList(request: QueryDNAJobListRequest): QueryDNAJobListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryDNAJobList', 'POST', '/', 'json', false, 'json', request);
}

model QueryIProductionJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', position='Query'),
  jobId: string(name='JobId', description='The ID of the intelligent production job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model QueryIProductionJobResponseBody = {
  createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-07T07:16:11Z'),
  finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2021-11-26T14:50:25Z'),
  functionName?: string(name='FunctionName', description='The name of the algorithm that you want to use for the job. Valid values:

*   **Cover**: This algorithm intelligently generates a thumbnail image for a video.
*   **VideoClip**: This algorithm intelligently generates a summary for a video.
*   **VideoDelogo**: This algorithm removes logos from a video.
*   **VideoDetext**: This algorithm removes captions from a video.', example='Cover'),
  input?: {
    media?: string(name='Media', description='The input file. If Type is set to OSS, set this parameter to the path of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.', example='oss://bucket/object'),
    type?: string(name='Type', description='The media type. Valid values:

1.  OSS: Object Storage Service (OSS) object
2.  Media: media asset', example='OSS'),
  }(name='Input', description='The input file.'),
  jobId?: string(name='JobId', description='The ID of the intelligent production job.', example='****20b48fb04483915d4f2cd8ac****'),
  jobParams?: string(name='JobParams', description='The algorithm-specific parameters. The parameters are specified as JSON objects and vary based on the algorithm.', example='{"Model":"gif"}'),
  name?: string(name='Name', description='The name of the intelligent production job.'),
  output?: {
    media?: string(name='Media', description='The output file. If Type is set to OSS, set this parameter to the path of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.', example='oss://bucket/object'),
    type?: string(name='Type', description='The media type. Valid values:

*   OSS: OSS object
*   Media: media asset', example='OSS'),
  }(name='Output', description='The output file.'),
  outputFiles?: [ string ](name='OutputFiles', description='The output files.'),
  outputUrls?: [ string ](name='OutputUrls', description='The URLs of the output files.'),
  requestId?: string(name='RequestId', description='The ID of the request.'),
  result?: string(name='Result', description='The output of the algorithm. The output is in JSON format and varies based on the algorithm. For more information, see the "Parameters of Result" section of this topic.', example='{}'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue.', example='a54fdc9c9aab413caef0d1150f565e86'),
    priority?: int32(name='Priority', description='The priority of the job in the MPS queue to which the job is added.

*   A value of 10 indicates the highest priority.
*   Default value: **6**.', example='6'),
  }(name='ScheduleConfig', description='The scheduling configuration.'),
  status?: string(name='Status', description='The status of the job. Valid values:

*   Queuing: The job is waiting in the queue.
*   Analysing: The job is in progress.
*   Fail: The job failed.
*   Success: The job was successful.', example='Success'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
  userData?: string(name='UserData', description='The user-defined data that is returned in the response.', example='{"test":1}'),
}

model QueryIProductionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryIProductionJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QueryIProductionJob  QueryIProductionJobRequest
  * @return QueryIProductionJobResponse
 */
async function queryIProductionJob(request: QueryIProductionJobRequest): QueryIProductionJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryIProductionJob', 'POST', '/', 'json', false, 'json', request);
}

model QueryMediaCensorJobDetailRequest {
  jobId: string(name='JobId', description='The ID of the content moderation job. You can obtain the job ID from the response parameters of the [SubmitMediaCensorJob](https://help.aliyun.com/document_detail/444848.html) operation.

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****', position='Query'),
  maximumPageSize?: long(name='MaximumPageSize', description='The number of entries per page.

*   Default value: **30**.
*   Valid values: **1 to 300**.', example='30', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='ae0fd49c0840e14daf0d66a75b83****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model QueryMediaCensorJobDetailResponseBody = {
  mediaCensorJobDetail?: {
    barrageCensorResult?: {
      label?: string(name='Label', description='The label of the moderation result. Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='normal'),
      rate?: string(name='Rate', description='The score.', example='99.91'),
      scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
    }(name='BarrageCensorResult', description='The moderation results of live comments.'),
    code?: string(name='Code', description='The error code returned if the job failed. This parameter is not returned if the job is successful.', example='InvalidParameter.ResourceNotFound'),
    coverImageCensorResults?: {
      coverImageCensorResult?: [ 
      {
        bucket?: string(name='Bucket', description='The OSS bucket in which the thumbnail is stored.', example='bucket-out-test-****'),
        location?: string(name='Location', description='The OSS region in which the thumbnail resides.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The Object Storage Service (OSS) object that is used as the thumbnail.', example='test/ai/censor/v2/vme-****.jpg'),
        results?: {
          result?: [ 
          {
            label?: string(name='Label', description='The label of the moderation result.

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live broadcasting in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='Normal'),
            rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
            scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='Antispam'),
            suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
          }
        ](name='Result')
        }(name='Results', description='The moderation results.'),
      }
    ](name='CoverImageCensorResult')
    }(name='CoverImageCensorResults', description='The moderation results of thumbnails.'),
    creationTime?: string(name='CreationTime', description='The time when the content moderation job was created.', example='2018-09-13T16:32:24Z'),
    descCensorResult?: {
      label?: string(name='Label', description='The label of the moderation result. Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='terrorism'),
      rate?: string(name='Rate', description='The score.', example='100'),
      scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='review'),
    }(name='DescCensorResult', description='The moderation results of descriptions.'),
    finishTime?: string(name='FinishTime', description='The time when the content moderation job was complete.', example='2018-09-13T16:38:24Z'),
    input?: {
      bucket?: string(name='Bucket', description='The name of the OSS bucket in which the input file is stored.', example='bucket-test-in-****'),
      location?: string(name='Location', description='The OSS region in which the input file resides.', example='oss-cn-shanghai'),
      object?: string(name='Object', description='The name of the OSS object that is used as the input file.', example='test/ai/censor/test-****.mp4'),
    }(name='Input', description='The information about the job input.'),
    jobId?: string(name='JobId', description='The ID of the content moderation job.', example='f8f166eea7a44e9bb0a4aecf9543****'),
    message?: string(name='Message', description='The error message returned if the job failed. This parameter is not returned if the job is successful.', example='The resource operated cannot be found'),
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the job was submitted.', example='c5b30b7c0d0e4a0abde1d5f9e751****'),
    state?: string(name='State', description='The job state.', example='Success'),
    suggestion?: string(name='Suggestion', description='The overall result of the content moderation job. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.

>  If the moderation result of any type of content is review, the overall result is review. If the moderation result of any type of content is block, the overall result is block.', example='block'),
    titleCensorResult?: {
      label?: string(name='Label', description='The label of the moderation result. Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='meaningless'),
      rate?: string(name='Rate', description='The score.', example='99.91'),
      scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
    }(name='TitleCensorResult', description='The moderation results of titles.'),
    userData?: string(name='UserData', description='The user-defined data.', example='example userdata ****'),
    vensorCensorResult?: {
      censorResults?: {
        censorResult?: [ 
        {
          label?: string(name='Label', description='The label of the moderation result.

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live broadcasting in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='meaningless'),
          rate?: string(name='Rate', description='The score.', example='100'),
          scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='terrorism'),
          suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='review'),
        }
      ](name='CensorResult')
      }(name='CensorResults', description='A collection of moderation results. The information includes the summary about various scenarios such as pornographic content moderation and terrorist content moderation.'),
      nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='ea04afcca7cd4e80b9ece8fbb251****'),
      videoTimelines?: {
        videoTimeline?: [ 
        {
          censorResults?: {
            censorResult?: [ 
            {
              label?: string(name='Label', description='The label of the moderation result.

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live broadcasting in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='flood'),
              rate?: string(name='Rate', description='The score.', example='99.99'),
              scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='porn'),
              suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
            }
          ](name='CensorResult')
          }(name='CensorResults', description='The moderation results that include information such as labels and scores.'),
          object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg`, `output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
          timestamp?: string(name='Timestamp', description='The position in the video. Format: `hh:mm:ss[.SSS]`.', example='00:02:59.999'),
        }
      ](name='VideoTimeline')
      }(name='VideoTimelines', description='The moderation results that are sorted in ascending order by time.'),
    }(name='VensorCensorResult', description='The moderation results of videos.'),
    videoCensorConfig?: {
      bizType?: string(name='BizType', description='The custom business type. Default value: common.', example='common'),
      outputFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket in which the output snapshot is stored.', example='test-bucket-****'),
        location?: string(name='Location', description='The OSS region in which the output snapshot resides.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg`, `output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
      }(name='OutputFile', description='The information about output snapshots.'),
      videoCensor?: string(name='VideoCensor', description='Indicates whether the video content needs to be moderated. Default value: **true**. Valid values:

*   **true**: The video content needs to be moderated.
*   **false**: The video content does not need to be moderated.', example='true'),
    }(name='VideoCensorConfig', description='The video moderation configurations.'),
  }(name='MediaCensorJobDetail', description='The results of the content moderation job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='B42299E6-F71F-465F-8FE9-4FC2E3D3C2CA'),
}

model QueryMediaCensorJobDetailResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryMediaCensorJobDetailResponseBody(name='body'),
}

/**
  * @description In the content moderation results, the moderation results of the video are sorted in ascending order by time into a timeline. If the video is long, the content moderation results are paginated, and the first page is returned. You can call this operation again to query the remaining moderation results of the video.
  * @param request  the request parameters of QueryMediaCensorJobDetail  QueryMediaCensorJobDetailRequest
  * @return QueryMediaCensorJobDetailResponse
 */
async function queryMediaCensorJobDetail(request: QueryMediaCensorJobDetailRequest): QueryMediaCensorJobDetailResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryMediaCensorJobDetail', 'POST', '/', 'json', false, 'json', request);
}

model QueryMediaCensorJobListRequest {
  endOfJobCreatedTimeRange?: string(name='EndOfJobCreatedTimeRange', description='The end of the time range to query.

*   Specify the time in the ISO 8601 standard. The time must be in UTC.
*   Format: yyyy-MM-ddTHH:mm:ssZ.', example='2022-02-14T02:16:07Z', position='Query'),
  jobIds?: string(name='JobIds', description='The IDs of the content moderation jobs. You can obtain the ID of a content moderation job from the response parameters of the SubmitMediaCensorJob operation. Separate multiple IDs with commas (,).', example='fa9c34be3bcf42919ac4d1775239****,78dc866518b843259669df58ed30****', position='Query'),
  maximumPageSize?: long(name='MaximumPageSize', description='The number of entries per page.

*   Default value: **30**.
*   Valid values: **1 to 300**.', example='20', minimum=1, maximum=100, position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='79aff3eee82242e092899db5f669', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the jobs were submitted.', example='c5b30b7c0d0e4a0abde1d5f9e751****', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  startOfJobCreatedTimeRange?: string(name='StartOfJobCreatedTimeRange', description='The beginning of the time range to query.

*   Specify the time in the ISO 8601 standard. The time must be in UTC.
*   Format: yyyy-MM-ddTHH:mm:ssZ.', example='2021-12-22T03:48:05Z', position='Query'),
  state?: string(name='State', description='The state of the jobs that you want to query. Valid values:

*   **All**: all jobs.
*   **Queuing**: the jobs that are waiting in the queue.
*   **Analysing**: the jobs that are in progress.
*   **Fail**: failed jobs.
*   **Success**: successful jobs.', example='All', position='Query'),
}

model QueryMediaCensorJobListResponseBody = {
  mediaCensorJobList?: {
    mediaCensorJob?: [ 
    {
      barrageCensorResult?: {
        label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,). Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='normal'),
        rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='99.91'),
        scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
        suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
      }(name='BarrageCensorResult', description='The moderation results of live comments.'),
      code?: string(name='Code', description='The error code returned if the job failed. This parameter is not returned if the job is successful.', example='InvalidParameter.ResourceNotFound'),
      coverImageCensorResults?: {
        coverImageCensorResult?: [ 
        {
          bucket?: string(name='Bucket', description='The OSS bucket in which the thumbnail is stored.', example='example-Bucket-****'),
          location?: string(name='Location', description='The OSS region in which the thumbnail resides.', example='oss-cn-shanghai'),
          object?: string(name='Object', description='The Object Storage Service (OSS) object that is used as the thumbnail.', example='test/ai/censor/v2/vme-****.jpg'),
          results?: {
            result?: [ 
            {
              label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,).

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live streaming in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='normal'),
              rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
              scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='live'),
              suggestion?: string(name='Suggestion', description='The overall result of the moderation job. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.

>  If the moderation result of any type of content is review, the overall result is review. If the moderation result of any type of content is block, the overall result is block.', example='pass'),
            }
          ](name='Result')
          }(name='Results', description='The moderation results.'),
        }
      ](name='CoverImageCensorResult')
      }(name='CoverImageCensorResults', description='The moderation results of thumbnails.'),
      creationTime?: string(name='CreationTime', description='The time when the content moderation job was created.', example='2021-11-04T07:25:48Z'),
      descCensorResult?: {
        label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,). Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='normal'),
        rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
        scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
        suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
      }(name='DescCensorResult', description='The moderation results of descriptions.'),
      finishTime?: string(name='FinishTime', description='The time when the content moderation job was complete.', example='2021-11-04T07:25:50Z'),
      input?: {
        bucket?: string(name='Bucket', description='The name of the OSS bucket in which the input file is stored.', example='bucket-test-in-****'),
        location?: string(name='Location', description='The OSS region in which the input file resides.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The name of the OSS object that is used as the input file.', example='test/ai/censor/test-****.mp4'),
      }(name='Input', description='The information about the job input.'),
      jobId?: string(name='JobId', description='The ID of the content moderation job.', example='f8f166eea7a44e9bb0a4aecf9543'),
      message?: string(name='Message', description='The error message returned if the job failed. This parameter is not returned if the job is successful.', example='The resource operated cannot be found'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='c5b30b7c0d0e4a0abde1d5f9e751****'),
      state?: string(name='State', description='The job state.', example='Success'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
      titleCensorResult?: {
        label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,). Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='meaningless'),
        rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
        scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
        suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
      }(name='TitleCensorResult', description='The moderation results of titles.'),
      userData?: string(name='UserData', description='The user-defined data.', example='example userdata ****'),
      vensorCensorResult?: {
        censorResults?: {
          censorResult?: [ 
          {
            label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,).

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live streaming in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='meaningless'),
            rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
            scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='ad'),
            suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
          }
        ](name='CensorResult')
        }(name='CensorResults', description='A collection of moderation results. The information includes the summary about various scenarios such as pornographic content moderation and terrorist content moderation.'),
        nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='ea04afcca7cd4e80b9ece8fbb251'),
        videoTimelines?: {
          videoTimeline?: [ 
          {
            censorResults?: {
              censorResult?: [ 
              {
                label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,).

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live streaming in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='normal'),
                rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
                scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='porn'),
                suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
              }
            ](name='CensorResult')
            }(name='CensorResults', description='The moderation results that include information such as labels and scores.'),
            object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg`, `output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
            timestamp?: string(name='Timestamp', description='The position in the video. Format: `hh:mm:ss[.SSS]`.', example='00:02:59.999'),
          }
        ](name='VideoTimeline')
        }(name='VideoTimelines', description='The moderation results that are sorted in ascending order by time.'),
      }(name='VensorCensorResult', description='The moderation results of videos.'),
      videoCensorConfig?: {
        bizType?: string(name='BizType', description='The moderation template. Default value: common. The default value indicates that the default template is used.

>  If the moderation template is not specified, the default value common is returned. If a custom moderation template that is created by submitting a ticket is specified, the UID of the template is returned.', example='common'),
        outputFile?: {
          bucket?: string(name='Bucket', description='The OSS bucket in which the output snapshot is stored.', example='test-bucket-****'),
          location?: string(name='Location', description='The ID of the region in which the output snapshot resides.', example='oss-cn-shanghai'),
          object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg, output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
        }(name='OutputFile', description='The information about output snapshots.'),
        videoCensor?: string(name='VideoCensor', description='Indicates whether the video content needs to be moderated. Default value: **true**. Valid values:

*   **true**: The video content needs to be moderated.
*   **false**: The video content does not need to be moderated.', example='true'),
      }(name='VideoCensorConfig', description='The video moderation configurations.'),
    }
  ](name='MediaCensorJob')
  }(name='MediaCensorJobList', description='The queried content moderation jobs.'),
  nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. The value is 32-character UUID. If the returned query results cannot be displayed within one page, this parameter is returned. The value of this parameter is updated for each query.', example='9b1a42bc6e8d46e6a1383b7e7f01****'),
  nonExistIds?: {
    string?: [ string ](name='String')
  }(name='NonExistIds', description='The IDs of the jobs that do not exist. This parameter is not returned if all the specified jobs are found.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D1D5C080-8E2F-5030-8AB4-13092F17631B'),
}

model QueryMediaCensorJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryMediaCensorJobListResponseBody(name='body'),
}

/**
  * @description You can call this operation to query only the content moderation jobs within the most recent three months.
  * @param request  the request parameters of QueryMediaCensorJobList  QueryMediaCensorJobListRequest
  * @return QueryMediaCensorJobListResponse
 */
async function queryMediaCensorJobList(request: QueryMediaCensorJobListRequest): QueryMediaCensorJobListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryMediaCensorJobList', 'POST', '/', 'json', false, 'json', request);
}

model QueryMediaIndexJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='c2e77390f75271ec802f0674a2ce6***', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1', position='Query'),
}

model QueryMediaIndexJobResponseBody = {
  code?: string(name='Code', description='The response code.', example='200'),
  indexJobInfoList?: [ 
    {
      gmtFinish?: string(name='GmtFinish', description='The end time of the indexing job.', example='2023-11-21 11:33:51'),
      gmtSubmit?: string(name='GmtSubmit', description='The time when the index job was submitted.', example='2023-11-21 11:33:50'),
      indexType?: string(name='IndexType', description='The index type. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.', example='mm'),
      status?: string(name='Status', description='The job status. Valid values:

*   Running
*   Success
*   Fail', example='Success'),
    }
  ](name='IndexJobInfoList', description='The indexing jobs enabled for the media asset.'),
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model QueryMediaIndexJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryMediaIndexJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QueryMediaIndexJob  QueryMediaIndexJobRequest
  * @return QueryMediaIndexJobResponse
 */
async function queryMediaIndexJob(request: QueryMediaIndexJobRequest): QueryMediaIndexJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryMediaIndexJob', 'POST', '/', 'json', false, 'json', request);
}

model QuerySearchIndexRequest {
  regionId?: string(name='RegionId', position='Host'),
  indexType: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.

This parameter is required.', example='mm', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

*   If you leave this parameter empty, the search index is created in the default search library of Intelligent Media Service (IMS). Default value: ims-default-search-lib.
*   To query information about an existing search library, call the [QuerySearchLib](https://help.aliyun.com/document_detail/2584455.html) API operation.', example='test1', position='Query'),
}

model QuerySearchIndexResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  indexStatus?: string(name='IndexStatus', description='The state of the index. Valid values:

*   active: the index is enabled.
*   Deactive: the index is not enabled.', example='Active'),
  indexType?: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.', example='mm'),
  mediaTotal?: string(name='MediaTotal', description='The total number of media assets.', example='12'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model QuerySearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QuerySearchIndexResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QuerySearchIndex  QuerySearchIndexRequest
  * @return QuerySearchIndexResponse
 */
async function querySearchIndex(request: QuerySearchIndexRequest): QuerySearchIndexResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QuerySearchIndex', 'POST', '/', 'json', false, 'json', request);
}

model QuerySearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  searchLibName: string(name='SearchLibName', description='The name of the search library.

This parameter is required.', example='test1', position='Query'),
}

model QuerySearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
  status?: string(name='Status', description='The status of the search library.

Valid values:

*   normal
*   deleting
*   deleteFail', example='normal'),
  success?: string(name='Success', description='Indicates whether the call was successful. Valid values:

*   true
*   false', example='true'),
}

model QuerySearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QuerySearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QuerySearchLib  QuerySearchLibRequest
  * @return QuerySearchLibResponse
 */
async function querySearchLib(request: QuerySearchLibRequest): QuerySearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QuerySearchLib', 'POST', '/', 'json', false, 'json', request);
}

model QuerySmarttagJobRequest {
  jobId: string(name='JobId', description='The ID of the smart tagging job that you want to query. You can obtain the job ID from the response parameters of the SubmitSmarttagJob operation.

This parameter is required.', example='88c6ca184c0e47098a5b665e2****', position='Query'),
  params?: string(name='Params', description='The extra parameters that you want to query in the request. The value is a JSON string. Example: {"labelResultType":"auto"}. The value of labelResultType is of the STRING type. Valid values:

*   auto: machine tagging
*   hmi: tagging by human and machine', example='{"labelResultType":"auto"}', position='Query'),
}

model QuerySmarttagJobResponseBody = {
  jobStatus?: string(name='JobStatus', description='The status of the job. Valid values:

*   **Success**: The job was successful.
*   **Fail**: The job failed.
*   **Processing**: The job is in progress.
*   **Submitted**: The job is submitted and waiting to be processed.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  results?: {
    result?: [ 
    {
      data?: string(name='Data', description='The details of the analysis result. The value is a JSON string. For more information about the parameters of different result types, see the "Parameters of different result types" section of this topic.', example='{"title":"example-title-****"}'),
      type?: string(name='Type', description='The type of the analysis result.

*   The type of the analysis result based on Smart tagging V1.0. Valid values:

1.  TextLabel: the text tag.
2.  VideoLabel: the video tag.
3.  ASR: the original result of automatic speech recognition (ASR). By default, this type of result is not returned.
4.  OCR: the original result of optical character recognition (OCR). By default, this type of result is not returned.
5.  NLP: the natural language processing (NLP)-based result. By default, this type of result is not returned.

*   The type of the analysis result based on Smart tagging V2.0. Valid values:

1.  CPVLabel
2.  Meta: the information about the video file, such as the title of the video. By default, this type of information is not returned.

*   The type of the analysis result based on Smart tagging V2.0-custom. Valid values:

1.  CPVLabel
2.  Meta: the information about the video file, such as the title of the video. By default, this type of information is not returned.', example='Meta'),
    }
  ](name='Result')
  }(name='Results', description='The analysis results of the smart tagging job. The value is an array.'),
  userData?: string(name='UserData', description='The content of callback messages that are sent to Simple Message Queue (SMQ) when the information of the smart tagging job changes. For more information about the parameters contained in the callback message, see the "Callback parameters" section of this topic.', example='{"userId":"123432412831"}'),
}

model QuerySmarttagJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QuerySmarttagJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QuerySmarttagJob  QuerySmarttagJobRequest
  * @return QuerySmarttagJobResponse
 */
async function querySmarttagJob(request: QuerySmarttagJobRequest): QuerySmarttagJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QuerySmarttagJob', 'POST', '/', 'json', false, 'json', request);
}

model RefreshUploadMediaRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***', position='Query'),
}

model RefreshUploadMediaResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='c2e77390f75271ec802f0674a2ce6***'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  uploadAddress?: string(name='UploadAddress', description='The upload URL.

>  The returned upload URL is a Base64-encoded URL. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAddress only if you use Object Storage Service (OSS) SDK or call an OSS API operation to upload media files.', example='eyJFbmRwb2ludCI6Imh0dHBzOi8vb3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbSIsIkJ1Y2tldCI6InN6aGQtdmlkZW8iLCJGaWxlTmFtZSI6InZvZC0yOTYzMWEvc3YvNTBmYTJlODQtMTgxMjdhZGRiMTcvNTBmYTJlODQtMTgxMjdhZGRiM***'),
  uploadAuth?: string(name='UploadAuth', description='The upload credential.

>  The returned upload credential is a Base64-encoded value. You must decode the Base64-encoded upload credential before you use an SDK or call an API operation to upload media files. You need to parse UploadAuth only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJBY2Nlc3NLZXlJZCI6IkxUQUk0Rm53bTk1dHdxQjMxR3IzSE5hRCIsIkFjY2Vzc0tleVNlY3JldCI6Ik9lWllKR0dTMTlkNkZaM1E3UVpJQmdmSVdnM3BPaiIsIkV4cGlyYXRpb24iOiI***'),
}

model RefreshUploadMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RefreshUploadMediaResponseBody(name='body'),
}

/**
  * @description You can also call this operation to overwrite media files. After you obtain the upload URL of a media file, you can upload the media file again without changing the audio or video ID.
  * @param request  the request parameters of RefreshUploadMedia  RefreshUploadMediaRequest
  * @return RefreshUploadMediaResponse
 */
async function refreshUploadMedia(request: RefreshUploadMediaRequest): RefreshUploadMediaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RefreshUploadMedia', 'POST', '/', 'json', false, 'json', request);
}

model RegisterMediaInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  businessType?: string(name='BusinessType', description='The business type of the media asset. Valid values:

*   subtitles
*   watermark
*   opening
*   ending
*   general', example='opening', position='Query'),
  cateId?: long(name='CateId', description='The category ID.', example='3048', position='Query'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request. The value must be a UUID that contains 32 characters.', example='****0311a423d11a5f7dee713535****', position='Query'),
  coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png', position='Query'),
  description?: string(name='Description', description='The description of the media asset.

*   The value can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultDescription', position='Query'),
  inputURL: string(name='InputURL', description='The URL of the media asset in another service. The URL is associated with the ID of the media asset in IMS. The URL cannot be modified once registered. The following types of URLs are supported:

*   OSS URL in one of the following formats:

http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4

oss://example-bucket/example.mp4: In this format, it is considered by default that the region of the OSS bucket in which the media asset resides is the same as the region in which IMS is activated.

*   URL of an ApsaraVideo VOD media asset

vod://\\*\\*\\*20b48fb04483915d4f2cd8ac\\*\\*\\*\\*

This parameter is required.', position='Query'),
  mediaTags?: string(name='MediaTags', description='The tags of the media asset.

*   Up to 16 tags are supported.
*   Separate multiple tags with commas (,).
*   Each tag can be up to 32 bytes in length.
*   The value must be encoded in UTF-8.', example='tag1,tag2', position='Query'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

*   image
*   video
*   audio
*   text

We recommend that you specify this parameter based on your business requirements. If you set InputURL to an OSS URL, the media asset type can be automatically determined based on the file name extension. For more information
<props="china">, see [File formats](https://help.aliyun.com/document_detail/466207.html).', example='video', position='Query'),
  overwrite?: boolean(name='Overwrite', description='Specifies whether to overwrite the media asset that has been registered by using the same URL. Default value: false. Valid values:

\\- true: If a media asset has been registered by using the same URL, the original media asset is deleted and the new media asset is registered.

\\- false: If a media asset has been registered by using the same URL, the new media asset is not registered. A URL cannot be used to register multiple media assets.', example='true', position='Query'),
  referenceId?: string(name='ReferenceId', description='The custom ID. The ID can be 6 to 64 characters in length and can contain only letters, digits, hyphens (-), and underscores (_). Make sure that the ID is unique among users.', example='123-123', position='Query'),
  registerConfig?: string(name='RegisterConfig', description='The registration configurations.

By default, a sprite is generated for the media asset. You can set NeedSprite to false to disable automatic sprite generation.

By default, a snapshot is generated for the media asset. You can set NeedSnapshot to false to disable automatic snapshot generation.', example='{
      "NeedSprite": "false"
}', position='Query'),
  smartTagTemplateId?: string(name='SmartTagTemplateId', description='The ID of the smart tagging template. Valid values:

*   S00000101-300080: the system template that supports natural language processing (NLP) for content recognition.
*   S00000103-000001: the system template that supports NLP for content recognition and all tagging capabilities.
*   S00000103-000002: the system template that supports all tagging capabilities but does not support NLP for content recognition.

After you configure this parameter, a smart tag analysis task is automatically initiated after the media asset is registered. For more information about the billable items<props="china">, see [Smart tagging](https://help.aliyun.com/zh/ims/media-ai-billing?spm=a2c4g.11186623.0.0.3147392dWwlSjL#p-k38-3rb-dug).', example='S00000101-300080', position='Query'),
  title?: string(name='Title', description='The title. If you do not specify this parameter, a default title is automatically generated based on the date.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultTitle', position='Query'),
  userData?: string(name='UserData', description='The user data. You can specify a custom callback URL. For more information<props="china"> ,see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).

*   The value can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.
*   The value must be in the JSON format.', position='Query'),
  workflowId?: string(name='WorkflowId', description='The workflow ID.', example='******b4fb044839815d4f2cd8******', position='Query'),
}

model RegisterMediaInfoResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset in IMS.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The request ID.', example='******5A-CAAC-4850-A3AF-B74606******'),
}

model RegisterMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RegisterMediaInfoResponseBody(name='body'),
}

/**
  * @description Registering a media asset is an asynchronous job that takes 2 to 3 seconds. When the operation returns the ID of the media asset, the registration may have not be completed. If you call the GetMediaInfo operation at this time, you may fail to obtain the information about the media asset.
  * @param request  the request parameters of RegisterMediaInfo  RegisterMediaInfoRequest
  * @return RegisterMediaInfoResponse
 */
async function registerMediaInfo(request: RegisterMediaInfoRequest): RegisterMediaInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RegisterMediaInfo', 'POST', '/', 'json', false, 'json', request);
}

model RegisterMediaStreamRequest {
  regionId?: string(name='RegionId', position='Host'),
  inputURL?: string(name='InputURL', description='The URL of the media asset in another service. The URL is associated with the ID of the media asset in IMS. The URL cannot be modified once registered.

Set this parameter to the OSS URL of the media asset. The following formats are supported:

http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4

oss://example-bucket/example.mp4: In this format, it is considered by default that the region of the OSS bucket in which the media asset resides is the same as the region in which IMS is activated.', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='5e778ec0027b71ed80a8909598506***', position='Query'),
  userData?: string(name='UserData', description='The user data.', example='{"MessageCallback":{"CallbackURL":"http://test.test.com"}, "Extend":{"localId":"xxx","test":"www"}}', position='Query'),
}

model RegisterMediaStreamResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='5e778ec0027b71ed80a8909598506302'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model RegisterMediaStreamResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RegisterMediaStreamResponseBody(name='body'),
}

/**
  * @description You can call this operation to register a media stream file in an Object Storage Service (OSS) bucket with Intelligent Media Services (IMS) and associate the media stream with the specified media asset ID.
  * @param request  the request parameters of RegisterMediaStream  RegisterMediaStreamRequest
  * @return RegisterMediaStreamResponse
 */
async function registerMediaStream(request: RegisterMediaStreamRequest): RegisterMediaStreamResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RegisterMediaStream', 'POST', '/', 'json', false, 'json', request);
}

model SearchEditingProjectRequest {
  createSource?: string(name='CreateSource', example='WebSDK', position='Query'),
  endTime?: string(name='EndTime', example='2017-01-11T12:00:00Z', position='Query'),
  pageNo?: long(name='PageNo', example='1', position='Query'),
  pageSize?: long(name='PageSize', example='10', position='Query'),
  projectType?: string(name='ProjectType', example='EditingProject', position='Query'),
  sortBy?: string(name='SortBy', example='CreationTime:Desc', position='Query'),
  startTime?: string(name='StartTime', example='2017-01-11T12:00:00Z', position='Query'),
  status?: string(name='Status', example='Producing', position='Query'),
  templateType?: string(name='TemplateType', example='Timeline', position='Query'),
}

model SearchEditingProjectResponseBody = {
  maxResults?: long(name='MaxResults', example='10'),
  nextToken?: string(name='NextToken', example='null'),
  projectList?: [ 
    {
      businessConfig?: string(name='BusinessConfig', example='{ "OutputMediaConfig" : { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path" }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
      businessStatus?: string(name='BusinessStatus', example='Reserving'),
      coverURL?: string(name='CoverURL', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example-cover.jpg'),
      createSource?: string(name='CreateSource', example='OpenAPI'),
      createTime?: string(name='CreateTime', example='2017-01-11T12:00:00Z'),
      description?: string(name='Description', example='sample description'),
      duration?: long(name='Duration', example='30.100000'),
      errorCode?: string(name='ErrorCode', example='InvalidParameter'),
      errorMessage?: string(name='ErrorMessage', example='"EventTime":"2021-08-12T10:04:15Z","ErrorCode":"InvalidParameter","ErrorMessage":"The specified parameter \\"LiveStreamConfig\\" is not valid. specified parameter example is not valid.'),
      modifiedSource?: string(name='ModifiedSource', example='2017-01-11T12:00:00Z'),
      modifiedTime?: string(name='ModifiedTime', example='2017-01-11T12:00:00Z'),
      projectId?: string(name='ProjectId', example='****fddd7748b58bf1d47e95****'),
      projectType?: string(name='ProjectType', example='EditingProject'),
      status?: string(name='Status', example='PRODUCE_FAILED'),
      templateType?: string(name='TemplateType', example='Timeline'),
      timeline?: string(name='Timeline', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
      title?: string(name='Title', example='title'),
    }
  ](name='ProjectList'),
  requestId?: string(name='RequestId', example='****9262E3DA-07FA-4862-FCBB6BC61D08*****'),
  totalCount?: long(name='TotalCount', example='110'),
}

model SearchEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchEditingProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SearchEditingProject  SearchEditingProjectRequest
  * @return SearchEditingProjectResponse
 */
async function searchEditingProject(request: SearchEditingProjectRequest): SearchEditingProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchEditingProject', 'POST', '/', 'json', false, 'json', request);
}

model SearchIndexJobRerunRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaIds: string(name='MediaIds', description='This parameter is required.', example='******b48fb04483915d4f2cd8******,******c48fb37407365d4f2cd8******', position='Query'),
  searchLibName?: string(name='SearchLibName', example='test-1', position='Query'),
  task?: string(name='Task', example='AiLabel,Face,Mm', position='Query'),
}

model SearchIndexJobRerunResponseBody = {
  code?: string(name='Code', example='200'),
  data?: {
    mediaIdsNoExist?: [ string ](name='MediaIdsNoExist'),
  }(name='Data'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', example='true'),
}

model SearchIndexJobRerunResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchIndexJobRerunResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SearchIndexJobRerun  SearchIndexJobRerunRequest
  * @return SearchIndexJobRerunResponse
 */
async function searchIndexJobRerun(request: SearchIndexJobRerunRequest): SearchIndexJobRerunResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchIndexJobRerun', 'POST', '/', 'json', false, 'json', request);
}

model SearchMediaRequest {
  regionId?: string(name='RegionId', position='Host'),
  entityId?: string(name='EntityId', description='The ID of the entity.', example='2d3bf1e35a1e42b5ab338d701efa7603', position='Query'),
  match?: string(name='Match', description='The filter conditions. For more information about the parameter syntax
<props="china">, see [Media asset search protocols](https://help.aliyun.com/document_detail/2584256.html).', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='20', position='Query'),
  scrollToken?: string(name='ScrollToken', description='The pagination identifier. The value can be up to 32 characters in length. The first time you call this operation for each new search, you do not need to specify this parameter. The value of this parameter is returned each time data records that meet the specified filter condition are found. The value is used to record the current position of queried data. Record the returned parameter value and set this parameter according to the following requirements during the next search: If you need to traverse all data that meets the filter criteria, you must set the ScrollToken parameter. If the value of the PageNo parameter exceeds 200, we recommend that you set this parameter to optimize search performance. You can only page backward. You can page a maximum of 1,000 entries in an operation.', example='F8C4F642184DBDA5D93907A70AAE****', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='test-1', position='Query'),
  sortBy?: string(name='SortBy', description='The sort field and order. Separate multiple parameters with commas (,).', example='utcCreate:Desc, utcModified:Desc', position='Query'),
}

model SearchMediaResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaInfoList?: [ 
    {
      aiData?: {
        aiLabelInfo?: [ 
          {
            category?: string(name='Category', description='The category.'),
            faceId?: string(name='FaceId', description='The face ID.', example='5FE19530C7A422197535FE74F5DB2B9F'),
            labelId?: string(name='LabelId', description='The ID of the entity.', example='10310250338'),
            labelName?: string(name='LabelName', description='The name of the entity.'),
            labelType?: string(name='LabelType', description='The type of the tag.'),
            occurrences?: [ 
              {
                content?: string(name='Content', description='The text content.'),
                finegrainId?: string(name='FinegrainId', description='The fine-grained ID of the entity.', example='10310250338'),
                finegrainName?: string(name='FinegrainName', description='The fine-grained name of the entity.'),
                from?: double(name='From', description='The start time of the clip.', example='1.4'),
                image?: string(name='Image', description='The optimal face image encoded in Base64.', example='99C64F6287'),
                score?: double(name='Score', description='The score.', example='0.75287705'),
                tableBatchSeqId?: string(name='TableBatchSeqId', description='The sequence ID of the vector table.', example='85010D1'),
                to?: double(name='To', description='The end time of the clip.', example='2.5'),
                tracks?: [ 
                  {
                    position?: string(name='Position', description='The coordinates of the bounding box.', example='468.0;67.0;615.0;267.0'),
                    size?: double(name='Size', description='The size of the bounding box.', example='50.2'),
                    timestamp?: double(name='Timestamp', description='The timestamp of the track.', example='1.4'),
                  }
                ](name='Tracks', description='The track sequence.'),
                clipId?: string(name='clipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB2B9F'),
              }
            ](name='Occurrences', description='The clips.'),
            source?: string(name='Source', description='The source.', example='vision'),
          }
        ](name='AiLabelInfo', description='The tags of the intelligent AI job.'),
        asrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB2B9F'),
            content?: string(name='Content', description='The text content.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='AsrInfo', description='The information about audio files.'),
        ocrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB2B9F'),
            content?: string(name='Content', description='The text content.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='OcrInfo', description='The subtitles.'),
      }(name='AiData', description='The details of the intelligent AI job.'),
      aiRoughData?: {
        aiCategory?: string(name='AiCategory', description='TV Series', example='TV series'),
        aiJobId?: string(name='AiJobId', description='The ID of the AI job.', example='cd35b0b0025f71edbfcb472190a9xxxx'),
        result?: string(name='Result', description='The results of the AI job.', example='http://xxxx.json'),
        saveType?: string(name='SaveType', description='The save type.', example='TEXT'),
        status?: string(name='Status', description='The data status.', example='SaveSuccess'),
      }(name='AiRoughData', description='The description of the AI job.'),
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate of the file.', example='1912.13'),
            createTime?: string(name='CreateTime', description='The time when the file was created.', example='2022-05-30T02:02:17Z'),
            duration?: string(name='Duration', description='The duration of the file.', example='60.00000'),
            fileName?: string(name='FileName', description='The name of the file.', example='164265080291300080527050.wav'),
            fileSize?: string(name='FileSize', description='The size of the file in bytes.', example='324784'),
            fileStatus?: string(name='FileStatus', description='The status of the file.', example='Normal'),
            fileType?: string(name='FileType', description='The type of the file.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='https://outin-d3f4681ddfd911ec99a600163e1403e7.oss-cn-shanghai.aliyuncs.com/sv/23d5cdd1-18180984899/23d5cdd1-18180984899.mp4'),
            formatName?: string(name='FormatName', description='The encapsulation format of the file.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height of the file.', example='480'),
            modifiedTime?: string(name='ModifiedTime', description='The time when the file was last modified.', example='2021-12-10T12:19Z'),
            region?: string(name='Region', description='The region in which the file is stored.', example='cn-beijing'),
            width?: string(name='Width', description='The width of the file.', example='1920'),
          }(name='FileBasicInfo', description='The basic information about the file, such as the duration and size.'),
        }
      ](name='FileInfoList', description='The information about the files.'),
      indexStatusList?: [ 
        {
          indexStatus?: string(name='IndexStatus', example='Success'),
          indexType?: string(name='IndexType', example='mm'),
        }
      ](name='IndexStatusList'),
      mediaBasicInfo?: {
        biz?: string(name='Biz', description='The business to which the media asset belongs.', example='IMS'),
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='opening'),
        cateId?: long(name='CateId', description='The ID of the category.', example='44'),
        cateName?: string(name='CateName', description='The name of the category.'),
        category?: string(name='Category', description='The category of the media asset.', example='image'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='https://dtlive-bj.oss-cn-beijing.aliyuncs.com/cover/e694372e-4f5b-4821-ae09-efd064f27b63_large_cover_url.jpg'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-01T19:48Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-01T19:48Z'),
        description?: string(name='Description', description='The description of the media asset.'),
        inputURL?: string(name='InputURL', description='The address of the media asset that is waiting to be registered.', example='oss://clipres/longvideo/material/voice/prod/20220418/07d7c799f6054dc3bbef250854cf84981650248140427'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='132bd600fc3c71ec99476732a78f6402'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='tags,tags2'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was modified.', example='2020-12-01T19:48Z'),
        referenceId?: string(name='ReferenceId', description='The custom ID of the media asset. The ID is a string that contains 6 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are supported. Each custom ID is unique.', example='123-123'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='[{"bucket":"example-bucket","count":"3","iceJobId":"******f48f0e4154976b2b8c45******","location":"oss-cn-beijing","snapshotRegular":"example.jpg","templateId":"******e6a6440b29eb60bd7c******"}]'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The image sprite of the media asset', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
        status?: string(name='Status', description='The state of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        uploadSource?: string(name='UploadSource', description='The upload source of the media asset.', example='general'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information about the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='3b187b3620c8490886cfc2a9578c3ce6'),
    }
  ](name='MediaInfoList', description='The media assets that meet the requirements.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='6F61C357-ACC0-57FB-876E-D58795335E59'),
  scrollToken?: string(name='ScrollToken', description='The pagination identifier.', example='F8C4F642184DBDA5D93907A70AAE****'),
  success?: string(name='Success', description='Indicates whether the request was successful.', example='True'),
  total?: long(name='Total', description='The total number of media assets that meet the conditions.', example='163'),
}

model SearchMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaResponseBody(name='body'),
}

/**
  * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
  * @param request  the request parameters of SearchMedia  SearchMediaRequest
  * @return SearchMediaResponse
 */
async function searchMedia(request: SearchMediaRequest): SearchMediaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchMedia', 'POST', '/', 'json', false, 'json', request);
}

model SearchMediaByAILabelRequest {
  regionId?: string(name='RegionId', position='Host'),
  matchingMode?: string(name='MatchingMode', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. This parameter is required if you want to query media asset clips.', example='****c469e944b5a856828dc2****', position='Query'),
  mediaType?: string(name='MediaType', description='The type of the media assets. Valid values:

*   image
*   video
*   audio', example='video', position='Query'),
  multimodalSearchType?: string(name='MultimodalSearchType', description='The type of query. Valid values:

*   PersonName: queries media assets based on character names.
*   Ocr: queries media assets based on subtitles.
*   AiCategory: queries media assets based on AI categories.
*   FullSearch (default): queries all media assets.', example='Ocr', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='20', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test-1', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting method of the results. Valid values:

*   CreationTime:Desc (default): sorts results in reverse chronological order.
*   CreationTime:Asc: sorts results in chronological order.', example='CreationTime:Desc', position='Query'),
  specificSearch?: boolean(name='SpecificSearch', description='Specifies whether to query media asset clips. Valid values:

*   true
*   false', example='true', position='Query'),
  text?: string(name='Text', description='The content that you want to query.', position='Query'),
}

model SearchMediaByAILabelResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaList?: [ 
    {
      aiData?: {
        aiLabelInfo?: [ 
          {
            category?: string(name='Category', description='The category.'),
            faceId?: string(name='FaceId', description='The ID of the face.', example='5FE19530C7A422197535FE74F5DB****'),
            labelId?: string(name='LabelId', description='The ID of the entity.', example='103102503**'),
            labelName?: string(name='LabelName', description='The name of the entity.'),
            labelType?: string(name='LabelType', description='The type of the tag.'),
            occurrences?: [ 
              {
                clipId?: string(name='ClipId', description='The ID of the clip.', example='158730355E4B82257D8AA1583A58****'),
                content?: string(name='Content', description='The content of the text.'),
                finegrainId?: string(name='FinegrainId', description='The fine-grained ID of the entity.', example='103102503**'),
                finegrainName?: string(name='FinegrainName', description='The fine-grained name of the entity.'),
                from?: double(name='From', description='The start time of the clip.', example='1.4'),
                image?: string(name='Image', description='The image that contains the most face information.', example='https://service-****-public.oss-cn-hangzhou.aliyuncs.com/1563457****438522/service-image/f788974f-9595-43b2-a478-7c7a1afb****.jpg'),
                score?: double(name='Score', description='The score.', example='0.75287705'),
                tableBatchSeqId?: string(name='TableBatchSeqId', description='The sequence ID of the vector table.', example='85010D1**'),
                to?: double(name='To', description='The end time of the clip.', example='2.5'),
                tracks?: [ 
                  {
                    position?: string(name='Position', description='The coordinates of the bounding box.', example='468.0;67.0;615.0;267.0'),
                    size?: double(name='Size', description='The size of the bounding box.', example='50'),
                    timestamp?: double(name='Timestamp', description='The timestamp of the track.', example='1.4'),
                  }
                ](name='Tracks', description='The tracks.'),
              }
            ](name='Occurrences', description='The information about the clips.'),
            source?: string(name='Source', description='The source.', example='vision'),
          }
        ](name='AiLabelInfo', description='The tags of the AI job.'),
        asrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB****'),
            content?: string(name='Content', description='The content of the audio.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='AsrInfo', description='The information about audio files.'),
        ocrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB****'),
            content?: string(name='Content', description='The content of the text.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='OcrInfo', description='The information about subtitle files.'),
      }(name='AiData', description='The details of the AI job.'),
      appId?: string(name='AppId', description='The ID of the application. Default value: app-1000000.', example='app-1000000'),
      coverUrl?: string(name='CoverUrl', description='The URL of the thumbnail.', example='http://example.aliyundoc.com/snapshot/****.jpg?auth_key=1498476426-0-0-f00b9455c49a423ce69cf4e27333****'),
      creationTime?: string(name='CreationTime', description='The time when the media asset was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:15:50Z'),
      description?: string(name='Description', description='The description of the media asset.'),
      duration?: float(name='Duration', description='The duration. Unit: seconds.', example='12.2'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='1c6ce34007d571ed94667630a6bc****'),
      modificationTime?: string(name='ModificationTime', description='The time when the media asset was updated. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:15:50Z'),
      size?: long(name='Size', description='The size of the source file. Unit: bytes.', example='10897890'),
      snapshots?: [ string ](name='Snapshots', description='The array of video snapshot URLs.'),
      status?: string(name='Status', description='The status of the video.

Valid values:

*   PrepareFail
*   UploadFail
*   Init
*   UploadSucc
*   Transcoding
*   TranscodeFail
*   Deleted
*   Normal
*   Uploading
*   Preparing
*   Blocked
*   Checking', example='Normal'),
      storageLocation?: string(name='StorageLocation', description='The storage address.', example='out-****.oss-cn-shanghai.aliyuncs.com'),
      tags?: string(name='Tags', description='The tags of the media asset.'),
      title?: string(name='Title', description='The title of the media asset.'),
    }
  ](name='MediaList', description='The media assets that contain the specified content.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request was successful.', example='true'),
  total?: long(name='Total', description='The total number of audio and video files that meet the conditions.', example='30'),
}

model SearchMediaByAILabelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByAILabelResponseBody(name='body'),
}

/**
  * @description You can call this operation to query media assets or media asset clips based on character names, subtitles, or AI categories.
  * @param request  the request parameters of SearchMediaByAILabel  SearchMediaByAILabelRequest
  * @return SearchMediaByAILabelResponse
 */
async function searchMediaByAILabel(request: SearchMediaByAILabelRequest): SearchMediaByAILabelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchMediaByAILabel', 'POST', '/', 'json', false, 'json', request);
}

model SearchMediaByFaceRequest {
  regionId?: string(name='RegionId', position='Host'),
  entityId?: string(name='EntityId', description='The ID of the entity.', example='2d3bf1e35a1e42b5ab338d701efa****', position='Query'),
  faceSearchToken: string(name='FaceSearchToken', description='The token that is used to identify the query. You can use this parameter in the SearchMediaClipByFace operation to specify the same query conditions.

This parameter is required.', example='zxtest-huangxuan-2023-3-7-V1', position='Query'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

*   image
*   video', example='video', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10', position='Query'),
  personImageUrl: string(name='PersonImageUrl', description='The URL of the face image.

This parameter is required.', example='https://****.oss-cn-shanghai.aliyuncs.com/input/huangxuan****.jpg', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1', position='Query'),
}

model SearchMediaByFaceResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaInfoList?: [ 
    {
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='3b187b3620c8490886cfc2a9578c****'),
    }
  ](name='MediaInfoList', description='The media assets that meet the conditions.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='7CA7D615-CFB1-5437-9A12-2D185C3EE6CB'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
  total?: long(name='Total', description='The total number of data records that meet the specified filter condition.', example='163'),
}

model SearchMediaByFaceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByFaceResponseBody(name='body'),
}

/**
  * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
  * @param request  the request parameters of SearchMediaByFace  SearchMediaByFaceRequest
  * @return SearchMediaByFaceResponse
 */
async function searchMediaByFace(request: SearchMediaByFaceRequest): SearchMediaByFaceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchMediaByFace', 'POST', '/', 'json', false, 'json', request);
}

model SearchMediaByHybridRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. The details of the media asset are returned.', example='****c469e944b5a856828dc2****', position='Query'),
  mediaType?: string(name='MediaType', example='video', position='Query'),
  pageNo?: int32(name='PageNo', example='1', position='Query'),
  pageSize?: int32(name='PageSize', example='20', position='Query'),
  searchLibName?: string(name='SearchLibName', example='test-1', position='Query'),
  text?: string(name='Text', position='Query'),
}

model SearchMediaByHybridResponseBody = {
  code?: string(name='Code', example='200'),
  mediaList?: [ 
    {
      clipInfo?: [ 
        {
          from?: double(name='From', example='2'),
          score?: double(name='Score', example='0.99'),
          to?: double(name='To', example='4'),
        }
      ](name='ClipInfo'),
      mediaId?: string(name='MediaId', example='a18936e0e28771edb59ae6f6f47a****'),
    }
  ](name='MediaList'),
  requestId?: string(name='RequestId', example='******3B-0E1A-586A-AC29-742247******'),
  success?: string(name='Success', example='true'),
  total?: long(name='Total', example='30'),
}

model SearchMediaByHybridResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByHybridResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SearchMediaByHybrid  SearchMediaByHybridRequest
  * @return SearchMediaByHybridResponse
 */
async function searchMediaByHybrid(request: SearchMediaByHybridRequest): SearchMediaByHybridResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchMediaByHybrid', 'POST', '/', 'json', false, 'json', request);
}

model SearchMediaByMultimodalRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaType?: string(name='MediaType', description='The type of the media assets.

Valid values:

*   image
*   video (default)', example='video', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='test-1', position='Query'),
  text?: string(name='Text', description='The content that you want to query. You can describe the content in natural language.', position='Query'),
}

model SearchMediaByMultimodalResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaList?: [ 
    {
      clipInfo?: [ 
        {
          from?: double(name='From', description='The start time of the clip.', example='2'),
          score?: double(name='Score', description='The score.', example='1.2'),
          to?: double(name='To', description='The end time of the clip.', example='4'),
        }
      ](name='ClipInfo', description='The information about the clip.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='a18936e0e28771edb59ae6f6f47a****'),
    }
  ](name='MediaList', description='The media assets that contain the specified content.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
  total?: long(name='Total', description='The total number of data records that meet the specified filter condition.', example='20'),
}

model SearchMediaByMultimodalResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByMultimodalResponseBody(name='body'),
}

/**
  * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
  * @param request  the request parameters of SearchMediaByMultimodal  SearchMediaByMultimodalRequest
  * @return SearchMediaByMultimodalResponse
 */
async function searchMediaByMultimodal(request: SearchMediaByMultimodalRequest): SearchMediaByMultimodalResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchMediaByMultimodal', 'POST', '/', 'json', false, 'json', request);
}

model SearchMediaClipByFaceRequest {
  regionId?: string(name='RegionId', position='Host'),
  entityId?: string(name='EntityId', description='The ID of the entity.', example='2d3bf1e35a1e42b5ab338d701efa****', position='Query'),
  faceSearchToken: string(name='FaceSearchToken', description='The value of this parameter is the same as that of the FaceSearchToken parameter in the SearchMediaByFace request. This specifies to return media asset clips that meet the same query conditions.

This parameter is required.', example='zxtest-huangxuan-2023-3-7-V1', position='Query'),
  mediaId: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='3b187b3620c8490886cfc2a9578c****', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1', position='Query'),
}

model SearchMediaClipByFaceResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaClipList?: [ 
    {
      category?: string(name='Category', description='The type of the character. Valid values: celebrity sensitive politician custom unknown', example='celebrity'),
      entityId?: string(name='EntityId', description='The ID of the entity, which is the same as the entity ID returned in tag analysis.', example='1031025****'),
      labelName?: string(name='LabelName', description='The name of the entity.'),
      occurrencesInfos?: [ 
        {
          endTime?: float(name='EndTime', description='The end time of the clip. Unit: seconds. The value is of the Float type.', example='69.06635'),
          startTime?: float(name='StartTime', description='The start time of the clip. Unit: seconds. The value is of the Float type.', example='61.066353'),
          trackData?: [ 
            {
              boxPosition?: {
                h?: int32(name='H', description='The height of the rectangle frame. Unit: pixels.', example='168'),
                w?: int32(name='W', description='The width of the rectangle frame. Unit: pixels.', example='128'),
                x?: int32(name='X', description='The x-axis coordinate of the upper-left corner. Unit: pixels.', example='517'),
                y?: int32(name='Y', description='The y-axis coordinate of the upper-left corner. Unit: pixels.', example='409'),
              }(name='BoxPosition', description='The coordinates of the face.'),
              timestamp?: float(name='Timestamp', description='The timestamp when the face appears in the clip. Unit: seconds. The value is of the Float type.', example='62.03302'),
            }
          ](name='TrackData', description='The information about the face in the clip.'),
        }
      ](name='OccurrencesInfos', description='The information about clips related to the face.'),
      score?: float(name='Score', description='The score of the clip. The value is of the Float type. The value is in the range of [0,1].', example='0.99041677'),
    }
  ](name='MediaClipList', description='The media asset clips that meet the requirements.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='E44FFACD-9E90-555A-A09A-6FD3B7335E39'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values: true and false.', example='true'),
  total?: long(name='Total', description='The total number of media asset clips that meet the conditions.', example='5'),
}

model SearchMediaClipByFaceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaClipByFaceResponseBody(name='body'),
}

/**
  * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
  * @param request  the request parameters of SearchMediaClipByFace  SearchMediaClipByFaceRequest
  * @return SearchMediaClipByFaceResponse
 */
async function searchMediaClipByFace(request: SearchMediaClipByFaceRequest): SearchMediaClipByFaceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchMediaClipByFace', 'POST', '/', 'json', false, 'json', request);
}

model SearchPublicMediaInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  authorized?: boolean(name='Authorized', example='true', position='Query'),
  dynamicMetaDataMatchFields?: string(name='DynamicMetaDataMatchFields', example='"ApprovalStatus=\\"Available\\"&amp;MaterialBags=\\"boutiquemusic\\"&amp;Mood=\\"Nervous\\""', position='Query'),
  entityId?: string(name='EntityId', example='Copyright_Music', position='Query'),
  favorite?: boolean(name='Favorite', example='true', position='Query'),
  mediaIds?: string(name='MediaIds', example='****20b48fb04483915d4f2cd8ac****,****15d4a4b0448391508f2cb486****', position='Query'),
  pageNo?: int32(name='PageNo', example='1', position='Query'),
  pageSize?: int32(name='PageSize', example='10', position='Query'),
  sortBy?: string(name='SortBy', example='UsageCount:Desc,UnitPrice:Asc', position='Query'),
}

model SearchPublicMediaInfoResponseBody = {
  publicMediaInfos?: [ 
    {
      authorized?: boolean(name='Authorized', example='true'),
      favorite?: boolean(name='Favorite', example='true'),
      mediaInfo?: {
        dynamicMetaData?: {
          data?: string(name='Data', example='"{\\"AuditionUrl\\": \\"http://xxx\\", \\"AuditionCount\\": 3...}"'),
          type?: string(name='Type', example='system'),
        }(name='DynamicMetaData'),
        mediaBasicInfo?: {
          businessType?: string(name='BusinessType', example='general'),
          category?: string(name='Category', example='category'),
          coverURL?: string(name='CoverURL', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
          createTime?: string(name='CreateTime', example='2020-12-26T06:04:49Z'),
          deletedTime?: string(name='DeletedTime', example='2020-12-29T06:04:49Z'),
          description?: string(name='Description', example='description'),
          mediaId?: string(name='MediaId', description='MediaId', example='icepublic-****87b921bb4a55908a72a0537e****'),
          mediaTags?: string(name='MediaTags'),
          mediaType?: string(name='MediaType', example='audio'),
          modifiedTime?: string(name='ModifiedTime', example='2020-12-26T06:04:50Z'),
          source?: string(name='Source', example='oss'),
          spriteImages?: string(name='SpriteImages', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
          status?: string(name='Status', example='Normal'),
          title?: string(name='Title', example='title'),
          userData?: string(name='UserData', example='userDataTest'),
        }(name='MediaBasicInfo', description='BasicInfo'),
        mediaId?: string(name='MediaId', example='icepublic-****87b921bb4a55908a72a0537e****'),
      }(name='MediaInfo'),
      remainingAuthTime?: string(name='RemainingAuthTime', example='100'),
    }
  ](name='PublicMediaInfos'),
  requestId?: string(name='RequestId', example='****3CFB-2767-54FD-B311-BD15A4C1****'),
  totalCount?: long(name='TotalCount', example='100'),
}

model SearchPublicMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchPublicMediaInfoResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SearchPublicMediaInfo  SearchPublicMediaInfoRequest
  * @return SearchPublicMediaInfoResponse
 */
async function searchPublicMediaInfo(request: SearchPublicMediaInfoRequest): SearchPublicMediaInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchPublicMediaInfo', 'POST', '/', 'json', false, 'json', request);
}

model SendAIAgentSpeechRequest {
  enableInterrupt?: boolean(name='EnableInterrupt', example='true', position='Query'),
  instanceId: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
  text: string(name='Text', description='This parameter is required.', position='Query'),
}

model SendAIAgentSpeechResponseBody = {
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model SendAIAgentSpeechResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendAIAgentSpeechResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SendAIAgentSpeech  SendAIAgentSpeechRequest
  * @return SendAIAgentSpeechResponse
 */
async function sendAIAgentSpeech(request: SendAIAgentSpeechRequest): SendAIAgentSpeechResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SendAIAgentSpeech', 'POST', '/', 'json', false, 'json', request);
}

model SendLiveSnapshotJobCommandRequest {
  command: string(name='Command', description='The operation command.

Valid values:

*   stop
*   restart
*   start

This parameter is required.', example='start', position='Body'),
  jobId: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Body'),
}

model SendLiveSnapshotJobCommandResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SendLiveSnapshotJobCommandResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendLiveSnapshotJobCommandResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SendLiveSnapshotJobCommand  SendLiveSnapshotJobCommandRequest
  * @return SendLiveSnapshotJobCommandResponse
 */
async function sendLiveSnapshotJobCommand(request: SendLiveSnapshotJobCommandRequest): SendLiveSnapshotJobCommandResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SendLiveSnapshotJobCommand', 'POST', '/', 'json', true, 'form', request);
}

model SendLiveTranscodeJobCommandRequest {
  command: string(name='Command', description='The operation command. Only the stop command is supported. This command is used to stop a transcoding job.

This parameter is required.', example='stop', position='Query'),
  jobId: string(name='JobId', description='The ID of the transcoding job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model SendLiveTranscodeJobCommandResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model SendLiveTranscodeJobCommandResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendLiveTranscodeJobCommandResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SendLiveTranscodeJobCommand  SendLiveTranscodeJobCommandRequest
  * @return SendLiveTranscodeJobCommandResponse
 */
async function sendLiveTranscodeJobCommand(request: SendLiveTranscodeJobCommandRequest): SendLiveTranscodeJobCommandResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SendLiveTranscodeJobCommand', 'POST', '/', 'json', false, 'json', request);
}

model SetContentAnalyzeConfigRequest {
  regionId?: string(name='RegionId', position='Host'),
  auto?: boolean(name='Auto', example='true', position='Query'),
  saveType?: string(name='SaveType', example='TEXT,FACE', position='Query'),
  templateId?: string(name='TemplateId', example='S00000101-100070', position='Query'),
}

model SetContentAnalyzeConfigResponseBody = {
  requestId?: string(name='RequestId', example='953CFD27-4A2C-54AD-857F-B79EF3A338E0'),
  success?: boolean(name='Success', example='true'),
}

model SetContentAnalyzeConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetContentAnalyzeConfigResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SetContentAnalyzeConfig  SetContentAnalyzeConfigRequest
  * @return SetContentAnalyzeConfigResponse
 */
async function setContentAnalyzeConfig(request: SetContentAnalyzeConfigRequest): SetContentAnalyzeConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetContentAnalyzeConfig', 'POST', '/', 'json', false, 'json', request);
}

model SetDefaultCustomTemplateRequest {
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****d80e4e4044975745c14b****', position='Query'),
}

model SetDefaultCustomTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model SetDefaultCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetDefaultCustomTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SetDefaultCustomTemplate  SetDefaultCustomTemplateRequest
  * @return SetDefaultCustomTemplateResponse
 */
async function setDefaultCustomTemplate(request: SetDefaultCustomTemplateRequest): SetDefaultCustomTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetDefaultCustomTemplate', 'POST', '/', 'json', false, 'json', request);
}

model SetDefaultStorageLocationRequest {
  regionId?: string(name='RegionId', position='Host'),
  bucket?: string(name='Bucket', example='oss-test-bucket', position='Query'),
  path?: string(name='Path', example='ims/dir', position='Query'),
  storageType?: string(name='StorageType', example='user_oss_bucket', position='Query'),
}

model SetDefaultStorageLocationResponseBody = {
  requestId?: string(name='RequestId', example='******5A-CAAC-4850-A3AF-B74606******'),
  success?: boolean(name='Success', example='true'),
}

model SetDefaultStorageLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetDefaultStorageLocationResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SetDefaultStorageLocation  SetDefaultStorageLocationRequest
  * @return SetDefaultStorageLocationResponse
 */
async function setDefaultStorageLocation(request: SetDefaultStorageLocationRequest): SetDefaultStorageLocationResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetDefaultStorageLocation', 'POST', '/', 'json', false, 'json', request);
}

model SetEventCallbackRequest {
  regionId?: string(name='RegionId', position='Host'),
  authKey?: string(name='AuthKey', description='The authentication key. The key can be up to 32 characters in length and must contain uppercase letters, lowercase letters, and digits. This parameter takes effect only if you set CallbackType to **HTTP**.', example='TestKey001', position='Query'),
  authSwitch?: string(name='AuthSwitch', description='Specifies whether to enable callback authentication. This parameter takes effect only if you set CallbackType to **HTTP**. Valid values:

*   **on**
*   **off**', example='on', position='Query'),
  callbackQueueName?: string(name='CallbackQueueName', description='The name of the Simple Message Queue (SMQ) queue in the region. The name must start with ice-callback-.', example='ice-callback-queue', position='Query'),
  callbackType?: string(name='CallbackType', description='The callback method. Valid values:

*   **HTTP**
*   **MNS**', example='HTTP', position='Query'),
  callbackURL?: string(name='CallbackURL', description='The callback URL. This parameter is required if you set CallbackType to **HTTP**. The callback URL cannot exceed 256 bytes in length. You can specify only one callback URL.', example='http://xxx.yyy/callback', position='Query'),
  eventTypeList?: string(name='EventTypeList', description='The type of the callback event. You can specify multiple values separated with commas (,). ProduceMediaComplete: indicates that the editing and production task is complete.', example='ProduceMediaComplete', position='Query'),
}

model SetEventCallbackResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the configuration was successful. Valid values: true and false.', example='true'),
}

model SetEventCallbackResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetEventCallbackResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SetEventCallback  SetEventCallbackRequest
  * @return SetEventCallbackResponse
 */
async function setEventCallback(request: SetEventCallbackRequest): SetEventCallbackResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetEventCallback', 'POST', '/', 'json', false, 'json', request);
}

model SetNotifyConfigRequest {
  AIAgentId: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
  callbackUrl?: string(name='CallbackUrl', example='http://customer.com/callback', position='Query'),
  enableNotify: boolean(name='EnableNotify', description='This parameter is required.', example='true', position='Query'),
  eventTypes?: string(name='EventTypes', example='agent_start,agent_stop,error', position='Query'),
  token?: string(name='Token', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx', position='Query'),
}

model SetNotifyConfigResponseBody = {
  requestId?: string(name='RequestId', example='771A1414-27BF-53E6-AB73-EFCB*****ACF'),
}

model SetNotifyConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetNotifyConfigResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SetNotifyConfig  SetNotifyConfigRequest
  * @return SetNotifyConfigResponse
 */
async function setNotifyConfig(request: SetNotifyConfigRequest): SetNotifyConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetNotifyConfig', 'POST', '/', 'json', false, 'json', request);
}

model StartAIAgentInstanceRequest {
  AIAgentId: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
  runtimeConfig: AIAgentRuntimeConfig(name='RuntimeConfig', description='This parameter is required.', shrink='json', position='Query'),
  templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', shrink='json', position='Query'),
  userData?: string(name='UserData', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}', position='Query'),
}

model StartAIAgentInstanceResponseBody = {
  instanceId?: string(name='InstanceId', example='39f8e0bc005e4f309379701645f4****'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model StartAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartAIAgentInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of StartAIAgentInstance  StartAIAgentInstanceRequest
  * @return StartAIAgentInstanceResponse
 */
async function startAIAgentInstance(request: StartAIAgentInstanceRequest): StartAIAgentInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartAIAgentInstance', 'POST', '/', 'json', false, 'json', request);
}

model StartRtcRobotInstanceRequest {
  authToken: string(name='AuthToken', description='This parameter is required.', example='**********', position='Query'),
  channelId: string(name='ChannelId', description='This parameter is required.', example='testId', position='Query'),
  config?: {
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt', example='true'),
    greeting?: string(name='Greeting'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    voiceId?: string(name='VoiceId', example='zhixiaoxia'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
  }(name='Config', shrink='json', position='Query'),
  robotId: string(name='RobotId', description='This parameter is required.', example='ca28b08ad3464ebcb42e5c0f7c6d2e89', position='Query'),
  userData?: string(name='UserData', example='{}', position='Query'),
  userId: string(name='UserId', description='This parameter is required.', example='my-robot', position='Query'),
}

model StartRtcRobotInstanceResponseBody = {
  instanceId?: string(name='InstanceId', example='727dc0e296014bb58670940a3da95592'),
  requestId?: string(name='RequestId', description='Id of the request', example='11DE0AB3-603B-5055-8A72-9C424854F983'),
}

model StartRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartRtcRobotInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of StartRtcRobotInstance  StartRtcRobotInstanceRequest
  * @return StartRtcRobotInstanceResponse
 */
async function startRtcRobotInstance(request: StartRtcRobotInstanceRequest): StartRtcRobotInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartRtcRobotInstance', 'POST', '/', 'json', false, 'json', request);
}

model StartWorkflowRequest {
  taskInput?: string(name='TaskInput', description='The workflow input. Only media assets are supported.', example='{
      "Type": "Media",
      "Media": "******30706071edbfe290b488******"
}', position='Query'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which cannot be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.htm).', position='Query'),
  workflowId?: string(name='WorkflowId', description='The ID of the workflow template. To view the template ID, log on to the [IMS console](https://ims.console.aliyun.com/settings/workflow/list) and choose Configurations > Workflow Template.', example='******f0e54971ecbffd472190******', position='Query'),
}

model StartWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******42-E8E1-4FBB-8E52-F4225C******'),
  taskId?: string(name='TaskId', description='The ID of the workflow task.', example='******22dad741d086a50325f9******'),
}

model StartWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartWorkflowResponseBody(name='body'),
}

/**
  * @description *   Only media assets from Intelligent Media Services (IMS) or ApsaraVideo VOD can be used as the input of a workflow.
  * *   When you submit a workflow task, you must specify a workflow template. You can create a workflow template in the [IMS console](https://ims.console.aliyun.com/settings/workflow/list) or use a preset workflow template.
  * @param request  the request parameters of StartWorkflow  StartWorkflowRequest
  * @return StartWorkflowResponse
 */
async function startWorkflow(request: StartWorkflowRequest): StartWorkflowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartWorkflow', 'POST', '/', 'json', false, 'json', request);
}

model StopAIAgentInstanceRequest {
  instanceId: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
}

model StopAIAgentInstanceResponseBody = {
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model StopAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopAIAgentInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of StopAIAgentInstance  StopAIAgentInstanceRequest
  * @return StopAIAgentInstanceResponse
 */
async function stopAIAgentInstance(request: StopAIAgentInstanceRequest): StopAIAgentInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopAIAgentInstance', 'POST', '/', 'json', false, 'json', request);
}

model StopRtcRobotInstanceRequest {
  instanceId: string(name='InstanceId', description='This parameter is required.', example='727dc0e296014bb58670940a3da95592', position='Query'),
}

model StopRtcRobotInstanceResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='AC84E5DD-AB56-56C0-A992-07ECB82008CA'),
}

model StopRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopRtcRobotInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of StopRtcRobotInstance  StopRtcRobotInstanceRequest
  * @return StopRtcRobotInstanceResponse
 */
async function stopRtcRobotInstance(request: StopRtcRobotInstanceRequest): StopRtcRobotInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopRtcRobotInstance', 'POST', '/', 'json', false, 'json', request);
}

model SubmitASRJobRequest {
  description?: string(name='Description', description='The job description, which can up to 128 bytes in length.', example='测试描述', position='Query'),
  duration?: string(name='Duration', description='The speech duration.', example='00:00:10', position='Query'),
  inputFile?: string(name='InputFile', description='The input file. You can specify an Object Storage Service (OSS) URL or the ID of a media asset in the media asset library.', example='oss://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4 或 ****20b48fb04483915d4f2cd8ac****', position='Query'),
  startTime?: string(name='StartTime', description='The start time of the speech to recognize.', example='00:00:00', position='Query'),
  title?: string(name='Title', description='The job title, which can be up to 128 bytes in length.', example='测试标题', position='Query'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format. You can specify your business information, such as the business environment and job information.', example='{
      "user": "data",
      "env": "prod"
}', position='Query'),
}

model SubmitASRJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  state?: string(name='State', description='The job state. Valid values:

*   Created
*   Executing
*   Finished
*   Failed', example='Finished'),
}

model SubmitASRJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitASRJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitASRJob  SubmitASRJobRequest
  * @return SubmitASRJobResponse
 */
async function submitASRJob(request: SubmitASRJobRequest): SubmitASRJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitASRJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitAudioProduceJobRequest {
  description?: string(name='Description', description='The job description.

*   The job description can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.', example='任务描述  长度不超过1024字节  UTF8编码', position='Query'),
  editingConfig: string(name='EditingConfig', description='The audio editing configurations.

*   voice: the [voice type](https://help.aliyun.com/document_detail/402424.html).
*   customizedVoice: the ID of the personalized human voice.
*   format: the format of the output file. Valid values: PCM, WAV, and MP3.
*   volume: the volume. Default value: 50. Valid values: 0 to 100.
*   speech_rate: the speech tempo. Default value: 0. Value range: -500 to 500.
*   pitch_rate: the intonation. Default value: 0. Value range: -500 to 500.

>  If you specify both voice and customizedVoice, customizedVoice takes precedence over voice.

This parameter is required.', example='{"voice":"Siqi","format":"MP3","volume":50}', position='Query'),
  inputConfig: string(name='InputConfig', description='The text content. A maximum of 2,000 characters are supported. The [Speech Synthesis Markup Language (SSML)](https://help.aliyun.com/document_detail/2672807.html) is supported.

This parameter is required.', example='测试文本', position='Query'),
  outputConfig: string(name='OutputConfig', description='The output audio configurations.

This parameter is required.', example='{"bucket":"bucket","object":"objeck"}', position='Query'),
  overwrite?: boolean(name='Overwrite', description='Specifies whether to overwrite the existing Object Storage Service (OSS) object.', example='true', position='Query'),
  title?: string(name='Title', description='The job title. If you do not specify this parameter, the system generates a title based on the current date.

*   The job title can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='任务标题。若不提供，根据日期自动生成默认title  长度不超过128字节  UTF8编码', position='Query'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).', example='{"user":"data"}', position='Query'),
}

model SubmitAudioProduceJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****2bcbfcfa30fccb36f72dca22****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  state?: string(name='State', description='The job state. Valid values:

*   Created
*   Executing
*   Finished
*   Failed', example='Created'),
}

model SubmitAudioProduceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitAudioProduceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitAudioProduceJob  SubmitAudioProduceJobRequest
  * @return SubmitAudioProduceJobResponse
 */
async function submitAudioProduceJob(request: SubmitAudioProduceJobRequest): SubmitAudioProduceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitAudioProduceJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitAvatarTrainingJobRequest {
  jobId: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model SubmitAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****29faef8144638ba42eb8e037****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model SubmitAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitAvatarTrainingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitAvatarTrainingJob  SubmitAvatarTrainingJobRequest
  * @return SubmitAvatarTrainingJobResponse
 */
async function submitAvatarTrainingJob(request: SubmitAvatarTrainingJobRequest): SubmitAvatarTrainingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitAvatarTrainingJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitAvatarVideoJobRequest {
  description?: string(name='Description', example='测试描述', position='Query'),
  editingConfig?: string(name='EditingConfig', example='{"AvatarId":"yunqiao"}', position='Query'),
  inputConfig?: string(name='InputConfig', position='Query'),
  outputConfig?: string(name='OutputConfig', example='{"MediaURL":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/xxx.mp4","Width":1920,"Height":1080}', position='Query'),
  title?: string(name='Title', example='测试标题', position='Query'),
  userData?: string(name='UserData', example='{"user":"data","env":"prod"}', position='Query'),
}

model SubmitAvatarVideoJobResponseBody = {
  jobId?: string(name='JobId', example='****20b48fb04483915d4f2cd8ac****'),
  mediaId?: string(name='MediaId', example='******70dcc471edaf00e6f6f4******'),
  requestId?: string(name='RequestId', description='Id of the request', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitAvatarVideoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitAvatarVideoJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitAvatarVideoJob  SubmitAvatarVideoJobRequest
  * @return SubmitAvatarVideoJobResponse
 */
async function submitAvatarVideoJob(request: SubmitAvatarVideoJobRequest): SubmitAvatarVideoJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitAvatarVideoJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitBatchMediaProducingJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****', position='Query'),
  editingConfig?: string(name='EditingConfig', description='The editing configurations. For more information, see [EditingConfig](~~2692547#1be9bba03b7qu~~).', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}', position='Body'),
  inputConfig?: string(name='InputConfig', description='The input configurations. For more information, see [InputConfig](~~2692547#2faed1559549n~~).', position='Body'),
  outputConfig?: string(name='OutputConfig', description='The output configurations. For more information, see [OutputConfig](~~2692547#447b928fcbuoa~~).', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 20,
  "MaxDuration": 15,
  "Width": 1080,
  "Height": 1920,
  "Video": {"Crf": 27}
}', position='Query'),
  userData?: string(name='UserData', description='The user-defined data, including the business and callback configurations. For more information, see [UserData](https://help.aliyun.com/document_detail/357745.html?spm=a2c4g.439285.0.i1#section-urj-v3f-0s1).', position='Query'),
}

model SubmitBatchMediaProducingJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the quick video production job.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model SubmitBatchMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitBatchMediaProducingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitBatchMediaProducingJob  SubmitBatchMediaProducingJobRequest
  * @return SubmitBatchMediaProducingJobResponse
 */
async function submitBatchMediaProducingJob(request: SubmitBatchMediaProducingJobRequest): SubmitBatchMediaProducingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitBatchMediaProducingJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitCustomizedVoiceJobRequest {
  demoAudioMediaURL?: string(name='DemoAudioMediaURL', description='The URL of the sample audio file.

*   If this parameter is specified, a sample audio file is generated at the specified Object Storage Service (OSS) URL after the training is complete.

*   If this parameter is not specified, no sample audio file is generated.

    **

    **Note**: The URL must be a valid public OSS URL within your Alibaba Cloud account.', example='https://your-bucket.oss-cn-shanghai.aliyuncs.com/demo.MP3', position='Query'),
  voiceId: string(name='VoiceId', description='The voice ID.

This parameter is required.', example='xiaozhuan', maxLength=32, position='Query'),
}

model SubmitCustomizedVoiceJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****d718e2ff4f018ccf419a7b71****'),
    voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model SubmitCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitCustomizedVoiceJob  SubmitCustomizedVoiceJobRequest
  * @return SubmitCustomizedVoiceJobResponse
 */
async function submitCustomizedVoiceJob(request: SubmitCustomizedVoiceJobRequest): SubmitCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitDNAJobRequest {
  config?: string(name='Config', description='The configurations of the media fingerprint analysis job. The value is a JSON object. If you specify this parameter, the template parameters are overwritten.', example='{"SaveType": "save","MediaType"":"video"}', position='Query'),
  DBId: string(name='DBId', description='The ID of the media fingerprint library. If you do not specify this parameter, the default media fingerprint library is used. For more information about how to create a media fingerprint library, see [CreateDNADB](https://help.aliyun.com/document_detail/479275.html).

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****', position='Query'),
  input: {
    media: string(name='Media', description='The input file. The file can be an OSS object or a media asset. You can specify the path of an OSS object in one of the following formats:

1\\. oss://bucket/object

2\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the preceding paths, bucket indicates an OSS bucket that resides in the same region as the current project, and object indicates the path of the object in the bucket.

This parameter is required.', example='1b1b9cd148034739af413150fded****'),
    type: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: Object Storage Service (OSS) object.
2.  Media: media asset.

This parameter is required.', example='Media'),
  }(name='Input', description='The input file for media fingerprint analysis.

This parameter is required.', shrink='json', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the media fingerprint analysis job is submitted.', example='5246b8d12a62433ab77845074039****', position='Query'),
  primaryKey: string(name='PrimaryKey', description='The primary key of the video. You must make sure that each primary key is unique.

This parameter is required.', example='3ca84a39a9024f19853b21be9cf9****', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID.', example='S00000101-100060', position='Query'),
  userData?: string(name='UserData', description='The user-defined data. The data can be up to 128 bytes in length.', example='userData', position='Query'),
}

model SubmitDNAJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the media fingerprint analysis job. We recommend that you save this ID for subsequent calls of other operations.', example='88c6ca184c0e47098a5b665e2****'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model SubmitDNAJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitDNAJobResponseBody(name='body'),
}

/**
  * @description *   SubmitDNAJob is an asynchronous operation. After a request is sent, the system returns a request ID and a job ID and runs the task in the background.
  * *   You can call this operation only in the China (Beijing), China (Hangzhou), and China (Shanghai) regions.
  * *   You can submit a text fingerprint analysis job only in the China (Shanghai) region.
  * @param request  the request parameters of SubmitDNAJob  SubmitDNAJobRequest
  * @return SubmitDNAJobResponse
 */
async function submitDNAJob(request: SubmitDNAJobRequest): SubmitDNAJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitDNAJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitDynamicChartJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  axisParams?: string(name='AxisParams', example='{"FontFile":"Microsoft YaHei","XAxisFontSize":"30","YAxisFontSize":"30","XAxisFontInterval":"30","AxisColor":"30"}', position='Query'),
  background?: string(name='Background', example='{"Color":"#000000","ImageUrl":"http://your-bucket.oss-cn-shanghai.aliyuncs.com/obj.jpg"}', position='Query'),
  chartConfig?: string(name='ChartConfig', example='{"Style":"Normal","TitleStartTime":"3000","ChartStartTime":"3000","VideoDuration":"15000"}', position='Query'),
  chartTitle?: string(name='ChartTitle', position='Query'),
  chartType: string(name='ChartType', description='This parameter is required.', example='Line', position='Query'),
  dataSource?: string(name='DataSource', position='Query'),
  description?: string(name='Description', position='Query'),
  input: string(name='Input', description='This parameter is required.', example='{"XlsFile":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/obj.xls"}', position='Query'),
  outputConfig: string(name='OutputConfig', description='This parameter is required.', example='{"MediaURL":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/obj.mp4","Bitrate":2000,"Width":800,"Height":680}', position='Query'),
  subtitle?: string(name='Subtitle', position='Query'),
  title?: string(name='Title', position='Query'),
  unit?: string(name='Unit', position='Query'),
  userData?: string(name='UserData', example='{"user":"data"}', position='Query'),
}

model SubmitDynamicChartJobResponseBody = {
  jobId?: string(name='JobId', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitDynamicChartJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitDynamicChartJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitDynamicChartJob  SubmitDynamicChartJobRequest
  * @return SubmitDynamicChartJobResponse
 */
async function submitDynamicChartJob(request: SubmitDynamicChartJobRequest): SubmitDynamicChartJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitDynamicChartJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitDynamicImageJobRequest {
  input: {
    media: string(name='Media', description='The input file. If Type is set to OSS, set this parameter to the URL of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/440592.html) page of the Intelligent Media Services (IMS) console.

This parameter is required.', example='oss://bucket/object.mp4'),
    type: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.

*
*

This parameter is required.', example='OSS'),
  }(name='Input', description='The input of the job.

This parameter is required.', shrink='json', position='Query'),
  name?: string(name='Name', description='The name of the job.', example='SampleJob', position='Query'),
  output: {
    media: string(name='Media', description='The output file. The file can be an OSS object or a media asset. The URL of an OSS object can be in one of the following formats:

*   oss://bucket/object
*   http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/440592.html) page of the IMS console.

This parameter is required.', example='****96e8864746a0b6f3****'),
    type: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

*
*

This parameter is required.', example='Media'),
  }(name='Output', description='The output of the job.

This parameter is required.', shrink='json', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****96e8864746a0b6f3****'),
    priority?: int32(name='Priority', description='The priority. Valid values: 1 to 10. Default value: 6. A greater value specifies a higher priority.', example='6'),
  }(name='ScheduleConfig', description='The scheduling settings.', shrink='json', position='Query'),
  templateConfig: {
    overwriteParams?: {
      format?: string(name='Format', description='The format of the animated image. Valid values:

*   **gif**
*   **webp**', example='gif'),
      fps?: int32(name='Fps', description='The frame rate. Valid values: [1,60].', example='15'),
      height?: int32(name='Height', description='The height of the animated image. Valid values: [128,4096].', example='720'),
      longShortMode?: boolean(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature. Valid values:

*   **true**
*   **false**

Default value: **true**.

>  If this feature is enabled, the width of the output video corresponds to the long side of the input video, which is the height of the input video in portrait mode. The height of the output video corresponds to the short side of the input video, which is the width of the input video in portrait mode.', example='false'),
      scanMode?: string(name='ScanMode', description='The scan mode. Valid values:

*   **interlaced**
*   **progressive** This is the default value.', example='progressive'),
      timeSpan?: {
        duration?: string(name='Duration', description='The length of the clip.

*   Format: `hh:mm:ss[.SSS]` or `sssss[.SSS]`.
*   Valid values: `[00:00:00.000,23:59:59.999]` or `[0.000,86399.999]`.'),
        end?: string(name='End', description='The length of the ending part of the original clip to be cropped out. If you specify this parameter, the Duration parameter becomes invalid.

*   Format: `hh:mm:ss[.SSS]` or `sssss[.SSS]`.
*   Valid values: `[00:00:00.000,23:59:59.999]` or `[0.000,86399.999]`.'),
        seek?: string(name='Seek', description='The start point of the clip.

*   Format: `hh:mm:ss[.SSS]` or `sssss[.SSS]`.
*   Valid values: `[00:00:00.000,23:59:59.999]` or `[0.000,86399.999]`.'),
      }(name='TimeSpan', description='The timeline parameters.'),
      width?: int32(name='Width', description='The width of the animated image. Valid values: [128,4096].', example='1024'),
    }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters.'),
    templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
  }(name='TemplateConfig', description='The snapshot template configuration.

This parameter is required.', shrink='json', position='Query'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"SampleKey": "SampleValue"}', position='Query'),
}

model SubmitDynamicImageJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitDynamicImageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitDynamicImageJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitDynamicImageJob  SubmitDynamicImageJobRequest
  * @return SubmitDynamicImageJobResponse
 */
async function submitDynamicImageJob(request: SubmitDynamicImageJobRequest): SubmitDynamicImageJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitDynamicImageJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitIProductionJobRequest {
  functionName: string(name='FunctionName', description='The name of the algorithm that you want to use for the job. Valid values:

*   **Cover**: This algorithm intelligently generates a thumbnail image for a video.
*   **VideoClip**: This algorithm intelligently generates a summary for a video.
*   **VideoDelogo**: This algorithm removes logos from a video.
*   **VideoDetext**: This algorithm removes captions from a video.
*   **CaptionExtraction**: This algorithm extracts captions from a video and generates the caption file.
*   **VideoGreenScreenMatting**: This algorithm performs green-screen image matting on a video and generates a new video.
*   **FaceBeauty**: This algorithm performs video retouching.
*   **VideoH2V**: This algorithm transforms a video from the landscape mode to the portrait mode.
*   **MusicSegmentDetect**: This algorithm detects the chorus of a song.
*   **AudioBeatDetection**: This algorithm detects rhythms.
*   **AudioQualityAssessment**: This algorithm assesses the audio quality.
*   **SpeechDenoise**: This algorithm performs noise reduction.
*   **AudioMixing**: This algorithm mixes audio streams.

This parameter is required.', example='Cover', position='Query'),
  input: {
    media: string(name='Media', description='The input file. The file can be an OSS object or a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[regionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.

This parameter is required.', example='oss://bucket/object'),
    type: string(name='Type', description='The media type. Valid values:

*   OSS: OSS object
*   Media: media asset

This parameter is required.', example='OSS'),
  }(name='Input', description='The input file. The file can be an Object Storage Service (OSS) object or a media asset.

This parameter is required.', shrink='json', position='Query'),
  jobParams?: string(name='JobParams', description='The algorithm-specific parameters. The parameters are specified as JSON objects and vary based on the algorithm. For more information, see the "Parameters of JobParams" section of this topic.', example='{"Model":"gif"}', position='Query'),
  modelId?: string(name='ModelId', position='Query'),
  name?: string(name='Name', description='The name of the intelligent production job. The name can be up to 100 characters in length.', position='Query'),
  output: {
    media: string(name='Media', description='The output file. If Type is set to OSS, set this parameter to the path of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.

This parameter is required.', example='oss://bucket/object'),
    type: string(name='Type', description='The media type. Valid values:

*   OSS: OSS object
*   Media: media asset

This parameter is required.', example='OSS'),
  }(name='Output', description='The output file. The file can be an OSS object or a media asset.

This parameter is required.', shrink='json', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue.', example='5246b8d12a62433ab77845074039c3dc'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. A smaller value indicates a higher priority.', example='6'),
  }(name='ScheduleConfig', description='The scheduling configuration.', shrink='json', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  userData?: string(name='UserData', description='The user-defined data that is returned in the response. The value can be up to 1,024 bytes in length.', example='{"test":1}', position='Query'),
}

model SubmitIProductionJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the intelligent production job.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='C1849434-FC47-5DC1-92B6-F7EAAFE3851E'),
}

model SubmitIProductionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitIProductionJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitIProductionJob  SubmitIProductionJobRequest
  * @return SubmitIProductionJobResponse
 */
async function submitIProductionJob(request: SubmitIProductionJobRequest): SubmitIProductionJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitIProductionJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitLiveEditingJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  clips: string(name='Clips', description='The clips in the JSON array format. The output video is created by merging these clips sequentially.

Each clip has a start time and an end time. If no live stream parameters are specified, the outer live stream configurations apply. The start and end timestamps are in UTC. For more information about the parameters, see the "Clip" section of this topic.

This parameter is required.', example='[{\\"StartTime\\": \\" 2021-06-21T08:01:00Z\\",  \\"EndTime\\": \\" 2021-06-21T08:03:00Z\\" ,  "AppName": "app", "DomainName": "domain.com", "StreamName": "stream"},  {\\"StartTime\\": \\" 2021-06-21T08:05:00Z\\",  \\"EndTime\\": \\" 2021-06-21T08:09:00Z\\" }]', position='Query'),
  liveStreamConfig?: string(name='LiveStreamConfig', description='The live stream configurations, in the JSON format. The configurations must include the following parameters:

*   AppName: the name of the application to which the live stream belongs.
*   DomainName: the domain name of the application.
*   StreamName: the name of the live stream.', example='{ "AppName": "app", "DomainName": "domain.com", "StreamName": "stream"  }', position='Query'),
  mediaProduceConfig?: string(name='MediaProduceConfig', description='The production configurations, in the JSON format. Mode specifies the editing mode. Valid values:

*   **AccurateFast** (default): fast editing. It is faster than the Accurate mode. The resolution of the output file is the same as that of the source stream. You cannot specify the width and height of the output file.
*   **Accurate**: accurate editing. In this mode, you can specify the width and height of the output file.
*   **Rough**: rough editing. The minimum precision is one TS segment. The output file comprises all segments within the specified time range. You can specify the width and height of the output file.
*   **RoughFast**: fast rough editing. It is faster than the Accurate mode. The minimum precision is one TS segment. The output file comprises all segments within the specified time range. The resolution of the output file is the same as that of the source stream. You cannot specify the width and height of the output file.', example='{ "Mode": "AccurateFast"}', position='Query'),
  outputMediaConfig?: string(name='OutputMediaConfig', description='The configurations of the output file, in the JSON format. You can specify an OSS URL or a storage location in a storage bucket of ApsaraVideo VOD.

*   To store the output file in OSS, you must specify MediaURL.
*   To store the output file in ApsaraVideo VOD, you must specify StorageLocation and FileName.', position='Query'),
  outputMediaTarget?: string(name='OutputMediaTarget', description='The type of the output file. Valid values:

*   oss-object: OSS object in an OSS bucket.
*   vod-media: media asset in Alibaba Cloud VOD.', example='oss-object', position='Query'),
  projectId?: string(name='ProjectId', description='The ID of the live editing project. If this parameter is specified, the system reads the storage configurations of the project. If this parameter is not specified, the specified storage configurations take precedence.', example='****fddd7748b58bf1d47e95****', position='Query'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length.', example='{"key": "value"}', position='Query'),
}

model SubmitLiveEditingJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the live editing job.', example='****d80e4e4044975745c14b****'),
  mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****c469e944b5a856828dc2****'),
  mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://test-bucket.cn-shanghai.aliyuncs.com/test.mp4'),
  projectId?: string(name='ProjectId', description='The ID of the live editing project.', example='****fddd7748b58bf1d47e95****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
  vodMediaId?: string(name='VodMediaId', description='The media asset ID of the output file in ApsaraVideo VOD if the output file is stored in ApsaraVideo VOD.', example='****d7578s4h75ci945c14b****'),
}

model SubmitLiveEditingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveEditingJobResponseBody(name='body'),
}

/**
  * @description Live editing is supported for live streams that are recorded and stored in Object Storage Service (OSS) and ApsaraVideo VOD. If multiple live streams are involved in a single job, only those recorded within the same application are supported for mixed editing. The streams must all be recorded either in OSS or ApsaraVideo VOD.
  * @param request  the request parameters of SubmitLiveEditingJob  SubmitLiveEditingJobRequest
  * @return SubmitLiveEditingJobResponse
 */
async function submitLiveEditingJob(request: SubmitLiveEditingJobRequest): SubmitLiveEditingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitLiveEditingJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitLiveRecordJobRequest {
  name: string(name='Name', description='The name of the recording job.

This parameter is required.', example='live stream record 1', position='Body'),
  notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify', position='Body'),
  recordOutput: {
    bucket?: string(name='Bucket', description='The bucket name.', example='imsbucket1'),
    endpoint?: string(name='Endpoint', description='The endpoint of the storage service.', example='oss-cn-hangzhou.aliyuncs.com'),
    type: string(name='Type', description='The type of the storage address.

This parameter is required.', example='oss'),
  }(name='RecordOutput', description='The storage address of the recording.

This parameter is required.', shrink='json', position='Body'),
  streamInput: {
    type: string(name='Type', description='The type of the live stream URL. The value can only be rtmp.

This parameter is required.', example='rtmp'),
    url?: string(name='Url', description='The URL of the live stream.', example='rtmp://example.com/live/stream1'),
  }(name='StreamInput', description='The URL of the live stream.

This parameter is required.', shrink='json', position='Body'),
  templateId: string(name='TemplateId', description='The ID of the recording template.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66', position='Body'),
}

model SubmitLiveRecordJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the recording job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
}

model SubmitLiveRecordJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveRecordJobResponseBody(name='body'),
}

/**
  * @description You can call this operation to record live streams of ApsaraVideo Live or third-party Real-Time Messaging Protocol (RTMP) live streams. We recommend that you ingest a stream before you call this operation to submit a recording job. If no stream is pulled from the streaming URL, the job attempts to pull a stream for 3 minutes. If the attempt times out, the recording service stops.
  * Before you submit a recording job, you must prepare an Object Storage Service (OSS) or ApsaraVideo VOD bucket. We recommend that you use a storage address configured in Intelligent Media Services (IMS) to facilitate the management and processing of generated recording files.
  * If the preset recording template does not meet your requirements, you can create a custom recording template.
  * @param request  the request parameters of SubmitLiveRecordJob  SubmitLiveRecordJobRequest
  * @return SubmitLiveRecordJobResponse
 */
async function submitLiveRecordJob(request: SubmitLiveRecordJobRequest): SubmitLiveRecordJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitLiveRecordJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitLiveSnapshotJobRequest {
  callbackUrl?: string(name='CallbackUrl', description='The snapshot callback URL.

*   It cannot exceed 255 characters in length.
*   Both HTTP and HTTPS URLs are supported.', example='http://www.aliyun.com/snapshot/callback', position='Body'),
  jobName: string(name='JobName', description='The name of the job.

*   It cannot exceed 128 characters in length.

This parameter is required.', position='Body'),
  snapshotOutput: {
    bucket: string(name='Bucket', description='The bucket of the snapshot output endpoint.

This parameter is required.', example='testbucket'),
    endpoint: string(name='Endpoint', description='The output endpoint of the snapshot.

This parameter is required.', example='oss-cn-shanghai.aliyuncs.com'),
    storageType: string(name='StorageType', description='The storage type of the snapshot. The value can only be oss.

This parameter is required.', example='oss'),
  }(name='SnapshotOutput', description='The information about the output snapshot.

This parameter is required.', shrink='json', position='Body'),
  streamInput: {
    type: string(name='Type', description='The type of the input stream. The value can only be rtmp.

This parameter is required.', example='rtmp'),
    url: string(name='Url', description='The URL of the input stream.

*   It cannot exceed 255 characters in length.

This parameter is required.', example='rtmp://www.aliyun.com/stream'),
  }(name='StreamInput', description='The information about the input stream.

This parameter is required.', shrink='json', position='Body'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Body'),
}

model SubmitLiveSnapshotJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287666****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitLiveSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveSnapshotJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitLiveSnapshotJob  SubmitLiveSnapshotJobRequest
  * @return SubmitLiveSnapshotJobResponse
 */
async function submitLiveSnapshotJob(request: SubmitLiveSnapshotJobRequest): SubmitLiveSnapshotJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitLiveSnapshotJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitLiveTranscodeJobRequest {
  name: string(name='Name', description='The name of the transcoding job.

This parameter is required.', example='task1', minLength=1, maxLength=128, position='Query'),
  startMode: int32(name='StartMode', description='The start mode of the transcoding job.

*   0: The transcoding job immediately starts.
*   1: The transcoding job starts at the scheduled time.

This parameter is required.', example='0', position='Query'),
  streamInput: {
    inputUrl: string(name='InputUrl', description='The URL of the input stream.

This parameter is required.', example='rtmp://mydomain/app/stream1'),
    type: string(name='Type', description='The type of the input stream. The value can only be rtmp.

This parameter is required.', example='rtmp'),
  }(name='StreamInput', description='The information about the input stream.

This parameter is required.', shrink='json', position='Query'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****', position='Query'),
  timedConfig?: {
    endTime?: string(name='EndTime', description='The stop time of the transcoding job. Note: The time span between the stop time and the current time cannot exceed seven days.', example='2022-07-20T08:20:32Z'),
    startTime?: string(name='StartTime', description='The start time of the transcoding job. Note: The time span between the start time and the current time cannot exceed seven days.', example='2022-02-21T00:00:00Z'),
  }(name='TimedConfig', description='The configuration of a timed transcoding job. This parameter is required if you set StartMode to 1.', shrink='json', position='Query'),
  transcodeOutput: {
    domainName?: string(name='DomainName', description='The streaming domain name of ApsaraVideo Live.', example='mydomain'),
    type: string(name='Type', description='The type of the output stream. A value of LiveCenter indicates that the URL of the output stream is generated based on the domain name of ApsaraVideo Live. The value can only be LiveCenter.

This parameter is required.', example='LiveCenter'),
  }(name='TranscodeOutput', description='The information about the transcoding output.

This parameter is required.', shrink='json', position='Query'),
}

model SubmitLiveTranscodeJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the transcoding job.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model SubmitLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveTranscodeJobResponseBody(name='body'),
}

/**
  * @description *   When you submit a transcoding job that immediately takes effect, make sure that the input stream can be streamed.
  * *   When you submit a timed transcoding job, make sure that the input stream can be streamed before the specified time.
  * @param request  the request parameters of SubmitLiveTranscodeJob  SubmitLiveTranscodeJobRequest
  * @return SubmitLiveTranscodeJobResponse
 */
async function submitLiveTranscodeJob(request: SubmitLiveTranscodeJobRequest): SubmitLiveTranscodeJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitLiveTranscodeJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitMediaAiAnalysisJobRequest {
  analysisParams?: string(name='AnalysisParams', description='The analysis parameters.', example='{"nlpParams":{"sourceLanguage":"cn","diarizationEnabled":true,"speakerCount":0,"summarizationEnabled":false,"translationEnabled":false}}', position='Query'),
  input?: string(name='Input', description='The media asset that you want to analyze. You can specify an Object Storage Service (OSS) URL, a media asset ID, or an external URL.', example='{"MediaType":"video","Media":"https://xxx.com/your_movie.mp4"}', position='Query'),
}

model SubmitMediaAiAnalysisJobResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model SubmitMediaAiAnalysisJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaAiAnalysisJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitMediaAiAnalysisJob  SubmitMediaAiAnalysisJobRequest
  * @return SubmitMediaAiAnalysisJobResponse
 */
async function submitMediaAiAnalysisJob(request: SubmitMediaAiAnalysisJobRequest): SubmitMediaAiAnalysisJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitMediaAiAnalysisJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitMediaCensorJobRequest {
  barrages?: string(name='Barrages', description='The live comments of the video.

>  If this parameter is specified, the system checks the live comments specified by this parameter instead of the live comments of the input file specified by Media.', example='hello world', position='Query'),
  coverImages?: string(name='CoverImages', description='The Object Storage Service (OSS) objects that are used as the thumbnails. Specify the thumbnails in a JSON array. A maximum of five thumbnails are supported.

>  If this parameter is specified, the system checks the thumbnails specified by this parameter instead of the thumbnails of the input file specified by **Media**.', example='[{"Bucket":"example-bucket-****","Location":"oss-cn-shanghai","Object":"example-****.jpeg","RoleArn":"acs:ram::1997018457688683:role/AliyunICEDefaultRole"}]', position='Query'),
  description?: string(name='Description', description='The video description, which can be up to 128 bytes in length.

>  If this parameter is specified, the system checks the description specified by this parameter instead of the description of the input file specified by Media.', example='example description', position='Query'),
  input?: {
    media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. You can specify the path of an OSS object in one of the following formats:

1\\. oss://bucket/object

2\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the preceding paths, bucket indicates an OSS bucket that resides in the same region as the current project, and object indicates the path of the object in the bucket.', example='1b1b9cd148034739af413150fded****'),
    type?: string(name='Type', description='The type of the input file. Valid values:

OSS: OSS object.

Media: media asset.', example='Media'),
  }(name='Input', description='The information about the file to be moderated.', shrink='json', position='Query'),
  notifyUrl?: string(name='NotifyUrl', description='The callback URL. Simple Message Queue (SMQ, formerly MNS) and HTTP callbacks are supported.', example='mns://125340688170****.oss-cn-shanghai.aliyuncs.com/queues/example-pipeline', position='Query'),
  output?: string(name='Output', description='The output snapshots. The moderation job generates output snapshots and the result JSON file in the path corresponding to the input file.

*   File name format of output snapshots: oss://bucket/snapshot-{Count}.jpg. In the path, bucket indicates an OSS bucket that resides in the same region as the current project, and {Count} is the sequence number of the snapshot.
*   The detailed moderation results are stored in the {jobId}.output file in the same OSS folder as the output snapshots. For more information about the parameters in the output file, see [Output parameters of media moderation jobs](https://help.aliyun.com/document_detail/609211.html).', example='oss://sashimi-cn-shanghai/censor/snapshot-{Count}.jpg', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the job is submitted.', example='5246b8d12a62433ab77845074039****'),
    priority?: int32(name='Priority', description='The job priority. A larger value indicates a higher priority. Valid values: 1 to 10.', example='6'),
  }(name='ScheduleConfig', description='The scheduling configurations.', shrink='json', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID. If this parameter is not specified, the default template is used for moderation.', example='S00000001-100060', position='Query'),
  title?: string(name='Title', description='The video title, which can be up to 64 bytes in length.

>  If this parameter is specified, the system checks the title specified by this parameter instead of the title of the input file specified by Media.', example='Hello World', position='Query'),
  userData?: string(name='UserData', description='The user-defined data, which can be up to 128 bytes in length.', example='UserDatatestid-001-****', position='Query'),
}

model SubmitMediaCensorJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the content moderation job. We recommend that you save this ID for subsequent calls of other operations.', example='88c6ca184c0e47098a5b665e2****'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model SubmitMediaCensorJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaCensorJobResponseBody(name='body'),
}

/**
  * @description The job that you submit by calling this operation is run in asynchronous mode. The job is added to an ApsaraVideo Media Processing (MPS) queue to be scheduled and run. You can call the [QueryMediaCensorJobDetail](https://help.aliyun.com/document_detail/444847.html) operation or configure an asynchronous notification to obtain the job results.
  * @param request  the request parameters of SubmitMediaCensorJob  SubmitMediaCensorJobRequest
  * @return SubmitMediaCensorJobResponse
 */
async function submitMediaCensorJob(request: SubmitMediaCensorJobRequest): SubmitMediaCensorJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitMediaCensorJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitMediaInfoJobRequest {
  input: {
    media: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/440592.html) page of the Intelligent Media Services (IMS) console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
    type: string(name='Type', description='The type of the media object. Valid values: OSS and Media. A value of OSS indicates an Object Storage Service (OSS) object. A value of Media indicates a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The input of the job.

This parameter is required.', shrink='json', position='Query'),
  name?: string(name='Name', description='The job name.', example='job-name', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling parameters.', shrink='json', position='Query'),
  userData?: string(name='UserData', description='The user data.', example='user-data', position='Query'),
}

model SubmitMediaInfoJobResponseBody = {
  mediaInfoJob?: {
    async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
    input?: {
      media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values: OSS and Media. A value of OSS indicates an OSS object. A value of Media indicates a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    mediaInfoProperty?: {
      audioStreamInfoList?: [ 
        {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
          channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
          codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
          codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
          codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
          codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
          duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
          index?: string(name='Index', description='The sequence number of the stream.', example='1'),
          lang?: string(name='Lang', description='The language of the stream.', example='us'),
          sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
          sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
          startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
          timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
        }
      ](name='AudioStreamInfoList', description='The information about the audio stream.'),
      fileBasicInfo?: {
        bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
        duration?: string(name='Duration', description='The duration of the video.', example='403.039999'),
        fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
        fileSize?: string(name='FileSize', description='The file size.', example='31737'),
        fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
        fileType?: string(name='FileType', description='The file type.', example='source_file'),
        fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
        formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
        height?: string(name='Height', description='The height of the output video.', example='478'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='2b36bd19c13f4145b094c0cad80dbce5'),
        region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
        width?: string(name='Width', description='The width of the output video.', example='848'),
      }(name='FileBasicInfo', description='The basic file information.'),
      videoStreamInfoList?: [ 
        {
          avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
          bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
          codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
          codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
          codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
          codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
          codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
          dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          fps?: string(name='Fps', description='The frame rate.', example='25.0'),
          hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
          height?: string(name='Height', description='The height of the output video.', example='478'),
          index?: string(name='Index', description='The sequence number of the stream.', example='0'),
          lang?: string(name='Lang', description='The language of the stream.', example='zh'),
          level?: string(name='Level', description='The codec level.', example='31'),
          numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
          pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
          profile?: string(name='Profile', description='The encoder profile.', example='High'),
          rotate?: string(name='Rotate', description='The rotation angle of the video image.', example='0'),
          sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
          startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
          timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
          width?: string(name='Width', description='The width of the output video.', example='848'),
        }
      ](name='VideoStreamInfoList', description='The information about the video stream.'),
    }(name='MediaInfoProperty', description='The details of the media information.'),
    name?: string(name='Name', description='The job name.', example='job-name'),
    requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling information.'),
    status?: string(name='Status', description='The state of the job. Valid values: Init (the job is submitted), Success (the job is successful), and Fail (the job failed).', example='Init'),
    submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.', example='{}'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='MediaInfoJob', description='MediaInfoJobDTO'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model SubmitMediaInfoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaInfoJobResponseBody(name='body'),
}

/**
  * @description You can call this operation to analyze an input media file by using a callback mechanism or initiating subsequent queries. This operation is suitable for scenarios in which real-time performance is less critical and high concurrency is expected.
  * @param request  the request parameters of SubmitMediaInfoJob  SubmitMediaInfoJobRequest
  * @return SubmitMediaInfoJobResponse
 */
async function submitMediaInfoJob(request: SubmitMediaInfoJobRequest): SubmitMediaInfoJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitMediaInfoJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitMediaProducingJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****', position='Query'),
  clipsParam?: string(name='ClipsParam', description='The material parameters of the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified. For more information, see [Create and use a regular template](https://help.aliyun.com/document_detail/328557.html) and [Create and use advanced templates](https://help.aliyun.com/document_detail/291418.html).', position='Query'),
  editingProduceConfig?: string(name='EditingProduceConfig', description='The parameters for editing and production. For more information, see [EditingProduceConfig](https://help.aliyun.com/document_detail/357745.html#title-10z-t9u-n69).

>  If no thumbnail is specified in EditingProduceConfig, the first frame of the video is used as the thumbnail.

*   AutoRegisterInputVodMedia: specifies whether to automatically register the ApsaraVideo VOD media assets in your timeline with IMS. Default value: true.
*   OutputWebmTransparentChannel: specifies whether the output video contains alpha channels. Default value: false.
*   CoverConfig: the custom thumbnail parameters.
*', example='{
      "AutoRegisterInputVodMedia": "true",
      "OutputWebmTransparentChannel": "true"
}', position='Query'),
  mediaMetadata?: string(name='MediaMetadata', description='The metadata of the produced video, in the JSON format. For more information about the parameters, see [MediaMetadata](https://help.aliyun.com/document_detail/357745.html?spm=a2c4g.445712.0.0.49a716dbA8hgdz#97ff26d0e3c28).', example='{
      "Title":"test-title",
      "Tags":"test-tags1,tags2"
}', position='Query'),
  outputMediaConfig: string(name='OutputMediaConfig', description='The configurations of the output file, in the JSON format. You can specify an OSS URL or a storage location in a storage bucket of ApsaraVideo VOD.

To store the output file in OSS, you must specify MediaURL. To store the output file in ApsaraVideo VOD, you must specify StorageLocation and FileName.

For more information, see [OutputMediaConfig](https://help.aliyun.com/document_detail/357745.html#title-4j6-ve7-g31).

This parameter is required.', example='{"MediaURL":"https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4"}', position='Query'),
  outputMediaTarget?: string(name='OutputMediaTarget', description='The type of the output file. Valid values:

*   oss-object: OSS object in an OSS bucket.
*   vod-media: media asset in ApsaraVideo VOD.
*   S3: output file based on the Amazon Simple Storage Service (S3) protocol.', example='oss-object', position='Query'),
  projectId?: string(name='ProjectId', description='The ID of the editing project.

> : You must specify one of ProgectId, Timeline, and TempalteId and leave the other two parameters empty.', example='xxxxxfb2101cb318xxxxx', position='Query'),
  projectMetadata?: string(name='ProjectMetadata', description='The metadata of the editing project, in the JSON format. For more information about the parameters, see [ProjectMetadata](https://help.aliyun.com/document_detail/357745.html#title-yvp-81k-wff).', position='Query'),
  source?: string(name='Source', description='The source of the editing and production request. Valid values:

*   OpenAPI
*   AliyunConsole
*   WebSDK', example='OPENAPI', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID. The template is used to build a timeline with ease.

> : You must specify one of ProgectId, Timeline, and TempalteId and leave the other two parameters empty. If TemplateId is specified, ClipsParam must also be specified.', example='****96e8864746a0b6f3****', position='Query'),
  timeline?: string(name='Timeline', position='Body'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).', example='{"NotifyAddress":"https://xx.com/xx","RegisterMediaNotifyAddress":"https://xxx.com/xx"}', position='Query'),
}

model SubmitMediaProducingJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
  mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****c469e944b5a856828dc2****'),
  projectId?: string(name='ProjectId', description='The ID of the editing project.', example='****b4549d46c88681030f6e****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
  vodMediaId?: string(name='VodMediaId', description='The media asset ID of the output file in ApsaraVideo VOD if the output file is stored in ApsaraVideo VOD.', example='****d8s4h75ci975745c14b****'),
}

model SubmitMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaProducingJobResponseBody(name='body'),
}

/**
  * @description *   This operation returns only the submission result of a media editing and production job. When the submission result is returned, the job may still be in progress. After a media editing and production job is submitted, the job is queued in the background for asynchronous processing.
  * *   The materials referenced in the timeline of an online editing project can be media assets in the media asset library or Object Storage Service (OSS) objects. External URLs or Alibaba Cloud Content Delivery Network (CDN) URLs are not supported. To use an OSS object as a material, you must set MediaUrl to an OSS URL, such as https://your-bucket.oss-region-name.aliyuncs.com/your-object.ext.
  * *   After the production is complete, the output file is automatically registered as a media asset. The media asset first needs to be analyzed. After the media asset is analyzed, you can query the duration and resolution information based on the media asset ID.
  * ## [](#)Limits
  * *   The throttling threshold of this operation is 30 queries per second (QPS).
  *     **
  *     **Note** If the threshold is exceeded, a "Throttling.User" error is returned when you submit an editing job. For more information about how to resolve this issue, see the [FAQ](https://help.aliyun.com/document_detail/453484.html).
  * *   You can create up to 100 video tracks, 100 image tracks, and 100 subtitle tracks in a project.
  * *   The total size of material files cannot exceed 1 TB.
  * *   The OSS buckets in which the materials reside and where the output media assets are stored must be in the same region as the region in which Intelligent Media Services (IMS) is activated.
  * *   An output video must meet the following requirements:
  *     *   Both the width and height must be at least 128 pixels.
  *     *   Both the width and height cannot exceed 4,096 pixels.
  *     *   The shorter side of the video cannot exceed 2,160 pixels.
  * @param request  the request parameters of SubmitMediaProducingJob  SubmitMediaProducingJobRequest
  * @return SubmitMediaProducingJobResponse
 */
async function submitMediaProducingJob(request: SubmitMediaProducingJobRequest): SubmitMediaProducingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitMediaProducingJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitPackageJobRequest {
  inputs: [ 
    {
      input: {
        media: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
        type: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
      }(name='Input', description='The information about the input stream file.

This parameter is required.'),
    }
  ](name='Inputs', description='The input of the job.

This parameter is required.', shrink='json', position='Query'),
  name?: string(name='Name', description='The name of the job.', example='job-name', position='Query'),
  output: {
    media: string(name='Media', description='The media object. If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
    type: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Output', description='The output of the job.

This parameter is required.', shrink='json', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling settings.', shrink='json', position='Query'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}', position='Query'),
}

model SubmitPackageJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='2d705f385b704ee5b*******a36d93e0'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model SubmitPackageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitPackageJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitPackageJob  SubmitPackageJobRequest
  * @return SubmitPackageJobResponse
 */
async function submitPackageJob(request: SubmitPackageJobRequest): SubmitPackageJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitPackageJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitSmarttagJobRequest {
  content?: string(name='Content', description='The video description. The description can contain letters, digits, and hyphens (-) and cannot start with a special character. The description can be up to 1 KB in length.', example='example content ****', position='Query'),
  contentAddr?: string(name='ContentAddr', description='This parameter is discontinued.', example='http://123.com/testVideo.mp4', position='Query'),
  contentType?: string(name='ContentType', description='This parameter is discontinued.', example='application/zip', position='Query'),
  input?: {
    media?: string(name='Media', description='If Type is set to OSS, specify an OSS path. Example: OSS://test-bucket/video/202208/test.mp4.

If Type is set to Media, specify a media asset ID. Example: c5c62d8f0361337cab312dce8e77dc6d.

If Type is set to URL, specify an HTTP URL. Example: https://zc-test.oss-cn-shanghai.aliyuncs.com/test/unknowFace.mp4.', example='c5c62d8f0361337cab312dce8e77dc6d'),
    type?: string(name='Type', description='The media type. Valid values:

*   OSS
*   Media
*   URL', example='Media'),
  }(name='Input', description='The job input.', shrink='json', position='Query'),
  notifyUrl?: string(name='NotifyUrl', description='The URL for receiving callbacks. Set the value to an HTTP URL or an HTTPS URL.', example='https://example.com/endpoint/aliyun/ai?id=76401125000***', position='Query'),
  params?: string(name='Params', description='The additional request parameters. The value is a JSON string. Example: {"needAsrData":true, "needOcrData":false}. The following parameters are supported:

*   needAsrData: specifies whether to query the automatic speech recognition (ASR) data. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   needOcrData: specifies whether to query the optical character recognition (OCR) data. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   needMetaData: specifies whether to query the metadata. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   nlpParams: the input parameters of the natural language processing (NLP) operator. The value is a JSON object. This parameter is empty by default, which indicates that the NLP operator is not used. For more information, see the "nlpParams" section of this topic.', example='{"needAsrData":true, "needOcrData":false}', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which you want to submit the smart tagging job. The MPS queue is bound to an SMQ queue. This parameter specifies the default MPS queue. By default, an MPS queue can process a maximum of two concurrent smart tagging jobs. To increase the limit, submit a ticket.', example='acdbfe4323bcfdae'),
    priority?: string(name='Priority', description='The job priority. This parameter is not implemented. You can leave this parameter empty or enter a random value.', example='4'),
  }(name='ScheduleConfig', description='The scheduling configurations.', shrink='json', position='Query'),
  templateId?: string(name='TemplateId', description='The ID of the template that specifies the analysis algorithms. For more information about template operations, see [Configure templates](https://help.aliyun.com/document_detail/445702.html).', example='39f8e0bc005e4f309379701645f4', position='Query'),
  title?: string(name='Title', description='The video title. The title can contain letters, digits, and hyphens (-) and cannot start with a special character. The title can be up to 256 bytes in length.', example='example-title-****', position='Query'),
  userData?: string(name='UserData', description='The data to be passed through Simple Message Queue (SMQ, formerly MNS) during callbacks. The data can be up to 1 KB in length. For more information about how to specify an SMQ queue for receiving callbacks, see UpdatePipeline.', example='{“a”:"test"}', position='Query'),
}

model SubmitSmarttagJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the smart tagging job. We recommend that you save this ID for subsequent calls of other operations.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitSmarttagJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSmarttagJobResponseBody(name='body'),
}

/**
  * @description Before you call this operation to submit a smart tagging job, you must add a smart tagging template and specify the analysis types that you want to use in the template. For more information, see CreateCustomTemplate. You can use the smart tagging feature only in the China (Beijing), China (Shanghai), and China (Hangzhou) regions. By default, an ApsaraVideo Media Processing (MPS) queue can process a maximum of two concurrent smart tagging jobs. If you need to process more concurrent smart tagging jobs, submit a ticket to contact Alibaba Cloud Technical Support for evaluation and configuration.
  * @param request  the request parameters of SubmitSmarttagJob  SubmitSmarttagJobRequest
  * @return SubmitSmarttagJobResponse
 */
async function submitSmarttagJob(request: SubmitSmarttagJobRequest): SubmitSmarttagJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSmarttagJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitSnapshotJobRequest {
  input: {
    media: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/440592.html) page of the Intelligent Media Services (IMS) console.

This parameter is required.', example='oss://bucket/object.mp4'),
    type: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.

This parameter is required.', example='Media'),
  }(name='Input', description='The snapshot input.

This parameter is required.', shrink='json', position='Query'),
  name?: string(name='Name', description='The name of the job.', example='SampleJob', position='Query'),
  output: {
    media: string(name='Media', description='The output file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS. If multiple static snapshots were captured, the object must contain the "{Count}" placeholder. In the case of a sprite, the object must contain the "{TileCount}" placeholder. The suffix of the WebVTT snapshot objects must be ".vtt".

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/440592.html) page of the IMS console.

This parameter is required.', example='oss://test-bucket/output-{Count}.jpg'),
    type: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Output', description='The snapshot output.

This parameter is required.', shrink='json', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='****96e8864746a0b6f3****'),
  }(name='ScheduleConfig', description='The scheduling settings.', shrink='json', position='Query'),
  templateConfig: {
    overwriteParams?: {
      blackLevel?: int32(name='BlackLevel', description='The threshold that is used to filter out black frames for the first snapshot to be captured. This feature is available if you request the system to capture multiple snapshots.', example='30'),
      count?: long(name='Count', description='The number of snapshots.', example='5'),
      frameType?: string(name='FrameType', description='The type of the frame.', example='intra'),
      height?: int32(name='Height', description='The height of a captured snapshot.', example='480'),
      interval?: long(name='Interval', description='The interval at which snapshots are captured.', example='10'),
      isSptFrag?: boolean(name='IsSptFrag', description='The WebVTT snapshot configuration that specifies whether to merge the output snapshots.', example='true'),
      pixelBlackThreshold?: int32(name='PixelBlackThreshold', description='The color value threshold that determines whether a pixel is black.', example='70'),
      spriteSnapshotConfig?: {
        cellHeight?: int32(name='CellHeight', description='The height of a single snapshot before tiling. The default value is the height of the output snapshot.', example='480'),
        cellWidth?: int32(name='CellWidth', description='The width of a single snapshot before tiling. The default value is the width of the output snapshot.', example='720'),
        color?: string(name='Color', description='The background color.', example='#000000'),
        columns?: int32(name='Columns', description='The number of columns that the image sprite contains.', example='20'),
        lines?: int32(name='Lines', description='The number of rows that the image sprite contains.', example='20'),
        margin?: int32(name='Margin', description='The width of the frame. Default value: 0. Unit: pixels.', example='20'),
        padding?: int32(name='Padding', description='The spacing between two adjacent snapshots. Default value: 0. Unit: pixels.', example='20'),
      }(name='SpriteSnapshotConfig', description='The configuration of the sprite snapshot.'),
      time?: long(name='Time', description='The point in time at which the system starts to capture snapshots in the input video.', example='1000'),
      type?: string(name='Type', description='The snapshot type. Valid values:', example='Sprite'),
      width?: int32(name='Width', description='The width of a captured snapshot.', example='720'),
    }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters.'),
    templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
  }(name='TemplateConfig', description='The snapshot template configuration.

This parameter is required.', shrink='json', position='Query'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"test parameter": "test value"}', position='Query'),
}

model SubmitSnapshotJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSnapshotJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitSnapshotJob  SubmitSnapshotJobRequest
  * @return SubmitSnapshotJobResponse
 */
async function submitSnapshotJob(request: SubmitSnapshotJobRequest): SubmitSnapshotJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSnapshotJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitSportsHighlightsJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****', position='Query'),
  inputConfig?: string(name='InputConfig', description='The input configurations.', position='Body'),
  outputConfig?: string(name='OutputConfig', description='The output configurations.', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 1,
  "Width": 1080,
  "Height": 1920
}', position='Query'),
  userData?: string(name='UserData', description='The user-defined data.', position='Query'),
}

model SubmitSportsHighlightsJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the sports highlights job.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model SubmitSportsHighlightsJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSportsHighlightsJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitSportsHighlightsJob  SubmitSportsHighlightsJobRequest
  * @return SubmitSportsHighlightsJobResponse
 */
async function submitSportsHighlightsJob(request: SubmitSportsHighlightsJobRequest): SubmitSportsHighlightsJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSportsHighlightsJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitStandardCustomizedVoiceJobRequest {
  audios?: string(name='Audios', description='*   The material assets IDs of the materials for training.
*   Separate multiple media IDs with commas (,).

> : The total duration of all materials must be within 15 to 30 minutes. The duration of each material must be greater than 1 minute.', example='****571c704445f9a0ee011406c2****,****571c704445f9a0ee011406c2****,****571c704445f9a0ee011406c2****', position='Query'),
  authentication?: string(name='Authentication', description='*   The media asset ID of the authentication audio.

*   Upload an audio file for identity authentication. If the voiceprint extracted from the uploaded file differs from that of the training file, the job fails.

    **

    **Note**: Clearly read and record the following text: I confirm to customize human voice cloning and provide audio files that contain my voice for training. I promise that I am responsible for the customized content and that the content complies with laws and regulations.', example='****571c704445f9a0ee011406c2****', position='Query'),
  demoAudioMediaURL?: string(name='DemoAudioMediaURL', description='The URL of the sample audio file.

*   If this parameter is specified, a sample audio file is generated at the specified Object Storage Service (OSS) URL after the training is complete.

*   If this parameter is not specified, no sample audio file is generated.

    **

    **Note**: The URL must be a valid public OSS URL within your Alibaba Cloud account.', example='https://your-bucket.oss-cn-shanghai.aliyuncs.com/demo.mp3', position='Query'),
  gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female', position='Query'),
  voiceName?: string(name='VoiceName', description='The voice name.

*   The name can be up to 32 characters in length.', position='Query'),
}

model SubmitStandardCustomizedVoiceJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model SubmitStandardCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitStandardCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitStandardCustomizedVoiceJob  SubmitStandardCustomizedVoiceJobRequest
  * @return SubmitStandardCustomizedVoiceJobResponse
 */
async function submitStandardCustomizedVoiceJob(request: SubmitStandardCustomizedVoiceJobRequest): SubmitStandardCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitStandardCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitSyncMediaInfoJobRequest {
  input: {
    media: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/440592.html) page of the Intelligent Media Services (IMS) console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
    type: string(name='Type', description='The type of the media object.

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The input of the job.

This parameter is required.', shrink='json', position='Query'),
  name?: string(name='Name', description='The job name.', example='job-name', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling parameters. This parameter is optional.', shrink='json', position='Query'),
  userData?: string(name='UserData', description='The user data.', example='user-data', position='Query'),
}

model SubmitSyncMediaInfoJobResponseBody = {
  mediaInfoJob?: {
    async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    input?: {
      media?: string(name='Media', description='The media object. If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    mediaInfoProperty?: {
      audioStreamInfoList?: [ 
        {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
          channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
          codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
          codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
          codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
          codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          index?: string(name='Index', description='The sequence number of the stream.', example='1'),
          lang?: string(name='Lang', description='The language of the stream.', example='us'),
          sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
          sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
          startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
          timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
        }
      ](name='AudioStreamInfoList', description='The information about the audio stream.'),
      fileBasicInfo?: {
        bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
        duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
        fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
        fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
        fileStatus?: string(name='FileStatus', description='The state of the file. Valid values:

*   Normal', example='Normal'),
        fileType?: string(name='FileType', description='The file type.', example='source_file'),
        fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
        formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
        height?: string(name='Height', description='The height of the output video.', example='478'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='999e68259c924f52a6be603cbb3f91cc'),
        region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
        width?: string(name='Width', description='The width of the output video.', example='848'),
      }(name='FileBasicInfo', description='The basic file information.'),
      videoStreamInfoList?: [ 
        {
          avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
          bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
          codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
          codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
          codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
          codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
          codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
          dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          fps?: string(name='Fps', description='The frame rate.', example='25.0'),
          hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
          height?: string(name='Height', description='The height of the output video.', example='478'),
          index?: string(name='Index', description='The sequence number of the stream.', example='0'),
          lang?: string(name='Lang', description='The language of the stream.', example='zh'),
          level?: string(name='Level', description='The codec level.', example='31'),
          numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
          pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
          profile?: string(name='Profile', description='The encoder profile.', example='High'),
          rotate?: string(name='Rotate', description='The rotation angle of the video image.', example='0'),
          sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
          startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
          timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
          width?: string(name='Width', description='The width of the output video.', example='848'),
        }
      ](name='VideoStreamInfoList', description='The information about the video stream.'),
    }(name='MediaInfoProperty', description='The details of the media information.'),
    name?: string(name='Name', description='The job name.', example='job-name'),
    requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling information.'),
    status?: string(name='Status', description='The state of the job. Valid values: Init (the job is submitted), Success (the job is successful), and Fail (the job failed).', example='Init'),
    submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.', example='{}'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='MediaInfoJob', description='MediaInfoJobDTO'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model SubmitSyncMediaInfoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSyncMediaInfoJobResponseBody(name='body'),
}

/**
  * @description You can call this operation to analyze an input media file in synchronous mode. This operation is suitable for scenarios that require high real-time performance and low concurrency. If it takes an extended period of time to obtain the media information about the input media file, the request may time out or the obtained information may be inaccurate. We recommend that you call the [SubmitMediaInfoJob](https://help.aliyun.com/document_detail/441222.html) operation to obtain media information.
  * @param request  the request parameters of SubmitSyncMediaInfoJob  SubmitSyncMediaInfoJobRequest
  * @return SubmitSyncMediaInfoJobResponse
 */
async function submitSyncMediaInfoJob(request: SubmitSyncMediaInfoJobRequest): SubmitSyncMediaInfoJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSyncMediaInfoJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitTextGenerateJobRequest {
  description?: string(name='Description', description='The job description, which can be up to 1,024 bytes in length and must be encoded in UTF-8.', position='Query'),
  generateConfig?: string(name='GenerateConfig', description='The text generation configurations, including keywords and the requirements for the word count and number of output copies.', position='Query'),
  title?: string(name='Title', description='The job title.

The job title can be up to 128 bytes in length.

The value must be encoded in UTF-8.', position='Query'),
  type?: string(name='Type', description='The job type.

Valid values:

*   MarketingCopy: the marketing copy.
*   Title: the short video title.', example='MarketingCopy', position='Query'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).', position='Query'),
}

model SubmitTextGenerateJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitTextGenerateJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTextGenerateJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitTextGenerateJob  SubmitTextGenerateJobRequest
  * @return SubmitTextGenerateJobResponse
 */
async function submitTextGenerateJob(request: SubmitTextGenerateJobRequest): SubmitTextGenerateJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitTextGenerateJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitTranscodeJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****', position='Query'),
  inputGroup: [ 
    {
      inputUrl?: string(name='InputUrl', description='The URL of the input stream.

*   This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an input.
*   The system checks whether the input URL exists within the media asset.', example='oss://bucket/path/to/video.mp4'),
      media: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/440592.html) page of the Intelligent Media Services (IMS) console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
      type: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
    }
  ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.

This parameter is required.', example='job-name', shrink='json', position='Query'),
  name?: string(name='Name', description='The job name.', example='job-name', position='Query'),
  outputGroup: [ 
    {
      output: {
        media: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/440592.html) page of the IMS console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
        outputUrl?: string(name='OutputUrl', description='The URL of the output stream.\\
This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an output.\\
Supported placeholders:

*   {MediaId}: the ID of the media asset.
*   {JobId}: the ID of the transcoding subjob.
*   {MediaBucket}: the bucket to which the media asset belongs.
*   {ExtName}: the file suffix, which uses the output format of the transcoding template.
*   {DestMd5}: the MD5 value of the transcoded output file.\\
    Notes:

1.  This parameter must contain the {MediaId} and {JobId} placeholders.
2.  The output bucket is the same as the bucket to which the media asset belongs.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
        type: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
      }(name='Output', description='The output file configuration.

This parameter is required.'),
      processConfig: {
        combineConfigs?: [ 
          {
            audioIndex: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
            duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
            start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
            videoIndex: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
          }
        ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
        encryption?: {
          cipherText?: string(name='CipherText', description='The ciphertext of HTTP Live Streaming (HLS) encryption.', example='MTYi00NDU0LTg5O****'),
          decryptKeyUri?: string(name='DecryptKeyUri', description='The address of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
          encryptType?: string(name='EncryptType', description='Specifies the encryption type. Valid values:

*   PrivateEncryption: Alibaba Cloud proprietary cryptography
*   HLSEncryption: HTTP Live Streaming (HLS) encryption', example='PrivateEncryption'),
          keyServiceType?: string(name='KeyServiceType', description='The key service type for HLS encryption. Valid values:

*   KMS
*   Base64', example='KMS'),
        }(name='Encryption', description='The encryption settings.'),
        imageWatermarks?: [ 
          {
            overwriteParams?: {
              dx?: string(name='Dx', description='The horizontal offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the horizontal offset to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
              dy?: string(name='Dy', description='The vertical offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the vertical offset to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
              file?: {
                media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
              }(name='File', description='The watermark image file.'),
              height?: string(name='Height', description='The height of the watermark image in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark height.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark height to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
              referPos?: string(name='ReferPos', description='The position of the watermark.

*   Valid values: TopRight, TopLeft, BottomRight, and BottomLeft.
*   Default value: TopRight.', example='TopLeft'),
              timeline?: {
                duration?: string(name='Duration', description='The time range in which the watermark is displayed.

*   Valid values: integers and ToEND.
*   Default value: ToEND.', example='ToEND'),
                start?: string(name='Start', description='The beginning of the time range in which the watermark is displayed.

*   Unit: seconds.
*   Value values: integers.
*   Default value: 0.', example='00:00:05'),
              }(name='Timeline', description='The time settings of the dynamic watermark.'),
              width?: string(name='Width', description='The width of the watermark in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark width.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark width to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }
        ](name='ImageWatermarks', description='The watermark configuration of an image.'),
        subtitles?: [ 
          {
            overwriteParams?: {
              charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
              file?: {
                media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
              }(name='File', description='The subtitle file.'),
              format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }
        ](name='Subtitles', description='The subtitle configuration.'),
        textWatermarks?: [ 
          {
            overwriteParams?: {
              adaptive?: string(name='Adaptive', description='Specifies whether to the font size based on the output video dimensions. true / false, default: false', example='false'),
              borderColor?: string(name='BorderColor', description='The outline color of the text watermark. Default value: black. For more information, see BorderColor.', example='#006400'),
              borderWidth?: int32(name='BorderWidth', description='The outline width of the text watermark.

*   Default value: 0.
*   Valid values: (0,4096].', example='0'),
              content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
              fontAlpha?: string(name='FontAlpha', description='The transparency of the text.

*   Valid values: (0,1].
*   Default value: 1.', example='1.0'),
              fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
              fontName?: string(name='FontName', description='The font of the text. Default value: SimSun.', example='SimSun'),
              fontSize?: int32(name='FontSize', description='The size of the text.

*   Default value: 16.
*   Valid values: (4,120).', example='16'),
              left?: string(name='Left', description='The left margin of the text watermark.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
              top?: string(name='Top', description='The top margin of the text.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }
        ](name='TextWatermarks', description='The configurations of the text watermark.'),
        transcode: {
          overwriteParams?: {
            audio?: {
              bitrate?: string(name='Bitrate', description='The audio bitrate of the output file. Valid values: [8,1000]. Unit: Kbit/s. Default value: 128.', example='128'),
              channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
              codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
              profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
              remove?: string(name='Remove', description='Specifies whether to delete the audio stream.', example='false'),
              samplerate?: string(name='Samplerate', description='The sampling rate. Valid values: 22050, 32000, 44100, 48000, and 96000. Default value: 44100. Unit: Hz.', example='44100'),
              volume?: {
                integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
              }(name='Volume', description='The volume configurations.'),
            }(name='Audio', description='The audio settings.'),
            container?: {
              format?: string(name='Format', description='The container format.', example='mp4'),
            }(name='Container', description='The encapsulation format settings.'),
            muxConfig?: {
              segment?: {
                duration?: string(name='Duration', description='The segment length.', example='10'),
                forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
              }(name='Segment', description='The segment settings.'),
            }(name='MuxConfig', description='The encapsulation settings.'),
            transConfig?: {
              adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
              isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false: does not check the video resolution.

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
              isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckReso?: string(name='IsCheckReso', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckResoFail?: string(name='IsCheckResoFail', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
            }(name='TransConfig', description='The conditional transcoding configurations.'),
            video?: {
              abrMax?: string(name='AbrMax', description='The maximum adaptive bitrate (ABR). This parameter takes effect only for Narrowband HD 1.0. Valid values: [10,50000]. Unit: Kbit/s.', example='6000'),
              bitrate?: string(name='Bitrate', description='The average video bitrate. Valid values: [10,50000]. Unit: Kbit/s.', example='3000'),
              bufsize?: string(name='Bufsize', description='The buffer size. Valid values: [1000,128000]. Default value: 6000. Unit: KB.', example='6000'),
              codec?: string(name='Codec', description='The encoding format.', example='H.264'),
              crf?: string(name='Crf', description='The constant rate factor (CRF). Valid values: [0,51]. Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.

>  If this parameter is specified, the setting of the bitrate becomes invalid.', example='23'),
              crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
              fps?: string(name='Fps', description='The frame rate. Valid values:(0,60]. Default value: the frame rate of the input file.

>  The value is 60 if the frame rate of the input file exceeds 60.', example='25'),
              gop?: string(name='Gop', description='The maximum number of frames between keyframes. Valid values: [1,1080000]. Default value: 250.', example='250'),
              height?: string(name='Height', description='The height of the video. Valid values: [128,4096]. Unit: pixels. Default value: the original height of the video.', example='1080'),
              longShortMode?: string(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature.', example='false'),
              maxrate?: string(name='Maxrate', description='The maximum bitrate of the video. Valid values: [10,50000]. Unit: Kbit/s.', example='9000'),
              pad?: string(name='Pad', description='The black bars added to the video. Format: width:height:left:top. Example: 1280:800:0:140.', example='1280:800:0:140'),
              pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
              preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
              profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
              remove?: string(name='Remove', description='Specifies whether to remove the video.', example='false'),
              scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
              width?: string(name='Width', description='The width of the video. Valid values: [128,4096]. Unit: pixels. Default value: the original width of the video.', example='1920'),
            }(name='Video', description='The video settings.'),
          }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
          templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
        }(name='Transcode', description='The transcoding configuration.

This parameter is required.'),
      }(name='ProcessConfig', description='The job processing configuration.

This parameter is required.'),
    }
  ](name='OutputGroup', description='The output group of the job.

This parameter is required.', example='user-data', shrink='json', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling information about the job.', example='job-name', shrink='json', position='Query'),
  userData?: string(name='UserData', description='The custom settings. The value must be in the JSON format and can be up to 512 bytes in length. You can specify a [custom callback URL](https://help.aliyun.com/document_detail/451631.html).', example='user-data', position='Query'),
}

model SubmitTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
  transcodeParentJob?: {
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    inputGroup?: [ 
      {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
      }
    ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
    jobCount?: int32(name='JobCount', description='The number of subjobs.', example='1'),
    name?: string(name='Name', description='The job name.', example='transcode-job'),
    outputGroup?: [ 
      {
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HLS encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The address of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='Specifies the encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The horizontal offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the horizontal offset to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                dy?: string(name='Dy', description='The vertical offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the vertical offset to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the watermark image in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark height.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark height to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
                referPos?: string(name='ReferPos', description='The position of the watermark.

*   Valid values: TopRight, TopLeft, BottomRight, and BottomLeft.
*   Default value: TopRight.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The time range in which the watermark is displayed.

*   Valid values: integers and ToEND.
*   Default value: ToEND.', example='ToEND'),
                  start?: string(name='Start', description='The beginning of the time range in which the watermark is displayed.

*   Unit: seconds.
*   Value values: integers.
*   Default value: 0.', example='00:00:05'),
                }(name='Timeline', description='The time settings of the dynamic watermark.'),
                width?: string(name='Width', description='The width of the watermark in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark width.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark width to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object. If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Specifies whether to the font size based on the output video dimensions.

*   true: false
*   default: false', example='false'),
                borderColor?: string(name='BorderColor', description='The outline color of the text watermark. Default value: black. For more information, see BorderColor.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The outline width of the text watermark.

*   Default value: 0.
*   Valid values: (0,4096].', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the text.

*   Valid values: (0,1].
*   Default value: 1.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text. Default value: SimSun.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.

*   Default value: 16.
*   Valid values: (4,120).', example='16'),
                left?: string(name='Left', description='The left margin of the text watermark.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
                top?: string(name='Top', description='The top margin of the text.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Specifies whether to delete the audio stream.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Valid values: 22050, 32000, 44100, 48000, and 96000. Default value: 44100.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false: does not check the video resolution.

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum ABR. This parameter takes effect only for Narrowband HD 1.0.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or Default value when the Codec parameter is set to H.265: 26.

If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Specifies whether to remove the video.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The job processing configuration.'),
      }
    ](name='OutputGroup', description='The output group of the job.'),
    parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
    percent?: int32(name='Percent', description='The completion percentage of the job.', example='0'),
    requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling configuration of the job.'),
    status?: string(name='Status', description='The state of the job. Success: At least one of the subjobs is successful. Fail: All subjobs failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    transcodeJobList?: [ 
      {
        createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-01-12T08:49:41Z'),
        finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
        inputGroup?: [ 
          {
            inputUrl?: string(name='InputUrl', description='The URL of the input stream:

*   This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an input.
*   The system checks whether the input URL exists within the media asset.', example='oss://bucket/path/to/video.mp4'),
            media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
            type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
          }
        ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
        jobId?: string(name='JobId', description='The subjob ID.', example='7d6a7e0d4db2457a8d45ff5d43e1bf0a'),
        jobIndex?: int32(name='JobIndex', description='The index number of the subjob in the entire job.', example='0'),
        name?: string(name='Name', description='The job name.', example='transcode-job'),
        outFileMeta?: {
          audioStreamInfoList?: [ 
            {
              bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
              channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
              channels?: string(name='Channels', description='The number of sound channels.', example='2'),
              codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
              codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
              codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
              codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
              codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              index?: string(name='Index', description='The sequence number of the stream.', example='1'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
              sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
              startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
              timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
            }
          ](name='AudioStreamInfoList', description='The information about the audio stream.'),
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
            duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
            fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
            fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
            fileType?: string(name='FileType', description='The file type. Valid values: source_file and transcode_file.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
            formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
            height?: string(name='Height', description='The height of the output video.', example='478'),
            mediaId?: string(name='MediaId', description='The ID of the media asset.', example='73e07de0f77171eca3fc7035d0b26402'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width of the output video.', example='848'),
          }(name='FileBasicInfo', description='The basic file information.'),
          videoStreamInfoList?: [ 
            {
              avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
              bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
              codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
              codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
              codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
              codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
              codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
              dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              fps?: string(name='Fps', description='The frame rate.', example='25.0'),
              hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
              height?: string(name='Height', description='The height of the output video.', example='478'),
              index?: string(name='Index', description='The sequence number of the stream.', example='0'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              level?: string(name='Level', description='The codec level.', example='31'),
              numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
              pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
              profile?: string(name='Profile', description='The encoder profile.', example='High'),
              rotate?: string(name='Rotate', description='The rotation angle of the video image. Valid values: 0, 90, 180, and 270. Default value: 0.', example='0'),
              sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
              startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
              timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
              width?: string(name='Width', description='The width of the output video.', example='848'),
            }
          ](name='VideoStreamInfoList', description='The information about the video stream.'),
        }(name='OutFileMeta', description='The media information about the video generated by the job.'),
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
          outputUrl?: string(name='OutputUrl', description='The URL of the output stream.\\
This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an output.\\
Supported placeholders:

*   {MediaId}: the ID of the media asset.
*   {JobId}: the ID of the transcoding subjob.
*   {MediaBucket}: the bucket to which the media asset belongs.
*   {ExtName}: the file suffix, which uses the output format of the transcoding template.
*   {DestMd5}: the MD5 value of the transcoded output file.\\
    Notes:

1.  This parameter must contain the {MediaId} and {JobId} placeholders.
2.  The output bucket is the same as the bucket to which the media asset belongs.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HLS encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The address of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='Specifies the encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The horizontal offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the horizontal offset to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                dy?: string(name='Dy', description='The vertical offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the vertical offset to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the watermark image in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark height.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark height to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
                referPos?: string(name='ReferPos', description='The position of the watermark.

*   Valid values: TopRight, TopLeft, BottomRight, and BottomLeft.
*   Default value: TopRight.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The time range in which the watermark is displayed.

*   Valid values: integers and ToEND.
*   Default value: ToEND.', example='ToEND'),
                  start?: string(name='Start', description='The beginning of the time range in which the watermark is displayed.

*   Unit: seconds.
*   Value values: integers.
*   Default value: 0.', example='00:00:05'),
                }(name='Timeline', description='The time settings of the dynamic watermark.'),
                width?: string(name='Width', description='The width of the watermark in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark width.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark width to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Specifies whether to the font size based on the output video dimensions. true / false, default: false', example='false'),
                borderColor?: string(name='BorderColor', description='The outline color of the text watermark. Default value: black. For more information, see BorderColor.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The outline width of the text watermark.

*   Default value: 0.
*   Valid values: (0,4096].', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the text.

*   Valid values: (0,1].
*   Default value: 1.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text. Default value: SimSun.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.

*   Default value: 16.
*   Valid values: (4,120).', example='16'),
                left?: string(name='Left', description='The left margin of the text watermark.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
                top?: string(name='Top', description='The top margin of the text.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Specifies whether to delete the audio stream.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100.
*   Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false: does not check the video resolution.

Default values:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution. This is the default value.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. This is the default value. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum ABR. This parameter takes effect only for Narrowband HD 1.0. Valid values: [10,50000]. Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or Default value when the Codec parameter is set to H.265: 26.

If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video. Valid values: [10,50000]. Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Specifies whether to remove the video.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The transcoding configuration.'),
        requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
        scheduleConfig?: {
          pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
          priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
        }(name='ScheduleConfig', description='The scheduling information about the job.'),
        status?: string(name='Status', description='The state of the transcoding job. Valid values:

*   Init: The job is submitted.
*   Processing: The job is in progress.
*   Success: The job is successful.
*   Fail: The job failed.
*   Deleted: The job is deleted.', example='Init'),
        submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission result.', example='{}'),
        submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
        userData?: string(name='UserData', description='The user data.', example='user-data'),
      }
    ](name='TranscodeJobList', description='The list of subjobs.'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='TranscodeParentJob', description='TranscodeParentJobWithSubJobDTO'),
}

model SubmitTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTranscodeJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitTranscodeJob  SubmitTranscodeJobRequest
  * @return SubmitTranscodeJobResponse
 */
async function submitTranscodeJob(request: SubmitTranscodeJobRequest): SubmitTranscodeJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitTranscodeJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitVideoTranslationJobRequest {
  clientToken?: string(name='ClientToken', description='*   The client token.', position='Query'),
  description?: string(name='Description', description='*   The job description.', position='Query'),
  editingConfig?: string(name='EditingConfig', description='*   The configuration parameters of the video translation job.
*   The value must be in the JSON format.', example='{"SourceLanguage":"zh","TargetLanguage":"en","DetextArea":"Auto"}', position='Query'),
  inputConfig?: string(name='InputConfig', description='*   The input parameters of the video translation job.
*   A video translation job takes a video or subtitle file as the input.
*   The value must be in the JSON format.', example='{"Type":"Video","Media":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/xxx.mp4"}', position='Query'),
  outputConfig?: string(name='OutputConfig', description='*   The output parameters of the video translation job.
*   A video translation job can generate a video or subtitle file as the output.', example='{"MediaURL": "https://your-bucket.oss-cn-shanghai.aliyuncs.com/your-object.mp4"}', position='Query'),
  title?: string(name='Title', description='*   The job title.', position='Query'),
  userData?: string(name='UserData', description='*   The user-defined data.
*   The data must be in the JSON format, and can be up to 512 characters in length.', example='{"NotifyAddress":"http://xx.xx.xxx"}', position='Query'),
}

model SubmitVideoTranslationJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the video translation job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.

Valid values:

*   true
*   false', example='true'),
}

model SubmitVideoTranslationJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitVideoTranslationJobResponseBody(name='body'),
}

/**
  * @description After you call this operation to submit a video translation job, the system returns a job ID. You can call the GetSmartHandleJob operation based on the job ID to obtain the status and result information of the job.
  * @param request  the request parameters of SubmitVideoTranslationJob  SubmitVideoTranslationJobRequest
  * @return SubmitVideoTranslationJobResponse
 */
async function submitVideoTranslationJob(request: SubmitVideoTranslationJobRequest): SubmitVideoTranslationJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitVideoTranslationJob', 'POST', '/', 'json', false, 'json', request);
}

model UpdateAIAgentInstanceRequest {
  instanceId: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
  templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', shrink='json', position='Query'),
  userData?: string(name='UserData', position='Query'),
}

model UpdateAIAgentInstanceResponseBody = {
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model UpdateAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAIAgentInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateAIAgentInstance  UpdateAIAgentInstanceRequest
  * @return UpdateAIAgentInstanceResponse
 */
async function updateAIAgentInstance(request: UpdateAIAgentInstanceRequest): UpdateAIAgentInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateAIAgentInstance', 'POST', '/', 'json', false, 'json', request);
}

model UpdateAvatarTrainingJobRequest {
  avatarDescription?: string(name='AvatarDescription', description='*   The description of the digital human.
*   The description can be up to 1,000 characters in length.', maxLength=1024, position='Query'),
  avatarName?: string(name='AvatarName', description='*   The name of the digital human.
*   The name can be up to seven characters in length.', maxLength=7, position='Query'),
  jobId: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****cdb3e74639973036bc84****', position='Query'),
  portrait?: string(name='Portrait', description='*   The media asset ID of the portrait image.
*   The value must be 32 characters in length.', example='****571c704445f9a0ee011406c2****', minLength=32, maxLength=32, position='Query'),
  thumbnail?: string(name='Thumbnail', description='*   The thumbnail URL.
*   After the digital human is trained, the thumbnail is uploaded to this URL.
*   The URL must be a valid public Object Storage Service (OSS) URL.
*   The URL can be up to 512 characters in length.
*   The URL cannot be updated after the digital human is trained.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png', maxLength=512, position='Query'),
  transparent?: boolean(name='Transparent', description='*   Indicates whether the input video supports alpha channels.

*   You can modify this parameter only if the job is in the Init or Fail state.

    **

    **Note**: Make sure that the current settings are consistent with those of the submitted training video. Otherwise, the digital human may malfunction.', example='True', position='Query'),
  video?: string(name='Video', description='*   The ID of the video used for training.
*   The value must be 32 characters in length.
*   Supported formats: MP4, MOV, and WebM.
*   The duration of the video must be 5 to 15 minutes.
*   The resolution of the video must be 1920×1080 or 1080×1920.', example='****571c704445f9a0ee011406c2****', minLength=32, maxLength=32, position='Query'),
}

model UpdateAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAvatarTrainingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateAvatarTrainingJob  UpdateAvatarTrainingJobRequest
  * @return UpdateAvatarTrainingJobResponse
 */
async function updateAvatarTrainingJob(request: UpdateAvatarTrainingJobRequest): UpdateAvatarTrainingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateAvatarTrainingJob', 'POST', '/', 'json', false, 'json', request);
}

model UpdateCategoryRequest {
  regionId?: string(name='RegionId', position='Host'),
  cateId: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of CateId returned by the AddCategory operation that you called to create a category.
*   View the value of CateId returned by the GetCategories operation that you called to query a category.

This parameter is required.', example='43', position='Query'),
  cateName: string(name='CateName', description='The category name.

This parameter is required.', position='Query'),
}

model UpdateCategoryResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
}

model UpdateCategoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateCategoryResponseBody(name='body'),
}

/**
  * @description After you create a media asset category, you can call this operation to find the category based on the category ID and change the name of the category.
  * @param request  the request parameters of UpdateCategory  UpdateCategoryRequest
  * @return UpdateCategoryResponse
 */
async function updateCategory(request: UpdateCategoryRequest): UpdateCategoryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateCategory', 'POST', '/', 'json', false, 'json', request);
}

model UpdateCustomTemplateRequest {
  name?: string(name='Name', description='The template name.', example='test-template', position='Query'),
  templateConfig?: string(name='TemplateConfig', description='The [template parameters](https://help.aliyun.com/document_detail/448291.html).', example='{"param": "sample"}', position='Query'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****', position='Query'),
}

model UpdateCustomTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateCustomTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateCustomTemplate  UpdateCustomTemplateRequest
  * @return UpdateCustomTemplateResponse
 */
async function updateCustomTemplate(request: UpdateCustomTemplateRequest): UpdateCustomTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateCustomTemplate', 'POST', '/', 'json', false, 'json', request);
}

model UpdateCustomizedVoiceRequest {
  demoAudioMediaId?: string(name='DemoAudioMediaId', description='The media asset ID of the sample audio file.', example='****4d5e829d498aaf966b119348****', position='Query'),
  voiceId: string(name='VoiceId', description='The voice ID.

This parameter is required.', example='xiaozhuan', position='Query'),
}

model UpdateCustomizedVoiceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateCustomizedVoiceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateCustomizedVoiceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateCustomizedVoice  UpdateCustomizedVoiceRequest
  * @return UpdateCustomizedVoiceResponse
 */
async function updateCustomizedVoice(request: UpdateCustomizedVoiceRequest): UpdateCustomizedVoiceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateCustomizedVoice', 'POST', '/', 'json', false, 'json', request);
}

model UpdateEditingProjectRequest {
  businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

*   Reserving
*   ReservationCanceled', example='Reserving', position='Query'),
  clipsParam?: string(name='ClipsParam', description='The material parameter corresponding to the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified.', position='Query'),
  coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='https://****.com/6AB4D0E1E1C7446888****.png', position='Query'),
  description?: string(name='Description', description='The description of the online editing project.', example='testtimeline001desciption', position='Query'),
  projectId: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='****4ee4b97e27b525142a6b2****', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID. This parameter is used to quickly build a timeline with ease. Note: Only one of ProjectId, Timeline, and TemplateId can be specified. If TemplateId is specified, ClipsParam must also be specified.', example='****96e8864746a0b6f3****', position='Query'),
  timeline?: string(name='Timeline', position='Body'),
  title?: string(name='Title', description='The title of the online editing project.', example='testtimeline', position='Query'),
}

model UpdateEditingProjectResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****25818875-5F78-4AF6-D7393642CA58****'),
}

model UpdateEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateEditingProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateEditingProject  UpdateEditingProjectRequest
  * @return UpdateEditingProjectResponse
 */
async function updateEditingProject(request: UpdateEditingProjectRequest): UpdateEditingProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateEditingProject', 'POST', '/', 'json', true, 'form', request);
}

model UpdateLiveRecordTemplateRequest {
  name: string(name='Name', description='The template name.

This parameter is required.', example='test template', position='Body'),
  recordFormat: [ 
    {
      cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds If you do not specify this parameter, the default value 6 hours is used.

> 

*   If a live stream is interrupted during a recording cycle but is resumed within 3 minutes, the stream is recorded in the same recording before and after the interruption.

*   If a live stream is interrupted for more than 3 minutes, a new recording is generated. To change the default stream interruption time, submit a ticket.', example='3600'),
      format: string(name='Format', description='The format of recording files.

>  If you set this parameter to m3u8, you must also specify the SliceOssObjectPrefix and SliceDuration parameters.

This parameter is required.', example='m3u8'),
      ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording that is stored in Object Storage Service (OSS).

*   The name must be less than 256 bytes in length and can contain the {JobId}, {Sequence}, {StartTime}, {EndTime}, {EscapedStartTime}, and {EscapedEndTime} variables.
*   The name must contain the {StartTime} and {EndTime} variables or the {EscapedStartTime} and {EscapedEndTime} variables.', example='record/{JobId}/{Sequence}_{EscapedStartTime}_{EscapedEndTime}'),
      sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds

>  This parameter takes effect only if you set Format to m3u8.

If you do not specify this parameter, the default value 30 seconds is used. Valid values: 5 to 30.', example='30'),
      sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.

>  This parameter is required only if you set Format to m3u8. By default, the duration of a segment is 30 seconds. The segment name must be less than 256 bytes in length and can contain the {JobId}, {UnixTimestamp}, and {Sequence} variables.

The segment name must contain the {UnixTimestamp} and {Sequence} variables.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
    }
  ](name='RecordFormat', description='The list of recording formats.

This parameter is required.', shrink='json', position='Body'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66', position='Body'),
}

model UpdateLiveRecordTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0F3D5C03-4B6E-5F40-B7F6-B1956776E7D3'),
}

model UpdateLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveRecordTemplateResponseBody(name='body'),
}

/**
  * @description Only user-created templates can be updated. The preset template cannot be updated.
  * @param request  the request parameters of UpdateLiveRecordTemplate  UpdateLiveRecordTemplateRequest
  * @return UpdateLiveRecordTemplateResponse
 */
async function updateLiveRecordTemplate(request: UpdateLiveRecordTemplateRequest): UpdateLiveRecordTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateLiveRecordTemplate', 'POST', '/', 'json', true, 'form', request);
}

model UpdateLiveSnapshotTemplateRequest {
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   The value cannot exceed 255 characters in length.
*   The {JobId} placeholder is supported. It specifies the ID of the snapshot job.
*   Placeholders such as {UnixTimestamp}, {Sequence}, and {Date} are not allowed.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}.jpg', position='Body'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   The value cannot exceed 255 characters in length.
*   The {JobId}, {Date}, {UnixTimestamp}, and {Sequence} placeholders are supported. {JobId} specifies the ID of the snapshot job. {Date} specifies the date on which the snapshot is captured. {UnixTimestamp} specifies the timestamp of the snapshot. {Sequence} specifies the sequence number of the snapshot. You must specify at least one of the {UnixTimestamp} and {Sequence} placeholders.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}/{UnixTimestamp}.jpg', position='Body'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Body'),
  templateName: string(name='TemplateName', description='The name of the template.

*   It cannot exceed 128 characters in length.

This parameter is required.', position='Body'),
  timeInterval: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.

*   Valid values: [5,3600].

This parameter is required.', example='5', position='Body'),
}

model UpdateLiveSnapshotTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveSnapshotTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateLiveSnapshotTemplate  UpdateLiveSnapshotTemplateRequest
  * @return UpdateLiveSnapshotTemplateResponse
 */
async function updateLiveSnapshotTemplate(request: UpdateLiveSnapshotTemplateRequest): UpdateLiveSnapshotTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateLiveSnapshotTemplate', 'POST', '/', 'json', true, 'form', request);
}

model UpdateLiveTranscodeJobRequest {
  jobId: string(name='JobId', description='The job ID.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  name?: string(name='Name', description='The name of the job.', example='mytest3', minLength=1, maxLength=128, position='Query'),
  streamInput?: {
    inputUrl: string(name='InputUrl', description='The URL of the input stream.

This parameter is required.', example='rtmp://mydomain/app/stream1'),
    type: string(name='Type', description='The type of the input stream. The value can only be rtmp.

This parameter is required.', example='rtmp'),
  }(name='StreamInput', description='The information about the input stream.', shrink='json', position='Query'),
  timedConfig?: {
    endTime?: string(name='EndTime', description='The stop time of the transcoding job. Note: The time span between the stop time and the current time cannot exceed seven days.', example='2022-08-05T06:08:31Z'),
    startTime?: string(name='StartTime', description='The start time of the transcoding job. Note: The time span between the start time and the current time cannot exceed seven days.', example='2022-06-19T02:16:41Z'),
  }(name='TimedConfig', description='The configuration of a timed transcoding job.', shrink='json', position='Query'),
  transcodeOutput?: {
    domainName: string(name='DomainName', description='The streaming domain name of ApsaraVideo Live.

This parameter is required.', example='mydomain'),
    type: string(name='Type', description='The type of the output stream. A value of LiveCenter indicates that the URL of the output stream is generated based on the domain name of ApsaraVideo Live. The value can only be LiveCenter.

This parameter is required.', example='LiveCenter'),
  }(name='TranscodeOutput', description='The information about the transcoding output.', shrink='json', position='Query'),
}

model UpdateLiveTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model UpdateLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveTranscodeJobResponseBody(name='body'),
}

/**
  * @description *   For a non-timed transcoding job, you can modify the Name parameter of the job, regardless of the job state.
  * *   For a timed job, you can modify the Name, StreamInput, TranscodeOutput, and TimedConfig parameters. However, the StreamInput, TranscodeOutput, and TimedConfig parameters can be modified only when the job is not started.
  * @param request  the request parameters of UpdateLiveTranscodeJob  UpdateLiveTranscodeJobRequest
  * @return UpdateLiveTranscodeJobResponse
 */
async function updateLiveTranscodeJob(request: UpdateLiveTranscodeJobRequest): UpdateLiveTranscodeJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateLiveTranscodeJob', 'POST', '/', 'json', false, 'json', request);
}

model UpdateLiveTranscodeTemplateRequest {
  name?: string(name='Name', description='The template name.', position='Query'),
  templateConfig?: {
    audioParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output audio. Unit: Kbit/s. Valid values: 1 to 1000.', example='100'),
      channels?: string(name='Channels', description='The number of sound channels. Valid values: 1: mono 2: binaural', example='2'),
      codec?: string(name='Codec', description='The audio codec. Valid values: AAC MP3', example='AAC'),
      profile?: string(name='Profile', description='The audio codec profile. Valid values when the Codec parameter is set to AAC:

*   aac_low
*   aac_he
*   aac_he_v2
*   aac_ld', example='aac_low'),
      samplerate?: string(name='Samplerate', description='The audio sampling rate. Valid values: 22050 to 96000.

Note If you set AudioProfile to aac_ld, the audio sampling rate cannot exceed 44100.', example='44100'),
    }(name='AudioParams', description='The audio parameters.'),
    videoParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output video. Unit: Kbit/s. Valid values: 1 to 6000.', example='2500'),
      codec?: string(name='Codec', description='The encoding type. Valid values:

*   H.264
*   H.265', example='H.264'),
      fps?: string(name='Fps', description='The frame rate of the output video. Unit: frames per second (FPS). Valid values: 1 to 60.', example='30'),
      gop?: string(name='Gop', description='The group of pictures (GOP) of the output video. Unit: frame. Valid values: 1 to 3000.', example='1000'),
      height?: string(name='Height', description='The height of the output video. Valid values:

*   Height ≥ 128
*   max (Height,Width) ≤ 2560
*   min（Height,Width）≤ 1440

>  The resolution of a video transcoded by using the H.265 Narrowband HD template cannot exceed 1,280 × 720 pixels.', example='720'),
      profile?: string(name='Profile', description='The video encoding profile. The profile determines how a video is encoded. In most cases, a greater value indicates better image quality and higher resource consumption. Valid values:

*   1: baseline. This value is suitable for mobile devices.
*   2: main. This value is suitable for standard-definition devices.
*   3: high. This value is suitable for high-definition devices.', example='2'),
      width?: string(name='Width', description='The width of the output video. Valid values:

*   Width ≥ 128
*   max (Height,Width) ≤ 2560
*   min（Height,Width）≤ 1440

>  The resolution of a video transcoded by using the H.265 Narrowband HD template cannot exceed 1,280 × 720 pixels.', example='1280'),
    }(name='VideoParams', description='The video parameters.'),
  }(name='TemplateConfig', description='The configuration of the template.', shrink='json', position='Query'),
  templateId: string(name='TemplateId', description='The template ID. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com/summary), choose Real-time Media Processing > Template Management, and then click the Transcoding tab. Alternatively, find the ID from the response parameters of the [CreateLiveTranscodeTemplate](https://help.aliyun.com/document_detail/449217.html) operation.

This parameter is required.', example='****96e8864746a0b6f3****', position='Query'),
}

model UpdateLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model UpdateLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveTranscodeTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateLiveTranscodeTemplate  UpdateLiveTranscodeTemplateRequest
  * @return UpdateLiveTranscodeTemplateResponse
 */
async function updateLiveTranscodeTemplate(request: UpdateLiveTranscodeTemplateRequest): UpdateLiveTranscodeTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateLiveTranscodeTemplate', 'POST', '/', 'json', false, 'json', request);
}

model UpdateMediaInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  appendTags?: boolean(name='AppendTags', description='Specifies whether to append tags. Default value: false. Valid values:

*   true: updates the MediaTags parameter by appending new tags.
*   false: updates the MediaTags parameter by overwriting existing tags with new tags.', example='true', position='Query'),
  businessType?: string(name='BusinessType', description='The business type. Valid values:

*   subtitles
*   watermark
*   opening
*   ending
*   general', example='video', position='Query'),
  cateId?: long(name='CateId', description='The category ID.', example='3048', position='Query'),
  category?: string(name='Category', description='The category.

*   The value can be up to 64 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultCategory', position='Query'),
  coverURL?: string(name='CoverURL', description='The URL of the thumbnail.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png', position='Query'),
  description?: string(name='Description', description='The content description.

*   The value can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultDescription', position='Query'),
  inputURL?: string(name='InputURL', description='The input URL of the media asset in another service. The URL must be bound to the ID of the media asset in IMS. The URL cannot be modified once registered.

For a media asset from Object Storage Service (OSS), the URL may have one of the following formats:

1\\. http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4

2\\. oss://example-bucket/example.mp4. This format indicates that the region in which the OSS bucket of the media asset resides is the same as the region in which OSS is activated.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. If this parameter is left empty, you must specify the input URL of the media asset, which has been registered in the IMS content library.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  mediaTags?: string(name='MediaTags', description='The tags.

*   Up to 16 tags are supported.
*   Separate multiple tags with commas (,).
*   Each tag can be up to 32 bytes in length.
*   The value must be encoded in UTF-8.', example='updateTags1,updateTags2', position='Query'),
  referenceId?: string(name='ReferenceId', description='The custom ID. The ID can be 6 to 64 characters in length and can contain only letters, digits, hyphens (-), and underscores (_). Make sure that the ID is unique among users.', example='123-123', position='Query'),
  title?: string(name='Title', description='The title.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultTitle', position='Query'),
  userData?: string(name='UserData', description='The user data. It can be up to 1,024 bytes in size.', example='userData', position='Query'),
}

model UpdateMediaInfoResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset in IMS.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaInfoResponseBody(name='body'),
}

/**
  * @description If the MediaId parameter is specified, the MediaId parameter is preferentially used for the query. If the MediaId parameter is left empty, the InputURL parameter must be specified. The request ID and media asset ID are returned. You cannot modify the input URL of a media asset by specifying the ID of the media asset.
  * @param request  the request parameters of UpdateMediaInfo  UpdateMediaInfoRequest
  * @return UpdateMediaInfoResponse
 */
async function updateMediaInfo(request: UpdateMediaInfoRequest): UpdateMediaInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMediaInfo', 'POST', '/', 'json', false, 'json', request);
}

model UpdateMediaMarksRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='53afdf003a******6a16b5feac6402', position='Query'),
  mediaMarks: string(name='MediaMarks', description='The marks of the media asset.

This parameter is required.', position='Query'),
}

model UpdateMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='53afdf003a******6a16b5feac6402'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The IDs of the successfully modified marks.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaMarksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateMediaMarks  UpdateMediaMarksRequest
  * @return UpdateMediaMarksResponse
 */
async function updateMediaMarks(request: UpdateMediaMarksRequest): UpdateMediaMarksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMediaMarks', 'POST', '/', 'json', false, 'json', request);
}

model UpdateMediaToSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='****019b82e24b37a1c2958dec38****', position='Query'),
  msgBody: string(name='MsgBody', description='The message body.

This parameter is required.', example='{}', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1', position='Query'),
}

model UpdateMediaToSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateMediaToSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaToSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateMediaToSearchLib  UpdateMediaToSearchLibRequest
  * @return UpdateMediaToSearchLibResponse
 */
async function updateMediaToSearchLib(request: UpdateMediaToSearchLibRequest): UpdateMediaToSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMediaToSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model UpdatePipelineRequest {
  name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline', position='Query'),
  pipelineId: string(name='PipelineId', description='The ID of the MPS queue.

This parameter is required.', example='****d80e4e4044975745c14b****', position='Query'),
  priority?: int32(name='Priority', description='The priority of the MPS queue. Valid values: 1 to 10.', example='6', position='Query'),
  status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Paused', position='Query'),
}

model UpdatePipelineResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdatePipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdatePipelineResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdatePipeline  UpdatePipelineRequest
  * @return UpdatePipelineResponse
 */
async function updatePipeline(request: UpdatePipelineRequest): UpdatePipelineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdatePipeline', 'POST', '/', 'json', false, 'json', request);
}

model UpdateRtcRobotInstanceRequest {
  config?: {
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt', example='false'),
    greeting?: string(name='Greeting'),
    voiceId?: string(name='VoiceId', example='zhixiaoxia'),
  }(name='Config', shrink='json', position='Query'),
  instanceId: string(name='InstanceId', description='This parameter is required.', example='727dc0e296014bb58670940a3da95592', position='Query'),
}

model UpdateRtcRobotInstanceResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='7707F0A2-C6FD-5959-87EB-7C4D02384FD4'),
}

model UpdateRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateRtcRobotInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateRtcRobotInstance  UpdateRtcRobotInstanceRequest
  * @return UpdateRtcRobotInstanceResponse
 */
async function updateRtcRobotInstance(request: UpdateRtcRobotInstanceRequest): UpdateRtcRobotInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateRtcRobotInstance', 'POST', '/', 'json', false, 'json', request);
}

model UpdateTemplateRequest {
  config?: string(name='Config', example='参见模板Config文档', position='Body'),
  coverUrl?: string(name='CoverUrl', description='The URL of the template thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg', position='Query'),
  name?: string(name='Name', description='The name of the online editing template.', example='视频添加水印模板', position='Query'),
  previewMedia?: string(name='PreviewMedia', description='The ID of the preview video.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  relatedMediaids?: string(name='RelatedMediaids', description='The IDs of the materials associated with the template for use by the regular template editor.', example='{"video":["******c04f1d4a06996144cc1a******","******cb7db64841b159b4f2ea******"],"audio":["******c04f1d4a06996144cc1a******"],"image":["******c04f1d4a06996144cc1a******"]}', position='Query'),
  source?: string(name='Source', description='The source from which the template is modified. Default value: OpenAPI. Valid values:

*   AliyunConsole
*   OpenAPI
*   WebSDK', example='OpenAPI', position='Query'),
  status?: string(name='Status', description='The template state. Valid values:

*   Available: The template is available.
*   Created: The template is created but not ready for use.
*   Uploading: The video is being uploaded.
*   Processing: The advanced template is being processed.
*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.

>  After an advanced template is created, it enters the Processing state. In this case, the template is unavailable. The template can be used only when it is in the Available state. The time required for template processing varies based on the size of the template file. Generally, it ranges from 10 seconds to 5 minutes.', example='Available', position='Query'),
  templateId?: string(name='TemplateId', description='The ID of the online editing template. You can obtain the template ID in the [Intelligent Media Services (IMS) console](https://ice.console.aliyun.com/production/template/list/common) or the response parameters of the [AddTemplate](https://help.aliyun.com/document_detail/441161.html) operation.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model UpdateTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateTemplateResponseBody(name='body'),
}

/**
  * @description *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/270942.html).
  * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/291418.html).
  * @param request  the request parameters of UpdateTemplate  UpdateTemplateRequest
  * @return UpdateTemplateResponse
 */
async function updateTemplate(request: UpdateTemplateRequest): UpdateTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateTemplate', 'POST', '/', 'json', true, 'form', request);
}

model UploadMediaByURLRequest {
  regionId?: string(name='RegionId', position='Host'),
  appId?: string(name='AppId', description='The application ID.', example='app-1000000', position='Query'),
  entityId?: string(name='EntityId', description='The entity ID. You can call the CreateEntity operation to create an entity and specify a dynamic metadata structure.', example='d67281da3c8743b8823ad12976187***', position='Query'),
  mediaMetaData?: string(name='MediaMetaData', description='The metadata of the media file that you want to upload. The value must be a JSON string.

*   This parameter takes effect only if its value matches a URL that is specified in UploadURLs.
*   You must convert the JSON-formatted data, such as [UploadMetadata, UploadMetadata,…], into a JSON string.
*   For more information, see the "UploadMetadata" section of this topic.', example='[{"SourceURL":"https://example.aliyundoc.com/video01.mp4","Title":"urlUploadTest"}]', position='Query'),
  postProcessConfig?: string(name='PostProcessConfig', description='The postprocessing configurations. You can specify this parameter if Type is set to video or audio.

Set ProcessType to Workflow.', example='{"ProcessType": "Workflow","ProcessID":"b72a06c6beeb4dcdb898feef067b1***"}', position='Query'),
  uploadTargetConfig?: string(name='UploadTargetConfig', description='The destination storage address.

Set StorageType to oss.

Set StorageLocation to an address in ApsaraVideo VOD. You cannot set this field to an OSS URL.', example='{"StorageType":"oss","StorageLocation":"outin-***.oss-cn-shanghai.aliyuncs.com"}', position='Query'),
  uploadURLs?: string(name='UploadURLs', description='The URL of the source file.

*   The URL must contain a file name extension, such as mp4 in `https://****.mp4`.

    *   If the URL does not contain a file name extension, you can specify one by setting `FileExtension` in `UploadMetadata`.
    *   If the URL contains a file name extension and `FileExtension` is also specified, the value of `FileExtension` prevails.

*   URL encoding is required. Separate multiple URLs with commas (,). You can specify a maximum of 20 URLs.

*   Special characters may cause upload failures. Therefore, you must encode URLs before you separate them with commas (,).', example='https://diffurl.mp4', position='Query'),
  userData?: string(name='UserData', description='The user data. The value must be a JSON string. You can configure settings such as message callbacks.', example='{"MessageCallback":{"CallbackURL":"http://example.aliyundoc.com"},"Extend":{"localId":"xxx","test":"www"}}', position='Query'),
}

model UploadMediaByURLResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****83B7-7F87-4792-BFE9-63CD2137****'),
  uploadJobs?: [ 
    {
      jobId?: string(name='JobId', description='The ID of the upload job.', example='20ce1e05dba64576b96e9683879f0***'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='f476988629f54a7b8a4ba90d1a6c7***'),
      sourceURL?: string(name='SourceURL', description='The URL of the source file that is uploaded in the upload job.', example='http://example****.mp4'),
    }
  ](name='UploadJobs', description='The information about upload jobs.'),
}

model UploadMediaByURLResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UploadMediaByURLResponseBody(name='body'),
}

/**
  * @description *   If a callback is configured, you will receive an UploadByURLComplete event notification after the file is uploaded. You can query the upload status by calling the GetURLUploadInfos operation.
  * *   After a request is submitted, the upload job is queued as an asynchronous job in the cloud. You can query the status of the upload job based on information such as the URL and media asset ID that are returned in the event notification.
  * *   You can call this operation to upload media files that are not stored on a local server or device and must be uploaded by using URLs that are accessible over the Internet.
  * *   You can call this operation to upload media files only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media file to an OSS bucket, pull the file to a local directory, use [OSS SDK](https://help.aliyun.com/document_detail/32006.html) to upload the file to an OSS bucket, and then call the [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html) operation to register the file in the OSS bucket with the media asset library.
  * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
  * *   You can call this operation to upload only audio and video files.
  * @param request  the request parameters of UploadMediaByURL  UploadMediaByURLRequest
  * @return UploadMediaByURLResponse
 */
async function uploadMediaByURL(request: UploadMediaByURLRequest): UploadMediaByURLResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UploadMediaByURL', 'POST', '/', 'json', false, 'json', request);
}

model UploadStreamByURLRequest {
  regionId?: string(name='RegionId', position='Host'),
  definition?: string(name='Definition', description='The quality of the media stream. Valid values:

*   FD: low definition.
*   LD: standard definition.
*   SD: high definition.
*   HD: ultra-high definition.
*   OD: original quality.
*   2K: 2K resolution.
*   4K: 4K resolution.
*   SQ: standard sound quality.
*   HQ: high sound quality.', example='HD', position='Query'),
  fileExtension?: string(name='FileExtension', description='The file name extension of the media stream.', example='mp4', position='Query'),
  HDRType?: string(name='HDRType', description='The high dynamic range (HDR) format of the transcoded stream. Valid values:

*   HDR
*   HDR10
*   HLG
*   DolbyVision
*   HDRVivid
*   SDR+

> 

*   The value is not case-sensitive,

*   You can leave this parameter empty for non-HDR streams.', example='HDR10', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***', position='Query'),
  streamURL?: string(name='StreamURL', description='The URL of the transcoded stream file.

If the URL of the transcoded stream requires authentication, you must specify the authentication parameters in the stream URL and make sure that the URL can be accessed over the Internet.', example='https://example.com/sample-stream.mp4', position='Query'),
  userData?: string(name='UserData', description='The user data.', example='{"MessageCallback":{"CallbackURL":"http://test.test.com"}, "Extend":{"localId":"xxx","test":"www"}}', position='Query'),
}

model UploadStreamByURLResponseBody = {
  fileURL?: string(name='FileURL', description='The OSS URL of the file.', example='http://outin-***.oss-cn-shanghai.aliyuncs.com/stream/48555e8b-181dd5a8c07/48555e8b-181dd5a8c07.mp4'),
  jobId?: string(name='JobId', description='The ID of the upload job.', example='****cdb3e74639973036bc84****'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***'),
  requestId?: string(name='RequestId', description='The request ID.', example='******89-C21D-4B78-AE24-3788B8******'),
  sourceURL?: string(name='SourceURL', description='The URL of the source file that is uploaded in the upload job.', example='https://example.com/sample-stream.mp4'),
}

model UploadStreamByURLResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UploadStreamByURLResponseBody(name='body'),
}

/**
  * @description *   You can call this operation to pull a media stream file based on a URL and upload the file. After the media stream file is uploaded, the media stream is associated with the specified media asset ID.
  * *   You can call this operation to upload media stream files only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media stream file to an OSS bucket, pull the file to a local directory, use [OSS SDK](https://help.aliyun.com/document_detail/32006.html) to upload the file to an OSS bucket, and then call the [RegisterMediaStream](https://help.aliyun.com/document_detail/440765.html) operation to associate the media stream with the specified media asset ID.
  * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
  * @param request  the request parameters of UploadStreamByURL  UploadStreamByURLRequest
  * @return UploadStreamByURLResponse
 */
async function uploadStreamByURL(request: UploadStreamByURLRequest): UploadStreamByURLResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UploadStreamByURL', 'POST', '/', 'json', false, 'json', request);
}

