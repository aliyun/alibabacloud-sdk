/**
  *
  */
import BaseClientBuilder;
import TeaAsyncHandler;
import TeaRequest;
import AsyncRequestBody;
import RequestBody;
import AsyncResponseHandler;
import ClientConfiguration;
import ClientExecutionParams;
extends BaseClientBuilder;
type @product = string
type @version = string
type @endpointRule = string
type @endpointMap = map[string]string
type @REQUEST = TeaRequest
type @handler = TeaAsyncHandler

init(configuration: ClientConfiguration){
  @handler = new TeaAsyncHandler(configuration);
  @product = 'ICE';
  @version = '2020-11-09';
  @endpointRule = 'regional';
  @endpointMap = {
    'ap-northeast-1' = 'ice.aliyuncs.com',
    'ap-northeast-2-pop' = 'ice.aliyuncs.com',
    'ap-south-1' = 'ice.aliyuncs.com',
    'ap-southeast-1' = 'ice.aliyuncs.com',
    'ap-southeast-2' = 'ice.aliyuncs.com',
    'ap-southeast-3' = 'ice.aliyuncs.com',
    'ap-southeast-5' = 'ice.aliyuncs.com',
    'cn-beijing' = 'ice.aliyuncs.com',
    'cn-beijing-finance-1' = 'ice.aliyuncs.com',
    'cn-beijing-finance-pop' = 'ice.aliyuncs.com',
    'cn-beijing-gov-1' = 'ice.aliyuncs.com',
    'cn-beijing-nu16-b01' = 'ice.aliyuncs.com',
    'cn-chengdu' = 'ice.aliyuncs.com',
    'cn-edge-1' = 'ice.aliyuncs.com',
    'cn-fujian' = 'ice.aliyuncs.com',
    'cn-haidian-cm12-c01' = 'ice.aliyuncs.com',
    'cn-hangzhou' = 'ice.aliyuncs.com',
    'cn-hangzhou-bj-b01' = 'ice.aliyuncs.com',
    'cn-hangzhou-finance' = 'ice.aliyuncs.com',
    'cn-hangzhou-internal-prod-1' = 'ice.aliyuncs.com',
    'cn-hangzhou-internal-test-1' = 'ice.aliyuncs.com',
    'cn-hangzhou-internal-test-2' = 'ice.aliyuncs.com',
    'cn-hangzhou-internal-test-3' = 'ice.aliyuncs.com',
    'cn-hangzhou-test-306' = 'ice.aliyuncs.com',
    'cn-hongkong' = 'ice.aliyuncs.com',
    'cn-hongkong-finance-pop' = 'ice.aliyuncs.com',
    'cn-huhehaote' = 'ice.aliyuncs.com',
    'cn-huhehaote-nebula-1' = 'ice.aliyuncs.com',
    'cn-north-2-gov-1' = 'ice.aliyuncs.com',
    'cn-qingdao' = 'ice.aliyuncs.com',
    'cn-qingdao-nebula' = 'ice.aliyuncs.com',
    'cn-shanghai-et15-b01' = 'ice.aliyuncs.com',
    'cn-shanghai-et2-b01' = 'ice.aliyuncs.com',
    'cn-shanghai-finance-1' = 'ice.aliyuncs.com',
    'cn-shanghai-inner' = 'ice.aliyuncs.com',
    'cn-shanghai-internal-test-1' = 'ice.aliyuncs.com',
    'cn-shenzhen' = 'ice.aliyuncs.com',
    'cn-shenzhen-finance-1' = 'ice.aliyuncs.com',
    'cn-shenzhen-inner' = 'ice.aliyuncs.com',
    'cn-shenzhen-st4-d01' = 'ice.aliyuncs.com',
    'cn-shenzhen-su18-b01' = 'ice.aliyuncs.com',
    'cn-wuhan' = 'ice.aliyuncs.com',
    'cn-wulanchabu' = 'ice.aliyuncs.com',
    'cn-yushanfang' = 'ice.aliyuncs.com',
    'cn-zhangbei' = 'ice.aliyuncs.com',
    'cn-zhangbei-na61-b01' = 'ice.aliyuncs.com',
    'cn-zhangjiakou' = 'ice.aliyuncs.com',
    'cn-zhangjiakou-na62-a01' = 'ice.aliyuncs.com',
    'cn-zhengzhou-nebula-1' = 'ice.aliyuncs.com',
    'eu-central-1' = 'ice.aliyuncs.com',
    'eu-west-1' = 'ice.aliyuncs.com',
    'eu-west-1-oxs' = 'ice.aliyuncs.com',
    'me-east-1' = 'ice.aliyuncs.com',
    'rus-west-1-pop' = 'ice.aliyuncs.com',
    'us-east-1' = 'ice.aliyuncs.com',
    'us-west-1' = 'ice.aliyuncs.com',
  };
}

function close(): void {
  @handler.close();
}

model AIAgentConfig {
  ambientSoundConfig?: {
    resourceId?: string(name='ResourceId'),
    volume?: int32(name='Volume'),
  }(name='AmbientSoundConfig'),
  asrConfig?: {
    asrHotWords?: [ string ](name='AsrHotWords'),
    asrLanguageId?: string(name='AsrLanguageId'),
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    customParams?: string(name='CustomParams'),
    vadDuration?: int32(name='VadDuration'),
    vadLevel?: int32(name='VadLevel'),
  }(name='AsrConfig'),
  avatarConfig?: {
    avatarId?: string(name='AvatarId'),
  }(name='AvatarConfig'),
  avatarUrl?: string(name='AvatarUrl'),
  avatarUrlType?: string(name='AvatarUrlType'),
  enableIntelligentSegment?: boolean(name='EnableIntelligentSegment'),
  enablePushToTalk?: boolean(name='EnablePushToTalk'),
  experimentalConfig?: string(name='ExperimentalConfig'),
  gracefulShutdown?: boolean(name='GracefulShutdown'),
  greeting?: string(name='Greeting'),
  interruptConfig?: {
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    interruptWords?: [ string ](name='InterruptWords'),
  }(name='InterruptConfig'),
  llmConfig?: {
    bailianAppParams?: string(name='BailianAppParams'),
    functionMap?: [ 
      {
        function?: string(name='Function'),
        matchFunction?: string(name='MatchFunction'),
      }
    ](name='FunctionMap'),
    llmCompleteReply?: boolean(name='LlmCompleteReply'),
    llmHistory?: [ 
      {
        content?: string(name='Content'),
        role?: string(name='Role'),
      }
    ](name='LlmHistory'),
    llmHistoryLimit?: int32(name='LlmHistoryLimit'),
    llmSystemPrompt?: string(name='LlmSystemPrompt'),
    openAIExtraQuery?: string(name='OpenAIExtraQuery'),
    outputMaxDelay?: int32(name='OutputMaxDelay'),
    outputMinLength?: int32(name='OutputMinLength'),
  }(name='LlmConfig'),
  maxIdleTime?: int32(name='MaxIdleTime'),
  ttsConfig?: {
    emotion?: string(name='Emotion'),
    languageId?: string(name='LanguageId'),
    modelId?: string(name='ModelId'),
    pronunciationRules?: [ 
      {
        pronunciation?: string(name='Pronunciation'),
        type?: string(name='Type'),
        word?: string(name='Word'),
      }
    ](name='PronunciationRules'),
    speechRate?: double(name='SpeechRate'),
    voiceId?: string(name='VoiceId'),
    voiceIdList?: [ string ](name='VoiceIdList'),
  }(name='TtsConfig'),
  turnDetectionConfig?: {
    mode?: string(name='Mode'),
    semanticWaitDuration?: int32(name='SemanticWaitDuration'),
    turnEndWords?: [ string ](name='TurnEndWords'),
  }(name='TurnDetectionConfig'),
  userOfflineTimeout?: int32(name='UserOfflineTimeout'),
  userOnlineTimeout?: int32(name='UserOnlineTimeout'),
  vcrConfig?: {
    equipment?: {
      enabled?: boolean(name='Enabled'),
    }(name='Equipment'),
    headMotion?: {
      enabled?: boolean(name='Enabled'),
    }(name='HeadMotion'),
    invalidFrameMotion?: {
      callbackDelay?: int32(name='CallbackDelay'),
      enabled?: boolean(name='Enabled'),
    }(name='InvalidFrameMotion'),
    lookAway?: {
      enabled?: boolean(name='Enabled'),
    }(name='LookAway'),
    peopleCount?: {
      enabled?: boolean(name='Enabled'),
    }(name='PeopleCount'),
    stillFrameMotion?: {
      callbackDelay?: int32(name='CallbackDelay'),
      enabled?: boolean(name='Enabled'),
    }(name='StillFrameMotion'),
  }(name='VcrConfig'),
  voiceprintConfig?: {
    useVoiceprint?: boolean(name='UseVoiceprint'),
    voiceprintId?: string(name='VoiceprintId'),
  }(name='VoiceprintConfig'),
  volume?: long(name='Volume'),
  wakeUpQuery?: string(name='WakeUpQuery'),
  workflowOverrideParams?: string(name='WorkflowOverrideParams'),
}

model AIAgentOutboundCallConfig {
  ambientSoundConfig?: {
    resourceId?: string(name='ResourceId'),
    volume?: int32(name='Volume'),
  }(name='AmbientSoundConfig'),
  asrConfig?: {
    asrHotWords?: [ string ](name='AsrHotWords'),
    asrLanguageId?: string(name='AsrLanguageId'),
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    customParams?: string(name='CustomParams'),
    vadDuration?: int32(name='VadDuration'),
    vadLevel?: int32(name='VadLevel'),
  }(name='AsrConfig'),
  enableIntelligentSegment?: boolean(name='EnableIntelligentSegment'),
  experimentalConfig?: string(name='ExperimentalConfig'),
  greeting?: string(name='Greeting'),
  greetingDelay?: int32(name='GreetingDelay'),
  interruptConfig?: {
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    interruptWords?: [ string ](name='InterruptWords'),
  }(name='InterruptConfig'),
  llmConfig?: {
    bailianAppParams?: string(name='BailianAppParams'),
    functionMap?: [ 
      {
        function?: string(name='Function'),
        matchFunction?: string(name='MatchFunction'),
      }
    ](name='FunctionMap'),
    llmCompleteReply?: boolean(name='LlmCompleteReply'),
    llmHistory?: [ 
      {
        content?: string(name='Content'),
        role?: string(name='Role'),
      }
    ](name='LlmHistory'),
    llmHistoryLimit?: int32(name='LlmHistoryLimit'),
    llmSystemPrompt?: string(name='LlmSystemPrompt'),
    openAIExtraQuery?: string(name='OpenAIExtraQuery'),
    outputMaxDelay?: string(name='OutputMaxDelay'),
    outputMinLength?: int32(name='OutputMinLength'),
  }(name='LlmConfig'),
  ttsConfig?: {
    emotion?: string(name='Emotion'),
    languageId?: string(name='LanguageId'),
    modelId?: string(name='ModelId'),
    pronunciationRules?: [ 
      {
        pronunciation?: string(name='Pronunciation'),
        type?: string(name='Type'),
        word?: string(name='Word'),
      }
    ](name='PronunciationRules'),
    speechRate?: double(name='SpeechRate'),
    voiceId?: string(name='VoiceId'),
    voiceIdList?: [ string ](name='VoiceIdList'),
  }(name='TtsConfig'),
  turnDetectionConfig?: {
    mode?: string(name='Mode'),
    semanticWaitDuration?: int32(name='SemanticWaitDuration'),
    turnEndWords?: [ string ](name='TurnEndWords'),
  }(name='TurnDetectionConfig'),
}

model AIAgentRuntimeConfig {
  agentUserId?: string(name='AgentUserId'),
  authToken?: string(name='AuthToken'),
  avatarChat3D?: {
    agentUserId?: string(name='AgentUserId'),
    authToken?: string(name='AuthToken'),
    channelId?: string(name='ChannelId'),
  }(name='AvatarChat3D', deprecated='true'),
  channelId?: string(name='ChannelId'),
  visionChat?: {
    agentUserId?: string(name='AgentUserId'),
    authToken?: string(name='AuthToken'),
    channelId?: string(name='ChannelId'),
  }(name='VisionChat', deprecated='true'),
  voiceChat?: {
    agentUserId?: string(name='AgentUserId'),
    authToken?: string(name='AuthToken'),
    channelId?: string(name='ChannelId'),
  }(name='VoiceChat', deprecated='true'),
}

model AIAgentTemplateConfig {
  avatarChat3D?: {
    asrHotWords?: [ string ](name='AsrHotWords'),
    asrLanguageId?: string(name='AsrLanguageId'),
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    avatarId?: string(name='AvatarId'),
    bailianAppParams?: string(name='BailianAppParams'),
    charBreak?: boolean(name='CharBreak'),
    enableIntelligentSegment?: boolean(name='EnableIntelligentSegment'),
    enablePushToTalk?: boolean(name='EnablePushToTalk'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    gracefulShutdown?: boolean(name='GracefulShutdown'),
    greeting?: string(name='Greeting'),
    interruptWords?: [ string ](name='InterruptWords'),
    llmHistory?: [ 
      {
        content?: string(name='Content'),
        role?: string(name='Role'),
      }
    ](name='LlmHistory'),
    llmHistoryLimit?: int32(name='LlmHistoryLimit'),
    llmSystemPrompt?: string(name='LlmSystemPrompt'),
    maxIdleTime?: int32(name='MaxIdleTime'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    vadLevel?: int32(name='VadLevel'),
    voiceId?: string(name='VoiceId'),
    voiceIdList?: [ string ](name='VoiceIdList'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
    wakeUpQuery?: string(name='WakeUpQuery'),
    workflowOverrideParams?: string(name='WorkflowOverrideParams'),
  }(name='AvatarChat3D'),
  visionChat?: {
    asrHotWords?: [ string ](name='AsrHotWords'),
    asrLanguageId?: string(name='AsrLanguageId'),
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    bailianAppParams?: string(name='BailianAppParams'),
    charBreak?: boolean(name='CharBreak'),
    enableIntelligentSegment?: boolean(name='EnableIntelligentSegment'),
    enablePushToTalk?: boolean(name='EnablePushToTalk'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    gracefulShutdown?: boolean(name='GracefulShutdown'),
    greeting?: string(name='Greeting'),
    interruptWords?: [ string ](name='InterruptWords'),
    llmHistory?: [ 
      {
        content?: string(name='Content'),
        role?: string(name='Role'),
      }
    ](name='LlmHistory'),
    llmHistoryLimit?: int32(name='LlmHistoryLimit'),
    llmSystemPrompt?: string(name='LlmSystemPrompt'),
    maxIdleTime?: int32(name='MaxIdleTime'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    vadLevel?: int32(name='VadLevel'),
    voiceId?: string(name='VoiceId'),
    voiceIdList?: [ string ](name='VoiceIdList'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
    wakeUpQuery?: string(name='WakeUpQuery'),
    workflowOverrideParams?: string(name='WorkflowOverrideParams'),
  }(name='VisionChat'),
  voiceChat?: {
    asrHotWords?: [ string ](name='AsrHotWords'),
    asrLanguageId?: string(name='AsrLanguageId'),
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    avatarUrl?: string(name='AvatarUrl'),
    avatarUrlType?: string(name='AvatarUrlType'),
    bailianAppParams?: string(name='BailianAppParams'),
    charBreak?: boolean(name='CharBreak'),
    enableIntelligentSegment?: boolean(name='EnableIntelligentSegment'),
    enablePushToTalk?: boolean(name='EnablePushToTalk'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    gracefulShutdown?: boolean(name='GracefulShutdown'),
    greeting?: string(name='Greeting'),
    interruptWords?: [ string ](name='InterruptWords'),
    llmHistory?: [ 
      {
        content?: string(name='Content'),
        role?: string(name='Role'),
      }
    ](name='LlmHistory'),
    llmHistoryLimit?: int32(name='LlmHistoryLimit'),
    llmSystemPrompt?: string(name='LlmSystemPrompt'),
    maxIdleTime?: int32(name='MaxIdleTime'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    vadLevel?: int32(name='VadLevel'),
    voiceId?: string(name='VoiceId'),
    voiceIdList?: [ string ](name='VoiceIdList'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
    wakeUpQuery?: string(name='WakeUpQuery'),
    workflowOverrideParams?: string(name='WorkflowOverrideParams'),
  }(name='VoiceChat'),
}

model AiRtcAuthCodeDTO {
  activatedTime?: string(name='ActivatedTime'),
  authCode?: string(name='AuthCode'),
  creationTime?: string(name='CreationTime'),
  deviceId?: string(name='DeviceId'),
  license?: string(name='License'),
  licenseItemId?: string(name='LicenseItemId'),
  modificationTime?: string(name='ModificationTime'),
  status?: int32(name='Status'),
  type?: int32(name='Type'),
}

model AiRtcLicenseInfoDTO {
  availableCapacity?: long(name='AvailableCapacity'),
  beginOn?: string(name='BeginOn'),
  contractNo?: string(name='ContractNo'),
  creationTime?: string(name='CreationTime'),
  expiredOn?: string(name='ExpiredOn'),
  instanceId?: string(name='InstanceId'),
  licenseCount?: long(name='LicenseCount'),
  licenseItemId?: string(name='LicenseItemId'),
  modificationTime?: string(name='ModificationTime'),
  status?: int32(name='Status'),
  type?: int32(name='Type'),
  validDays?: long(name='ValidDays'),
}

model AppInfoDTO {
  appName?: string(name='AppName'),
  appType?: int32(name='AppType', example='1-普通应用，2-内嵌SDK.'),
  creationTime?: string(name='CreationTime'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  itemId?: string(name='ItemId'),
  modificationTime?: string(name='ModificationTime'),
  platforms?: [ 
    {
      itemId?: string(name='ItemId'),
      licenseItemIds?: [ string ](name='LicenseItemIds'),
      pkgName?: string(name='PkgName'),
      pkgSignature?: string(name='PkgSignature'),
      platformType?: long(name='PlatformType'),
      type?: long(name='Type'),
    }
  ](name='Platforms'),
  userId?: long(name='UserId'),
}

model Channel {
  accessPolicy?: boolean(name='AccessPolicy'),
  accessToken?: string(name='AccessToken'),
  arn?: string(name='Arn'),
  channelName?: string(name='ChannelName'),
  channelTier?: string(name='ChannelTier'),
  fillerSourceLocationName?: string(name='FillerSourceLocationName'),
  fillerSourceName?: string(name='FillerSourceName'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  outPutConfigList?: [ 
    {
      channelName?: string(name='ChannelName'),
      format?: string(name='Format'),
      manifestName?: string(name='ManifestName'),
      manifestSettings?: string(name='ManifestSettings'),
      playbackUrl?: string(name='PlaybackUrl'),
      sourceGroupName?: string(name='SourceGroupName'),
    }
  ](name='OutPutConfigList'),
  playbackMode?: string(name='PlaybackMode'),
  state?: int32(name='State'),
}

model ChannelAssemblyChannel {
  accessPolicy?: boolean(name='AccessPolicy'),
  accessToken?: string(name='AccessToken'),
  arn?: string(name='Arn'),
  channelName?: string(name='ChannelName'),
  channelTier?: string(name='ChannelTier'),
  fillerSourceLocationName?: string(name='FillerSourceLocationName'),
  fillerSourceName?: string(name='FillerSourceName'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  outPutConfigList?: [ 
    {
      channelName?: string(name='ChannelName'),
      format?: string(name='Format'),
      manifestName?: string(name='ManifestName'),
      manifestSettings?: string(name='ManifestSettings'),
      playbackUrl?: string(name='PlaybackUrl'),
      sourceGroupName?: string(name='SourceGroupName'),
    }
  ](name='OutPutConfigList'),
  playbackMode?: string(name='PlaybackMode'),
  state?: int32(name='State'),
}

model ChannelAssemblyProgram {
  adBreaks?: [ 
    {
      channelName?: string(name='ChannelName'),
      messageType?: string(name='MessageType'),
      offsetMillis?: long(name='OffsetMillis'),
      programName?: string(name='ProgramName'),
      sourceLocationName?: string(name='SourceLocationName'),
      sourceName?: string(name='SourceName'),
      spliceInsertSettings?: string(name='SpliceInsertSettings'),
      timeSignalSettings?: string(name='TimeSignalSettings'),
    }
  ](name='AdBreaks'),
  arn?: string(name='Arn'),
  channelName?: string(name='ChannelName'),
  clipRange?: string(name='ClipRange'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  programName?: string(name='ProgramName'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
  transition?: string(name='Transition'),
}

model ChannelAssemblyScheduleData {
  adBreaks?: [ 
    {
      messageType?: string(name='MessageType'),
      offsetMillis?: string(name='OffsetMillis'),
      sourceLocationName?: string(name='SourceLocationName'),
      sourceName?: string(name='SourceName'),
      spliceInsertSettings?: string(name='SpliceInsertSettings'),
      timeSignalSettings?: string(name='TimeSignalSettings'),
    }
  ](name='AdBreaks'),
  approximateDurationSeconds?: long(name='ApproximateDurationSeconds'),
  approximateStartTime?: string(name='ApproximateStartTime'),
  entryType?: string(name='EntryType'),
  programName?: string(name='ProgramName'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
}

model ChannelAssemblySource {
  arn?: string(name='Arn'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  httpPackageConfigurations?: string(name='HttpPackageConfigurations'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
  state?: int32(name='State'),
}

model ChannelAssemblySourceLocation {
  arn?: string(name='Arn'),
  baseUrl?: string(name='BaseUrl'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  segmentDeliveryConfigurations?: string(name='SegmentDeliveryConfigurations'),
  sourceLocationName?: string(name='SourceLocationName'),
  state?: int32(name='State'),
}

model EntityMediaBasicInfo {
  appId?: string(name='AppId'),
  biz?: string(name='Biz'),
  createTime?: string(name='CreateTime'),
  entityId?: string(name='EntityId'),
  entityMediaId?: string(name='EntityMediaId'),
  modifiedTime?: string(name='ModifiedTime'),
  status?: string(name='Status'),
  userData?: string(name='UserData'),
}

model Hotword {
  language?: string(name='Language', example='en'),
  text?: string(name='Text', example='hello'),
  transpositionResultList?: [
    TranspositionResult
  ](name='TranspositionResultList'),
  weight?: int32(name='Weight'),
}

model LicenseInstanceAppDTO {
  appId?: string(name='AppId'),
  beginOn?: string(name='BeginOn'),
  contractNo?: string(name='ContractNo'),
  creationTime?: string(name='CreationTime'),
  expiredOn?: string(name='ExpiredOn'),
  instanceId?: string(name='InstanceId'),
  itemId?: string(name='ItemId'),
  licenseConfigs?: [ 
    {
      businessType?: string(name='BusinessType'),
      featureIds?: string(name='FeatureIds'),
      isTrial?: boolean(name='IsTrial'),
      sdkId?: int32(name='SdkId'),
      sdkName?: string(name='SdkName'),
      subscription?: string(name='Subscription'),
      subscriptionImp?: string(name='SubscriptionImp'),
      subscriptionPkg?: string(name='SubscriptionPkg'),
    }
  ](name='LicenseConfigs'),
  modificationTime?: string(name='ModificationTime'),
  status?: string(name='Status'),
  userId?: long(name='UserId'),
}

model LiveManifestConfig {
  adMarkers?: string(name='AdMarkers'),
  dateTimeInterval?: int32(name='DateTimeInterval'),
  manifestDuration?: int32(name='ManifestDuration'),
  maxVideoBitrate?: int32(name='MaxVideoBitrate'),
  minBufferTime?: int32(name='MinBufferTime'),
  minUpdatePeriod?: int32(name='MinUpdatePeriod'),
  minVideoBitrate?: int32(name='MinVideoBitrate'),
  presentationDelay?: int32(name='PresentationDelay'),
  segmentCount?: int32(name='SegmentCount'),
  segmentTemplateFormat?: string(name='SegmentTemplateFormat'),
  streamOrder?: string(name='StreamOrder'),
}

model LivePackagingConfig {
  drmConfig?: {
    contentId?: string(name='ContentId'),
    encryptionMethod?: string(name='EncryptionMethod'),
    iv?: string(name='IV'),
    rotatePeriod?: int32(name='RotatePeriod'),
    systemIds?: [ string ](name='SystemIds'),
    url?: string(name='Url'),
  }(name='DrmConfig'),
  liveManifestConfigs?: [
    LiveManifestConfig
  ](name='LiveManifestConfigs'),
  segmentDuration?: int32(name='SegmentDuration'),
  useAudioRenditionGroups?: boolean(name='UseAudioRenditionGroups'),
}

model MediaConvertAudio {
  bitrate?: long(name='Bitrate'),
  channels?: long(name='Channels'),
  codec?: string(name='Codec'),
  profile?: string(name='Profile'),
  remove?: boolean(name='Remove'),
  samplerate?: string(name='Samplerate'),
}

model MediaConvertInput {
  inputFile?: MediaObject(name='InputFile'),
  name?: string(name='Name'),
}

model MediaConvertJob {
  clientToken?: string(name='ClientToken'),
  code?: string(name='Code'),
  config?: {
    inputs?: [
      MediaConvertInput
    ](name='Inputs'),
    jobName?: string(name='JobName'),
    outputGroups?: [
      MediaConvertOutputGroup
    ](name='OutputGroups'),
    outputs?: [
      MediaConvertOutput
    ](name='Outputs'),
  }(name='Config'),
  createTime?: string(name='CreateTime'),
  finishTime?: string(name='FinishTime'),
  jobId?: string(name='JobId'),
  message?: string(name='Message'),
  outputDetails?: [
    MediaConvertOutputDetail
  ](name='OutputDetails'),
  outputGroupDetails?: [
    MediaConvertOutputGroupDetail
  ](name='OutputGroupDetails'),
  percent?: int32(name='Percent'),
  pipelineId?: string(name='PipelineId'),
  requestId?: string(name='RequestId'),
  state?: string(name='State'),
  userData?: string(name='UserData'),
}

model MediaConvertJobWithoutDetail {
  clientToken?: string(name='ClientToken'),
  code?: string(name='Code'),
  config?: {
    inputs?: [
      MediaConvertInput
    ](name='Inputs'),
    jobName?: string(name='JobName'),
    outputGroups?: [
      MediaConvertOutputGroup
    ](name='OutputGroups'),
    outputs?: [
      MediaConvertOutput
    ](name='Outputs'),
  }(name='Config'),
  createTime?: string(name='CreateTime'),
  finishTime?: string(name='FinishTime'),
  jobId?: string(name='JobId'),
  message?: string(name='Message'),
  pipelineId?: string(name='PipelineId'),
  requestId?: string(name='RequestId'),
  state?: string(name='State'),
  userData?: string(name='UserData'),
}

model MediaConvertMuxConfig {
  segment?: MediaConvertSegment(name='Segment'),
}

model MediaConvertOutput {
  features?: string(name='Features'),
  name?: string(name='Name'),
  outputFile?: MediaObject(name='OutputFile'),
  overrideParams?: string(name='OverrideParams'),
  priority?: int32(name='Priority', minimum=1, maximum=10),
  templateId?: string(name='TemplateId'),
}

model MediaConvertOutputDetail {
  code?: string(name='Code'),
  createTime?: string(name='CreateTime'),
  finishTime?: string(name='FinishTime'),
  message?: string(name='Message'),
  name?: string(name='Name'),
  result?: {
    outFileMeta?: MediaConvertOutputDetailFileMeta(name='OutFileMeta'),
    outputFile?: {
      media?: string(name='Media'),
      type?: string(name='Type'),
      url?: string(name='Url'),
    }(name='OutputFile'),
  }(name='Result'),
  status?: string(name='Status'),
  taskId?: string(name='TaskId'),
}

model MediaConvertOutputDetailFileMeta {
  audioStreamInfoList?: [ 
    {
      bitrate?: string(name='Bitrate', example='0.f'),
      channelLayout?: string(name='ChannelLayout', example='stereo'),
      channels?: string(name='Channels', example='2'),
      codecLongName?: string(name='CodecLongName', example='AAC (Advanced Audio Coding)'),
      codecName?: string(name='CodecName', example='aac'),
      codecTag?: string(name='CodecTag', example='0x000f'),
      codecTagString?: string(name='CodecTagString', example='[15][0][0][0]'),
      codecTimeBase?: string(name='CodecTimeBase', example='1/44100'),
      duration?: string(name='Duration', example='403.039989'),
      index?: string(name='Index', example='1'),
      lang?: string(name='Lang', example='cn'),
      sampleFmt?: string(name='SampleFmt', example='fltp'),
      sampleRate?: string(name='SampleRate', example='44100'),
      startTime?: string(name='StartTime', example='1.473556'),
      timebase?: string(name='Timebase', example='1/90000'),
    }
  ](name='AudioStreamInfoList'),
  fileBasicInfo?: {
    bitrate?: string(name='Bitrate', example='888.563'),
    duration?: string(name='Duration', example='403.039999'),
    fileName?: string(name='FileName', example='file.m3u8'),
    fileSize?: string(name='FileSize', example='31737'),
    fileStatus?: string(name='FileStatus', example='Normal'),
    fileType?: string(name='FileType', example='source_file'),
    fileUrl?: string(name='FileUrl', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
    formatName?: string(name='FormatName', example='hls,applehttp'),
    height?: string(name='Height', example='478'),
    mediaId?: string(name='MediaId'),
    region?: string(name='Region', example='cn-shanghai'),
    width?: string(name='Width', example='848'),
  }(name='FileBasicInfo'),
  videoStreamInfoList?: [ 
    {
      avgFps?: string(name='Avg_fps', example='25.0'),
      bitRate?: string(name='Bit_rate', example='888.563'),
      codecLongName?: string(name='Codec_long_name', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
      codecName?: string(name='Codec_name', example='h264'),
      codecTag?: string(name='Codec_tag', example='0x001b'),
      codecTagString?: string(name='Codec_tag_string', example='[27][0][0][0]'),
      codecTimeBase?: string(name='Codec_time_base'),
      dar?: string(name='Dar', example='16:9'),
      duration?: string(name='Duration', example='403.039989'),
      fps?: string(name='Fps', example='25.0'),
      hasBFrames?: string(name='Has_b_frames', example='2'),
      height?: string(name='Height', example='478'),
      index?: string(name='Index', example='0'),
      lang?: string(name='Lang', example='cn'),
      level?: string(name='Level', example='31'),
      numFrames?: string(name='NumFrames', example='10040'),
      pixFmt?: string(name='PixFmt', example='yuv420p'),
      profile?: string(name='Profile', example='High'),
      rotate?: string(name='Rotate', example='0'),
      sar?: string(name='Sar', example='478:477'),
      startTime?: string(name='Start_time', example='1.473556'),
      timeBase?: string(name='Time_base', example='1/90000'),
      width?: string(name='Width', example='848'),
    }
  ](name='VideoStreamInfoList'),
}

model MediaConvertOutputGroup {
  groupConfig?: MediaConvertOutputGroupConfig(name='GroupConfig'),
  name?: string(name='Name'),
  outputs?: [
    MediaConvertOutputGroupOutput
  ](name='Outputs'),
}

model MediaConvertOutputGroupConfig {
  manifestName?: string(name='ManifestName'),
  outputFileBase?: MediaObject(name='OutputFileBase'),
  type?: string(name='Type'),
}

model MediaConvertOutputGroupDetail {
  code?: string(name='Code'),
  createTime?: string(name='CreateTime'),
  finishTime?: string(name='FinishTime'),
  message?: string(name='Message'),
  name?: string(name='Name'),
  outputs?: [
    MediaConvertOutputDetail
  ](name='Outputs'),
  status?: string(name='Status'),
  taskId?: string(name='TaskId'),
}

model MediaConvertOutputGroupOutput {
  features?: string(name='Features'),
  name?: string(name='Name'),
  outputFileName?: string(name='OutputFileName'),
  overrideParams?: string(name='OverrideParams'),
  priority?: int32(name='Priority'),
  templateId?: string(name='TemplateId'),
}

model MediaConvertSegment {
  duration?: int32(name='Duration'),
  forceSegTime?: string(name='ForceSegTime'),
}

model MediaConvertTransConfig {
  adjDarMethod?: string(name='AdjDarMethod'),
  isCheckAudioBitrate?: boolean(name='IsCheckAudioBitrate'),
  isCheckAudioBitrateFail?: boolean(name='IsCheckAudioBitrateFail'),
  isCheckReso?: boolean(name='IsCheckReso'),
  isCheckResoFail?: boolean(name='IsCheckResoFail'),
  isCheckVideoBitrate?: boolean(name='IsCheckVideoBitrate'),
  isCheckVideoBitrateFail?: boolean(name='IsCheckVideoBitrateFail'),
  transMode?: string(name='TransMode'),
}

model MediaConvertVideo {
  bitrate?: int32(name='Bitrate'),
  bufsize?: int32(name='Bufsize'),
  codec?: string(name='Codec'),
  crf?: any(name='Crf'),
  crop?: string(name='Crop'),
  fps?: any(name='Fps'),
  gop?: any(name='Gop'),
  height?: int32(name='Height'),
  longShortMode?: boolean(name='LongShortMode'),
  maxFps?: any(name='MaxFps'),
  maxrate?: int32(name='Maxrate'),
  pad?: string(name='Pad'),
  profile?: string(name='Profile'),
  qscale?: int32(name='Qscale'),
  remove?: boolean(name='Remove'),
  scanMode?: string(name='ScanMode'),
  width?: int32(name='Width'),
}

model MediaConvertVolume {
  integratedLoudnessTarget?: int32(name='IntegratedLoudnessTarget'),
  level?: int32(name='Level'),
  loudnessRangeTarget?: int32(name='LoudnessRangeTarget'),
  method?: string(name='Method'),
  truePeak?: int32(name='TruePeak'),
}

model MediaObject {
  media?: string(name='Media'),
  type?: string(name='Type'),
  url?: string(name='Url'),
}

model Program {
  adBreaks?: [ 
    {
      channelName?: string(name='ChannelName'),
      messageType?: string(name='MessageType'),
      offsetMillis?: long(name='OffsetMillis'),
      programName?: string(name='ProgramName'),
      sourceLocationName?: string(name='SourceLocationName'),
      sourceName?: string(name='SourceName'),
      spliceInsertSettings?: string(name='SpliceInsertSettings'),
      timeSignalSettings?: string(name='TimeSignalSettings'),
    }
  ](name='AdBreaks'),
  arn?: string(name='Arn'),
  channelName?: string(name='ChannelName'),
  clipRange?: string(name='ClipRange'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  programName?: string(name='ProgramName'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
  transition?: string(name='Transition'),
}

model ScheduleData {
  adBreaks?: [ 
    {
      messageType?: string(name='MessageType'),
      offsetMillis?: string(name='OffsetMillis'),
      sourceLocationName?: string(name='SourceLocationName'),
      sourceName?: string(name='SourceName'),
      spliceInsertSettings?: string(name='SpliceInsertSettings'),
      timeSignalSettings?: string(name='TimeSignalSettings'),
    }
  ](name='AdBreaks'),
  approximateDurationSeconds?: long(name='ApproximateDurationSeconds'),
  approximateStartTime?: string(name='ApproximateStartTime'),
  entryType?: string(name='EntryType'),
  programName?: string(name='ProgramName'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
}

model Source {
  arn?: string(name='Arn'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  httpPackageConfigurations?: string(name='HttpPackageConfigurations'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
  state?: int32(name='State'),
}

model SourceLocation {
  arn?: string(name='Arn'),
  baseUrl?: string(name='BaseUrl'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  segmentDeliveryConfigurations?: string(name='SegmentDeliveryConfigurations'),
  sourceLocationName?: string(name='SourceLocationName'),
  state?: int32(name='State'),
}

model TranspositionResult {
  targetLanguage?: string(name='TargetLanguage', example='zh'),
  translatedText?: string(name='TranslatedText', example='你好'),
}

model VodPackagingAsset {
  assetName?: string(name='AssetName'),
  contentId?: string(name='ContentId'),
  createTime?: string(name='CreateTime'),
  groupName?: string(name='GroupName'),
  input?: {
    media?: string(name='Media'),
    type?: string(name='Type'),
  }(name='Input'),
}

model VodPackagingConfig {
  drmProvider?: {
    encryptionMethod?: string(name='EncryptionMethod'),
    iv?: string(name='IV'),
    systemIds?: [ string ](name='SystemIds'),
    url?: string(name='Url'),
  }(name='DrmProvider'),
  manifestName?: string(name='ManifestName'),
  segmentDuration?: long(name='SegmentDuration'),
  streamSelection?: {
    maxVideoBitsPerSecond?: long(name='MaxVideoBitsPerSecond'),
    minVideoBitsPerSecond?: long(name='MinVideoBitsPerSecond'),
    streamOrder?: string(name='StreamOrder'),
  }(name='StreamSelection'),
}

model VodPackagingConfiguration {
  configurationName?: string(name='ConfigurationName'),
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  groupName?: string(name='GroupName'),
  packageConfig?: VodPackagingConfig(name='PackageConfig'),
  protocol?: string(name='Protocol'),
}

model VodPackagingGroup {
  approximateAssetCount?: long(name='ApproximateAssetCount'),
  configurationCount?: long(name='ConfigurationCount'),
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  domainName?: string(name='DomainName'),
  groupName?: string(name='GroupName'),
}

model ActiveAiRtcLicenseRequest {
  authCode?: string(name='AuthCode', example='iU1IeJech7***', position='Query'),
  deviceId?: string(name='DeviceId', example='device-***', position='Query'),
  licenseItemId?: string(name='LicenseItemId', example='17712***', position='Query'),
}

model ActiveAiRtcLicenseResponseBody = {
  code?: string(name='Code', example='Success'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  license?: string(name='License', example='a659a06659a***'),
  message?: string(name='Message', example='OK'),
  requestId?: string(name='RequestId', example='4F9C14FE-1147-15AC-8EDF-A590FF12***'),
  success?: boolean(name='Success', example='true'),
}

model ActiveAiRtcLicenseResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ActiveAiRtcLicenseResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ActiveAiRtcLicense  ActiveAiRtcLicenseRequest
  * @return ActiveAiRtcLicenseResponse
 */
async function activeAiRtcLicense(request: ActiveAiRtcLicenseRequest): ActiveAiRtcLicenseResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ActiveAiRtcLicense', 'POST', '/', 'json', false, 'json', request);
}

model AddAdInsertionRequest {
  adMarkerPassthrough?: string(name='AdMarkerPassthrough', description='Specifies whether to enable ad marker passthrough. Default value: OFF.

Valid values:

*   OFF: Disable.
*   ON: Enable.', example='ON', position='Body'),
  adsUrl: string(name='AdsUrl', description='The request URL of the ad decision server (ADS). HTTP and HTTPS are supported. The maximum length is 2,048 characters.

This parameter is required.', example='http://ads.com/ad1?param1=[palyer_params.p1]', position='Body'),
  cdnAdSegmentUrlPrefix?: string(name='CdnAdSegmentUrlPrefix', description='The CDN prefix for ad segments. HTTP and HTTPS are supported. The maximum length is 512 characters.', example='http://cdn.com/', position='Body'),
  cdnContentSegmentUrlPrefix?: string(name='CdnContentSegmentUrlPrefix', description='The CDN prefix for content segments. HTTP and HTTPS are supported. The maximum length is 512 characters.', example='http://cdn.com/', position='Body'),
  clientToken?: string(name='ClientToken', description='The idempotency key that is used to avoid repeated submission. The value can be up to 200 characters in length.', example='****0311a423d11a5f7dee713535****', position='Body'),
  configAliases?: string(name='ConfigAliases', description='A JSON string that specifies the player parameter variables and aliases. You can add up to 20 player_params.{name} entries. The name field can be up to 150 characters in length. Each player parameter can include up to 50 key-value pairs. A key can be up to 150 characters long, and a value can be up to 500 characters. Example: { "player_params.{name}": { "{key}": "{value}" } }', example='{ "player_params.p1": { "1": "abc" } }', position='Body'),
  contentUrlPrefix: string(name='ContentUrlPrefix', description='The URL prefix for the source content. HTTP and HTTPS are supported. The maximum length is 512 characters.

This parameter is required.', example='https://source.com/', position='Body'),
  name: string(name='Name', description='The name of the configuration. The name must be unique and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.

This parameter is required.', example='my_ad', position='Body'),
  personalizationThreshold?: int32(name='PersonalizationThreshold', description='Specifies the maximum duration of underfilled time allowed in an ad break. Unit: seconds. Default value: 8 seconds.', example='5', position='Body'),
  slateAdUrl?: string(name='SlateAdUrl', description='The HTTP or HTTPS URL of the slate ad. Only MP4 format is supported. The maximum length is 2,048 characters.', example='http://storage.com/slate1.mp4', position='Body'),
}

model AddAdInsertionResponseBody = {
  config?: {
    adMarkerPassthrough?: string(name='AdMarkerPassthrough', description='Indicates whether ad marker passthrough is enabled.', example='ON'),
    adsUrl?: string(name='AdsUrl', description='The request URL of ADS.', example='http://ads.com/ad1?param1=[palyer_params.p1]'),
    cdnConfig?: {
      adSegmentUrlPrefix?: string(name='AdSegmentUrlPrefix', description='The CDN prefix for ad segments.', example='http://cdn.com/'),
      contentSegmentUrlPrefix?: string(name='ContentSegmentUrlPrefix', description='The CDN prefix for content segments.', example='http://cdn.com/'),
    }(name='CdnConfig', description='The CDN configurations.'),
    configAliases?: string(name='ConfigAliases', description='The player parameter variables and aliases.', example='{ "player_params.p1": { "1": "abc" } }'),
    contentUrlPrefix?: string(name='ContentUrlPrefix', description='The URL prefix for the source content.', example='https://source.com/'),
    createTime?: string(name='CreateTime', description='The time when the configuration was created.', example='2024-06-13T08:26:09Z'),
    lastModified?: string(name='LastModified', description='The time when the configuration was last modified.', example='2024-06-13T08:26:09Z'),
    manifestEndpointConfig?: {
      dashPrefix?: string(name='DashPrefix', description='DASH清单播放端点前缀'),
      hlsPrefix?: string(name='HlsPrefix', description='The prefix of the playback endpoint for HLS manifests.'),
    }(name='ManifestEndpointConfig', description='The playback endpoint configuration.'),
    name?: string(name='Name', description='The name of the ad insertion configuration.', example='my_ad'),
    personalizationThreshold?: int32(name='PersonalizationThreshold', description='The personalization threshold.', example='5'),
    slateAdUrl?: string(name='SlateAdUrl', description='The URL of the slate ad.', example='http://storage.com/slate1.mp4'),
  }(name='Config', description='The ad insertion configuration.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
}

model AddAdInsertionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddAdInsertionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AddAdInsertion  AddAdInsertionRequest
  * @return AddAdInsertionResponse
 */
async function addAdInsertion(request: AddAdInsertionRequest): AddAdInsertionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddAdInsertion', 'POST', '/', 'json', true, 'form', request);
}

model AddCategoryRequest {
  regionId?: string(name='RegionId', position='Host'),
  cateName: string(name='CateName', description='The category name.

*   The value can be up to 64 bytes in length.
*   The value must be encoded in UTF-8.

This parameter is required.', position='Query'),
  parentId?: long(name='ParentId', description='The ID of the parent category.', example='5', position='Query'),
  type?: string(name='Type', description='The type of the category. Valid values:

*   default: audio, video, and image files. This is the default value.
*   material: short video materials.', example='default', position='Query'),
}

model AddCategoryResponseBody = {
  category?: {
    cateId?: long(name='CateId', description='The ID of the created category.', example='45'),
    cateName?: string(name='CateName', description='The category name.'),
    level?: long(name='Level', description='The level of the category. A value of **0** indicates a level-1 category, a value of **1** indicates a level-2 category, and a value of **2** indicates a level-3 category.', example='0'),
    parentId?: long(name='ParentId', description='The ID of the parent category. By default, if ParentId is left empty or less than 1, -1 is returned, which indicates that the created category is the root directory.', example='-1'),
    type?: string(name='Type', description='The type of the category. Valid values:

*   **default**: audio, video, and image files. This is the default value.
*   **material**: short video materials.', example='default'),
  }(name='Category', description='The information about the category.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model AddCategoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddCategoryResponseBody(name='body'),
}

/**
  * @description You can create at most three levels of categories. Each category level can contain a maximum of 100 subcategories.
  * @param request  the request parameters of AddCategory  AddCategoryRequest
  * @return AddCategoryResponse
 */
async function addCategory(request: AddCategoryRequest): AddCategoryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddCategory', 'POST', '/', 'json', false, 'json', request);
}

model AddEditingProjectMaterialsRequest {
  materialMaps: string(name='MaterialMaps', description='The material ID. Separate multiple material IDs with commas (,). Each type supports up to 10 material IDs. The following material types are supported:

*   video
*   audio
*   image
*   liveStream
*   editingProject

This parameter is required.', example='{"video":"*****2e057304fcd9b145c5cafc*****", "image":"****8021a8d493da643c8acd98*****,*****cb6307a4edea614d8b3f3c*****", "liveStream": "[{\\"appName\\":\\"testrecord\\",\\"domainName\\":\\"test.alivecdn.com\\",\\"liveUrl\\":\\"rtmp://test.alivecdn.com/testrecord/teststream\\",\\"streamName\\":\\"teststream\\"}]", "editingProject": "*****9b145c5cafc2e057304fcd*****"}', position='Query'),
  projectId: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='*****b2101cb318c*****', position='Query'),
}

model AddEditingProjectMaterialsResponseBody = {
  liveMaterials?: [ 
    {
      appName?: string(name='AppName', description='The application name of the live stream.', example='testrecord'),
      domainName?: string(name='DomainName', description='The domain name of the live stream.', example='test.alivecdn.com'),
      liveUrl?: string(name='LiveUrl', description='The URL of the live stream.', example='rtmp://test.alivecdn.com/testrecord/teststream'),
      streamName?: string(name='StreamName', description='The name of the live stream.', example='teststream'),
    }
  ](name='LiveMaterials', description='The materials associated with the live stream.'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
            duration?: string(name='Duration', description='The duration.', example='216.206667'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
            fileStatus?: string(name='FileStatus', description='The file status.

\\-Uploading

\\-Normal

\\-UploadFail

\\-Disable

\\-Deleted', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='540'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='960'),
          }(name='FileBasicInfo', description='The basic information of the file, including the duration and size.'),
        }
      ](name='FileInfoList', description='FileInfos'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.', example='audio'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-23T03:32:59Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-23T03:32:59Z'),
        description?: string(name='Description', description='The description of the media asset.', example='sample_description'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/file.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****5cb2e35433198daae94a72*****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='sample_tag'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='Video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-23T03:32:59Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='null'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite of the media asset.', example='http://outin-example.oss-cn-shanghai.aliyuncs.com/test.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        status?: string(name='Status', description='The status of the media asset. Valid values:

\\- Init

\\- Preparing

\\- PrepareFail

\\- Normal', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.', example='default_title_2020-12-23T03:32:59Z'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information of the media assets.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****5cb2e35433198daae94a72*****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='*****67ae06542b9b93e0d1c387*****'),
  projectMaterials?: [ string ](name='ProjectMaterials', description='The materials associated with the editing project. A live stream editing project will be associated with a regular editing project after the live streaming ends.', example='*****9b145c5cafc2e057304fcd*****'),
  requestId?: string(name='RequestId', description='The request ID.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
}

model AddEditingProjectMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddEditingProjectMaterialsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AddEditingProjectMaterials  AddEditingProjectMaterialsRequest
  * @return AddEditingProjectMaterialsResponse
 */
async function addEditingProjectMaterials(request: AddEditingProjectMaterialsRequest): AddEditingProjectMaterialsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddEditingProjectMaterials', 'POST', '/', 'json', false, 'json', request);
}

model AddFavoritePublicMediaRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaIds?: string(name='MediaIds', example='icepublic-****7213c6050cbc66750b469701****,icepublic-****0b4697017213c6050cbc6675****', position='Query'),
}

model AddFavoritePublicMediaResponseBody = {
  ignoredList?: [ string ](name='IgnoredList'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model AddFavoritePublicMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddFavoritePublicMediaResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AddFavoritePublicMedia  AddFavoritePublicMediaRequest
  * @return AddFavoritePublicMediaResponse
 */
async function addFavoritePublicMedia(request: AddFavoritePublicMediaRequest): AddFavoritePublicMediaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddFavoritePublicMedia', 'POST', '/', 'json', false, 'json', request);
}

model AddMediaConnectFlowInputRequest {
  cidrs?: string(name='Cidrs', description='The IP address whitelist in CIDR format. Separate multiple CIDR blocks with commas (,).', example='19.168.1.1/32,18.168.1.1/16', position='Query'),
  flowId: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f', position='Query'),
  inputFromUrl?: string(name='InputFromUrl', description='The source URL. This parameter is required when the source type is RTMP-PULL or SRT-Listener.', example='rtmp://pull.test.alivecdn.com/live/alitest', position='Query'),
  inputName: string(name='InputName', description='The source name.

This parameter is required.', example='AliTestInput', position='Query'),
  inputProtocol: string(name='InputProtocol', description='The source type.

Valid values:

*   RTMP-PUSH
*   SRT-Caller
*   RTMP-PULL
*   SRT-Listener
*   Flow

This parameter is required.', example='RTMP-PUSH', position='Query'),
  maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s.', example='2000000', position='Query'),
  pairFlowId?: string(name='PairFlowId', description='The ID of the source flow. This parameter is required when the source type is Flow.', example='805fbdd0-575e-4146-b35d-ec7f63937b20', position='Query'),
  pairOutputName?: string(name='PairOutputName', description='The output of the source flow. This parameter is required when the source type is Flow.', example='AliTestOutput', position='Query'),
  srtLatency?: int32(name='SrtLatency', description='The latency for the SRT stream. This parameter is required the source type is SRT-Listener or SRT-Caller.', example='1000', position='Query'),
  srtPassphrase?: string(name='SrtPassphrase', description='The SRT key. This parameter is required when the source type is SRT-Listener or SRT-Caller.', example='BETTERG08S01', position='Query'),
  srtPbkeyLen?: string(name='SrtPbkeyLen', description='The encryption key length. This parameter is required when the source type is SRT-Listener or SRT-Caller.

Valid values:

*   0
*   16
*   24
*   32', example='32', position='Query'),
}

model AddMediaConnectFlowInputResponseBody = {
  content?: {
    inputUrl?: string(name='InputUrl', description='The source URL.', example='rtmp://1.2.3.4:1935/live/AliTestInput_8666ec062190f00e263012666319a5be'),
  }(name='Content', description='The response body.'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='11357BE8-4C54-58EA-890A-5AB646EDE4B2'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model AddMediaConnectFlowInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddMediaConnectFlowInputResponseBody(name='body'),
}

/**
  * @description *   When the specified flow ID is not available, an error code is returned.
  * *   A flow can have only one source.
  * ### [](#)Source type
  * *   RTMP-PUSH: An input that you can push to the returned URL over the RTMP protocol.
  * *   RTMP-PULL: An input that the MediaConnect flow pulls from the specified server over the RTMP protocol.
  * *   SRT-Listener: An input that you can push to the returned URL over the SRT protocol.
  * *   SRT-Caller: An input that the MediaConnect flow pulls from the specified server over the SRT protocol.
  * *   Flow: An input that uses the output of another upstream flow. You must specify an upstream flow and its output. The output type of the upstream flow must be SRT-Listener or RTMP-PULL. By default, a dedicated line is used when flows are cascaded. This allows for cross-region distribution among multiple flows.
  * @param request  the request parameters of AddMediaConnectFlowInput  AddMediaConnectFlowInputRequest
  * @return AddMediaConnectFlowInputResponse
 */
async function addMediaConnectFlowInput(request: AddMediaConnectFlowInputRequest): AddMediaConnectFlowInputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddMediaConnectFlowInput', 'POST', '/', 'json', false, 'json', request);
}

model AddMediaConnectFlowOutputRequest {
  cidrs?: string(name='Cidrs', description='The IP address whitelist in CIDR format. Separate multiple CIDR blocks with commas (,).', example='83.17.231.31/32', position='Query'),
  flowId: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f', position='Query'),
  outputName: string(name='OutputName', description='The output name.

This parameter is required.', example='AliTestOutput', position='Query'),
  outputProtocol: string(name='OutputProtocol', description='The output type.

Valid values:

*   RTMP-PUSH
*   SRT-Caller
*   RTMP-PULL
*   SRT-Listener
*   Flow

This parameter is required.', example='RTMP-PULL', position='Query'),
  outputToUrl?: string(name='OutputToUrl', description='The output URL. This parameter is required when OutputProtocol is set to RTMP-PUSH or SRT-Caller.', example='rtmp://push.test.alivecdn.com/live/alitest', position='Query'),
  pairFlowId?: string(name='PairFlowId', description='The ID of the destination flow. This parameter is required when OutputProtocol is set to Flow.', example='8666ec062190f00e263012666319a5be', position='Query'),
  pairInputName?: string(name='PairInputName', description='The source name of the destination flow. This parameter is required when OutputProtocol is set to Flow.', example='AliTestInput', position='Query'),
  playerLimit?: int32(name='PlayerLimit', description='The maximum number of viewers.', example='5', position='Query'),
  srtLatency?: int32(name='SrtLatency', description='The latency for the SRT stream. This parameter is required when the source type is SRT-Listener or SRT-Caller.', example='1000', position='Query'),
  srtPassphrase?: string(name='SrtPassphrase', description='The SRT key. This parameter is required when the source type is SRT-Listener or SRT-Caller.', example='BETTERG08S01', position='Query'),
  srtPbkeyLen?: string(name='SrtPbkeyLen', description='The encryption key length. This parameter is required when the source type is SRT-Listener or SRT-Caller.', example='32', position='Query'),
}

model AddMediaConnectFlowOutputResponseBody = {
  content?: {
    outputUrl?: string(name='OutputUrl', description='The output URL.', example='srt://1.2.3.4:1025'),
  }(name='Content', description='The response body.'),
  description?: string(name='Description', description='The call description.', example='ok'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='11AA9E73-FBA0-58DC-97BA-D606D847BCB6'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates that the call is successful.', example='0'),
}

model AddMediaConnectFlowOutputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddMediaConnectFlowOutputResponseBody(name='body'),
}

/**
  * @description *   When the specified flow ID is not available, an error code is returned.
  * *   A flow can have a maximum of four outputs.
  * *   The output names in the same flow cannot be duplicated.
  * *   You can set an upper limit on the number of concurrent viewers for each output. If this limit is exceeded, any new playback requests will fail. Each output supports up to five streams.
  * ### [](#)Output types
  * *   RTMP-PUSH: An output that the MediaConnect flow pushes to the server you specified over the RTMP protocol.
  * *   RTMP-PULL: An output that you can pull using the returned streaming URL over the RTMP protocol.
  * *   SRT-Caller: An output that the MediaConnect flow pushes to the server you specified over the SRT protocol.
  * *   SRT-Listener: An output that you can pull using the returned streaming URL over the SRT protocol.
  * *   Flow: An output that is pushed to the source URL of another MediaConnect flow. The source type of the destination flow must be SRT-Listener or RTMP-PUSH. By default, a dedicated line is used when flows are cascaded. This allows for cross-region distribution among multiple flows.
  * @param request  the request parameters of AddMediaConnectFlowOutput  AddMediaConnectFlowOutputRequest
  * @return AddMediaConnectFlowOutputResponse
 */
async function addMediaConnectFlowOutput(request: AddMediaConnectFlowOutputRequest): AddMediaConnectFlowOutputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddMediaConnectFlowOutput', 'POST', '/', 'json', false, 'json', request);
}

model AddMediaMarksRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='53afdf003a2171ed9c6a16b5feac6402', position='Query'),
  mediaMarks: string(name='MediaMarks', description='The mark information. The value must be a JSONArray.

This parameter is required.', position='Query'),
}

model AddMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='53afdf003a******6a16b5feac6402'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The IDs of the marks that are added.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
  requestId?: string(name='RequestId', description='The request ID.', example='771A1414-27BF-53E6-AB73-EFCB*****ACF'),
}

model AddMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddMediaMarksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AddMediaMarks  AddMediaMarksRequest
  * @return AddMediaMarksResponse
 */
async function addMediaMarks(request: AddMediaMarksRequest): AddMediaMarksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddMediaMarks', 'POST', '/', 'json', false, 'json', request);
}

model AddStreamTagToSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******', position='Query'),
  msgBody?: string(name='MsgBody', description='The message body.', example='{"startTime":1657684600793,"endTime":1657684600793,"userData":"{}"}', position='Query'),
  namespace?: string(name='Namespace', description='The namespace.', example='name-1', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='Stream_xxx', position='Query'),
}

model AddStreamTagToSearchLibResponseBody = {
  code?: string(name='Code', description='The return code.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='Id of the request', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  success?: string(name='Success', description='Indicates whether the request is successful. Default value: true. Valid values:

*   true
*   false', example='true'),
}

model AddStreamTagToSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddStreamTagToSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AddStreamTagToSearchLib  AddStreamTagToSearchLibRequest
  * @return AddStreamTagToSearchLibResponse
 */
async function addStreamTagToSearchLib(request: AddStreamTagToSearchLibRequest): AddStreamTagToSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddStreamTagToSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model AddTemplateRequest {
  config?: string(name='Config', example='参见Timeline模板Config文档', position='Body'),
  coverUrl?: string(name='CoverUrl', description='The URL of the template thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg', position='Query'),
  name?: string(name='Name', description='The name of the custom template.', example='视频添加水印模板', position='Query'),
  previewMedia?: string(name='PreviewMedia', description='The ID of the template preview video.', example='****01bf24bf41c78b2754cb3187****', position='Query'),
  relatedMediaids?: string(name='RelatedMediaids', description='The IDs of the materials associated with the template for use by the regular template editor.', example='{"video":["1805a0c6ca544fb395a06ca683619655"]}', position='Query'),
  source?: string(name='Source', description='The source from which the template is created. Valid values:

*   OpenAPI
*   AliyunConsole
*   WebSDK

<!---->', example='OpenAPI', position='Query'),
  status?: string(name='Status', description='The template state. Valid values:

*   Available: The template is available.
*   Created: The template is created but not ready for use.
*   Uploading: The video is being uploaded.
*   Processing: The advanced template is being processed.
*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.

<!---->', example='Available', position='Query'),
  type?: string(name='Type', description='The template type. Valid values:

*   Timeline: a regular template created based on the timeline of a video editing project, in which multiple materials are arranged in sequence across multiple layers. It can be used to convert text and images into videos, create photo albums, add opening and closing parts, and apply the default watermark.
*   VETemplate: an advanced template created using effects of Adobe After Effects (AE). It can be used to produce complex animations and advanced media effects.

<!---->', example='Timeline', position='Query'),
}

model AddTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
  template?: {
    config?: string(name='Config', description='The template configurations.', example='参见Timeline模板Config文档'),
    coverUrl?: string(name='CoverUrl', description='The URL of the template thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
    createSource?: string(name='CreateSource', description='The source from which the template was created.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
    modifiedSource?: string(name='ModifiedSource', description='The source from which the template was modified.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
    name?: string(name='Name', description='The template name.', example='视频添加水印模板'),
    previewMedia?: string(name='PreviewMedia', description='The ID of the preview video.', example='****01bf24bf41c78b2754cb3187****'),
    status?: string(name='Status', description='The template state.

Valid values:

*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.
*   Available: The template is available.
*   Uploading: The video is being uploaded.
*   Created: The template is created but not ready for use.
*   Processing: The advanced template is being processed.', example='Available'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****01bf24bf41c78b2754cb3187****'),
    type?: string(name='Type', description='The template type.

Valid values:

*   Timeline: regular template.
*   VETemplate: advanced template.', example='Timeline'),
  }(name='Template', description='The template information.'),
}

model AddTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddTemplateResponseBody(name='body'),
}

/**
  * @description *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
  * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
  * *   After an advanced template is created, it enters the Processing state. In this case, the template is unavailable. The template can be used only when it is in the Available state. The time required for template processing varies based on the size of the template file. Generally, it ranges from 10 seconds to 5 minutes.
  * @param request  the request parameters of AddTemplate  AddTemplateRequest
  * @return AddTemplateResponse
 */
async function addTemplate(request: AddTemplateRequest): AddTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddTemplate', 'POST', '/', 'json', true, 'form', request);
}

model AlterSearchIndexRequest {
  regionId?: string(name='RegionId', position='Host'),
  indexConfig?: string(name='IndexConfig', description='The configurations of the index.

>  You must specify either IndexStatus or IndexConfig.', example='{}', position='Query'),
  indexStatus?: string(name='IndexStatus', description='The state of the index. Valid values:

*   active (default): the index is enabled.
*   Deactive: the index is not enabled.

>  You must specify either IndexStatus or IndexConfig.', example='Active', position='Query'),
  indexType: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.

This parameter is required.', example='mm', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

*   If you leave this parameter empty, the search index is created in the default search library of Intelligent Media Service (IMS). Default value: ims-default-search-lib.
*   To query information about an existing search library, call the [QuerySearchLib](https://help.aliyun.com/document_detail/2584455.html) API operation.', example='test1', position='Query'),
}

model AlterSearchIndexResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model AlterSearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AlterSearchIndexResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AlterSearchIndex  AlterSearchIndexRequest
  * @return AlterSearchIndexResponse
 */
async function alterSearchIndex(request: AlterSearchIndexRequest): AlterSearchIndexResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AlterSearchIndex', 'POST', '/', 'json', false, 'json', request);
}

model BatchCreateVodPackagingAssetRequest {
  assets?: [ 
    {
      assetName?: string(name='AssetName', description='The name of the asset. The name must be unique and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='30min_movie'),
      contentId?: string(name='ContentId', description='The content ID in the digital rights management (DRM) system. The maximum length is 256 characters. Letters, digits, underscores (_), and hyphens (-) are supported.', example='movie'),
      input?: {
        media?: string(name='Media', description='The URL of the media file. You can only specify a M3U8 file stored in Object Storage Service (OSS).'),
        type?: string(name='Type', description='The input type. Only OSS is supported.', example='OSS'),
      }(name='Input', description='The asset input configurations.'),
    }
  ](name='Assets', description='The assets that you want to ingest.', shrink='json', position='Query'),
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls', position='Query'),
}

model BatchCreateVodPackagingAssetResponseBody = {
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
  resultList?: [ 
    {
      asset?: VodPackagingAsset(name='Asset', description='The information about the ingested asset.'),
      code?: string(name='Code', description='The error code for failed ingestion.', example='InvalidParameter.PackagingAssetAlreadyExists'),
      message?: string(name='Message', description='The error message for failed ingestion.', example='The specified packagingAsset "inputMovie" already exists'),
    }
  ](name='ResultList', description='The results of asset ingestion.'),
}

model BatchCreateVodPackagingAssetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: BatchCreateVodPackagingAssetResponseBody(name='body'),
}

/**
  * @param request  the request parameters of BatchCreateVodPackagingAsset  BatchCreateVodPackagingAssetRequest
  * @return BatchCreateVodPackagingAssetResponse
 */
async function batchCreateVodPackagingAsset(request: BatchCreateVodPackagingAssetRequest): BatchCreateVodPackagingAssetResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'BatchCreateVodPackagingAsset', 'POST', '/', 'json', false, 'json', request);
}

model BatchGetMediaInfosRequest {
  regionId?: string(name='RegionId', position='Host'),
  additionType?: string(name='AdditionType', description='The additional information that you want to query about the media assets. By default, only BasicInfo is returned. The following additional information can be queried:

\\- FileInfo

\\- DynamicMetaData', example='FileInfo,DynamicMetaData', position='Query'),
  authTimeout?: long(name='AuthTimeout', position='Query'),
  mediaIds?: string(name='MediaIds', description='The IDs of the media assets that you want to query. Separate the IDs with commas (,).', example='******b48fb04483915d4f2cd8******,******c48fb37407365d4f2cd8******', position='Query'),
}

model BatchGetMediaInfosResponseBody = {
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
            duration?: string(name='Duration', description='The duration.', example='200'),
            fileName?: string(name='FileName', description='The file name.', example='example'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='1080'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='1920'),
          }(name='FileBasicInfo', description='The basic information of the file, including the duration and size.'),
        }
      ](name='FileInfoList', description='FileInfos'),
      mediaBasicInfo?: {
        biz?: string(name='Biz'),
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-26T04:11:10Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-26T04:11:10Z'),
        description?: string(name='Description', description='The description of the media asset.'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        mediaId?: string(name='MediaId', description='MediaId', example='******c48fb37407365d4f2cd8******'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.'),
        mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

\\- image

\\- video

\\- audio

\\- text', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-26T04:11:12Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='[{"bucket":"example-bucket","count":"3","iceJobId":"******f48f0e4154976b2b8c45******","location":"oss-cn-beijing","snapshotRegular":"example.jpg","templateId":"******e6a6440b29eb60bd7c******"}]'),
        source?: string(name='Source', description='The source of the media asset. Valid values:

\\- oss

\\- vod', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite.', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userDataTest'),
      }(name='MediaBasicInfo', description='The basic information of the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******c48fb37407365d4f2cd8******'),
    }
  ](name='MediaInfos', description='The queried media assets.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model BatchGetMediaInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: BatchGetMediaInfosResponseBody(name='body'),
}

/**
  * @param request  the request parameters of BatchGetMediaInfos  BatchGetMediaInfosRequest
  * @return BatchGetMediaInfosResponse
 */
async function batchGetMediaInfos(request: BatchGetMediaInfosRequest): BatchGetMediaInfosResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'BatchGetMediaInfos', 'POST', '/', 'json', false, 'json', request);
}

model CancelDNAJobRequest {
  jobId: string(name='JobId', description='The ID of the media fingerprint analysis job that you want to cancel.

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model CancelDNAJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='2288c6ca184c0e47098a5b665e2a12****'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model CancelDNAJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CancelDNAJobResponseBody(name='body'),
}

/**
  * @description *   You can cancel a media fingerprint analysis job only if the job is in the Queuing state.
  * *   We recommend that you call the **UpdatePipeline** operation to set the status of the ApsaraVideo Media Processing (MPS) queue to Paused before you cancel a job. This suspends job scheduling in the MPS queue. After the job is canceled, you must set the status of the MPS queue back to Active so that the other jobs in the MPS queue can be scheduled.
  * @param request  the request parameters of CancelDNAJob  CancelDNAJobRequest
  * @return CancelDNAJobResponse
 */
async function cancelDNAJob(request: CancelDNAJobRequest): CancelDNAJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CancelDNAJob', 'POST', '/', 'json', false, 'json', request);
}

model CancelFavoritePublicMediaRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaIds?: string(name='MediaIds', example='icepublic-****7213c6050cbc66750b469701****,icepublic-****0b4697017213c6050cbc6675****', position='Query'),
}

model CancelFavoritePublicMediaResponseBody = {
  ignoredList?: [ string ](name='IgnoredList'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model CancelFavoritePublicMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CancelFavoritePublicMediaResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CancelFavoritePublicMedia  CancelFavoritePublicMediaRequest
  * @return CancelFavoritePublicMediaResponse
 */
async function cancelFavoritePublicMedia(request: CancelFavoritePublicMediaRequest): CancelFavoritePublicMediaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CancelFavoritePublicMedia', 'POST', '/', 'json', false, 'json', request);
}

model CancelIProductionJobRequest {
  clientToken?: string(name='ClientToken', example='****12e8864746a0a398****', position='Query'),
  jobId: string(name='JobId', description='The ID of the intelligent production job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model CancelIProductionJobResponseBody = {
  accessDeniedDetail?: {
    authAction?: string(name='AuthAction', description='The operation that failed the permission check.', example='ice:CancelIProductionJob'),
    authPrincipalDisplayName?: string(name='AuthPrincipalDisplayName', description='The identity. Values:

*   RAM user: a UID
*   RAM role: RoleName:RoleSessionName
*   Federated user: ProviderType/ProviderName', example='****4522705967****'),
    authPrincipalOwnerId?: string(name='AuthPrincipalOwnerId', description='The account to which the principal belongs.', example='****82303720****'),
    authPrincipalType?: string(name='AuthPrincipalType', description='The type of identity that made the request. Valid values:

*   SubUser: RAM user
*   AssumedRoleUser: RAM role
*   Federated: SSO federated user', example='SubUser'),
    encodedDiagnosticMessage?: string(name='EncodedDiagnosticMessage', description='The encoded diagnostic message.', example='******AAZ/h8jzNEODc5QUUyLUZCOTAtNUQyQy1BMEFBLUUzODQxODUx******=='),
    noPermissionType?: string(name='NoPermissionType', description='The type of policy that resulted in the denial. Valid values:

*   **ImplicitDeny**: The resource holder has not configured a policy for the current user. By default, unauthorized operations are denied.
*   **ExplicitDeny**: The RAM policy configured by the resource holder explicitly denies the current user access to the corresponding resources.', example='ImplicitDeny'),
    policyType?: string(name='PolicyType', description='The type of policy that triggered the permission failure.

*   **ControlPolicy**: control policy
*   **SessionPolicy**: an additional policy attached to a temporary token.
*   **AssumeRolePolicy**: the trust policy of a RAM role.
*   **AccountLevelIdentityBasedPolicy**: an identity-based policy at the account level (custom or system).
*   **ResourceGroupLevelIdentityBasedPolicy**: an identity-based policy scoped to a resource group.', example='AssumeRolePolicy'),
  }(name='AccessDeniedDetail', description='The details about the access denial. This parameter is returned only if Resource Access Management (RAM) permission verification failed.'),
  message?: string(name='Message', description='The message returned.', example='Success'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CancelIProductionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CancelIProductionJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CancelIProductionJob  CancelIProductionJobRequest
  * @return CancelIProductionJobResponse
 */
async function cancelIProductionJob(request: CancelIProductionJobRequest): CancelIProductionJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CancelIProductionJob', 'POST', '/', 'json', false, 'json', request);
}

model ClearAIAgentVoiceprintRequest {
  voiceprintId?: string(name='VoiceprintId', description='The unique identifier for the voiceprint.', example='vp_1699123456_8527', position='Query'),
}

model ClearAIAgentVoiceprintResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ClearAIAgentVoiceprintResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ClearAIAgentVoiceprintResponseBody(name='body'),
}

/**
  * @description ## [](#)
  * ``````````
  * @param request  the request parameters of ClearAIAgentVoiceprint  ClearAIAgentVoiceprintRequest
  * @return ClearAIAgentVoiceprintResponse
 */
async function clearAIAgentVoiceprint(request: ClearAIAgentVoiceprintRequest): ClearAIAgentVoiceprintResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ClearAIAgentVoiceprint', 'POST', '/', 'json', false, 'json', request);
}

model CloseMediaConnectFlowFailoverRequest {
  flowId?: string(name='FlowId', description='The ID of the MediaConnect flow.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f', position='Query'),
}

model CloseMediaConnectFlowFailoverResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='391DDF25-705C-5B38-9DB9-7A6B00D6065A'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model CloseMediaConnectFlowFailoverResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CloseMediaConnectFlowFailoverResponseBody(name='body'),
}

/**
  * @description *   If a flow has two sources, you cannot disable Source Failover. Delete one of them before this operation.
  * @param request  the request parameters of CloseMediaConnectFlowFailover  CloseMediaConnectFlowFailoverRequest
  * @return CloseMediaConnectFlowFailoverResponse
 */
async function closeMediaConnectFlowFailover(request: CloseMediaConnectFlowFailoverRequest): CloseMediaConnectFlowFailoverResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CloseMediaConnectFlowFailover', 'POST', '/', 'json', false, 'json', request);
}

model CloseStreamToSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  namespace?: string(name='Namespace', description='The namespace.', example='name-1', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='Stream_xxx', position='Query'),
}

model CloseStreamToSearchLibResponseBody = {
  code?: string(name='Code', description='The return code.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****c469e944b5a856828dc2****'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request is successful. Valid values:

*   true
*   false', example='true'),
}

model CloseStreamToSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CloseStreamToSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CloseStreamToSearchLib  CloseStreamToSearchLibRequest
  * @return CloseStreamToSearchLibResponse
 */
async function closeStreamToSearchLib(request: CloseStreamToSearchLibRequest): CloseStreamToSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CloseStreamToSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model CreateAuditRequest {
  regionId?: string(name='RegionId', position='Host'),
  auditContent: string(name='AuditContent', description='The review results. You can specify the results for a maximum of 20 videos at a time. The value must be converted to a string. For more information about the parameters in AuditContent, see the "AuditContent" section of this topic.

This parameter is required.', example='[
      {
            "MediaId": "93ab850b4f*****b54b6e91d24d81d4",
            "Status": "Normal"
      },
      {
            "MediaId": "f867fbfb58*****8bbab65c4480ae1d",
            "Status": "Blocked",
            "Reason": "xxxx",
            "Comment": "xxxx"
      }
]', position='Query'),
}

model CreateAuditResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateAuditResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateAuditResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateAudit  CreateAuditRequest
  * @return CreateAuditResponse
 */
async function createAudit(request: CreateAuditRequest): CreateAuditResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateAudit', 'POST', '/', 'json', false, 'json', request);
}

model CreateAvatarTrainingJobRequest {
  avatarDescription?: string(name='AvatarDescription', description='*   The description of the digital human.
*   The description can be up to 1,000 characters in length.', maxLength=1027, position='Query'),
  avatarName: string(name='AvatarName', description='*   The name of the digital human.
*   The name can be up to seven characters in length.

This parameter is required.', maxLength=7, position='Query'),
  avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar', position='Query'),
  portrait?: string(name='Portrait', description='*   The media asset ID of the portrait image.
*   The value must be 32 characters in length.', example='****571c704445f9a0ee011406c2****', minLength=32, maxLength=32, position='Query'),
  thumbnail?: string(name='Thumbnail', description='*   The thumbnail URL.
*   After the digital human is trained, the thumbnail is uploaded to this URL.
*   The URL must be a valid public Object Storage Service (OSS) URL.
*   The URL can be up to 512 characters in length.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png', maxLength=512, position='Query'),
  transparent?: boolean(name='Transparent', description='*   Specifies whether the training video supports alpha channels.

    **

    **Note**: Make sure that the current settings are consistent with those of the submitted training video. Otherwise, the digital human may malfunction.', example='True', position='Query'),
  video?: string(name='Video', description='*   The ID of the video used for training.
*   The value must be 32 characters in length.
*   Supported formats: MP4, MOV, and WebM.
*   The duration of the video must be 5 to 15 minutes.
*   The resolution of the video must be 1920×1080 or 1080×1920.', example='****571c704445f9a0ee011406c2****', minLength=32, maxLength=32, position='Query'),
}

model CreateAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateAvatarTrainingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateAvatarTrainingJob  CreateAvatarTrainingJobRequest
  * @return CreateAvatarTrainingJobResponse
 */
async function createAvatarTrainingJob(request: CreateAvatarTrainingJobRequest): CreateAvatarTrainingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateAvatarTrainingJob', 'POST', '/', 'json', false, 'json', request);
}

model CreateChannelRequest {
  accessPolicy?: boolean(name='AccessPolicy', description='Specifies whether to enable access control.', example='false', position='Query'),
  accessToken?: string(name='AccessToken', description='The token for accessing the channel.', example='xxxxx', position='Query'),
  channelName: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel', position='Query'),
  channelTier: string(name='ChannelTier', description='The tier of the channel. Valid values: basic and standard.

This parameter is required.', example='basic', position='Query'),
  fillerSourceLocationName?: string(name='FillerSourceLocationName', description='The source location of the filler slate.', example='MySourceLocation', position='Query'),
  fillerSourceName?: string(name='FillerSourceName', description='The name of the filler slate.', example='FillerSource', position='Query'),
  outPutConfigList: string(name='OutPutConfigList', description='The channel output configurations.

This parameter is required.', example='[{
	"ManifestName": "manifest-1",
	"Format": "HLS",
	"SourceGroupName": "source-group-1",
	"ManifestSettings": {
		"WindowDuration": 60,
		"AdMarkType": "Daterange"
	}
}]', position='Query'),
  playbackMode: string(name='PlaybackMode', description='The playback mode. Valid values: loop and linear.

This parameter is required.', example='loop', position='Query'),
}

model CreateChannelResponseBody = {
  channel?: ChannelAssemblyChannel(name='Channel', description='The channel information.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
}

model CreateChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateChannelResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateChannel  CreateChannelRequest
  * @return CreateChannelResponse
 */
async function createChannel(request: CreateChannelRequest): CreateChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateChannel', 'POST', '/', 'json', false, 'json', request);
}

model CreateCustomTemplateRequest {
  name: string(name='Name', description='The template name.

This parameter is required.', example='test-template', position='Query'),
  subtype?: int32(name='Subtype', description='The template subtype.

Valid values for transcoding templates:

*   1 (Normal): regular template.
*   2 (AudioTranscode): audio transcoding template.
*   3 (Remux): container format conversion template.
*   4 (NarrowBandV1): Narrowband HD 1.0 template.
*   5 (NarrowBandV2): Narrowband HD 2.0 template.

Valid values for snapshot templates:

*   1 (Normal): regular template.
*   2 (Sprite): sprite template.
*   3 (WebVtt): WebVTT template.

Valid values for AI-assisted content moderation templates:

*   1 (Video): video moderation template.
*   2 (Audio): audio moderation template.
*   3 (Image): image moderation template.

Valid values for AI-assisted intelligent erasure templates.

*   1 (VideoDelogo): logo erasure template.
*   2 (VideoDetext): subtitle erasure template.', example='1', position='Query'),
  templateConfig: string(name='TemplateConfig', description='The template configurations. For more information, see [Template parameters](https://help.aliyun.com/document_detail/448291.html).

This parameter is required.', example='{"Container":{"Format":"flv"},"Video":{},"Audio":{}}', position='Query'),
  type: int32(name='Type', description='The template type. Valid values:

*   1: transcoding template.
*   2: snapshot template.
*   3: animated image template.
*   4\\. image watermark template.
*   5: text watermark template.
*   6: subtitle template.
*   7: AI-assisted content moderation template.
*   8: AI-assisted intelligent thumbnail template.
*   9: AI-assisted intelligent erasure template.
*   10: AI-assisted media fingerprint analysis template.
*   11: AI-assisted smart tagging template.

This parameter is required.', example='1', position='Query'),
}

model CreateCustomTemplateResponseBody = {
  customTemplate?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-04-19T02:04:31Z'),
    isDefault?: boolean(name='IsDefault', description='Indicates whether the template is the default template.', example='true'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-04-19T02:04:31Z'),
    status?: string(name='Status', description='The template state.', example='Normal'),
    subtype?: string(name='Subtype', description='The subtype name of the template.', example='Remux'),
    templateConfig?: string(name='TemplateConfig', description='The template configurations.', example='{"Container":{"Format":"flv"},"Video":{},"Audio":{}}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
    templateName?: string(name='TemplateName', description='The template name.', example='test-template'),
    type?: int32(name='Type', description='The type ID of the template.', example='1'),
    typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
  }(name='CustomTemplate', description='The template information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateCustomTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateCustomTemplate  CreateCustomTemplateRequest
  * @return CreateCustomTemplateResponse
 */
async function createCustomTemplate(request: CreateCustomTemplateRequest): CreateCustomTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateCustomTemplate', 'POST', '/', 'json', false, 'json', request);
}

model CreateCustomizedVoiceJobRequest {
  gender: string(name='Gender', description='The gender. Valid values:

*   female
*   male

This parameter is required.', example='female', position='Query'),
  scenario: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation

This parameter is required.', example='story', position='Query'),
  voiceDesc?: string(name='VoiceDesc', description='The voice description.

*   The description can be up to 256 characters in length.', maxLength=256, position='Query'),
  voiceId: string(name='VoiceId', description='The voice ID. It can be the English name or Chinese Pinyin of the voice.

*   The value must be a unique ID that is not used by other custom voices.
*   The ID can be up to 32 characters in length.
*   Only letters and digits are supported.

This parameter is required.', example='xiaozhuan', maxLength=32, position='Query'),
  voiceName?: string(name='VoiceName', description='The voice name.

*   The name can be up to 32 characters in length.', maxLength=32, position='Query'),
}

model CreateCustomizedVoiceJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****29faef8144638ba42eb8e037****'),
    voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
}

model CreateCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateCustomizedVoiceJob  CreateCustomizedVoiceJobRequest
  * @return CreateCustomizedVoiceJobResponse
 */
async function createCustomizedVoiceJob(request: CreateCustomizedVoiceJobRequest): CreateCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model CreateDNADBRequest {
  description?: string(name='Description', description='The description of the media fingerprint library.', position='Query'),
  model?: string(name='Model', description='The model of the media fingerprint library. Valid values:

*   **Video**
*   **Audio**
*   **Image**
*   **Text** (supported only in the China (Shanghai) region)', example='Video', position='Query'),
  name: string(name='Name', description='The name of the media fingerprint library.

This parameter is required.', example='example name', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model CreateDNADBResponseBody = {
  DBInfo?: {
    DBId?: string(name='DBId', description='The ID of the media fingerprint library. We recommend that you save this ID for subsequent calls of other operations.', example='88c6ca184c0e47098a5b665e2a12****'),
    description?: string(name='Description', description='The description of the media fingerprint library.'),
    model?: string(name='Model', description='The model of the media fingerprint library.', example='Video'),
    name?: string(name='Name', description='The name of the media fingerprint library.', example='example name'),
    status?: string(name='Status', description='The state of the media fingerprint library. After a media fingerprint library is created, it enters the offline state. After the media fingerprint library is processed at the backend, it enters the active state.', example='offline'),
  }(name='DBInfo', description='The details of the media fingerprint library.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model CreateDNADBResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDNADBResponseBody(name='body'),
}

/**
  * @description *   You can create up to five media fingerprint libraries within an account. To increase the quota, submit a ticket. You can call the DeleteDNADB operation to delete the fingerprint libraries that you no longer need.
  * @param request  the request parameters of CreateDNADB  CreateDNADBRequest
  * @return CreateDNADBResponse
 */
async function createDNADB(request: CreateDNADBRequest): CreateDNADBResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDNADB', 'POST', '/', 'json', false, 'json', request);
}

model CreateEditingProjectRequest {
  businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.

For a live stream editing project, observe the following rules: OutputMediaConfig.StorageLocation is required. OutputMediaConfig.Path is optional. If you do not specify this option, the live streaming clips are stored in the root directory by default.

Valid values of OutputMediaTarget include vod-media and oss-object. If you do not specify OutputMediaTarget, the default value oss-object is used.

If you set OutputMediaTarget to vod-media, the setting of OutputMediaConfig.Path does not take effect.', example='{ "OutputMediaConfig" : { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path" }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }', position='Query'),
  clipsParam?: string(name='ClipsParam', description='The material parameter corresponding to the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified. For more information<props="china">, see [Create and use a regular template](https://help.aliyun.com/document_detail/328557.html) and [Create and use an advanced template](https://help.aliyun.com/document_detail/291418.html).', position='Query'),
  coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='https://example.com/example.png', position='Query'),
  description?: string(name='Description', description='The description of the online editing project.', example='描述', position='Query'),
  materialMaps?: string(name='MaterialMaps', description='The material associated with the project. Separate multiple material IDs with commas (,). Each type supports up to 10 material IDs.', example='{"video":"*****2e057304fcd9b145c5cafc*****", "image":"****8021a8d493da643c8acd98*****,*****cb6307a4edea614d8b3f3c*****", "liveStream": "[{\\"appName\\":\\"testrecord\\",\\"domainName\\":\\"test.alivecdn.com\\",\\"liveUrl\\":\\"rtmp://test.alivecdn.com/testrecord/teststream\\",\\"streamName\\":\\"teststream\\"}]", "editingProject": "*****9b145c5cafc2e057304fcd*****"}', position='Query'),
  projectType?: string(name='ProjectType', description='The type of the editing project. Valid values: EditingProject and LiveEditingProject. A value of EditingProject indicates a regular editing project, and a value of LiveEditingProject indicates a live stream editing project.', example='LiveEditingProject', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID. This parameter is used to quickly build a timeline with ease. Note: Only one of Timeline and TemplateId can be specified. If TemplateId is specified, ClipsParam must also be specified.', example='****96e8864746a0b6f3****', position='Query'),
  templateType?: string(name='TemplateType', description='The template type. This parameter is required if you create a template-based online editing project. Default value: Timeline. Valid values:

*   Timeline: a regular template.
*   VETemplate: an advanced template.', example='Timeline', position='Query'),
  timeline?: string(name='Timeline', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}', position='Body'),
  title: string(name='Title', description='The title of the online editing project.

This parameter is required.', example='example', position='Query'),
}

model CreateEditingProjectResponseBody = {
  project?: {
    businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{ "OutputMediaConfig" :    { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path"   }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
    businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

*   Reserving
*   ReservationCanceled
*   BroadCasting
*   LoadingFailed
*   LiveFinished', example='Reserving'),
    clipsParam?: string(name='ClipsParam', description='The template material parameters.'),
    coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
    createSource?: string(name='CreateSource', description='The method for creating the online editing project. Valid values:

\\- OpenAPI

\\- AliyunConsole

\\- WebSDK

\\- LiveEditingOpenAPI

\\- LiveEditingConsole', example='WebSDK'),
    createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2021-01-08T16:52:07Z'),
    description?: string(name='Description', description='The description of the online editing project.', example='example_description'),
    duration?: float(name='Duration', description='The duration of the online editing project.', example='3.4200000'),
    modifiedSource?: string(name='ModifiedSource', description='The method for editing the online editing project. Valid values:

\\- OpenAPI

\\- AliyunConsole

\\- WebSDK

\\- LiveEditingOpenAPI

\\- LiveEditingConsole', example='WebSDK'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last edited.', example='2021-01-08T16:52:07Z'),
    projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****01bf24bf41c78b2754cb3187****'),
    projectType?: string(name='ProjectType', description='The type of the editing project. Default value: EditingProject. Valid values:

\\- EditingProject: a regular editing project.

\\- LiveEditingProject: a live stream editing project.', example='LiveEditingProject'),
    status?: long(name='Status', description='The status of the online editing project.

Valid values:

\\- 1: Draft

\\- 2: Editing

\\- 3: Producing

\\- 4: Produced

\\- 5: ProduceFailed

\\- 7: Deleted', example='2'),
    statusName?: string(name='StatusName', description='The status of the online editing project. For more information, see the status list.', example='Editing'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
    templateType?: string(name='TemplateType', description='The template type of the online editing project. Valid values:

\\- Timeline

\\- VETemplate', example='Timeline'),
    timeline?: string(name='Timeline', description='The timeline of the online editing project, in the JSON format.<props="china">For more information about objects in a timeline, see [Timeline configurations](https://help.aliyun.com/document_detail/198823.htm?spm=a2c4g.11186623.2.9.90dc653dF67srN#topic-2024662).  If you leave this parameter empty, an empty timeline is created and the duration of the online editing project is zero.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
    title?: string(name='Title', description='The title of the online editing project.', example='example_title'),
  }(name='Project', description='The information about the online editing project.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model CreateEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateEditingProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateEditingProject  CreateEditingProjectRequest
  * @return CreateEditingProjectResponse
 */
async function createEditingProject(request: CreateEditingProjectRequest): CreateEditingProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateEditingProject', 'POST', '/', 'json', true, 'form', request);
}

model CreateHotwordLibraryRequest {
  description?: string(name='Description', description='The description of the hotword library. It can be up to 200 characters in length.', example='存放名人的词库', position='Query'),
  hotwords: [
    Hotword
  ](name='Hotwords', description='The hotword list. You can add up to 300 hotword entries to a single library.

This parameter is required.', shrink='json', position='Query'),
  name: string(name='Name', description='The name of the hotword library. It can be up to 100 characters in length.

This parameter is required.', example='my_hotwords', position='Query'),
  usageScenario: string(name='UsageScenario', description='The usage scenario of the hotword library. Valid values:

· ASR: Automatic Speech Recognition

· StructuredMediaAssets: structured media analysis

· VideoTranslation: Video translation.

This field cannot be modified after the hotword library is created.

This parameter is required.', example='ASR', position='Query'),
}

model CreateHotwordLibraryResponseBody = {
  hotwordLibraryId?: string(name='HotwordLibraryId', description='The ID of the hotword library.', example='****96e8864746a0b6f3****'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='13cbb83e-043c-4728-ac35-*****'),
}

model CreateHotwordLibraryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateHotwordLibraryResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateHotwordLibrary  CreateHotwordLibraryRequest
  * @return CreateHotwordLibraryResponse
 */
async function createHotwordLibrary(request: CreateHotwordLibraryRequest): CreateHotwordLibraryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateHotwordLibrary', 'POST', '/', 'json', false, 'json', request);
}

model CreateLivePackageChannelRequest {
  channelName: string(name='ChannelName', description='The channel name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='channel-1', position='Body'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****', position='Query'),
  description?: string(name='Description', description='The channel description. It can be up to 1,000 characters in length.', position='Body'),
  groupName: string(name='GroupName', description='The channel group name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='channel-group-1', position='Body'),
  protocol: string(name='Protocol', description='The ingest protocol. Only HLS is supported.

This parameter is required.', example='HLS', position='Body'),
  segmentCount: int32(name='SegmentCount', description='The number of M3U8 segments. Valid values: 2 to 100.

This parameter is required.', example='3', position='Body'),
  segmentDuration: int32(name='SegmentDuration', description='The segment duration. Valid values: 1 to 30.

This parameter is required.', example='6', position='Body'),
}

model CreateLivePackageChannelResponseBody = {
  livePackageChannel?: {
    channelName?: string(name='ChannelName', description='The channel name.', example='example-channel'),
    createTime?: string(name='CreateTime', description='The time when the channel was created. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The channel description.'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    ingestEndpoints?: [ 
      {
        id?: string(name='Id', description='The ingest endpoint ID.', example='ingest1'),
        password?: string(name='Password', description='The password.', example='2F9e******b569c8'),
        url?: string(name='Url', description='The ingest endpoint URL.', example='http://xxx-1.packagepush-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
        username?: string(name='Username', description='The username.', example='us12******das'),
      }
    ](name='IngestEndpoints', description='The ingest endpoints.'),
    lastModified?: string(name='LastModified', description='The time when the channel was last modified. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    protocol?: string(name='Protocol', description='The ingest protocol. Only HLS is supported.', example='HLS'),
    segmentCount?: int32(name='SegmentCount', description='The number of M3U8 segments.', example='3'),
    segmentDuration?: int32(name='SegmentDuration', description='The segment duration.', example='5'),
  }(name='LivePackageChannel', description='The information about the live package channel.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model CreateLivePackageChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLivePackageChannelResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * After you call this operation to create a live package channel, the system will automatically generate the ingest endpoint URL, and username and password required for authentication.
  * ### [](#)Precautions
  * *   Channel group names and channel names can contain only letters, digits, underscores (_), and hyphens (-).
  * *   Only `HLS` is supported.
  * *   The segment duration must be from 1 to 30 seconds.
  * *   The number of M3U8 segments must be from 2 to 100.
  * If the request succeeds, the system will return the details of the newly created channel, including the channel name, creation time, modification time, and ingest endpoint details.
  * @param request  the request parameters of CreateLivePackageChannel  CreateLivePackageChannelRequest
  * @return CreateLivePackageChannelResponse
 */
async function createLivePackageChannel(request: CreateLivePackageChannelRequest): CreateLivePackageChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateLivePackageChannel', 'POST', '/', 'json', true, 'form', request);
}

model CreateLivePackageChannelGroupRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****', position='Query'),
  description?: string(name='Description', description='The channel group description. It can be up to 1,000 characters in length.', position='Query'),
  groupName: string(name='GroupName', description='The channel group name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='channel-group-01', position='Body'),
}

model CreateLivePackageChannelGroupResponseBody = {
  livePackageChannelGroup?: {
    createTime?: string(name='CreateTime', description='The time when the channel group was created. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The channel group description.'),
    groupName?: string(name='GroupName', description='The channel group name.', example='example-group'),
    lastModified?: string(name='LastModified', description='The time when the channel group was last modified. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    originDomain?: string(name='OriginDomain', description='The origin domain.', example='example.com'),
  }(name='LivePackageChannelGroup', description='The information about the channel group.'),
  requestId?: string(name='RequestId', description='The request ID.', example='123e4567-e89b-12d3-a456-426614174000'),
}

model CreateLivePackageChannelGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLivePackageChannelGroupResponseBody(name='body'),
}

/**
  * @description After you create a channel group, the assigned origin domain is returned.
  * @param request  the request parameters of CreateLivePackageChannelGroup  CreateLivePackageChannelGroupRequest
  * @return CreateLivePackageChannelGroupResponse
 */
async function createLivePackageChannelGroup(request: CreateLivePackageChannelGroupRequest): CreateLivePackageChannelGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateLivePackageChannelGroup', 'POST', '/', 'json', true, 'form', request);
}

model CreateLivePackageOriginEndpointRequest {
  authorizationCode?: string(name='AuthorizationCode', description='The authorization code. It can be up to 200 characters in length. You must configure AuthorizationCode, IpWhitelist, or both. Format: [A-Za-z0-9-_.]+', example='AbcDef123', position='Body'),
  channelName: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1', position='Body'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****0311a423d11a5f7dee713535****', position='Query'),
  description?: string(name='Description', description='The endpoint description.', position='Body'),
  endpointName: string(name='EndpointName', description='The origin endpoint name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='endpoint-1', position='Body'),
  groupName: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1', position='Body'),
  ipBlacklist?: string(name='IpBlacklist', description='The IP address blacklist. It supports subnet masks. 0.0.0.0/0 is not allowed. It can be up to 1,000 characters in length. Separate multiple IP addresses with commas (,).', example='103.21.222.1/32,192.168.100.0/24', position='Body'),
  ipWhitelist?: string(name='IpWhitelist', description='The IP address whitelist. It supports subnet masks. 0.0.0.0/0 is not allowed. It can be up to 1,000 characters in length. Separate multiple IP addresses with commas (,). You must configure AuthorizationCode, IpWhitelist, or both.', example='192.168.1.0/24,10.0.0.1/24', position='Body'),
  livePackagingConfig?: LivePackagingConfig(name='LivePackagingConfig', shrink='json', position='Body'),
  manifestName?: string(name='ManifestName', description='The playlist name. Default value: manifest.', example='manifest', position='Body'),
  protocol: string(name='Protocol', description='The distribution protocol.

This parameter is required.', example='HLS', position='Body'),
  timeshiftVision?: int32(name='TimeshiftVision', description='The number of days that time-shifted content is available. Maximum value: 30. Default value: 0, which indicates that time shifting is not supported.', example='1', position='Body'),
}

model CreateLivePackageOriginEndpointResponseBody = {
  livePackageOriginEndpoint?: {
    authorizationCode?: string(name='AuthorizationCode', description='The authorization code.', example='Abcded123'),
    channelName?: string(name='ChannelName', description='The channel name.', example='channel-1'),
    createTime?: string(name='CreateTime', description='The time when the endpoint was created.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The endpoint description.'),
    endpointName?: string(name='EndpointName', description='The endpoint name.', example='endpoint-1'),
    endpointUrl?: string(name='EndpointUrl', description='The endpoint URL.', example='https://xxx.packagepull-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    ipBlacklist?: string(name='IpBlacklist', description='The IP address blacklist.', example='103.21.222.1/32,192.168.100.0/24'),
    ipWhitelist?: string(name='IpWhitelist', description='The IP address whitelist.', example='192.168.1.0/24,10.0.0.1/24'),
    lastModified?: string(name='LastModified', description='The time when the endpoint was last modified.', example='2023-04-01T12:00:00Z'),
    livePackagingConfig?: LivePackagingConfig(name='LivePackagingConfig'),
    manifestName?: string(name='ManifestName', description='The playlist name.', example='manifest'),
    protocol?: string(name='Protocol', description='The protocol. Only HLS is supported.', example='HLS'),
    timeshiftVision?: int32(name='TimeshiftVision', description='The number of days that time-shifted content is available. Maximum value: 30.', example='1'),
  }(name='LivePackageOriginEndpoint', description='The information about the origin endpoint.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateLivePackageOriginEndpointResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLivePackageOriginEndpointResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * This API operation is mainly used to configure origin settings, security policies including the IP address blacklist and whitelist and authorization code, and time shifting settings for channels. Before you create an origin endpoint, you must create a live package channel group and channel. After you create the endpoint, the endpoint URL and other configuration details are returned.
  * @param request  the request parameters of CreateLivePackageOriginEndpoint  CreateLivePackageOriginEndpointRequest
  * @return CreateLivePackageOriginEndpointResponse
 */
async function createLivePackageOriginEndpoint(request: CreateLivePackageOriginEndpointRequest): CreateLivePackageOriginEndpointResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateLivePackageOriginEndpoint', 'POST', '/', 'json', true, 'form', request);
}

model CreateLiveRecordTemplateRequest {
  name: string(name='Name', description='The name of the template.

This parameter is required.', position='Body'),
  recordFormat: [ 
    {
      cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds. If you do not specify this parameter, the default value 6 hours is used.

> 

*   If a live stream is interrupted during a recording cycle but is resumed within 3 minutes, the stream is recorded in the same recording before and after the interruption.

*   If a live stream is interrupted for more than 3 minutes, a new recording is generated. To change the default stream interruption time, submit a ticket.', example='3600'),
      format: string(name='Format', description='The format.

>  If you set this parameter to m3u8, you must also specify the SliceOssObjectPrefix and SliceDuration parameters.

This parameter is required.', example='m3u8'),
      ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording file that is stored in Object Storage Service (OSS).

*   The name must be less than 256 bytes in length and can contain the {JobId}, {Sequence}, {StartTime}, {EndTime}, {EscapedStartTime}, and {EscapedEndTime} variables.
*   The name must contain the {StartTime} and {EndTime} variables or the {EscapedStartTime} and {EscapedEndTime} variables.', example='record/{JobId}/{Sequence}_{EscapedStartTime}_{EscapedEndTime}'),
      sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds.

>  This parameter takes effect only if you set Format to m3u8.

If you do not specify this parameter, the default value 30 seconds is used. Valid values: 5 to 30.', example='30'),
      sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.

>  This parameter is required only if you set Format to m3u8.

*   By default, the duration of a segment is 30 seconds. The segment name must be less than 256 bytes in length and can contain the {JobId}, {UnixTimestamp}, and {Sequence} variables.
*   The segment name must contain the {UnixTimestamp} and {Sequence} variables.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
    }
  ](name='RecordFormat', description='The list of recording formats.

This parameter is required.', shrink='json', position='Body'),
}

model CreateLiveRecordTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
}

model CreateLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLiveRecordTemplateResponseBody(name='body'),
}

/**
  * @description You must specify a recording template for live stream recording. You can configure information such as the format and duration of a recording in a recording template. The recording format can be M3U8, MP4, or FLV.
  * @param request  the request parameters of CreateLiveRecordTemplate  CreateLiveRecordTemplateRequest
  * @return CreateLiveRecordTemplateResponse
 */
async function createLiveRecordTemplate(request: CreateLiveRecordTemplateRequest): CreateLiveRecordTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateLiveRecordTemplate', 'POST', '/', 'json', true, 'form', request);
}

model CreateLiveSnapshotTemplateRequest {
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   It cannot exceed 255 characters in length.
*   The {JobId} placeholder is supported. It specifies the ID of the snapshot job.
*   Placeholders such as {UnixTimestamp}, {Sequence}, and {Date} are not allowed.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}.jpg', position='Body'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   It cannot exceed 255 characters in length.
*   The {JobId}, {Date}, {UnixTimestamp}, and {Sequence} placeholders are supported. {JobId} specifies the ID of the snapshot job. {Date} specifies the date on which the snapshot is captured. {UnixTimestamp} specifies the timestamp of the snapshot. {Sequence} specifies the sequence number of the snapshot. You must specify at least one of the {UnixTimestamp} and {Sequence} placeholders.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}/{UnixTimestamp}.jpg', position='Body'),
  templateName: string(name='TemplateName', description='The name of the template.

*   It cannot exceed 128 characters in length.

This parameter is required.', position='Body'),
  timeInterval: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.

*   Valid values: [5,3600].

This parameter is required.', example='5', position='Body'),
}

model CreateLiveSnapshotTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287782****'),
}

model CreateLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLiveSnapshotTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateLiveSnapshotTemplate  CreateLiveSnapshotTemplateRequest
  * @return CreateLiveSnapshotTemplateResponse
 */
async function createLiveSnapshotTemplate(request: CreateLiveSnapshotTemplateRequest): CreateLiveSnapshotTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateLiveSnapshotTemplate', 'POST', '/', 'json', true, 'form', request);
}

model CreateLiveTranscodeTemplateRequest {
  name: string(name='Name', description='The name of the template.

This parameter is required.', example='my template', minLength=1, maxLength=20, position='Query'),
  templateConfig?: {
    audioParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output audio. Unit: Kbit/s. Valid values: 1 to 1000.', example='100'),
      channels?: string(name='Channels', description='The number of sound channels. Valid values: 1: mono 2: binaural', example='2'),
      codec?: string(name='Codec', description='The audio codec. Valid values:

*   AAC
*   MP3', example='AAC'),
      profile?: string(name='Profile', description='The audio codec profile. Valid values when the Codec parameter is set to AAC:

*   aac_low
*   aac_he
*   aac_he_v2
*   aac_ld', example='aaclow'),
      samplerate?: string(name='Samplerate', description='The audio sampling rate. Valid values: 22050 to 96000.

Note: If you set AudioProfile to aac_ld, the audio sampling rate cannot exceed 44,100.', example='44100'),
    }(name='AudioParams', description='The audio parameters.'),
    videoParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output video. Unit: Kbit/s. Valid values: 1 to 6000.', example='2500'),
      codec?: string(name='Codec', description='The encoding type. Valid values:

*   H.264
*   H.265', example='H.264'),
      fps?: string(name='Fps', description='The frame rate of the output video. Unit: frames per second (FPS). Valid values: 1 to 60.', example='25'),
      gop?: string(name='Gop', description='The group of pictures (GOP) of the output video. Unit: frame. Valid values: 1 to 3000.', example='1000'),
      height?: string(name='Height', description='The height of the output video. Valid values: Height ≥ 128 max (Height,Width) ≤ 2560 min (Height,Width) ≤ 1440

Note: The resolution of the output video that is transcoded by using the H.265 Narrowband HD transcoding template cannot exceed 1280 × 720 pixels.', example='720'),
      profile?: string(name='Profile', description='The encoding profile. The profile determines how a video is encoded. In most cases, a greater value indicates better image quality and higher resource consumption. Valid values: 1: baseline. This value is suitable for mobile devices. 2: main. This value is suitable for standard-definition devices. 3: high. This value is suitable for high-definition devices.', example='2'),
      width?: string(name='Width', description='The width of the output video. Valid values: Width ≥ 128 max (Height,Width) ≤ 2560 min (Height,Width) ≤ 1440

Note: The resolution of the output video that is transcoded by using the H.265 Narrowband HD transcoding template cannot exceed 1280 × 720 pixels.', example='1280'),
    }(name='VideoParams', description='The video parameters.'),
  }(name='TemplateConfig', description='The configuration of the template.', shrink='json', position='Query'),
  type: string(name='Type', description='The type of the template. Valid values:

*   normal
*   narrow-band
*   audio-only
*   origin

This parameter is required.', example='normal', position='Query'),
}

model CreateLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  templateId?: string(name='TemplateId', description='The ID of the template.', example='****20b48fb04483915d4f2cd8ac****'),
}

model CreateLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLiveTranscodeTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateLiveTranscodeTemplate  CreateLiveTranscodeTemplateRequest
  * @return CreateLiveTranscodeTemplateResponse
 */
async function createLiveTranscodeTemplate(request: CreateLiveTranscodeTemplateRequest): CreateLiveTranscodeTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateLiveTranscodeTemplate', 'POST', '/', 'json', false, 'json', request);
}

model CreateMediaConnectFlowRequest {
  flowName: string(name='FlowName', description='The flow name.

This parameter is required.', example='AliTestFlow', position='Query'),
  flowRegion: string(name='FlowRegion', description='The region in which the flow resides.

This parameter is required.', example='ap-southeast-1', position='Query'),
}

model CreateMediaConnectFlowResponseBody = {
  content?: {
    flowId?: string(name='FlowId', description='The flow ID.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f'),
  }(name='Content', description='The response body.'),
  description?: string(name='Description', description='The returned message.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='86D92F9D-65E8-58A2-85D1-9DEEECC172E8'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model CreateMediaConnectFlowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateMediaConnectFlowResponseBody(name='body'),
}

/**
  * @description *   The flow names cannot be duplicated in the same region.
  * *   Take note of the returned flow ID. You may reference it in other API operations.
  * @param request  the request parameters of CreateMediaConnectFlow  CreateMediaConnectFlowRequest
  * @return CreateMediaConnectFlowResponse
 */
async function createMediaConnectFlow(request: CreateMediaConnectFlowRequest): CreateMediaConnectFlowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateMediaConnectFlow', 'POST', '/', 'json', false, 'json', request);
}

model CreateMediaLiveChannelRequest {
  audioSettings?: [ 
    {
      audioCodec?: string(name='AudioCodec', description='The audio codec. If it is not specified, the source specification is used. Valid values: aac and libfdk_aac.', example='libfdk_aac'),
      audioCodecSetting?: {
        bitrate?: int32(name='Bitrate', description='The audio bitrate. Unit: bit/s. Valid values: 8000 to 1000000. The value must be divisible by 1000.', example='200000'),
        profile?: string(name='Profile', description='The audio codec profile. When AudioCodec is set to aac, AAC-LOW and AAC-MAIN are supported. When AudioCodec is set to libfdk_aac, AAC-LOW, AAC-HE, and AAC-HEV2 are supported.', example='AAC-LOW'),
        sampleRate?: int32(name='SampleRate', description='The audio sample rate. Unit: Hz. Valid values: 22050, 32000, 44100, 48000, and 96000.', example='44100'),
      }(name='AudioCodecSetting', description='The audio encoding settings.'),
      audioSelectorName?: string(name='AudioSelectorName', description='The name of the audio selector.', example='a1'),
      languageCode?: string(name='LanguageCode', description='Enter a three-letter ISO 639-2 language code. If the audio track selected by the audio selector has a language code, the language code specified in the audio selector is used. If the selected audio track does not have a language code, or if the audio selector cannot find a track that matches its criteria, this language code is used.', example='eng'),
      languageName?: string(name='LanguageName', description='The tag that identifies the language of the RTMP input. It can be referenced by the output. The maximum length is 32 characters. Supported characters:

*   Unicode letters
*   Digits (0-9)
*   Underscore (_)
*   Hyphen (-)
*   Space (a space cannot be at the beginning or end)', example='English'),
      name: string(name='Name', description='The name of the audio settings. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='audio1'),
    }
  ](name='AudioSettings', description='The audio settings.', shrink='json', position='Body'),
  inputAttachments: [ 
    {
      audioSelectors?: [ 
        {
          audioLanguageSelection?: {
            languageCode: string(name='LanguageCode', description='Enter a three-letter ISO 639-2 language code from within an audio source.

This parameter is required.', example='eng'),
          }(name='AudioLanguageSelection', description='The audio language selection.'),
          audioPidSelection?: {
            pid: long(name='Pid', description='Enter a specific PID from within a source.

This parameter is required.', example='123'),
          }(name='AudioPidSelection', description='The audio PID selection.'),
          audioTrackSelection?: [ 
            {
              trackId: long(name='TrackId', description='Specify one or more audio tracks from within a source using Track ID.

This parameter is required.', example='1'),
            }
          ](name='AudioTrackSelection', description='The audio track selection.'),
          name: string(name='Name', description='The name of the audio selector. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='myselector'),
        }
      ](name='AudioSelectors', description='The audio selectors.'),
      inputId: string(name='InputId', description='The ID of the associated input.

This parameter is required.', example='myinput'),
      languageName?: string(name='LanguageName', description='The tag that identifies the language of the RTMP input. It can be referenced by the output. The maximum length is 32 characters. Supported characters:

*   Unicode letters
*   Digits (0-9)
*   Underscore (_)
*   Hyphen (-)
*   Space (a space cannot be at the beginning or end)', example='English'),
    }
  ](name='InputAttachments', description='The associated inputs.

This parameter is required.', shrink='json', position='Body'),
  name: string(name='Name', description='The name of the channel. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='mych', position='Body'),
  outputGroups: [ 
    {
      mediaPackageGroupSetting?: {
        channelName: string(name='ChannelName', description='ChannelName in MediaPackage.

This parameter is required.', example='myPackageChannel'),
        groupName: string(name='GroupName', description='GroupName in MediaPackage.

This parameter is required.', example='myPackageGroup'),
      }(name='MediaPackageGroupSetting', description='The MediaPackage destination.'),
      name: string(name='Name', description='The name of the output group. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='group1'),
      outputs: [ 
        {
          audioSettingNames?: [ string ](name='AudioSettingNames', description='The referenced AudioSettings.'),
          mediaPackageOutputSetting?: {
            audioGroupId?: string(name='AudioGroupId', description='The manifest audio group ID. To associate several audio tracks into one group, assign the same audio group ID. Viewers can select a track as needed. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 40 characters in length.', example='audiogroup'),
            nameModifier?: string(name='NameModifier', description='The manifest name modifier. The child manifests include this modifier in their M3U8 file names. Letters, digits, hyphens (-), and underscores (_) are supported. The maximum length is 40 characters.', example='480p'),
          }(name='MediaPackageOutputSetting', description='The settings of the output delivered to MediaPackage.'),
          mediaType?: int32(name='MediaType', description='The media type of the output. Valid values:

*   0: Audio and Video.
*   1: Audio. If you set the value to 1, you cannot reference VideoSettings.
*   2: Video. If you set the value to 2, you cannot reference AudioSettings.', example='0'),
          name: string(name='Name', description='The name of the output. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='output1'),
          videoSettingName?: string(name='VideoSettingName', description='The name of the referenced VideoSettings.', example='myVideo1'),
        }
      ](name='Outputs', description='The outputs in the output group.

This parameter is required.'),
      type: string(name='Type', description='The output group type. Only MediaPackage is supported.

This parameter is required.', example='MediaPackage'),
    }
  ](name='OutputGroups', description='The output groups.

This parameter is required.', shrink='json', position='Body'),
  videoSettings?: [ 
    {
      height?: int32(name='Height', description='The height of the output. If you set it to 0 or leave it empty, the height automatically adapts to the specified width to maintain the original aspect ratio.

Valid values:

*   For regular transcoding, the larger dimension cannot exceed 3840 px, and the smaller one cannot exceed 2160 px.
*   For Narrowband HD™ transcoding, the larger dimension cannot exceed 1920 px, and the smaller one cannot exceed 1080 px.', example='720'),
      name: string(name='Name', description='The name of the video settings. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='video1'),
      videoCodec?: string(name='VideoCodec', description='The video codec. Valid values: H264 and H265.', example='H264'),
      videoCodecSetting?: {
        codecDetail?: {
          level?: string(name='Level', description='The video encoding level. It is not supported yet.', example='H264_LEVEL_AUTO'),
          profile?: string(name='Profile', description='The H.264 profile. Valid values: BASELINE, HIGH, and MAIN. Default value: MAIN. The parameter takes effect only when the codec is H.264.', example='MAIN'),
        }(name='CodecDetail', description='The video encoding settings.'),
        framerate?: {
          framerateControl?: string(name='FramerateControl', description='The frame rate mode. Valid values: SPECIFIED (fixed frame rate) and FROM_SOURCE (use source specification).', example='SPECIFIED'),
          framerateDenominator?: int32(name='FramerateDenominator', description='The denominator of the fixed frame rate. The parameter is required when FramerateControl is set to SPECIFIED. Valid values: 1 to 60. The numerator must be divisible by the denominator.', example='1'),
          framerateNumerator?: int32(name='FramerateNumerator', description='The numerator of the fixed frame rate. The parameter is required when FramerateControl is set to SPECIFIED. Valid values: 1 to 60. The numerator must be divisible by the denominator.', example='25'),
        }(name='Framerate', description='The frame rate. If it is not specified, the source specification is used.'),
        gop?: {
          bframesNum?: int32(name='BframesNum', description='The number of B frames. Valid values: 1 to 3.', example='3'),
          gopSize?: int32(name='GopSize', description='The GOP size. When GopSizeUnits is set to SECONDS, the value range is from 1 to 20. When GopSizeUnits is set to FRAMES, the value range is from 1 to 3000.', example='90'),
          gopSizeUnits?: string(name='GopSizeUnits', description='The GOP size unit. Valid values: FRAMES and SECONDS.', example='FRAMES'),
        }(name='Gop', description='The GOP setting. If it is not specified, the source specification is used.'),
        rate?: {
          bitrate?: int32(name='Bitrate', description='The video bitrate. Unit: bit/s. If you set it to 0 or leave it empty, the source specification is used. Valid values: 50000 to 6000000. The value must be divisible by 1000.', example='2500000'),
          bufferSize?: int32(name='BufferSize', description='The video buffer size. Unit: bit/s. Valid values: 100000 to 6000000. The value must be divisible by 1000.', example='6000000'),
          maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s. Valid values: 100000 to 6000000. The value must be divisible by 1000.', example='6000000'),
          rateControlMode?: string(name='RateControlMode', description='The bitrate control mode. Valid values: CBR, ABR, and VBR.', example='ABR'),
        }(name='Rate', description='The video encoding rate. If it is not specified, the source specification is used.'),
      }(name='VideoCodecSetting', description='The video encoding settings.'),
      videoCodecType?: string(name='VideoCodecType', description='The video transcoding method. Valid values:

*   NORMAL: regular transcoding
*   NBHD: Narrowband HD™ transcoding

If not specified, regular transcoding is used by default.', example='NORMAL'),
      width?: int32(name='Width', description='The width of the output. If you set it to 0 or leave it empty, the width automatically adapts to the specified height to maintain the original aspect ratio.

Valid values:

*   For regular transcoding, the larger dimension cannot exceed 3840 px, and the smaller one cannot exceed 2160 px.
*   For Narrowband HD™ transcoding, the larger dimension cannot exceed 1920 px, and the smaller one cannot exceed 1080 px.', example='1280'),
    }
  ](name='VideoSettings', description='The video settings.', shrink='json', position='Body'),
}

model CreateMediaLiveChannelResponseBody = {
  channelId?: string(name='ChannelId', description='The ID of the channel.', example='SEGK5KA6KYKAWQQH'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateMediaLiveChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateMediaLiveChannelResponseBody(name='body'),
}

/**
  * @description ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of CreateMediaLiveChannel  CreateMediaLiveChannelRequest
  * @return CreateMediaLiveChannelResponse
 */
async function createMediaLiveChannel(request: CreateMediaLiveChannelRequest): CreateMediaLiveChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateMediaLiveChannel', 'POST', '/', 'json', true, 'form', request);
}

model CreateMediaLiveInputRequest {
  inputSettings: [ 
    {
      flowId?: string(name='FlowId', description='The ID of the flow from MediaConnect. This parameter is required when Type is set to MEDIA_CONNECT.', example='******81-9693-40dc-bbab-db5e49******'),
      flowOutputName?: string(name='FlowOutputName', description='The output name of the MediaConnect flow. This parameter is required when Type is set to MEDIA_CONNECT.', example='myFlowOutputName'),
      sourceUrl?: string(name='SourceUrl', description='The source URL from which the stream is pulled. This parameter is required for PULL inputs.', example='rtmp://domain/app/stream'),
      srtLatency?: int32(name='SrtLatency'),
      srtMaxBitrate?: int32(name='SrtMaxBitrate'),
      srtPassphrase?: string(name='SrtPassphrase'),
      srtPbKeyLen?: int32(name='SrtPbKeyLen'),
      streamName?: string(name='StreamName', description='The name of the pushed stream. This parameter is required for PUSH inputs. It can be up to 255 characters in length.', example='mystream'),
    }
  ](name='InputSettings', description='The input settings. An input can have up to two sources: primary and backup sources.

This parameter is required.', shrink='json', position='Body'),
  name: string(name='Name', description='The name of the input. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='myinput', position='Body'),
  securityGroupIds?: [ string ](name='SecurityGroupIds', description='The IDs of the security groups to be associated with the input. This parameter is required for PUSH inputs.', example='["G6G4X5T4SZYPSTT5"]', shrink='json', position='Body'),
  type: string(name='Type', description='The input type. Valid values: RTMP_PUSH, RTMP_PULL, SRT_PUSH, SRT_PULL, and MEDIA_CONNECT.

This parameter is required.', example='RTMP_PUSH', position='Body'),
}

model CreateMediaLiveInputResponseBody = {
  inputId?: string(name='InputId', description='The ID of the input.', example='SEGK5KA6KYKAWQQH'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateMediaLiveInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateMediaLiveInputResponseBody(name='body'),
}

/**
  * @description ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of CreateMediaLiveInput  CreateMediaLiveInputRequest
  * @return CreateMediaLiveInputResponse
 */
async function createMediaLiveInput(request: CreateMediaLiveInputRequest): CreateMediaLiveInputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateMediaLiveInput', 'POST', '/', 'json', true, 'form', request);
}

model CreateMediaLiveInputSecurityGroupRequest {
  name: string(name='Name', description='The name of the security group. Letters, digits, hyphens (-), and underscores (_) are supported. The maximum length is 64 characters.

This parameter is required.', example='mysg', position='Body'),
  whitelistRules: [ string ](name='WhitelistRules', description='The security group rules.

This parameter is required.', example='["10.1.1.0/24", "11.11.11.11/0"]', shrink='json', position='Body'),
}

model CreateMediaLiveInputSecurityGroupResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  securityGroupId?: string(name='SecurityGroupId', description='The ID of the security group.', example='SEGK5KA6KYKAWQQH'),
}

model CreateMediaLiveInputSecurityGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateMediaLiveInputSecurityGroupResponseBody(name='body'),
}

/**
  * @description ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of CreateMediaLiveInputSecurityGroup  CreateMediaLiveInputSecurityGroupRequest
  * @return CreateMediaLiveInputSecurityGroupResponse
 */
async function createMediaLiveInputSecurityGroup(request: CreateMediaLiveInputSecurityGroupRequest): CreateMediaLiveInputSecurityGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateMediaLiveInputSecurityGroup', 'POST', '/', 'json', true, 'form', request);
}

model CreatePipelineRequest {
  name: string(name='Name', description='The name of the MPS queue.

This parameter is required.', example='test-pipeline', position='Query'),
  priority?: int32(name='Priority', description='The priority. Default value: 6. Valid values: 1 to 10. A greater value specifies a higher priority.', example='6', position='Query'),
  speed: string(name='Speed', description='The type of the MPS queue. Valid values:

1.  Standard: standard MPS queue.
2.  Boost: MPS queue with transcoding speed boosted.
3.  NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.

This parameter is required.', example='Standard', position='Query'),
}

model CreatePipelineResponseBody = {
  pipeline?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
    name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.', example='****20b48fb04483915d4f2cd8ac****'),
    priority?: int32(name='Priority', description='The priority of the MPS queue.', example='6'),
    speed?: string(name='Speed', description='The type of the MPS queue.

Valid values:

*   Boost: MPS queue with transcoding speed boosted.
*   Standard: standard MPS queue.
*   NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.', example='Standard'),
    status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Active'),
  }(name='Pipeline', description='The information about the MPS queue.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreatePipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreatePipelineResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreatePipeline  CreatePipelineRequest
  * @return CreatePipelineResponse
 */
async function createPipeline(request: CreatePipelineRequest): CreatePipelineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreatePipeline', 'POST', '/', 'json', false, 'json', request);
}

model CreateProgramRequest {
  adBreaks?: string(name='AdBreaks', description='The information about ad breaks.', example='[{"MessageType":"SPLICE_INSERT","OffsetMillis":1000,"SourceLocationName":"MySourceLocation","SourceName":"MyAdSource","SpliceInsertSettings":{"AvailNumber":0,"AvailExpected":0,"SpliceEventID":1,"UniqueProgramID":0}}]', position='Query'),
  channelName: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel', position='Query'),
  clipRange?: string(name='ClipRange', description='Extracts a clip from the source.', example='{StartOffsetMillis: 213123, EndOffsetMillis: 213134}', position='Query'),
  programName: string(name='ProgramName', description='The name of the program.

This parameter is required.', example='program1', position='Query'),
  sourceLocationName: string(name='SourceLocationName', description='The source location.

This parameter is required.', example='MySourceLcation', position='Query'),
  sourceName: string(name='SourceName', description='The name of the source.

This parameter is required.', example='MySource', position='Query'),
  sourceType: string(name='SourceType', description='The source type of the program.

This parameter is required.', example='vodSource', position='Query'),
  transition: string(name='Transition', description='The program transition method.

This parameter is required.', example='{"Type": "RELATIVE", "RelativePosition": "AFTER_PROGRAM", "RelativeProgram": "program2"}', position='Query'),
}

model CreateProgramResponseBody = {
  program?: ChannelAssemblyProgram(name='Program', description='The information about the program.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
}

model CreateProgramResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateProgramResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateProgram  CreateProgramRequest
  * @return CreateProgramResponse
 */
async function createProgram(request: CreateProgramRequest): CreateProgramResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateProgram', 'POST', '/', 'json', false, 'json', request);
}

model CreateRecognitionEntityRequest {
  algorithm: string(name='Algorithm', description='The type of recognition algorithm. Valid values:

*   landmark
*   object
*   logo
*   face
*   label

This parameter is required.', example='landmark', position='Query'),
  entityInfo?: string(name='EntityInfo', description='The extra information about the custom entity, provided as a JSON string. Max length: 256 bytes.', position='Query'),
  entityName: string(name='EntityName', description='The name of the custom entity. Max length: 64 bytes.

This parameter is required.', position='Query'),
  libId: string(name='LibId', description='The ID of the recognition library.

This parameter is required.', example='*************24b47865c6**************', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model CreateRecognitionEntityResponseBody = {
  entityId?: string(name='EntityId', description='The ID of the created entity.', example='**************544cb84754************'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateRecognitionEntityResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateRecognitionEntityResponseBody(name='body'),
}

/**
  * @description *   This operation is supported only in the China (Beijing), China (Shanghai), China (Hangzhou), and China (Shenzhen) regions.
  * *   You can call this operation up to 50 times per second per account. Requests that exceed this limit are dropped and you may experience service interruptions. For more information, see [QPS limits](https://help.aliyun.com/zh/mps/developer-reference/qps-limits?spm=a2c4g.11186623.0.0.647e1081YGcerb).
  * @param request  the request parameters of CreateRecognitionEntity  CreateRecognitionEntityRequest
  * @return CreateRecognitionEntityResponse
 */
async function createRecognitionEntity(request: CreateRecognitionEntityRequest): CreateRecognitionEntityResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateRecognitionEntity', 'POST', '/', 'json', false, 'json', request);
}

model CreateRecognitionLibRequest {
  algorithm: string(name='Algorithm', description='The type of recognition algorithm. Valid values:

*   landmark
*   object
*   logo
*   face
*   label

This parameter is required.', example='landmark', position='Query'),
  libDescription?: string(name='LibDescription', description='The description of the recognition library. Max length: 128 bytes.', position='Query'),
  libName: string(name='LibName', description='The name of the recognition library. Max length: 64 bytes.

This parameter is required.', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model CreateRecognitionLibResponseBody = {
  libId?: string(name='LibId', description='The ID of the recognition library created.', example='*************24b47865c6**************'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateRecognitionLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateRecognitionLibResponseBody(name='body'),
}

/**
  * @description *   This operation is supported only in the China (Beijing), China (Shanghai), China (Hangzhou), and China (Shenzhen) regions.
  * *   Workflow for using a custom recognition library: Create a library, create a custom object entity within the library, register sample images for the entity, create an analysis template that uses your custom library, and then submit an analysis task using the template.
  * *   You can call this operation up to 50 times per second per account. Requests that exceed this limit are dropped and you may experience service interruptions. For more information, see [QPS limits](https://help.aliyun.com/zh/mps/developer-reference/qps-limits?spm=a2c4g.11186623.0.0.647e1081YGcerb).
  * @param request  the request parameters of CreateRecognitionLib  CreateRecognitionLibRequest
  * @return CreateRecognitionLibResponse
 */
async function createRecognitionLib(request: CreateRecognitionLibRequest): CreateRecognitionLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateRecognitionLib', 'POST', '/', 'json', false, 'json', request);
}

model CreateRecognitionSampleRequest {
  algorithm: string(name='Algorithm', description='The type of recognition this sample is for.

*   landmark
*   object
*   logo
*   face
*   label

This parameter is required.', example='landmark', position='Query'),
  entityId: string(name='EntityId', description='The ID of the specific entity within the library.

This parameter is required.', example='**************544cb84754************', position='Query'),
  imageUrl?: string(name='ImageUrl', description='The URL of the sample image.', example='https://example.com/sample.png', position='Query'),
  labelPrompt?: string(name='LabelPrompt', description='The custom text label.', position='Query'),
  libId: string(name='LibId', description='The ID of the recognition library.

This parameter is required.', example='*************24b47865c6**************', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model CreateRecognitionSampleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sampleId?: string(name='SampleId', description='The ID of the sample.', example='**************4d2ba728e2f**************'),
}

model CreateRecognitionSampleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateRecognitionSampleResponseBody(name='body'),
}

/**
  * @description *   This operation is supported only in the China (Beijing), China (Shanghai), China (Hangzhou), and China (Shenzhen) regions.
  * *   You can call this operation up to 50 times per second per account. Requests that exceed this limit are dropped and you may experience service interruptions. For more information, see [QPS limits](https://help.aliyun.com/zh/mps/developer-reference/qps-limits?spm=a2c4g.11186623.0.0.647e1081YGcerb).
  * @param request  the request parameters of CreateRecognitionSample  CreateRecognitionSampleRequest
  * @return CreateRecognitionSampleResponse
 */
async function createRecognitionSample(request: CreateRecognitionSampleRequest): CreateRecognitionSampleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateRecognitionSample', 'POST', '/', 'json', false, 'json', request);
}

model CreateSearchIndexRequest {
  regionId?: string(name='RegionId', position='Host'),
  indexConfig?: string(name='IndexConfig', example='{}', position='Query'),
  indexStatus?: string(name='IndexStatus', example='Active', position='Query'),
  indexType: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model. You can use this model to describe complex visual features and identify and search for specific actions, movements, and events in videos, such as when athletes score a goal or get injured.

>  This feature is in the public preview phase. You can use this feature for free for 1,000 hours of videos.

*   face: face recognition. You can use the face recognition technology to describe face characteristics and automatically mark or search for faces in videos.
*   aiLabel: smart tagging. The smart tagging category is used to describe content such as subtitles and audio in videos. You can use the speech recognition technology to automatically extract, mark, and search for subtitles and dialog content from videos. This helps you quickly locate the video content that is related to specific topics or keywords.

This parameter is required.', example='mm', position='Query'),
  searchLibName?: string(name='SearchLibName', example='test1', position='Query'),
}

model CreateSearchIndexResponseBody = {
  code?: string(name='Code', example='200'),
  requestId?: string(name='RequestId', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  success?: string(name='Success', example='true'),
}

model CreateSearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSearchIndexResponseBody(name='body'),
}

/**
  * @description The large visual model feature is still in the public preview phase. You can use this feature for free for 1,000 hours of videos.
  * @param request  the request parameters of CreateSearchIndex  CreateSearchIndexRequest
  * @return CreateSearchIndexResponse
 */
async function createSearchIndex(request: CreateSearchIndexRequest): CreateSearchIndexResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateSearchIndex', 'POST', '/', 'json', false, 'json', request);
}

model CreateSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  searchLibName: string(name='SearchLibName', description='The name of the search library. The name can contain letters and digits and must start with a letter.

This parameter is required.', example='test1', position='Query'),
}

model CreateSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model CreateSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateSearchLib  CreateSearchLibRequest
  * @return CreateSearchLibResponse
 */
async function createSearchLib(request: CreateSearchLibRequest): CreateSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model CreateSourceRequest {
  httpPackageConfigurations: string(name='HttpPackageConfigurations', description='The source configurations.

This parameter is required.', example='“[{
	"sourceGroupName": "mySourceGroup-1",
	"relativePath": "group1/hls.m3u8",
	"type": "hls"
}]”', position='Query'),
  sourceLocationName: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourceLocation', position='Query'),
  sourceName: string(name='SourceName', description='The name of the source.

This parameter is required.', example='MyVodSource', position='Query'),
  sourceType: string(name='SourceType', description='The source type. Valid values: vodSource and liveSource.

This parameter is required.', example='vodSource', position='Query'),
}

model CreateSourceResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  source?: ChannelAssemblySource(name='Source', description='The source information.'),
}

model CreateSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateSource  CreateSourceRequest
  * @return CreateSourceResponse
 */
async function createSource(request: CreateSourceRequest): CreateSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateSource', 'POST', '/', 'json', false, 'json', request);
}

model CreateSourceLocationRequest {
  baseUrl: string(name='BaseUrl', description='The protocol and hostname of the source location.

This parameter is required.', example='http://xxx.com', position='Query'),
  enableSegmentDelivery?: boolean(name='EnableSegmentDelivery', description='Specifies whether to use an independent domain name to access the segments.', example='true', position='Query'),
  segmentDeliveryUrl?: string(name='SegmentDeliveryUrl', description='The domain name used to access the segments.', example='http://xxxxx.com', position='Query'),
  sourceLocationName: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourcelocation', position='Query'),
}

model CreateSourceLocationResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  sourceLocation?: ChannelAssemblySourceLocation(name='SourceLocation', description='The source location information.'),
}

model CreateSourceLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSourceLocationResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateSourceLocation  CreateSourceLocationRequest
  * @return CreateSourceLocationResponse
 */
async function createSourceLocation(request: CreateSourceLocationRequest): CreateSourceLocationResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateSourceLocation', 'POST', '/', 'json', false, 'json', request);
}

model CreateStreamToSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  input?: string(name='Input', description='The URL of the live stream to be ingested and analyzed.', example='rtmp://xxx', position='Query'),
  namespace?: string(name='Namespace', description='The namespace.', example='name-1', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='Stream_xxx', position='Query'),
}

model CreateStreamToSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true: succeeded.
*   false: failed.', example='true'),
}

model CreateStreamToSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateStreamToSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateStreamToSearchLib  CreateStreamToSearchLibRequest
  * @return CreateStreamToSearchLibResponse
 */
async function createStreamToSearchLib(request: CreateStreamToSearchLibRequest): CreateStreamToSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateStreamToSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model CreateUploadMediaRequest {
  regionId?: string(name='RegionId', position='Host'),
  appId?: string(name='AppId', description='The application ID. Default value: app-1000000.', example='app-1000000', position='Query'),
  entityId?: string(name='EntityId', description='The entity ID. You can call the CreateEntity operation to create an entity and specify a dynamic metadata structure.', example='9e177cac2fb44f8b8c67b199fcc7bffd', position='Query'),
  fileInfo?: string(name='FileInfo', description='The file information, which is in the JSON format and contains the following fields:

*   Type: required. The file type. Valid values: video, image, audio, text, and other.
*   Name: required. The file name without the extension.
*   Size: optional. The file size.
*   Ext: required. The file name extension.', example='{\\"Type\\":\\"video\\",\\"Name\\":\\"test.mp4\\",\\"Size\\":108078336,\\"Ext\\":\\"mp4\\"}', position='Query'),
  mediaMetaData?: string(name='MediaMetaData', description='The metadata of the media asset, which is a JSON string that contains the following fields:

Title: required.

*   The value can be up to 128 characters in length.
*   The value must be encoded in UTF-8.

Description: optional.

*   The value can be up to 1,024 characters in length.
*   The value must be encoded in UTF-8.

CateId: optional.

Tags: optional.

BusinessType: required. Valid values:

*   opening or ending if Type is set to video
*   default or cover if Type is set to image
*   subtitles or font if Type is set to text
*   watermark if Type is set to material
*   general CoverURL: optional.

DynamicMetaData: The value is a string.', example='{\\"Title\\": \\"UploadTest\\", \\"Description\\": \\"UploadImageTest\\", \\"Tags\\": \\"tag1,tag2\\",\\"BusinessType\\":\\"cover\\"}', position='Query'),
  postProcessConfig?: string(name='PostProcessConfig', description='The postprocessing configurations. You can specify this parameter if Type is set to video or audio.

Set ProcessType to Workflow.', example='{\\"ProcessType\\":\\"Workflow\\",\\"ProcessID\\":\\"74ba870f1a4873a3ba238e0bf6fa9***\\"}', position='Query'),
  uploadTargetConfig?: string(name='UploadTargetConfig', description='The destination storage address.

Set StorageType to oss.

Set StorageLocation to an address in ApsaraVideo VOD. You cannot set this field to an OSS URL.', example='{\\"StorageType\\":\\"oss\\",\\"StorageLocation\\":\\"outin-***.oss-cn-shanghai.aliyuncs.com\\"}', position='Query'),
  userData?: string(name='UserData', description='The user data. The value must be a JSON string. You can configure settings such as message callbacks.', example='{"MessageCallback":{"CallbackURL":"http://example.aliyundoc.com"},"Extend":{"localId":"*****","test":"www"}}', position='Query'),
}

model CreateUploadMediaResponseBody = {
  fileURL?: string(name='FileURL', description='The OSS URL of the file. The URL does not contain the information used for authentication.', example='http://outin-***.oss-cn-north-2-gov-1.aliyuncs.com/sv/40360f05-181f63c3110-0004-cd8e-27f-de3c9.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaURL?: string(name='MediaURL', description='The URL of the media asset.

>  If a domain name for Alibaba Cloud CDN (CDN) is specified, a CDN URL is returned. Otherwise, an OSS URL is returned. If the HTTP status code 403 is returned when you access the URL from your browser, the URL authentication feature of ApsaraVideo VOD is enabled. To resolve this issue, disable URL authentication or generate an authentication signature.', example='https://xxq-live-playback.oss-cn-shanghai.aliyuncs.com/capture/5d96d2b4-111b-4e5d-a0e5-20f44405bb55.mp4'),
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  uploadAddress?: string(name='UploadAddress', description='The upload URL.

>  The returned upload URL is a Base64-encoded URL. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAddress only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJFbmRwb2ludCI6Imh0dHBzOi8vb3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbSIsIkJ1Y2tldCI6InN6aGQtdmlkZW8iLCJGaWxlTmFtZSI6InZvZC0yOTYzMWEvc3YvNTBmYTJlODQtMTgxMjdhZGRiMTcvNTBmYTJlODQtMTgxMjdhZGRiM***'),
  uploadAuth?: string(name='UploadAuth', description='The upload credential.

>  The returned upload credential is a Base64-encoded value. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAuth only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJBY2Nlc3NLZXlJZCI6IkxUQUk0Rm53bTk1dHdxQjMxR3IzSE5hRCIsIkFjY2Vzc0tleVNlY3JldCI6Ik9lWllKR0dTMTlkNkZaM1E3UVpJQmdmSVdnM3BPaiIsIkV4cGlyYXRpb24iOiI***'),
}

model CreateUploadMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateUploadMediaResponseBody(name='body'),
}

/**
  * @description *   You can call this operation to obtain the upload URLs and credentials of audio and video files. You can also call this operation to obtain the upload URLs and credentials of images and auxiliary media assets.
  * *   Obtaining an upload URL and credential is essential for Intelligent Media Services (IMS) and is required in each upload operation.
  * *   If the video upload credential expires, you can call the RefreshUploadMedia operation to obtain a new upload credential. The default validity period of a video upload credential is 3,000 seconds.
  * *   After you upload a media asset, you can configure a callback to receive upload event notifications or call the GetMediaInfo operation to determine whether the media asset is uploaded based on the returned status.
  * *   The MediaId parameter returned by this operation can be used for media asset lifecycle management or media processing.
  * *   You can call this operation to upload media assets only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media asset to your own OSS bucket, you can upload the file to your OSS bucket by using [OSS SDK](https://help.aliyun.com/document_detail/32006.html), and then call the [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html) operation to register the file in the OSS bucket with the media asset library.
  * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
  * @param request  the request parameters of CreateUploadMedia  CreateUploadMediaRequest
  * @return CreateUploadMediaResponse
 */
async function createUploadMedia(request: CreateUploadMediaRequest): CreateUploadMediaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateUploadMedia', 'POST', '/', 'json', false, 'json', request);
}

model CreateUploadStreamRequest {
  regionId?: string(name='RegionId', position='Host'),
  definition?: string(name='Definition', description='The quality of the media stream. Valid values:

*   FD: low definition.
*   LD: standard definition.
*   SD: high definition.
*   HD: ultra-high definition.
*   OD: original quality.
*   2K: 2K resolution.
*   4K: 4K resolution.
*   SQ: standard sound quality.
*   HQ: high sound quality.', example='HD', position='Query'),
  fileExtension?: string(name='FileExtension', description='The file name extension of the media stream.', example='MP4', position='Query'),
  HDRType?: string(name='HDRType', description='The high dynamic range (HDR) format of the transcoded stream. Valid values:

*   HDR
*   HDR10
*   HLG
*   DolbyVision
*   HDRVivid
*   SDR+

> 

*   The value is not case-sensitive,

*   You can leave this parameter empty for non-HDR streams.', example='HDR10', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  userData?: string(name='UserData', description='The user data.', example='{"MessageCallback":{"CallbackURL":"http://aliyundoc.com"}, "Extend":{"localId":"xxx","test":"www"}}', position='Query'),
}

model CreateUploadStreamResponseBody = {
  fileURL?: string(name='FileURL', description='The Object Storage Service (OSS) URL of the file. The URL does not contain the information used for authentication.', example='http://outin-***.oss-cn-shanghai.aliyuncs.com/stream/48555e8b-181dd5a8c07/48555e8b-181dd5a8c07.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****c469e944b5a856828dc2****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  uploadAddress?: string(name='UploadAddress', description='The upload URL.

>  The returned upload URL is a Base64-encoded URL. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAddress only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJFbmRwb2ludCI6Imh0dHBzOi8vb3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbSIsIkJ1Y2tldCI6InN6aGQtdmlkZW8iLCJGaWxlTmFtZSI6InZvZC0yOTYzMWEvc3YvNTBmYTJlODQtMTgxMjdhZGRiMTcvNTBmYTJlODQtMTgxMjdhZGRiM***'),
  uploadAuth?: string(name='UploadAuth', description='The upload credential.

>  The returned upload credential is a Base64-encoded value. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAuth only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJBY2Nlc3NLZXlJZCI6IkxUQUk0Rm53bTk1dHdxQjMxR3IzSE5hRCIsIkFjY2Vzc0tleVNlY3JldCI6Ik9lWllKR0dTMTlkNkZaM1E3UVpJQmdmSVdnM3BPaiIsIkV4cGlyYXRpb24iOiI***'),
}

model CreateUploadStreamResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateUploadStreamResponseBody(name='body'),
}

/**
  * @description *   You can call this operation to upload only a local media stream. After the media stream is uploaded, it is associated with the specified media asset ID.
  * *   You can call this operation to upload media streams only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media stream to your own OSS bucket, you can upload the file to your OSS bucket by using [OSS SDK](https://help.aliyun.com/document_detail/32006.html), and then call the [RegisterMediaStream](https://help.aliyun.com/document_detail/440765.html) operation to associate the media stream with the specified media asset ID.
  * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
  * @param request  the request parameters of CreateUploadStream  CreateUploadStreamRequest
  * @return CreateUploadStreamResponse
 */
async function createUploadStream(request: CreateUploadStreamRequest): CreateUploadStreamResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateUploadStream', 'POST', '/', 'json', false, 'json', request);
}

model CreateVodPackagingAssetRequest {
  assetName?: string(name='AssetName', description='The name of the asset. The name must be unique and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='hls_3s', position='Query'),
  contentId?: string(name='ContentId', description='The content ID in the digital rights management (DRM) system. The maximum length is 256 characters. Letters, digits, underscores (_), and hyphens (-) are supported.', example='movie', position='Query'),
  description?: string(name='Description', description='The asset description.', example='HLS 3 second packaging', position='Query'),
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls', position='Query'),
  input?: {
    media?: string(name='Media', description='The URL of the media file. Only M3U8 files stored in OSS are supported.'),
    type?: string(name='Type', description='The input type. Only Object Storage Service (OSS) is supported.', example='OSS'),
  }(name='Input', description='The asset input configurations.', shrink='json', position='Query'),
}

model CreateVodPackagingAssetResponseBody = {
  asset?: VodPackagingAsset(name='Asset', description='The information about the asset.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model CreateVodPackagingAssetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateVodPackagingAssetResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateVodPackagingAsset  CreateVodPackagingAssetRequest
  * @return CreateVodPackagingAssetResponse
 */
async function createVodPackagingAsset(request: CreateVodPackagingAssetRequest): CreateVodPackagingAssetResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateVodPackagingAsset', 'POST', '/', 'json', false, 'json', request);
}

model CreateVodPackagingConfigurationRequest {
  configurationName?: string(name='ConfigurationName', description='The name of the packaging configuration. The name must be unique in an account and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='hls_3s', position='Query'),
  description?: string(name='Description', description='The description of the packaging configuration.', example='HLS 3s vod packaging', position='Query'),
  groupName?: string(name='GroupName', description='The name of the packaging group. The name can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='vod_hls', position='Query'),
  packageConfig?: {
    drmProvider?: {
      encryptionMethod?: string(name='EncryptionMethod', description='The encryption method. Valid values:

*   AES_128: Advanced Encryption Standard (AES) with 128-bit key length.
*   SAMPLE_AES: an encryption method that encrypts individual media samples.', example='AES_128'),
      iv?: string(name='IV', description='A 128-bit, 16-byte hex value represented by a 32-character string that is used with the key for encrypting data blocks. If you leave this parameter empty, MediaPackage creates a constant initialization vector (IV). If it is specified, the value is passed to the DRM service.', example='00001111222233334444555566667777'),
      systemIds?: [ string ](name='SystemIds', description='The ID of the DRM system. The maximum number of system IDs allowed is determined by the protocol type. Limits:

*   DASH: 2
*   HLS: 1
*   HLS_CMAF: 2

Apple FairPlay, Google Widevine, and Microsoft PlayReady are supported. Their system IDs are as follows:

*   Apple FairPlay: 94ce86fb-07ff-4f43-adb8-93d2fa968ca2
*   Google Widevine: edef8ba9-79d6-4ace-a3c8-27dcd51d21e
*   Microsoft PlayReady: 9a04f079-9840-4286-ab92-e65be0885f95'),
      url?: string(name='Url', description='The URL of the DRM key provider.'),
    }(name='DrmProvider', description='The settings of digital rights management (DRM) encryption.'),
    manifestName?: string(name='ManifestName', description='The manifest name. The name can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='index'),
    segmentDuration?: long(name='SegmentDuration', description='The duration of each segment in a packaged stream. Unit: seconds. MediaPackage rounds segments to the nearest multiple of the input segment duration. Valid values: 1 to 30.', example='6'),
    streamSelection?: {
      maxVideoBitsPerSecond?: long(name='MaxVideoBitsPerSecond', description='The maximum bitrate of the video stream. Unit: bit/s.', example='1000000000'),
      minVideoBitsPerSecond?: long(name='MinVideoBitsPerSecond', description='The minimum bitrate of the video stream. Unit: bit/s.', example='100000'),
      streamOrder?: string(name='StreamOrder', description='The order of manifest files in the master playlist. Valid values:

*   ORIGINAL: sorts the manifest files in the same order as the source.
*   VIDEO_BITRATE_ASCENDING: sorts the manifest files in ascending order of bitrates, from lowest to highest.
*   VIDEO_BITRATE_DESCENDING: sorts the manifest files in descending order of bitrates, from highest to lowest.', example='ORIGINAL'),
    }(name='StreamSelection', description='The settings of stream selection.'),
  }(name='PackageConfig', description='The packaging configuration.', shrink='json', position='Query'),
  protocol?: string(name='Protocol', description='The package type.

*   HLS: packages content into TS segments for delivery over the HLS protocol.
*   HLS_CMAF: packages content into CMAF segments for delivery over the HLS protocol.
*   DASH: packages content for delivery over the DASH protocol.', example='HLS', position='Query'),
}

model CreateVodPackagingConfigurationResponseBody = {
  packagingConfiguration?: VodPackagingConfiguration(name='PackagingConfiguration', description='The packaging configuration.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateVodPackagingConfigurationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateVodPackagingConfigurationResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateVodPackagingConfiguration  CreateVodPackagingConfigurationRequest
  * @return CreateVodPackagingConfigurationResponse
 */
async function createVodPackagingConfiguration(request: CreateVodPackagingConfigurationRequest): CreateVodPackagingConfigurationResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateVodPackagingConfiguration', 'POST', '/', 'json', false, 'json', request);
}

model CreateVodPackagingGroupRequest {
  description?: string(name='Description', description='The packaging group description.', example='vod hls packaging', position='Query'),
  groupName?: string(name='GroupName', description='The name of the packaging group. The name must be unique in an account and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='vod_hls', position='Query'),
}

model CreateVodPackagingGroupResponseBody = {
  packagingGroup?: VodPackagingGroup(name='PackagingGroup', description='The packaging group information.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateVodPackagingGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateVodPackagingGroupResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateVodPackagingGroup  CreateVodPackagingGroupRequest
  * @return CreateVodPackagingGroupResponse
 */
async function createVodPackagingGroup(request: CreateVodPackagingGroupRequest): CreateVodPackagingGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateVodPackagingGroup', 'POST', '/', 'json', false, 'json', request);
}

model DecryptKMSDataKeyRequest {
  ciphertextBlob: string(name='CiphertextBlob', description='The ciphertext that you want to decrypt.

This parameter is required.', example='ODZhOWVmZDktM2QxNi00ODk0LWJkNGYtMWZjNDNmM2YyYWJmS7FmDBBQ0BkKsQrtRnidtPwirmDcS0ZuJCU41xxAAWk4Z8qsADfbV0b+i6kQmlvj79dJdGOvtX69Uycs901qOjop4bTS****', position='Query'),
}

model DecryptKMSDataKeyResponseBody = {
  dataKey?: {
    keyId?: string(name='KeyId', description='The ID of the customer master key (CMK) that was used to decrypt the ciphertext.', example='202b9877-5a25-46e3-a763-e20791b5****'),
    plaintext?: string(name='Plaintext', description='The plaintext that is generated after decryption.', example='tRYXuCwgja12xxO1N/gZERDDCLw9doZEQiPDk/Bv****'),
  }(name='DataKey', description='The information about the decryption result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DecryptKMSDataKeyResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DecryptKMSDataKeyResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DecryptKMSDataKey  DecryptKMSDataKeyRequest
  * @return DecryptKMSDataKeyResponse
 */
async function decryptKMSDataKey(request: DecryptKMSDataKeyRequest): DecryptKMSDataKeyResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DecryptKMSDataKey', 'POST', '/', 'json', false, 'json', request);
}

model DeleteAIAgentDialogueRequest {
  dialogueId: string(name='DialogueId', description='The ID of the dialog that you want to delete.

This parameter is required.', example='f27f9b9be28642a88e18*******', position='Query'),
  nodeId?: string(name='NodeId', position='Query'),
  sessionId: string(name='SessionId', description='The session ID.

This parameter is required.', example='6d594e7f55624c47a48789******', position='Query'),
}

model DeleteAIAgentDialogueResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='7B117AF5-2A1******'),
}

model DeleteAIAgentDialogueResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteAIAgentDialogueResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteAIAgentDialogue  DeleteAIAgentDialogueRequest
  * @return DeleteAIAgentDialogueResponse
 */
async function deleteAIAgentDialogue(request: DeleteAIAgentDialogueRequest): DeleteAIAgentDialogueResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteAIAgentDialogue', 'POST', '/', 'json', false, 'json', request);
}

model DeleteAdInsertionRequest {
  name: string(name='Name', description='The name of the configuration that you want to delete.

This parameter is required.', example='my_ad', position='Body'),
}

model DeleteAdInsertionResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteAdInsertionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteAdInsertionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteAdInsertion  DeleteAdInsertionRequest
  * @return DeleteAdInsertionResponse
 */
async function deleteAdInsertion(request: DeleteAdInsertionRequest): DeleteAdInsertionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteAdInsertion', 'POST', '/', 'json', true, 'form', request);
}

model DeleteAvatarTrainingJobRequest {
  jobId: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model DeleteAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteAvatarTrainingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteAvatarTrainingJob  DeleteAvatarTrainingJobRequest
  * @return DeleteAvatarTrainingJobResponse
 */
async function deleteAvatarTrainingJob(request: DeleteAvatarTrainingJobRequest): DeleteAvatarTrainingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteAvatarTrainingJob', 'POST', '/', 'json', false, 'json', request);
}

model DeleteCategoryRequest {
  regionId?: string(name='RegionId', position='Host'),
  cateId: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of CateId returned by the AddCategory operation that you called to create a category.
*   View the value of CateId returned by the GetCategories operation that you called to query a category.

This parameter is required.', example='46', position='Query'),
}

model DeleteCategoryResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model DeleteCategoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCategoryResponseBody(name='body'),
}

/**
  * @description This operation also deletes the subcategories, including the level-2 and level-3 categories, of the category.
  * @param request  the request parameters of DeleteCategory  DeleteCategoryRequest
  * @return DeleteCategoryResponse
 */
async function deleteCategory(request: DeleteCategoryRequest): DeleteCategoryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteCategory', 'POST', '/', 'json', false, 'json', request);
}

model DeleteChannelRequest {
  channelName: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel', position='Query'),
}

model DeleteChannelResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteChannelResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteChannel  DeleteChannelRequest
  * @return DeleteChannelResponse
 */
async function deleteChannel(request: DeleteChannelRequest): DeleteChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteChannel', 'POST', '/', 'json', false, 'json', request);
}

model DeleteCustomTemplateRequest {
  templateId: string(name='TemplateId', description='The ID of the custom template.

This parameter is required.', example='****96e8864746a0b6f3****', position='Query'),
}

model DeleteCustomTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCustomTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteCustomTemplate  DeleteCustomTemplateRequest
  * @return DeleteCustomTemplateResponse
 */
async function deleteCustomTemplate(request: DeleteCustomTemplateRequest): DeleteCustomTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteCustomTemplate', 'POST', '/', 'json', false, 'json', request);
}

model DeleteCustomizedVoiceJobRequest {
  jobId: string(name='JobId', description='The ID of the human voice cloning job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model DeleteCustomizedVoiceJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteCustomizedVoiceJob  DeleteCustomizedVoiceJobRequest
  * @return DeleteCustomizedVoiceJobResponse
 */
async function deleteCustomizedVoiceJob(request: DeleteCustomizedVoiceJobRequest): DeleteCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDNADBRequest {
  DBId: string(name='DBId', description='The ID of the media fingerprint library that you want to delete.

This parameter is required.', example='fb712a6890464059b1b2ea7c8647****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model DeleteDNADBResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model DeleteDNADBResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDNADBResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDNADB  DeleteDNADBRequest
  * @return DeleteDNADBResponse
 */
async function deleteDNADB(request: DeleteDNADBRequest): DeleteDNADBResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDNADB', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDNAFilesRequest {
  DBId: string(name='DBId', description='The ID of the media fingerprint library from which you want to delete files.

This parameter is required.', example='fb712a6890464059b1b2ea7c8647****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  primaryKeys: string(name='PrimaryKeys', description='The primary key values of the files that you want to delete. Separate multiple values with commas (,). You can delete up to 50 files at a time.

This parameter is required.', example='41e6536e4f2250e2e9bf26cdea19****', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model DeleteDNAFilesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model DeleteDNAFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDNAFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDNAFiles  DeleteDNAFilesRequest
  * @return DeleteDNAFilesResponse
 */
async function deleteDNAFiles(request: DeleteDNAFilesRequest): DeleteDNAFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDNAFiles', 'POST', '/', 'json', false, 'json', request);
}

model DeleteEditingProjectMaterialsRequest {
  materialIds: string(name='MaterialIds', description='The material ID. Separate multiple material IDs with commas (,). You can specify up to 10 IDs.

This parameter is required.', example='*****cbd721b418a89a7dafb1dc*****,*****86f5d534c95997c55c96f*****', position='Query'),
  materialType: string(name='MaterialType', description='The material type. Valid values:

\\- video

\\- image

\\- audio

\\- subtitle

\\- text

This parameter is required.', example='video', position='Query'),
  projectId: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='*****fb2101cb318*****', position='Query'),
}

model DeleteEditingProjectMaterialsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******36-3C1E-4417-BDB2-1E034F******'),
}

model DeleteEditingProjectMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteEditingProjectMaterialsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteEditingProjectMaterials  DeleteEditingProjectMaterialsRequest
  * @return DeleteEditingProjectMaterialsResponse
 */
async function deleteEditingProjectMaterials(request: DeleteEditingProjectMaterialsRequest): DeleteEditingProjectMaterialsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteEditingProjectMaterials', 'POST', '/', 'json', false, 'json', request);
}

model DeleteEditingProjectsRequest {
  projectIds?: string(name='ProjectIds', description='The ID of the online editing project. You can specify multiple IDs separated with commas (,).', example='****fb2101bf24bf41cb318787dc****,****87dcfb2101bf24bf41cb3187****', position='Query'),
}

model DeleteEditingProjectsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****25818875-5F78-4AF6-D7393642CA58****'),
}

model DeleteEditingProjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteEditingProjectsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteEditingProjects  DeleteEditingProjectsRequest
  * @return DeleteEditingProjectsResponse
 */
async function deleteEditingProjects(request: DeleteEditingProjectsRequest): DeleteEditingProjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteEditingProjects', 'POST', '/', 'json', false, 'json', request);
}

model DeleteHotwordLibraryRequest {
  hotwordLibraryId?: string(name='HotwordLibraryId', description='The ID of the hotword library that you want to delete.', example='****cdb3e74639973036bc84****', position='Query'),
}

model DeleteHotwordLibraryResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='****83B7-7F87-4792-BFE9-63CD2137****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.'),
}

model DeleteHotwordLibraryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteHotwordLibraryResponseBody(name='body'),
}

/**
  * @description ## [](#)
  * *   You can call this operation to delete a specified hotword library.
  * *   The delete operation is irreversible.
  * *   You can create up to 100 hotword libraries in an account.
  * @param request  the request parameters of DeleteHotwordLibrary  DeleteHotwordLibraryRequest
  * @return DeleteHotwordLibraryResponse
 */
async function deleteHotwordLibrary(request: DeleteHotwordLibraryRequest): DeleteHotwordLibraryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteHotwordLibrary', 'POST', '/', 'json', false, 'json', request);
}

model DeleteLivePackageChannelRequest {
  channelName: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1', position='Query'),
  groupName: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1', position='Query'),
}

model DeleteLivePackageChannelResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='20B3A1B6-4BD2-5DE6-BCBC-098C9B4F4E91'),
}

model DeleteLivePackageChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLivePackageChannelResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * You need to provide GroupName and ChannelName as parameters to specify exactly which channel to delete. Before you delete a channel, you must delete the origin endpoints associated with the channel.
  * @param request  the request parameters of DeleteLivePackageChannel  DeleteLivePackageChannelRequest
  * @return DeleteLivePackageChannelResponse
 */
async function deleteLivePackageChannel(request: DeleteLivePackageChannelRequest): DeleteLivePackageChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLivePackageChannel', 'POST', '/', 'json', false, 'json', request);
}

model DeleteLivePackageChannelGroupRequest {
  groupName: string(name='GroupName', description='The channel group name.

This parameter is required.', example='group1', position='Query'),
}

model DeleteLivePackageChannelGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='5D87B753-0250-5D9D-B248-D40C3271F864'),
}

model DeleteLivePackageChannelGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLivePackageChannelGroupResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * Make sure that no channels are included in the channel group before you delete it.
  * @param request  the request parameters of DeleteLivePackageChannelGroup  DeleteLivePackageChannelGroupRequest
  * @return DeleteLivePackageChannelGroupResponse
 */
async function deleteLivePackageChannelGroup(request: DeleteLivePackageChannelGroupRequest): DeleteLivePackageChannelGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLivePackageChannelGroup', 'POST', '/', 'json', false, 'json', request);
}

model DeleteLivePackageOriginEndpointRequest {
  channelName: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1', position='Query'),
  endpointName: string(name='EndpointName', description='The endpoint name.

This parameter is required.', example='endpoint-1', position='Query'),
  groupName: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1', position='Query'),
}

model DeleteLivePackageOriginEndpointResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='5D87B753-0250-5D9D-B248-D40C3271F864'),
}

model DeleteLivePackageOriginEndpointResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLivePackageOriginEndpointResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * This API operation is used to delete an origin endpoint associated with a live package channel by specifying `GroupName`, `ChannelName`, and `EndpointName`. This operation will permanently delete the relevant configurations. Exercise caution when you perform this operation.
  * @param request  the request parameters of DeleteLivePackageOriginEndpoint  DeleteLivePackageOriginEndpointRequest
  * @return DeleteLivePackageOriginEndpointResponse
 */
async function deleteLivePackageOriginEndpoint(request: DeleteLivePackageOriginEndpointRequest): DeleteLivePackageOriginEndpointResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLivePackageOriginEndpoint', 'POST', '/', 'json', false, 'json', request);
}

model DeleteLiveRecordFilesRequest {
  recordIds: [ string ](name='RecordIds', description='The collection of IDs of recording files.

This parameter is required.', position='Query'),
  removeFile?: boolean(name='RemoveFile', description='Specifies whether to delete the original files in OSS.', example='true', position='Query'),
}

model DeleteLiveRecordFilesResponseBody = {
  deleteFileInfoList?: [ 
    {
      code?: string(name='Code', description='The code that identifies the result of the deletion.', example='OK'),
      message?: string(name='Message', description='The result of deletion.', example='OK'),
      recordId?: string(name='RecordId', description='The ID of the deleted recording file.', example='13cbb83e-043c-4728-ac35-*****'),
    }
  ](name='DeleteFileInfoList', description='The list of files deleted.'),
  message?: string(name='Message', description='The description of the state returned.', example='OK'),
  requestId?: string(name='RequestId', description='Id of the request', example='13cbb83e-043c-4728-ac35-*****'),
}

model DeleteLiveRecordFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveRecordFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLiveRecordFiles  DeleteLiveRecordFilesRequest
  * @return DeleteLiveRecordFilesResponse
 */
async function deleteLiveRecordFiles(request: DeleteLiveRecordFilesRequest): DeleteLiveRecordFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLiveRecordFiles', 'POST', '/', 'json', false, 'json', request);
}

model DeleteLiveRecordTemplateRequest {
  templateId: string(name='TemplateId', description='The ID of the template to be deleted. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ice.console.aliyun.com/live-processing/template/list/record), choose Real-time Media Processing > Template Management, and then click the Recording tab. Alternatively, find the ID from the response parameters of the [CreateLiveRecordTemplate](https://help.aliyun.com/document_detail/448213.html) operation.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66', position='Query'),
}

model DeleteLiveRecordTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='3E5330CF-B4C8-5BEF-AA6B-8E70BD20FAEE'),
}

model DeleteLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveRecordTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLiveRecordTemplate  DeleteLiveRecordTemplateRequest
  * @return DeleteLiveRecordTemplateResponse
 */
async function deleteLiveRecordTemplate(request: DeleteLiveRecordTemplateRequest): DeleteLiveRecordTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLiveRecordTemplate', 'POST', '/', 'json', false, 'json', request);
}

model DeleteLiveSnapshotFilesRequest {
  createTimestampList: [ long ](name='CreateTimestampList', description='The list of timestamps when the jobs were created. The values are UNIX timestamps representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC. A maximum of 200 jobs can be deleted at a time.

This parameter is required.', shrink='json', position='Query'),
  deleteOriginalFile?: boolean(name='DeleteOriginalFile', description='Specifies whether to delete the original files at the same time. Default value: false.', example='true', position='Query'),
  jobId: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Query'),
}

model DeleteLiveSnapshotFilesResponseBody = {
  deleteFileResultList?: [ 
    {
      createTimestamp?: long(name='CreateTimestamp', description='The time when the file was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1660638613798'),
      result?: string(name='Result', description='The result of deletion. A value of OK indicates that the file is deleted. Other values indicate that the file failed to be deleted.

Valid values:

*   OK: The file was deleted.
*   NotFound: The file was not found.', example='OK'),
    }
  ](name='DeleteFileResultList', description='The list of deleted files.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
}

model DeleteLiveSnapshotFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveSnapshotFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLiveSnapshotFiles  DeleteLiveSnapshotFilesRequest
  * @return DeleteLiveSnapshotFilesResponse
 */
async function deleteLiveSnapshotFiles(request: DeleteLiveSnapshotFilesRequest): DeleteLiveSnapshotFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLiveSnapshotFiles', 'POST', '/', 'json', false, 'json', request);
}

model DeleteLiveSnapshotTemplateRequest {
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Body'),
}

model DeleteLiveSnapshotTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveSnapshotTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLiveSnapshotTemplate  DeleteLiveSnapshotTemplateRequest
  * @return DeleteLiveSnapshotTemplateResponse
 */
async function deleteLiveSnapshotTemplate(request: DeleteLiveSnapshotTemplateRequest): DeleteLiveSnapshotTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLiveSnapshotTemplate', 'POST', '/', 'json', true, 'form', request);
}

model DeleteLiveTranscodeJobRequest {
  jobId: string(name='JobId', description='The ID of the transcoding job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model DeleteLiveTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model DeleteLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveTranscodeJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLiveTranscodeJob  DeleteLiveTranscodeJobRequest
  * @return DeleteLiveTranscodeJobResponse
 */
async function deleteLiveTranscodeJob(request: DeleteLiveTranscodeJobRequest): DeleteLiveTranscodeJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLiveTranscodeJob', 'POST', '/', 'json', false, 'json', request);
}

model DeleteLiveTranscodeTemplateRequest {
  templateId: string(name='TemplateId', description='The template ID. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ice.console.aliyun.com/summary), choose Real-time Media Processing > Template Management, and then click the Transcoding tab. Alternatively, find the ID from the response parameters of the [CreateLiveTranscodeTemplate](https://help.aliyun.com/document_detail/449217.html) operation.

This parameter is required.', example='****d80e4e4044975745c14b****', position='Query'),
}

model DeleteLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model DeleteLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveTranscodeTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLiveTranscodeTemplate  DeleteLiveTranscodeTemplateRequest
  * @return DeleteLiveTranscodeTemplateResponse
 */
async function deleteLiveTranscodeTemplate(request: DeleteLiveTranscodeTemplateRequest): DeleteLiveTranscodeTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLiveTranscodeTemplate', 'POST', '/', 'json', false, 'json', request);
}

model DeleteMediaConnectFlowRequest {
  flowId: string(name='FlowId', description='The flow ID.

This parameter is required.', example='0381f478-7d53-4076-9d5f-27680a6f73e7', position='Query'),
}

model DeleteMediaConnectFlowResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='5AEC17BD-D80B-5F78-BE1B-F07DFA0C8622'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of `0` indicates the call is successful.', example='0'),
}

model DeleteMediaConnectFlowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaConnectFlowResponseBody(name='body'),
}

/**
  * @description *   When the specified flow ID is not available, an error code is returned.
  * *   When a flow is deleted, its source and outputs are also deleted.
  * *   When a flow is in the online state, it cannot be deleted.
  * @param request  the request parameters of DeleteMediaConnectFlow  DeleteMediaConnectFlowRequest
  * @return DeleteMediaConnectFlowResponse
 */
async function deleteMediaConnectFlow(request: DeleteMediaConnectFlowRequest): DeleteMediaConnectFlowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMediaConnectFlow', 'POST', '/', 'json', false, 'json', request);
}

model DeleteMediaConnectFlowInputRequest {
  flowId: string(name='FlowId', description='The flow ID.

This parameter is required.', example='0381f478-7d53-4076-9d5f-27680a6f73e7', position='Query'),
  inputName?: string(name='InputName', position='Query'),
}

model DeleteMediaConnectFlowInputResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='C0C02296-113C-5838-8FE9-8F3A32998DDC'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model DeleteMediaConnectFlowInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaConnectFlowInputResponseBody(name='body'),
}

/**
  * @description *   When the specified flow ID is not available, an error code is returned.
  * *   When a flow is in the online state, its source cannot be deleted.
  * *   You can delete the source only after all outputs of the flow have been deleted.
  * @param request  the request parameters of DeleteMediaConnectFlowInput  DeleteMediaConnectFlowInputRequest
  * @return DeleteMediaConnectFlowInputResponse
 */
async function deleteMediaConnectFlowInput(request: DeleteMediaConnectFlowInputRequest): DeleteMediaConnectFlowInputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMediaConnectFlowInput', 'POST', '/', 'json', false, 'json', request);
}

model DeleteMediaConnectFlowOutputRequest {
  flowId: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f', position='Query'),
  outputName: string(name='OutputName', description='The name of the output that you want to delete.

This parameter is required.', example='AliTestOutput', position='Query'),
}

model DeleteMediaConnectFlowOutputResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='DF73E08E-F807-50F5-A2BD-B76391EAE8FF'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model DeleteMediaConnectFlowOutputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaConnectFlowOutputResponseBody(name='body'),
}

/**
  * @description *   When the specified flow ID is not available, an error code is returned.
  * *   When a flow is in the online state, its outputs cannot be deleted.
  * @param request  the request parameters of DeleteMediaConnectFlowOutput  DeleteMediaConnectFlowOutputRequest
  * @return DeleteMediaConnectFlowOutputResponse
 */
async function deleteMediaConnectFlowOutput(request: DeleteMediaConnectFlowOutputRequest): DeleteMediaConnectFlowOutputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMediaConnectFlowOutput', 'POST', '/', 'json', false, 'json', request);
}

model DeleteMediaFromSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  msgBody?: string(name='MsgBody', description='The message body.', example='{}', position='Query'),
  namespace?: string(name='Namespace', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1', position='Query'),
}

model DeleteMediaFromSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteMediaFromSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaFromSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteMediaFromSearchLib  DeleteMediaFromSearchLibRequest
  * @return DeleteMediaFromSearchLibResponse
 */
async function deleteMediaFromSearchLib(request: DeleteMediaFromSearchLibRequest): DeleteMediaFromSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMediaFromSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model DeleteMediaInfosRequest {
  regionId?: string(name='RegionId', position='Host'),
  deletePhysicalFiles?: boolean(name='DeletePhysicalFiles', description='Specifies whether to delete the physical file of the media asset.

If the media asset is stored in your own OSS bucket, you must authorize the service role AliyunICEDefaultRole in advance. For more information<props="china">, see [Authorize IMS to delete recording files in OSS](https://help.aliyun.com/zh/ims/user-guide/record?spm=a2c4g.11186623.0.i8#0737d9c437bmn).', example='false', position='Query'),
  inputURLs?: string(name='InputURLs', description='The URL of the media asset that you want to delete. The file corresponding to the URL must be registered with IMS. Separate multiple URLs with commas (,). The following two formats are supported:

1.  http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?
2.  OSS://example-bucket/example.mp4?\\
    In this format, it is considered by default that the region of the OSS bucket in which the media asset resides is the same as the region in which IMS is activated.', position='Query'),
  mediaIds?: string(name='MediaIds', description='The ID of the media asset that you want to delete from Intelligent Media Services (IMS).

*   Separate multiple IDs with commas (,).

If you leave MediaIds empty, you must specify InputURLs.', example='****20b48fb04483915d4f2cd8ac****,****15d4a4b0448391508f2cb486****', position='Query'),
}

model DeleteMediaInfosResponseBody = {
  forbiddenList?: [ string ](name='ForbiddenList', description='The IDs or URLs of media assets that cannot be deleted. Generally, media assets cannot be deleted if you do not have the required permissions.'),
  ignoredList?: [ string ](name='IgnoredList', description='The IDs or URLs of ignored media assets. An error occurred while obtaining such media assets.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
}

model DeleteMediaInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaInfosResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteMediaInfos  DeleteMediaInfosRequest
  * @return DeleteMediaInfosResponse
 */
async function deleteMediaInfos(request: DeleteMediaInfosRequest): DeleteMediaInfosResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMediaInfos', 'POST', '/', 'json', false, 'json', request);
}

model DeleteMediaLiveChannelRequest {
  channelId: string(name='ChannelId', description='The ID of the channel.

This parameter is required.', example='SEGK5KA6KYKAWQQH', position='Body'),
}

model DeleteMediaLiveChannelResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteMediaLiveChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaLiveChannelResponseBody(name='body'),
}

/**
  * @description *  You can only delete a channel that is not running.
  * ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of DeleteMediaLiveChannel  DeleteMediaLiveChannelRequest
  * @return DeleteMediaLiveChannelResponse
 */
async function deleteMediaLiveChannel(request: DeleteMediaLiveChannelRequest): DeleteMediaLiveChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMediaLiveChannel', 'POST', '/', 'json', true, 'form', request);
}

model DeleteMediaLiveInputRequest {
  inputId: string(name='InputId', description='The ID of the input.

This parameter is required.', example='SEGK5KA6KYKAWQQH', position='Body'),
}

model DeleteMediaLiveInputResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteMediaLiveInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaLiveInputResponseBody(name='body'),
}

/**
  * @description *   You can delete an input only when it is not associated with a MediaLive channel.
  * ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of DeleteMediaLiveInput  DeleteMediaLiveInputRequest
  * @return DeleteMediaLiveInputResponse
 */
async function deleteMediaLiveInput(request: DeleteMediaLiveInputRequest): DeleteMediaLiveInputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMediaLiveInput', 'POST', '/', 'json', true, 'form', request);
}

model DeleteMediaLiveInputSecurityGroupRequest {
  securityGroupId: string(name='SecurityGroupId', description='The ID of the security group.

This parameter is required.', example='SEGK5KA6KYKAWQQH', position='Body'),
}

model DeleteMediaLiveInputSecurityGroupResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteMediaLiveInputSecurityGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaLiveInputSecurityGroupResponseBody(name='body'),
}

/**
  * @description *   You can only delete a security group not associated with an input.
  * ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of DeleteMediaLiveInputSecurityGroup  DeleteMediaLiveInputSecurityGroupRequest
  * @return DeleteMediaLiveInputSecurityGroupResponse
 */
async function deleteMediaLiveInputSecurityGroup(request: DeleteMediaLiveInputSecurityGroupRequest): DeleteMediaLiveInputSecurityGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMediaLiveInputSecurityGroup', 'POST', '/', 'json', true, 'form', request);
}

model DeleteMediaMarksRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****c469e944b5a856828dc2****', position='Query'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The mark ID. You can specify multiple mark IDs separated with commas (,).

If you do not specify MediaMarkIds, all the marks of the media asset are deleted.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60', position='Query'),
}

model DeleteMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The IDs of the deleted marks separated with commas (,).', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaMarksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteMediaMarks  DeleteMediaMarksRequest
  * @return DeleteMediaMarksResponse
 */
async function deleteMediaMarks(request: DeleteMediaMarksRequest): DeleteMediaMarksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMediaMarks', 'POST', '/', 'json', false, 'json', request);
}

model DeletePipelineRequest {
  pipelineId: string(name='PipelineId', description='The ID of the MPS queue.

This parameter is required.', example='****96e8864746a0b6f3****', position='Query'),
}

model DeletePipelineResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeletePipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeletePipelineResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeletePipeline  DeletePipelineRequest
  * @return DeletePipelineResponse
 */
async function deletePipeline(request: DeletePipelineRequest): DeletePipelineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeletePipeline', 'POST', '/', 'json', false, 'json', request);
}

model DeletePlayInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  deletePhysicalFiles?: boolean(name='DeletePhysicalFiles', description='Specifies whether to delete the physical file of the media stream.

If the media asset is stored in your own Object Storage Service (OSS) bucket, you must authorize the service role AliyunICEDefaultRole in advance. <props="china">For more information, see [Authorize IMS to delete recording files in OSS](https://help.aliyun.com/document_detail/449331.html#p-ko2-wc7-iad).

You can delete only the physical files of transcoded streams, but not the physical files of source files.', example='false', position='Query'),
  fileURLs?: string(name='FileURLs', description='The URL of the media stream file that you want to delete. Separate multiple URLs with commas (,).', example='https://ice-test001.oss-cn-shanghai.aliyuncs.com/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95/%E5%B0%8F%E7%8C%AA%E4%BD%A9%E5%A5%87640*360.mp4', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='1d3518e0027d71ed80cd909598416303', position='Query'),
}

model DeletePlayInfoResponseBody = {
  forbiddenList?: [ string ](name='ForbiddenList', description='The URLs of the media streams that cannot be deleted. Generally, media streams cannot be deleted if you do not have the required permissions.'),
  ignoredList?: [ string ](name='IgnoredList', description='The URLs of ignored media streams. An error occurred while obtaining such media assets because the IDs or URLs of the media assets do not exist.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeletePlayInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeletePlayInfoResponseBody(name='body'),
}

/**
  * @description You can call this operation to delete multiple media streams at a time.
  * @param request  the request parameters of DeletePlayInfo  DeletePlayInfoRequest
  * @return DeletePlayInfoResponse
 */
async function deletePlayInfo(request: DeletePlayInfoRequest): DeletePlayInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeletePlayInfo', 'POST', '/', 'json', false, 'json', request);
}

model DeleteProgramRequest {
  channelName: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel', position='Query'),
  programName: string(name='ProgramName', description='The name of the program.

This parameter is required.', example='program_name', position='Query'),
}

model DeleteProgramResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteProgramResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteProgramResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteProgram  DeleteProgramRequest
  * @return DeleteProgramResponse
 */
async function deleteProgram(request: DeleteProgramRequest): DeleteProgramResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteProgram', 'POST', '/', 'json', false, 'json', request);
}

model DeleteRecognitionEntityRequest {
  algorithm: string(name='Algorithm', description='The type of recognition algorithm associated with the entity. Valid values:

*   landmark
*   object
*   logo
*   face
*   label

This parameter is required.', example='landmark', position='Query'),
  entityId: string(name='EntityId', description='The ID of the entity to be deleted.

This parameter is required.', example='**************544cb84754************', position='Query'),
  libId: string(name='LibId', description='The ID of the recognition library.

This parameter is required.', example='*************24b47865c6**************', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model DeleteRecognitionEntityResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteRecognitionEntityResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteRecognitionEntityResponseBody(name='body'),
}

/**
  * @description *   This operation is supported only in the China (Beijing), China (Shanghai), China (Hangzhou), and China (Shenzhen) regions.
  * *   You can call this operation up to 50 times per second per account. Requests that exceed this limit are dropped and you may experience service interruptions. For more information, see [QPS limits](https://help.aliyun.com/zh/mps/developer-reference/qps-limits?spm=a2c4g.11186623.0.0.647e1081YGcerb).
  * @param request  the request parameters of DeleteRecognitionEntity  DeleteRecognitionEntityRequest
  * @return DeleteRecognitionEntityResponse
 */
async function deleteRecognitionEntity(request: DeleteRecognitionEntityRequest): DeleteRecognitionEntityResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteRecognitionEntity', 'POST', '/', 'json', false, 'json', request);
}

model DeleteRecognitionLibRequest {
  algorithm: string(name='Algorithm', description='The type of recognition algorithm. Valid values:

*   landmark
*   object
*   logo
*   face
*   label

This parameter is required.', example='landmark', position='Query'),
  libId: string(name='LibId', description='The ID of the recognition library.

This parameter is required.', example='*************24b47865c6**************', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model DeleteRecognitionLibResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteRecognitionLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteRecognitionLibResponseBody(name='body'),
}

/**
  * @description *   This operation is supported only in the China (Beijing), China (Shanghai), China (Hangzhou), and China (Shenzhen) regions.
  * *   You can call this operation up to 50 times per second per account. Requests that exceed this limit are dropped and you may experience service interruptions. For more information, see [QPS limits](https://help.aliyun.com/zh/mps/developer-reference/qps-limits?spm=a2c4g.11186623.0.0.647e1081YGcerb).
  * @param request  the request parameters of DeleteRecognitionLib  DeleteRecognitionLibRequest
  * @return DeleteRecognitionLibResponse
 */
async function deleteRecognitionLib(request: DeleteRecognitionLibRequest): DeleteRecognitionLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteRecognitionLib', 'POST', '/', 'json', false, 'json', request);
}

model DeleteRecognitionSampleRequest {
  algorithm: string(name='Algorithm', description='The type of recognition algorithm. Valid values:

*   landmark
*   object
*   logo
*   face
*   label

This parameter is required.', example='landmark', position='Query'),
  entityId: string(name='EntityId', description='The ID of the entity.

This parameter is required.', example='**************544cb84754************', position='Query'),
  libId: string(name='LibId', description='The ID of the recognition library.

This parameter is required.', example='*************24b47865c6**************', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  sampleId: string(name='SampleId', description='The ID of the sample that you want to delete.

This parameter is required.', example='**************4d2ba728e2f**************', position='Query'),
}

model DeleteRecognitionSampleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteRecognitionSampleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteRecognitionSampleResponseBody(name='body'),
}

/**
  * @description *   This operation is supported only in the China (Beijing), China (Shanghai), China (Hangzhou), and China (Shenzhen) regions.
  * *   You can call this operation up to 50 times per second per account. Requests that exceed this limit are dropped and you may experience service interruptions. For more information, see [QPS limits](https://help.aliyun.com/zh/mps/developer-reference/qps-limits?spm=a2c4g.11186623.0.0.647e1081YGcerb).
  * @param request  the request parameters of DeleteRecognitionSample  DeleteRecognitionSampleRequest
  * @return DeleteRecognitionSampleResponse
 */
async function deleteRecognitionSample(request: DeleteRecognitionSampleRequest): DeleteRecognitionSampleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteRecognitionSample', 'POST', '/', 'json', false, 'json', request);
}

model DeleteSmartJobRequest {
  jobId?: string(name='JobId', description='The IDs of the jobs to delete. Separate multiple IDs with commas (,).', example='******b48fb04483915d4f2cd8******,******042d5e4db6866f6289d1******', position='Query'),
}

model DeleteSmartJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteSmartJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteSmartJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteSmartJob  DeleteSmartJobRequest
  * @return DeleteSmartJobResponse
 */
async function deleteSmartJob(request: DeleteSmartJobRequest): DeleteSmartJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteSmartJob', 'POST', '/', 'json', false, 'json', request);
}

model DeleteSourceRequest {
  softDelete?: boolean(name='SoftDelete', description='Specifies whether to use delete markers.', example='true', position='Query'),
  sourceLocationName: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourceLocation', position='Query'),
  sourceName: string(name='SourceName', description='The name of the source.

This parameter is required.', example='MyVodSource', position='Query'),
  sourceType: string(name='SourceType', description='The source type. Valid values: vodSource and liveSource.

This parameter is required.', example='vodSource', position='Query'),
}

model DeleteSourceResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteSourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteSource  DeleteSourceRequest
  * @return DeleteSourceResponse
 */
async function deleteSource(request: DeleteSourceRequest): DeleteSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteSource', 'POST', '/', 'json', false, 'json', request);
}

model DeleteSourceLocationRequest {
  softDelete?: boolean(name='SoftDelete', description='Specifies whether to use delete markers.', example='true', position='Query'),
  sourceLocationName: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourceLocation', position='Query'),
}

model DeleteSourceLocationResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid value:

*   true: The request succeeded.
*   false: The request failed.', example='true'),
}

model DeleteSourceLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteSourceLocationResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteSourceLocation  DeleteSourceLocationRequest
  * @return DeleteSourceLocationResponse
 */
async function deleteSourceLocation(request: DeleteSourceLocationRequest): DeleteSourceLocationResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteSourceLocation', 'POST', '/', 'json', false, 'json', request);
}

model DeleteTemplateRequest {
  templateIds?: string(name='TemplateIds', description='The IDs of the templates that you want to delete. Separate multiple IDs with commas (,).', example='****20b48fb04483915d4f2cd8ac****,****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model DeleteTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteTemplateResponseBody(name='body'),
}

/**
  * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
  * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
  * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
  * @param request  the request parameters of DeleteTemplate  DeleteTemplateRequest
  * @return DeleteTemplateResponse
 */
async function deleteTemplate(request: DeleteTemplateRequest): DeleteTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteTemplate', 'GET', '/', 'json', false, 'json', request);
}

model DeleteVodPackagingAssetRequest {
  assetName?: string(name='AssetName', description='The name of the VOD packaging asset.', example='30min_movie', position='Query'),
}

model DeleteVodPackagingAssetResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteVodPackagingAssetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteVodPackagingAssetResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteVodPackagingAsset  DeleteVodPackagingAssetRequest
  * @return DeleteVodPackagingAssetResponse
 */
async function deleteVodPackagingAsset(request: DeleteVodPackagingAssetRequest): DeleteVodPackagingAssetResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteVodPackagingAsset', 'POST', '/', 'json', false, 'json', request);
}

model DeleteVodPackagingConfigurationRequest {
  configurationName?: string(name='ConfigurationName', description='The name of the packaging configuration.', example='hls_3s', position='Query'),
}

model DeleteVodPackagingConfigurationResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteVodPackagingConfigurationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteVodPackagingConfigurationResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteVodPackagingConfiguration  DeleteVodPackagingConfigurationRequest
  * @return DeleteVodPackagingConfigurationResponse
 */
async function deleteVodPackagingConfiguration(request: DeleteVodPackagingConfigurationRequest): DeleteVodPackagingConfigurationResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteVodPackagingConfiguration', 'POST', '/', 'json', false, 'json', request);
}

model DeleteVodPackagingGroupRequest {
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls', position='Query'),
}

model DeleteVodPackagingGroupResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='13cbb83e-043c-4728-ac35-*****'),
}

model DeleteVodPackagingGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteVodPackagingGroupResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteVodPackagingGroup  DeleteVodPackagingGroupRequest
  * @return DeleteVodPackagingGroupResponse
 */
async function deleteVodPackagingGroup(request: DeleteVodPackagingGroupRequest): DeleteVodPackagingGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteVodPackagingGroup', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAIAgentInstanceRequest {
  instanceId: string(name='InstanceId', description='The ID of the AI agent that you want to query.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
}

model DescribeAIAgentInstanceResponseBody = {
  instance?: {
    agentConfig?: AIAgentConfig(name='AgentConfig'),
    callLogUrl?: string(name='CallLogUrl', description='The URL of the call log file.', example='https://example.com/call_logs/12345'),
    gmtCreate?: string(name='GmtCreate'),
    gmtModified?: string(name='GmtModified'),
    runtimeConfig?: AIAgentRuntimeConfig(name='RuntimeConfig', description='The runtime configurations of the AI agent.', example='{"VoiceChat":{"AgentUserId":"voice_agent_001","ChannelId":"voice_channel_001","AuthToken":"your_voice_chat_auth_token"}}'),
    sessionId?: string(name='SessionId'),
    status?: string(name='Status', description='The state of the AI agent. Valid values: Finished and Executing.', example='Finished'),
    templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', description='The template configurations of the AI agent.', example='{"VoiceChat": {"AppId": "your_voice_chat_app_id"}}', deprecated='true'),
    userData?: string(name='UserData', description='The custom information.', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
  }(name='Instance', description='The information about the AI agent.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model DescribeAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAIAgentInstanceResponseBody(name='body'),
}

/**
  * @description ## [](#)Request description
  * *   **Feature**: You can call this operation to query the information about an AI agent.
  * *   **Scenario**: If you need to monitor or analyze the performance of an AI agent in a call or debug the agent configurations, you can call this operation to obtain required data.
  * @param request  the request parameters of DescribeAIAgentInstance  DescribeAIAgentInstanceRequest
  * @return DescribeAIAgentInstanceResponse
 */
async function describeAIAgentInstance(request: DescribeAIAgentInstanceRequest): DescribeAIAgentInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAIAgentInstance', 'POST', '/', 'json', false, 'json', request);
}

model DescribeMeterImsEditUsageRequest {
  endTs: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1656995036', position='Query'),
  interval: long(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='86400', position='Query'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai', position='Query'),
  startTs: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1654403036', position='Query'),
}

model DescribeMeterImsEditUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='1.23'),
      profile?: string(name='Profile', description='The video profile.', example='1080P'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
    }
  ](name='Data', description='The usage statistics of IMS on VOD editing.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7F3AE2C6-5CC6-5712-BAC5-5A735A157687'),
}

model DescribeMeterImsEditUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsEditUsageResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeMeterImsEditUsage  DescribeMeterImsEditUsageRequest
  * @return DescribeMeterImsEditUsageResponse
 */
async function describeMeterImsEditUsage(request: DescribeMeterImsEditUsageRequest): DescribeMeterImsEditUsageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeMeterImsEditUsage', 'POST', '/', 'json', false, 'json', request);
}

model DescribeMeterImsMediaConvertUHDUsageRequest {
  endTs: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1656995036', position='Query'),
  interval: string(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='3600', position='Query'),
  regionId?: string(name='RegionId', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai', position='Query'),
  startTs: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1654403036', position='Query'),
}

model DescribeMeterImsMediaConvertUHDUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='308028'),
      specification?: string(name='Specification', description='The transcoding specifications.', example='SuperResolution.Standard.1080P'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
    }
  ](name='Data', description='The usage statistics of IMS on UHD transcoding of MPS.'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
}

model DescribeMeterImsMediaConvertUHDUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsMediaConvertUHDUsageResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeMeterImsMediaConvertUHDUsage  DescribeMeterImsMediaConvertUHDUsageRequest
  * @return DescribeMeterImsMediaConvertUHDUsageResponse
 */
async function describeMeterImsMediaConvertUHDUsage(request: DescribeMeterImsMediaConvertUHDUsageRequest): DescribeMeterImsMediaConvertUHDUsageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeMeterImsMediaConvertUHDUsage', 'POST', '/', 'json', false, 'json', request);
}

model DescribeMeterImsMediaConvertUsageRequest {
  endTs: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp. The maximum query range is 31 days. The duration between StartTs and EndTs cannot exceed 31 days.

This parameter is required.', example='1656995036', position='Query'),
  interval: long(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='86400', position='Query'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai', position='Query'),
  startTs: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp. You can query data within the last 90 days.

This parameter is required.', example='1654403036', position='Query'),
}

model DescribeMeterImsMediaConvertUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='20'),
      specification?: string(name='Specification', description='The transcoding specifications.', example='H264.HD'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
    }
  ](name='Data', description='The usage statistics of IMS on VOD transcoding.'),
  requestId?: string(name='RequestId', description='The request ID.', example='FBBB5210-2B78-58FB-A6FE-9DD887BB2C61'),
}

model DescribeMeterImsMediaConvertUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsMediaConvertUsageResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeMeterImsMediaConvertUsage  DescribeMeterImsMediaConvertUsageRequest
  * @return DescribeMeterImsMediaConvertUsageResponse
 */
async function describeMeterImsMediaConvertUsage(request: DescribeMeterImsMediaConvertUsageRequest): DescribeMeterImsMediaConvertUsageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeMeterImsMediaConvertUsage', 'POST', '/', 'json', false, 'json', request);
}

model DescribeMeterImsMpsAiUsageRequest {
  endTs: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp. The maximum query range is 31 days. The duration between StartTs and EndTs cannot exceed 31 days.

This parameter is required.', example='1656995036', position='Query'),
  interval: long(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='86400', position='Query'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai', position='Query'),
  startTs: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp. You can query data within the last 90 days.

This parameter is required.', example='1654403036', position='Query'),
}

model DescribeMeterImsMpsAiUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='644'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
      type?: string(name='Type', description='The AI type. Valid values:'),
    }
  ](name='Data', description='The usage statistics of IMS on AI processing of MPS.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
}

model DescribeMeterImsMpsAiUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsMpsAiUsageResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeMeterImsMpsAiUsage  DescribeMeterImsMpsAiUsageRequest
  * @return DescribeMeterImsMpsAiUsageResponse
 */
async function describeMeterImsMpsAiUsage(request: DescribeMeterImsMpsAiUsageRequest): DescribeMeterImsMpsAiUsageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeMeterImsMpsAiUsage', 'POST', '/', 'json', false, 'json', request);
}

model DescribeMeterImsSummaryRequest {
  endTs: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1656995036', position='Query'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai', position='Query'),
  startTs: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1654403036', position='Query'),
}

model DescribeMeterImsSummaryResponseBody = {
  data?: [ 
    {
      editingDuration?: string(name='EditingDuration', description='The duration of video editing.', example='8722'),
      liveEditDuration?: string(name='LiveEditDuration', description='The duration of live editing.', example='2000'),
      liveRecordDuration?: string(name='LiveRecordDuration', description='The duration of live stream recording.', example='100'),
      liveSnapshotCount?: string(name='LiveSnapshotCount', description='The number of live stream snapshots.', example='100'),
      liveTranscodeDuration?: long(name='LiveTranscodeDuration', description='The duration of live stream transcoding.', example='12356'),
      mpsAiDuration?: long(name='MpsAiDuration', description='The duration of AI processing.', example='0'),
      mpsTranscodeDuration?: long(name='MpsTranscodeDuration', description='The duration of video-on-demand (VOD) transcoding.', example='17337'),
      mpsTranscodeUHDDuration?: long(name='MpsTranscodeUHDDuration', description='The duration of audio and video enhancement.', example='300'),
    }
  ](name='Data', description='The usage statistics of IMS.'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
}

model DescribeMeterImsSummaryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsSummaryResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeMeterImsSummary  DescribeMeterImsSummaryRequest
  * @return DescribeMeterImsSummaryResponse
 */
async function describeMeterImsSummary(request: DescribeMeterImsSummaryRequest): DescribeMeterImsSummaryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeMeterImsSummary', 'POST', '/', 'json', false, 'json', request);
}

model DescribeNotifyConfigRequest {
  AIAgentId: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
}

model DescribeNotifyConfigResponseBody = {
  audioOssPath?: string(name='AudioOssPath'),
  callbackUrl?: string(name='CallbackUrl', example='http://customer.com/callback'),
  enableAudioRecording?: boolean(name='EnableAudioRecording'),
  enableNotify?: boolean(name='EnableNotify', example='true'),
  eventTypes?: string(name='EventTypes', description='The event types. If this parameter is empty, all event types are selected.

*   agent_start: The agent is started.
*   agent_stop: The agent is stopped.
*   error: An error occurred.', example='agent_start,agent_stop,error'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
  token?: string(name='Token', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx'),
}

model DescribeNotifyConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeNotifyConfigResponseBody(name='body'),
}

/**
  * @description You can call this operation to query the detailed callback configurations of an AI agent.
  * @param request  the request parameters of DescribeNotifyConfig  DescribeNotifyConfigRequest
  * @return DescribeNotifyConfigResponse
 */
async function describeNotifyConfig(request: DescribeNotifyConfigRequest): DescribeNotifyConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeNotifyConfig', 'POST', '/', 'json', false, 'json', request);
}

model DescribePlayListRequest {
  beginTs: string(name='BeginTs', description='The beginning of the time range to query. By default, the system queries data of the current day.

This parameter is required.', example='1676170500011', position='Query'),
  endTs: string(name='EndTs', description='The end of the time range to query. The time range cannot exceed 24 hours.

This parameter is required.', example='1682474405173', position='Query'),
  orderName?: string(name='OrderName', description='The criteria by which the sorting is performed. Valid values:

- FirstFrameDuration
- PlayDuration
- VideoDuration
- StuckDuration', example='FirstFrameDuration', position='Query'),
  orderType?: string(name='OrderType', description='The sort order. Valid values:

- DESC: descending order.
- ASC: ascending order.', example='DESC', position='Query'),
  pageNo: int32(name='PageNo', description='The page number. Default value: 1.

This parameter is required.', example='1', position='Query'),
  pageSize: int32(name='PageSize', description='The number of entries per page.

This parameter is required.', example='10', position='Query'),
  playType?: string(name='PlayType', description='The playback type. Valid value: 

- vod', example='vod', position='Query'),
  status?: string(name='Status', description='The playback status. Valid values:

- complete
- playing
- unusual: A playback error occurs.', example='complete', position='Query'),
  traceId?: string(name='TraceId', description='The TraceId of the player.', example='0bc5e70516766285805381012d271e', position='Query'),
}

model DescribePlayListResponseBody = {
  pageNum?: long(name='PageNum', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10'),
  playList?: [ 
    {
      firstFrameDuration?: string(name='FirstFrameDuration', description='Time to first frame.', example='200'),
      playDuration?: string(name='PlayDuration', description='The playback duration.', example='1000'),
      playTs?: string(name='PlayTs', description='The timestamp when the playback started.', example='1675922209572'),
      playType?: string(name='PlayType', description='The playback type.', example='vod'),
      sessionId?: string(name='SessionId', description='The ID of the player session.', example='91488be2-8381-40c9-8494-e8afe22c4a2d'),
      status?: string(name='Status', description='The playback status.', example='complete'),
      stuckDuration?: string(name='StuckDuration', description='The stuttering duration.', example='20'),
      traceId?: string(name='TraceId', description='The TraceId of the player.', example='0b736abf16724820210842673d9543'),
      videoDuration?: string(name='VideoDuration', description='The duration of the video.', example='2000'),
      videoId?: string(name='VideoId', description='The ID of the video.', example='250314203f0171eebff17035d0b20102'),
    }
  ](name='PlayList', description='The playback records.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='B960580D-26FA-5547-8AFC-3CDC812DBF27'),
  totalNum?: long(name='TotalNum', description='The total playback count.', example='49'),
}

model DescribePlayListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribePlayListResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribePlayList  DescribePlayListRequest
  * @return DescribePlayListResponse
 */
async function describePlayList(request: DescribePlayListRequest): DescribePlayListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribePlayList', 'POST', '/', 'json', false, 'json', request);
}

model DescribeRtcRobotInstanceRequest {
  instanceId?: string(name='InstanceId', example='727dc0e296014bb58670940a3da95592', position='Query'),
}

model DescribeRtcRobotInstanceResponseBody = {
  authToken?: string(name='AuthToken', example='**********'),
  channelId?: string(name='ChannelId', example='testId'),
  config?: {
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt', example='true'),
    greeting?: string(name='Greeting'),
    voiceId?: string(name='VoiceId', example='zhixiaoxia'),
  }(name='Config'),
  requestId?: string(name='RequestId', description='Id of the request', example='20B3A1B6-4BD2-5DE6-BCBC-098C9B4F4E91'),
  status?: string(name='Status', example='Executing'),
  userData?: string(name='UserData', example='{}'),
  userId?: string(name='UserId', example='my-robot'),
}

model DescribeRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeRtcRobotInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DescribeRtcRobotInstance  DescribeRtcRobotInstanceRequest
  * @return DescribeRtcRobotInstanceResponse
 */
async function describeRtcRobotInstance(request: DescribeRtcRobotInstanceRequest): DescribeRtcRobotInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeRtcRobotInstance', 'POST', '/', 'json', false, 'json', request);
}

model DetectAudioForCustomizedVoiceJobRequest {
  audioRecordId: int32(name='AudioRecordId', description='The sequence number of the recording file.

This parameter is required.', example='1', minimum=1, maximum=20, position='Query'),
  recordUrl: string(name='RecordUrl', description='The URL of the recording file.

> : The URL must be an Object Storage Service (OSS) URL within your Alibaba Cloud account. The OSS bucket must be in the same region in which IMS is activated.

> : The audio file must be in the WAV or PCM format and must be a 16-bit mono audio file at 48000 Hz.

This parameter is required.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/record1.wav', position='Query'),
  voiceId: string(name='VoiceId', description='The voice ID.

This parameter is required.', example='xiaozhuan', position='Query'),
}

model DetectAudioForCustomizedVoiceJobResponseBody = {
  data?: {
    pass?: boolean(name='Pass', description='Indicates whether the audio file passes the check. Valid values:

*   true
*   false', example='false'),
    reason?: string(name='Reason', description='The reason returned if the audio file failed to pass the check.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
}

model DetectAudioForCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DetectAudioForCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DetectAudioForCustomizedVoiceJob  DetectAudioForCustomizedVoiceJobRequest
  * @return DetectAudioForCustomizedVoiceJobResponse
 */
async function detectAudioForCustomizedVoiceJob(request: DetectAudioForCustomizedVoiceJobRequest): DetectAudioForCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DetectAudioForCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model DropSearchIndexRequest {
  regionId?: string(name='RegionId', position='Host'),
  indexType: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.

This parameter is required.', example='mm', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

*   If you leave this parameter empty, the search index is created in the default search library of Intelligent Media Service (IMS). Default value: ims-default-search-lib.
*   To query information about an existing search library, call the [QuerySearchLib](https://help.aliyun.com/document_detail/2584455.html) API operation.', example='test1', position='Query'),
}

model DropSearchIndexResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DropSearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DropSearchIndexResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DropSearchIndex  DropSearchIndexRequest
  * @return DropSearchIndexResponse
 */
async function dropSearchIndex(request: DropSearchIndexRequest): DropSearchIndexResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DropSearchIndex', 'POST', '/', 'json', false, 'json', request);
}

model DropSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  searchLibName: string(name='SearchLibName', description='The name of the search library.

This parameter is required.', example='test1', position='Query'),
}

model DropSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DropSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DropSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DropSearchLib  DropSearchLibRequest
  * @return DropSearchLibResponse
 */
async function dropSearchLib(request: DropSearchLibRequest): DropSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DropSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model ForbidMediaConnectFlowOutputRequest {
  flowId?: string(name='FlowId', description='The ID of the MediaConnect flow.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f', position='Query'),
  outputName?: string(name='OutputName', description='The name of the output.', example='AliTestOutput', position='Query'),
}

model ForbidMediaConnectFlowOutputResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The request ID.', example='1BCA0CFC-CBD4-5656-9D04-21B1FADBB92A'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model ForbidMediaConnectFlowOutputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ForbidMediaConnectFlowOutputResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ForbidMediaConnectFlowOutput  ForbidMediaConnectFlowOutputRequest
  * @return ForbidMediaConnectFlowOutputResponse
 */
async function forbidMediaConnectFlowOutput(request: ForbidMediaConnectFlowOutputRequest): ForbidMediaConnectFlowOutputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ForbidMediaConnectFlowOutput', 'POST', '/', 'json', false, 'json', request);
}

model ForwardAIAgentCallRequest {
  calledNumber?: string(name='CalledNumber', example='13**********', position='Query'),
  errorPrompt?: string(name='ErrorPrompt', position='Query'),
  instanceId?: string(name='InstanceId', example='call_instance_202******', position='Query'),
  transferPrompt?: string(name='TransferPrompt', position='Query'),
}

model ForwardAIAgentCallResponseBody = {
  requestId?: string(name='RequestId', example='550e8400********55440000'),
}

model ForwardAIAgentCallResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ForwardAIAgentCallResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ForwardAIAgentCall  ForwardAIAgentCallRequest
  * @return ForwardAIAgentCallResponse
 */
async function forwardAIAgentCall(request: ForwardAIAgentCallRequest): ForwardAIAgentCallResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ForwardAIAgentCall', 'POST', '/', 'json', false, 'json', request);
}

model GenerateAIAgentCallRequest {
  AIAgentId: string(name='AIAgentId', description='The ID of the AI agent.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
  agentConfig?: AIAgentConfig(name='AgentConfig', shrink='json', position='Query'),
  chatSyncConfig?: {
    IMAIAgentId?: string(name='IMAIAgentId', example='******005e4f309379701645f4****'),
    receiverId?: string(name='ReceiverId', example='4167626d312034b2b1c3b7f2f3e41884'),
  }(name='ChatSyncConfig', shrink='json', position='Query'),
  expire?: long(name='Expire', description='The time when the token expires. Unit: seconds. Default value: 3600. Valid values: 0 to 604800.', example='3600', position='Query'),
  sessionId?: string(name='SessionId', example='fw1gr0bc005e4f309379701645f4****', position='Query'),
  templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', description='The template configurations of the AI agent. The specified configurations are merged with the template configurations that are specified in the console. If you do not specify this parameter, the system uses the default configurations for an AI agent created in the console.', deprecated='true', shrink='json', position='Query'),
  userData?: string(name='UserData', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}', position='Query'),
  userId?: string(name='UserId', description='The username of the AI agent in the channel. If you do not specify this parameter, the system automatically generates a username. The value can be up to 64 characters in length.', example='877ae632caae49b1afc81c2e8194ffb4', position='Query'),
}

model GenerateAIAgentCallResponseBody = {
  AIAgentUserId?: string(name='AIAgentUserId', description='The username of the AI agent in the Alibaba Real-Time Communication (ARTC) channel.', example='877ae632caae49b1afc81c2e8194ffb4'),
  channelId?: string(name='ChannelId', description='The ARTC channel ID.', example='70f22d5784194938a7e387052f2b3208'),
  instanceId?: string(name='InstanceId', description='The ID of the AI agent.', example='39f8e0bc005e4f309379701645f4****'),
  requestId?: string(name='RequestId', description='The request ID.', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
  token?: string(name='Token', description='The ARTC token of the client.', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx'),
  userId?: string(name='UserId', description='The username in the ARTC channel.', example='user123'),
}

model GenerateAIAgentCallResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GenerateAIAgentCallResponseBody(name='body'),
}

/**
  * @description ## [](#)Request description
  * You can call this operation to create an AI agent based on the provided ID. You can join the channel based on the returned information and talk to the agent.
  * **Note:** Make sure that the provided AI agent ID is valid and configure optional parameters based on your business requirements.
  * @param request  the request parameters of GenerateAIAgentCall  GenerateAIAgentCallRequest
  * @return GenerateAIAgentCallResponse
 */
async function generateAIAgentCall(request: GenerateAIAgentCallRequest): GenerateAIAgentCallResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GenerateAIAgentCall', 'POST', '/', 'json', false, 'json', request);
}

model GenerateKMSDataKeyRequest {
}

model GenerateKMSDataKeyResponseBody = {
  dataKey?: {
    ciphertextBlob?: string(name='CiphertextBlob', description='The ciphertext of the encrypted data key. This parameter is used as CipherText when you create a transcoding job.', example='ODZhOWVmZDktM2QxNi00ODk0LWJkNGYtMWZjNDNmM2YyYWJmS7FmDBBQ0BkKsQrtRnidtPwirmDcS0ZuJCU41xxAAWk4Z8qsADfbV0b+i6kQmlvj79dJdGOvtX69Uycs901qOjop4bTS****'),
    keyId?: string(name='KeyId', description='The ID of the customer master key (CMK). The ID must be globally unique.', example='7906979c-8e06-46a2-be2d-68e3ccbc****'),
    plaintext?: string(name='Plaintext', description='The Base64-encoded plaintext of the data key.', example='QmFzZTY0IGVuY29kZWQgcGxhaW50****'),
  }(name='DataKey', description='The information about the data key.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GenerateKMSDataKeyResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GenerateKMSDataKeyResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GenerateKMSDataKey  GenerateKMSDataKeyRequest
  * @return GenerateKMSDataKeyResponse
 */
async function generateKMSDataKey(request: GenerateKMSDataKeyRequest): GenerateKMSDataKeyResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GenerateKMSDataKey', 'POST', '/', 'json', false, 'json', request);
}

model GenerateMessageChatTokenRequest {
  AIAgentId: string(name='AIAgentId', description='The ID of the AI agent.

This parameter is required.', example='19de81b3b3d94abda22******', position='Query'),
  expire?: int32(name='Expire', description='The validity period. Unit: seconds. Default value: 3600.', example='3600', position='Query'),
  role?: string(name='Role', description='The role. A value of admin indicates that the user can perform management operations. This parameter is empty by default.', example='user', position='Query'),
  userId: string(name='UserId', description='The ID of the user to sign in. It can be up to 64 characters in length and can contain only letters, digits, and underscores (_).

This parameter is required.', example='YOURUSERID', position='Query'),
}

model GenerateMessageChatTokenResponseBody = {
  appId?: string(name='AppId', description='The AppID of the user.', example='***********'),
  appSign?: string(name='AppSign', description='The application signature.', example='H4sIAAAAAAAE******************'),
  nonce?: string(name='Nonce', description='The nonce used to generate the token.', example='AK-***********'),
  requestId?: string(name='RequestId', description='The request ID.', example='req_1234567890abcdef'),
  role?: string(name='Role', description='The role used to generate the token.', example='admin'),
  timeStamp?: long(name='TimeStamp', description='The expiration time. Unit: seconds. Expiration time = Current time + Validity period.', example='1700000000'),
  token?: string(name='Token', description='The generated token.', example='acet**********'),
  userId?: string(name='UserId', description='The ID of the user for joining the channel.', example='YOURUSERID'),
}

model GenerateMessageChatTokenResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GenerateMessageChatTokenResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GenerateMessageChatToken  GenerateMessageChatTokenRequest
  * @return GenerateMessageChatTokenResponse
 */
async function generateMessageChatToken(request: GenerateMessageChatTokenRequest): GenerateMessageChatTokenResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GenerateMessageChatToken', 'POST', '/', 'json', false, 'json', request);
}

model GetAIWorkflowTaskRequest {
  taskId?: string(name='TaskId', description='The ID of the workflow task.', example='********-266c-4bb8-b20c-6faa********', position='Query'),
}

model GetAIWorkflowTaskResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  workflowTask?: {
    createTime?: string(name='CreateTime', description='The time when the task was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2025-07-28T02:17:26Z'),
    finishTime?: string(name='FinishTime', description='The time when the task was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2025-08-19T02:28:22Z'),
    inputs?: string(name='Inputs', description='The input parameters of the workflow task.', example='{\\"source_language_id\\":\\"en\\",\\"live_id\\":123,\\"live_url\\":{\\"url\\":\\"rtmp://test.com.cn/video/638d9088fe4f15ce\\"}}'),
    nodeResults?: string(name='NodeResults', description='The results of the workflow nodes. The structure of this JSON varies based on the workflow\\"s configuration.', example='{...}'),
    outputs?: string(name='Outputs', description='The node output.', example='{
"result":"test"
}'),
    status?: string(name='Status', description='The task state.

Valid values:

*   running
*   stopped
*   failed
*   partial-succeeded
*   succeeded', example='succeeded'),
    taskId?: string(name='TaskId', description='The ID of the workflow task.', example='********-67fd-43aa-9cc1-3e7f********'),
    userData?: string(name='UserData', description='The user-defined data.', example='{"NotifyAddress":"http://xx.xx.xxx"}'),
    version?: string(name='Version', description='The version of the workflow template that was executed.', example='****ec0a-e3b9-40b1-abf2-6549d00e****'),
    workflow?: {
      createTime?: string(name='CreateTime', description='The time when the template was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2025-08-20T01:35:04Z'),
      graph?: string(name='Graph', description='The workflow\\"s topological structure.', example='{
"nodes":[...],
"edges":[...]
}'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2025-08-20T01:35:04Z'),
      name?: string(name='Name', description='The name of the workflow template.', example='RealtimeTranslation'),
      status?: string(name='Status', description='Workflow template status. Valid values:

*   Draft
*   Published
*   Editing', example='Draft'),
      type?: string(name='Type', description='The scenario type of the template.', example='Live'),
      version?: string(name='Version', description='The template version.', example='****ec0a-e3b9-40b1-abf2-6549d00e****'),
      workflowId?: string(name='WorkflowId', description='The ID of the workflow template.', example='****3f44-f1f6-477e-9364-c5e6c49e****'),
    }(name='Workflow', description='The workflow template information.'),
  }(name='WorkflowTask', description='The information about the workflow task.'),
}

model GetAIWorkflowTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAIWorkflowTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetAIWorkflowTask  GetAIWorkflowTaskRequest
  * @return GetAIWorkflowTaskResponse
 */
async function getAIWorkflowTask(request: GetAIWorkflowTaskRequest): GetAIWorkflowTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAIWorkflowTask', 'POST', '/', 'json', false, 'json', request);
}

model GetAdInsertionRequest {
  name: string(name='Name', description='The name of the ad insertion configuration that you want to query.

This parameter is required.', example='my_ad', position='Query'),
}

model GetAdInsertionResponseBody = {
  config?: {
    adMarkerPassthrough?: string(name='AdMarkerPassthrough', description='Indicates whether ad marker passthrough is enabled.', example='ON'),
    adsUrl?: string(name='AdsUrl', description='The URL of the ad decision server (ADS).', example='http://ads.com/ad1?param1=[palyer_params.p1]'),
    cdnConfig?: {
      adSegmentUrlPrefix?: string(name='AdSegmentUrlPrefix', description='The CDN prefix for accessing ad segments.', example='http://cdn.com/'),
      contentSegmentUrlPrefix?: string(name='ContentSegmentUrlPrefix', description='The CDN prefix for accessing content segments.', example='http://cdn.com/'),
    }(name='CdnConfig', description='The CDN configurations.'),
    configAliases?: string(name='ConfigAliases', description='The aliases for dynamic variable replacement.', example='{
      "player_params.p1": {
            "1": "abc"
      }
}'),
    contentUrlPrefix?: string(name='ContentUrlPrefix', description='The prefix of the source URL.', example='https://source.com/'),
    createTime?: string(name='CreateTime', description='The time when the configuration was created.', example='2024-06-13T08:26:09Z'),
    lastModified?: string(name='LastModified', description='The time when the configuration was last modified.', example='2024-06-13T08:26:09Z'),
    manifestEndpointConfig?: {
      dashPrefix?: string(name='DashPrefix', description='DASH清单播放端点前缀'),
      hlsPrefix?: string(name='HlsPrefix', description='The playback endpoint prefix for accessing HLS manifests.'),
    }(name='ManifestEndpointConfig', description='The playback endpoint prefix for accessing manifests.'),
    name?: string(name='Name', description='The name of the configuration.', example='my_ad'),
    personalizationThreshold?: int32(name='PersonalizationThreshold', description='The personalization threshold.', example='5'),
    slateAdUrl?: string(name='SlateAdUrl', description='The URL of the slate ad.', example='http://storage.com/slate1.mp4'),
  }(name='Config', description='The ad insertion configuration.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
}

model GetAdInsertionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAdInsertionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetAdInsertion  GetAdInsertionRequest
  * @return GetAdInsertionResponse
 */
async function getAdInsertion(request: GetAdInsertionRequest): GetAdInsertionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAdInsertion', 'POST', '/', 'json', false, 'json', request);
}

model GetAiRtcAuthCodeListRequest {
  licenseItemId?: string(name='LicenseItemId', example='17712***', position='Query'),
  needTotalCount?: boolean(name='NeedTotalCount', example='true', position='Query'),
  pageNo?: long(name='PageNo', example='1', position='Query'),
  pageSize?: long(name='PageSize', example='10', position='Query'),
  status?: int32(name='Status', example='1', position='Query'),
  type?: int32(name='Type', example='1', position='Query'),
}

model GetAiRtcAuthCodeListResponseBody = {
  authCodeList?: [
    AiRtcAuthCodeDTO
  ](name='AuthCodeList'),
  code?: string(name='Code', example='Success'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  message?: string(name='Message', example='OK'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1***'),
  success?: boolean(name='Success', example='true'),
  totalCount?: long(name='TotalCount', example='10'),
}

model GetAiRtcAuthCodeListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAiRtcAuthCodeListResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetAiRtcAuthCodeList  GetAiRtcAuthCodeListRequest
  * @return GetAiRtcAuthCodeListResponse
 */
async function getAiRtcAuthCodeList(request: GetAiRtcAuthCodeListRequest): GetAiRtcAuthCodeListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAiRtcAuthCodeList', 'POST', '/', 'json', false, 'json', request);
}

model GetAiRtcLicenseInfoListRequest {
  licenseItemId?: string(name='LicenseItemId', example='17712***', position='Query'),
  needTotalCount?: boolean(name='NeedTotalCount', example='true', position='Query'),
  pageNo?: long(name='PageNo', example='1', position='Query'),
  pageSize?: long(name='PageSize', example='10', position='Query'),
  status?: int32(name='Status', example='1', position='Query'),
  type?: int32(name='Type', example='1', position='Query'),
}

model GetAiRtcLicenseInfoListResponseBody = {
  code?: string(name='Code', example='Success'),
  httpStatusCode?: int32(name='HttpStatusCode', example='httpStatusCode'),
  licenseInfoList?: [
    AiRtcLicenseInfoDTO
  ](name='LicenseInfoList'),
  message?: string(name='Message', example='OK'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1***'),
  success?: boolean(name='Success', example='true'),
  totalCount?: long(name='TotalCount', example='100'),
}

model GetAiRtcLicenseInfoListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAiRtcLicenseInfoListResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetAiRtcLicenseInfoList  GetAiRtcLicenseInfoListRequest
  * @return GetAiRtcLicenseInfoListResponse
 */
async function getAiRtcLicenseInfoList(request: GetAiRtcLicenseInfoListRequest): GetAiRtcLicenseInfoListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAiRtcLicenseInfoList', 'POST', '/', 'json', false, 'json', request);
}

model GetAvatarRequest {
  avatarId: string(name='AvatarId', description='*   The ID of the digital human.

This parameter is required.', example='Avatar-XXXX', position='Query'),
}

model GetAvatarResponseBody = {
  data?: {
    avatar?: {
      avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
      avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXXX'),
      avatarName?: string(name='AvatarName', description='The name of the digital human.'),
      avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
      height?: int32(name='Height', description='The height of the digital human image in pixels.', example='1920'),
      portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='****571c704445f9a0ee011406c2****'),
      thumbnail?: string(name='Thumbnail', description='The thumbnail URL.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
      transparent?: boolean(name='Transparent', description='Indicates whether the digital human supports alpha channels.', example='true'),
      width?: int32(name='Width', description='The width of the digital human image in pixels.', example='1080'),
    }(name='Avatar', description='The information about the digital human.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetAvatarResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAvatarResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetAvatar  GetAvatarRequest
  * @return GetAvatarResponse
 */
async function getAvatar(request: GetAvatarRequest): GetAvatarResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAvatar', 'POST', '/', 'json', false, 'json', request);
}

model GetAvatarTrainingJobRequest {
  jobId: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetAvatarTrainingJobResponseBody = {
  data?: {
    avatarTrainingJob?: {
      avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
      avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXXX'),
      avatarName?: string(name='AvatarName', description='The name of the digital human.'),
      avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
      firstTrainingTime?: string(name='FirstTrainingTime', description='*   The time when the first training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
      jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****55d86f7f4587943ce7734d6b****'),
      lastTrainingTime?: string(name='LastTrainingTime', description='*   The time when the last training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
      message?: string(name='Message', description='The status description.'),
      portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='****571c704445f9a0ee011406c2****'),
      status?: string(name='Status', description='*   The state of the digital human training job.
*   Valid values: Init, Queuing, Training, Success, and Fail.', example='Success'),
      thumbnail?: string(name='Thumbnail', description='The thumbnail URL.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
      transparent?: boolean(name='Transparent', description='Indicates whether the input video supports alpha channels.', example='true'),
      video?: string(name='Video', description='The ID of the video used for training.', example='****571c704445f9a0ee011406c2****'),
    }(name='AvatarTrainingJob', description='The information about the digital human training job.'),
  }(name='Data', description='The data returned if the request was successful.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAvatarTrainingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetAvatarTrainingJob  GetAvatarTrainingJobRequest
  * @return GetAvatarTrainingJobResponse
 */
async function getAvatarTrainingJob(request: GetAvatarTrainingJobRequest): GetAvatarTrainingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAvatarTrainingJob', 'POST', '/', 'json', false, 'json', request);
}

model GetBatchMediaProducingJobRequest {
  jobId?: string(name='JobId', description='The ID of the quick video production job.', example='****b4549d46c88681030f6e****', position='Query'),
}

model GetBatchMediaProducingJobResponseBody = {
  editingBatchJob?: {
    completeTime?: string(name='CompleteTime', description='The time when the job was complete.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:57:07Z'),
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:47:07Z'),
    editingConfig?: string(name='EditingConfig', description='The editing configurations. For more information, see [EditingConfig](~~2692547#1be9bba03b7qu~~).', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}'),
    extend?: string(name='Extend', description='The extended information. This parameter contains the following fields:

ErrorCode: the error code of the main job.

ErrorMessage: the error message of the main job.', example='{
	"ErrorCode": "InvalidMaterial.NotFound",
	"ErrorMessage": "The specified clips id not found:[\\"****30d0b5e871eebb2ff7f6c75a****\\"]"
}'),
    extendInput?: string(name='ExtendInput'),
    extendOutput?: string(name='ExtendOutput'),
    inputConfig?: string(name='InputConfig', description='The input configurations. For more information, see [InputConfig](~~2692547#2faed1559549n~~).'),
    jobId?: string(name='JobId', description='The job ID.', example='****b6b2750d4308892ac3330238****'),
    jobType?: string(name='JobType'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:57:07Z'),
    outputConfig?: string(name='OutputConfig', description='The output configurations. For more information, see [OutputConfig](~~2692547#447b928fcbuoa~~).', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 20,
  "MaxDuration": 15,
  "Width": 1080,
  "Height": 1920,
  "Video": {"Crf": 27}
}'),
    status?: string(name='Status', description='The job state. Valid values:

Init: The job is initialized.

Processing: The job is in progress.

Finished: The job is complete.', example='Finished'),
    subJobList?: [ 
      {
        duration?: float(name='Duration'),
        errorCode?: string(name='ErrorCode', description='The error code that is returned if the subjob failed. This parameter is not returned if the subjob is successful.', example='InvalidMaterial.NotFound'),
        errorMessage?: string(name='ErrorMessage', description='The error message that is returned if the subjob failed. This parameter is not returned if the subjob is successful.', example='The specified clips id not found:["****30d0b5e871eebb2ff7f6c75a****"]'),
        jobId?: string(name='JobId', description='The subjob ID.', example='****8e81933d44e3ae69e2f81485****'),
        mediaId?: string(name='MediaId', description='The ID of the output media asset.', example='****1470b11171ee9d19e7e6c66a****'),
        mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http:/xxx.oss-cn-shanghai.aliyuncs.com/xxx_0.mp4'),
        projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****7cc47fe04eaa81bd853acb6a****'),
        status?: string(name='Status', description='The subjob state. Valid values:

Init: The subjob is initialized.

Processing: The subjob is in progress.

Success: The subjob is successful.

Failed: The subjob failed.', example='Success'),
      }
    ](name='SubJobList', description='The quick video production subjobs.'),
    userData?: string(name='UserData', description='The user-defined data, including the business and callback configurations. For more information, see [UserData](https://help.aliyun.com/document_detail/357745.html).', example='{"NotifyAddress":"http://xx.xx.xxx"}'),
  }(name='EditingBatchJob', description='The information about the quick video production job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model GetBatchMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetBatchMediaProducingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetBatchMediaProducingJob  GetBatchMediaProducingJobRequest
  * @return GetBatchMediaProducingJobResponse
 */
async function getBatchMediaProducingJob(request: GetBatchMediaProducingJobRequest): GetBatchMediaProducingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetBatchMediaProducingJob', 'POST', '/', 'json', false, 'json', request);
}

model GetCategoriesRequest {
  regionId?: string(name='RegionId', position='Host'),
  cateId?: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of CateId returned by the AddCategory operation that you called to create a category.
*   View the value of CateId returned by the GetCategories operation that you called to query a category.', example='33', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values: 10 to 100.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting rule of results. Valid values:

\\- CreationTime:Desc (default): The results are sorted in reverse chronological order based on the creation time.

\\- CreationTime:Asc: The results are sorted in chronological order based on the creation time.', example='CreationTime:Desc', position='Query'),
  type?: string(name='Type', description='The type of the category. Valid values: default and material. A value of default indicates audio, video, and image files. This is the default value. A value of material indicates short video materials.', example='default', position='Query'),
}

model GetCategoriesResponseBody = {
  category?: {
    cateId?: long(name='CateId', description='The category ID.', example='46'),
    cateName?: string(name='CateName', description='The category name.'),
    level?: long(name='Level', description='The level of the category. A value of **0** indicates a level-1 category, a value of **1** indicates a level-2 category, and a value of **2** indicates a level-3 category.', example='0'),
    parentId?: long(name='ParentId', description='The ID of the parent category.', example='-1'),
    type?: string(name='Type', description='The type of the category. Valid values:

*   **default**: audio, video, and image files. This is the default value.
*   **material**: short video materials.', example='default'),
  }(name='Category', description='The information about the category.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  subCategories?: {
    category?: [ 
    {
      cateId?: long(name='CateId', description='The category ID.', example='129'),
      cateName?: string(name='CateName', description='The category name.

*   The value can be up to 64 bytes in length.
*   The value is encoded in UTF-8.'),
      level?: long(name='Level', description='The level of the category. A value of **0** indicates a level-1 category, a value of **1** indicates a level-2 category, and a value of **2** indicates a level-3 category.', example='1'),
      parentId?: long(name='ParentId', description='The ID of the parent category.', example='46'),
      subTotal?: long(name='SubTotal', description='The total number of subcategories.', example='100'),
      type?: string(name='Type', description='The type of the category. Valid values:

*   **default**: audio, video, and image files. This is the default value.
*   **material**: short video materials.', example='default'),
    }
  ](name='Category')
  }(name='SubCategories', description='The subcategories in the category.'),
  subTotal?: long(name='SubTotal', description='The total number of subcategories.', example='100'),
}

model GetCategoriesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCategoriesResponseBody(name='body'),
}

/**
  * @description You can call this operation to query the information about a category and its subcategories based on the category ID and category type.
  * @param request  the request parameters of GetCategories  GetCategoriesRequest
  * @return GetCategoriesResponse
 */
async function getCategories(request: GetCategoriesRequest): GetCategoriesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCategories', 'POST', '/', 'json', false, 'json', request);
}

model GetChannelRequest {
  channelName: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel', position='Query'),
}

model GetChannelResponseBody = {
  channel?: ChannelAssemblyChannel(name='Channel', description='The channel information.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
}

model GetChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetChannelResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetChannel  GetChannelRequest
  * @return GetChannelResponse
 */
async function getChannel(request: GetChannelRequest): GetChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetChannel', 'POST', '/', 'json', false, 'json', request);
}

model GetContentAnalyzeConfigRequest {
  regionId?: string(name='RegionId', position='Host'),
}

model GetContentAnalyzeConfigResponseBody = {
  contentAnalyzeConfig?: {
    auto?: boolean(name='Auto', example='true'),
    saveType?: string(name='SaveType', example='TEXT,FACE'),
    templateId?: string(name='TemplateId', example='S00000101-100070'),
  }(name='ContentAnalyzeConfig'),
  requestId?: string(name='RequestId', example='31FEC819-2344-5771-9366-9172DB0D26C9'),
}

model GetContentAnalyzeConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetContentAnalyzeConfigResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetContentAnalyzeConfig  GetContentAnalyzeConfigRequest
  * @return GetContentAnalyzeConfigResponse
 */
async function getContentAnalyzeConfig(request: GetContentAnalyzeConfigRequest): GetContentAnalyzeConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetContentAnalyzeConfig', 'POST', '/', 'json', false, 'json', request);
}

model GetCustomTemplateRequest {
  subtype?: int32(name='Subtype', description='The template subtype.', example='1', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****', position='Query'),
  type?: int32(name='Type', description='The ID of the template type that is used to query the default template. This parameter is required if TemplateId is not specified.', example='1', position='Query'),
}

model GetCustomTemplateResponseBody = {
  customTemplate?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-01-01T10:00:00Z'),
    frontendHint?: {
      transcodeTemplateHint?: {
        bitrateControlType?: string(name='BitrateControlType'),
      }(name='TranscodeTemplateHint'),
    }(name='FrontendHint'),
    isDefault?: boolean(name='IsDefault', description='Indicates whether the template is the default template.', example='true'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-01-01T11:00:00Z'),
    status?: string(name='Status', description='The template state.', example='Normal'),
    subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='1'),
    subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='Normal'),
    templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Type":"Normal","FrameType":"normal","Time":0,"Count":10}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
    templateName?: string(name='TemplateName', description='The template name.', example='测试转码模板'),
    type?: int32(name='Type', description='The type ID of the template.', example='2'),
    typeName?: string(name='TypeName', description='The type name of the template.', example='SnapshotTemplate'),
  }(name='CustomTemplate', description='The template information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCustomTemplateResponseBody(name='body'),
}

/**
  * @description You can call this operation to query the information about a template with the ID specified by the TemplateId parameter. You can also query the information about the default template. If TemplateId is specified, other parameters are ignored and the template whose ID is specified is queried. If TemplateId is not specified, the default template is queried based on other parameters. In this case, Type is required.
  * Template types:
  * 1.  1: transcoding template.
  * 2.  2: snapshot template.
  * 3.  3: animated image template.
  * 4.  4\\. image watermark template.
  * 5.  5: text watermark template.
  * 6.  6: subtitle template.
  * 7.  7: AI-assisted content moderation template.
  * 8.  8: AI-assisted intelligent thumbnail template.
  * 9.  9: AI-assisted intelligent erasure template.
  * Subtypes of transcoding templates:
  * 1.  1 (Normal): regular template.
  * 2.  2 (AudioTranscode): audio transcoding template.
  * 3.  3 (Remux): container format conversion template.
  * 4.  4 (NarrowBandV1): Narrowband HD 1.0 template.
  * 5.  5 (NarrowBandV2): Narrowband HD 2.0 template.
  * Subtypes of snapshot templates:
  * 1.  1 (Normal): regular template.
  * 2.  2 (Sprite): sprite template.
  * 3.  3 (WebVtt): WebVTT template.
  * Subtypes of AI-assisted content moderation templates:
  * 1.  1 (Video): video moderation template.
  * 2.  2 (Audio): audio moderation template.
  * 3.  3 (Image): image moderation template.
  * Subtypes of AI-assisted intelligent erasure templates:
  * 1.  1 (VideoDelogo): logo erasure template.
  * 2.  2 (VideoDetext): subtitle erasure template.
  * @param request  the request parameters of GetCustomTemplate  GetCustomTemplateRequest
  * @return GetCustomTemplateResponse
 */
async function getCustomTemplate(request: GetCustomTemplateRequest): GetCustomTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCustomTemplate', 'POST', '/', 'json', false, 'json', request);
}

model GetCustomizedVoiceRequest {
  voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan', position='Query'),
}

model GetCustomizedVoiceResponseBody = {
  data?: {
    customizedVoice?: {
      demoAudioMediaId?: string(name='DemoAudioMediaId', description='The media asset ID of the sample audio file.', example='****42d3c312402982be65975f5b****'),
      gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
      scenario?: string(name='Scenario', description='The demonstration scenario.

Valid values:

*   **story**
*   **interaction**
*   **navigation**', example='interaction'),
      voiceDesc?: string(name='VoiceDesc', description='The voice description.'),
      voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
      voiceName?: string(name='VoiceName', description='The voice name.'),
    }(name='CustomizedVoice', description='The personalized human voice.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetCustomizedVoiceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCustomizedVoiceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetCustomizedVoice  GetCustomizedVoiceRequest
  * @return GetCustomizedVoiceResponse
 */
async function getCustomizedVoice(request: GetCustomizedVoiceRequest): GetCustomizedVoiceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCustomizedVoice', 'POST', '/', 'json', false, 'json', request);
}

model GetCustomizedVoiceJobRequest {
  jobId: string(name='JobId', description='The ID of the human voice cloning job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetCustomizedVoiceJobResponseBody = {
  data?: {
    customizedVoiceJob?: {
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-06-07T02:27:08Z'),
      gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
      jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****571c704445f9a0ee011406c2****'),
      message?: string(name='Message', description='The status description.'),
      scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation', example='story'),
      status?: string(name='Status', description='The job state. Valid values:

*   Initialization
*   AudioDetecting
*   PreTraining
*   Training
*   Success
*   Fail', example='Fail'),
      type?: string(name='Type', description='The type of the human voice cloning job. Valid values:

*   Basic
*   Standard', example='Standard'),
      voiceDesc?: string(name='VoiceDesc', description='The voice description.', example='This is an exclusive voice'),
      voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
      voiceName?: string(name='VoiceName', description='The voice name.', example='Xiaozhuan'),
    }(name='CustomizedVoiceJob', description='The information about the human voice cloning job.'),
  }(name='Data', description='The data returned if the request was successful.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetCustomizedVoiceJob  GetCustomizedVoiceJobRequest
  * @return GetCustomizedVoiceJobResponse
 */
async function getCustomizedVoiceJob(request: GetCustomizedVoiceJobRequest): GetCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model GetDefaultStorageLocationRequest {
  regionId?: string(name='RegionId', position='Host'),
}

model GetDefaultStorageLocationResponseBody = {
  bucket?: string(name='Bucket', example='oss-test-bucket'),
  path?: string(name='Path', example='ice/dir'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
  status?: string(name='Status', example='normal'),
  storageType?: string(name='StorageType', example='user_oss_bucket'),
}

model GetDefaultStorageLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDefaultStorageLocationResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDefaultStorageLocation  GetDefaultStorageLocationRequest
  * @return GetDefaultStorageLocationResponse
 */
async function getDefaultStorageLocation(request: GetDefaultStorageLocationRequest): GetDefaultStorageLocationResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDefaultStorageLocation', 'POST', '/', 'json', false, 'json', request);
}

model GetDemonstrationForCustomizedVoiceJobRequest {
  scenario: string(name='Scenario', description='The demonstration scenario.

Valid values:

*   **story**
*   **interaction**
*   **navigation**

This parameter is required.', example='story', position='Query'),
}

model GetDemonstrationForCustomizedVoiceJobResponseBody = {
  data?: {
    demonstrationList?: [ 
      {
        audioId?: int32(name='AudioId', description='The sequence number of the text, which corresponds to the AduioRecordId parameter to be passed during audio check.', example='2'),
        demoAudio?: string(name='DemoAudio', description='The URL of the sample audio.

*   The value is an Object Storage Service (OSS) URL.

    **

    **Note**: The URL expires in 12 hours.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/1.wav'),
        text?: string(name='Text', description='The text content to be read.'),
      }
    ](name='DemonstrationList', description='A list of 20 text entries to be read and the corresponding sample audio.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetDemonstrationForCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDemonstrationForCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDemonstrationForCustomizedVoiceJob  GetDemonstrationForCustomizedVoiceJobRequest
  * @return GetDemonstrationForCustomizedVoiceJobResponse
 */
async function getDemonstrationForCustomizedVoiceJob(request: GetDemonstrationForCustomizedVoiceJobRequest): GetDemonstrationForCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDemonstrationForCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model GetDynamicImageJobRequest {
  jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****', position='Query'),
}

model GetDynamicImageJobResponseBody = {
  dynamicImageJob?: {
    code?: string(name='Code', description='Error codes', example='ResourceNotFound'),
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
    input?: {
      media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://test-bucket/sample-input.mp4'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='sample-input.mp4'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
    message?: string(name='Message', description='The error message that is returned.', example='The specified resource for "CustomTemplate" could not be found.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
    name?: string(name='Name', description='The name of the job.', example='SampleJob'),
    output?: {
      media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='****d80e4e4044975745c14b****'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='sample-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='path/to/object'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the input file. Valid values: OSS: an OSS object. Media: a media asset.', example='Media'),
    }(name='Output', description='The output of the job.'),
    outputUrl?: string(name='OutputUrl', description='The URL of the output animated image.', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/output.gif'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****d80e4e4044975745c14b****'),
    status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
    templateConfig?: string(name='TemplateConfig', description='The animation template configuration.', example='{"Format":"gif","Fps":5,"Height":1080,"Width":1920}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****d80e4e4044975745c14b****'),
    triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
    userData?: string(name='UserData', description='The user-defined data.', example='{"sampleParam": "sampleValue"}'),
  }(name='DynamicImageJob', description='The information about the snapshot job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******36-3C1E-4417-BDB2-1E034F******'),
}

model GetDynamicImageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDynamicImageJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDynamicImageJob  GetDynamicImageJobRequest
  * @return GetDynamicImageJobResponse
 */
async function getDynamicImageJob(request: GetDynamicImageJobRequest): GetDynamicImageJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDynamicImageJob', 'POST', '/', 'json', false, 'json', request);
}

model GetEditingProjectRequest {
  regionId?: string(name='RegionId', position='Host'),
  projectId: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='****fb2101bf24b2754cb318787dc****', position='Query'),
  requestSource?: string(name='RequestSource', description='The ID of the request source. Valid values:

\\- OpenAPI (default): Timeline conversion is not performed.

\\- WebSDK: If you specify this value, the project timeline is automatically converted into the frontend style, and the materials in the timeline are associated with the project to enable preview by using frontend web SDKs.', example='WebSDK', position='Query'),
}

model GetEditingProjectResponseBody = {
  project?: {
    businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{ "OutputMediaConfig" : { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path" }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
    businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

Reserving

ReservationCanceled

BroadCasting

LoadingFailed

LiveFinished', example='Reserving'),
    clipsParam?: string(name='ClipsParam', description='The material parameter corresponding to the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified. For more information<props="china">, see [Create and use a regular template](https://help.aliyun.com/document_detail/328557.html) and [Create and use an advanced template](https://help.aliyun.com/document_detail/291418.html).'),
    coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='oss://example-bucket/example.jpg'),
    createSource?: string(name='CreateSource', description='The method for creating the online editing project. Valid values:

\\- OpenAPI

\\- AliyunConsole

\\- WebSDK

\\- LiveEditingOpenAPI

\\- LiveEditingConsole', example='OpenAPI'),
    createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2020-12-20T12:00:00Z'),
    description?: string(name='Description', description='The description of the online editing project.'),
    duration?: long(name='Duration', description='The total duration of the online editing project.', example='24.120000'),
    modifiedSource?: string(name='ModifiedSource', description='The method for editing the online editing project. Valid values:

\\- OpenAPI

\\- AliyunConsole

\\- WebSDK

\\- LiveEditingOpenAPI

\\- LiveEditingConsole', example='OpenAPI'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last modified.', example='2020-12-20T13:00:00Z'),
    projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fb2101bf24b2754cb318787dc****'),
    projectType?: string(name='ProjectType', description='The type of the editing project. Default value: EditingProject. Valid values:

\\- EditingProject: a regular editing project.

\\- LiveEditingProject: a live stream editing project.', example='EditingProject'),
    status?: string(name='Status', description='The status of the online editing project. Valid values:

\\- Draft

\\- Editing

\\- Producing

\\- Produced

\\- ProduceFailed

\\- Deleted', example='Editing'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
    templateType?: string(name='TemplateType', description='The template type of the online editing project. Valid values:

\\- Timeline

\\- VETemplate', example='Timeline'),
    timeline?: string(name='Timeline', description='The timeline of the online editing project.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****9b4d7cf14dc7b83b0e801cbe****"},{"MediaId":"****9b4d7cf14dc7b83b0e801cbe****"},{"MediaId":"****1656bca4474999c961a6d2a2****"}]}]}'),
    timelineConvertErrorMessage?: string(name='TimelineConvertErrorMessage', description='The error message returned if the project conversion failed. The error message displays the detailed information about the failure, and is returned only if the value of TimelineConvertStatus is ConvertFailed.', example='The StorageLocation must be in the same division(apiRegion) as ICE service access point.'),
    timelineConvertStatus?: string(name='TimelineConvertStatus', description='The project conversion status. Conversion of an API-style timeline into a frontend-style timeline is an asynchronous process and takes effect only if RequestSource:WebSDK is specified.

\\- Unconverted

\\- Converting

\\- Converted

\\- ConvertFailed', example='Converted'),
    title?: string(name='Title', description='The title of the online editing project.'),
  }(name='Project', description='The information about the online editing project.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model GetEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEditingProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetEditingProject  GetEditingProjectRequest
  * @return GetEditingProjectResponse
 */
async function getEditingProject(request: GetEditingProjectRequest): GetEditingProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetEditingProject', 'POST', '/', 'json', false, 'json', request);
}

model GetEditingProjectMaterialsRequest {
  regionId?: string(name='RegionId', position='Host'),
  projectId: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='*****fb2101cb318*****', position='Query'),
}

model GetEditingProjectMaterialsResponseBody = {
  liveMaterials?: [ 
    {
      appName?: string(name='AppName', description='The application name of the live stream.', example='testrecord'),
      domainName?: string(name='DomainName', description='The domain name of the live stream.', example='test.alivecdn.com'),
      liveUrl?: string(name='LiveUrl', description='The URL of the live stream.', example='rtmp://test.alivecdn.com/testrecord/teststream'),
      streamName?: string(name='StreamName', description='The name of the live stream.', example='testrecord'),
    }
  ](name='LiveMaterials', description='The materials associated with the live stream.'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
            duration?: string(name='Duration', description='The duration.', example='216.206667'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='540'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='960'),
          }(name='FileBasicInfo', description='The basic information of the file, such as the duration and size.'),
        }
      ](name='FileInfoList', description='The information about the file.'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.', example='video'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://sample-bucket.oss-cn-shanghai.aliyuncs.com/sample-corver.jpg?Expires=1628670610&OSSAccessKeyId=AK&Signature=signature'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-26T04:11:08Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-26T04:11:08Z'),
        description?: string(name='Description', description='The description of the media asset.', example='sample_description'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/file.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****64623a94eca8516569c8f*****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-26T04:11:08Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='null'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite of the media asset', example='null'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.', example='file.mp4'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.

Valid values:

*   TranscodeSuccess: transcoding completed.
*   TranscodeFailed: transcoding failed.
*   Init: initializing.
*   Transcoding: transcoding in progress.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information of the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****64623a94eca8516569c8fe*****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  projectId?: string(name='ProjectId', description='The project ID.', example='*****67ae06542b9b93e0d1c387*****'),
  projectMaterials?: [ string ](name='ProjectMaterials', description='The materials associated with the editing project. A live stream editing project will be associated with a regular editing project after the live streaming ends.', example='*****9b145c5cafc2e057304fcd*****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******89-C21D-4B78-AE24-3788B8******'),
}

model GetEditingProjectMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEditingProjectMaterialsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetEditingProjectMaterials  GetEditingProjectMaterialsRequest
  * @return GetEditingProjectMaterialsResponse
 */
async function getEditingProjectMaterials(request: GetEditingProjectMaterialsRequest): GetEditingProjectMaterialsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetEditingProjectMaterials', 'POST', '/', 'json', false, 'json', request);
}

model GetEventCallbackRequest {
  regionId?: string(name='RegionId', position='Host'),
}

model GetEventCallbackResponseBody = {
  authKey?: string(name='AuthKey', description='The authentication key. This parameter is returned only for HTTP callbacks.', example='TestKey001'),
  authSwitch?: string(name='AuthSwitch', description='Specifies whether callback authentication is enabled. This parameter is returned only for **HTTP** callbacks. Valid values:

*   **on**
*   **off**', example='on'),
  callbackQueueName?: string(name='CallbackQueueName', description='The name of the Simple Message Queue (SMQ) queue to which callback messages are sent.', example='ice-callback-queue'),
  callbackType?: string(name='CallbackType', description='The callback method. Valid values:

*   **HTTP**
*   **MNS**', example='HTTP'),
  callbackURL?: string(name='CallbackURL', description='The callback URL to which event notifications are sent.', example='http://xxx.yyy/callback'),
  eventTypeList?: string(name='EventTypeList', description='The type of the callback event. Multiple values are separated with commas (,). For more information about callback event types, see [Event notification content](https://help.aliyun.com/document_detail/610204.html).', example='ProduceMediaComplete,TranscodeComplete'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetEventCallbackResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEventCallbackResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetEventCallback  GetEventCallbackRequest
  * @return GetEventCallbackResponse
 */
async function getEventCallback(request: GetEventCallbackRequest): GetEventCallbackResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetEventCallback', 'POST', '/', 'json', false, 'json', request);
}

model GetHotwordLibraryRequest {
  hotwordLibraryId: string(name='HotwordLibraryId', description='The ID of the hotword library.

This parameter is required.', example='****96e8864746a0b6f3****', position='Query'),
}

model GetHotwordLibraryResponseBody = {
  creationTime?: string(name='CreationTime', description='The time when the hotword library was created.', example='2020-12-23T13:33:49Z'),
  description?: string(name='Description', description='The description of the hotword library.', example='热词库描述'),
  hotwordLibraryId?: string(name='HotwordLibraryId', description='The ID of the hotword library.', example='****05512043f49f697f7425****'),
  hotwords?: [
    Hotword
  ](name='Hotwords', description='The hotword list.'),
  name?: string(name='Name', description='The name of the hotword library.', example='热词库名称'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****12e8864746a0a398****'),
  usageScenario?: string(name='UsageScenario', description='The usage scenario of the hotword library.', example='ASR'),
}

model GetHotwordLibraryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetHotwordLibraryResponseBody(name='body'),
}

/**
  * @description ## [](#)
  * You can call this operation to retrieve details of a specified hotword library based on the ID, including the library name, description, and content and attributes of all hotwords in it.
  * @param request  the request parameters of GetHotwordLibrary  GetHotwordLibraryRequest
  * @return GetHotwordLibraryResponse
 */
async function getHotwordLibrary(request: GetHotwordLibraryRequest): GetHotwordLibraryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetHotwordLibrary', 'POST', '/', 'json', false, 'json', request);
}

model GetLiveEditingIndexFileRequest {
  appName?: string(name='AppName', description='The application name of the live stream.', example='testrecord', position='Query'),
  domainName?: string(name='DomainName', description='The domain name of the live stream.', example='test.alivecdn.com', position='Query'),
  projectId?: string(name='ProjectId', description='The ID of the live stream editing project.', example='*****cb6307a4edea614d8b3f3c*****', position='Query'),
  streamName?: string(name='StreamName', description='The name of the live stream.', example='teststream', position='Query'),
}

model GetLiveEditingIndexFileResponseBody = {
  indexFile?: string(name='IndexFile', description='The URL of the index file.'),
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
}

model GetLiveEditingIndexFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveEditingIndexFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveEditingIndexFile  GetLiveEditingIndexFileRequest
  * @return GetLiveEditingIndexFileResponse
 */
async function getLiveEditingIndexFile(request: GetLiveEditingIndexFileRequest): GetLiveEditingIndexFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveEditingIndexFile', 'POST', '/', 'json', false, 'json', request);
}

model GetLiveEditingJobRequest {
  jobId?: string(name='JobId', description='The ID of the live editing job.', example='****d80e4e4044975745c14b****', position='Query'),
}

model GetLiveEditingJobResponseBody = {
  liveEditingJob?: {
    clips?: string(name='Clips', description='The clips.', example='[{\\"StartTime\\": \\" 2021-06-21T08:01:00Z\\",  \\"EndTime\\": \\" 2021-06-21T08:03:00Z\\" }]'),
    code?: string(name='Code', description='The response code. Note: Pay attention to this parameter if the job failed.', example='InvalidParameter'),
    completeTime?: string(name='CompleteTime', description='The time when the live editing job was completed. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:52Z'),
    creationTime?: string(name='CreationTime', description='The time when the live editing job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
    jobId?: string(name='JobId', description='The ID of the live editing job.', example='****cdb3e74639973036bc84****'),
    liveStreamConfig?: {
      appName?: string(name='AppName', description='The name of the application to which the live stream belongs.', example='app'),
      domainName?: string(name='DomainName', description='The domain name of the live stream.', example='domain.com'),
      streamName?: string(name='StreamName', description='The name of the live stream.', example='streamName'),
    }(name='LiveStreamConfig', description='The live editing configurations.'),
    mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****0cc6ba49eab379332c5b****'),
    mediaProduceConfig?: {
      mode?: string(name='Mode', description='The editing mode. Default value: Accurate.', example='Accurate'),
    }(name='MediaProduceConfig', description='The production configurations.'),
    mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example2.mp4'),
    message?: string(name='Message', description='The returned message. Note: Pay attention to this parameter if the job failed.', example='The specific parameter LiveStreamConfig is not valid.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the live editing job was last modified. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:49Z'),
    outputMediaConfig?: {
      bitrate?: long(name='Bitrate', description='The bitrate of the output file. Unit: Kbit/s. You can leave this parameter empty. The default value is the maximum bitrate of the input materials.', example='1000'),
      fileName?: string(name='FileName', description='If OutputMediaTarget is set to vod-media, this parameter indicates the file name of the output file. The value contains the file name extension but not the path.', example='test.mp4'),
      height?: int32(name='Height', description='The height of the output file. You can leave this parameter empty. The default value is the maximum height of the input materials.', example='480'),
      mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='https://testice-testbucket.oss-cn-shanghai.aliyuncs.com/test.mp4'),
      storageLocation?: string(name='StorageLocation', description='If OutputMediaTarget is set to vod-media, this parameter indicates the storage location of the media asset in ApsaraVideo VOD. The storage location is the path of the file in ApsaraVideo VOD, excluding the prefix http://. Example: outin-xxxxxx.oss-cn-shanghai.aliyuncs.com.', example='outin-xxxxxx.oss-cn-shanghai.aliyuncs.com'),
      vodTemplateGroupId?: string(name='VodTemplateGroupId', description='The ID of the VOD transcoding template group. If VOD transcoding is not required, set the value to VOD_NO_TRANSCODE.', example='VOD_NO_TRANSCODE'),
      width?: int32(name='Width', description='The width of the output file. You can leave this parameter empty. The default value is the maximum width of the input materials.', example='640'),
    }(name='OutputMediaConfig', description='The storage configurations of the output file.'),
    projectId?: string(name='ProjectId', description='The ID of the live editing project.', example='****fddd7748b58bf1d47e95****'),
    status?: string(name='Status', description='The state of the live editing job. Valid values: Init, Queuing, Processing, Success, and Failed.', example='Success'),
    userData?: string(name='UserData', description='The user-defined data.', example='{"key": "value\\"}'),
  }(name='LiveEditingJob', description='The information about the live editing job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model GetLiveEditingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveEditingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveEditingJob  GetLiveEditingJobRequest
  * @return GetLiveEditingJobResponse
 */
async function getLiveEditingJob(request: GetLiveEditingJobRequest): GetLiveEditingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveEditingJob', 'POST', '/', 'json', false, 'json', request);
}

model GetLivePackageChannelRequest {
  channelName: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1', position='Query'),
  groupName: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1', position='Query'),
}

model GetLivePackageChannelResponseBody = {
  livePackageChannel?: {
    channelName?: string(name='ChannelName', description='The channel name.', example='ch4'),
    createTime?: string(name='CreateTime', description='The time when the channel was created.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The channel description.'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    ingestEndpoints?: [ 
      {
        id?: string(name='Id', description='The ingest endpoint ID.', example='ingest1'),
        password?: string(name='Password', description='The password.', example='2F9e******b569c8'),
        url?: string(name='Url', description='The ingest endpoint URL.', example='http://xxx-1.packagepush-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
        username?: string(name='Username', description='The username.', example='us12******das'),
      }
    ](name='IngestEndpoints', description='The ingest endpoints.'),
    lastModified?: string(name='LastModified', description='The time when the endpoint was last modified.', example='2023-04-01T12:00:00Z'),
    protocol?: string(name='Protocol', description='The ingest protocol. Only HLS is supported.', example='HLS'),
    segmentCount?: int32(name='SegmentCount', description='The number of M3U8 segments.', example='3'),
    segmentDuration?: int32(name='SegmentDuration', description='The segment duration.', example='5'),
  }(name='LivePackageChannel', description='Details of the live package channel.'),
  requestId?: string(name='RequestId', description='The request ID.', example='RequestId-12345678'),
}

model GetLivePackageChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLivePackageChannelResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * This API operation allows you to query the details of a live package channel, including the creation time, description, ingest endpoint, protocol, number of segments, and segment duration.
  * @param request  the request parameters of GetLivePackageChannel  GetLivePackageChannelRequest
  * @return GetLivePackageChannelResponse
 */
async function getLivePackageChannel(request: GetLivePackageChannelRequest): GetLivePackageChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLivePackageChannel', 'POST', '/', 'json', false, 'json', request);
}

model GetLivePackageChannelGroupRequest {
  groupName: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1', position='Query'),
}

model GetLivePackageChannelGroupResponseBody = {
  livePackageChannelGroup?: {
    createTime?: string(name='CreateTime', description='The time when the channel group was created. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The channel group description.', example='Updated description of the channel group.'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    lastModified?: string(name='LastModified', description='The time when the channel group was last modified. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    originDomain?: string(name='OriginDomain', description='The origin domain.', example='example.com'),
  }(name='LivePackageChannelGroup', description='Details of the channel group.'),
  requestId?: string(name='RequestId', description='The request ID.', example='req-abcdefg123456'),
}

model GetLivePackageChannelGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLivePackageChannelGroupResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * You can call this API operation to query the details of a specific channel group, including its name, description, origin domain, and creation and last modification timestamps.
  * @param request  the request parameters of GetLivePackageChannelGroup  GetLivePackageChannelGroupRequest
  * @return GetLivePackageChannelGroupResponse
 */
async function getLivePackageChannelGroup(request: GetLivePackageChannelGroupRequest): GetLivePackageChannelGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLivePackageChannelGroup', 'POST', '/', 'json', false, 'json', request);
}

model GetLivePackageOriginEndpointRequest {
  channelName: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1', position='Query'),
  endpointName: string(name='EndpointName', description='The endpoint name.

This parameter is required.', example='endpoint-1', position='Query'),
  groupName: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1', position='Query'),
}

model GetLivePackageOriginEndpointResponseBody = {
  livePackageOriginEndpoint?: {
    authorizationCode?: string(name='AuthorizationCode', description='The authorization code.', example='Abc123Def456'),
    channelName?: string(name='ChannelName', description='The channel name.', example='channel-1'),
    createTime?: string(name='CreateTime', description='The time when the endpoint was created.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The endpoint description.'),
    endpointName?: string(name='EndpointName', description='The endpoint name.', example='endpoint-1'),
    endpointUrl?: string(name='EndpointUrl', description='The endpoint URL.', example='https://xxx.packagepull-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    ipBlacklist?: string(name='IpBlacklist', description='The IP address blacklist.', example='10.21.222.1/32'),
    ipWhitelist?: string(name='IpWhitelist', description='The IP address whitelist.', example='192.168.1.0/24,10.0.0.1/24'),
    lastModified?: string(name='LastModified', description='The time when the endpoint was last modified.', example='2023-04-01T12:00:00Z'),
    livePackagingConfig?: LivePackagingConfig(name='LivePackagingConfig'),
    manifestName?: string(name='ManifestName', description='The playlist name.', example='manifest'),
    protocol?: string(name='Protocol', description='The distribution protocol.', example='HLS'),
    timeshiftVision?: int32(name='TimeshiftVision', description='The number of days that time-shifted content is available.', example='5'),
  }(name='LivePackageOriginEndpoint', description='The information about the origin endpoints.'),
  requestId?: string(name='RequestId', description='The request ID.', example='requestIdExample123'),
}

model GetLivePackageOriginEndpointResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLivePackageOriginEndpointResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * @param request  the request parameters of GetLivePackageOriginEndpoint  GetLivePackageOriginEndpointRequest
  * @return GetLivePackageOriginEndpointResponse
 */
async function getLivePackageOriginEndpoint(request: GetLivePackageOriginEndpointRequest): GetLivePackageOriginEndpointResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLivePackageOriginEndpoint', 'POST', '/', 'json', false, 'json', request);
}

model GetLiveRecordJobRequest {
  jobId: string(name='JobId', description='The ID of the recording job.

This parameter is required.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66', position='Query'),
}

model GetLiveRecordJobResponseBody = {
  recordJob?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T02:48:58Z'),
    jobId?: string(name='JobId', description='The ID of the recording job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
    name?: string(name='Name', description='The name of the recording job.'),
    notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify'),
    recordOutput?: {
      bucket?: string(name='Bucket', description='The bucket name.', example='imsbucket1'),
      endpoint?: string(name='Endpoint', description='The endpoint of the storage service.', example='oss-cn-shanghai.aliyuncs.com'),
      type?: string(name='Type', description='The type of the storage address.

Valid values:

*   vod
*   oss', example='oss'),
    }(name='RecordOutput', description='The storage address of the recording.'),
    status?: string(name='Status', description='The state of the recording job.

Valid values:

*   paused: The job is paused.
*   initial: The job is not started.
*   started: The job is in progress.', example='paused'),
    streamInput?: {
      type?: string(name='Type', description='The type of the live stream. The value can only be rtmp.', example='rtmp'),
      url?: string(name='Url', description='The URL of the live stream.', example='rtmp://example.com/app/stream'),
    }(name='StreamInput', description='The URL of the live stream.'),
    templateId?: string(name='TemplateId', description='The ID of the recording template.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
    templateName?: string(name='TemplateName', description='The name of the recording template.', example='test template'),
  }(name='RecordJob', description='The details of the recording job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='B57A046C-CE33-5FBB-B57A-D2B89ACF6907'),
}

model GetLiveRecordJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveRecordJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveRecordJob  GetLiveRecordJobRequest
  * @return GetLiveRecordJobResponse
 */
async function getLiveRecordJob(request: GetLiveRecordJobRequest): GetLiveRecordJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveRecordJob', 'GET', '/', 'json', false, 'json', request);
}

model GetLiveRecordTemplateRequest {
  jobId?: string(name='JobId', description='The ID of the recording job. You can specify the JobId parameter to retrieve the snapshot of the template used by the job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66', position='Query'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66', position='Query'),
}

model GetLiveRecordTemplateResponseBody = {
  recordTemplate?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
    lastModified?: string(name='LastModified', description='The time when the template was last modified.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
    name?: string(name='Name', description='The template name.', example='test template'),
    recordFormatList?: [ 
      {
        cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds. If you do not specify this parameter, the default value 6 hours is used.', example='7200'),
        format?: string(name='Format', description='The output file format.', example='m3u8'),
        ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording file that is stored in Object Storage Service (OSS).', example='record/{JobId}/{Sequence}{EscapedStartTime}{EscapedEndTime}'),
        sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds.', example='30'),
        sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
      }
    ](name='RecordFormatList', description='The list of recording formats.'),
    templateId?: string(name='TemplateId', description='The template ID.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
    type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
  }(name='RecordTemplate', description='The recording template.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C892855F-95DF-50D6-A28C-279ABDB76810'),
}

model GetLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveRecordTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveRecordTemplate  GetLiveRecordTemplateRequest
  * @return GetLiveRecordTemplateResponse
 */
async function getLiveRecordTemplate(request: GetLiveRecordTemplateRequest): GetLiveRecordTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveRecordTemplate', 'GET', '/', 'json', false, 'json', request);
}

model GetLiveSnapshotJobRequest {
  jobId: string(name='JobId', description='The job ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Query'),
}

model GetLiveSnapshotJobResponseBody = {
  callbackUrl?: string(name='CallbackUrl', description='The snapshot callback URL.', example='http://www.aliyun.com/snapshot/callback'),
  createTime?: string(name='CreateTime', description='The time when the file was created.', example='2022-02-02T22:22:22Z'),
  jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287782****'),
  jobName?: string(name='JobName', description='The name of the job.'),
  lastModified?: string(name='LastModified', description='The time when the file was last modified.', example='2022-02-02T22:22:22Z'),
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.', example='snapshot/{JobId}.jpg'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.', example='snapshot/{JobId}/{UnixTimestamp}.jpg'),
  snapshotOutput?: {
    bucket?: string(name='Bucket', description='The bucket of the output endpoint. If the storage type is set to oss, the OSS bucket is returned.', example='testbucket'),
    endpoint?: string(name='Endpoint', description='The output endpoint. If the storage type is set to oss, the Object Storage Service (OSS) domain name is returned.', example='oss-cn-shanghai.aliyuncs.com'),
    storageType?: string(name='StorageType', description='The storage type. The value can only be oss.', example='oss'),
  }(name='SnapshotOutput', description='The output information.'),
  status?: string(name='Status', description='The state of the job.

Valid values:

*   init: The job is not started.
*   paused: The job is paused.
*   started: The job is in progress.', example='started'),
  streamInput?: {
    type?: string(name='Type', description='The type of the input stream. The value can only be rtmp.', example='rtmp'),
    url?: string(name='Url', description='The URL of the input stream.', example='rtmp://www.aliyun.com/stream'),
  }(name='StreamInput', description='The input information.'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287666****'),
  templateName?: string(name='TemplateName', description='The name of the template.'),
  timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots.', example='5'),
}

model GetLiveSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveSnapshotJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveSnapshotJob  GetLiveSnapshotJobRequest
  * @return GetLiveSnapshotJobResponse
 */
async function getLiveSnapshotJob(request: GetLiveSnapshotJobRequest): GetLiveSnapshotJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveSnapshotJob', 'GET', '/', 'json', false, 'json', request);
}

model GetLiveSnapshotTemplateRequest {
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Query'),
}

model GetLiveSnapshotTemplateResponseBody = {
  createTime?: string(name='CreateTime', description='The time when the configuration was modified.', example='2022-02-02T22:22:22Z'),
  lastModified?: string(name='LastModified', description='The time when the template was created.', example='2022-02-02T22:22:22Z'),
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.', example='snapshot/{JobId}.jpg'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.', example='snapshot/{JobId}/{UnixTimestamp}.jpg'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287782****'),
  templateName?: string(name='TemplateName', description='The template name.'),
  timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots.', example='5'),
  type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
}

model GetLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveSnapshotTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveSnapshotTemplate  GetLiveSnapshotTemplateRequest
  * @return GetLiveSnapshotTemplateResponse
 */
async function getLiveSnapshotTemplate(request: GetLiveSnapshotTemplateRequest): GetLiveSnapshotTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveSnapshotTemplate', 'GET', '/', 'json', false, 'json', request);
}

model GetLiveTranscodeJobRequest {
  jobId: string(name='JobId', description='The ID of the transcoding job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetLiveTranscodeJobResponseBody = {
  job?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T02:48:58Z'),
    jobId?: string(name='JobId', description='The ID of the transcoding job.', example='****20b48fb04483915d4f2cd8ac****'),
    name?: string(name='Name', description='The name of the transcoding job.', example='task1'),
    outputStream?: {
      streamInfos?: [ 
        {
          outputUrl?: string(name='OutputUrl', description='The URL of the output stream.', example='rtmp://mydomain/app/mytranscode1'),
          type?: string(name='Type', description='The type of the output stream protocol. Only the RTMP protocol is supported.', example='rtmp'),
        }
      ](name='StreamInfos', description='The information about the output stream.'),
    }(name='OutputStream', description='The information about the output stream.'),
    startMode?: int32(name='StartMode', description='The start mode of the job.', example='0'),
    status?: int32(name='Status', description='The state of the job.

*   0: The job is not started.
*   1: The job is in progress.
*   2: The job is stopped.', example='1'),
    streamInput?: {
      inputUrl?: string(name='InputUrl', description='The URL of the input stream.', example='rtmp://mydomain/app/stream1'),
      type?: string(name='Type', description='The type of the input stream.', example='rtmp'),
    }(name='StreamInput', description='The information about the input stream.'),
    templateId?: string(name='TemplateId', description='The template ID.', example='b6491d5b3e514b7d895d14b5453ea119'),
    templateName?: string(name='TemplateName', description='The template name.', example='basic'),
    templateType?: string(name='TemplateType', description='The type of the template.', example='normal'),
  }(name='Job', description='The information about the transcoding job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model GetLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveTranscodeJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveTranscodeJob  GetLiveTranscodeJobRequest
  * @return GetLiveTranscodeJobResponse
 */
async function getLiveTranscodeJob(request: GetLiveTranscodeJobRequest): GetLiveTranscodeJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveTranscodeJob', 'POST', '/', 'json', false, 'json', request);
}

model GetLiveTranscodeTemplateRequest {
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287666****', position='Query'),
}

model GetLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  templateContent?: {
    category?: string(name='Category', description='The category of the template. Valid values:

*   system
*   customized', example='customized'),
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-25T06:15:14Z'),
    name?: string(name='Name', description='The name of the template.', example='my-template'),
    templateConfig?: {
      audioParams?: {
        bitrate?: string(name='Bitrate', description='The bitrate of the output audio.', example='1000'),
        channels?: string(name='Channels', description='The number of sound channels.', example='2'),
        codec?: string(name='Codec', description='The audio codec.', example='AAC'),
        profile?: string(name='Profile', description='The audio codec profile.', example='1'),
        samplerate?: string(name='Samplerate', description='The audio sampling rate.', example='44100'),
      }(name='AudioParams', description='The audio parameters.'),
      videoParams?: {
        bitrate?: string(name='Bitrate', description='The bitrate of the output video.', example='2500'),
        codec?: string(name='Codec', description='The encoding type.', example='H.264'),
        fps?: string(name='Fps', description='The frame rate of the output video.', example='30'),
        gop?: string(name='Gop', description='The group of pictures (GOP) of the output video.', example='1000'),
        height?: string(name='Height', description='The height of the output video.', example='720'),
        profile?: string(name='Profile', description='The encoding profile.', example='2'),
        width?: string(name='Width', description='The width of the output video.', example='1280'),
      }(name='VideoParams', description='The video parameters.'),
    }(name='TemplateConfig', description='The configuration of the template.'),
    templateId?: string(name='TemplateId', description='The template ID.', example='bcfa57950bc649b2abfb476ecd36ea4f'),
    type?: string(name='Type', description='The type of the template.', example='normal'),
  }(name='TemplateContent', description='The content of the template.'),
}

model GetLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveTranscodeTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLiveTranscodeTemplate  GetLiveTranscodeTemplateRequest
  * @return GetLiveTranscodeTemplateResponse
 */
async function getLiveTranscodeTemplate(request: GetLiveTranscodeTemplateRequest): GetLiveTranscodeTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLiveTranscodeTemplate', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaConnectAvailableRegionRequest {
}

model GetMediaConnectAvailableRegionResponseBody = {
  content?: {
    defaultRegion?: string(name='DefaultRegion', description='The default region. You can ignore the parameter.', example='cn-shanghai'),
    regionList?: [ string ](name='RegionList', description='The supported regions.'),
  }(name='Content', description='The rsponse body.'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='41CB9D4C-4650-5723-BA89-D6824F706ACB'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model GetMediaConnectAvailableRegionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaConnectAvailableRegionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetMediaConnectAvailableRegion  GetMediaConnectAvailableRegionRequest
  * @return GetMediaConnectAvailableRegionResponse
 */
async function getMediaConnectAvailableRegion(request: GetMediaConnectAvailableRegionRequest): GetMediaConnectAvailableRegionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaConnectAvailableRegion', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaConnectFlowRequest {
  flowId: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f', position='Query'),
}

model GetMediaConnectFlowResponseBody = {
  content?: {
    createTime?: string(name='CreateTime', description='The time when the flow was created.', example='2024-07-18T01:29:24Z'),
    flowFailover?: string(name='FlowFailover'),
    flowId?: string(name='FlowId', description='The flow ID.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f'),
    flowName?: string(name='FlowName', description='The flow name.', example='AliTestFlow'),
    flowRegion?: string(name='FlowRegion'),
    flowStatus?: string(name='FlowStatus', description='The state of the flow.', example='online'),
    startTime?: string(name='StartTime', description='The time when the flow is started.', example='2024-07-18T01:39:24Z'),
  }(name='Content', description='The response body.'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='FB503AEF-118E-1516-89E2-7B227EA1AC20'),
  retcode?: int32(name='Retcode', description='The returned code. A value of 0 indicates the call is successful.', example='0'),
}

model GetMediaConnectFlowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaConnectFlowResponseBody(name='body'),
}

/**
  * @description *   When the specified flow ID is not available, an error code is returned.
  * *   The returned StartTime is valid only when the flow is in the online state.
  * @param request  the request parameters of GetMediaConnectFlow  GetMediaConnectFlowRequest
  * @return GetMediaConnectFlowResponse
 */
async function getMediaConnectFlow(request: GetMediaConnectFlowRequest): GetMediaConnectFlowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaConnectFlow', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaConnectFlowAllOutputNameRequest {
  flowId: string(name='FlowId', description='The ID of the MediaConnect flow.

This parameter is required.', example='0381f478-7d53-4076-9d5f-27680a6f73e7', position='Query'),
}

model GetMediaConnectFlowAllOutputNameResponseBody = {
  content?: [ string ](name='Content', description='The response body, as an array of strings.'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The request ID.', example='559E9828-245D-5CBA-9C7A-4E01453F091F'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model GetMediaConnectFlowAllOutputNameResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaConnectFlowAllOutputNameResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetMediaConnectFlowAllOutputName  GetMediaConnectFlowAllOutputNameRequest
  * @return GetMediaConnectFlowAllOutputNameResponse
 */
async function getMediaConnectFlowAllOutputName(request: GetMediaConnectFlowAllOutputNameRequest): GetMediaConnectFlowAllOutputNameResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaConnectFlowAllOutputName', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaConnectFlowInputRequest {
  flowId: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f', position='Query'),
}

model GetMediaConnectFlowInputResponseBody = {
  content?: {
    backupCidrs?: string(name='BackupCidrs'),
    backupCreateTime?: string(name='BackupCreateTime'),
    backupInputName?: string(name='BackupInputName'),
    backupInputStatus?: string(name='BackupInputStatus'),
    backupInputUrl?: string(name='BackupInputUrl'),
    backupMaxBitrate?: int32(name='BackupMaxBitrate'),
    backupSrtLatency?: int32(name='BackupSrtLatency'),
    backupSrtPassphrase?: string(name='BackupSrtPassphrase'),
    backupSrtPbkeyLen?: int32(name='BackupSrtPbkeyLen'),
    cidrs?: string(name='Cidrs', description='The IP address whitelist in CIDR format. CIDR blocks are separated with commas (,).', example='10.211.0.0/17'),
    createTime?: string(name='CreateTime', description='The time when the flow was created.', example='2024-07-18T01:29:24Z'),
    inputName?: string(name='InputName', description='The source name.', example='AliTestInput'),
    inputProtocol?: string(name='InputProtocol', description='The source type.

Valid values:

*   RTMP-PUSH
*   SRT-Caller
*   RTMP-PULL
*   SRT-Listener
*   Flow', example='RTMP-PUSH'),
    inputStatus?: string(name='InputStatus'),
    inputUrl?: string(name='InputUrl', description='The source URL.', example='rtmp://1.2.3.4:1935/live/AliTestInput_8666ec062190f00e263012666319a5be'),
    maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s.', example='2000000'),
    pairFlowId?: string(name='PairFlowId', description='The ID of the source flow. This parameter is returned when the source type is Flow.', example='05c3adf4-aa0e-421d-a991-48ceae3e642e'),
    pairOutputName?: string(name='PairOutputName', description='The output of the source flow. This parameter is returned when the source type is Flow.', example='AliTestOutput'),
    srtLatency?: int32(name='SrtLatency', description='The latency for the SRT stream. Unit: milliseconds. This parameter is returned when the source type is SRT-Listener or SRT-Caller.', example='1000'),
    srtPassphrase?: string(name='SrtPassphrase', description='The SRT key. This parameter is returned when the source type is SRT-Listener or SRT-Caller.', example='FICUBPX4Q77DYHRF'),
    srtPbkeyLen?: int32(name='SrtPbkeyLen', description='The encryption key length. This parameter is returned when the source type is SRT-Listener or SRT-Caller.

Valid values:

*   0
*   16
*   24
*   32', example='32'),
  }(name='Content', description='The response body.'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D4C231DF-103A-55FF-8D09-E699552457DE'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model GetMediaConnectFlowInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaConnectFlowInputResponseBody(name='body'),
}

/**
  * @description *   When the specified flow ID is not available, an error code is returned.
  * @param request  the request parameters of GetMediaConnectFlowInput  GetMediaConnectFlowInputRequest
  * @return GetMediaConnectFlowInputResponse
 */
async function getMediaConnectFlowInput(request: GetMediaConnectFlowInputRequest): GetMediaConnectFlowInputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaConnectFlowInput', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaConnectFlowOutputRequest {
  flowId: string(name='FlowId', description='The flow ID.

This parameter is required.', example='0381f478-7d53-4076-9d5f-27680a6f73e7', position='Query'),
  outputName: string(name='OutputName', description='The name of the output that you want to query.

This parameter is required.', example='AliTestOutput', position='Query'),
}

model GetMediaConnectFlowOutputResponseBody = {
  content?: {
    cidrs?: string(name='Cidrs', description='The IP address whitelist in CIDR format. CIDR blocks are separated with commas (,).', example='10.211.0.0/17'),
    createTime?: string(name='CreateTime', description='The time when the flow was created.', example='2024-07-18T01:29:24Z'),
    forbid?: string(name='Forbid'),
    outputName?: string(name='OutputName', description='The output name.', example='AliTestInput'),
    outputProtocol?: string(name='OutputProtocol', description='The output type.

Valid values:

*   RTMP-PUSH
*   SRT-Caller
*   RTMP-PULL
*   SRT-Listener
*   Flow', example='SRT-PULL'),
    outputUrl?: string(name='OutputUrl', description='The output URL.', example='srt://1.2.3.4:1025'),
    pairFlowId?: string(name='PairFlowId', description='The ID of the destination flow. This parameter is returned when the output type is Flow.', example='805fbdd0-575e-4146-b35d-ec7f63937b20'),
    pairInputName?: string(name='PairInputName', description='The source name of the destination flow. This parameter is returned when the output type is Flow.', example='AliTestInput'),
    playerLimit?: int32(name='PlayerLimit', description='The maximum number of viewers.', example='5'),
    srtLatency?: int32(name='SrtLatency', description='The latency for the SRT stream. Unit: milliseconds. This parameter is returned when the source type is SRT-Listener or SRT-Caller.', example='1000'),
    srtPassphrase?: string(name='SrtPassphrase', description='The SRT key. This parameter is returned when the source type is SRT-Listener or SRT-Caller.', example='FICUBPX4Q77DYHRF'),
    srtPbkeyLen?: int32(name='SrtPbkeyLen', description='The encryption key length. This parameter is returned when the source type is SRT-Listener or SRT-Caller.

Valid values:

*   0
*   16
*   24
*   32', example='32'),
  }(name='Content', description='The response body.'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='0DB23DCE-0D69-598B-AA7C-7268D55E2F89'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model GetMediaConnectFlowOutputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaConnectFlowOutputResponseBody(name='body'),
}

/**
  * @description *   When the specified flow ID is not available, an error code is returned.
  * @param request  the request parameters of GetMediaConnectFlowOutput  GetMediaConnectFlowOutputRequest
  * @return GetMediaConnectFlowOutputResponse
 */
async function getMediaConnectFlowOutput(request: GetMediaConnectFlowOutputRequest): GetMediaConnectFlowOutputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaConnectFlowOutput', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaConvertJobRequest {
  jobId?: string(name='JobId', description='The ID of the transcoding task.', example='****d80e4e4044975745c14b****', position='Query'),
}

model GetMediaConvertJobResponseBody = {
  job?: {
    clientToken?: string(name='ClientToken', description='The idempotency key of the request for creating the transcoding task.', example='780018cb-55ba-466d-8acc-946c0c319a0e'),
    code?: string(name='Code', description='The error code returned when the transcoding task failed.', example='InvalidParameter.ResourceContentBad'),
    config?: {
      inputs?: [
        MediaConvertInput
      ](name='Inputs', description='The inputs of the transcoding task.'),
      jobName?: string(name='JobName'),
      outputGroups?: [
        MediaConvertOutputGroup
      ](name='OutputGroups', description='The output group configurations.'),
      outputs?: [
        MediaConvertOutput
      ](name='Outputs', description='The output configurations.'),
    }(name='Config', description='The configurations of the transcoding task.'),
    createTime?: string(name='CreateTime'),
    finishTime?: string(name='FinishTime'),
    jobId?: string(name='JobId', description='The ID of the transcoding task, which is a 32-bit string.', example='******4579b5e748b99a27f6d6******'),
    message?: string(name='Message', description='The error message returned when the transcoding task failed.', example='The resource operated InputFile is bad'),
    outputDetails?: [
      MediaConvertOutputDetail
    ](name='OutputDetails', description='The details of the transcoded outputs, each corresponding to an output configuration.'),
    outputGroupDetails?: [
      MediaConvertOutputGroupDetail
    ](name='OutputGroupDetails', description='The details of the output groups, each corresponding to an output group configuration.'),
    percent?: int32(name='Percent'),
    pipelineId?: string(name='PipelineId', description='The ID of the queue.', example='83500cb2a3b94fabb0956e38d64bd16d'),
    requestId?: string(name='RequestId', description='The ID of the request for creating the transcoding task.', example='******11-DB8D-4A9A-875B-275798******'),
    state?: string(name='State', description='The status of the transcoding task. Valid values:

*   Inited: The task is initialized.
*   Running
*   Success
*   Failed
*   Cancelled', example='Success'),
    userData?: string(name='UserData', description='The user data.', example='{"videoId":"ddd333"}'),
  }(name='Job', description='The transcoding task.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='4BAEA8E8-1C16-5CD3-AC50-CCBA81A53402'),
}

model GetMediaConvertJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaConvertJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetMediaConvertJob  GetMediaConvertJobRequest
  * @return GetMediaConvertJobResponse
 */
async function getMediaConvertJob(request: GetMediaConvertJobRequest): GetMediaConvertJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaConvertJob', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  authTimeout?: long(name='AuthTimeout', position='Query'),
  inputURL?: string(name='InputURL', description='The input URL of the media asset in another service. The URL must be registered in the IMS content library and bound to the ID of the media asset in IMS.

*   For a media asset from Object Storage Service (OSS), the URL may have one of the following formats:

http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4 or

oss://example-bucket/example.mp4. The second format indicates that the region in which the OSS bucket of the media asset resides is the same as the region in which OSS is activated.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset in IMS. If this parameter is left empty, the InputURL parameter must be specified.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  outputType?: string(name='OutputType', description='The type of the URL of the media asset to return in the response. Valid values:

*   oss (default): an OSS URL.
*   cdn: a CDN URL. A CDN URL is returned only if the media asset is imported from ApsaraVideo VOD and the relevant domain name is an accelerated domain name in ApsaraVideo VOD.', example='cdn', position='Query'),
  returnDetailedInfo?: string(name='ReturnDetailedInfo', description='Specifies whether to return detailed information for specific media asset attributes. Supported attributes: AiRoughData.StandardSmartTagJob, which specifies whether to return detailed tag information if a tagging job has been submitted for the media asset. Valid values for the attribute:

*   false (default): The job result is returned as a URL.
*   true: The job result is returned as text.', example='{"AiRoughData.StandardSmartTagJob": false}', position='Query'),
}

model GetMediaInfoResponseBody = {
  mediaInfo?: {
    aiRoughData?: {
      aiCategory?: string(name='AiCategory', description='The AI category. Valid values:

*   Life
*   Good-looking
*   Cute pets
*   News
*   Ads
*   Environmental resources
*   Automobile'),
      aiJobId?: string(name='AiJobId', description='The ID of the AI task.', example='****483915d4f2cd8ac20b48fb04****'),
      result?: string(name='Result', description='The analysis result.', example='https://sample-bucket.cn-shanghai.aliyuncs.com/result.json'),
      saveType?: string(name='SaveType', description='The storage type. This parameter indicates the library in which the analysis data is stored. Valid values:

*   TEXT: the text library.', example='TEXT'),
      standardSmartTagJob?: {
        aiJobId?: string(name='AiJobId', description='The ID of the AI task.', example='****483915d4f2cd8ac20b48fb04****'),
        resultUrl?: string(name='ResultUrl', description='The URL of the tagging result.', example='http://xx.oss-cn-shanghai.aliyuncs.com/result2.txt'),
        results?: [ 
          {
            data?: string(name='Data', description='The result data. The value is a JSON string. For information about the data structures of different data types<props="china">, see [Description of the Results parameter](https://help.aliyun.com/zh/ims/developer-reference/api-ice-2020-11-09-querysmarttagjob?spm=a2c4g.11186623.0.0.521d48b7KfapOL#api-detail-40).', example='{"autoChapters": [...]}'),
            type?: string(name='Type', description='The tagging type. Valid values:

*   NLP: natural language processing (NLP)-based tagging', example='NLP'),
          }
        ](name='Results', description='The recognized tags.'),
        status?: string(name='Status', description='The analysis status. Valid values:

*   Analyzing
*   AnalyzeSuccess
*   AnalyzeFailed', example='Analyzing'),
      }(name='StandardSmartTagJob', description='The information about the tagging job.'),
      status?: string(name='Status', description='The analysis status. Valid values:

*   Analyzing
*   AnalyzeSuccess
*   AnalyzeFailed
*   Saving
*   SaveSuccess
*   SaveFailed
*   Deleting
*   DeleteSuccess
*   DeleteFailed', example='Analyzing'),
    }(name='AiRoughData', description='The original AI analysis data.'),
    fileInfoList?: [ 
      {
        audioStreamInfoList?: [ 
          {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='127.794'),
            channelLayout?: string(name='ChannelLayout', description='The output layout of sound channels.', example='stereo'),
            channels?: string(name='Channels', description='The number of sound channels.', example='2'),
            codecLongName?: string(name='CodecLongName', description='The full name of the codec.', example='AAC (Advanced Audio Coding)'),
            codecName?: string(name='CodecName', description='The short name of the codec.', example='aac'),
            codecTag?: string(name='CodecTag', description='The tag of the codec.', example='0x6134706d'),
            codecTagString?: string(name='CodecTagString', description='The tag string of the codec.', example='mp4a'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the codec.', example='1/24000'),
            duration?: string(name='Duration', description='The duration.', example='16.200998'),
            fps?: string(name='Fps', description='The audio frame rate.', example='8'),
            index?: string(name='Index', description='The sequence number of the audio track.', example='1'),
            lang?: string(name='Lang', description='The language.', example='und'),
            numFrames?: string(name='NumFrames', description='The number of frames.', example='10'),
            profile?: string(name='Profile', description='The codec profile.', example='High'),
            sampleFmt?: string(name='SampleFmt', description='The sampling format.', example='fltp'),
            sampleRate?: string(name='SampleRate', description='The sampling rate.', example='44100'),
            startTime?: string(name='StartTime', description='The start time.', example='0.000000'),
            timebase?: string(name='Timebase', description='The time base.', example='1/44100'),
          }
        ](name='AudioStreamInfoList', description='The information about the audio tracks. A media asset may have multiple audio tracks.'),
        fileBasicInfo?: {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
          createTime?: string(name='CreateTime', description='The time when the file was created.', example='2020-12-26T04:11:08Z'),
          duration?: string(name='Duration', description='The duration.', example='216.206667'),
          fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
          fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
          fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
          fileType?: string(name='FileType', description='The file type.', example='source_file'),
          fileUrl?: string(name='FileUrl', description='The OSS URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
          formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
          height?: string(name='Height', description='The height.', example='540'),
          modifiedTime?: string(name='ModifiedTime', description='The time when the file was last modified.', example='2020-12-26T04:11:10Z'),
          region?: string(name='Region', description='The region in which the file is stored.', example='cn-shanghai'),
          width?: string(name='Width', description='The width.', example='960'),
        }(name='FileBasicInfo', description='The basic information about the file, including the duration and size.'),
        subtitleStreamInfoList?: [ 
          {
            codecLongName?: string(name='CodecLongName', description='The full name of the codec.', example='SubRip Text'),
            codecName?: string(name='CodecName', description='The short name of the codec.', example='srt'),
            codecTag?: string(name='CodecTag', description='The tag of the codec.', example='unicode'),
            codecTagString?: string(name='CodecTagString', description='The tag string of the codec.', example='unicode'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the codec.', example='29.97'),
            duration?: string(name='Duration', description='The duration.', example='1'),
            index?: string(name='Index', description='The sequence number of the subtitle track.', example='1'),
            lang?: string(name='Lang', description='The language.', example='und'),
            startTime?: string(name='StartTime', description='The start time.', example='0'),
            timebase?: string(name='Timebase', description='The time base.', example='30'),
          }
        ](name='SubtitleStreamInfoList', description='The information about the subtitle tracks. A media asset may have multiple subtitle tracks.'),
        videoStreamInfoList?: [ 
          {
            avgFPS?: string(name='AvgFPS', description='The average video frame rate.', example='24.0'),
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1001.594'),
            codecLongName?: string(name='CodecLongName', description='The full name of the codec.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
            codecName?: string(name='CodecName', description='The short name of the codec.', example='h264'),
            codecTag?: string(name='CodecTag', description='The tag of the codec.', example='0x0000'),
            codecTagString?: string(name='CodecTagString', description='The tag string of the codec.', example='[0][0][0][0]'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the codec.', example='1/48'),
            dar?: string(name='Dar', description='The display aspect ratio (DAR).', example='0:1'),
            duration?: string(name='Duration', description='The duration.', example='216.206706'),
            fps?: string(name='Fps', description='The video frame rate.', example='24.0'),
            hasBFrames?: string(name='HasBFrames', description='Indicates whether the video track contains bidirectional frames (B-frames).', example='2'),
            height?: string(name='Height', description='The height.', example='540'),
            index?: string(name='Index', description='The sequence number of the video track.', example='0'),
            lang?: string(name='Lang', description='The language.', example='und'),
            level?: string(name='Level', description='The codec level.', example='30'),
            nbFrames?: string(name='Nb_frames', description='The total number of frames.', example='5184'),
            numFrames?: string(name='NumFrames', description='The number of frames.', example='5184'),
            pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
            profile?: string(name='Profile', description='The codec profile.', example='High'),
            rotate?: string(name='Rotate', description='The rotation angle.', example='0'),
            sar?: string(name='Sar', description='The sample aspect ratio (SAR).', example='0:1'),
            startTime?: string(name='StartTime', description='The start time.', example='0.081706'),
            timebase?: string(name='Timebase', description='The time base.', example='1/12288'),
            width?: string(name='Width', description='The width.', example='960'),
          }
        ](name='VideoStreamInfoList', description='The information about the video tracks. A media asset may have multiple video tracks.'),
      }
    ](name='FileInfoList', description='The file information.'),
    mediaBasicInfo?: {
      biz?: string(name='Biz', description='The service to which the media asset belongs.', example='ICE'),
      businessType?: string(name='BusinessType', description='The business type.', example='general'),
      cateId?: long(name='CateId', description='The category ID.', example='3048'),
      cateName?: string(name='CateName', description='The category name.', example='cateName'),
      category?: string(name='Category', description='The category.'),
      coverURL?: string(name='CoverURL', description='The URL of the thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
      createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-26T04:11:08Z'),
      deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-26T04:11:15Z'),
      description?: string(name='Description', description='The content description.'),
      inputURL?: string(name='InputURL', description='The input URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
      mediaTags?: string(name='MediaTags', description='The tags.'),
      mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-26T04:11:10Z'),
      referenceId?: string(name='ReferenceId', description='The custom ID. The ID can be 6 to 64 characters in length and can contain only letters, digits, hyphens (-), and underscores (_). The ID is unique among users.', example='123-1234'),
      snapshots?: string(name='Snapshots', description='The snapshots.', example='[
    "http://example-bucket.oss-cn-shanghai.aliyuncs.com/snapshot-00001.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>",
    "http://example-bucket.oss-cn-shanghai.aliyuncs.com/snapshot-00002.jpg?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>",
    "http://example-bucket.oss-cn-shanghai.aliyuncs.com/snapshot-00003.jpg?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>"
]'),
      source?: string(name='Source', description='The source.', example='oss'),
      spriteImages?: string(name='SpriteImages', description='The sprite.', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
      status?: string(name='Status', description='The resource status.', example='Normal'),
      title?: string(name='Title', description='The title.'),
      uploadSource?: string(name='UploadSource', description='The upload source of the media asset.', example='general'),
      userData?: string(name='UserData', description='The user data.', example='userDataTest'),
    }(name='MediaBasicInfo', description='The basic information about the media asset.'),
    mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  }(name='MediaInfo', description='The information about the media asset.'),
  requestId?: string(name='RequestId', description='The request ID.', example='2FDE2411-DB8D-4A9A-875B-275798F14A5E'),
}

model GetMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaInfoResponseBody(name='body'),
}

/**
  * @description If the MediaId parameter is specified, the MediaId parameter is preferentially used for the query. If the MediaId parameter is left empty, the InputURL parameter must be specified.
  * @param request  the request parameters of GetMediaInfo  GetMediaInfoRequest
  * @return GetMediaInfoResponse
 */
async function getMediaInfo(request: GetMediaInfoRequest): GetMediaInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaInfo', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaInfoJobRequest {
  jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8', position='Query'),
}

model GetMediaInfoJobResponseBody = {
  mediaInfoJob?: {
    async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
    input?: {
      media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    mediaInfoProperty?: {
      audioStreamInfoList?: [ 
        {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
          channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
          codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
          codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
          codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
          codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
          duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
          index?: string(name='Index', description='The sequence number of the stream.', example='1'),
          lang?: string(name='Lang', description='The language of the stream.', example='us'),
          sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
          sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
          startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
          timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
        }
      ](name='AudioStreamInfoList', description='The information about the audio stream.'),
      fileBasicInfo?: {
        bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
        duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
        fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
        fileSize?: string(name='FileSize', description='The file size.', example='31737'),
        fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
        fileType?: string(name='FileType', description='The file type.', example='source_file'),
        fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
        formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
        height?: string(name='Height', description='The height of the output video.', example='478'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='e520090207114cc7a392d44f0b211574'),
        region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
        width?: string(name='Width', description='The width of the output video.', example='848'),
      }(name='FileBasicInfo', description='The basic file information.'),
      videoStreamInfoList?: [ 
        {
          avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
          bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
          codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
          codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
          codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
          codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
          codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
          dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          fps?: string(name='Fps', description='The frame rate.', example='25.0'),
          hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
          height?: string(name='Height', description='The height of the output video.', example='478'),
          index?: string(name='Index', description='The sequence number of the stream.', example='0'),
          lang?: string(name='Lang', description='The language of the stream.', example='zh'),
          level?: string(name='Level', description='The codec level.', example='31'),
          numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
          pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
          profile?: string(name='Profile', description='The encoder profile.', example='High'),
          rotate?: string(name='Rotate', description='The rotation angle of the video image.', example='0'),
          sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
          startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
          timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
          width?: string(name='Width', description='The width of the output video.', example='848'),
        }
      ](name='VideoStreamInfoList', description='The information about the video stream.'),
    }(name='MediaInfoProperty', description='The details of the media information.'),
    name?: string(name='Name', description='The job name.', example='job-name'),
    requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling information.'),
    status?: string(name='Status', description='The state of the job. Valid values: Init (the job is submitted), Success (the job is successful), and Fail (the job failed).', example='Init'),
    submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='MediaInfoJob', description='MediaInfoJobDTO'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model GetMediaInfoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaInfoJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetMediaInfoJob  GetMediaInfoJobRequest
  * @return GetMediaInfoJobResponse
 */
async function getMediaInfoJob(request: GetMediaInfoJobRequest): GetMediaInfoJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaInfoJob', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaLiveChannelRequest {
  channelId: string(name='ChannelId', description='The ID of the channel.

This parameter is required.', example='SEGK5KA6KYKAWQQH', position='Body'),
}

model GetMediaLiveChannelResponseBody = {
  channel?: {
    audioSettings?: [ 
      {
        audioCodec?: string(name='AudioCodec', description='The audio codec.', example='aac'),
        audioCodecSetting?: {
          bitrate?: int32(name='Bitrate', description='The audio bitrate. Unit: bit/s.', example='200000'),
          profile?: string(name='Profile', description='The audio codec profile.', example='AAC-LOW'),
          sampleRate?: int32(name='SampleRate', description='The audio sample rate. Unit: Hz.', example='44100'),
        }(name='AudioCodecSetting', description='The audio encoding settings.'),
        audioSelectorName?: string(name='AudioSelectorName', description='The name of the audio selector.', example='myselector'),
        languageCode?: string(name='LanguageCode', description='A three-letter ISO 639-2 language code.', example='eng'),
        languageName?: string(name='LanguageName', description='The name of the language.', example='English'),
        name?: string(name='Name', description='The name of the audio settings.', example='zhuanfengzhuang'),
      }
    ](name='AudioSettings', description='The audio settings.'),
    channelId?: string(name='ChannelId', description='The ID of the channel.', example='SEGK5KA6KYKAWQQH'),
    createTime?: string(name='CreateTime', description='The time when the channel was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-12-03T06:56:42Z'),
    inputAttachments?: [ 
      {
        audioSelectors?: [ 
          {
            audioLanguageSelection?: {
              languageCode: string(name='LanguageCode', description='A three-letter ISO 639-2 language code from within an audio source.

This parameter is required.', example='eng'),
            }(name='AudioLanguageSelection', description='The audio language selection.'),
            audioPidSelection?: {
              pid: long(name='Pid', description='A PID from within a source.

This parameter is required.', example='123'),
            }(name='AudioPidSelection', description='The audio PID selection.'),
            audioTrackSelection?: [ 
              {
                trackId: long(name='TrackId', description='The track ID from within a source.

This parameter is required.', example='1'),
              }
            ](name='AudioTrackSelection', description='The audio track selection.'),
            name: string(name='Name', description='The name of the audio selector.

This parameter is required.', example='myselector'),
          }
        ](name='AudioSelectors', description='The audio selectors.'),
        inputId: string(name='InputId', description='The ID of the associated input.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
        inputName?: string(name='InputName', description='The name of the input.', example='myinput'),
        languageName?: string(name='LanguageName', description='The language name.', example='eng'),
      }
    ](name='InputAttachments', description='The inputs associated with the channel.'),
    lastStartTime?: string(name='LastStartTime', description='The time when the channel was last started. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC. If the channel has never been started since it was created, an empty string is returned.', example='2024-12-03T06:56:42Z'),
    lastStopTime?: string(name='LastStopTime', description='The time when the channel was last stopped. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC. If the channel has never stopped since it was created, an empty string is returned.', example='2024-12-03T06:56:42Z'),
    name?: string(name='Name', description='The channel name.', example='mych'),
    outputGroups?: [ 
      {
        mediaPackageGroupSetting?: {
          channelName?: string(name='ChannelName', description='ChannelName in MediaPackage.', example='myPackageChannel'),
          groupName?: string(name='GroupName', description='GroupName in MediaPackage.', example='myPackageGroup'),
        }(name='MediaPackageGroupSetting', description='The MediaPackage destination.'),
        monitorUrl?: string(name='MonitorUrl', description='The URL for monitoring the output group. The parameter is returned only when the output gourp type is MediaPackage.', example='rtmp://xxx'),
        name?: string(name='Name', description='The name of the output group.', example='group1'),
        outputs?: [ 
          {
            audioSettingNames?: [ string ](name='AudioSettingNames', description='The referenced AudioSettings.'),
            mediaPackageOutputSetting?: {
              audioGroupId?: string(name='AudioGroupId', description='The manifest audio group ID.', example='audiogroup'),
              nameModifier?: string(name='NameModifier', description='The manifest name modifier. The child manifests include this modifier in their M3U8 file names.', example='480p'),
            }(name='MediaPackageOutputSetting', description='The settings of the output delivered to MediaPackage.'),
            mediaType?: int32(name='MediaType', description='The media type of the output.', example='0'),
            name?: string(name='Name', description='The name of the output.', example='output1'),
            videoSettingName?: string(name='VideoSettingName', description='The name of the referenced VideoSettings.', example='myVideo1'),
          }
        ](name='Outputs', description='The outputs in the output group.'),
        type?: string(name='Type', description='The output group type.', example='MediaPackage'),
      }
    ](name='OutputGroups', description='The output groups.'),
    state?: string(name='State', description='The state of the channel. Valid values: IDLE, STARTING, RUNNING, RECOVERING, and STOPPING.', example='IDLE'),
    videoSettings?: [ 
      {
        height?: int32(name='Height', description='The height of the video in pixels.', example='720'),
        name?: string(name='Name', description='The name of the video settings.', example='video1'),
        videoCodec?: string(name='VideoCodec', description='The video codec.', example='H264'),
        videoCodecSetting?: {
          codecDetail?: {
            level?: string(name='Level', description='The video encoding level. It is not supported yet.', example='H264_LEVEL_AUTO'),
            profile?: string(name='Profile', description='The H.264 profile.', example='MAIN'),
          }(name='CodecDetail', description='The video encoding settings.'),
          framerate?: {
            framerateControl?: string(name='FramerateControl', description='The frame rate mode.', example='SPECIFIED'),
            framerateDenominator?: int32(name='FramerateDenominator', description='The denominator of the fixed frame rate.', example='1'),
            framerateNumerator?: int32(name='FramerateNumerator', description='The numerator of the fixed frame rate.', example='25'),
          }(name='Framerate', description='The frame rate.'),
          gop?: {
            bframesNum?: int32(name='BframesNum', description='The number of B frames.', example='3'),
            gopSize?: int32(name='GopSize', description='The GOP size.', example='90'),
            gopSizeUnits?: string(name='GopSizeUnits', description='The GOP size unit.', example='FRAMES'),
          }(name='Gop', description='The GOP setting.'),
          rate?: {
            bitrate?: int32(name='Bitrate', description='The video bitrate. Unit: bit/s.', example='2500000'),
            bufferSize?: int32(name='BufferSize', description='The video buffer size. Unit: bit/s.', example='6000000'),
            maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s.', example='6000000'),
            rateControlMode?: string(name='RateControlMode', description='The bitrate control mode.', example='ABR'),
          }(name='Rate', description='The video encoding rate.'),
        }(name='VideoCodecSetting', description='The video encoding settings.'),
        videoCodecType?: string(name='VideoCodecType', description='The video transcoding method. Valid values: NORMAL (regular transcoding) and NBHD (Narrowband HD™ transcoding).', example='NORMAL'),
        width?: int32(name='Width', description='The width of the video in pixels.', example='1280'),
      }
    ](name='VideoSettings', description='The video settings.'),
  }(name='Channel', description='The channel information.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetMediaLiveChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaLiveChannelResponseBody(name='body'),
}

/**
  * @description ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of GetMediaLiveChannel  GetMediaLiveChannelRequest
  * @return GetMediaLiveChannelResponse
 */
async function getMediaLiveChannel(request: GetMediaLiveChannelRequest): GetMediaLiveChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaLiveChannel', 'POST', '/', 'json', true, 'form', request);
}

model GetMediaLiveInputRequest {
  inputId: string(name='InputId', description='The ID of the input.

This parameter is required.', example='SEGK5KA6KYKAWQQH', position='Body'),
}

model GetMediaLiveInputResponseBody = {
  input?: {
    channelIds?: [ string ](name='ChannelIds', description='The IDs of the channels associated with the input.'),
    createTime?: string(name='CreateTime', description='The time when the input was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-12-03T06:56:42Z'),
    inputId?: string(name='InputId', description='The ID of the input.', example='SEGK5KA6KYKAWQQH'),
    inputInfos?: [ 
      {
        destHost?: string(name='DestHost', description='The endpoint that the stream is pushed to. This parameter is returned for PUSH inputs.', example='rtmp://domain/app/stream'),
        flowId?: string(name='FlowId', description='The ID of the flow from MediaConnect.', example='******81-9693-40dc-bbab-db5e49******'),
        flowOutputName?: string(name='FlowOutputName', description='The output name of the MediaConnect flow.', example='myFlowOutputName'),
        monitorUrl?: string(name='MonitorUrl', description='The URL for input monitoring.', example='rtmp://domain/app/stream_for_monitor'),
        sourceUrl?: string(name='SourceUrl', description='The source URL where the stream is pulled from. This parameter is returned for PULL inputs.', example='rtmp://domain/app/stream'),
        srtLatency?: int32(name='SrtLatency'),
        srtMaxBitrate?: int32(name='SrtMaxBitrate'),
        srtPassphrase?: string(name='SrtPassphrase'),
        srtPbKeyLen?: int32(name='SrtPbKeyLen'),
        streamName?: string(name='StreamName', description='The name of the pushed stream. This parameter is returned for PUSH inputs.', example='mystream'),
      }
    ](name='InputInfos', description='The input configurations.'),
    name?: string(name='Name', description='The name of the input.', example='myinput'),
    securityGroupIds?: [ string ](name='SecurityGroupIds', description='The IDs of the security groups associated with the input.'),
    type?: string(name='Type', description='The input type.', example='RTMP_PUSH'),
  }(name='Input', description='The input information.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetMediaLiveInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaLiveInputResponseBody(name='body'),
}

/**
  * @description ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of GetMediaLiveInput  GetMediaLiveInputRequest
  * @return GetMediaLiveInputResponse
 */
async function getMediaLiveInput(request: GetMediaLiveInputRequest): GetMediaLiveInputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaLiveInput', 'POST', '/', 'json', true, 'form', request);
}

model GetMediaLiveInputSecurityGroupRequest {
  securityGroupId: string(name='SecurityGroupId', description='The ID of the security group.

This parameter is required.', example='SEGK5KA6KYKAWQQH', position='Body'),
}

model GetMediaLiveInputSecurityGroupResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  securityGroup?: {
    createTime?: string(name='CreateTime', description='The time when the security group was created. It follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:31:56Z'),
    inputIds?: [ string ](name='InputIds', description='The IDs of the inputs associated with the security group.'),
    name?: string(name='Name', description='The name of the security group.', example='mysg'),
    securityGroupId?: string(name='SecurityGroupId', description='The ID of the security group.', example='SEGK5KA6KYKAWQQH'),
    whitelistRules?: [ string ](name='WhitelistRules', description='The security group rules.'),
  }(name='SecurityGroup', description='The security group information.'),
}

model GetMediaLiveInputSecurityGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaLiveInputSecurityGroupResponseBody(name='body'),
}

/**
  * @description ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of GetMediaLiveInputSecurityGroup  GetMediaLiveInputSecurityGroupRequest
  * @return GetMediaLiveInputSecurityGroupResponse
 */
async function getMediaLiveInputSecurityGroup(request: GetMediaLiveInputSecurityGroupRequest): GetMediaLiveInputSecurityGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaLiveInputSecurityGroup', 'POST', '/', 'json', true, 'form', request);
}

model GetMediaMarksRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The mark ID. You can specify multiple mark IDs separated with commas (,).', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60', position='Query'),
}

model GetMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaMarks?: string(name='MediaMarks', description='The queried marks.

*   The value is in the JSONArray format.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaMarksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetMediaMarks  GetMediaMarksRequest
  * @return GetMediaMarksResponse
 */
async function getMediaMarks(request: GetMediaMarksRequest): GetMediaMarksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaMarks', 'POST', '/', 'json', false, 'json', request);
}

model GetMediaProducingJobRequest {
  jobId?: string(name='JobId', description='The ID of the media editing and production job.', example='****cdb3e74639973036bc84****', position='Query'),
}

model GetMediaProducingJobResponseBody = {
  mediaProducingJob?: {
    clipsParam?: string(name='ClipsParam', description='The template parameters of the media editing and production job.', example='{"VideoArray":["****05512043f49f697f7425****","****05512043f49f697f7425****","****05512043f49f697f7425****"]}'),
    code?: string(name='Code', description='The response code

Note: Pay attention to this parameter if the job failed.', example='ExceededMaximumValue'),
    completeTime?: string(name='CompleteTime', description='The time when the media editing and production job was complete.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:52Z'),
    createTime?: string(name='CreateTime', description='The time when the media editing and production job was created.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
    duration?: float(name='Duration', description='The duration of the output file.

Note: This parameter has a value if the job is successful and the output file is an audio or video file.', example='30.500000'),
    jobId?: string(name='JobId', description='The ID of the media editing and production job.', example='****cdb3e74639973036bc84****'),
    mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****0cc6ba49eab379332c5b****'),
    mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example2.mp4'),
    message?: string(name='Message', description='The returned message.

Note: Pay attention to this parameter if the job failed.', example='The specified "Width_Height" has exceeded maximum value.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the media editing and production job was last modified.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:49Z'),
    progress?: int32(name='Progress'),
    projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fddd7748b58bf1d47e95****'),
    status?: string(name='Status', description='The state of the media editing and production job. Valid values:

Init

Queuing

Processing

Success

Failed', example='Failed'),
    subJobMaterials?: string(name='SubJobMaterials', description='The materials of the media editing and production job if the job is a subjob of a quick video production job, including the broadcast text and title.', example='{"Title": "Title", "SpeechText": "Broadcast text of a quick video production job"}'),
    templateId?: string(name='TemplateId', description='The ID of the template used by the media editing and production job.', example='****6e76134d739cc3e85d3e****'),
    timeline?: string(name='Timeline', description='The timeline of the media editing and production job.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
    userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"NotifyAddress":"http://xx.xx.xxx","Key":"Valuexxx"}'),
    vodMediaId?: string(name='VodMediaId', description='The media asset ID of the output file in ApsaraVideo VOD if the output file is stored in ApsaraVideo VOD.', example='****332c5b0cc6ba49eab379****'),
  }(name='MediaProducingJob', description='The information about the online editing project.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****83B7-7F87-4792-BFE9-63CD2137****'),
}

model GetMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaProducingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetMediaProducingJob  GetMediaProducingJobRequest
  * @return GetMediaProducingJobResponse
 */
async function getMediaProducingJob(request: GetMediaProducingJobRequest): GetMediaProducingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMediaProducingJob', 'GET', '/', 'json', false, 'json', request);
}

model GetPackageJobRequest {
  jobId: string(name='JobId', description='The job ID. You can obtain the job ID from the response parameters of the [SubmitPackageJob](https://help.aliyun.com/document_detail/461964.html) operation.

This parameter is required.', example='ab4802364a2e49208c99efab82dfa8e8', position='Query'),
}

model GetPackageJobResponseBody = {
  packageJob?: {
    code?: string(name='Code', description='The error code returned if the job fails.', example='InvalidParameter'),
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:34:05Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:44:05Z'),
    inputs?: [ 
      {
        input?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
        }(name='Input', description='The information about the input stream file.'),
      }
    ](name='Inputs', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    message?: string(name='Message', description='The error message that is returned.', example='Resource content bad.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:44:05Z'),
    name?: string(name='Name', description='The name of the job.', example='job-name'),
    output?: {
      media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.m3u8'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
    }(name='Output', description='The output of the job.'),
    outputUrl?: string(name='OutputUrl', description='The URL of the output file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/output.m3u8'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='36f3fee40aa047c0b067d0fb85edc12b'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='6'),
    status?: string(name='Status', description='The state of the job.', example='Init'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:34:05Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
    userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}'),
  }(name='PackageJob', description='The information about the packaging job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model GetPackageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPackageJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetPackageJob  GetPackageJobRequest
  * @return GetPackageJobResponse
 */
async function getPackageJob(request: GetPackageJobRequest): GetPackageJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPackageJob', 'POST', '/', 'json', false, 'json', request);
}

model GetPipelineRequest {
  pipelineId: string(name='PipelineId', description='The ID of the MPS queue.

This parameter is required.', example='****96e8864746a0b6f3****', position='Query'),
}

model GetPipelineResponseBody = {
  pipeline?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
    name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.', example='****20b48fb04483915d4f2cd8ac****'),
    priority?: int32(name='Priority', description='The priority of the MPS queue. Valid values: 1 to 10.', example='6'),
    speed?: string(name='Speed', description='The type of the MPS queue.

Valid values:

*   Standard: standard MPS queue.
*   Boost: MPS queue with transcoding speed boosted.
*   NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.', example='Standard'),
    status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Active'),
  }(name='Pipeline', description='The information about the MPS queue.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetPipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPipelineResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetPipeline  GetPipelineRequest
  * @return GetPipelineResponse
 */
async function getPipeline(request: GetPipelineRequest): GetPipelineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPipeline', 'POST', '/', 'json', false, 'json', request);
}

model GetPlayInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  authTimeout?: long(name='AuthTimeout', position='Query'),
  inputURL?: string(name='InputURL', description='The input URL that you specified for the media asset when you registered the media asset. For more information, see [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html).

>  You must specify at least one of the MediaId and InputURL parameters.', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.

>  You must specify at least one of the MediaId and InputURL parameters.', example='86434e152b7d4f20be480574439fe***', position='Query'),
}

model GetPlayInfoResponseBody = {
  mediaBase?: {
    cateId?: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of the CateId parameter returned by the AddCategory operation that you called to create a category.
*   View the value of the CateId parameter returned by the GetCategories operation that you called to query a category.', example='4220'),
    coverURL?: string(name='CoverURL', description='The URL of the thumbnail.', example='https://***.oss-cn-shanghai.aliyuncs.com/cover/281c64d6-b5fb-4c57-97cd-84da56a8b151_large_cover_url.jpg'),
    creationTime?: string(name='CreationTime', description='The time when the media asset was created.', example='2021-09-22T10:07:31+08:00'),
    description?: string(name='Description', description='The content description.', example='desc'),
    mediaId?: string(name='MediaId', description='The ID of the media asset.', example='2eea77a61c7b4ddd95bec34a6f65b***'),
    mediaTags?: string(name='MediaTags', description='The tags.

*   Up to 16 tags are supported.
*   Multiple tags are separated by commas (,).
*   Each tag can be up to 32 bytes in length.
*   The value is encoded in UTF-8.', example='test,ccc'),
    mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

video audio', example='video'),
    status?: string(name='Status', description='The resource status. Valid values:

Init: the initial state, which indicates that the source file is not ready.

Preparing: The source file is being prepared. For example, the file is being uploaded or edited.

PrepareFail: The source file failed to be prepared. For example, the information of the source file failed to be obtained.

Normal: The source file is ready.', example='Normal'),
    title?: string(name='Title', description='The title.', example='testTitle'),
  }(name='MediaBase', description='The information about the media asset.'),
  playInfoList?: [ 
    {
      bitDepth?: int32(name='BitDepth', description='The color depth.', example='8'),
      bitrate?: string(name='Bitrate', description='The bitrate of the media stream. Unit: Kbit/s.', example='20'),
      creationTime?: string(name='CreationTime', description='The time when the media stream was created. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2022-05-10T02:28:49Z'),
      definition?: string(name='Definition', description='The quality of the media stream. Valid values:

*   **FD**: low definition
*   **LD**: standard definition
*   **SD**: high definition
*   **HD**: ultra-high definition
*   **OD**: original definition
*   **2K**
*   **4K**
*   **SQ**: standard sound quality
*   **HQ**: high sound quality
*   **AUTO**: adaptive bitrate', example='HD'),
      duration?: string(name='Duration', description='The duration of the media stream. Unit: seconds.', example='9.0464'),
      encrypt?: long(name='Encrypt', description='Indicates whether the media stream is encrypted. Valid values:

*   **0**: The media stream is not encrypted.
*   **1**: The media stream is encrypted.', example='0'),
      encryptType?: string(name='EncryptType', description='The encryption type of the media stream. Valid values:

*   **AliyunVoDEncryption**: Alibaba Cloud proprietary cryptography
*   **HLSEncryption**: HTTP Live Streaming (HLS) encryption

>  If the encryption type is AliyunVoDEncryption, only ApsaraVideo Player SDK can be used to play videos.', example='AliyunVoDEncryption'),
      fileURL?: string(name='FileURL', description='The OSS URL of the file.', example='http://outin-***.oss-cn-shanghai.aliyuncs.com/sv/43a68ee9-181809b6aba/43a68ee9-181809b6aba.mpeg'),
      format?: string(name='Format', description='The format of the media stream.

*   If the media asset is a video file, the valid values are **mp4** and **m3u8**.
*   If the media asset is an audio-only file, the value is **mp3**.', example='mp4'),
      fps?: string(name='Fps', description='The frame rate of the media stream. Unit: frames per second (FPS).', example='25'),
      HDRType?: string(name='HDRType', description='The high dynamic range (HDR) type of the media stream. Valid values:

*   HDR
*   HDR10
*   HLG
*   DolbyVision
*   HDRVivid
*   SDR+', example='HDR'),
      height?: long(name='Height', description='The height of the media stream. Unit: pixels.', example='1080'),
      jobId?: string(name='JobId', description='The task ID.', example='36c9d38e70bf43ed9f7f8f48d6356***'),
      modificationTime?: string(name='ModificationTime', description='The time when the media stream was updated. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2022-05-13T11:39:41.714+08:00'),
      narrowBandType?: string(name='NarrowBandType', description='The type of Narrowband HD™ transcoding. Valid values:

*   **0**: standard transcoding
*   **1.0**: Narrowband HD™ 1.0 transcoding
*   **2.0**: Narrowband HD™ 2.0 transcoding

This parameter is returned only when a definition that is available in the built-in Narrowband HD™ 1.0 transcoding template is specified. For more information, see the [Definition parameter in TranscodeTemplate](https://help.aliyun.com/document_detail/52839.html) table.', example='0'),
      playURL?: string(name='PlayURL', description='The playback URL of the media stream.', example='https://***.aliyuncdn.com/sv/756bee1-17f980f0945/756bee1-17f980f0945.mp4'),
      size?: long(name='Size', description='The size of the media stream. Unit: bytes.', example='418112'),
      status?: string(name='Status', description='The status of the media stream. Valid values:

*   **Normal**
*   **Invisible**', example='Normal'),
      streamTags?: string(name='StreamTags', description='The tags of the media stream, which are used to identify the transcoding type.', example='"{\\"ims.audioServiceType\\": \\"AudioEnhancement\\"}"'),
      streamType?: string(name='StreamType', description='The type of the media stream. If the media stream is a video stream, the value is **video**. If the media stream is an audio-only stream, the value is **audio**.', example='video'),
      transTemplateType?: string(name='TransTemplateType', description='The type of the transcoding template. Valid values:

*   Normal: standard transcoding
*   AudioTranscode: audio transcoding
*   Remux: container format conversion
*   NarrowBandV1: Narrowband HD™ 1.0
*   NarrowBandV2: Narrowband HD™ 2.0
*   UHD: audio and video enhancement (ultra-high definition)', example='Normal'),
      watermarkId?: string(name='WatermarkId', description='The ID of the watermark that is associated with the media stream.', example='5bed88672b1e2520ead228935ed51***'),
      width?: long(name='Width', description='The width of the media stream. Unit: pixels.', example='1024'),
    }
  ](name='PlayInfoList', description='The information about the audio or video stream.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetPlayInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPlayInfoResponseBody(name='body'),
}

/**
  * @description You use the ID of a video or audio file to query the playback URL of the file. Then, you can use the playback URL to play the audio or video in ApsaraVideo Player SDK (for URL-based playback) or a third-party player.
  * @param request  the request parameters of GetPlayInfo  GetPlayInfoRequest
  * @return GetPlayInfoResponse
 */
async function getPlayInfo(request: GetPlayInfoRequest): GetPlayInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPlayInfo', 'POST', '/', 'json', false, 'json', request);
}

model GetProgramRequest {
  channelName: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel', position='Query'),
  programName: string(name='ProgramName', description='The name of the program.

This parameter is required.', example='program1', position='Query'),
}

model GetProgramResponseBody = {
  program?: ChannelAssemblyProgram(name='Program', description='The information about the program.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
}

model GetProgramResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetProgramResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetProgram  GetProgramRequest
  * @return GetProgramResponse
 */
async function getProgram(request: GetProgramRequest): GetProgramResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetProgram', 'POST', '/', 'json', false, 'json', request);
}

model GetProjectExportJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  jobId: string(name='JobId', description='The ID of the project export task.

This parameter is required.', example='****cdb3e74639973036bc84****', position='Query'),
}

model GetProjectExportJobResponseBody = {
  projectExportJob?: {
    code?: string(name='Code', description='The error code for the failed export task.
>Notice: Use the error code for troubleshooting.', example='InvalidParameter'),
    exportResult?: {
      projectUrl?: string(name='ProjectUrl', description='The URL of the exported project, which is typically a signed OSS URL. This field is returned when ExportType is AdobePremierePro.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example_prefix/exported_project_1e8c39a502c3436c84f88290cd713bf3.zip?Expires=1750331685&....'),
      timeline?: string(name='Timeline', description='The timeline of the online editing job. This field is returned when ExportType is BaseTimeline. For data structure, see [Timeline](https://help.aliyun.com/document_detail/198823.html).', example='{"VideoTracks":[{"VideoTrackClips":[{"Type":"Video","MediaId":"****4d7cf14dc7b83b0e801c****","MediaURL":"https://test-bucket.oss-cn-shanghai.aliyuncs.com/test.mp4","TimelineIn":0.0,"TimelineOut":5.0,"In":0.0,"Out":5.0,"Speed":1.0,"Duration":5.0,"VirginDuration":13.334,"Height":1.0,"Width":1.0,"X":0.0,"Y":0.0}]}]}'),
    }(name='ExportResult', description='The exported data.'),
    exportType?: string(name='ExportType', description='The export type. Valid values:

*   **BaseTimeline**: exports the timeline.
*   **AdobePremierePro**: exports an Adobe Premiere Pro project.', example='BaseTimeline'),
    jobId?: string(name='JobId', description='The ID of the project export task.', example='****cdb3e74639973036bc84****'),
    message?: string(name='Message', description='The error message for the failed export task.
>Notice: Use the error message for troubleshooting.', example='The specified parameter is not valid.'),
    projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fddd7748b58bf1d47e95****'),
    status?: string(name='Status', description='The status of the project export task. Valid values:

- Init: Initializing
- Processing
- Success
- Failed', example='Success'),
    userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"NotifyAddress":"http://xx.xx.xxx","Key":"Valuexxx"}'),
  }(name='ProjectExportJob', description='The project export task.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
}

model GetProjectExportJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetProjectExportJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetProjectExportJob  GetProjectExportJobRequest
  * @return GetProjectExportJobResponse
 */
async function getProjectExportJob(request: GetProjectExportJobRequest): GetProjectExportJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetProjectExportJob', 'POST', '/', 'json', false, 'json', request);
}

model GetPublicMediaInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId?: string(name='MediaId', example='icepublic-****14e501538aeef0a3140176f6****', position='Query'),
}

model GetPublicMediaInfoResponseBody = {
  mediaInfo?: {
    dynamicMetaData?: {
      data?: string(name='Data', example='{"AuditionUrl": "http://example-bucket.cdn.domain.com/example.mp4", "AuditionCount": 3}'),
      type?: string(name='Type', example='system'),
    }(name='DynamicMetaData'),
    fileInfoList?: [ 
      {
        audioStreamInfoList?: [ 
          {
            bitrate?: string(name='Bitrate', example='192.0'),
            channelLayout?: string(name='ChannelLayout', example='stereo'),
            channels?: string(name='Channels', example='2'),
            codecLongName?: string(name='CodecLongName', example='AAC (Advanced Audio Coding)'),
            codecName?: string(name='CodecName', example='aac'),
            codecTag?: string(name='CodecTag', example='0x6134706d'),
            codecTagString?: string(name='CodecTagString', example='mp4a'),
            codecTimeBase?: string(name='CodecTimeBase', example='1/44100'),
            duration?: string(name='Duration', example='16.2'),
            fps?: string(name='Fps', example='10'),
            index?: string(name='Index', example='1'),
            lang?: string(name='Lang', example='und'),
            numFrames?: string(name='NumFrames', example='162'),
            profile?: string(name='Profile', example='High'),
            sampleFmt?: string(name='SampleFmt', example='fltp'),
            sampleRate?: string(name='SampleRate', example='44100'),
            startTime?: string(name='StartTime', example='0.000000'),
            timebase?: string(name='Timebase', example='1/44100'),
          }
        ](name='AudioStreamInfoList'),
        fileBasicInfo?: {
          bitrate?: string(name='Bitrate', example='192.0'),
          duration?: string(name='Duration', example='16.2'),
          fileName?: string(name='FileName', example='example.mp4'),
          fileSize?: string(name='FileSize', example='27007'),
          fileStatus?: string(name='FileStatus', example='Normal'),
          fileType?: string(name='FileType', example='source_file'),
          fileUrl?: string(name='FileUrl', example='http://example-bucket.cdn.domain.com/example.mp4'),
          formatName?: string(name='FormatName', example='mp4'),
          height?: string(name='Height', example='0'),
          region?: string(name='Region', example='cn-shanghai'),
          width?: string(name='Width', example='0'),
        }(name='FileBasicInfo'),
        subtitleStreamInfoList?: [ 
          {
            codecLongName?: string(name='CodecLongName', example='SubRip Text'),
            codecName?: string(name='CodecName', example='srt'),
            codecTag?: string(name='CodecTag', example='unicode'),
            codecTagString?: string(name='CodecTagString', example='unicode'),
            codecTimeBase?: string(name='CodecTimeBase', example='29.97'),
            duration?: string(name='Duration', example='1'),
            index?: string(name='Index', example='1'),
            lang?: string(name='Lang', example='und'),
            startTime?: string(name='StartTime', example='0'),
            timebase?: string(name='Timebase', example='30'),
          }
        ](name='SubtitleStreamInfoList'),
        videoStreamInfoList?: [ 
          {
            avgFPS?: string(name='AvgFPS', example='24.0'),
            bitrate?: string(name='Bitrate', example='1001.594'),
            codecLongName?: string(name='CodecLongName', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
            codecName?: string(name='CodecName', example='h264'),
            codecTag?: string(name='CodecTag', example='0x0000'),
            codecTagString?: string(name='CodecTagString', example='[0][0][0][0]'),
            codecTimeBase?: string(name='CodecTimeBase', example='1/48'),
            dar?: string(name='Dar', example='0:1'),
            duration?: string(name='Duration', example='216.206706'),
            fps?: string(name='Fps', example='24.0'),
            hasBFrames?: string(name='HasBFrames', example='2'),
            height?: string(name='Height', example='540'),
            index?: string(name='Index', example='0'),
            lang?: string(name='Lang', example='und'),
            level?: string(name='Level', example='30'),
            nbFrames?: string(name='Nb_frames', example='5184'),
            numFrames?: string(name='NumFrames', example='5184'),
            pixFmt?: string(name='PixFmt', example='yuv420p'),
            profile?: string(name='Profile', example='High'),
            rotate?: string(name='Rotate', example='0'),
            sar?: string(name='Sar', example='0:1'),
            startTime?: string(name='StartTime', example='0.081706'),
            timebase?: string(name='Timebase', example='1/12288'),
            width?: string(name='Width', example='960'),
          }
        ](name='VideoStreamInfoList'),
      }
    ](name='FileInfoList', description='FileInfos'),
    mediaBasicInfo?: {
      businessType?: string(name='BusinessType', example='general'),
      category?: string(name='Category', example='category'),
      coverURL?: string(name='CoverURL', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
      createTime?: string(name='CreateTime', example='2020-12-26T04:11:08Z'),
      deletedTime?: string(name='DeletedTime', example='2020-12-26T04:11:15Z'),
      description?: string(name='Description', example='description'),
      mediaId?: string(name='MediaId', description='MediaId', example='icepublic-****14e501538aeef0a3140176f6****'),
      mediaTags?: string(name='MediaTags'),
      mediaType?: string(name='MediaType', example='video'),
      modifiedTime?: string(name='ModifiedTime', example='2020-12-26T04:11:10Z'),
      source?: string(name='Source', example='oss'),
      spriteImages?: string(name='SpriteImages', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
      status?: string(name='Status', example='Normal'),
      title?: string(name='Title', example='title'),
      userData?: string(name='UserData', example='{"key":"value"}'),
    }(name='MediaBasicInfo', description='BasicInfo'),
    mediaId?: string(name='MediaId', example='icepublic-****14e501538aeef0a3140176f6****'),
  }(name='MediaInfo'),
  requestId?: string(name='RequestId', description='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetPublicMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPublicMediaInfoResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetPublicMediaInfo  GetPublicMediaInfoRequest
  * @return GetPublicMediaInfoResponse
 */
async function getPublicMediaInfo(request: GetPublicMediaInfoRequest): GetPublicMediaInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPublicMediaInfo', 'POST', '/', 'json', false, 'json', request);
}

model GetSmartHandleJobRequest {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetSmartHandleJobResponseBody = {
  errorCode?: string(name='ErrorCode'),
  errorMessage?: string(name='ErrorMessage'),
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  jobResult?: {
    aiResult?: string(name='AiResult', description='The AI analysis result.', example='Intelligent segmentation or tagging information'),
    mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
    mediaUrl?: string(name='MediaUrl'),
    usage?: string(name='Usage', description='The token usage. This parameter is returned only for keyword-based text generation jobs.', example='{"total_tokens":100}'),
  }(name='JobResult', description='The job results.'),
  output?: string(name='Output', description='The job results.', example='{}'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  smartJobInfo?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2020-12-26T04:11:10Z'),
    description?: string(name='Description', description='The job description.', example='测试描述'),
    inputConfig?: {
      inputFile?: string(name='InputFile', description='The OSS URL or the ID of the material in the media asset library.', example='oss://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4 或 ******11-DB8D-4A9A-875B-275798******'),
    }(name='InputConfig', description='The input configurations.'),
    jobType?: string(name='JobType', description='The job type.', example='ASR'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2020-12-26T04:11:10Z'),
    outputConfig?: {
      bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
      object?: string(name='Object', description='The OSS object.', example='test-object'),
    }(name='OutputConfig', description='The output configurations.'),
    title?: string(name='Title', description='The job title.', example='测试标题'),
    userId?: string(name='UserId', description='The user ID.', example='1974526429******'),
  }(name='SmartJobInfo', description='The information about the intelligent job.'),
  state?: string(name='State', description='The job state.

Valid values:

*   Finished
*   Failed
*   Executing
*   Created', example='Finished'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"user":"data"}'),
}

model GetSmartHandleJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSmartHandleJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetSmartHandleJob  GetSmartHandleJobRequest
  * @return GetSmartHandleJobResponse
 */
async function getSmartHandleJob(request: GetSmartHandleJobRequest): GetSmartHandleJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSmartHandleJob', 'POST', '/', 'json', false, 'json', request);
}

model GetSnapshotJobRequest {
  jobId: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****d80e4e4044975745c14b****', position='Query'),
}

model GetSnapshotJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  snapshotJob?: {
    async?: boolean(name='Async', description='Indicates whether the snapshots were captured in asynchronous mode. Default value: true.', example='true'),
    code?: string(name='Code', description='Error codes', example='ResourceNotFound'),
    count?: int32(name='Count', description='The number of snapshots.', example='8'),
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
    input?: {
      media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://test-bucket/object.mp4'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='object.mp4'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
    message?: string(name='Message', description='The error message that is returned.', example='The specified resource for "Pipeline" could not be found.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
    name?: string(name='Name', description='The name of the job.'),
    output?: {
      media?: string(name='Media', description='The output file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS. If multiple static snapshots were captured, the object must contain the "{Count}" placeholder. In the case of a sprite, the object must contain the "{TileCount}" placeholder. The suffix of the WebVTT snapshot objects must be ".vtt".', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/output-{Count}.jpg'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='output-{Count}.jpg'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.', example='OSS'),
    }(name='Output', description='The output of the job.'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****d80e4e4044975745c14b****'),
    status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
    templateConfig?: string(name='TemplateConfig', description='The snapshot template configuration.', example='{"Type":"Normal","FrameType":"normal","Time":0,"Count":10}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****d80e4e4044975745c14b****'),
    triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
    type?: string(name='Type', description='Snapshot types

Valid values:

*   WebVtt
*   Sprite
*   Normal', example='Sprite'),
    userData?: string(name='UserData', description='The user-defined parameters.', example='{"test parameter": "test value"}'),
  }(name='SnapshotJob', description='The information about the snapshot job.'),
}

model GetSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSnapshotJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetSnapshotJob  GetSnapshotJobRequest
  * @return GetSnapshotJobResponse
 */
async function getSnapshotJob(request: GetSnapshotJobRequest): GetSnapshotJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSnapshotJob', 'POST', '/', 'json', false, 'json', request);
}

model GetSnapshotUrlsRequest {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values: Asc and Desc.

- Asc

- Desc', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 30. Default value: 10.', example='10', position='Query'),
  timeout?: long(name='Timeout', description='The authentication timeout period. Unit: seconds Default value: 3600. Maximum value: 129600 (36 hours).', example='3600', position='Query'),
}

model GetSnapshotUrlsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  snapshotUrls?: [ string ](name='SnapshotUrls', description='The list of snapshot URLs.'),
  total?: int32(name='Total', description='The total number of snapshots.', example='30'),
  webVTTUrl?: string(name='WebVTTUrl', description='The URL of the WebVTT file.', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/ouoput.vtt'),
}

model GetSnapshotUrlsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSnapshotUrlsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetSnapshotUrls  GetSnapshotUrlsRequest
  * @return GetSnapshotUrlsResponse
 */
async function getSnapshotUrls(request: GetSnapshotUrlsRequest): GetSnapshotUrlsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSnapshotUrls', 'POST', '/', 'json', false, 'json', request);
}

model GetSourceRequest {
  sourceLocationName: string(name='SourceLocationName', description='The source location.

This parameter is required.', example='MySourceLocation', position='Query'),
  sourceName: string(name='SourceName', description='The name of the source.

This parameter is required.', example='MyVodSource', position='Query'),
  sourceType: string(name='SourceType', description='The source type. Valid values: vodSource and liveSource.

This parameter is required.', example='vodSource', position='Query'),
}

model GetSourceResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  source?: ChannelAssemblySource(name='Source', description='The source information.'),
}

model GetSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetSource  GetSourceRequest
  * @return GetSourceResponse
 */
async function getSource(request: GetSourceRequest): GetSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSource', 'POST', '/', 'json', false, 'json', request);
}

model GetSourceLocationRequest {
  sourceLocationName: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourceLocation', position='Query'),
}

model GetSourceLocationResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  sourceLocation?: ChannelAssemblySourceLocation(name='SourceLocation', description='The source location information.'),
}

model GetSourceLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSourceLocationResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetSourceLocation  GetSourceLocationRequest
  * @return GetSourceLocationResponse
 */
async function getSourceLocation(request: GetSourceLocationRequest): GetSourceLocationResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSourceLocation', 'POST', '/', 'json', false, 'json', request);
}

model GetStorageListRequest {
  regionId?: string(name='RegionId', position='Host'),
  appId?: string(name='AppId', description='The application ID.', example='app-****', position='Query'),
  status?: string(name='Status', description='The OSS storage status.', example='Normal', position='Query'),
  storageType?: string(name='StorageType', description='The storage type.', example='vod_oss_bucket', position='Query'),
}

model GetStorageListResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******73-8B78-5D86-A50C-49B96C******'),
  storageInfoList?: [ 
    {
      appId?: string(name='AppId', description='The application ID.', example='app-****'),
      creationTime?: string(name='CreationTime', description='The time when the configuration was created.', example='2024-06-06T01:55:07Z'),
      defaultStorage?: boolean(name='DefaultStorage', description='Indicates whether it is the default storage location.', example='true'),
      editingTempFileStorage?: boolean(name='EditingTempFileStorage', description='Indicates whether temporary files created during editing processes are stored in this location.', example='false'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the configuration was last modified.', example='2024-06-06T03:07:07Z'),
      path?: string(name='Path', description='The file path.', example='your-path/'),
      status?: string(name='Status', description='The OSS storage status.', example='Normal'),
      storageLocation?: string(name='StorageLocation', description='The bucket.', example='your-bucket'),
      storageType?: string(name='StorageType', description='The storage type.', example='vod_oss_bucket'),
    }
  ](name='StorageInfoList', description='The storage configurations.'),
}

model GetStorageListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetStorageListResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetStorageList  GetStorageListRequest
  * @return GetStorageListResponse
 */
async function getStorageList(request: GetStorageListRequest): GetStorageListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetStorageList', 'POST', '/', 'json', false, 'json', request);
}

model GetStreamTagListRequest {
  regionId?: string(name='RegionId', position='Host'),
  endTime?: string(name='EndTime', description='The end of the query time range, based on the tagging timestamp. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-12-22T08:00:00Z', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******', position='Query'),
  namespace?: string(name='Namespace', description='The namespace.', example='name-1', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****73f33c91-d59383e8280b****', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='Stream_xxx', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order for the results. Valid values:

*   StartTime:Desc (default): Sort by creation time in descending order.
*   StartTime:Asc: Sort by creation time in ascending order.', example='StartTime:Asc', position='Query'),
  startTime?: string(name='StartTime', description='The start of the query time range, based on the tagging timestamp. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2025-04-23T02:26:00Z', position='Query'),
}

model GetStreamTagListResponseBody = {
  code?: string(name='Code', description='The return code.', example='200'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****73f33c91-d59383e8280b****'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  streamTagList?: [ 
    {
      endTime?: string(name='EndTime', description='The end time. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2025-02-25T02:24:00Z'),
      startTime?: string(name='StartTime', description='The start time. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2025-04-26T16:00:00Z'),
      userData?: string(name='UserData', description='The user-defined data.', example='{"result":"xxx"}'),
    }
  ](name='StreamTagList', description='The tag information.'),
  success?: string(name='Success', description='Indicates whether the request is successful. Valid values:

*   true
*   false', example='true'),
  total?: long(name='Total', description='The total number of entries that are returned.', example='163'),
}

model GetStreamTagListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetStreamTagListResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetStreamTagList  GetStreamTagListRequest
  * @return GetStreamTagListResponse
 */
async function getStreamTagList(request: GetStreamTagListRequest): GetStreamTagListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetStreamTagList', 'POST', '/', 'json', false, 'json', request);
}

model GetSystemTemplateRequest {
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='S00000001-100060', position='Query'),
}

model GetSystemTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  systemTemplate?: {
    status?: string(name='Status', description='The template state.', example='Normal'),
    subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='1'),
    subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='Normal'),
    templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Container":{"Format":"m3u8"},"TransConfig":{"TransMode":"onepass"},"Video":{"Codec":"H.264","Maxrate":8000,"Preset":"medium","PixFmt":"yuv420p","Width":2048,"Bitrate":3500},"Audio":{"Codec":"aac","Bitrate":160,"Samplerate":44100,"Channels":2}}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='S00000001-100060'),
    templateName?: string(name='TemplateName', description='The template name.', example='M3U8-2K'),
    type?: int32(name='Type', description='The type ID of the template.', example='1'),
    typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
  }(name='SystemTemplate', description='The template information.'),
}

model GetSystemTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSystemTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetSystemTemplate  GetSystemTemplateRequest
  * @return GetSystemTemplateResponse
 */
async function getSystemTemplate(request: GetSystemTemplateRequest): GetSystemTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSystemTemplate', 'POST', '/', 'json', false, 'json', request);
}

model GetTemplateRequest {
  relatedMediaidFlag?: string(name='RelatedMediaidFlag', description='Specifies whether to return the information about the associated materials. Default value: 0. Valid values: 0 and 1. A value of 1 specifies that the information about the associated materials is returned. This parameter is valid only for regular templates.', example='0', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  template?: {
    clipsParam?: string(name='ClipsParam', description='The clip parameters for submitting a video production job. You can replace mediaId and text with real values to submit a job. References:

*   [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html)
*   [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html)', example='{"Media1":"mediaId","Text1":"text"}'),
    config?: string(name='Config', description='The template configurations.

*   For more information about the configurations of a regular template, see [Config object of a regular template](https://help.aliyun.com/document_detail/456193.html).
*   For more information about the configurations of an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).', example='参考Timeline模板配置详解'),
    coverURL?: string(name='CoverURL', description='The thumbnail URL.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
    createSource?: string(name='CreateSource', description='The source from which the template was created. Valid values:

*   AliyunConsole
*   OpenAPI
*   WebSDK', example='OpenAPI'),
    creationTime?: string(name='CreationTime', description='The time when the template was created.', example='2020-12-26T04:11:10Z'),
    modifiedSource?: string(name='ModifiedSource', description='The source from which the template was modified. Valid values:

*   AliyunConsole
*   OpenAPI
*   WebSDK', example='OpenAPI'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2020-12-26T04:11:10Z'),
    name?: string(name='Name', description='The template name.', example='视频添加水印模板'),
    previewMedia?: string(name='PreviewMedia', description='The preview media asset.', example='****20b48fb04483915d4f2cd8ac****'),
    previewMediaStatus?: string(name='PreviewMediaStatus', description='The state of the preview media asset. Valid values:

*   Init: the initial state, which indicates that the source file is not ready.
*   Preparing: The source file is being prepared. For example, the file is being uploaded or edited.
*   PrepareFail: The source file failed to be prepared. For example, the information about the source file failed to be obtained.
*   Normal: The source file is ready.', example='Normal'),
    relatedMediaids?: string(name='RelatedMediaids', description='The IDs of the materials associated with the template for use by the regular template editor.', example='{"video":["******c04f1d4a06996144cc1a******"],"audio":["******c04f1d4a06996144cc1a******"],"image":["******c04f1d4a06996144cc1a******"]}'),
    status?: string(name='Status', description='The template state. Valid values:

*   Available
*   Created
*   Uploading
*   Processing
*   UploadFailed
*   ProcessFailed', example='Available'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
    type?: string(name='Type', description='The template type. Valid values:

*   Timeline
*   VETemplate', example='Timeline'),
  }(name='Template', description='The template information.'),
}

model GetTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTemplateResponseBody(name='body'),
}

/**
  * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
  * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
  * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
  * @param request  the request parameters of GetTemplate  GetTemplateRequest
  * @return GetTemplateResponse
 */
async function getTemplate(request: GetTemplateRequest): GetTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTemplate', 'POST', '/', 'json', false, 'json', request);
}

model GetTemplateMaterialsRequest {
  fileList?: string(name='FileList', description='The materials that you want to query.', example='["music.mp3","config.json","assets/1.jpg"]', position='Query'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetTemplateMaterialsResponseBody = {
  materialUrls?: string(name='MaterialUrls', description='The URLs of the associated materials.', example='{"music.mp3":"https://bucket.oss-cn-shanghai.aliyuncs.com/music.mp3?sign=xxx","config.json":"https://bucket.oss-cn-shanghai.aliyuncs.com/config.json?sign=xxx","assets/1.jpg":"https://bucket.oss-cn-shanghai.aliyuncs.com/assets/1.jpg?sign=xxx"}'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetTemplateMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTemplateMaterialsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTemplateMaterials  GetTemplateMaterialsRequest
  * @return GetTemplateMaterialsResponse
 */
async function getTemplateMaterials(request: GetTemplateMaterialsRequest): GetTemplateMaterialsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTemplateMaterials', 'POST', '/', 'json', false, 'json', request);
}

model GetTemplateParamsRequest {
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model GetTemplateParamsResponseBody = {
  paramList?: [ 
    {
      content?: string(name='Content', description='The original subtitle content.'),
      coverUrl?: string(name='CoverUrl', description='The thumbnail URL of the original material.'),
      key?: string(name='Key', description='The parameter name.', example='video1'),
      mediaUrl?: string(name='MediaUrl', description='The URL of the original material.'),
      type?: string(name='Type', description='The material type.

Valid values:

*   Video
*   Text
*   Image', example='Image'),
    }
  ](name='ParamList', description='The queried parameters.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
  templateId?: string(name='TemplateId', description='The template ID.', example='******419c8741c1b4325f035b******'),
}

model GetTemplateParamsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTemplateParamsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTemplateParams  GetTemplateParamsRequest
  * @return GetTemplateParamsResponse
 */
async function getTemplateParams(request: GetTemplateParamsRequest): GetTemplateParamsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTemplateParams', 'GET', '/', 'json', false, 'json', request);
}

model GetTranscodeJobRequest {
  parentJobId?: string(name='ParentJobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8', position='Query'),
}

model GetTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='9EDC30DC-0050-5459-B788-F761B2BE359B'),
  transcodeParentJob?: {
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    inputGroup?: [ 
      {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
      }
    ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
    jobCount?: int32(name='JobCount', description='The number of subjobs.', example='1'),
    name?: string(name='Name', description='The job name.', example='transcode-job'),
    outputGroup?: [ 
      {
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          outputUrl?: string(name='OutputUrl', description='The URL of the output stream.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HLS encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The endpoint of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='The encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The position of the watermark on the x-axis.', example='10'),
                dy?: string(name='Dy', description='The position of the watermark on the y-axis.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the output video.', example='32'),
                referPos?: string(name='ReferPos', description='The reference position of the watermark. Valid values: TopLeft, TopRight, BottomLeft, and BottomRight. Default value: TopLeft.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The duration of the stream. Valid values: the number of seconds or "ToEND".', example='ToEND'),
                  start?: string(name='Start', description='The start time of the stream.', example='00:00:05'),
                }(name='Timeline', description='The timeline settings.'),
                width?: string(name='Width', description='The width of the output video.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Indicates whether the text size was adjusted based on the output video dimensions. Valid values: true and false. Default value: false.', example='false'),
                borderColor?: string(name='BorderColor', description='The border color.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The border width.', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the watermark.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.', example='16'),
                left?: string(name='Left', description='The distance of the watermark from the left edge.', example='10'),
                top?: string(name='Top', description='The distance of the watermark from the top edge.', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Indicates whether the audio stream is deleted.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100.
*   Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum ABR. This parameter takes effect only for Narrowband HD 1.0.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.
*   If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values: border: automatically detects and removes black bars. A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Indicates whether the auto-rotate screen feature is enabled.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Indicates whether the video was removed.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The job processing configuration.'),
      }
    ](name='OutputGroup', description='The output group of the job.'),
    parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
    percent?: int32(name='Percent', description='The completion percentage of the job.', example='0'),
    requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the snapshot job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling configuration of the job.'),
    status?: string(name='Status', description='The state of the job.

*   Success: At least one of the subjobs is successful.
*   Fail: All subjobs failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    transcodeJobList?: [ 
      {
        createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-01-12T08:49:41Z'),
        finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
        inputGroup?: [ 
          {
            inputUrl?: string(name='InputUrl', description='The URL of the media asset. This parameter is specified only when the media asset is transcoded.', example='oss://bucket/path/to/video.mp4'),
            media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
            type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
          }
        ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
        jobId?: string(name='JobId', description='The subjob ID.', example='7d6a7e0d4db2457a8d45ff5d43e1bf0a'),
        jobIndex?: int32(name='JobIndex', description='The index number of the subjob in the entire job.', example='0'),
        name?: string(name='Name', description='The job name.', example='transcode-job'),
        outFileMeta?: {
          audioStreamInfoList?: [ 
            {
              bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
              channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
              channels?: string(name='Channels', description='The number of sound channels.', example='2'),
              codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
              codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
              codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
              codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
              codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              index?: string(name='Index', description='The sequence number of the stream.', example='1'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
              sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
              startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
              timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
            }
          ](name='AudioStreamInfoList', description='The information about the audio stream.'),
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
            duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
            fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
            fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
            fileType?: string(name='FileType', description='The file type. Valid values: source_file and transcode_file.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
            formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
            height?: string(name='Height', description='The height of the output video.', example='478'),
            mediaId?: string(name='MediaId', description='The ID of the media asset.', example='486c2890096871edba6f81848c016303'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width of the output video.', example='848'),
          }(name='FileBasicInfo', description='The basic file information.'),
          videoStreamInfoList?: [ 
            {
              avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
              bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
              codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
              codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
              codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
              codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
              codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
              dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              fps?: string(name='Fps', description='The frame rate.', example='25.0'),
              hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
              height?: string(name='Height', description='The height of the output video.', example='478'),
              index?: string(name='Index', description='The sequence number of the stream.', example='0'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              level?: string(name='Level', description='The codec level.', example='31'),
              numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
              pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
              profile?: string(name='Profile', description='The encoder profile.', example='High'),
              rotate?: string(name='Rotate', description='The rotation angle of the video image. Valid values: 0, 90, 180, and 270. Default value: 0.', example='0'),
              sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
              startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
              timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
              width?: string(name='Width', description='The width of the output video.', example='848'),
            }
          ](name='VideoStreamInfoList', description='The information about the video stream.'),
        }(name='OutFileMeta', description='The media information about the video generated by the job.'),
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          outputUrl?: string(name='OutputUrl', description='The path of the transcoded output stream. This parameter is required only when the output is a media asset.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HTTP Live Streaming (HLS) encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The endpoint of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='The encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The position of the watermark on the x-axis.', example='10'),
                dy?: string(name='Dy', description='The position of the watermark on the y-axis.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the output video.', example='32'),
                referPos?: string(name='ReferPos', description='The reference position of the watermark. Valid values: TopLeft, TopRight, BottomLeft, and BottomRight. Default value: TopLeft.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The duration of the stream. Valid values: the number of seconds or "ToEND".', example='ToEND'),
                  start?: string(name='Start', description='The start time of the stream.', example='00:00:05'),
                }(name='Timeline', description='The timeline settings.'),
                width?: string(name='Width', description='The width of the output video.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          isInheritTags?: boolean(name='IsInheritTags', description='Indicates whether the tags of the input stream are inherited in the output stream. This parameter does not take effect when the input is not a media asset. Default value: false.', example='true'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Indicates whether the text size was adjusted based on the output video dimensions. Valid values: true and false. Default value: false.', example='false'),
                borderColor?: string(name='BorderColor', description='The border color.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The border width.', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the watermark.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.', example='16'),
                left?: string(name='Left', description='The distance of the watermark from the left edge.', example='10'),
                top?: string(name='Top', description='The distance of the watermark from the top edge.', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Indicates whether the audio stream is deleted.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100. Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              tags?: map[string]string(name='Tags'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.

For more information about examples, see How do I set the resolution for an output video?', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum adaptive bitrate (ABR). This parameter takes effect only for Narrowband HD 1.0.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: Kbit/s.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.

If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60]. The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.

Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Indicates whether the auto-rotate screen feature is enabled.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video. Format: width:height:left:top.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Indicates whether the video was removed.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.

Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The transcoding configuration.'),
        requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
        scheduleConfig?: {
          pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the snapshot job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
          priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
        }(name='ScheduleConfig', description='The scheduling information about the job.'),
        status?: string(name='Status', description='The state of the transcoding job. Valid values: Init (the job is submitted), Success (the job is successful), Fail (the job failed), and Deleted (the job is deleted).', example='Init'),
        submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission result.', example='{}'),
        submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
        userData?: string(name='UserData', description='The user data.', example='user-data'),
      }
    ](name='TranscodeJobList', description='The list of subjobs.'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='TranscodeParentJob', description='TranscodeParentJobWithSubJobDTO'),
}

model GetTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTranscodeJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTranscodeJob  GetTranscodeJobRequest
  * @return GetTranscodeJobResponse
 */
async function getTranscodeJob(request: GetTranscodeJobRequest): GetTranscodeJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTranscodeJob', 'POST', '/', 'json', false, 'json', request);
}

model GetUrlUploadInfosRequest {
  regionId?: string(name='RegionId', position='Host'),
  jobIds?: string(name='JobIds', description='The IDs of the upload jobs. You can specify one or more job IDs. You can obtain the job IDs from the response parameter JobId of the [UploadMediaByURL](https://help.aliyun.com/document_detail/86311.html) operation.

*   You can specify a maximum of 10 job IDs.
*   Separate the job IDs with commas (,).

>  You must specify either JobIds or UploadURLs. If you specify both parameters, only the value of JobIds takes effect.', example='df2ac80b481346daa1db6a7c40edc7f8', position='Query'),
  uploadURLs?: string(name='UploadURLs', description='The upload URLs of the source files. You can specify a maximum of 10 URLs. Separate the URLs with commas (,).

> 

*   The URLs must be encoded.

*   If a media file is uploaded multiple times, we recommend that you specify the URL of the media file only once in this parameter.

*   You must specify either JobIds or UploadURLs. If you specify both parameters, only the value of JobIds takes effect.', example='https://media.w3.org/2010/05/sintel/trailer.mp4', position='Query'),
}

model GetUrlUploadInfosResponseBody = {
  nonExists?: [ string ](name='NonExists', description='The job IDs or upload URLs that do not exist.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  URLUploadInfoList?: [ 
    {
      completeTime?: string(name='CompleteTime', description='The time when the upload job was complete. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2021-11-26 21:47:37'),
      creationTime?: string(name='CreationTime', description='The time when the upload job was created. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2021-11-07T10:03:37Z'),
      errorCode?: string(name='ErrorCode', description='The error code returned if the upload job failed.', example='200'),
      errorMessage?: string(name='ErrorMessage', description='The error message returned if the upload job failed.', example='Success'),
      fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='64610'),
      jobId?: string(name='JobId', description='The ID of the upload job.', example='3829500c0fef429fa4ec1680b122d***'),
      mediaId?: string(name='MediaId', description='The ID of the uploaded media file.', example='5014ca70f08171ecbf940764a0fd6***'),
      status?: string(name='Status', description='The status of the upload job. For more information about the valid values of the parameter, see the "Status: the status of a URL-based upload job" section of the [Basic data types](https://help.aliyun.com/document_detail/52839.html) topic.', example='Normal'),
      uploadURL?: string(name='UploadURL', description='The upload URL of the source file.

>  A maximum of 100 URLs can be returned.', example='http://****.mp4'),
      userData?: string(name='UserData', description='The user data. The value is a JSON string.', example='{"MessageCallback":"{"CallbackURL":"http://example.aliyundoc.com"}", "Extend":"{"localId":"***", "test":"www"}"}'),
    }
  ](name='URLUploadInfoList', description='The details about URL-based upload jobs.'),
}

model GetUrlUploadInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetUrlUploadInfosResponseBody(name='body'),
}

/**
  * @description You can call this operation to query the information, including the upload status, user data, creation time, and completion time, about URL-based upload jobs based on the returned job IDs or the URLs used during the upload.
  * If an upload job fails, you can view the error code and error message. If an upload job is successful, you can obtain the video ID.
  * @param request  the request parameters of GetUrlUploadInfos  GetUrlUploadInfosRequest
  * @return GetUrlUploadInfosResponse
 */
async function getUrlUploadInfos(request: GetUrlUploadInfosRequest): GetUrlUploadInfosResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetUrlUploadInfos', 'POST', '/', 'json', false, 'json', request);
}

model GetVideoListRequest {
  regionId?: string(name='RegionId', position='Host'),
  cateId?: long(name='CateId', description='The ID of the category.', example='781111', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. The end time must be later than the start time. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-01-11T12:59:00Z', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='20', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting method of the results. Valid values:

*   CreationTime:Desc (default): sorts results in reverse chronological order.
*   CreationTime:Asc: sorts results in chronological order.', example='CreationTime:Asc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-01-11T12:00:00Z', position='Query'),
  status?: string(name='Status', description='The status of the video. You can specify multiple video statuses and separate them with commas (,).

Valid values:

*   PrepareFail: The file is abnormal.
*   UploadFail: The video failed to be uploaded.
*   UploadSucc: The video is uploaded.
*   Transcoding: The video is being transcoded.
*   TranscodeFail: The video failed to be transcoded.
*   ProduceFail: The video failed to be produced.
*   Normal: The video is normal.
*   Uploading: The video is being uploaded.
*   Preparing: The file is being generated.
*   Blocked: The video is blocked.
*   checking: The video is being reviewed.', example='Uploading,Normal', position='Query'),
}

model GetVideoListResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaList?: [ 
    {
      appId?: string(name='AppId', description='The ID of the application. Default value: app-1000000.', example='app-1000000'),
      cateId?: long(name='CateId', description='The ID of the category.', example='3679'),
      cateName?: string(name='CateName', description='The name of the category.'),
      coverUrl?: string(name='CoverUrl', description='The URL of the thumbnail.', example='http://example.aliyundoc.com/snapshot/****.jpg?auth_key=1498476426-0-0-f00b9455c49a423ce69cf4e27333****'),
      creationTime?: string(name='CreationTime', description='The time when the audio or video file was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:15:50Z'),
      description?: string(name='Description', description='The description of the audio or video file.'),
      duration?: float(name='Duration', description='The duration. Unit: seconds.', example='135.6'),
      mediaId?: string(name='MediaId', description='The ID of the audio or video file.', example='1c6ce34007d571ed94667630a6bc****'),
      modificationTime?: string(name='ModificationTime', description='The time when the audio or video file was updated. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:16:50Z'),
      size?: long(name='Size', description='The size of the source file. Unit: bytes.', example='10897890'),
      snapshots?: [ string ](name='Snapshots', description='The array of video snapshot URLs.'),
      status?: string(name='Status', description='The status of the video.

Valid values:

*   PrepareFail: The file is abnormal.
*   UploadFail: The video failed to be uploaded.
*   UploadSucc: The video is uploaded.
*   Transcoding: The video is being transcoded.
*   TranscodeFail: The video failed to be transcoded.
*   ProduceFail: The video failed to be produced.
*   Normal: The video is normal.
*   Uploading: The video is being uploaded.
*   Preparing: The file is being generated.
*   Blocked: The video is blocked.
*   checking: The video is being reviewed.', example='Normal'),
      storageLocation?: string(name='StorageLocation', description='The storage address.', example='out-****.oss-cn-shanghai.aliyuncs.com'),
      tags?: string(name='Tags', description='The tags of the audio or video file.'),
      title?: string(name='Title', description='The title of the audio or video file.'),
    }
  ](name='MediaList', description='The information about the audio and video files.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request is successful. Valid values:

*   true
*   false', example='true'),
  total?: long(name='Total', description='The total number of audio and video files that meet the conditions.', example='163'),
}

model GetVideoListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetVideoListResponseBody(name='body'),
}

/**
  * @description You can call this operation to query information about up to the first 5,000 audio and video files based on the filter condition, such as the status or category ID of the file. We recommend that you set the StartTime and EndTime parameters to narrow down the time range and perform multiple queries to obtain data.
  * @param request  the request parameters of GetVideoList  GetVideoListRequest
  * @return GetVideoListResponse
 */
async function getVideoList(request: GetVideoListRequest): GetVideoListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetVideoList', 'POST', '/', 'json', false, 'json', request);
}

model GetVodPackagingAssetRequest {
  assetName?: string(name='AssetName', description='The name of the VOD packaging asset.', example='30min_movie', position='Query'),
}

model GetVodPackagingAssetResponseBody = {
  asset?: {
    assetName?: string(name='AssetName', description='The name of the asset.', example='30min_movie'),
    contentId?: string(name='ContentId', description='The content ID in the DRM system. The maximum length is 256 characters. Letters, digits, underscores (_), and hyphens (-) are supported.', example='movie'),
    createTime?: string(name='CreateTime', description='The time when the asset was created. It follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-11-21T06:45:32Z'),
    egressEndpoints?: [ 
      {
        configurationName?: string(name='ConfigurationName', description='The name of the packaging configuration.', example='hls_3s'),
        status?: string(name='Status', description='The asset status. Valid values:

*   Queuing: The asset is waiting for packaging.
*   Playable: The asset is packaged and playable.
*   Failed: The asset fails to be packaged.', example='Playable'),
        url?: string(name='Url', description='The playback URL. If the asset fails to be packaged, no playback URL is returned.'),
      }
    ](name='EgressEndpoints', description='The egress endpoints, each corresponding to a packaging configuration.'),
    groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls'),
    input?: {
      media?: string(name='Media', description='The URL of the media file. Only M3U8 files stored in OSS are supported.'),
      type?: string(name='Type', description='The input type. Only Object Storage Service (OSS) is supported.', example='OSS'),
    }(name='Input', description='The asset input configurations.'),
  }(name='Asset', description='The information about the asset.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
}

model GetVodPackagingAssetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetVodPackagingAssetResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetVodPackagingAsset  GetVodPackagingAssetRequest
  * @return GetVodPackagingAssetResponse
 */
async function getVodPackagingAsset(request: GetVodPackagingAssetRequest): GetVodPackagingAssetResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetVodPackagingAsset', 'POST', '/', 'json', false, 'json', request);
}

model GetVodPackagingConfigurationRequest {
  configurationName?: string(name='ConfigurationName', description='The name of the packaging configuration.', example='hls_3s', position='Query'),
}

model GetVodPackagingConfigurationResponseBody = {
  packagingConfiguration?: VodPackagingConfiguration(name='PackagingConfiguration', description='The information about the packaging configuration.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetVodPackagingConfigurationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetVodPackagingConfigurationResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetVodPackagingConfiguration  GetVodPackagingConfigurationRequest
  * @return GetVodPackagingConfigurationResponse
 */
async function getVodPackagingConfiguration(request: GetVodPackagingConfigurationRequest): GetVodPackagingConfigurationResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetVodPackagingConfiguration', 'POST', '/', 'json', false, 'json', request);
}

model GetVodPackagingGroupRequest {
  groupName?: string(name='GroupName', description='The name of the packaging group. The name must be unique and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='vod_hls', position='Query'),
}

model GetVodPackagingGroupResponseBody = {
  packagingGroup?: VodPackagingGroup(name='PackagingGroup', description='The information about the packaging group.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model GetVodPackagingGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetVodPackagingGroupResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetVodPackagingGroup  GetVodPackagingGroupRequest
  * @return GetVodPackagingGroupResponse
 */
async function getVodPackagingGroup(request: GetVodPackagingGroupRequest): GetVodPackagingGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetVodPackagingGroup', 'POST', '/', 'json', false, 'json', request);
}

model GetWorkflowTaskRequest {
  taskId?: string(name='TaskId', description='The ID of the workflow task.', example='******4215e042b3966ca5441e******', position='Query'),
}

model GetWorkflowTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******0C-7870-15FE-B96F-8880BB******'),
  workflowTask?: {
    activityResults?: string(name='ActivityResults', description='The results for all nodes of the workflow task.'),
    createTime?: string(name='CreateTime', description='The time when the task was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-01-04T02:05:17Z'),
    finishTime?: string(name='FinishTime', description='The time when the task was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-01-04T02:06:19Z'),
    status?: string(name='Status', description='The task state.

Valid values:

*   Init: The task is being initialized.
*   Failed: The task failed.
*   Canceled: The task is canceled.
*   Processing: The task is in progress.
*   Succeed: The task is successful.', example='Succeed'),
    taskId?: string(name='TaskId', description='The ID of the workflow task.', example='******4215e042b3966ca5441e******'),
    taskInput?: string(name='TaskInput', description='The input of the workflow task.', example='{
      "Type": "Media",
      "Media": "******30706071edbfe290b488******"
}'),
    userData?: string(name='UserData', description='The user-defined field that was specified when the workflow task was submitted.', example='{"NotifyAddress":"http://xx.xx.xxx"}'),
    workflow?: {
      createTime?: string(name='CreateTime', description='The time when the workflow was created.', example='2022-11-27T10:02:12Z'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the workflow was last modified.', example='2022-11-29T02:06:19Z'),
      name?: string(name='Name', description='The workflow name.'),
      status?: string(name='Status', description='The workflow state.

Valid values:

*   Active
*   Inactive', example='Active'),
      type?: string(name='Type', description='The workflow type.

Valid values:

*   Customize: custom workflow.
*   System: system workflow.
*   Common: user-created workflow.', example='Common'),
      workflowId?: string(name='WorkflowId', description='The workflow ID.', example='******63dca94c609de02ac0d1******'),
    }(name='Workflow', description='The workflow Information.'),
  }(name='WorkflowTask', description='The information about the workflow task.'),
}

model GetWorkflowTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkflowTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetWorkflowTask  GetWorkflowTaskRequest
  * @return GetWorkflowTaskResponse
 */
async function getWorkflowTask(request: GetWorkflowTaskRequest): GetWorkflowTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetWorkflowTask', 'POST', '/', 'json', false, 'json', request);
}

model InsertMediaToSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  imagesInput?: string(name='ImagesInput', position='Query'),
  input: string(name='Input', description='The URL of the video, audio, or image file that you want to import to the search library.

Note: Make sure that you specify a correct file name and the bucket in which the file resides is in the same region where this operation is called. Otherwise, the file cannot be found or the operation may fail.

Specify an Object Storage Service (OSS) URL in the following format: oss://[Bucket name]/[File path]. For example, you can specify oss://[example-bucket-****]/[object_path-****].

Specify an HTTP URL in the following format: public endpoint. For example, you can specify http://example-test-\\*\\*\\*\\*.mp4.

This parameter is required.', example='http://example-test-****.mp4', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. Each media ID is unique. If you leave this parameter empty, a media ID is automatically generated for this parameter.', example='411bed50018971edb60b0764a0ec6***', position='Query'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

*   video (default)
*   image
*   audio', example='video', position='Query'),
  msgBody?: string(name='MsgBody', description='The message body.', example='{}', position='Query'),
  namespace?: string(name='Namespace', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1', position='Query'),
}

model InsertMediaToSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model InsertMediaToSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: InsertMediaToSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of InsertMediaToSearchLib  InsertMediaToSearchLibRequest
  * @return InsertMediaToSearchLibResponse
 */
async function insertMediaToSearchLib(request: InsertMediaToSearchLibRequest): InsertMediaToSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'InsertMediaToSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model ListAIAgentDialoguesRequest {
  endTime: long(name='EndTime', description='Specify the end of the time range to query using a UNIX timestamp accurate to milliseconds.

This parameter is required.', example='17358082464030', position='Query'),
  order?: string(name='Order', description='The sorting order. Valid values: 

- DESC: descending order (default)
- ASC: ascending order', example='DESC', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='20', position='Query'),
  roundLimit?: string(name='RoundLimit', position='Query'),
  sessionId: string(name='SessionId', description='The session ID.

This parameter is required.', example='f27f9b9be28642a88e18****', position='Query'),
  startTime: long(name='StartTime', description='Specify the start of the time range to query using a UNIX timestamp accurate to milliseconds.

This parameter is required.', example='0', position='Query'),
}

model ListAIAgentDialoguesResponseBody = {
  dialogues?: [ 
    {
      attachedFileList?: [ 
        {
          format?: string(name='Format'),
          id?: string(name='Id'),
          name?: string(name='Name'),
          type?: int32(name='Type'),
          url?: string(name='Url'),
        }
      ](name='AttachedFileList'),
      dialogueId?: string(name='DialogueId', description='The unique ID of the dialog.', example='19de81b3b3d94abda22****'),
      extend?: string(name='Extend'),
      nodeId?: string(name='NodeId'),
      producer?: string(name='Producer', description='The speaker. Valid values: 

- user
- agent', example='user'),
      reasoningText?: string(name='ReasoningText', description='The reasoning trace.', example='I\\"m thinking'),
      roundId?: string(name='RoundId', description='The ID of the conversational turn.', example='f27f9b9be28642a88e18****'),
      source?: string(name='Source', description='The source of the message. Valid values:

chat: messaging conversations.

call: voice calls.', example='chat'),
      text?: string(name='Text', description='The specific content.', example='Hello'),
      time?: long(name='Time', description='The UNIX timestamp, measured in milliseconds, which indicates the time when the message was generated.', example='1734511087000'),
      type?: string(name='Type', description='The message type. Valid values:

Voice calls:

1.  greeting: the welcome message.
2.  normal: the voice response.
3.  speech: the proactive message.

Messaging conversations:

1.  normal: the text reply.
2.  announcement: the proactive text message.
3.  custom: the custom message.', example='announcement'),
    }
  ](name='Dialogues', description='The dialog records.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7B117AF5-***************'),
}

model ListAIAgentDialoguesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAIAgentDialoguesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAIAgentDialogues  ListAIAgentDialoguesRequest
  * @return ListAIAgentDialoguesResponse
 */
async function listAIAgentDialogues(request: ListAIAgentDialoguesRequest): ListAIAgentDialoguesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAIAgentDialogues', 'POST', '/', 'json', false, 'json', request);
}

model ListAIAgentInstanceRequest {
  AIAgentId: string(name='AIAgentId', description='The ID of the AI agent.

This parameter is required.', example='39f8e0bc005e4f309379701645f4***', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC. This parameter does not have a default value.', example='2023-01-02T00:00:00Z', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number. Default value: 1. Valid values: 1 to 100.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 0 to 100.', example='10', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC. This parameter does not have a default value.', example='2023-01-01T00:00:00Z', position='Query'),
}

model ListAIAgentInstanceResponseBody = {
  instances?: [ 
    {
      agentConfig?: AIAgentConfig(name='AgentConfig'),
      callLogUrl?: string(name='CallLogUrl', description='The URL of the call log file for the AI agent. The structure of the file is CallLog in the JSON format.', example='https://example.com/call_logs/12345.json'),
      runtimeConfig?: AIAgentRuntimeConfig(name='RuntimeConfig', description='The runtime configurations of the AI agent.', example='{"VoiceChat":{"AgentUserId":"voice_agent_001","ChannelId":"voice_channel_001","AuthToken":"your_voice_chat_auth_token"}}'),
      status?: string(name='Status', description='The state of the instance. Valid values:

*   Executing
*   Finished', example='Finished'),
      templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', description='The template configurations of the AI agent.', example='{"VoiceChat": {"VoiceId": "zhixiaoxia"}}', deprecated='true'),
      userData?: string(name='UserData', description='The custom information.', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
    }
  ](name='Instances', description='The list of the AI agents.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model ListAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAIAgentInstanceResponseBody(name='body'),
}

/**
  * @description ## [](#)Request description
  * You can call this operation to query a list of AI agents based on the `AIAgentId`. The optional parameters include `StartTime`, `EndTime`, `PageSize`, and `PageNumber`. The returned result includes the status, runtime configurations, template configurations, custom information, and the URL of call log file for each AI agent.
  * **Note**:
  * *   The default value of `PageSize` is 10, and the default value of `PageNumber` is 1.
  * @param request  the request parameters of ListAIAgentInstance  ListAIAgentInstanceRequest
  * @return ListAIAgentInstanceResponse
 */
async function listAIAgentInstance(request: ListAIAgentInstanceRequest): ListAIAgentInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAIAgentInstance', 'POST', '/', 'json', false, 'json', request);
}

model ListAIAgentPhoneNumberRequest {
  number?: string(name='Number', position='Query'),
  pageNumber?: long(name='PageNumber', example='1', position='Query'),
  pageSize?: long(name='PageSize', example='50', position='Query'),
  status?: int32(name='Status', position='Query'),
}

model ListAIAgentPhoneNumberResponseBody = {
  data?: [ 
    {
      phoneNumber?: string(name='PhoneNumber', example='132*****683'),
      status?: int32(name='Status', example='1'),
    }
  ](name='Data'),
  pageNumber?: int32(name='PageNumber', example='1'),
  pageSize?: int32(name='PageSize', example='10'),
  requestId?: string(name='RequestId', example='************16-412C-B127-******'),
  totalNumber?: int32(name='TotalNumber', example='186'),
}

model ListAIAgentPhoneNumberResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAIAgentPhoneNumberResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAIAgentPhoneNumber  ListAIAgentPhoneNumberRequest
  * @return ListAIAgentPhoneNumberResponse
 */
async function listAIAgentPhoneNumber(request: ListAIAgentPhoneNumberRequest): ListAIAgentPhoneNumberResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAIAgentPhoneNumber', 'POST', '/', 'json', false, 'json', request);
}

model ListAIAgentVoiceprintsRequest {
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Value values: [1,100].', example='100', position='Query'),
  voiceprintId?: string(name='VoiceprintId', description='A unique identifier for the voiceprint. This parameter is optional. If provided, only the information for that ID is returned. If not specified, all voiceprints under the account are returned.', example='vp_1699123456_8527', position='Query'),
}

model ListAIAgentVoiceprintsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  totalCount?: int32(name='TotalCount', description='The total number of voiceprints that match the query criteria.', example='2'),
  voiceprints?: [ 
    {
      gmtCreate?: string(name='GmtCreate', description='The creation time of the voiceprint.', example='2025-07-28T10:03:58.000+00:00'),
      gmtModified?: string(name='GmtModified', description='The last modification time of the voiceprint.', example='2025-07-28T10:03:58.000+00:00'),
      voiceprintId?: string(name='VoiceprintId', description='The unique identifier for the voiceprint.', example='vp_1699123456_8527'),
    }
  ](name='Voiceprints', description='The voiceprints.'),
}

model ListAIAgentVoiceprintsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAIAgentVoiceprintsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAIAgentVoiceprints  ListAIAgentVoiceprintsRequest
  * @return ListAIAgentVoiceprintsResponse
 */
async function listAIAgentVoiceprints(request: ListAIAgentVoiceprintsRequest): ListAIAgentVoiceprintsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAIAgentVoiceprints', 'POST', '/', 'json', false, 'json', request);
}

model ListAdInsertionsRequest {
  keyword?: string(name='Keyword', description='The configuration name. Fuzzy match is supported.', example='ad', position='Query'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to retrieve in a subsequent request. If this parameter is used, the pagination parameters become invalid. Default value: 10.', example='10', minimum=0, position='Query'),
  nextToken?: string(name='NextToken', description='The token that is used in the next request to retrieve a new page of results. If this parameter is used, the pagination parameters become invalid.', example='******8EqYpQbZ6Eh7+Zz8DxVYoQ*****', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order of the configurations by creation time. asc: ascending. desc: descending.', example='asc', position='Query'),
}

model ListAdInsertionsResponseBody = {
  configs?: [ 
    {
      adMarkerPassthrough?: string(name='AdMarkerPassthrough', description='Indicates whether ad marker passthrough is enabled.', example='ON'),
      adsUrl?: string(name='AdsUrl', description='The request URL of the ad decision server (ADS).', example='http://ads.com/ad1?param1=[palyer_params.p1]'),
      cdnConfig?: {
        adSegmentUrlPrefix?: string(name='AdSegmentUrlPrefix', description='The CDN prefix for ad segments.', example='http://cdn.com/'),
        contentSegmentUrlPrefix?: string(name='ContentSegmentUrlPrefix', description='The CDN prefix for content segments.', example='http://cdn.com/'),
      }(name='CdnConfig', description='The CDN configurations.'),
      configAliases?: string(name='ConfigAliases', description='The player parameter variables and aliases.', example='{
      "player_params.p1": {
            "1": "abc"
      }
}'),
      contentUrlPrefix?: string(name='ContentUrlPrefix', description='The URL prefix for the source content.', example='https://source.com/'),
      createTime?: string(name='CreateTime', description='The time when the configuration was created.', example='2024-06-13T08:26:09Z'),
      lastModified?: string(name='LastModified', description='The time when the configuration was last modified.', example='2024-06-13T08:26:09Z'),
      manifestEndpointConfig?: {
        dashPrefix?: string(name='DashPrefix', description='DASH清单播放端点前缀'),
        hlsPrefix?: string(name='HlsPrefix', description='The prefix of the playback endpoint for HLS manifests.'),
      }(name='ManifestEndpointConfig', description='The playback endpoint configuration.'),
      name?: string(name='Name', description='The name of the ad insertion configuration.', example='my_ad'),
      personalizationThreshold?: int32(name='PersonalizationThreshold', description='The personalization threshold that defines the maximum duration of underfilled time allowed in an ad break.', example='5'),
      slateAdUrl?: string(name='SlateAdUrl', description='The URL of the slate ad.', example='http://storage.com/slate1.mp4'),
    }
  ](name='Configs', description='Array'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to retrieve in a subsequent request. If this parameter is used, the pagination parameters become invalid.', example='10'),
  nextToken?: string(name='NextToken', description='The token that is used in the next request to retrieve a new page of results. If this parameter is used, the pagination parameters become invalid.', example='******8EqYpQbZ6Eh7+Zz8DxVYoQ*****'),
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the configurations by creation time. asc: ascending. desc: descending.', example='asc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='10'),
}

model ListAdInsertionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAdInsertionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAdInsertions  ListAdInsertionsRequest
  * @return ListAdInsertionsResponse
 */
async function listAdInsertions(request: ListAdInsertionsRequest): ListAdInsertionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAdInsertions', 'POST', '/', 'json', false, 'json', request);
}

model ListAlertsRequest {
  category?: string(name='Category', description='The alert type.', position='Query'),
  gmtEnd?: string(name='GmtEnd', description='The end of the time range to query.', example='2024-11-22T16:10:45Z', position='Query'),
  gmtStart?: string(name='GmtStart', description='The beginning of the time range to query.', example='2024-11-21T16:10:45Z', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='20', position='Query'),
  resourceArn: string(name='ResourceArn', description='The ARN of the source or program.

This parameter is required.', example='acs:ims:mediaweaver:<regionId>:<userId>:vodSource/mySourceLocation/MySource', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values: asc and desc.', example='asc', position='Query'),
  sortByModifiedTime?: string(name='SortByModifiedTime', description='The sorting order by modification time. Valid values: asc and desc.', example='asc', position='Query'),
}

model ListAlertsResponseBody = {
  alerts?: [ 
    {
      category?: string(name='Category', description='The alert type.'),
      code?: string(name='Code', description='The error code.', example='ScheduleError'),
      gmtCreate?: string(name='GmtCreate', description='The time when the alert was received in UTC.', example='2024-07-16T10:03Z'),
      gmtModified?: string(name='GmtModified', description='The time when the alert was modified in UTC.', example='2024-07-16T10:03Z'),
      message?: string(name='Message', description='The error message.', example='xxxxx'),
      relatedResourceArns?: string(name='RelatedResourceArns', description='The ARN of the related resource.', example='acs:ims:mediaweaver:<regionId>:<userId>:vodSource/mySourceLocation/MySource'),
      resourceArn?: string(name='ResourceArn', description='The ARN of the resource.', example='acs:ims:mediaweaver:<regionId>:<userId>:vodSource/mySourceLocation/MySource'),
    }
  ](name='Alerts', description='The alerts.'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListAlertsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAlertsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAlerts  ListAlertsRequest
  * @return ListAlertsResponse
 */
async function listAlerts(request: ListAlertsRequest): ListAlertsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAlerts', 'POST', '/', 'json', false, 'json', request);
}

model ListAllPublicMediaTagsRequest {
  regionId?: string(name='RegionId', position='Host'),
  businessType?: string(name='BusinessType', description='The business type of the media asset.', example='"sticker"', position='Query'),
  entityId?: string(name='EntityId', description='The entity ID, which is used to distinguish between media assets of different types in the public domain.

Set this parameter to Copyright_Music, which indicates music in the public domain.', example='Copyright_Music', position='Query'),
}

model ListAllPublicMediaTagsResponseBody = {
  mediaTagList?: [ 
    {
      mediaTagId?: string(name='MediaTagId', description='The ID of the media tag.', example='sticker-gif'),
      mediaTagNameChinese?: string(name='MediaTagNameChinese', description='The name of the media tag in Chinese.', example='Gif'),
      mediaTagNameEnglish?: string(name='MediaTagNameEnglish', description='The name of the material tag in English.'),
      options?: [ 
        {
          optionChineseName?: string(name='OptionChineseName', description='The option name in Chinese.'),
          optionEnglishName?: string(name='OptionEnglishName', description='The option name in English.', example='Angry'),
          optionId?: string(name='OptionId', description='The option ID.', example='Angry'),
        }
      ](name='Options', description='The options.'),
    }
  ](name='MediaTagList', description='The tags of media assets in the public media library.'),
  requestId?: string(name='RequestId', description='The request ID.', example='B45F83B7-7F87-4792-BFE9-63CD2137CAF0'),
}

model ListAllPublicMediaTagsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAllPublicMediaTagsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAllPublicMediaTags  ListAllPublicMediaTagsRequest
  * @return ListAllPublicMediaTagsResponse
 */
async function listAllPublicMediaTags(request: ListAllPublicMediaTagsRequest): ListAllPublicMediaTagsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAllPublicMediaTags', 'POST', '/', 'json', false, 'json', request);
}

model ListAvatarTrainingJobsRequest {
  pageNo?: int32(name='PageNo', description='*   The page number.
*   Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='*   The number of entries per page.
*   Default value: 10.
*   Valid values: 1 to 100.', example='10', maximum=100, position='Query'),
  status?: string(name='Status', description='*   The job state.
*   Valid values: Init, Queuing, Training, Success, and Fail.', example='Success', position='Query'),
}

model ListAvatarTrainingJobsResponseBody = {
  data?: {
    avatarTrainingJobList?: [ 
      {
        avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
        avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXX'),
        avatarName?: string(name='AvatarName', description='The name of the digital human.'),
        avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
        createTime?: string(name='CreateTime', description='*   The time when the job was created.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
        firstTrainingTime?: string(name='FirstTrainingTime', description='*   The time when the first training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
        jobId?: string(name='JobId', description='The ID of the digital human training job.', example='*****aded114489ea02e0addf93*****'),
        lastTrainingTime?: string(name='LastTrainingTime', description='*   The time when the last training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
        message?: string(name='Message', description='The status description.'),
        portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='*****aded114489ea02e0addf93*****'),
        status?: string(name='Status', description='The state of the digital human training job.', example='Normal'),
      }
    ](name='AvatarTrainingJobList', description='The list of digital human training jobs.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='3'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model ListAvatarTrainingJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAvatarTrainingJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAvatarTrainingJobs  ListAvatarTrainingJobsRequest
  * @return ListAvatarTrainingJobsResponse
 */
async function listAvatarTrainingJobs(request: ListAvatarTrainingJobsRequest): ListAvatarTrainingJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAvatarTrainingJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListAvatarsRequest {
  avatarType?: string(name='AvatarType', description='*   The type of the digital human.
*   2DAvatar', example='2DAvatar', position='Query'),
  pageNo?: int32(name='PageNo', description='*   The page number.
*   Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='*   The number of entries per page.
*   Default value: 10.', example='10', maximum=100, position='Query'),
}

model ListAvatarsResponseBody = {
  data?: {
    avatarList?: [ 
      {
        avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
        avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXX'),
        avatarName?: string(name='AvatarName', description='The name of the digital human.'),
        avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
        portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='****571c704445f9a0ee011406c2****'),
        thumbnail?: string(name='Thumbnail', description='The thumbnail URL.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
        transparent?: boolean(name='Transparent', description='Indicates whether the digital human image supports the alpha channels.', example='true'),
      }
    ](name='AvatarList', description='The queried digital humans.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model ListAvatarsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAvatarsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAvatars  ListAvatarsRequest
  * @return ListAvatarsResponse
 */
async function listAvatars(request: ListAvatarsRequest): ListAvatarsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAvatars', 'POST', '/', 'json', false, 'json', request);
}

model ListBatchMediaProducingJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2023-06-05T15:59:59Z', position='Query'),
  jobId?: string(name='JobId', description='The ID of the quick video production job.', example='****d80e4e4044975745c14b****', position='Query'),
  jobType?: string(name='JobType', description='The job type.

Valid values:

*   Script: script-based editing job that mixes media assets.
*   Smart_Mix: intelligent editing job that mixes media assets.', example='Script', position='Query'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.', example='100', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='mRZkKAovub0xWVfH14he4Q==', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting parameter. Valid values:

*   desc (default): sorted by creation time in descending order.
*   asc: sorted by creation time in ascending order.

<!---->', example='desc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-02-02T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The job state.

Valid values:

*   Finished
*   Init
*   Failed
*   Processing', example='Finished', position='Query'),
}

model ListBatchMediaProducingJobsResponseBody = {
  editingBatchJobList?: [ 
    {
      completeTime?: string(name='CompleteTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2023-06-09T06:38:09Z'),
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-06-09T06:36:48Z'),
      editingConfig?: string(name='EditingConfig', description='The editing configurations. For more information, see [EditingConfig](~~2692547#1be9bba03b7qu~~).', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}'),
      extend?: string(name='Extend', description='The extended information of the job.', example='{}'),
      inputConfig?: string(name='InputConfig', description='The input configurations.'),
      jobId?: string(name='JobId', description='The ID of the quick video production job.', example='******7ecbee4c6d9b8474498e******'),
      jobType?: string(name='JobType', description='The job type.

Valid values:

*   Script: script-based editing job that mixes media assets.
*   Smart_Mix: intelligent editing job that mixes media assets.', example='Script'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2023-06-09T06:37:58Z'),
      outputConfig?: string(name='OutputConfig', description='The output configurations. For more information, see [OutputConfig](~~2692547#447b928fcbuoa~~).', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 20,
  "MaxDuration": 15,
  "Width": 1080,
  "Height": 1920,
  "Video": {"Crf": 27}
}'),
      status?: string(name='Status', description='The job state.

Valid values:

*   Finished
*   Init
*   Failed
*   Processing', example='Finished'),
      userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).'),
    }
  ](name='EditingBatchJobList', description='The queried quick video production jobs.'),
  maxResults?: int32(name='MaxResults', description='The number of entries per page. Valid values: 1 to 100.

Default value: 10.', example='100'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model ListBatchMediaProducingJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListBatchMediaProducingJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListBatchMediaProducingJobs  ListBatchMediaProducingJobsRequest
  * @return ListBatchMediaProducingJobsResponse
 */
async function listBatchMediaProducingJobs(request: ListBatchMediaProducingJobsRequest): ListBatchMediaProducingJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListBatchMediaProducingJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListChannelAlertsRequest {
  category?: string(name='Category', description='The alert type.', position='Query'),
  gmtEnd?: string(name='GmtEnd', description='The end of the time range to query.', example='2024-11-21T16:10:45Z', position='Query'),
  gmtStart?: string(name='GmtStart', description='The beginning of the time range to query.', example='2024-11-21T16:10:45Z', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10', position='Query'),
  resourceArn: string(name='ResourceArn', description='The ARN of the channel.

This parameter is required.', example='acs:ims:mediaweaver:<regionId>:<userId>:channel/myChannel', position='Query'),
  sortByModifiedTime?: string(name='SortByModifiedTime', description='The sorting order by modification time. Valid values: asc and desc.', example='desc', position='Query'),
}

model ListChannelAlertsResponseBody = {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  programAlerts?: [ 
    {
      arn?: string(name='Arn', description='The ARN of the program.', example='acs:ims:mediaweaver:<regionId>:<userId>:program/myChannel/MyProgram'),
      category?: string(name='Category', description='The alert type.'),
      count?: int32(name='Count', description='The number of alerts.', example='4'),
      gmtModified?: string(name='GmtModified', description='The time when the alert was last modified in UTC.', example='2024-07-16T10:03Z'),
      programName?: string(name='ProgramName', description='The name of the program.', example='program_name'),
    }
  ](name='ProgramAlerts', description='The alerts.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  totalCount?: int32(name='TotalCount', description='The total number of alerts returned.', example='4'),
}

model ListChannelAlertsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListChannelAlertsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListChannelAlerts  ListChannelAlertsRequest
  * @return ListChannelAlertsResponse
 */
async function listChannelAlerts(request: ListChannelAlertsRequest): ListChannelAlertsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListChannelAlerts', 'POST', '/', 'json', false, 'json', request);
}

model ListChannelsRequest {
  channelName?: string(name='ChannelName', description='The name of the channel.', example='MyChannel', position='Query'),
  channelTier?: string(name='ChannelTier', description='The tier of the channel. Valid values: basic and standard.', example='basic', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='20', position='Query'),
  playbackMode?: string(name='PlaybackMode', description='The playback mode. Valid values: loop and linear.', example='loop', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order by creation time. Valid values: asc and desc.', example='asc', position='Query'),
  sortByModifiedTime?: string(name='SortByModifiedTime', description='The sorting order by modification time. Valid values: asc and desc.', example='desc', position='Query'),
  state?: int32(name='State', description='The channel status. A value of 0 specifies stopped. A value of 1 specifies started.', example='0', position='Query'),
}

model ListChannelsResponseBody = {
  channelList?: [
    ChannelAssemblyChannel
  ](name='ChannelList', description='The channels.'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  totalCount?: int32(name='TotalCount', description='The total number of channels returned.', example='180'),
}

model ListChannelsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListChannelsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListChannels  ListChannelsRequest
  * @return ListChannelsResponse
 */
async function listChannels(request: ListChannelsRequest): ListChannelsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListChannels', 'POST', '/', 'json', false, 'json', request);
}

model ListCustomTemplatesRequest {
  name?: string(name='Name', description='The template name.', example='test-template', position='Query'),
  orderBy?: string(name='OrderBy', description='The order in which the entries are sorted. Valid values:

*   CreateTimeDesc: sorted by creation time in descending order.
*   CreateTimeAsc: sorted by creation time in ascending order.', example='CreateTimeDesc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='20', position='Query'),
  subtype?: string(name='Subtype', description='The subtype ID of the template.

*   Valid values for transcoding templates:

    *   1 (Normal): regular template.
    *   2 (AudioTranscode): audio transcoding template.
    *   3 (Remux): container format conversion template.
    *   4 (NarrowBandV1): Narrowband HD 1.0 template.
    *   5 (NarrowBandV2): Narrowband HD 2.0 template.

*   Valid values for snapshot templates:

    *   1 (Normal): regular template.
    *   2 (Sprite): sprite template.
    *   3 (WebVtt): WebVTT template.

*   Valid values for AI-assisted content moderation templates:

    *   1 (Video): video moderation template.
    *   2 (Audio): audio moderation template.
    *   3 (Image): image moderation template.

*   Valid values for AI-assisted intelligent erasure templates:

    *   1 (VideoDelogo): logo erasure template.
    *   2 (VideoDetext): subtitle erasure template.', example='2', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****', position='Query'),
  type: string(name='Type', description='The template type. Valid values:

*   1: transcoding template.
*   2: snapshot template.
*   3: animated image template.
*   4\\. image watermark template.
*   5: text watermark template.
*   6: subtitle template.
*   7: AI-assisted content moderation template.
*   8: AI-assisted intelligent thumbnail template.
*   9: AI-assisted intelligent erasure template.

This parameter is required.', example='1', position='Query'),
}

model ListCustomTemplatesResponseBody = {
  customTemplateList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
      frontendHint?: {
        transcodeTemplateHint?: {
          bitrateControlType?: string(name='BitrateControlType'),
        }(name='TranscodeTemplateHint'),
      }(name='FrontendHint'),
      isDefault?: boolean(name='IsDefault', description='Indicates whether the template is the default template.

Valid values:

*   true
*   false', example='true'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
      status?: string(name='Status', description='The template state.

Valid values:

*   Normal', example='Normal'),
      subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='2'),
      subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='AudioTranscode'),
      templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Container":{"Format":"mp3"},"Audio":{"Codec":"mp3","Bitrate":"64","Samplerate":"22050","Channels":"2"}}'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
      templateName?: string(name='TemplateName', description='The template name.', example='test-template'),
      type?: int32(name='Type', description='The type ID of the template.', example='1'),
      typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
    }
  ](name='CustomTemplateList', description='The queried templates.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  total?: int32(name='Total', description='The total number of templates.', example='20'),
}

model ListCustomTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCustomTemplatesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListCustomTemplates  ListCustomTemplatesRequest
  * @return ListCustomTemplatesResponse
 */
async function listCustomTemplates(request: ListCustomTemplatesRequest): ListCustomTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListCustomTemplates', 'POST', '/', 'json', false, 'json', request);
}

model ListCustomizedVoiceJobsRequest {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10', position='Query'),
  type?: string(name='Type', description='The type of the human voice cloning job. Valid values:

*   Basic
*   Standard

> : If you do not specify this parameter, the default value Basic is used.', example='Standard', position='Query'),
}

model ListCustomizedVoiceJobsResponseBody = {
  data?: {
    customizedVoiceJobList?: [ 
      {
        createTime?: string(name='CreateTime', description='*   The time when the job was created.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-04-01T06:23:59Z'),
        gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
        gmtCreate?: string(name='GmtCreate', description='The time when the job was created.', example='2022-06-27T02:42:28Z'),
        jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='2245ab99a7fd4116a4fd3f499b7a56c5'),
        message?: string(name='Message', description='The returned message.'),
        scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation', example='story'),
        status?: string(name='Status', description='The job state. Valid values:

*   Initialization
*   AudioDetecting
*   PreTraining
*   Training
*   Success
*   Fail', example='Success'),
        type?: string(name='Type', description='*   The voice type. Valid values:

    *   Basic
    *   Standard', example='Standard'),
        voiceDesc?: string(name='VoiceDesc', description='The voice description.

*   The description can be up to 256 characters in length.'),
        voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
        voiceName?: string(name='VoiceName', description='The voice name.

*   The name can be up to 32 characters in length.'),
      }
    ](name='CustomizedVoiceJobList', description='The queried human voice cloning jobs.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='271'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
}

model ListCustomizedVoiceJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCustomizedVoiceJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListCustomizedVoiceJobs  ListCustomizedVoiceJobsRequest
  * @return ListCustomizedVoiceJobsResponse
 */
async function listCustomizedVoiceJobs(request: ListCustomizedVoiceJobsRequest): ListCustomizedVoiceJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListCustomizedVoiceJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListCustomizedVoicesRequest {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10', position='Query'),
  type?: string(name='Type', description='*   The voice type. Valid values:

    *   Basic
    *   Standard

*   If you do not specify this parameter, the default value Basic is used.', example='Standard', position='Query'),
}

model ListCustomizedVoicesResponseBody = {
  data?: {
    customizedVoiceList?: [ 
      {
        demoAudioMediaId?: string(name='DemoAudioMediaId', description='The media asset ID of the sample audio file.', example='****4d5e829d498aaf966b119348****'),
        gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='male'),
        scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation', example='story'),
        type?: string(name='Type', description='*   The voice type. Valid values:

    *   Basic
    *   Standard', example='Standard'),
        voiceDesc?: string(name='VoiceDesc', description='The voice description.'),
        voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
        voiceName?: string(name='VoiceName', description='The voice name.'),
      }
    ](name='CustomizedVoiceList', description='The queried personalized human voices.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='41'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model ListCustomizedVoicesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCustomizedVoicesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListCustomizedVoices  ListCustomizedVoicesRequest
  * @return ListCustomizedVoicesResponse
 */
async function listCustomizedVoices(request: ListCustomizedVoicesRequest): ListCustomizedVoicesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListCustomizedVoices', 'POST', '/', 'json', false, 'json', request);
}

model ListDNADBRequest {
  DBIds?: string(name='DBIds', description='The IDs of the media fingerprint libraries. We recommend that you query at most 10 libraries at a time. Separate multiple library IDs with commas (,).', example='2288c6ca184c0e47098a5b665e2a12****,78dc866518b843259669df58ed30****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model ListDNADBResponseBody = {
  DBList?: [ 
    {
      DBId?: string(name='DBId', description='The ID of the media fingerprint library.', example='88c6ca184c0e47098a5b665e2a12****'),
      description?: string(name='Description', description='The description of the media fingerprint library.'),
      model?: string(name='Model', description='The model of the media fingerprint library. Valid values:

*   **Video**
*   **Audio**
*   **Image**
*   **Text** (supported only in the China (Shanghai) region)', example='Video'),
      name?: string(name='Name', description='The name of the media fingerprint library.', example='example-name'),
      status?: string(name='Status', description='The state of the media fingerprint library. Default value: **offline**. ****Valid values:

*   **offline**: The media fingerprint library is offline.
*   **active**: The media fingerprint library is online.
*   **deleted**: The media fingerprint library is deleted.', example='active'),
    }
  ](name='DBList', description='The queried media fingerprint libraries.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model ListDNADBResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDNADBResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDNADB  ListDNADBRequest
  * @return ListDNADBResponse
 */
async function listDNADB(request: ListDNADBRequest): ListDNADBResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDNADB', 'POST', '/', 'json', false, 'json', request);
}

model ListDNAFilesRequest {
  DBId: string(name='DBId', description='The ID of the media fingerprint library.

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='ae0fd49c0840e14daf0d66a75b83****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10', minimum=1, maximum=100, position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model ListDNAFilesResponseBody = {
  fileList?: [ 
    {
      inputFile?: {
        bucket?: string(name='Bucket', description='The name of the OSS bucket in which the input file is stored.', example='example-bucket'),
        location?: string(name='Location', description='The OSS region in which the input file resides.', example='oss-cn-beijing'),
        object?: string(name='Object', description='The name of the OSS object that is used as the input file.', example='example-****.mp4'),
      }(name='InputFile', description='The Object Storage Service (OSS) information about the input file.'),
      primaryKey?: string(name='PrimaryKey', description='The primary key of the file.', example='ae0fd49c0840e14daf0d66a75b83****'),
    }
  ](name='FileList', description='The queried files.'),
  nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='ae0fd49c0840e14daf0d66a75b83****'),
  requestId?: string(name='RequestId', description='The request ID.', example='2AE89FA5-E620-56C7-9B80-75D09757385A'),
}

model ListDNAFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDNAFilesResponseBody(name='body'),
}

/**
  * @description You can call this operation to query files in a media fingerprint library based on the library ID. The queried results can be paginated.
  * @param request  the request parameters of ListDNAFiles  ListDNAFilesRequest
  * @return ListDNAFilesResponse
 */
async function listDNAFiles(request: ListDNAFilesRequest): ListDNAFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDNAFiles', 'POST', '/', 'json', false, 'json', request);
}

model ListDynamicImageJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created.', example='2022-07-14T00:00:00Z', position='Query'),
  jobId?: string(name='JobId', description='The job ID.', example='****cdb3e74639973036bc84****', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='cdb3e74639973036bc84', position='Query'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

1.  CreateTimeAsc: sorts the jobs by creation time in ascending order.
2.  CreateTimeDesc: sorts the jobs by creation time in descending order.', example='CreateTimeDesc', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Maximum value: 100.', example='20', position='Query'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created.', example='2022-07-12T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success', position='Query'),
}

model ListDynamicImageJobsResponseBody = {
  jobs?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
      input?: {
        media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[regionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://bucket/object'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.

*
*', example='OSS'),
      }(name='Input', description='The input of the job.'),
      jobId?: string(name='JobId', description='The job ID.', example='****cdb3e74639973036bc84****'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
      name?: string(name='Name', description='The name of the job.', example='SampleJob'),
      output?: {
        media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='****cdb3e74639973036bc84****'),
        type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

*
*', example='Media'),
      }(name='Output', description='The output of the job.'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****cdb3e74639973036bc84****'),
      status?: string(name='Status', description='The state of the job.

*   **Success**: The job is successful.
*   **Fail**: The job failed.
*   **Init**: The job is submitted.', example='Success'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****cdb3e74639973036bc84****'),
      triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
    }
  ](name='Jobs', description='The list of jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****cdb3e74639973036bc84****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListDynamicImageJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDynamicImageJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDynamicImageJobs  ListDynamicImageJobsRequest
  * @return ListDynamicImageJobsResponse
 */
async function listDynamicImageJobs(request: ListDynamicImageJobsRequest): ListDynamicImageJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDynamicImageJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListEditingProjectsRequest {
  regionId?: string(name='RegionId', position='Host'),
  createSource?: string(name='CreateSource', description='The method for creating the online editing project. Valid values:

\\- OpenAPI

\\- AliyunConsole

\\- WebSDK', example='OpenAPI', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-02-02T23:59:59Z', position='Query'),
  keyword?: string(name='Keyword', description='The search keyword. You can search by job ID.', example='******6f36bc45d09a9d5cde49******', position='Query'),
  maxResults?: string(name='MaxResults', description='The number of entries per page. A maximum of 100 entries can be returned on each page.

Default value: 10.', example='10', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ==', position='Query'),
  projectType?: string(name='ProjectType', description='The type of the editing project. Valid values:

*   EditingProject: a regular editing project.
*   LiveEditingProject: a live stream editing project.', example='EditingProject', position='Query'),
  sortBy?: string(name='SortBy', description='The order of sorting of the results. Valid values:

*   CreationTime:Desc (default): sorts the results in reverse chronological order.
*   CreationTime:Asc: sorts the results in chronological order.', example='CreationTime:Desc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-12-21T08:00:01Z', position='Query'),
  status?: string(name='Status', description='The status of the online editing project. By default, online editing projects in all states are queried.', example='Produced', position='Query'),
  templateType?: string(name='TemplateType', description='The template type. This parameter is required if you create a template-based online editing project. Default value: Timeline.

*
*

Valid values:

*   Timeline: a regular template.
*   VETemplate: an advanced template.
*   None: general editing.', example='None', position='Query'),
}

model ListEditingProjectsResponseBody = {
  maxResults?: int32(name='MaxResults', description='The maximum number of entries returned.', example='10'),
  nextToken: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.

This parameter is required.', example='Nzv3rcKla9wHUGua9YXHNA=='),
  projectList?: [ 
    {
      businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{}'),
      businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects.', example='{}'),
      coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='https://xxx.com/cover/xxx.jpg'),
      createSource?: string(name='CreateSource', description='The method for editing the online editing project. Valid values:

\\- OpenAPI

\\- AliyunConsole

\\- WebSDK', example='OpenAPI'),
      createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2017-01-11T12:00:00Z'),
      description?: string(name='Description', description='The description of the online editing project.'),
      errorCode?: string(name='ErrorCode', description='The error code returned if the production of the online editing project failed.', example='InvalidParameter'),
      errorMessage?: string(name='ErrorMessage', description='The error message returned if the production of the online editing project failed.', example='The specified parameter \\"LiveStreamConfig\\" is not valid. specified parameter example is not valid.'),
      modifiedSource?: string(name='ModifiedSource', description='The method for modifying the online editing project last time.', example='OpenAPI'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last modified.', example='2017-01-11T12:00:00Z'),
      projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fddd7748b58bf1d47e95****'),
      projectType?: string(name='ProjectType', description='The type of the editing project. Valid values:

*   EditingProject: a regular editing project.
*   LiveEditingProject: a live stream editing project.', example='EditingProject'),
      status?: string(name='Status', description='The status of the online editing project. Valid values:

\\- Draft

\\- Editing

\\- Producing

\\- Produced

\\- ProduceFailed', example='Produced'),
      templateType?: string(name='TemplateType', description='The template type. Valid values:

*   Timeline: a regular template.
*   VETemplate: an advanced template.', example='Timeline'),
      title?: string(name='Title', description='The title of the online editing project.'),
    }
  ](name='ProjectList', description='The queried online editing projects.'),
  requestId?: string(name='RequestId', description='The request ID.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
}

model ListEditingProjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListEditingProjectsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListEditingProjects  ListEditingProjectsRequest
  * @return ListEditingProjectsResponse
 */
async function listEditingProjects(request: ListEditingProjectsRequest): ListEditingProjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListEditingProjects', 'POST', '/', 'json', false, 'json', request);
}

model ListHotwordLibrariesRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query.', example='2020-12-26T04:11:10Z', position='Query'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.

Default value: 10. Valid values: 1 to 100.', example='10', position='Query'),
  name?: string(name='Name', description='The name of the hotword library.', example='热词库使用名称', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****73f33c91-d59383e8280b****', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.', example='CreationTime:Desc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query.', example='2020-12-26T04:11:10Z', position='Query'),
  usageScenario?: string(name='UsageScenario', description='The usage scenario of the hotword library. Valid values:

*   ASR: Automatic Speech Recognition
*   StructuredMediaAssets: structured media analysis
*   VideoTranslation: Video translation. This field cannot be modified after the hotword library is created.', example='ASR', position='Query'),
}

model ListHotwordLibrariesResponseBody = {
  hotwordLibraryList?: [ 
    {
      creationTime?: string(name='CreationTime', description='The time when the hotword library was created.', example='2017-01-11T12:00:00Z'),
      description?: string(name='Description', description='The description of the hotword library. It can be up to 200 characters in length.'),
      hotwordLibraryId?: string(name='HotwordLibraryId', description='The ID of the hotword library.', example='a93b91141c0f422fa114af203f8b****'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the hotword library was last modified.', example='2017-01-11T12:00:00Z'),
      name?: string(name='Name', description='The name of the hotword library.', example='my_hotwords'),
      usageScenario?: string(name='UsageScenario', description='The usage scenario of the hotword library. Valid values:

*   ASR: Automatic Speech Recognition
*   StructuredMediaAssets: structured media analysis
*   VideoTranslation: Video translation This field cannot be modified after the hotword library is created.', example='ASR'),
    }
  ](name='HotwordLibraryList', description='The hotword libraries.'),
  maxResults?: int32(name='MaxResults', description='The maximum number of hotword libraries that can be returned.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token that can be used in the next request to retrieve a new page of results. If it is empty, all results are returned.', example='CBB6BC61D08'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****9262E3DA-07FA-4862-FCBB6BC61D08*****'),
  totalCount?: int32(name='TotalCount', description='The total number of hotword libraries.', example='20'),
}

model ListHotwordLibrariesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListHotwordLibrariesResponseBody(name='body'),
}

/**
  * @description ## [](#)
  * *   You can call this operation to get information about all hotword libraries that you created.
  * *   The API supports fuzzy search by `Name`, filtering by creation time range, and pagination.
  * *   By default, the results are sorted by creation time in descending order. You can set `SortBy` to change the sorting order.
  * *   The maximum number of entries returned for each request is 100. Default value: 10.
  * *   Use `NextToken` for pagination.
  * @param request  the request parameters of ListHotwordLibraries  ListHotwordLibrariesRequest
  * @return ListHotwordLibrariesResponse
 */
async function listHotwordLibraries(request: ListHotwordLibrariesRequest): ListHotwordLibrariesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListHotwordLibraries', 'POST', '/', 'json', false, 'json', request);
}

model ListLivePackageChannelGroupsRequest {
  keyword?: string(name='Keyword', description='The channel group name or description. Fuzzy match is supported.', example='channel-group', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sort order by creation time. Default value: desc.', example='desc', position='Query'),
}

model ListLivePackageChannelGroupsResponseBody = {
  livePackageChannelGroups?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the channel group was created. It is in the `yyyy-MM-ddTHH:mm:ssZ` format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
      description?: string(name='Description', description='The channel group description.'),
      groupName?: string(name='GroupName', description='The channel group name.', example='testChannelGroup'),
      lastModified?: string(name='LastModified', description='The time when the channel group was last modified. It is in the `yyyy-MM-ddTHH:mm:ssZ` format and displayed in UTC.', example='2023-04-02T12:00:00Z'),
      originDomain?: string(name='OriginDomain', description='The origin domain.', example='origin.example.com'),
    }
  ](name='LivePackageChannelGroups', description='The channel groups returned.'),
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='5D87B753-0250-5D9D-B248-D40C3271F864'),
  sortBy?: string(name='SortBy', description='The sort order.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLivePackageChannelGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLivePackageChannelGroupsResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * @param request  the request parameters of ListLivePackageChannelGroups  ListLivePackageChannelGroupsRequest
  * @return ListLivePackageChannelGroupsResponse
 */
async function listLivePackageChannelGroups(request: ListLivePackageChannelGroupsRequest): ListLivePackageChannelGroupsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLivePackageChannelGroups', 'POST', '/', 'json', false, 'json', request);
}

model ListLivePackageChannelsRequest {
  groupName: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1', position='Query'),
  keyword?: string(name='Keyword', description='The channel name or description. Fuzzy match is supported.', example='group-1', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sort order by creation time. Default value: desc.

Valid values:

*   asc
*   desc', example='desc', position='Query'),
}

model ListLivePackageChannelsResponseBody = {
  livePackageChannels?: [ 
    {
      channelName?: string(name='ChannelName', description='The channel name.', example='ch3'),
      createTime?: string(name='CreateTime', description='The time when the channel was created.', example='2023-04-01T12:00:00Z'),
      description?: string(name='Description', description='The channel description.'),
      groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
      ingestEndpoints?: [ 
        {
          id?: string(name='Id', description='The ingest endpoint ID.', example='ingest1'),
          password?: string(name='Password', description='The password.', example='2F9e9******18b569c8'),
          url?: string(name='Url', description='The ingest endpoint URL.', example='http://xxx-1.packagepush-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
          username?: string(name='Username', description='The username.', example='us12******das'),
        }
      ](name='IngestEndpoints', description='The ingest endpoints.'),
      lastModified?: string(name='LastModified', description='The time when the channel was last modified.', example='2023-04-01T12:00:00Z'),
      protocol?: string(name='Protocol', description='The ingest protocol. Only HLS is supported.', example='HLS'),
      segmentCount?: int32(name='SegmentCount', description='The number of M3U8 segments.', example='3'),
      segmentDuration?: int32(name='SegmentDuration', description='The segment duration.', example='5'),
    }
  ](name='LivePackageChannels', description='The live package channels.'),
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.'),
  sortBy?: string(name='SortBy', description='The sort order. Valid values: asc and desc (default).', example='asc/desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='15'),
}

model ListLivePackageChannelsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLivePackageChannelsResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * This API operation allows you to query live package channels by **GroupName** and **Keyword**. Keyword is optional. You can sort the channels by creation time in ascending or descending order and paginate the results. This facilitates the management of channels and retrieval of channel information.
  * *   **GroupName** is required to specify the channel group to which the channel belongs.
  * *   **Keyword** supports fuzzy match of channel names or descriptions, which helps quickly filter desired channels.
  * *   **PageNo** and **PageSize** can help control the paging of returned results to facilitate batch processing of data.
  * *   **SortBy** allows you to customize how the results are sorted. By default, the results are sorted in descending order.
  * **RequestId** in the response is used for subsequent troubleshooting. **TotalCount** indicates the total number of channels that meet the conditions.
  * @param request  the request parameters of ListLivePackageChannels  ListLivePackageChannelsRequest
  * @return ListLivePackageChannelsResponse
 */
async function listLivePackageChannels(request: ListLivePackageChannelsRequest): ListLivePackageChannelsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLivePackageChannels', 'POST', '/', 'json', false, 'json', request);
}

model ListLivePackageOriginEndpointsRequest {
  channelName: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1', position='Query'),
  groupName: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1', position='Query'),
  keyword?: string(name='Keyword', description='The endpoint name or description. Fuzzy match is supported.', example='endpoint-', position='Query'),
  pageNo?: long(name='PageNo', description='The page number.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sort order by creation time. Valid values: asc and desc (default).', example='desc', position='Query'),
}

model ListLivePackageOriginEndpointsResponseBody = {
  livePackageOriginEndpoints?: [ 
    {
      authorizationCode?: string(name='AuthorizationCode', description='The authorization code.', example='Abc123Def456'),
      channelName?: string(name='ChannelName', description='The channel name.', example='channel-1'),
      createTime?: string(name='CreateTime', description='The time when the endpoint was created.', example='2023-04-01T12:00:00Z'),
      description?: string(name='Description', description='The endpoint description.'),
      endpointName?: string(name='EndpointName', description='The endpoint name.', example='endpoint-1'),
      endpointUrl?: string(name='EndpointUrl', description='The endpoint URL.', example='https://xxx.packagepull-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest.m3u8'),
      groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
      ipBlacklist?: string(name='IpBlacklist', description='The IP address blacklist.', example='10.21.222.1/32,192.168.100.0/24'),
      ipWhitelist?: string(name='IpWhitelist', description='The IP address whitelist.', example='192.168.1.0/24,10.0.0.1/24'),
      lastModified?: string(name='LastModified', description='The time when the endpoint was last modified.', example='2023-04-01T12:00:00Z'),
      manifestName?: string(name='ManifestName', description='The playlist name.', example='manifest'),
      protocol?: string(name='Protocol', description='The distribution protocol.', example='HLS'),
      timeshiftVision?: int32(name='TimeshiftVision', description='The number of days that time-shifted content is available.', example='1'),
    }
  ](name='LivePackageOriginEndpoints', description='The origin endpoints returned.'),
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='b9f90a7ac8904db28dc18e0c2a72c75d'),
  sortBy?: string(name='SortBy', description='The sort order. Valid values: `asc` and `desc` (default).', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='10'),
}

model ListLivePackageOriginEndpointsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLivePackageOriginEndpointsResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * This API operation allows you to query origin endpoints associated with a live package channel. The results include detailed configurations about the origin endpoints, such as access URL, protocol, and security policies. Paging and sorting by creation time are supported.
  * @param request  the request parameters of ListLivePackageOriginEndpoints  ListLivePackageOriginEndpointsRequest
  * @return ListLivePackageOriginEndpointsResponse
 */
async function listLivePackageOriginEndpoints(request: ListLivePackageOriginEndpointsRequest): ListLivePackageOriginEndpointsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLivePackageOriginEndpoints', 'POST', '/', 'json', false, 'json', request);
}

model ListLiveRecordFilesRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. The maximum time range to query is four days. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-12-22T08:00:00Z', position='Query'),
  jobIds?: [ string ](name='JobIds', description='The list of job IDs.', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number of the page to return. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 5 to 30. Default value: 10.', example='10', position='Query'),
  recordFormat?: string(name='RecordFormat', description='The format of the recording file. Valid values:

M3U8, FLV, and MP4', example='m3u8', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order of the index files by creation time. Valid values:

asc: The query results are displayed in ascending order. This is the default value.

desc: The query results are displayed in descending order.', example='asc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-12-21T08:00:01Z', position='Query'),
}

model ListLiveRecordFilesResponseBody = {
  files?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the file was created in UTC.', example='2016-05-27T09:40:56Z'),
      duration?: float(name='Duration', description='The recording length. Unit: seconds.', example='100.0'),
      endTime?: string(name='EndTime', description='The end of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2015-12-01T07:36:10Z'),
      format?: string(name='Format', description='The format of the recording file.', example='m3u8'),
      height?: int32(name='Height', description='The height of the video.', example='640'),
      jobId?: string(name='JobId', description='The ID of the recording job.', example='c4d7f0a4-b506-43f9-8de3-07732c3f****'),
      jobName?: string(name='JobName', description='The name of the recording job.', example='LiveRecordJob***'),
      recordId?: string(name='RecordId', description='The ID of the index file.', example='c4d7f0a4-b506-43f9-8de3-07732c3f****'),
      recordOutput?: string(name='RecordOutput', description='The storage information about the recording file.', example='{ "Type": "oss", "Endpoint":"oss-cn-shanghai.aliyuncs.com", "Bucket": "test-bucket" }'),
      recordUrl?: string(name='RecordUrl', description='The URL of the index file.'),
      startTime?: string(name='StartTime', description='The beginning of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2015-12-01T07:36:00Z'),
      streamUrl?: string(name='StreamUrl', description='The name of the live stream.', example='LiveStream***'),
      width?: int32(name='Width', description='The width of the video.', example='480'),
    }
  ](name='Files', description='The list of index files.'),
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='DE24625C-7C0F-4020-8448-****'),
  sortBy?: string(name='SortBy', description='The sorting order of the index files by creation time.', example='asc'),
  totalCount?: string(name='TotalCount', description='The total number of files that meet the specified conditions.', example='100'),
}

model ListLiveRecordFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveRecordFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveRecordFiles  ListLiveRecordFilesRequest
  * @return ListLiveRecordFilesResponse
 */
async function listLiveRecordFiles(request: ListLiveRecordFilesRequest): ListLiveRecordFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveRecordFiles', 'GET', '/', 'json', false, 'json', request);
}

model ListLiveRecordJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. The maximum time range between EndTime and StartTime cannot exceed 30 days. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-11T08:00:00Z', position='Query'),
  keyword?: string(name='Keyword', description='The search keyword. You can use the job ID or name as the keyword to search for jobs.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='20', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results in ascending order.
*   desc: sorts the query results in descending order.', example='desc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-15T08:00:00Z', position='Query'),
  status?: string(name='Status', description='The state of the job. By default, the state is not filtered.

Valid values:

*   paused: The job is paused.
*   initial: The job is not started.
*   started: The job is in progress.', example='started', position='Query'),
}

model ListLiveRecordJobsResponseBody = {
  liveRecordJobs?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
      jobId?: string(name='JobId', description='The ID of the recording job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
      name?: string(name='Name', description='The name of the recording job.'),
      notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify'),
      recordOutput?: {
        bucket?: string(name='Bucket', description='The bucket name.', example='imsbucket1'),
        endpoint?: string(name='Endpoint', description='The endpoint of the storage service.', example='oss-cn-hangzhou.aliyuncs.com'),
        type?: string(name='Type', description='The type of the storage address.

Valid values:

*   vod
*   oss', example='oss'),
      }(name='RecordOutput', description='The storage address of the recording.'),
      status?: string(name='Status', description='The state of the recording job.', example='paused'),
      streamInput?: {
        type?: string(name='Type', description='The type of the live stream URL.', example='rtmp'),
        url?: string(name='Url', description='The URL of the live stream.', example='rtmp://example-live.com/live/stream1'),
      }(name='StreamInput', description='The URL of the live stream.'),
      templateId?: string(name='TemplateId', description='The ID of the recording template.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
      templateName?: string(name='TemplateName', description='The name of the recording template.', example='test template'),
    }
  ](name='LiveRecordJobs', description='The list of live stream recording jobs.'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='20'),
  requestId?: string(name='RequestId', description='The request ID.', example='A27DFFA4-F272-5563-8363-CB0BC42740BA'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='180'),
}

model ListLiveRecordJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveRecordJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveRecordJobs  ListLiveRecordJobsRequest
  * @return ListLiveRecordJobsResponse
 */
async function listLiveRecordJobs(request: ListLiveRecordJobsRequest): ListLiveRecordJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveRecordJobs', 'GET', '/', 'json', false, 'json', request);
}

model ListLiveRecordTemplatesRequest {
  keyword?: string(name='Keyword', description='The search keyword. You can use the template ID or name as the keyword to search for templates. If you search for templates by name, fuzzy match is supported.', example='test template', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Minimum value: 1. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results in ascending order.
*   desc: sorts the query results in descending order.', example='desc', position='Query'),
  templateIds?: [ string ](name='TemplateIds', position='Query'),
  type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom', position='Query'),
}

model ListLiveRecordTemplatesResponseBody = {
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
  recordTemplateList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T02:48:58Z'),
      lastModified?: string(name='LastModified', description='The time when the template was last modified.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
      name?: string(name='Name', description='The template name.', example='test template'),
      recordFormatList?: [ 
        {
          cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds.', example='21600'),
          format?: string(name='Format', description='The output file format.', example='m3u8'),
          ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording file that is stored in Object Storage Service (OSS).', example='record/{JobId}/{Sequence}_{EscapedStartTime}_{EscapedEndTime}'),
          sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds.', example='30'),
          sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
        }
      ](name='RecordFormatList', description='The list of recording formats.'),
      templateId?: string(name='TemplateId', description='The template ID.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
      type?: string(name='Type', description='The type of the template.', example='custom'),
    }
  ](name='RecordTemplateList', description='The list of recording templates.'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results in ascending order.
*   desc: sorts the query results in descending order.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='5'),
}

model ListLiveRecordTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveRecordTemplatesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveRecordTemplates  ListLiveRecordTemplatesRequest
  * @return ListLiveRecordTemplatesResponse
 */
async function listLiveRecordTemplates(request: ListLiveRecordTemplatesRequest): ListLiveRecordTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveRecordTemplates', 'GET', '/', 'json', false, 'json', request);
}

model ListLiveSnapshotFilesRequest {
  endTime: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

*   The maximum time range that can be specified is one day.

This parameter is required.', example='2022-02-02T23:59:59Z', position='Query'),
  jobId: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Query'),
  limit?: int32(name='Limit', description='The number of results to return each time. Valid values: 1 to 100. Default value: 10.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. Default value: asc.

Valid values:

*   asc: sorts the query results by creation time in ascending order.
*   desc: sorts the query results by creation time in descending order.', example='desc', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

This parameter is required.', example='2022-02-02T00:00:00Z', position='Query'),
}

model ListLiveSnapshotFilesResponseBody = {
  fileList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-02-02T22:22:22Z'),
      createTimestamp?: long(name='CreateTimestamp', description='The creation timestamp that is used as an input parameter for a delete API operation.', example='1619503516000'),
      isOverlay?: boolean(name='IsOverlay', description='Specifies whether to overlay snapshots.', example='true'),
      ossBucket?: string(name='OssBucket', description='The OSS bucket.', example='testbucket'),
      ossEndpoint?: string(name='OssEndpoint', description='The Object Storage Service (OSS) domain name.', example='oss-cn-shanghai.aliyuncs.com'),
      ossObject?: string(name='OssObject', description='The location in which the OSS object is stored.'),
    }
  ](name='FileList', description='The list of files.'),
  nextStartTime?: string(name='NextStartTime', description='The start time of the next page. If no value is returned, the pagination ends.', example='2022-02-02T22:22:22Z'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListLiveSnapshotFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveSnapshotFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveSnapshotFiles  ListLiveSnapshotFilesRequest
  * @return ListLiveSnapshotFilesResponse
 */
async function listLiveSnapshotFiles(request: ListLiveSnapshotFilesRequest): ListLiveSnapshotFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveSnapshotFiles', 'GET', '/', 'json', false, 'json', request);
}

model ListLiveSnapshotJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

*   By default, EndTime is seven days later than StartTime.
*   The time range specified by the StartTime and EndTime parameters cannot exceed 30 days.', example='2022-02-02T23:59:59Z', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Valid values: [1,n). Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10', position='Query'),
  searchKeyWord?: string(name='SearchKeyWord', description='The search keyword. You can use the job ID or name as the keyword to search for jobs. If you search for jobs by name, fuzzy match is supported.

*   It cannot exceed 128 characters in length.', example='****a046-263c-3560-978a-fb287782****', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results by creation time in ascending order.
*   desc: sorts the query results by creation time in descending order.', example='desc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

*   The default value is seven days ago.
*   The time range specified by the StartTime and EndTime parameters cannot exceed 30 days.', example='2022-02-02T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The job state filter. By default, all jobs are queried.

Valid values:

*   init: The job is not started.
*   paused: The job is paused.
*   started: The job is in progress.', position='Query'),
}

model ListLiveSnapshotJobsResponseBody = {
  jobList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-20T02:48:58Z'),
      jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287782****'),
      jobName?: string(name='JobName', description='The name of the job.'),
      snapshotOutput?: {
        bucket?: string(name='Bucket', description='The bucket of the output endpoint. If the storage type is set to oss, the OSS bucket is returned.', example='testbucket'),
        endpoint?: string(name='Endpoint', description='The output endpoint. If the storage type is set to oss, the Object Storage Service (OSS) domain name is returned.', example='oss-cn-shanghai.aliyuncs.com'),
        storageType?: string(name='StorageType', description='The storage type. The value can only be oss.', example='oss'),
      }(name='SnapshotOutput', description='The output information.'),
      status?: string(name='Status', description='The state of the job.

Valid values:

*   init: The job is not started.
*   paused: The job is paused.
*   started: The job is in progress.', example='started'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287666****'),
      templateName?: string(name='TemplateName', description='The template name.'),
      timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.', example='5'),
    }
  ](name='JobList', description='The list of jobs.'),
  pageNo?: int32(name='PageNo', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the jobs by creation time.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveSnapshotJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveSnapshotJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveSnapshotJobs  ListLiveSnapshotJobsRequest
  * @return ListLiveSnapshotJobsResponse
 */
async function listLiveSnapshotJobs(request: ListLiveSnapshotJobsRequest): ListLiveSnapshotJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveSnapshotJobs', 'GET', '/', 'json', false, 'json', request);
}

model ListLiveSnapshotTemplatesRequest {
  pageNo?: int32(name='PageNo', description='The page number. Valid values: [1,n). Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10', position='Query'),
  searchKeyWord?: string(name='SearchKeyWord', description='The search keyword. You can use the template ID or name as the keyword to search for templates. If you search for templates by name, fuzzy match is supported.

*   It cannot exceed 128 characters in length.', example='****a046-263c-3560-978a-fb287782****', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results by creation time in ascending order.
*   desc: sorts the query results by creation time in descending order.', example='desc', position='Query'),
  templateIds?: [ string ](name='TemplateIds', description='The template IDs.

*   If you specify the SearchKeyWord parameter, this condition does not take effect.
*   The maximum length of the array is 200.', position='Query'),
  type?: string(name='Type', description='The type of the template. By default, all types are queried.

Valid values:

*   system
*   custom', example='custom', position='Query'),
}

model ListLiveSnapshotTemplatesResponseBody = {
  pageNo?: int32(name='PageNo', description='The number of the returned page.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the results by creation time.', example='desc'),
  templateList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T02:48:58Z'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287782****'),
      templateName?: string(name='TemplateName', description='The template name.'),
      timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.', example='10'),
      type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
    }
  ](name='TemplateList', description='The list of the templates.'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveSnapshotTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveSnapshotTemplatesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveSnapshotTemplates  ListLiveSnapshotTemplatesRequest
  * @return ListLiveSnapshotTemplatesResponse
 */
async function listLiveSnapshotTemplates(request: ListLiveSnapshotTemplatesRequest): ListLiveSnapshotTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveSnapshotTemplates', 'GET', '/', 'json', false, 'json', request);
}

model ListLiveTranscodeJobsRequest {
  keyWord?: string(name='KeyWord', description='The search keyword. You can use the job ID or name as the keyword to search for jobs. If you search for jobs by name, fuzzy match is supported.', example='24ecbb5c-4f98-4194-9400-f17102e27fc5', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='20', minimum=1, position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values:

*   asc
*   desc', example='asc', position='Query'),
  startMode?: int32(name='StartMode', description='The start mode of the transcoding job.

*   0: The transcoding job immediately starts.
*   1: The transcoding job starts at the scheduled time.', example='0', position='Query'),
  status?: int32(name='Status', description='The state of the job.

0: The job is not started. 1: The job is in progress. 2: The job is stopped.', example='1', position='Query'),
  type?: string(name='Type', description='The type of the template used by the transcoding job.

*   normal
*   narrow-band
*   audio-only
*   origin', example='normal', position='Query'),
}

model ListLiveTranscodeJobsResponseBody = {
  jobList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T02:48:58Z'),
      jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287782****'),
      name?: string(name='Name', description='The name of the transcoding job.', example='mytask'),
      outputStream?: {
        streamInfos?: [ 
          {
            outputUrl?: string(name='OutputUrl', description='The URL of the output stream.', example='rtmp://mydomain/app/mytranscode1'),
            type?: string(name='Type', description='The type of the output stream protocol. Only the RTMP protocol is supported.', example='rtmp'),
          }
        ](name='StreamInfos', description='The list of stream URLs.'),
      }(name='OutputStream', description='The information about the output stream.'),
      startMode?: int32(name='StartMode', description='The start mode of the job.', example='0'),
      status?: int32(name='Status', description='The state of the job.', example='1'),
      streamInput?: {
        inputUrl?: string(name='InputUrl', description='The URL of the input stream.', example='rtmp://mydomain/app/stream1'),
        type?: string(name='Type', description='The type of the input stream.', example='rtmp'),
      }(name='StreamInput', description='The information about the input stream.'),
      templateId?: string(name='TemplateId', description='The ID of the transcoding template used by the transcoding job.', example='****a046-263c-3560-978a-fb287666****'),
      templateName?: string(name='TemplateName', description='The template name.'),
      templateType?: string(name='TemplateType', description='The type of the transcoding template used by the transcoding job.', example='normal'),
    }
  ](name='JobList', description='The list of transcoding jobs.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveTranscodeJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveTranscodeJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveTranscodeJobs  ListLiveTranscodeJobsRequest
  * @return ListLiveTranscodeJobsResponse
 */
async function listLiveTranscodeJobs(request: ListLiveTranscodeJobsRequest): ListLiveTranscodeJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveTranscodeJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListLiveTranscodeTemplatesRequest {
  category?: string(name='Category', description='The category of the template. Valid values:

*   system
*   customized', example='customized', position='Query'),
  keyWord?: string(name='KeyWord', description='The search keyword. You can use the template ID or name as the keyword to search for templates. If you search for templates by name, fuzzy match is supported.', example='my_template', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number of the page to return. Default value: 1.', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='20', minimum=1, position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values:

*   asc
*   desc', example='asc', position='Query'),
  type?: string(name='Type', description='The type of the template. Valid values:

*   normal
*   narrow-band
*   audio-only
*   origin', example='normal', position='Query'),
  videoCodec?: string(name='VideoCodec', description='The video codec. Valid values:

*   H.264
*   H.265', example='H.264', position='Query'),
}

model ListLiveTranscodeTemplatesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  templateContentList?: [ 
    {
      category?: string(name='Category', description='The category of the template. Valid values:', example='system'),
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T03:26:36Z'),
      name?: string(name='Name', description='The template name.', example='my_template'),
      templateConfig?: {
        audioParams?: {
          bitrate?: string(name='Bitrate', description='The audio bitrate.', example='1000'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codec?: string(name='Codec', description='The audio codec.', example='AAC'),
          profile?: string(name='Profile', description='The encoding profile.', example='aac_low'),
          samplerate?: string(name='Samplerate', description='The audio sampling rate.', example='44100'),
        }(name='AudioParams', description='The audio parameters.'),
        videoParams?: {
          bitrate?: string(name='Bitrate', description='The video bitrate.', example='2500'),
          codec?: string(name='Codec', description='The encoding format.', example='264'),
          fps?: string(name='Fps', description='The video frame rate.', example='30'),
          gop?: string(name='Gop', description='The group of pictures (GOP) of the output video. Unit: frame.', example='1000'),
          height?: string(name='Height', description='The vertical resolution of the video.', example='1280'),
          profile?: string(name='Profile', description='The encoding profile.', example='3'),
          width?: string(name='Width', description='The horizontal resolution of the video.', example='720'),
        }(name='VideoParams', description='The video parameters.'),
      }(name='TemplateConfig', description='The configuration of the template.'),
      templateId?: string(name='TemplateId', description='The template ID.', example='9b1571b513cb44f7a1ba6ae561ff46f7'),
      type?: string(name='Type', description='The type of the template.', example='normal'),
    }
  ](name='TemplateContentList', description='The list of transcoding templates.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveTranscodeTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveTranscodeTemplatesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLiveTranscodeTemplates  ListLiveTranscodeTemplatesRequest
  * @return ListLiveTranscodeTemplatesResponse
 */
async function listLiveTranscodeTemplates(request: ListLiveTranscodeTemplatesRequest): ListLiveTranscodeTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLiveTranscodeTemplates', 'POST', '/', 'json', false, 'json', request);
}

model ListMediaBasicInfosRequest {
  regionId?: string(name='RegionId', position='Host'),
  authTimeout?: long(name='AuthTimeout', position='Query'),
  businessType?: string(name='BusinessType', description='The business type of the media asset. Valid values:

\\- subtitles

\\- watermark

\\- opening

\\- ending

\\- general', example='opening', position='Query'),
  endTime?: string(name='EndTime', description='The end time of utcCreated.

\\- The value is the end of the left-open right-closed interval.

\\- Specify the time in the ISO 8601 standard in the YYYY-MM-DDThh:mm:ssZ format. For example, 2017-01-11T12:00:00Z indicates 20:00:00 on January 11, 2017 (UTC +8).', example='2020-12-20T13:00:00Z', position='Query'),
  includeFileBasicInfo?: boolean(name='IncludeFileBasicInfo', description='Specifies whether to return the basic information of the source file.', example='true', position='Query'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.

Maximum value: 100. Default value: 10.', example='5', minimum=1, maximum=100, position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****', position='Query'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

\\- image

\\- video

\\- audio

\\- text', example='video', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='pSa1SQ0wCe5pzVrQ6mWZEw==', position='Query'),
  sortBy?: string(name='SortBy', description='The order of sorting by utcCreated. Default value: desc. Valid values:

\\- desc

\\- asc', example='desc', position='Query'),
  source?: string(name='Source', description='The source of the media asset. Valid values:

\\- oss: Object Storage Service (OSS).

\\- vod: ApsaraVideo VOD.

\\- live: ApsaraVideo Live.

\\- general: other sources. This is the default value.', example='oss', position='Query'),
  startTime?: string(name='StartTime', description='The start time of utcCreated.

\\- The value is the beginning of a left-open right-closed interval.

\\- Specify the time in the ISO 8601 standard in the YYYY-MM-DDThh:mm:ssZ format. For example, 2017-01-11T12:00:00Z indicates 20:00:00 on January 11, 2017 (UTC +8).', example='2020-12-20T12:00:00Z', position='Query'),
  status?: string(name='Status', description='The status of the media asset. Valid values:

\\- Init: the initial state, which indicates that the source file is not ready.

\\- Preparing: The source file is being prepared. For example, the file is being uploaded or edited.

\\- PrepareFail: The source file failed to be prepared. For example, the information of the source file failed to be obtained.

\\- Normal: The source file is ready.', example='Normal', position='Query'),
}

model ListMediaBasicInfosResponseBody = {
  maxResults?: int32(name='MaxResults', description='The maximum number of entries returned in the query.', example='2'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1912.13'),
            createTime?: string(name='CreateTime', description='The time when the file was created.', example='2021-01-08T16:52:04Z'),
            duration?: string(name='Duration', description='The duration.', example='60.00000'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='14340962'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The OSS URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example2.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='720'),
            modifiedTime?: string(name='ModifiedTime', description='The time when the file was last modified.', example='2021-01-08T16:52:07Z'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='1280'),
          }(name='FileBasicInfo', description='The basic information of the file, including the duration and size.'),
        }
      ](name='FileInfoList', description='FileInfos'),
      mediaBasicInfo?: {
        biz?: string(name='Biz', description='The service to which the media asset belongs.', example='ICE'),
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='opening'),
        cateId?: long(name='CateId', description='The category ID.', example='3049'),
        category?: string(name='Category', description='The category of the media asset.'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2021-01-08T16:52:04Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2021-01-08T16:52:07Z'),
        description?: string(name='Description', description='The description of the media asset.'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='tags,tags2'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2021-01-08T16:52:07Z'),
        referenceId?: string(name='ReferenceId', description='The custom ID of the media asset. The ID is a string that contains 6 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are supported. The ID is unique among users.', example='123-123'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='[{"bucket":"example-bucket","count":"3","iceJobId":"******f48f0e4154976b2b8c45******","location":"oss-cn-beijing","snapshotRegular":"example.jpg","templateId":"******e6a6440b29eb60bd7c******"}]'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite.', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        uploadSource?: string(name='UploadSource', description='The upload source of the media asset.', example='general'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='BasicInfo'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******B7-7F87-4792-BFE9-63CD21******'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='4'),
}

model ListMediaBasicInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaBasicInfosResponseBody(name='body'),
}

/**
  * @description If includeFileBasicInfo is set to true, the basic information, such as the duration and file size, of the source file is also returned. At most the first 100 entries that meet the specified conditions are returned. All media assets must exactly match all non-empty fields. The fields that support exact match include MediaType, Source, BusinessType, Category, and Status. If all information cannot be returned at a time, you can use NextToken to initiate a request to retrieve a new page of results.
  * @param request  the request parameters of ListMediaBasicInfos  ListMediaBasicInfosRequest
  * @return ListMediaBasicInfosResponse
 */
async function listMediaBasicInfos(request: ListMediaBasicInfosRequest): ListMediaBasicInfosResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMediaBasicInfos', 'POST', '/', 'json', false, 'json', request);
}

model ListMediaConvertJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-15T00:00:00Z', position='Query'),
  jobId?: string(name='JobId', description='The task ID.', example='88c6ca184c0e47098a5b665e2****', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='ab4802364a2e49208c99efab82dfa8e8', position='Query'),
  orderBy?: string(name='OrderBy', description='The sorting order. Valid values: CreateTimeDesc: sorts by create time in descending order. CreateTimeAsc: sorts by create time in ascending order.', example='CreateTimeDesc', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 0 to 100. Default value: 20.', example='10', position='Query'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-01T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The task status.

*   Inited: submitted
*   Running
*   Complete
*   Error', example='Success', position='Query'),
}

model ListMediaConvertJobsResponseBody = {
  jobs?: [
    MediaConvertJobWithoutDetail
  ](name='Jobs', description='The tasks.'),
  nextPageToken: string(name='NextPageToken', description='Indicates the read position returned by the current call. An empty value means all data has been read.

This parameter is required.', example='****cdb3e74639973036bc84****'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListMediaConvertJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaConvertJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListMediaConvertJobs  ListMediaConvertJobsRequest
  * @return ListMediaConvertJobsResponse
 */
async function listMediaConvertJobs(request: ListMediaConvertJobsRequest): ListMediaConvertJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMediaConvertJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListMediaInfoJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-15T00:00:00Z', position='Query'),
  jobId?: string(name='JobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb11cbe', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='ab4802364a2e49208c99efab82dfa8e8', position='Query'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

*   CreateTimeDesc: sorts the query results by creation time in descending order.
*   CreateTimeAsc: sorts the query results by creation time in ascending order.', example='CreateTimeDesc', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-01T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The state of the job. Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success', position='Query'),
}

model ListMediaInfoJobsResponseBody = {
  jobs?: [ 
    {
      async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      input?: {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
      }(name='Input', description='The input of the job.'),
      jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
      mediaInfoProperty?: {
        audioStreamInfoList?: [ 
          {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
            channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
            channels?: string(name='Channels', description='The number of sound channels.', example='2'),
            codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
            codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
            codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
            codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
            duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
            index?: string(name='Index', description='The sequence number of the stream.', example='1'),
            lang?: string(name='Lang', description='The language of the stream.', example='cn'),
            sampleFmt?: string(name='SampleFmt', description='The sampling format.', example='fltp'),
            sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
            startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
            timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
          }
        ](name='AudioStreamInfoList', description='The information about the audio stream.'),
        fileBasicInfo?: {
          bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
          duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
          fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
          fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
          fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
          fileType?: string(name='FileType', description='The file type. Valid values: source_file and transcode_file.', example='source_file'),
          fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
          formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
          height?: string(name='Height', description='The height.', example='478'),
          mediaId?: string(name='MediaId', description='The ID of the media asset.', example='4765337007f571edbfdf81848c016303'),
          region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
          width?: string(name='Width', description='The width.', example='848'),
        }(name='FileBasicInfo', description='The basic file information.'),
        videoStreamInfoList?: [ 
          {
            avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
            bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
            codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
            codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
            codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
            codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
            codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
            dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
            duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
            fps?: string(name='Fps', description='The frame rate.', example='25.0'),
            hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
            height?: string(name='Height', description='The height.', example='478'),
            index?: string(name='Index', description='The sequence number of the stream.', example='0'),
            lang?: string(name='Lang', description='The language of the stream.', example='cn'),
            level?: string(name='Level', description='The codec level.', example='31'),
            numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
            pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
            profile?: string(name='Profile', description='The encoder profile.', example='High'),
            rotate?: string(name='Rotate', description='The rotation angle of the video image.

*   Valid values: 0, 90, 180, and 270.
*   Default value: 0.', example='0'),
            sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
            startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
            timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
            width?: string(name='Width', description='The width.', example='848'),
          }
        ](name='VideoStreamInfoList', description='The information about the video stream.'),
      }(name='MediaInfoProperty', description='The details of the media information.'),
      name?: string(name='Name', description='The job name.', example='job-name'),
      requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
      scheduleConfig?: {
        pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
        priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
      }(name='ScheduleConfig', description='The scheduling information.'),
      status?: string(name='Status', description='The state of the job. Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Init'),
      submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
      userData?: string(name='UserData', description='The user data.', example='user-data'),
    }
  ](name='Jobs', description='The list of media information analysis jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. The token of the next page is returned after you call this operation for the first time.', example='019daf5780f74831b0e1a767c9f1c178'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model ListMediaInfoJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaInfoJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListMediaInfoJobs  ListMediaInfoJobsRequest
  * @return ListMediaInfoJobsResponse
 */
async function listMediaInfoJobs(request: ListMediaInfoJobsRequest): ListMediaInfoJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMediaInfoJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListMediaLiveChannelsRequest {
  keyword?: string(name='Keyword', description='The keyword of the query. You can perform a fuzzy search on channel ID or name.', example='123', position='Body'),
  maxResults?: int32(name='MaxResults', description='The number of entries per page. Valid values: 1 to 100. Default value:

*   If you do not specify this parameter or if you set a value smaller than 10, the default value is 10.
*   If you set a value greater than 100, the default value is 100.', example='10', position='Body'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='caeba0bbb2be03f84eb48b699f0a4883', position='Body'),
  skip?: int32(name='Skip', description='The number of entries to be skipped in the query. If the number of entries you attempt to skip exceeds the number of entries that meet the condition, an empty list is returned.', example='20', position='Body'),
  sortOrder?: string(name='SortOrder', description='The sorting order of the channels by creation time. Default value: asc. Valid values: desc and asc. asc indicates the ascending order, and desc indicates the descending order.', example='desc', position='Body'),
  states?: string(name='States', description='The state of channels you want to query. You can separate multiple states with commas (,) in a JSON array.', example='["IDLE","RUNNING"]', position='Body'),
}

model ListMediaLiveChannelsResponseBody = {
  channels?: [ 
    {
      audioSettings?: [ 
        {
          audioCodec?: string(name='AudioCodec', description='The audio codec.', example='aac'),
          audioCodecSetting?: {
            bitrate?: int32(name='Bitrate', description='The audio bitrate. Unit: bit/s.', example='200000'),
            profile?: string(name='Profile', description='The audio codec profile.', example='AAC-LOW'),
            sampleRate?: int32(name='SampleRate', description='The audio sample rate. Unit: Hz.', example='44100'),
          }(name='AudioCodecSetting', description='The audio encoding settings.'),
          audioSelectorName?: string(name='AudioSelectorName', description='The name of the audio selector.', example='myselector'),
          languageCode?: string(name='LanguageCode', description='A three-letter ISO 639-2 language code.', example='eng'),
          languageName?: string(name='LanguageName', description='The name of the language.', example='English'),
          name?: string(name='Name', description='The name of the audio settings.', example='zhuanfengzhuang'),
        }
      ](name='AudioSettings', description='The audio settings.'),
      channelId?: string(name='ChannelId', description='The ID of the channel.', example='SEGK5KA6KYKAWQQH'),
      createTime?: string(name='CreateTime', description='The time when the channel was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-12-03T06:56:42Z'),
      inputAttachments?: [ 
        {
          audioSelectors?: [ 
            {
              audioLanguageSelection?: {
                languageCode: string(name='LanguageCode', description='A three-letter ISO 639-2 language code from within an audio source.

This parameter is required.', example='eng'),
              }(name='AudioLanguageSelection', description='The audio language selection.'),
              audioPidSelection?: {
                pid: long(name='Pid', description='A PID from within a source.

This parameter is required.', example='123'),
              }(name='AudioPidSelection', description='The audio PID selection.'),
              audioTrackSelection?: [ 
                {
                  trackId: long(name='TrackId', description='The track ID from within a source.

This parameter is required.', example='1'),
                }
              ](name='AudioTrackSelection', description='The audio track selection.'),
              name: string(name='Name', description='The name of the audio selector.

This parameter is required.', example='myselector'),
            }
          ](name='AudioSelectors', description='The audio selectors.'),
          inputId: string(name='InputId', description='The ID of the input.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
          inputName?: string(name='InputName', description='The name of the input.', example='myinput'),
          languageName?: string(name='LanguageName', description='The name of the language.', example='eng'),
        }
      ](name='InputAttachments', description='The inputs associated with the channel.'),
      lastStartTime?: string(name='LastStartTime', description='The time when the channel was last started. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC. If the channel has never been started since it was created, an empty string is returned.', example='2024-12-03T06:56:42Z'),
      lastStopTime?: string(name='LastStopTime', description='The time when the channel was last stopped. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC. If the channel has never stopped since it was created, an empty string is returned.', example='2024-12-03T06:56:42Z'),
      name?: string(name='Name', description='The name of the channel.', example='mych'),
      outputGroups?: [ 
        {
          mediaPackageGroupSetting?: {
            channelName?: string(name='ChannelName', description='ChannelName in MediaPackage.', example='myPackageChannel'),
            groupName?: string(name='GroupName', description='GroupName in MediaPackage.', example='myPackageGroup'),
          }(name='MediaPackageGroupSetting', description='The MediaPackage destination.'),
          monitorUrl?: string(name='MonitorUrl', description='The URL for monitoring the output group. The parameter is returned only when the output gourp type is MediaPackage.', example='rtmp://xxx'),
          name?: string(name='Name', description='The name of the output group.', example='group1'),
          outputs?: [ 
            {
              audioSettingNames?: [ string ](name='AudioSettingNames', description='The referenced AudioSettings.'),
              mediaPackageOutputSetting?: {
                audioGroupId?: string(name='AudioGroupId', description='The manifest audio group ID.', example='audiogroup'),
                nameModifier?: string(name='NameModifier', description='The manifest name modifier. The child manifests include this modifier in their M3U8 file names.', example='480p'),
              }(name='MediaPackageOutputSetting', description='The settings of the output delivered to MediaPackage.'),
              mediaType?: int32(name='MediaType', description='The media type of the output.', example='0'),
              name?: string(name='Name', description='The name of the output.', example='output1'),
              videoSettingName?: string(name='VideoSettingName', description='The name of the referenced VideoSettings.', example='myVideo1'),
            }
          ](name='Outputs', description='The outputs in the output group.'),
          type?: string(name='Type', description='The output group type.', example='MediaPackage'),
        }
      ](name='OutputGroups', description='The output groups.'),
      state?: string(name='State', description='The state of the channel. Valid values: IDLE, STARTING, RUNNING, RECOVERING, and STOPPING.', example='IDLE'),
      videoSettings?: [ 
        {
          height?: int32(name='Height', description='The height of the video in pixels.', example='720'),
          name?: string(name='Name', description='The name of the video settings.', example='video1'),
          videoCodec?: string(name='VideoCodec', description='The video codec.', example='H264'),
          videoCodecSetting?: {
            codecDetail?: {
              level?: string(name='Level', description='The video encoding level. It is not supported yet.', example='H264_LEVEL_AUTO'),
              profile?: string(name='Profile', description='The H.264 profile.', example='MAIN'),
            }(name='CodecDetail', description='The video encoding settings.'),
            framerate?: {
              framerateControl?: string(name='FramerateControl', description='The frame rate mode.', example='SPECIFIED'),
              framerateDenominator?: int32(name='FramerateDenominator', description='The denominator of the fixed frame rate.', example='1'),
              framerateNumerator?: int32(name='FramerateNumerator', description='The numerator of the fixed frame rate.', example='25'),
            }(name='Framerate', description='The frame rate.'),
            gop?: {
              bframesNum?: int32(name='BframesNum', description='The number of B frames.', example='3'),
              gopSize?: int32(name='GopSize', description='The GOP size.', example='90'),
              gopSizeUnits?: string(name='GopSizeUnits', description='The GOP size unit.', example='FRAMES'),
            }(name='Gop', description='The GOP setting.'),
            rate?: {
              bitrate?: int32(name='Bitrate', description='The video bitrate. Unit: bit/s.', example='2500000'),
              bufferSize?: int32(name='BufferSize', description='The video buffer size. Unit: bit/s.', example='6000000'),
              maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s.', example='6000000'),
              rateControlMode?: string(name='RateControlMode', description='The bitrate control mode.', example='ABR'),
            }(name='Rate', description='The video encoding rate.'),
          }(name='VideoCodecSetting', description='The video encoding settings.'),
          videoCodecType?: string(name='VideoCodecType', description='The video transcoding method. Valid values: NORMAL (regular transcoding) and NBHD (Narrowband HD™ transcoding).', example='NORMAL'),
          width?: int32(name='Width', description='The width of the video in pixels.', example='1280'),
        }
      ](name='VideoSettings', description='The video settings.'),
    }
  ](name='Channels', description='The channels.'),
  maxResults?: int32(name='MaxResults', description='The number of entries returned per page.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='caeba0bbb2be03f84eb48b699f0a4883'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListMediaLiveChannelsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaLiveChannelsResponseBody(name='body'),
}

/**
  * @description ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of ListMediaLiveChannels  ListMediaLiveChannelsRequest
  * @return ListMediaLiveChannelsResponse
 */
async function listMediaLiveChannels(request: ListMediaLiveChannelsRequest): ListMediaLiveChannelsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMediaLiveChannels', 'POST', '/', 'json', true, 'form', request);
}

model ListMediaLiveInputSecurityGroupsRequest {
  keyword?: string(name='Keyword', description='The keyword of the query. You can perform a fuzzy search on security group ID or name.', example='123', position='Body'),
  maxResults?: int32(name='MaxResults', description='The number of entries per page. Valid values: 1 to 100. Default value: If you do not specify this parameter or if you set a value smaller than 10, the default value is 10. If you set a value greater than 100, the default value is 100.', example='10', position='Body'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='caeba0bbb2be03f84eb48b699f0a4883', position='Body'),
  skip?: int32(name='Skip', description='The number of entries to be skipped in the query. If the number of entries you attempt to skip exceeds the number of entries that meet the condition, an empty list is returned.', example='20', position='Body'),
  sortOrder?: string(name='SortOrder', description='The sorting order of the security groups by creation time. Default value: asc. Valid values: desc and asc. asc indicates the ascending order, and desc indicates the descending order.', example='desc', position='Body'),
}

model ListMediaLiveInputSecurityGroupsResponseBody = {
  maxResults?: int32(name='MaxResults', description='The number of entries returned per page.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='caeba0bbb2be03f84eb48b699f0a4883'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='123e4567-e89b-12d3-a456-426614174000'),
  securityGroups?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the security group was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-12-03T06:56:42Z'),
      inputIds?: [ string ](name='InputIds', description='The IDs of the inputs associated with the security group.'),
      name?: string(name='Name', description='The security group name.', example='mysg'),
      securityGroupId?: string(name='SecurityGroupId', description='The ID of the security group.', example='SEGK5KA6KYKAWQQH'),
      whitelistRules?: [ string ](name='WhitelistRules', description='The security group rules.'),
    }
  ](name='SecurityGroups', description='The security groups.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListMediaLiveInputSecurityGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaLiveInputSecurityGroupsResponseBody(name='body'),
}

/**
  * @description ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of ListMediaLiveInputSecurityGroups  ListMediaLiveInputSecurityGroupsRequest
  * @return ListMediaLiveInputSecurityGroupsResponse
 */
async function listMediaLiveInputSecurityGroups(request: ListMediaLiveInputSecurityGroupsRequest): ListMediaLiveInputSecurityGroupsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMediaLiveInputSecurityGroups', 'POST', '/', 'json', true, 'form', request);
}

model ListMediaLiveInputsRequest {
  keyword?: string(name='Keyword', description='The keyword of the query. You can perform a fuzzy search on input ID or name.', example='123', position='Body'),
  maxResults?: int32(name='MaxResults', description='The number of entries per page. Valid values: 1 to 100. Default value: If you do not specify this parameter or if you set a value smaller than 10, the default value is 10. If you set a value greater than 100, the default value is 100.', example='10', position='Body'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='caeba0bbb2be03f84eb48b699f0a4883', position='Body'),
  skip?: int32(name='Skip', description='The number of entries to be skipped in the query. If the number of entries you attempt to skip exceeds the number of entries that meet the condition, an empty list is returned.', example='20', position='Body'),
  sortOrder?: string(name='SortOrder', description='The sorting order of the inputs by creation time. Default value: asc. Valid values: desc and asc. asc indicates the ascending order, and desc indicates the descending order.', example='desc', position='Body'),
  types?: string(name='Types', description='The type of inputs you want to query. You can separate multiple input types with commas (,) in a JSON array.', example='["RTMP_PUSH","SRT_PULL"]', position='Body'),
}

model ListMediaLiveInputsResponseBody = {
  inputs?: [ 
    {
      channelIds?: [ string ](name='ChannelIds', description='The IDs of the channels associated with the input.'),
      createTime?: string(name='CreateTime', description='The time when the input was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-12-03T06:56:42Z'),
      inputId?: string(name='InputId', description='The ID of the input.', example='SEGK5KA6KYKAWQQH'),
      inputInfos?: [ 
        {
          destHost?: string(name='DestHost', description='The endpoint that the stream is pushed to. This parameter is returned for PUSH inputs.', example='rtmp://domain/app/stream'),
          flowId?: string(name='FlowId', description='The ID of the flow from MediaConnect.', example='******81-9693-40dc-bbab-db5e49******'),
          flowOutputName?: string(name='FlowOutputName', description='The output name of the MediaConnect flow.', example='myFlowOutputName'),
          monitorUrl?: string(name='MonitorUrl', description='The URL for input monitoring.', example='rtmp://domain/app/stream_for_monitor'),
          sourceUrl?: string(name='SourceUrl', description='The source URL where the stream is pulled from. This parameter is returned for PULL inputs.', example='rtmp://domain/app/stream'),
          srtLatency?: int32(name='SrtLatency'),
          srtMaxBitrate?: int32(name='SrtMaxBitrate'),
          srtPassphrase?: string(name='SrtPassphrase'),
          srtPbKeyLen?: int32(name='SrtPbKeyLen'),
          streamName?: string(name='StreamName', description='The name of the pushed stream. This parameter is returned for PUSH inputs.', example='mystream'),
        }
      ](name='InputInfos', description='The input configurations.'),
      name?: string(name='Name', description='The name of the input.', example='myinput'),
      securityGroupIds?: [ string ](name='SecurityGroupIds', description='The IDs of the security groups associated with the input.'),
      type?: string(name='Type', description='The input type.', example='RTMP_PUSH'),
    }
  ](name='Inputs', description='The inputs.'),
  maxResults?: int32(name='MaxResults', description='The number of entries returned per page.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='caeba0bbb2be03f84eb48b699f0a4883'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='200'),
}

model ListMediaLiveInputsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaLiveInputsResponseBody(name='body'),
}

/**
  * @description ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of ListMediaLiveInputs  ListMediaLiveInputsRequest
  * @return ListMediaLiveInputsResponse
 */
async function listMediaLiveInputs(request: ListMediaLiveInputsRequest): ListMediaLiveInputsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMediaLiveInputs', 'POST', '/', 'json', true, 'form', request);
}

model ListMediaMarksRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***', position='Query'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The mark ID. You can specify multiple IDs separated with commas (,). This parameter is discontinued.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60', position='Query'),
}

model ListMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  mediaMarks?: string(name='MediaMarks', description='The marks of the media asset, in the JSONArray format.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaMarksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListMediaMarks  ListMediaMarksRequest
  * @return ListMediaMarksResponse
 */
async function listMediaMarks(request: ListMediaMarksRequest): ListMediaMarksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMediaMarks', 'POST', '/', 'json', false, 'json', request);
}

model ListMediaProducingJobsRequest {
  regionId?: string(name='RegionId', position='Host'),
  endTime?: string(name='EndTime', description='The end of the time range to query. The maximum time range between EndTime and StartTime cannot exceed 30 days. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-02-02T23:59:59Z', position='Query'),
  jobType?: string(name='JobType', description='The job type.

Valid values:

*   LiveEditingJob: live editing job.
*   EditingJob: regular template-based editing job
*   VETemplateJob: advanced template-based editing job.', example='EditingJob', position='Query'),
  keyword?: string(name='Keyword', description='The search keyword. For example, you can use a job ID as the keyword to search for jobs.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  masterJobId?: string(name='MasterJobId', description='The ID of the quick video production job. If this parameter is specified, the subjobs of the quick video production job are queried.', example='******8750b54e3c976a47da6f******', position='Query'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.

Default value: 10. Valid values: 1 to 100.', example='100', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ==', position='Query'),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='******927cfb53d05b96c1bfe1******', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting parameter. By default, the query results are sorted by creation time in descending order.

Valid values:

*   CreationTime:Asc: sorted by creation time in ascending order.
*   CreationTime:Desc: sorted by creation time in descending order.', example='CreationTime:Desc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-01-11T12:00:00Z', position='Query'),
  status?: string(name='Status', description='The job state.

Valid values:

*   Init: The job is initialized.
*   Failed: The job failed.
*   Success: The job is successful.
*   Processing: The job is in progress.', example='Success', position='Query'),
}

model ListMediaProducingJobsResponseBody = {
  maxResults?: string(name='MaxResults', description='The maximum number of entries returned.

Default value: 10. Valid values: 1 to 100.', example='100'),
  mediaProducingJobList?: [ 
    {
      clipsParam?: string(name='ClipsParam', description='The template material parameters.', example='{"Text1":"text","Text0":"text","Media1":"mediaId","Media0":"mediaId"}'),
      code?: string(name='Code', description='The response code.', example='Success'),
      completeTime?: string(name='CompleteTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-03-21T16:40:30Z'),
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-03-21T16:40:00Z'),
      duration?: float(name='Duration', description='The duration of the output file. Unit: seconds.', example='15.5'),
      jobId?: string(name='JobId', description='The ID of the online editing job.', example='******8750b54e3c976a47da6f******'),
      mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='0ce4ea70f52471edab61f7e7d6786302'),
      mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://your-bucket.oss-cn-shanghai.aliyuncs.com/your-video.mp4'),
      message?: string(name='Message', description='The returned message. Note: Pay attention to this parameter if the job failed.', example='The resource operated InputFile is bad'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-03-21T16:41:00Z'),
      projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='******faa3b542f5a6135217e3******'),
      status?: string(name='Status', description='The job state.', example='Sucess'),
      templateId?: string(name='TemplateId', description='The ID of the online editing template.', example='cb786a39c5d44cecb23d8c864facffc1'),
      userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"key":"value"}'),
    }
  ](name='MediaProducingJobList', description='The queried media editing and production jobs.'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListMediaProducingJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaProducingJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListMediaProducingJobs  ListMediaProducingJobsRequest
  * @return ListMediaProducingJobsResponse
 */
async function listMediaProducingJobs(request: ListMediaProducingJobsRequest): ListMediaProducingJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMediaProducingJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListPackageJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-15T00:00:00Z', position='Query'),
  jobId?: string(name='JobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb11cbe', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='ab4802364a2e49208c99efab82dfa8e8', position='Query'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

*   CreateTimeDesc: sorts the jobs by creation time in descending order.
*   CreateTimeAsc: sorts the jobs by creation time in ascending order.', example='CreateTimeDesc', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 0 to 100. Default value: 20.', example='10', position='Query'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-01T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The state of the job.

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success', position='Query'),
}

model ListPackageJobsResponseBody = {
  packageJobList?: {
    nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. The token of the next page is returned after you call this operation for the first time.', example='019daf5780f74831b0e1a767c9f1c178'),
    packageJobs?: [ 
      {
        code?: string(name='Code', description='The error code returned if the job fails.', example='InvalidParameter'),
        createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T14:00:32Z'),
        finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T15:00:32Z'),
        inputs?: [ 
          {
            input?: {
              media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
              type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
            }(name='Input', description='The information about the input stream file.'),
          }
        ](name='Inputs', description='The input of the job.'),
        jobId?: string(name='JobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb11cbe'),
        message?: string(name='Message', description='The error message that is returned.', example='Resource content bad.'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T15:00:32Z'),
        name?: string(name='Name', description='The name of the job.', example='job-name'),
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output of the job.'),
        pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='5b40833e4c3e4d4e95a866abb9a42510'),
        priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority. Default value: 6.', example='6'),
        status?: string(name='Status', description='The state of the job.', example='Success'),
        submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T14:00:32Z'),
        triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
        userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}'),
      }
    ](name='PackageJobs', description='The list of packaging jobs.'),
  }(name='PackageJobList', description='The list of packaging jobs.'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model ListPackageJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPackageJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListPackageJobs  ListPackageJobsRequest
  * @return ListPackageJobsResponse
 */
async function listPackageJobs(request: ListPackageJobsRequest): ListPackageJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListPackageJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListPipelinesRequest {
  speed?: string(name='Speed', description='The type of the MPS queue.

Valid values:

*   Boost: MPS queue with transcoding speed boosted.
*   Standard: standard MPS queue.
*   NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.', example='Standard', position='Query'),
}

model ListPipelinesResponseBody = {
  pipelineList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
      name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.', example='****20b48fb04483915d4f2cd8ac****'),
      priority?: int32(name='Priority', description='The priority of the MPS queue.', example='6'),
      speed?: string(name='Speed', description='The type of the MPS queue.', example='Standard'),
      status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Active'),
    }
  ](name='PipelineList', description='The queried MPS queues.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListPipelinesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPipelinesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListPipelines  ListPipelinesRequest
  * @return ListPipelinesResponse
 */
async function listPipelines(request: ListPipelinesRequest): ListPipelinesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListPipelines', 'POST', '/', 'json', false, 'json', request);
}

model ListProgramsRequest {
  channelName: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel', position='Query'),
  pageNo?: string(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10', position='Query'),
  programName?: string(name='ProgramName', description='The name of the program.', example='program1', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values:

*   asc: ascending order.
*   desc: descending order.', example='desc', position='Query'),
}

model ListProgramsResponseBody = {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10'),
  programs?: [
    ChannelAssemblyProgram
  ](name='Programs', description='The programs.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  totalCount?: int32(name='TotalCount', description='The total number of programs returned.', example='100'),
}

model ListProgramsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListProgramsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListPrograms  ListProgramsRequest
  * @return ListProgramsResponse
 */
async function listPrograms(request: ListProgramsRequest): ListProgramsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListPrograms', 'POST', '/', 'json', false, 'json', request);
}

model ListPublicMediaBasicInfosRequest {
  regionId?: string(name='RegionId', position='Host'),
  businessType?: string(name='BusinessType', description='The business type of the media asset. Valid values:

*   sticker
*   bgm
*   bgi', example='sticker', position='Query'),
  includeFileBasicInfo?: boolean(name='IncludeFileBasicInfo', description='Specifies whether to return the basic information of the media asset.', example='true', position='Query'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.

Maximum value: 100. Default value: 10.', example='5', minimum=1, maximum=100, position='Query'),
  mediaTagId?: string(name='MediaTagId', description='The media tag. All media assets that contain the specified media tag are returned. Valid values:

*   Sticker tags:

    *   sticker-atmosphere
    *   sticker-bubble
    *   sticker-cute
    *   sticker-daily
    *   sticker-expression
    *   sticker-gif

*   Background music (BGM) tags:

    *   bgm-romantic
    *   bgm-cuisine
    *   bgm-chinese-style
    *   bgm-upbeat
    *   bgm-dynamic
    *   bgm-relaxing
    *   bgm-quirky
    *   bgm-beauty

*   Background image (BGI) tags:

    *   bgi-grad
    *   bgi-solid
    *   bgi-pic', example='ticker-atmosphere', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='pSa1SQ0wCe5pzVrQ6mWZEw==', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
}

model ListPublicMediaBasicInfosResponseBody = {
  maxResults?: int32(name='MaxResults', description='The maximum number of entries returned.', example='2'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='270112.12'),
            duration?: string(name='Duration', description='The duration.', example='10.040000'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='338990717'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='1080'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='1920'),
          }(name='FileBasicInfo', description='The basic information of the file, such as the duration and size.'),
        }
      ](name='FileInfoList', description='The file information of the media asset.'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.', example='video'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2021-01-08T16:52:04Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2021-01-08T16:52:04Z'),
        description?: string(name='Description', description='The description of the media asset.', example='description'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='sticker-daily'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2021-01-08T16:52:04Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='null'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information of the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******B7-7F87-4792-BFE9-63CD21******'),
  totalCount?: long(name='TotalCount', description='The total number of media assets that meet the specified conditions.', example='2'),
}

model ListPublicMediaBasicInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPublicMediaBasicInfosResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListPublicMediaBasicInfos  ListPublicMediaBasicInfosRequest
  * @return ListPublicMediaBasicInfosResponse
 */
async function listPublicMediaBasicInfos(request: ListPublicMediaBasicInfosRequest): ListPublicMediaBasicInfosResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListPublicMediaBasicInfos', 'POST', '/', 'json', false, 'json', request);
}

model ListRecognitionEntitiesRequest {
  algorithm: string(name='Algorithm', description='The type of recognition algorithm associated with the entity. Valid values:

*   landmark
*   object
*   logo
*   face
*   label

This parameter is required.', example='landmark', position='Query'),
  libId: string(name='LibId', description='The ID of the recognition library.

This parameter is required.', example='1965304870001', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pageNumber: int32(name='PageNumber', description='The page number.

This parameter is required.', example='1', position='Query'),
  pageSize: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 50.

This parameter is required.', example='10', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model ListRecognitionEntitiesResponseBody = {
  entities?: {
    entity?: [ 
    {
      entityId?: string(name='EntityId', description='The ID of the entity.', example='**************544cb84754************'),
      entityInfo?: string(name='EntityInfo', description='The additional information of the entity, in JSON format.', example='{}'),
      entityName?: string(name='EntityName', description='The name of the entity.'),
    }
  ](name='Entity')
  }(name='Entities', description='The entities.'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='**Request ID**', example='******11-DB8D-4A9A-875B-275798******'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListRecognitionEntitiesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListRecognitionEntitiesResponseBody(name='body'),
}

/**
  * @description *   This operation is supported only in the China (Beijing), China (Shanghai), China (Hangzhou), and China (Shenzhen) regions.
  * *   You can call this operation up to 50 times per second per account. Requests that exceed this limit are dropped and you may experience service interruptions. For more information, see [QPS limits](https://help.aliyun.com/zh/mps/developer-reference/qps-limits?spm=a2c4g.11186623.0.0.647e1081YGcerb).
  * @param request  the request parameters of ListRecognitionEntities  ListRecognitionEntitiesRequest
  * @return ListRecognitionEntitiesResponse
 */
async function listRecognitionEntities(request: ListRecognitionEntitiesRequest): ListRecognitionEntitiesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListRecognitionEntities', 'POST', '/', 'json', false, 'json', request);
}

model ListRecognitionLibsRequest {
  algorithm: string(name='Algorithm', description='The type of recognition algorithm. Valid values:

*   landmark
*   object
*   logo
*   face
*   label

This parameter is required.', example='landmark', position='Query'),
  libId?: string(name='LibId', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pageNumber: int32(name='PageNumber', description='The page number.

This parameter is required.', example='1', position='Query'),
  pageSize: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 50.

This parameter is required.', example='10', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model ListRecognitionLibsResponseBody = {
  libs?: {
    lib?: [ 
    {
      libDescription?: string(name='LibDescription', description='The description of the recognition library.'),
      libId?: string(name='LibId', description='The ID of the recognition library.', example='*************24b47865c6**************'),
      libName?: string(name='LibName', description='The name of the recognition library.'),
    }
  ](name='Lib')
  }(name='Libs', description='The recognition libraries.'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='180'),
}

model ListRecognitionLibsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListRecognitionLibsResponseBody(name='body'),
}

/**
  * @description *   This operation is supported only in the China (Beijing), China (Shanghai), China (Hangzhou), and China (Shenzhen) regions.
  * *   You can call this operation up to 50 times per second per account. Requests that exceed this limit are dropped and you may experience service interruptions. For more information, see [QPS limits](https://help.aliyun.com/zh/mps/developer-reference/qps-limits?spm=a2c4g.11186623.0.0.647e1081YGcerb).
  * @param request  the request parameters of ListRecognitionLibs  ListRecognitionLibsRequest
  * @return ListRecognitionLibsResponse
 */
async function listRecognitionLibs(request: ListRecognitionLibsRequest): ListRecognitionLibsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListRecognitionLibs', 'POST', '/', 'json', false, 'json', request);
}

model ListRecognitionSamplesRequest {
  algorithm: string(name='Algorithm', description='The type of recognition algorithm. Valid values:

*   landmark
*   object
*   logo
*   face

This parameter is required.', example='landmark', position='Query'),
  entityId: string(name='EntityId', description='The ID of the entity.

This parameter is required.', example='e6b985c05174412dbc77c92496b7373b', position='Query'),
  entityName?: string(name='EntityName', position='Query'),
  libId: string(name='LibId', description='The ID of the recognition library.

This parameter is required.', example='xxxxxxxxxxx', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pageNumber: int32(name='PageNumber', description='The page number.

This parameter is required.', example='1', position='Query'),
  pageSize: int32(name='PageSize', description='The number of entries per page.

This parameter is required.', example='10', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model ListRecognitionSamplesResponseBody = {
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='20'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='xxx-xxxx-xxxxx-xxxx'),
  samples?: {
    sample?: [ 
    {
      entityId?: string(name='EntityId'),
      imageUrl?: string(name='ImageUrl', description='The URL of the image sample.', example='https://example.com/sample.png'),
      libId?: string(name='LibId'),
      sampleId?: string(name='SampleId', description='The sample ID.', example='xxxxxxxxxxxxx'),
    }
  ](name='Sample')
  }(name='Samples', description='The samples.'),
  totalCount?: long(name='TotalCount', description='The total number of samples.', example='5'),
}

model ListRecognitionSamplesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListRecognitionSamplesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListRecognitionSamples  ListRecognitionSamplesRequest
  * @return ListRecognitionSamplesResponse
 */
async function listRecognitionSamples(request: ListRecognitionSamplesRequest): ListRecognitionSamplesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListRecognitionSamples', 'POST', '/', 'json', false, 'json', request);
}

model ListSchedulesRequest {
  channelName: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  windowDurationSeconds: long(name='WindowDurationSeconds', description='The time window of the program schedule.

This parameter is required.', example='14400', position='Query'),
}

model ListSchedulesResponseBody = {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10'),
  programs?: [
    ChannelAssemblyScheduleData
  ](name='Programs', description='The program schedule.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='5'),
}

model ListSchedulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSchedulesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSchedules  ListSchedulesRequest
  * @return ListSchedulesResponse
 */
async function listSchedules(request: ListSchedulesRequest): ListSchedulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSchedules', 'POST', '/', 'json', false, 'json', request);
}

model ListSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10', position='Query'),
}

model ListSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  searchLibInfoList?: [ 
    {
      indexInfo?: [ 
        {
          indexReadiness?: string(name='IndexReadiness', example='Normal'),
          indexStatus?: string(name='IndexStatus', example='Active'),
          indexType?: string(name='IndexType', example='face'),
        }
      ](name='IndexInfo'),
      searchLibName?: string(name='SearchLibName', description='The search library.', example='faceSearchLib'),
      status?: string(name='Status', description='The status of the search library.

*   normal
*   deleting
*   deleteFail', example='normal'),
    }
  ](name='SearchLibInfoList', description='Information about search libraries.'),
  success?: string(name='Success', description='Indicates whether the request was successful.', example='true'),
  total?: long(name='Total', description='The total number of entries returned.', example='8'),
}

model ListSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSearchLib  ListSearchLibRequest
  * @return ListSearchLibResponse
 */
async function listSearchLib(request: ListSearchLibRequest): ListSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model ListSmartJobsRequest {
  jobState?: string(name='JobState', description='The job state.

Valid values:

*   Finished: The job is complete.
*   Failed: The job failed.
*   Executing: The job is in progress.
*   Created: The job is created.', example='Finished', position='Query'),
  jobType?: string(name='JobType', description='The job type.

Valid values:

*   ASR: automatic speech recognition(job) job.
*   DynamicChart: dynamic chart job.
*   VideoTranslation: video translation job.
*   TextToSpeech: intelligent audio production job.', example='ASR', position='Query'),
  maxResults?: long(name='MaxResults', description='The maximum number of entries to return.

Default value: 10. Valid values: 1 to 100.', example='10', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****73f33c91-d59383e8280b****', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting parameter. By default, the query results are sorted by creation time in descending order.

Valid values:

*   CreationTime:Asc: sorted by creation time in ascending order.
*   CreationTime:Desc: sorted by creation time in descending order.', example='CreationTime:Desc', position='Query'),
}

model ListSmartJobsResponseBody = {
  maxResults?: string(name='MaxResults', description='The maximum number of entries returned on a single page. The value is set to the maximum number of entries returned on each page except for the last page. Valid example: 10,10,5. Invalid example: 10,5,10.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='CBB6BC61D08'),
  requestId?: string(name='RequestId', description='The request ID.', example='****9262E3DA-07FA-4862-FCBB6BC61D08*****'),
  smartJobList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2020-12-26T04:11:10Z'),
      description?: string(name='Description', description='The job description.', example='测试描述'),
      editingConfig?: string(name='EditingConfig', description='The editing configurations.', example='{"AudioConfig":{},"InputConfig":""}'),
      inputConfig?: {
        inputFile?: string(name='InputFile', description='The information about the input file.', example='oss://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        keyword?: string(name='Keyword', description='The keyword information.', example='测试关键词'),
      }(name='InputConfig', description='The input configurations.'),
      jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
      jobState?: string(name='JobState', description='The job state.

Valid values:

*   Finished: The job is complete.
*   Failed: The job failed.
*   Executing: The job is in progress.
*   Created: The job is created.', example='Finished'),
      jobType?: string(name='JobType', description='The job type.

Valid values:

*   ASR: ASR job.
*   DynamicChart: dynamic chart job.
*   TextToSpeech: intelligent audio production job.', example='ASR'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2020-12-26T04:11:10Z'),
      outputConfig?: {
        bucket?: string(name='Bucket', description='The Object Storage Service (OSS) bucket.', example='test-bucket'),
        object?: string(name='Object', description='The OSS object.', example='test-object'),
      }(name='OutputConfig', description='The output configurations.'),
      title?: string(name='Title', description='The job title.', example='测试标题'),
      userData?: string(name='UserData', description='The user-defined data.', example='{"user":"data"}'),
      userId?: long(name='UserId', description='The user ID.', example='1084506228******'),
    }
  ](name='SmartJobList', description='The queried intelligent jobs.'),
  totalCount?: string(name='TotalCount', description='Optional. The total number of entries returned. By default, this parameter is not returned.', example='110'),
}

model ListSmartJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSmartJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSmartJobs  ListSmartJobsRequest
  * @return ListSmartJobsResponse
 */
async function listSmartJobs(request: ListSmartJobsRequest): ListSmartJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSmartJobs', 'GET', '/', 'json', false, 'json', request);
}

model ListSmartSysAvatarModelsRequest {
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10', position='Query'),
  sdkVersion?: string(name='SdkVersion', position='Query'),
}

model ListSmartSysAvatarModelsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  smartSysAvatarModelList?: [ 
    {
      avatarId?: string(name='AvatarId', description='The ID of the digital human. The ID is required to submit a separate digital human rendering job or use the digital human image in an intelligent timeline.', example='yunqiao'),
      avatarName?: string(name='AvatarName', description='The name of the digital human.'),
      bitrate?: int32(name='Bitrate', description='The video bitrate.', example='4000'),
      coverUrl?: string(name='CoverUrl', description='The sample thumbnail URL of the digital human.', example='http://ice-pub-media.myalicdn.com/smart/avatarModel/coverDemo/yunqiao.mp4'),
      height?: int32(name='Height', description='The video height.', example='1920'),
      outputMask?: boolean(name='OutputMask', description='Indicates whether portrait mask rendering is supported.', example='false'),
      videoUrl?: string(name='VideoUrl', description='The sample video URL of the digital human.', example='http://ice-pub-media.myalicdn.com/smart/avatarModel/videoDemo/yunqiao.mp4'),
      width?: int32(name='Width', description='The video width.', example='1080'),
    }
  ](name='SmartSysAvatarModelList', description='The queried digital humans.'),
  totalCount?: int32(name='TotalCount', description='The total number of system digital human images returned.', example='4'),
}

model ListSmartSysAvatarModelsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSmartSysAvatarModelsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSmartSysAvatarModels  ListSmartSysAvatarModelsRequest
  * @return ListSmartSysAvatarModelsResponse
 */
async function listSmartSysAvatarModels(request: ListSmartSysAvatarModelsRequest): ListSmartSysAvatarModelsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSmartSysAvatarModels', 'POST', '/', 'json', false, 'json', request);
}

model ListSmartVoiceGroupsRequest {
  voiceType?: string(name='VoiceType', position='Query'),
}

model ListSmartVoiceGroupsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='627B30EB-1D0A-5C6D-8467-431626E0FA10'),
  voiceGroups?: [ 
    {
      type?: string(name='Type', description='The name of the speaker group.'),
      voiceList?: [ 
        {
          desc?: string(name='Desc', description='The speaker description.'),
          name?: string(name='Name', description='The speaker name.'),
          remark?: string(name='Remark', description='The remarks of the speaker.'),
          supportSampleRate?: string(name='SupportSampleRate'),
          tag?: string(name='Tag', description='The tag of the speaker type.'),
          voice?: string(name='Voice', description='The speaker ID.', example='zhitian'),
          voiceSource?: string(name='VoiceSource'),
          voiceType?: string(name='VoiceType', description='The speaker type.

Valid values:

*   Male
*   Female
*   Boy
*   Girl', example='Female'),
          voiceUrl?: string(name='VoiceUrl', description='The URL of the sample audio file.', example='https://***.com/zhiqing.mp3'),
        }
      ](name='VoiceList', description='The speakers.'),
    }
  ](name='VoiceGroups', description='The queried speaker groups.'),
}

model ListSmartVoiceGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSmartVoiceGroupsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSmartVoiceGroups  ListSmartVoiceGroupsRequest
  * @return ListSmartVoiceGroupsResponse
 */
async function listSmartVoiceGroups(request: ListSmartVoiceGroupsRequest): ListSmartVoiceGroupsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSmartVoiceGroups', 'GET', '/', 'json', false, 'json', request);
}

model ListSnapshotJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created.', example='2022-07-14T00:00:00Z', position='Query'),
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results.

1.  CreateTimeDesc
2.  CreateTimeAsc

Valid values:

*   CreateTimeDesc: sorts the jobs by creation time in descending order
*   CreateTimeAsc: sorts the jobs by creation time in ascending order.', example='CreateTimeDesc', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Maximum value: 100.', example='20', position='Query'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created.', example='2022-07-12T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success', position='Query'),
}

model ListSnapshotJobsResponseBody = {
  jobs?: [ 
    {
      async?: boolean(name='Async', description='Indicates whether the snapshots were captured in asynchronous mode.', example='true'),
      count?: int32(name='Count', description='The number of snapshots.', example='10'),
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
      input?: {
        media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats: 1. OSS://bucket/object 2. http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://bucket/object.mp4'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
      }(name='Input', description='The input of the job.'),
      jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
      name?: string(name='Name', description='The name of the job.', example='SampleJob'),
      output?: {
        media?: string(name='Media', description='The output file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS. If multiple static snapshots were captured, the object must contain the "{Count}" placeholder. In the case of a sprite, the object must contain the "{TileCount}" placeholder. The suffix of the WebVTT snapshot objects must be ".vtt".', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/output-{Count}.jpg'),
        type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.', example='OSS'),
      }(name='Output', description='The output of the job.'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****20b48fb04483915d4f2cd8ac****'),
      status?: string(name='Status', description='The state of the job.

*   **Success**: The job is successful.
*   **Fail**: The job failed.
*   **Init**: The job is submitted.', example='Success'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
      triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
      type?: string(name='Type', description='The type of the job.

Valid values:

*   WebVtt
*   Sprite
*   Normal', example='Sprite'),
    }
  ](name='Jobs', description='The list of jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListSnapshotJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSnapshotJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSnapshotJobs  ListSnapshotJobsRequest
  * @return ListSnapshotJobsResponse
 */
async function listSnapshotJobs(request: ListSnapshotJobsRequest): ListSnapshotJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSnapshotJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListSourceLocationsRequest {
  filterState?: boolean(name='FilterState', description='Specifies whether to ignore source locations marked as deleted. A value of true means ignoring source locations marked as deleted.', example='true', position='Query'),
  pageNo?: int32(name='PageNo', description='*   The page number.
*   Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.', example='desc', position='Query'),
  sortByModifiedTime?: string(name='SortByModifiedTime', description='The sorting order of the source locations based on the time when they were last modified.', example='desc', position='Query'),
  sourceLocationName?: string(name='SourceLocationName', description='The name of the source location.', example='MySourceLocation', position='Query'),
}

model ListSourceLocationsResponseBody = {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  sourceLocationList?: [
    ChannelAssemblySourceLocation
  ](name='SourceLocationList', description='The source locations.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListSourceLocationsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSourceLocationsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSourceLocations  ListSourceLocationsRequest
  * @return ListSourceLocationsResponse
 */
async function listSourceLocations(request: ListSourceLocationsRequest): ListSourceLocationsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSourceLocations', 'POST', '/', 'json', false, 'json', request);
}

model ListSourcesRequest {
  filterState?: boolean(name='FilterState', description='Specifies whether to ignore sources marked as deleted.', example='true', position='Query'),
  pageNo?: string(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries per page.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values: asc and desc.', example='asc', position='Query'),
  sortByModifiedTime?: string(name='SortByModifiedTime', description='The sorting order by modification time. Valid values: asc and desc.', example='desc', position='Query'),
  sourceLocationName?: string(name='SourceLocationName', description='The name of the source location.', example='MySourceLocation', position='Query'),
  sourceName?: string(name='SourceName', description='The name of the source.', example='MyVodSource', position='Query'),
  sourceType?: string(name='SourceType', description='The source type. Valid values: vodSource and liveSource.', example='vodSource', position='Query'),
}

model ListSourcesResponseBody = {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='20'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  sourceList?: [
    ChannelAssemblySource
  ](name='SourceList', description='The sources.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListSourcesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSourcesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSources  ListSourcesRequest
  * @return ListSourcesResponse
 */
async function listSources(request: ListSourcesRequest): ListSourcesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSources', 'POST', '/', 'json', false, 'json', request);
}

model ListSystemTemplatesRequest {
  name?: string(name='Name', description='The template name.', example='SampleTemplate', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20 Valid values: 1 to 100.', example='20', position='Query'),
  status?: string(name='Status', description='The template state. Valid values: Normal, Invisible, and All.', example='Normal', position='Query'),
  subtype?: string(name='Subtype', description='The subtype ID of the template.', example='1', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****', position='Query'),
  type: string(name='Type', description='The template type. Separate multiple types with commas (,).

This parameter is required.', example='1,2', position='Query'),
}

model ListSystemTemplatesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  systemTemplateList?: [ 
    {
      status?: string(name='Status', description='The template state.', example='Normal'),
      subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='1'),
      subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='Remux'),
      templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Container":{"Format":"flv"},"Video":{},"Audio":{}}'),
      templateId?: string(name='TemplateId', description='The template ID.', example='S00000001-000000'),
      templateName?: string(name='TemplateName', description='The template name.', example='FLV-COPY'),
      type?: int32(name='Type', description='The type ID of the template.', example='1'),
      typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
    }
  ](name='SystemTemplateList', description='The queried templates.'),
  total?: int32(name='Total', description='The total number of templates.', example='20'),
}

model ListSystemTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSystemTemplatesResponseBody(name='body'),
}

/**
  * @description Template types:
  * 1.  1: transcoding template.
  * 2.  2: snapshot template.
  * 3.  3: animated image template.
  * 4.  4\\. image watermark template.
  * 5.  5: text watermark template.
  * 6.  6: subtitle template.
  * 7.  7: AI-assisted content moderation template.
  * 8.  8: AI-assisted intelligent thumbnail template.
  * 9.  9: AI-assisted intelligent erasure template.
  * Subtypes of transcoding templates:
  * 1.  1 (Normal): regular template.
  * 2.  2 (AudioTranscode): audio transcoding template.
  * 3.  3 (Remux): container format conversion template.
  * 4.  4 (NarrowBandV1): Narrowband HD 1.0 template.
  * 5.  5 (NarrowBandV2): Narrowband HD 2.0 template.
  * Subtypes of snapshot templates:
  * 1.  1 (Normal): regular template.
  * 2.  2 (Sprite): sprite template.
  * 3.  3 (WebVtt): WebVTT template.
  * Subtypes of AI-assisted content moderation templates:
  * 1.  1 (Video): video moderation template.
  * 2.  2 (Audio): audio moderation template.
  * 3.  3 (Image): image moderation template.
  * Subtypes of AI-assisted intelligent erasure templates:
  * 1.  1 (VideoDelogo): logo erasure template.
  * 2.  2 (VideoDetext): subtitle erasure template.
  * @param request  the request parameters of ListSystemTemplates  ListSystemTemplatesRequest
  * @return ListSystemTemplatesResponse
 */
async function listSystemTemplates(request: ListSystemTemplatesRequest): ListSystemTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSystemTemplates', 'POST', '/', 'json', false, 'json', request);
}

model ListTemplatesRequest {
  createSource?: string(name='CreateSource', description='The source from which the template was created.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI', position='Query'),
  keyword?: string(name='Keyword', description='The search keyword. You can use the template ID or title as the keyword to search for templates.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='20', position='Query'),
  sortType?: string(name='SortType', description='The sorting parameter. By default, the query results are sorted by creation time in descending order.

Valid values:

*   CreationTime:Asc: sorted by creation time in ascending order.
*   CreationTime:Desc: sorted by creation time in descending order.', example='CreationTime:Desc', position='Query'),
  status?: string(name='Status', description='The template state.

Valid values:

*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.
*   Available: The template is available.
*   Uploading: The video is being uploaded.
*   Created: The template is created but not ready for use.
*   Processing: The advanced template is being processed.', example='Available', position='Query'),
  type?: string(name='Type', description='The template type.

Valid values:

*   Timeline
*   VETemplate', example='Timeline', position='Query'),
}

model ListTemplatesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  templates?: [ 
    {
      clipsParam?: string(name='ClipsParam', description='The clip parameters.', example='{"Media1":"mediaId","Text1":"text"}'),
      config?: string(name='Config', description='The template configurations.', example='参考Timeline模板配置详解'),
      coverURL?: string(name='CoverURL', description='The thumbnail URL.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
      createSource?: string(name='CreateSource', description='The source from which the template was created.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
      creationTime?: string(name='CreationTime', description='The time when the template was created.', example='2020-12-26T04:11:10Z'),
      modifiedSource?: string(name='ModifiedSource', description='The source from which the template was modified.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2020-12-26T04:11:10Z'),
      name?: string(name='Name', description='The template name.', example='视频添加水印模板'),
      previewMedia?: string(name='PreviewMedia', description='The preview media asset.', example='****20b48fb04483915d4f2cd8ac****'),
      previewMediaStatus?: string(name='PreviewMediaStatus', description='The state of the preview media asset.

Valid values:

*   PrepareFail
*   Init
*   Normal
*   Preparing', example='Normal'),
      status?: string(name='Status', description='The template state.

Valid values:

*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.
*   Available: The template is available.
*   Uploading: The video is being uploaded.
*   Created: The template is created but not ready for use.
*   Processing: The advanced template is being processed.', example='Available'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
      type?: string(name='Type', description='The template type.

Valid values:

*   Timeline: regular template.
*   VETemplate: advanced template.', example='Timeline'),
    }
  ](name='Templates', description='The queried templates.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTemplatesResponseBody(name='body'),
}

/**
  * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
  * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
  * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
  * @param request  the request parameters of ListTemplates  ListTemplatesRequest
  * @return ListTemplatesResponse
 */
async function listTemplates(request: ListTemplatesRequest): ListTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTemplates', 'POST', '/', 'json', false, 'json', request);
}

model ListTranscodeJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-15T00:00:00Z', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='ab4802364a2e49208c99efab82dfa8e8', position='Query'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

*   CreateTimeDesc: sorts the query results by creation time in descending order.
*   CreateTimeAsc: sorts the query results by creation time in ascending order.', example='CreateTimeDesc', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 0 to 100. Default value: 20.', example='10', position='Query'),
  parentJobId?: string(name='ParentJobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb1****', position='Query'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-01T00:00:00Z', position='Query'),
  status?: string(name='Status', description='The state of the job.

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success', position='Query'),
}

model ListTranscodeJobsResponseBody = {
  jobs?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      inputGroup?: [ 
        {
          inputUrl?: string(name='InputUrl', description='The URL of the media asset. This parameter is specified only when the media asset is transcoded.', example='oss://bucket/path/to/video.mp4'),
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
        }
      ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
      jobCount?: int32(name='JobCount', description='The number of subjobs.', example='1'),
      name?: string(name='Name', description='The job name.', example='transcode-job'),
      outputGroup?: [ 
        {
          output?: {
            media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
            outputUrl?: string(name='OutputUrl', description='The URL of the transcoded output stream. This parameter is required only when the output is a media asset.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
            type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
          }(name='Output', description='The output file configuration.'),
          processConfig?: {
            combineConfigs?: [ 
              {
                audioIndex: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
                duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
                start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
                videoIndex: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
              }
            ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
            encryption?: {
              cipherText?: string(name='CipherText', description='The ciphertext of HTTP Live Streaming (HLS) encryption.', example='MTYi00NDU0LTg5O****'),
              decryptKeyUri?: string(name='DecryptKeyUri', description='The endpoint of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
              encryptType?: string(name='EncryptType', description='The encryption type.', example='PrivateEncryption'),
            }(name='Encryption', description='The encryption settings.'),
            imageWatermarks?: [ 
              {
                overwriteParams?: {
                  dx?: string(name='Dx', description='The position of the watermark on the x-axis.', example='10'),
                  dy?: string(name='Dy', description='The position of the watermark on the y-axis.', example='10'),
                  file?: {
                    media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                    type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                  }(name='File', description='The watermark image file.'),
                  height?: string(name='Height', description='The height of the output video.', example='32'),
                  referPos?: string(name='ReferPos', description='The reference position of the watermark. Valid values: TopLeft, TopRight, BottomLeft, and BottomRight. Default value: TopLeft.', example='TopLeft'),
                  timeline?: {
                    duration?: string(name='Duration', description='The duration of the stream. Valid values: the number of seconds or "ToEND".', example='ToEND'),
                    start?: string(name='Start', description='The beginning of the time range for which data was queried.', example='00:00:05'),
                  }(name='Timeline', description='The timeline settings.'),
                  width?: string(name='Width', description='The width of the output video.', example='32'),
                }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
                templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
              }
            ](name='ImageWatermarks', description='The watermark configuration for an image.'),
            isInheritTags?: boolean(name='IsInheritTags', description='Indicates whether the tags of the input stream are inherited in the output stream. This parameter does not take effect when the input is not a media asset. Default value: false.'),
            subtitles?: [ 
              {
                overwriteParams?: {
                  charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                  file?: {
                    media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                    type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                  }(name='File', description='The subtitle file.'),
                  format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
                }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
                templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
              }
            ](name='Subtitles', description='The subtitle configuration.'),
            textWatermarks?: [ 
              {
                overwriteParams?: {
                  adaptive?: string(name='Adaptive', description='Indicates whether the text size was adjusted based on the output video dimensions. true / false, default: false', example='false'),
                  borderColor?: string(name='BorderColor', description='The border color.', example='#006400'),
                  borderWidth?: int32(name='BorderWidth', description='The border width.', example='0'),
                  content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                  fontAlpha?: string(name='FontAlpha', description='The transparency of the watermark.', example='1.0'),
                  fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                  fontName?: string(name='FontName', description='The font of the text.', example='SimSun'),
                  fontSize?: int32(name='FontSize', description='The size of the text.', example='16'),
                  left?: string(name='Left', description='The distance of the watermark from the left edge.', example='10'),
                  top?: string(name='Top', description='The distance of the watermark from the top edge.', example='10'),
                }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
                templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
              }
            ](name='TextWatermarks', description='The configurations of the text watermarks.'),
            transcode?: {
              overwriteParams?: {
                audio?: {
                  bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                  channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                  codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                  profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                  remove?: string(name='Remove', description='Indicates whether the audio stream is deleted.', example='false'),
                  samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100.
*   Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                  volume?: {
                    integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                    loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                    method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                    truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                  }(name='Volume', description='The volume configurations.'),
                }(name='Audio', description='The audio settings.'),
                container?: {
                  format?: string(name='Format', description='The container format.', example='mp4'),
                }(name='Container', description='The encapsulation format settings.'),
                muxConfig?: {
                  segment?: {
                    duration?: string(name='Duration', description='The segment length.', example='10'),
                    forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                  }(name='Segment', description='The segment settings.'),
                }(name='MuxConfig', description='The encapsulation settings.'),
                tags?: map[string]string(name='Tags'),
                video?: {
                  abrMax?: string(name='AbrMax', description='The maximum adaptive bitrate (ABR). This parameter takes effect only for Narrowband HD 1.0. Valid values: [10,50000]. Unit: Kbit/s.', example='6000'),
                  bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                  bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                  codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                  crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.

If this parameter is set, the value of Bitrate becomes invalid.', example='23'),
                  crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                  fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                  gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                  height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                  longShortMode?: string(name='LongShortMode', description='Indicates whether the auto-rotate screen feature is enabled.', example='false'),
                  maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video. Valid values: [10,50000]. Unit: Kbit/s.', example='9000'),
                  pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                  pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                  preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                  profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                  remove?: string(name='Remove', description='Indicates whether the video was removed.', example='false'),
                  scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                  width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
                }(name='Video', description='The video settings.'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }(name='Transcode', description='The transcoding configuration.'),
          }(name='ProcessConfig', description='The job processing configuration.'),
        }
      ](name='OutputGroup', description='The output group of the job.'),
      parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
      percent?: int32(name='Percent', description='The completion percentage of the job.', example='0'),
      requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
      scheduleConfig?: {
        pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
        priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
      }(name='ScheduleConfig', description='The scheduling configuration of the job.'),
      status?: string(name='Status', description='The state of the job.

*   Success: At least one of the subjobs is successful.
*   Fail: All subjobs failed.', example='Success'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
      userData?: string(name='UserData', description='The user data.', example='user-data'),
    }
  ](name='Jobs', description='The list of jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. The token of the next page is returned after you call this operation for the first time.', example='019daf5780f74831b0e1a767c9f1c178'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model ListTranscodeJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTranscodeJobsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListTranscodeJobs  ListTranscodeJobsRequest
  * @return ListTranscodeJobsResponse
 */
async function listTranscodeJobs(request: ListTranscodeJobsRequest): ListTranscodeJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTranscodeJobs', 'POST', '/', 'json', false, 'json', request);
}

model ListVodPackagingAssetsRequest {
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls', position='Query'),
  keyword?: string(name='Keyword', description='The search keyword. The names of the returned assets are prefixed with this keyword.', example='movie', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', minimum=1, maximum=100, position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order of the assets based on the time when they were ingested. Valid values:

*   desc (default): descending order.
*   asc: ascending order.', example='desc', position='Query'),
}

model ListVodPackagingAssetsResponseBody = {
  assets?: [ 
    {
      assetName?: string(name='AssetName', description='The name of the VOD packaging asset.', example='30min_movie'),
      createTime?: string(name='CreateTime', description='The time when the asset was ingested. It follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-11-21T06:45:32Z'),
      description?: string(name='Description', description='The asset description.', example='movie 30min'),
      groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls'),
      input?: {
        media?: string(name='Media', description='The URL of the media file. Only M3U8 files stored in OSS are supported.'),
        type?: string(name='Type', description='The input type. Only Object Storage Service (OSS) is supported.', example='OSS'),
      }(name='Input', description='The asset input configurations.'),
    }
  ](name='Assets', description='The VOD packaging assets.'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the assets based on the time when they were ingested. Valid values:

*   desc: descending order.
*   asc: ascending order.', example='desc'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListVodPackagingAssetsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListVodPackagingAssetsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListVodPackagingAssets  ListVodPackagingAssetsRequest
  * @return ListVodPackagingAssetsResponse
 */
async function listVodPackagingAssets(request: ListVodPackagingAssetsRequest): ListVodPackagingAssetsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListVodPackagingAssets', 'POST', '/', 'json', false, 'json', request);
}

model ListVodPackagingConfigurationsRequest {
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls', position='Query'),
  keyword?: string(name='Keyword', description='The search keyword. The names of the returned packaging configurations contain the keyword.', example='hls', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order of the packaging configurations based on the time when they were created. Valid values:

*   desc (default): descending order.
*   asc: ascending order.', example='desc', position='Query'),
}

model ListVodPackagingConfigurationsResponseBody = {
  packagingConfigurations?: [
    VodPackagingConfiguration
  ](name='PackagingConfigurations', description='The packaging configurations.'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the packaging configurations based on the time when they were created. Valid values:

*   desc: descending order.
*   asc: ascending order.', example='desc'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='5'),
}

model ListVodPackagingConfigurationsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListVodPackagingConfigurationsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListVodPackagingConfigurations  ListVodPackagingConfigurationsRequest
  * @return ListVodPackagingConfigurationsResponse
 */
async function listVodPackagingConfigurations(request: ListVodPackagingConfigurationsRequest): ListVodPackagingConfigurationsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListVodPackagingConfigurations', 'POST', '/', 'json', false, 'json', request);
}

model ListVodPackagingGroupsRequest {
  keyword?: string(name='Keyword', description='The search keyword. The names of the returned packaging groups contain the keyword.', example='hls', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting order of the packaging groups based on the time when they were created. Valid values:

*   desc (default): descending order.
*   asc: ascending order.', example='desc', position='Query'),
}

model ListVodPackagingGroupsResponseBody = {
  packagingGroups?: [
    VodPackagingGroup
  ](name='PackagingGroups', description='The packaging groups.'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the packaging groups based on the time when they were created. Valid values:

*   desc: descending order.
*   asc: ascending order.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='5'),
}

model ListVodPackagingGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListVodPackagingGroupsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListVodPackagingGroups  ListVodPackagingGroupsRequest
  * @return ListVodPackagingGroupsResponse
 */
async function listVodPackagingGroups(request: ListVodPackagingGroupsRequest): ListVodPackagingGroupsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListVodPackagingGroups', 'POST', '/', 'json', false, 'json', request);
}

model ListWorkflowTasksRequest {
  regionId?: string(name='RegionId', position='Host'),
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range for filtering tasks by their creation time. Supports querying data from the last 90 days only.', example='2025-07-15T00:00:00Z', position='Query'),
  keyText?: string(name='KeyText', description='A keyword for fuzzy matching against the TaskInput, such as a file name or Media ID. Max length: 32 characters.', position='Query'),
  maxResults?: int32(name='MaxResults', description='The maximum number of media workflow instances to return. Valid values: 1 to 100. Default value: 10.', example='10', position='Query'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='**************VRpbWUQARgBIpcBCgkA1bUtaAAAAAAKiQEDhAAAADFTMzg2NTY2NjU2MzM3NjU2NjYyMzkzMTYyMzI2MjYzNjY2**********', position='Query'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The start of the time range for filtering tasks by their creation time. Supports querying data from the last 90 days only.', example='2025-07-12T00:00:00Z', position='Query'),
  workflowId?: string(name='WorkflowId', description='The ID of the workflow template.[](https://ims.console.aliyun.com/settings/workflow/list)', example='******b4fb044839815d4f2cd8******', position='Query'),
  workflowName?: string(name='WorkflowName', description='The name of the workflow template.', example='example-workflow-****', position='Query'),
}

model ListWorkflowTasksResponseBody = {
  maxResults?: int32(name='MaxResults', description='The maximum number of entries returned in this response.', example='10'),
  nextToken: string(name='NextToken', description='A pagination token.

This parameter is required.', example='****8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The ID of the request.', example='C0C02296-113C-5838-8FE9-8F3A32998DDC'),
  taskList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time the task was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-07-15T09:45:48Z'),
      finishTime?: string(name='FinishTime', description='The time the task was completed. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-12-07T10:53:45Z'),
      status?: string(name='Status', description='The task state.

**Valid values**:

*   Init: Initializing
*   Failed
*   Canceled
*   Processing
*   Succeed', example='Succeed'),
      taskId?: string(name='TaskId', description='The ID of the workflow task.', example='*****4c93d2f404f8345b16a965*****'),
      taskInput?: string(name='TaskInput', description='The input data for the workflow task.', example='{\\"Type\\":\\"Media\\",\\"Media\\":\\"****8b40884171efb0d9e7f7f458****\\"}'),
      userData?: string(name='UserData', description='The custom data that was passed when the task was submitted.', example='{"NotifyAddress":"http://xx.xx.xxx"}'),
      workflow?: {
        createTime?: string(name='CreateTime', description='The creation time of the workflow template.', example='2025-03-21T01:48:49Z'),
        mediaType?: string(name='MediaType', description='The source of the media file. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        modifiedTime?: string(name='ModifiedTime', description='The last modification time of the workflow template.', example='2025-02-23 10:19:37 +0800'),
        name?: string(name='Name', description='The name of the workflow template.', example='example-workflow-***'),
        status?: string(name='Status', description='The status of the workflow template.', example='Active'),
        type?: string(name='Type', description='The type of the workflow template.', example='Common'),
        workflowId?: string(name='WorkflowId', description='The workflow ID.', example='******2491c84dce913da9fe65******'),
      }(name='Workflow', description='The information about the workflow template.'),
    }
  ](name='TaskList', description='The media workflow tasks.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned. By default, this parameter is not returned.', example='4'),
}

model ListWorkflowTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListWorkflowTasksResponseBody(name='body'),
}

/**
  * @description This API only returns data from the last 90 days.
  * @param request  the request parameters of ListWorkflowTasks  ListWorkflowTasksRequest
  * @return ListWorkflowTasksResponse
 */
async function listWorkflowTasks(request: ListWorkflowTasksRequest): ListWorkflowTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListWorkflowTasks', 'POST', '/', 'json', false, 'json', request);
}

model OpenMediaConnectFlowFailoverRequest {
  flowId?: string(name='FlowId', description='The ID of the MediaConnect flow.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f', position='Query'),
}

model OpenMediaConnectFlowFailoverResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The request ID.', example='11357BE8-4C54-58EA-890A-5AB646EDE4B2'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model OpenMediaConnectFlowFailoverResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: OpenMediaConnectFlowFailoverResponseBody(name='body'),
}

/**
  * @description *   Before this operation, you must add a source to the flow.
  * *   After Source Failover is enabled, you can add an additional source. The input type of the two sources must be identical.
  * @param request  the request parameters of OpenMediaConnectFlowFailover  OpenMediaConnectFlowFailoverRequest
  * @return OpenMediaConnectFlowFailoverResponse
 */
async function openMediaConnectFlowFailover(request: OpenMediaConnectFlowFailoverRequest): OpenMediaConnectFlowFailoverResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'OpenMediaConnectFlowFailover', 'POST', '/', 'json', false, 'json', request);
}

model QueryCopyrightExtractJobRequest {
  jobId: string(name='JobId', description='The job ID. You can obtain the value of this parameter from the response of the SubmitCopyrightExtractJob operation.

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****', position='Query'),
}

model QueryCopyrightExtractJobResponseBody = {
  data?: {
    message?: string(name='Message', description='The copyright watermark information.'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The message returned.', example='ok'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  statusCode?: long(name='StatusCode', description='The status code.', example='200'),
}

model QueryCopyrightExtractJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryCopyrightExtractJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QueryCopyrightExtractJob  QueryCopyrightExtractJobRequest
  * @return QueryCopyrightExtractJobResponse
 */
async function queryCopyrightExtractJob(request: QueryCopyrightExtractJobRequest): QueryCopyrightExtractJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryCopyrightExtractJob', 'POST', '/', 'json', false, 'json', request);
}

model QueryCopyrightJobListRequest {
  createTimeEnd?: long(name='CreateTimeEnd', description='The end of the creation time range for the query, in UNIX timestamp format.', example='1627357325', position='Query'),
  createTimeStart?: long(name='CreateTimeStart', description='The start of the creation time range for the query, in UNIX timestamp format.', example='1627357322', position='Query'),
  jobId?: string(name='JobId', description='The job ID.', example='****cdb3e74639973036bc84****', position='Query'),
  level?: long(name='Level', description='The watermark level, indicating the color channel for embedding. 0: U. 1: UV. 2: YUV.', example='0', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number.', example='0', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries to return on each page.', example='10', position='Query'),
}

model QueryCopyrightJobListResponseBody = {
  data?: [ 
    {
      gmtCreate?: long(name='GmtCreate', description='The creation time of the job.', example='1627357322'),
      gmtModified?: long(name='GmtModified', description='The last modification time of the job.', example='1627357322'),
      input?: {
        media?: string(name='Media', description='The specific input information.', example='oss://bucket/object'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
      }(name='Input', description='Information about the input video for watermarking.'),
      jobId?: string(name='JobId', description='The job ID.', example='bfb786c639894f4d80648792021****'),
      level?: long(name='Level', description='The watermark level.', example='2'),
      message?: string(name='Message', description='The content of the embedded watermark.', example='test'),
      output?: {
        media?: string(name='Media', description='The specific output information.', example='oss://bucket/object'),
        type?: string(name='Type', description='The type of the output file. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
      }(name='Output', description='Information about the watermarked output video.'),
      result?: string(name='Result', description='The job result.', example='{"Code":"success","Message":"ok"}'),
      status?: string(name='Status', description='The status of the job.', example='success'),
      userData?: string(name='UserData', description='The user-defined data.', example='123'),
      userId?: long(name='UserId', description='The ID of the user who initiated the job.', example='1346693***'),
    }
  ](name='Data', description='The data returned.'),
  message?: string(name='Message', description='The message returned.', example='ok'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******36-3C1E-4417-BDB2-1E034F******'),
  statusCode?: long(name='StatusCode', description='The status code.', example='200'),
}

model QueryCopyrightJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryCopyrightJobListResponseBody(name='body'),
}

/**
  * @description *   This operation is supported only in the China (Shanghai) and China (Beijing) regions.
  * @param request  the request parameters of QueryCopyrightJobList  QueryCopyrightJobListRequest
  * @return QueryCopyrightJobListResponse
 */
async function queryCopyrightJobList(request: QueryCopyrightJobListRequest): QueryCopyrightJobListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryCopyrightJobList', 'POST', '/', 'json', false, 'json', request);
}

model QueryDNAJobListRequest {
  jobIds?: string(name='JobIds', description='The IDs of the media fingerprint analysis jobs that you want to query. We recommend that you query at most 10 jobs at a time. Separate multiple job IDs with commas (,).', example='88c6ca184c0e47098a5b665e2a12****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model QueryDNAJobListResponseBody = {
  jobList?: [ 
    {
      code?: string(name='Code', description='The response code.', example='"InvalidParameter.ResourceNotFound"'),
      config?: string(name='Config', description='The configurations of the media fingerprint analysis job.', example='{"SaveType": "save","MediaType"":"video"}'),
      creationTime?: string(name='CreationTime', description='The time when the job was created.', example='2022-12-28T03:21:37Z'),
      DBId?: string(name='DBId', description='The ID of the media fingerprint library.', example='2288c6ca184c0e47098a5b665e2a12****'),
      DNAResult?: string(name='DNAResult', description='The URL of the media fingerprint analysis result.', example='http://test_bucket.oss-cn-shanghai.aliyuncs.com/fingerprint/video/search_result/5/5.txt'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-12-28T03:21:44Z'),
      id?: string(name='Id', description='The job ID.', example='88c6ca184c0e47098a5b665e2a12****'),
      input?: {
        media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. The path of an OSS object can be in one of the following formats:

1\\. oss://bucket/object

2\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the preceding paths, bucket indicates an OSS bucket that resides in the same region as the current project, and object indicates the path of the object in the bucket.', example='1b1b9cd148034739af413150fded****'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: Object Storage Service (OSS) object.
2.  Media: media asset.', example='Media'),
      }(name='Input', description='The details of the input file.'),
      message?: string(name='Message', description='The returned message.', example='"The resource operated \\"a887d0b***d805ef6f7f6786302\\" cannot be found"'),
      primaryKey?: string(name='PrimaryKey', description='The primary key of the video. You must make sure that each primary key is unique.', example='3ca84a39a9024f19853b21be9cf9****'),
      status?: string(name='Status', description='The job state. Valid values:

*   **Queuing**: The job is waiting in the queue.
*   **Analysing**: The job is in progress.
*   **Success**: The job is successful.
*   **Fail**: The job failed.', example='Queuing'),
      userData?: string(name='UserData', description='The user-defined data.', example='testdna'),
    }
  ](name='JobList', description='The queried media fingerprint analysis jobs.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model QueryDNAJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryDNAJobListResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QueryDNAJobList  QueryDNAJobListRequest
  * @return QueryDNAJobListResponse
 */
async function queryDNAJobList(request: QueryDNAJobListRequest): QueryDNAJobListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryDNAJobList', 'POST', '/', 'json', false, 'json', request);
}

model QueryIProductionJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', position='Query'),
  jobId: string(name='JobId', description='The ID of the intelligent production job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model QueryIProductionJobResponseBody = {
  createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-07T07:16:11Z'),
  finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2021-11-26T14:50:25Z'),
  functionName?: string(name='FunctionName', description='The name of the algorithm that you want to use for the job. Valid values:

*   **Cover**: This algorithm intelligently generates a thumbnail image for a video.
*   **VideoClip**: This algorithm intelligently generates a summary for a video.
*   **VideoDelogo**: This algorithm removes logos from a video.
*   **VideoDetext**: This algorithm removes captions from a video.', example='Cover'),
  input?: {
    media?: string(name='Media', description='The input file. If Type is set to OSS, set this parameter to the path of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.', example='oss://bucket/object'),
    type?: string(name='Type', description='The media type. Valid values:

1.  OSS: Object Storage Service (OSS) object
2.  Media: media asset', example='OSS'),
  }(name='Input', description='The input file.'),
  jobId?: string(name='JobId', description='The ID of the intelligent production job.', example='****20b48fb04483915d4f2cd8ac****'),
  jobParams?: string(name='JobParams', description='The algorithm-specific parameters. The parameters are specified as JSON objects and vary based on the algorithm.', example='{"Model":"gif"}'),
  name?: string(name='Name', description='The name of the intelligent production job.'),
  output?: {
    biz?: string(name='Biz'),
    media?: string(name='Media', description='The output file. If Type is set to OSS, set this parameter to the path of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.', example='oss://bucket/object'),
    outputUrl?: string(name='OutputUrl'),
    type?: string(name='Type', description='The media type. Valid values:

*   OSS: OSS object
*   Media: media asset', example='OSS'),
  }(name='Output', description='The output file.'),
  outputFiles?: [ string ](name='OutputFiles', description='The output files.'),
  outputMediaIds?: [ string ](name='OutputMediaIds'),
  outputUrls?: [ string ](name='OutputUrls', description='The URLs of the output files.'),
  requestId?: string(name='RequestId', description='The ID of the request.'),
  result?: string(name='Result', description='The output of the algorithm. The output is in JSON format and varies based on the algorithm. For more information, see the "Parameters of Result" section of this topic.', example='{}'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue.', example='a54fdc9c9aab413caef0d1150f565e86'),
    priority?: int32(name='Priority', description='The priority of the job in the MPS queue to which the job is added.

*   A value of 10 indicates the highest priority.
*   Default value: **6**.', example='6'),
  }(name='ScheduleConfig', description='The scheduling configuration.'),
  status?: string(name='Status', description='The status of the job. Valid values:

*   Queuing: The job is waiting in the queue.
*   Analysing: The job is in progress.
*   Fail: The job failed.
*   Success: The job was successful.', example='Success'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
  userData?: string(name='UserData', description='The user-defined data that is returned in the response.', example='{"test":1}'),
}

model QueryIProductionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryIProductionJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QueryIProductionJob  QueryIProductionJobRequest
  * @return QueryIProductionJobResponse
 */
async function queryIProductionJob(request: QueryIProductionJobRequest): QueryIProductionJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryIProductionJob', 'POST', '/', 'json', false, 'json', request);
}

model QueryMediaCensorJobDetailRequest {
  jobId: string(name='JobId', description='The ID of the content moderation job. You can obtain the job ID from the response parameters of the [SubmitMediaCensorJob](https://help.aliyun.com/document_detail/444848.html) operation.

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****', position='Query'),
  maximumPageSize?: long(name='MaximumPageSize', description='The number of entries per page.

*   Default value: **30**.
*   Valid values: **1 to 300**.', example='30', position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='ae0fd49c0840e14daf0d66a75b83****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model QueryMediaCensorJobDetailResponseBody = {
  mediaCensorJobDetail?: {
    barrageCensorResult?: {
      label?: string(name='Label', description='The label of the moderation result. Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='normal'),
      rate?: string(name='Rate', description='The score.', example='99.91'),
      scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
    }(name='BarrageCensorResult', description='The moderation results of live comments.'),
    code?: string(name='Code', description='The error code returned if the job failed. This parameter is not returned if the job is successful.', example='InvalidParameter.ResourceNotFound'),
    coverImageCensorResults?: {
      coverImageCensorResult?: [ 
      {
        bucket?: string(name='Bucket', description='The OSS bucket in which the thumbnail is stored.', example='bucket-out-test-****'),
        location?: string(name='Location', description='The OSS region in which the thumbnail resides.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The Object Storage Service (OSS) object that is used as the thumbnail.', example='test/ai/censor/v2/vme-****.jpg'),
        results?: {
          result?: [ 
          {
            label?: string(name='Label', description='The label of the moderation result.

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live broadcasting in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='Normal'),
            rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
            scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='Antispam'),
            suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
          }
        ](name='Result')
        }(name='Results', description='The moderation results.'),
      }
    ](name='CoverImageCensorResult')
    }(name='CoverImageCensorResults', description='The moderation results of thumbnails.'),
    creationTime?: string(name='CreationTime', description='The time when the content moderation job was created.', example='2018-09-13T16:32:24Z'),
    descCensorResult?: {
      label?: string(name='Label', description='The label of the moderation result. Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='terrorism'),
      rate?: string(name='Rate', description='The score.', example='100'),
      scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='review'),
    }(name='DescCensorResult', description='The moderation results of descriptions.'),
    finishTime?: string(name='FinishTime', description='The time when the content moderation job was complete.', example='2018-09-13T16:38:24Z'),
    input?: {
      bucket?: string(name='Bucket', description='The name of the OSS bucket in which the input file is stored.', example='bucket-test-in-****'),
      location?: string(name='Location', description='The OSS region in which the input file resides.', example='oss-cn-shanghai'),
      object?: string(name='Object', description='The name of the OSS object that is used as the input file.', example='test/ai/censor/test-****.mp4'),
    }(name='Input', description='The information about the job input.'),
    jobId?: string(name='JobId', description='The ID of the content moderation job.', example='f8f166eea7a44e9bb0a4aecf9543****'),
    message?: string(name='Message', description='The error message returned if the job failed. This parameter is not returned if the job is successful.', example='The resource operated cannot be found'),
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the job was submitted.', example='c5b30b7c0d0e4a0abde1d5f9e751****'),
    state?: string(name='State', description='The job state.', example='Success'),
    suggestion?: string(name='Suggestion', description='The overall result of the content moderation job. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.

>  If the moderation result of any type of content is review, the overall result is review. If the moderation result of any type of content is block, the overall result is block.', example='block'),
    titleCensorResult?: {
      label?: string(name='Label', description='The label of the moderation result. Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='meaningless'),
      rate?: string(name='Rate', description='The score.', example='99.91'),
      scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
    }(name='TitleCensorResult', description='The moderation results of titles.'),
    userData?: string(name='UserData', description='The user-defined data.', example='example userdata ****'),
    vensorCensorResult?: {
      censorResults?: {
        censorResult?: [ 
        {
          label?: string(name='Label', description='The label of the moderation result.

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live broadcasting in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='meaningless'),
          rate?: string(name='Rate', description='The score.', example='100'),
          scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='terrorism'),
          suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='review'),
        }
      ](name='CensorResult')
      }(name='CensorResults', description='A collection of moderation results. The information includes the summary about various scenarios such as pornographic content moderation and terrorist content moderation.'),
      nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='ea04afcca7cd4e80b9ece8fbb251****'),
      videoTimelines?: {
        videoTimeline?: [ 
        {
          censorResults?: {
            censorResult?: [ 
            {
              label?: string(name='Label', description='The label of the moderation result.

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live broadcasting in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='flood'),
              rate?: string(name='Rate', description='The score.', example='99.99'),
              scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='porn'),
              suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
            }
          ](name='CensorResult')
          }(name='CensorResults', description='The moderation results that include information such as labels and scores.'),
          object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg`, `output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
          timestamp?: string(name='Timestamp', description='The position in the video. Format: `hh:mm:ss[.SSS]`.', example='00:02:59.999'),
        }
      ](name='VideoTimeline')
      }(name='VideoTimelines', description='The moderation results that are sorted in ascending order by time.'),
    }(name='VensorCensorResult', description='The moderation results of videos.'),
    videoCensorConfig?: {
      bizType?: string(name='BizType', description='The custom business type. Default value: common.', example='common'),
      outputFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket in which the output snapshot is stored.', example='test-bucket-****'),
        location?: string(name='Location', description='The OSS region in which the output snapshot resides.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg`, `output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
      }(name='OutputFile', description='The information about output snapshots.'),
      videoCensor?: string(name='VideoCensor', description='Indicates whether the video content needs to be moderated. Default value: **true**. Valid values:

*   **true**: The video content needs to be moderated.
*   **false**: The video content does not need to be moderated.', example='true'),
    }(name='VideoCensorConfig', description='The video moderation configurations.'),
  }(name='MediaCensorJobDetail', description='The results of the content moderation job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='B42299E6-F71F-465F-8FE9-4FC2E3D3C2CA'),
}

model QueryMediaCensorJobDetailResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryMediaCensorJobDetailResponseBody(name='body'),
}

/**
  * @description In the content moderation results, the moderation results of the video are sorted in ascending order by time into a timeline. If the video is long, the content moderation results are paginated, and the first page is returned. You can call this operation again to query the remaining moderation results of the video.
  * @param request  the request parameters of QueryMediaCensorJobDetail  QueryMediaCensorJobDetailRequest
  * @return QueryMediaCensorJobDetailResponse
 */
async function queryMediaCensorJobDetail(request: QueryMediaCensorJobDetailRequest): QueryMediaCensorJobDetailResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryMediaCensorJobDetail', 'POST', '/', 'json', false, 'json', request);
}

model QueryMediaCensorJobListRequest {
  endOfJobCreatedTimeRange?: string(name='EndOfJobCreatedTimeRange', description='The end of the time range to query.

*   Specify the time in the ISO 8601 standard. The time must be in UTC.
*   Format: yyyy-MM-ddTHH:mm:ssZ.', example='2022-02-14T02:16:07Z', position='Query'),
  jobIds?: string(name='JobIds', description='The IDs of the content moderation jobs. You can obtain the ID of a content moderation job from the response parameters of the SubmitMediaCensorJob operation. Separate multiple IDs with commas (,).', example='fa9c34be3bcf42919ac4d1775239****,78dc866518b843259669df58ed30****', position='Query'),
  maximumPageSize?: long(name='MaximumPageSize', description='The number of entries per page.

*   Default value: **30**.
*   Valid values: **1 to 300**.', example='20', minimum=1, maximum=100, position='Query'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='79aff3eee82242e092899db5f669', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the jobs were submitted.', example='c5b30b7c0d0e4a0abde1d5f9e751****', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  startOfJobCreatedTimeRange?: string(name='StartOfJobCreatedTimeRange', description='The beginning of the time range to query.

*   Specify the time in the ISO 8601 standard. The time must be in UTC.
*   Format: yyyy-MM-ddTHH:mm:ssZ.', example='2021-12-22T03:48:05Z', position='Query'),
  state?: string(name='State', description='The state of the jobs that you want to query. Valid values:

*   **All**: all jobs.
*   **Queuing**: the jobs that are waiting in the queue.
*   **Analysing**: the jobs that are in progress.
*   **Fail**: failed jobs.
*   **Success**: successful jobs.', example='All', position='Query'),
}

model QueryMediaCensorJobListResponseBody = {
  mediaCensorJobList?: {
    mediaCensorJob?: [ 
    {
      barrageCensorResult?: {
        label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,). Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='normal'),
        rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='99.91'),
        scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
        suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
      }(name='BarrageCensorResult', description='The moderation results of live comments.'),
      code?: string(name='Code', description='The error code returned if the job failed. This parameter is not returned if the job is successful.', example='InvalidParameter.ResourceNotFound'),
      coverImageCensorResults?: {
        coverImageCensorResult?: [ 
        {
          bucket?: string(name='Bucket', description='The OSS bucket in which the thumbnail is stored.', example='example-Bucket-****'),
          location?: string(name='Location', description='The OSS region in which the thumbnail resides.', example='oss-cn-shanghai'),
          object?: string(name='Object', description='The Object Storage Service (OSS) object that is used as the thumbnail.', example='test/ai/censor/v2/vme-****.jpg'),
          results?: {
            result?: [ 
            {
              label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,).

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live streaming in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='normal'),
              rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
              scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='live'),
              suggestion?: string(name='Suggestion', description='The overall result of the moderation job. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.

>  If the moderation result of any type of content is review, the overall result is review. If the moderation result of any type of content is block, the overall result is block.', example='pass'),
            }
          ](name='Result')
          }(name='Results', description='The moderation results.'),
        }
      ](name='CoverImageCensorResult')
      }(name='CoverImageCensorResults', description='The moderation results of thumbnails.'),
      creationTime?: string(name='CreationTime', description='The time when the content moderation job was created.', example='2021-11-04T07:25:48Z'),
      descCensorResult?: {
        label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,). Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='normal'),
        rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
        scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
        suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
      }(name='DescCensorResult', description='The moderation results of descriptions.'),
      finishTime?: string(name='FinishTime', description='The time when the content moderation job was complete.', example='2021-11-04T07:25:50Z'),
      input?: {
        bucket?: string(name='Bucket', description='The name of the OSS bucket in which the input file is stored.', example='bucket-test-in-****'),
        location?: string(name='Location', description='The OSS region in which the input file resides.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The name of the OSS object that is used as the input file.', example='test/ai/censor/test-****.mp4'),
      }(name='Input', description='The information about the job input.'),
      jobId?: string(name='JobId', description='The ID of the content moderation job.', example='f8f166eea7a44e9bb0a4aecf9543'),
      message?: string(name='Message', description='The error message returned if the job failed. This parameter is not returned if the job is successful.', example='The resource operated cannot be found'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='c5b30b7c0d0e4a0abde1d5f9e751****'),
      state?: string(name='State', description='The job state.', example='Success'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
      titleCensorResult?: {
        label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,). Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='meaningless'),
        rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
        scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
        suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
      }(name='TitleCensorResult', description='The moderation results of titles.'),
      userData?: string(name='UserData', description='The user-defined data.', example='example userdata ****'),
      vensorCensorResult?: {
        censorResults?: {
          censorResult?: [ 
          {
            label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,).

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live streaming in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='meaningless'),
            rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
            scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='ad'),
            suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
          }
        ](name='CensorResult')
        }(name='CensorResults', description='A collection of moderation results. The information includes the summary about various scenarios such as pornographic content moderation and terrorist content moderation.'),
        nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='ea04afcca7cd4e80b9ece8fbb251'),
        videoTimelines?: {
          videoTimeline?: [ 
          {
            censorResults?: {
              censorResult?: [ 
              {
                label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,).

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live streaming in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='normal'),
                rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
                scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='porn'),
                suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
              }
            ](name='CensorResult')
            }(name='CensorResults', description='The moderation results that include information such as labels and scores.'),
            object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg`, `output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
            timestamp?: string(name='Timestamp', description='The position in the video. Format: `hh:mm:ss[.SSS]`.', example='00:02:59.999'),
          }
        ](name='VideoTimeline')
        }(name='VideoTimelines', description='The moderation results that are sorted in ascending order by time.'),
      }(name='VensorCensorResult', description='The moderation results of videos.'),
      videoCensorConfig?: {
        bizType?: string(name='BizType', description='The moderation template. Default value: common. The default value indicates that the default template is used.

>  If the moderation template is not specified, the default value common is returned. If a custom moderation template that is created by submitting a ticket is specified, the UID of the template is returned.', example='common'),
        outputFile?: {
          bucket?: string(name='Bucket', description='The OSS bucket in which the output snapshot is stored.', example='test-bucket-****'),
          location?: string(name='Location', description='The ID of the region in which the output snapshot resides.', example='oss-cn-shanghai'),
          object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg, output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
        }(name='OutputFile', description='The information about output snapshots.'),
        videoCensor?: string(name='VideoCensor', description='Indicates whether the video content needs to be moderated. Default value: **true**. Valid values:

*   **true**: The video content needs to be moderated.
*   **false**: The video content does not need to be moderated.', example='true'),
      }(name='VideoCensorConfig', description='The video moderation configurations.'),
    }
  ](name='MediaCensorJob')
  }(name='MediaCensorJobList', description='The queried content moderation jobs.'),
  nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. The value is 32-character UUID. If the returned query results cannot be displayed within one page, this parameter is returned. The value of this parameter is updated for each query.', example='9b1a42bc6e8d46e6a1383b7e7f01****'),
  nonExistIds?: {
    string?: [ string ](name='String')
  }(name='NonExistIds', description='The IDs of the jobs that do not exist. This parameter is not returned if all the specified jobs are found.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D1D5C080-8E2F-5030-8AB4-13092F17631B'),
}

model QueryMediaCensorJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryMediaCensorJobListResponseBody(name='body'),
}

/**
  * @description You can call this operation to query only the content moderation jobs within the most recent three months.
  * @param request  the request parameters of QueryMediaCensorJobList  QueryMediaCensorJobListRequest
  * @return QueryMediaCensorJobListResponse
 */
async function queryMediaCensorJobList(request: QueryMediaCensorJobListRequest): QueryMediaCensorJobListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryMediaCensorJobList', 'POST', '/', 'json', false, 'json', request);
}

model QueryMediaIndexJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='c2e77390f75271ec802f0674a2ce6***', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1', position='Query'),
}

model QueryMediaIndexJobResponseBody = {
  code?: string(name='Code', description='The response code.', example='200'),
  indexJobInfoList?: [ 
    {
      gmtFinish?: string(name='GmtFinish', description='The end time of the indexing job.', example='2023-11-21 11:33:51'),
      gmtSubmit?: string(name='GmtSubmit', description='The time when the index job was submitted.', example='2023-11-21 11:33:50'),
      indexType?: string(name='IndexType', description='The index type. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.', example='mm'),
      status?: string(name='Status', description='The job status. Valid values:

*   Running
*   Success
*   Fail', example='Success'),
    }
  ](name='IndexJobInfoList', description='The indexing jobs enabled for the media asset.'),
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model QueryMediaIndexJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryMediaIndexJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QueryMediaIndexJob  QueryMediaIndexJobRequest
  * @return QueryMediaIndexJobResponse
 */
async function queryMediaIndexJob(request: QueryMediaIndexJobRequest): QueryMediaIndexJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryMediaIndexJob', 'POST', '/', 'json', false, 'json', request);
}

model QuerySearchIndexRequest {
  regionId?: string(name='RegionId', position='Host'),
  indexType: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.

This parameter is required.', example='mm', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

*   If you leave this parameter empty, the search index is created in the default search library of Intelligent Media Service (IMS). Default value: ims-default-search-lib.
*   To query information about an existing search library, call the [QuerySearchLib](https://help.aliyun.com/document_detail/2584455.html) API operation.', example='test1', position='Query'),
}

model QuerySearchIndexResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  indexStatus?: string(name='IndexStatus', description='The state of the index. Valid values:

*   active: the index is enabled.
*   Deactive: the index is not enabled.', example='Active'),
  indexType?: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.', example='mm'),
  mediaTotal?: string(name='MediaTotal', description='The total number of media assets.', example='12'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model QuerySearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QuerySearchIndexResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QuerySearchIndex  QuerySearchIndexRequest
  * @return QuerySearchIndexResponse
 */
async function querySearchIndex(request: QuerySearchIndexRequest): QuerySearchIndexResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QuerySearchIndex', 'POST', '/', 'json', false, 'json', request);
}

model QuerySearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  searchLibName: string(name='SearchLibName', description='The name of the search library.

This parameter is required.', example='test1', position='Query'),
}

model QuerySearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  indexInfo?: [ 
    {
      indexReadiness?: string(name='IndexReadiness'),
      indexStatus?: string(name='IndexStatus'),
      indexType?: string(name='IndexType'),
    }
  ](name='IndexInfo'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
  status?: string(name='Status', description='The status of the search library.

Valid values:

*   normal
*   deleting
*   deleteFail', example='normal'),
  success?: string(name='Success', description='Indicates whether the call was successful. Valid values:

*   true
*   false', example='true'),
}

model QuerySearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QuerySearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QuerySearchLib  QuerySearchLibRequest
  * @return QuerySearchLibResponse
 */
async function querySearchLib(request: QuerySearchLibRequest): QuerySearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QuerySearchLib', 'POST', '/', 'json', false, 'json', request);
}

model QuerySmarttagJobRequest {
  jobId: string(name='JobId', description='The ID of the smart tagging job that you want to query. You can obtain the job ID from the response parameters of the SubmitSmarttagJob operation.

This parameter is required.', example='88c6ca184c0e47098a5b665e2****', position='Query'),
  params?: string(name='Params', description='The extra parameters that you want to query in the request. The value is a JSON string. Example: {"labelResultType":"auto"}. The value of labelResultType is of the STRING type. Valid values:

*   auto: machine tagging
*   hmi: tagging by human and machine', example='{"labelResultType":"auto"}', position='Query'),
}

model QuerySmarttagJobResponseBody = {
  jobStatus?: string(name='JobStatus', description='The status of the job. Valid values:

*   **Success**: The job was successful.
*   **Fail**: The job failed.
*   **Processing**: The job is in progress.
*   **Submitted**: The job is submitted and waiting to be processed.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  results?: {
    result?: [ 
    {
      data?: string(name='Data', description='The details of the analysis result. The value is a JSON string. For more information about the parameters of different result types, see the "Parameters of different result types" section of this topic.', example='{"title":"example-title-****"}'),
      type?: string(name='Type', description='The type of the analysis result.

*   The type of the analysis result based on Smart tagging V1.0. Valid values:

1.  TextLabel: the text tag.
2.  VideoLabel: the video tag.
3.  ASR: the original result of automatic speech recognition (ASR). By default, this type of result is not returned.
4.  OCR: the original result of optical character recognition (OCR). By default, this type of result is not returned.
5.  NLP: the natural language processing (NLP)-based result. By default, this type of result is not returned.

*   The type of the analysis result based on Smart tagging V2.0. Valid values:

1.  CPVLabel
2.  Meta: the information about the video file, such as the title of the video. By default, this type of information is not returned.

*   The type of the analysis result based on Smart tagging V2.0-custom. Valid values:

1.  CPVLabel
2.  Meta: the information about the video file, such as the title of the video. By default, this type of information is not returned.', example='Meta'),
    }
  ](name='Result')
  }(name='Results', description='The analysis results of the smart tagging job. The value is an array.'),
  userData?: string(name='UserData', description='The content of callback messages that are sent to Simple Message Queue (SMQ) when the information of the smart tagging job changes. For more information about the parameters contained in the callback message, see the "Callback parameters" section of this topic.', example='{"userId":"123432412831"}'),
}

model QuerySmarttagJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QuerySmarttagJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QuerySmarttagJob  QuerySmarttagJobRequest
  * @return QuerySmarttagJobResponse
 */
async function querySmarttagJob(request: QuerySmarttagJobRequest): QuerySmarttagJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QuerySmarttagJob', 'POST', '/', 'json', false, 'json', request);
}

model QueryTraceAbJobListRequest {
  createTimeEnd?: long(name='CreateTimeEnd', description='The end of the creation time range for the query, in UNIX timestamp format.', example='1627357325', position='Query'),
  createTimeStart?: long(name='CreateTimeStart', description='The start of the creation time range for the query, in UNIX timestamp format.', example='1627357322', position='Query'),
  jobId?: string(name='JobId', description='The job ID. You can obtain the value of this parameter from the response of the SubmitTraceAbJob operation.', example='****d80e4e4044975745c14b****', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number.', example='0', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries to return on each page.', example='10', position='Query'),
  traceMediaId?: string(name='TraceMediaId', description='The media ID for the trace watermark. You can obtain this from the response of the SubmitTraceAbJob operation.', example='****437bd2b51105d07b12a9****', position='Query'),
}

model QueryTraceAbJobListResponseBody = {
  data?: [ 
    {
      gmtCreate?: long(name='GmtCreate', description='The creation time of the job.', example='1627357322'),
      gmtModified?: long(name='GmtModified', description='The last modification time of the job.', example='1627357322'),
      input?: {
        media?: string(name='Media', description='The specific input file information.', example='oss://bucket/object'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
      }(name='Input', description='Information about the input video for watermarking.'),
      jobId?: string(name='JobId', description='The job ID.', example='bfb786c639894f4d80648792021eff90'),
      level?: long(name='Level', description='The watermark level.', example='2'),
      output?: {
        media?: string(name='Media', description='The output directory.', example='oss://bucket/dir/'),
        type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.', example='OSS'),
      }(name='Output', description='Information about the output path for the A/B stream.'),
      result?: string(name='Result', description='The job result.', example='{"Code":"success","Message":"ok"}'),
      status?: string(name='Status', description='The status of the job.', example='success'),
      traceMediaId?: string(name='TraceMediaId', description='The media ID for the trace watermark.', example='****437bd2b51105d07b12a9****'),
      userData?: string(name='UserData', description='The user-defined data.', example='123'),
      userId?: long(name='UserId', description='The ID of the user who initiated the job.', example='13466932****'),
    }
  ](name='Data', description='The data returned.'),
  message?: string(name='Message', description='The message returned.', example='ok'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  statusCode?: long(name='StatusCode', description='The status code.', example='200'),
}

model QueryTraceAbJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryTraceAbJobListResponseBody(name='body'),
}

/**
  * @description *   This operation is supported only in the China (Shanghai) and China (Beijing) regions.
  * @param request  the request parameters of QueryTraceAbJobList  QueryTraceAbJobListRequest
  * @return QueryTraceAbJobListResponse
 */
async function queryTraceAbJobList(request: QueryTraceAbJobListRequest): QueryTraceAbJobListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryTraceAbJobList', 'POST', '/', 'json', false, 'json', request);
}

model QueryTraceExtractJobRequest {
  jobId: string(name='JobId', description='The job ID. You can obtain the value of this parameter from the response of the SubmitTraceExtractJob operation.

This parameter is required.', example='31fa3c9ca8134fb4b0b0f7878301****', position='Query'),
}

model QueryTraceExtractJobResponseBody = {
  data?: {
    trace?: string(name='Trace', description='The trace watermark information.'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The message returned.', example='ok'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  statusCode?: long(name='StatusCode', description='The status code.', example='200'),
}

model QueryTraceExtractJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryTraceExtractJobResponseBody(name='body'),
}

/**
  * @description This operation is supported only in the China (Shanghai) and China (Beijing) regions.
  * @param request  the request parameters of QueryTraceExtractJob  QueryTraceExtractJobRequest
  * @return QueryTraceExtractJobResponse
 */
async function queryTraceExtractJob(request: QueryTraceExtractJobRequest): QueryTraceExtractJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryTraceExtractJob', 'POST', '/', 'json', false, 'json', request);
}

model QueryTraceM3u8JobListRequest {
  createTimeEnd?: long(name='CreateTimeEnd', description='The end of the creation time range for the query, in UNIX timestamp format.', example='1627357325', position='Query'),
  createTimeStart?: long(name='CreateTimeStart', description='The start of the creation time range for the query, in UNIX timestamp format.', example='1627357322', position='Query'),
  jobId?: string(name='JobId', description='The job ID. You can obtain the value of this parameter from the response of the SubmitTraceM3u8Job operation.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number.', example='0', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries to return on each page.', example='10', position='Query'),
}

model QueryTraceM3u8JobListResponseBody = {
  data?: [ 
    {
      gmtCreate?: long(name='GmtCreate', description='The creation time of the job.', example='1627357322'),
      gmtModified?: long(name='GmtModified', description='The last modification time of the job.', example='1627357322'),
      jobId?: string(name='JobId', description='The job ID.', example='****d718e2ff4f018ccf419a7b71****'),
      output?: {
        media?: string(name='Media', description='The specific output information.', example='oss://bucket/object'),
        type?: string(name='Type', description='The type of the output file. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
      }(name='Output', description='The output video.'),
      status?: string(name='Status', description='The current status of the job.', example='success'),
      trace?: string(name='Trace', description='The watermark information.', example='test'),
      traceMediaId?: string(name='TraceMediaId', description='The media ID for the trace watermark.', example='****437bd2b105d07b12a9a82****'),
      userData?: string(name='UserData', description='The user-defined data.', example='112'),
      userId?: long(name='UserId', description='The ID of the user who initiated the job.', example='1346693276****'),
    }
  ](name='Data', description='The data returned.'),
  message?: string(name='Message', description='The message returned.', example='ok'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  statusCode?: long(name='StatusCode', description='The status code.', example='200'),
}

model QueryTraceM3u8JobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryTraceM3u8JobListResponseBody(name='body'),
}

/**
  * @description *   This operation is supported only in the China (Shanghai) and China (Beijing) regions.
  * *   The M3U8 file with absolute paths generated by the SubmitTraceM3u8Job API has a signed URL with an authentication validity period of 24 hours, starting from the moment the job is completed. After the signature expires, the M3U8 file will become inaccessible. You must submit a new M3U8 generation job.
  * @param request  the request parameters of QueryTraceM3u8JobList  QueryTraceM3u8JobListRequest
  * @return QueryTraceM3u8JobListResponse
 */
async function queryTraceM3u8JobList(request: QueryTraceM3u8JobListRequest): QueryTraceM3u8JobListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryTraceM3u8JobList', 'POST', '/', 'json', false, 'json', request);
}

model QueryVideoCognitionJobRequest {
  includeResults?: {
    needAsr?: boolean(name='NeedAsr', description='Specifies whether to include Automatic Speech Recognition (ASR) results.', example='true'),
    needOcr?: boolean(name='NeedOcr', description='Specifies whether to include Optical Character Recognition (OCR) results.', example='true'),
    needProcess?: boolean(name='NeedProcess', description='Specifies whether to include the URL to the raw output of the algorithm.', example='true'),
  }(name='IncludeResults', description='Specifies whether to include the full algorithm results in the response.', shrink='json', position='Query'),
  jobId: string(name='JobId', description='The ID of the task to query. It is returned when you call the [SubmitSmarttagJob](https://help.aliyun.com/document_detail/478786.html) operation.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  params?: string(name='Params', description='Additional request parameters, provided as a JSON string.', example='{}', position='Query'),
}

model QueryVideoCognitionJobResponseBody = {
  jobStatus?: string(name='JobStatus', description='The status of the task. Valid values:

*   **Success**
*   **Fail**
*   **Processing**
*   **Submitted**', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  results?: {
    result?: [ 
    {
      data?: string(name='Data', description='A JSON string containing the detailed analysis data. The structure of this data depends on the Type field. For details, see the Result parameters section below.', example='{"title":"example-title-****"}'),
      type?: string(name='Type', description='The type of analysis result. Valid values:

1.  TextLabel: Tags from text content.
2.  VideoLabel: Tags from video content.
3.  ASR: Raw speech recognition results. Not returned by default.
4.  OCR: Raw text recognition results. Not returned by default.
5.  NLP: Natural Language Processing results. Not returned by default.
6.  Process: URL to the raw algorithm output. Not returned by default.', example='ASR'),
    }
  ](name='result')
  }(name='Results', description='An array of analysis result objects.'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"userId":"123432412831"}'),
}

model QueryVideoCognitionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryVideoCognitionJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of QueryVideoCognitionJob  QueryVideoCognitionJobRequest
  * @return QueryVideoCognitionJobResponse
 */
async function queryVideoCognitionJob(request: QueryVideoCognitionJobRequest): QueryVideoCognitionJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'QueryVideoCognitionJob', 'POST', '/', 'json', false, 'json', request);
}

model RefreshUploadMediaRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***', position='Query'),
}

model RefreshUploadMediaResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='c2e77390f75271ec802f0674a2ce6***'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  uploadAddress?: string(name='UploadAddress', description='The upload URL.

>  The returned upload URL is a Base64-encoded URL. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAddress only if you use Object Storage Service (OSS) SDK or call an OSS API operation to upload media files.', example='eyJFbmRwb2ludCI6Imh0dHBzOi8vb3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbSIsIkJ1Y2tldCI6InN6aGQtdmlkZW8iLCJGaWxlTmFtZSI6InZvZC0yOTYzMWEvc3YvNTBmYTJlODQtMTgxMjdhZGRiMTcvNTBmYTJlODQtMTgxMjdhZGRiM***'),
  uploadAuth?: string(name='UploadAuth', description='The upload credential.

>  The returned upload credential is a Base64-encoded value. You must decode the Base64-encoded upload credential before you use an SDK or call an API operation to upload media files. You need to parse UploadAuth only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJBY2Nlc3NLZXlJZCI6IkxUQUk0Rm53bTk1dHdxQjMxR3IzSE5hRCIsIkFjY2Vzc0tleVNlY3JldCI6Ik9lWllKR0dTMTlkNkZaM1E3UVpJQmdmSVdnM3BPaiIsIkV4cGlyYXRpb24iOiI***'),
}

model RefreshUploadMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RefreshUploadMediaResponseBody(name='body'),
}

/**
  * @description You can also call this operation to overwrite media files. After you obtain the upload URL of a media file, you can upload the media file again without changing the audio or video ID.
  * @param request  the request parameters of RefreshUploadMedia  RefreshUploadMediaRequest
  * @return RefreshUploadMediaResponse
 */
async function refreshUploadMedia(request: RefreshUploadMediaRequest): RefreshUploadMediaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RefreshUploadMedia', 'POST', '/', 'json', false, 'json', request);
}

model RegisterMediaInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  businessType?: string(name='BusinessType', description='The business type of the media asset. Valid values:

*   subtitles
*   watermark
*   opening
*   ending
*   general', example='opening', position='Query'),
  cateId?: long(name='CateId', description='The category ID.', example='3048', position='Query'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request. The value must be a UUID that contains 32 characters.', example='****0311a423d11a5f7dee713535****', position='Query'),
  coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png', position='Query'),
  description?: string(name='Description', description='The description of the media asset.

*   The value can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultDescription', position='Query'),
  inputURL: string(name='InputURL', description='The URL of the media asset in another service. The URL is associated with the ID of the media asset in IMS. The URL cannot be modified once registered. The following types of URLs are supported:

*   OSS URL in one of the following formats:

http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4

oss://example-bucket/example.mp4: In this format, it is considered by default that the region of the OSS bucket in which the media asset resides is the same as the region in which IMS is activated.

*   URL of an ApsaraVideo VOD media asset

vod://\\*\\*\\*20b48fb04483915d4f2cd8ac\\*\\*\\*\\*

This parameter is required.', position='Query'),
  mediaTags?: string(name='MediaTags', description='The tags of the media asset.

*   Up to 16 tags are supported.
*   Separate multiple tags with commas (,).
*   Each tag can be up to 32 bytes in length.
*   The value must be encoded in UTF-8.', example='tag1,tag2', position='Query'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

*   image
*   video
*   audio
*   text

We recommend that you specify this parameter based on your business requirements. If you set InputURL to an OSS URL, the media asset type can be automatically determined based on the file name extension. For more information
<props="china">, see [File formats](https://help.aliyun.com/document_detail/466207.html).', example='video', position='Query'),
  overwrite?: boolean(name='Overwrite', description='Specifies whether to overwrite the media asset that has been registered by using the same URL. Default value: false. Valid values:

\\- true: If a media asset has been registered by using the same URL, the original media asset is deleted and the new media asset is registered.

\\- false: If a media asset has been registered by using the same URL, the new media asset is not registered. A URL cannot be used to register multiple media assets.', example='true', position='Query'),
  referenceId?: string(name='ReferenceId', description='The custom ID. The ID can be 6 to 64 characters in length and can contain only letters, digits, hyphens (-), and underscores (_). Make sure that the ID is unique among users.', example='123-123', position='Query'),
  registerConfig?: string(name='RegisterConfig', description='The registration configurations.

By default, a sprite is generated for the media asset. You can set NeedSprite to false to disable automatic sprite generation.

By default, a snapshot is generated for the media asset. You can set NeedSnapshot to false to disable automatic snapshot generation.', example='{
      "NeedSprite": "false"
}', position='Query'),
  smartTagTemplateId?: string(name='SmartTagTemplateId', description='The ID of the smart tagging template. Valid values:

*   S00000101-300080: the system template that supports natural language processing (NLP) for content recognition.
*   S00000103-000001: the system template that supports NLP for content recognition and all tagging capabilities.
*   S00000103-000002: the system template that supports all tagging capabilities but does not support NLP for content recognition.

After you configure this parameter, a smart tag analysis task is automatically initiated after the media asset is registered. For more information about the billable items<props="china">, see [Smart tagging](https://help.aliyun.com/zh/ims/media-ai-billing?spm=a2c4g.11186623.0.0.3147392dWwlSjL#p-k38-3rb-dug).', example='S00000101-300080', position='Query'),
  title?: string(name='Title', description='The title. If you do not specify this parameter, a default title is automatically generated based on the date.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultTitle', position='Query'),
  userData?: string(name='UserData', description='The user data. You can specify a custom callback URL. For more information<props="china"> ,see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).

*   The value can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.
*   The value must be in the JSON format.', position='Query'),
  workflowId?: string(name='WorkflowId', description='The workflow ID.', example='******b4fb044839815d4f2cd8******', position='Query'),
}

model RegisterMediaInfoResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset in IMS.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The request ID.', example='******5A-CAAC-4850-A3AF-B74606******'),
}

model RegisterMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RegisterMediaInfoResponseBody(name='body'),
}

/**
  * @description Registering a media asset is an asynchronous job that takes 2 to 3 seconds. When the operation returns the ID of the media asset, the registration may have not be completed. If you call the GetMediaInfo operation at this time, you may fail to obtain the information about the media asset.
  * @param request  the request parameters of RegisterMediaInfo  RegisterMediaInfoRequest
  * @return RegisterMediaInfoResponse
 */
async function registerMediaInfo(request: RegisterMediaInfoRequest): RegisterMediaInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RegisterMediaInfo', 'POST', '/', 'json', false, 'json', request);
}

model RegisterMediaStreamRequest {
  regionId?: string(name='RegionId', position='Host'),
  inputURL?: string(name='InputURL', description='The URL of the media asset in another service. The URL is associated with the ID of the media asset in IMS. The URL cannot be modified once registered.

Set this parameter to the OSS URL of the media asset. The following formats are supported:

http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4

oss://example-bucket/example.mp4: In this format, it is considered by default that the region of the OSS bucket in which the media asset resides is the same as the region in which IMS is activated.', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='5e778ec0027b71ed80a8909598506***', position='Query'),
  streamTags?: string(name='StreamTags', position='Query'),
  userData?: string(name='UserData', description='The user data.', example='{"MessageCallback":{"CallbackURL":"http://test.test.com"}, "Extend":{"localId":"xxx","test":"www"}}', position='Query'),
}

model RegisterMediaStreamResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='5e778ec0027b71ed80a8909598506302'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model RegisterMediaStreamResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RegisterMediaStreamResponseBody(name='body'),
}

/**
  * @description You can call this operation to register a media stream file in an Object Storage Service (OSS) bucket with Intelligent Media Services (IMS) and associate the media stream with the specified media asset ID.
  * @param request  the request parameters of RegisterMediaStream  RegisterMediaStreamRequest
  * @return RegisterMediaStreamResponse
 */
async function registerMediaStream(request: RegisterMediaStreamRequest): RegisterMediaStreamResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RegisterMediaStream', 'POST', '/', 'json', false, 'json', request);
}

model ResumeMediaConnectFlowOutputRequest {
  flowId?: string(name='FlowId', description='The ID of the MediaConnect flow.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f', position='Query'),
  outputName?: string(name='OutputName', description='The name of the output.', example='AliTestOutput', position='Query'),
}

model ResumeMediaConnectFlowOutputResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model ResumeMediaConnectFlowOutputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ResumeMediaConnectFlowOutputResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ResumeMediaConnectFlowOutput  ResumeMediaConnectFlowOutputRequest
  * @return ResumeMediaConnectFlowOutputResponse
 */
async function resumeMediaConnectFlowOutput(request: ResumeMediaConnectFlowOutputRequest): ResumeMediaConnectFlowOutputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ResumeMediaConnectFlowOutput', 'POST', '/', 'json', false, 'json', request);
}

model SearchEditingProjectRequest {
  createSource?: string(name='CreateSource', description='The source of the project.

\\-OpenAPI

\\-AliyunConsole

\\-WebSDK

Valid values:

*   AliyunConsole: The project is created in the Alibaba Cloud console.
*   WebSDK: The project is created by using the SDK for Web.
*   OpenAPI: The project is created by calling API operations.', example='WebSDK', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-01-11T12:00:00Z', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10', position='Query'),
  projectType?: string(name='ProjectType', description='The type of the editing project. Default value: EditingProject. Valid values:

*   EditingProject: a regular editing project.
*   LiveEditingProject: a live stream editing project.', example='EditingProject', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting rule of results. Valid values:

\\- CreationTime:Desc (default): The results are sorted in reverse chronological order based on the creation time.

\\- CreationTime:Asc: The results are sorted in chronological order based on the creation time.', example='CreationTime:Desc', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-01-11T12:00:00Z', position='Query'),
  status?: string(name='Status', description='The status of the online editing project. Separate multiple values with commas (,). By default, all online editing projects are queried.

Valid values:

\\-Draft

\\-Producing

\\-Produced

\\-ProduceFailed', example='Producing', position='Query'),
  templateType?: string(name='TemplateType', description='The template type. Valid values:

\\-Timeline

\\-VETemplate

Valid values:

*   Timeline: regular template.
*   VETemplate: advanced template.
*   None: No template is used.', example='Timeline', position='Query'),
}

model SearchEditingProjectResponseBody = {
  maxResults?: long(name='MaxResults', description='The maximum number of entries returned on a single page. The value is set to the maximum number of entries returned on each page except for the last page.

Examples:

Valid example: 10,10,5. Invalid example: 10,5,10.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='null'),
  projectList?: [ 
    {
      businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{ "OutputMediaConfig" : { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path" }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
      businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

Valid values:

*   BroadCasting:
*   ReservationCanceled
*   LiveFinished
*   LoadingFailed
*   Reserving', example='Reserving'),
      coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example-cover.jpg'),
      createSource?: string(name='CreateSource', description='The method for editing the online editing project.

\\-OpenAPI

\\-AliyunConsole

\\-WebSDK

Valid values:

*   AliyunConsole: The project is created in the Alibaba Cloud console.
*   WebSDK: The project is created by using the SDK for Web.
*   OpenAPI: The project is created by calling API operations.', example='OpenAPI'),
      createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2017-01-11T12:00:00Z'),
      description?: string(name='Description', description='The description of the online editing project.', example='sample description'),
      duration?: long(name='Duration', description='The total length of the online editing project. Unit: seconds.', example='30.100000'),
      errorCode?: string(name='ErrorCode', description='The error code returned if the production of the online editing project failed.', example='InvalidParameter'),
      errorMessage?: string(name='ErrorMessage', description='The error message returned if the production of the online editing project failed.', example='"EventTime":"2021-08-12T10:04:15Z","ErrorCode":"InvalidParameter","ErrorMessage":"The specified parameter \\"LiveStreamConfig\\" is not valid. specified parameter example is not valid.'),
      modifiedSource?: string(name='ModifiedSource', description='The method used when the online editing project was last modified.', example='2017-01-11T12:00:00Z'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last modified.', example='2017-01-11T12:00:00Z'),
      projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fddd7748b58bf1d47e95****'),
      projectType?: string(name='ProjectType', description='The type of the editing project.

Valid values:

*   LiveEditingProject: a live stream editing project.
*   EditingProject: a regular editing project.', example='EditingProject'),
      status?: string(name='Status', description='The status of the online editing project. Valid values:

\\-Draft

\\-Editing

\\-Producing

\\-Produced

\\-ProduceFailed

Valid values:

*   Draft
*   Produced
*   Editing
*   Producing
*   ProduceFailed', example='PRODUCE_FAILED'),
      templateType?: string(name='TemplateType', description='The type of the template.', example='Timeline'),
      timeline?: string(name='Timeline', description='The timeline of the online editing project.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
      title?: string(name='Title', description='The title of the online editing project.', example='title'),
    }
  ](name='ProjectList', description='The queried online editing projects.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****9262E3DA-07FA-4862-FCBB6BC61D08*****'),
  totalCount?: long(name='TotalCount', description='Optional. The total number of entries returned. By default, this parameter is not returned.', example='110'),
}

model SearchEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchEditingProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SearchEditingProject  SearchEditingProjectRequest
  * @return SearchEditingProjectResponse
 */
async function searchEditingProject(request: SearchEditingProjectRequest): SearchEditingProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchEditingProject', 'POST', '/', 'json', false, 'json', request);
}

model SearchIndexJobRerunRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaIds: string(name='MediaIds', description='The ID of the media asset. Separate multiple IDs with commas (,).

This parameter is required.', example='******b48fb04483915d4f2cd8******,******c48fb37407365d4f2cd8******', position='Query'),
  namespace?: string(name='Namespace', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='test-1', position='Query'),
  task?: string(name='Task', description='The type of the job. Separate multiple types with commas (,).

*   aiLabel: smart tagging.
*   face: face recognition.
*   mm: large visual model.', example='AiLabel,Face,Mm', position='Query'),
}

model SearchIndexJobRerunResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  data?: {
    mediaIdsNoExist?: [ string ](name='MediaIdsNoExist', description='The media asset IDs that do not exist.'),
  }(name='Data', description='The response data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request is successful. Valid values:

*   true
*   false', example='true'),
}

model SearchIndexJobRerunResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchIndexJobRerunResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SearchIndexJobRerun  SearchIndexJobRerunRequest
  * @return SearchIndexJobRerunResponse
 */
async function searchIndexJobRerun(request: SearchIndexJobRerunRequest): SearchIndexJobRerunResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchIndexJobRerun', 'POST', '/', 'json', false, 'json', request);
}

model SearchMediaRequest {
  regionId?: string(name='RegionId', position='Host'),
  customFilters?: string(name='CustomFilters', example='{}', position='Query'),
  entityId?: string(name='EntityId', description='The ID of the entity.', example='2d3bf1e35a1e42b5ab338d701efa7603', position='Query'),
  match?: string(name='Match', description='The filter conditions. For more information about the parameter syntax
<props="china">, see [Media asset search protocols](https://help.aliyun.com/document_detail/2584256.html).', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='20', position='Query'),
  scrollToken?: string(name='ScrollToken', description='The pagination identifier. The value can be up to 32 characters in length. The first time you call this operation for each new search, you do not need to specify this parameter. The value of this parameter is returned each time data records that meet the specified filter condition are found. The value is used to record the current position of queried data. Record the returned parameter value and set this parameter according to the following requirements during the next search: If you need to traverse all data that meets the filter criteria, you must set the ScrollToken parameter. If the value of the PageNo parameter exceeds 200, we recommend that you set this parameter to optimize search performance. You can only page backward. You can page a maximum of 1,000 entries in an operation.', example='F8C4F642184DBDA5D93907A70AAE****', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='test-1', position='Query'),
  sortBy?: string(name='SortBy', description='The sort field and order. Separate multiple parameters with commas (,).', example='utcCreate:Desc, utcModified:Desc', position='Query'),
}

model SearchMediaResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaInfoList?: [ 
    {
      aiData?: {
        aiLabelInfo?: [ 
          {
            category?: string(name='Category', description='The category.'),
            faceId?: string(name='FaceId', description='The face ID.', example='5FE19530C7A422197535FE74F5DB2B9F'),
            labelId?: string(name='LabelId', description='The ID of the entity.', example='10310250338'),
            labelName?: string(name='LabelName', description='The name of the entity.'),
            labelType?: string(name='LabelType', description='The type of the tag.'),
            occurrences?: [ 
              {
                content?: string(name='Content', description='The text content.'),
                finegrainId?: string(name='FinegrainId', description='The fine-grained ID of the entity.', example='10310250338'),
                finegrainName?: string(name='FinegrainName', description='The fine-grained name of the entity.'),
                from?: double(name='From', description='The start time of the clip.', example='1.4'),
                image?: string(name='Image', description='The optimal face image encoded in Base64.', example='99C64F6287'),
                score?: double(name='Score', description='The score.', example='0.75287705'),
                tableBatchSeqId?: string(name='TableBatchSeqId', description='The sequence ID of the vector table.', example='85010D1'),
                to?: double(name='To', description='The end time of the clip.', example='2.5'),
                tracks?: [ 
                  {
                    position?: string(name='Position', description='The coordinates of the bounding box.', example='468.0;67.0;615.0;267.0'),
                    size?: double(name='Size', description='The size of the bounding box.', example='50.2'),
                    timestamp?: double(name='Timestamp', description='The timestamp of the track.', example='1.4'),
                  }
                ](name='Tracks', description='The track sequence.'),
                clipId?: string(name='clipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB2B9F'),
              }
            ](name='Occurrences', description='The clips.'),
            source?: string(name='Source', description='The source.', example='vision'),
          }
        ](name='AiLabelInfo', description='The tags of the intelligent AI job.'),
        asrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB2B9F'),
            content?: string(name='Content', description='The text content.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='AsrInfo', description='The information about audio files.'),
        ocrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB2B9F'),
            content?: string(name='Content', description='The text content.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='OcrInfo', description='The subtitles.'),
      }(name='AiData', description='The details of the intelligent AI job.'),
      aiRoughData?: {
        aiCategory?: string(name='AiCategory', description='TV Series', example='TV series'),
        aiJobId?: string(name='AiJobId', description='The ID of the AI job.', example='cd35b0b0025f71edbfcb472190a9xxxx'),
        result?: string(name='Result', description='The results of the AI job.', example='http://xxxx.json'),
        saveType?: string(name='SaveType', description='The save type.', example='TEXT'),
        status?: string(name='Status', description='The data status.', example='SaveSuccess'),
      }(name='AiRoughData', description='The description of the AI job.'),
      customFields?: string(name='CustomFields', example='{}'),
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate of the file.', example='1912.13'),
            createTime?: string(name='CreateTime', description='The time when the file was created.', example='2022-05-30T02:02:17Z'),
            duration?: string(name='Duration', description='The duration of the file.', example='60.00000'),
            fileName?: string(name='FileName', description='The name of the file.', example='164265080291300080527050.wav'),
            fileSize?: string(name='FileSize', description='The size of the file in bytes.', example='324784'),
            fileStatus?: string(name='FileStatus', description='The status of the file.', example='Normal'),
            fileType?: string(name='FileType', description='The type of the file.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='https://outin-d3f4681ddfd911ec99a600163e1403e7.oss-cn-shanghai.aliyuncs.com/sv/23d5cdd1-18180984899/23d5cdd1-18180984899.mp4'),
            formatName?: string(name='FormatName', description='The encapsulation format of the file.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height of the file.', example='480'),
            imagesInput?: string(name='ImagesInput'),
            modifiedTime?: string(name='ModifiedTime', description='The time when the file was last modified.', example='2021-12-10T12:19Z'),
            region?: string(name='Region', description='The region in which the file is stored.', example='cn-beijing'),
            width?: string(name='Width', description='The width of the file.', example='1920'),
          }(name='FileBasicInfo', description='The basic information about the file, such as the duration and size.'),
        }
      ](name='FileInfoList', description='The information about the files.'),
      indexStatusList?: [ 
        {
          indexStatus?: string(name='IndexStatus', example='Success'),
          indexType?: string(name='IndexType', example='mm'),
        }
      ](name='IndexStatusList'),
      mediaBasicInfo?: {
        biz?: string(name='Biz', description='The business to which the media asset belongs.', example='IMS'),
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='opening'),
        cateId?: long(name='CateId', description='The ID of the category.', example='44'),
        cateName?: string(name='CateName', description='The name of the category.'),
        category?: string(name='Category', description='The category of the media asset.', example='image'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='https://dtlive-bj.oss-cn-beijing.aliyuncs.com/cover/e694372e-4f5b-4821-ae09-efd064f27b63_large_cover_url.jpg'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-01T19:48Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-01T19:48Z'),
        description?: string(name='Description', description='The description of the media asset.'),
        inputURL?: string(name='InputURL', description='The address of the media asset that is waiting to be registered.', example='oss://clipres/longvideo/material/voice/prod/20220418/07d7c799f6054dc3bbef250854cf84981650248140427'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='132bd600fc3c71ec99476732a78f6402'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='tags,tags2'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was modified.', example='2020-12-01T19:48Z'),
        namespace?: string(name='Namespace'),
        referenceId?: string(name='ReferenceId', description='The custom ID of the media asset. The ID is a string that contains 6 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are supported. Each custom ID is unique.', example='123-123'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='[{"bucket":"example-bucket","count":"3","iceJobId":"******f48f0e4154976b2b8c45******","location":"oss-cn-beijing","snapshotRegular":"example.jpg","templateId":"******e6a6440b29eb60bd7c******"}]'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The image sprite of the media asset', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
        status?: string(name='Status', description='The state of the media asset.', example='Normal'),
        streamStatus?: string(name='StreamStatus', example='Active'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        uploadSource?: string(name='UploadSource', description='The upload source of the media asset.', example='general'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
        visionDescription?: string(name='VisionDescription'),
      }(name='MediaBasicInfo', description='The basic information about the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='3b187b3620c8490886cfc2a9578c3ce6'),
    }
  ](name='MediaInfoList', description='The media assets that meet the requirements.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='6F61C357-ACC0-57FB-876E-D58795335E59'),
  scrollToken?: string(name='ScrollToken', description='The pagination identifier.', example='F8C4F642184DBDA5D93907A70AAE****'),
  success?: string(name='Success', description='Indicates whether the request was successful.', example='True'),
  total?: long(name='Total', description='The total number of media assets that meet the conditions.', example='163'),
}

model SearchMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaResponseBody(name='body'),
}

/**
  * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
  * @param request  the request parameters of SearchMedia  SearchMediaRequest
  * @return SearchMediaResponse
 */
async function searchMedia(request: SearchMediaRequest): SearchMediaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchMedia', 'POST', '/', 'json', false, 'json', request);
}

model SearchMediaByAILabelRequest {
  regionId?: string(name='RegionId', position='Host'),
  customFilters?: string(name='CustomFilters', example='{}', position='Query'),
  matchingMode?: string(name='MatchingMode', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. This parameter is required if you want to query media asset clips.', example='****c469e944b5a856828dc2****', position='Query'),
  mediaType?: string(name='MediaType', description='The type of the media assets. Valid values:

*   image
*   video
*   audio', example='video', position='Query'),
  multimodalSearchType?: string(name='MultimodalSearchType', description='The type of query. Valid values:

*   PersonName: queries media assets based on character names.
*   Ocr: queries media assets based on subtitles.
*   AiCategory: queries media assets based on AI categories.
*   FullSearch (default): queries all media assets.', example='Ocr', position='Query'),
  namespace?: string(name='Namespace', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='20', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test-1', position='Query'),
  sortBy?: string(name='SortBy', description='The sorting method of the results. Valid values:

*   CreationTime:Desc (default): sorts results in reverse chronological order.
*   CreationTime:Asc: sorts results in chronological order.', example='CreationTime:Desc', position='Query'),
  specificSearch?: boolean(name='SpecificSearch', description='Specifies whether to query media asset clips. Valid values:

*   true
*   false', example='true', position='Query'),
  text?: string(name='Text', description='The content that you want to query.', position='Query'),
  utcCreate?: string(name='UtcCreate', example='{}', position='Query'),
}

model SearchMediaByAILabelResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaList?: [ 
    {
      aiData?: {
        aiLabelInfo?: [ 
          {
            category?: string(name='Category', description='The category.'),
            faceId?: string(name='FaceId', description='The ID of the face.', example='5FE19530C7A422197535FE74F5DB****'),
            labelId?: string(name='LabelId', description='The ID of the entity.', example='103102503**'),
            labelName?: string(name='LabelName', description='The name of the entity.'),
            labelType?: string(name='LabelType', description='The type of the tag.'),
            occurrences?: [ 
              {
                clipId?: string(name='ClipId', description='The ID of the clip.', example='158730355E4B82257D8AA1583A58****'),
                content?: string(name='Content', description='The content of the text.'),
                finegrainId?: string(name='FinegrainId', description='The fine-grained ID of the entity.', example='103102503**'),
                finegrainName?: string(name='FinegrainName', description='The fine-grained name of the entity.'),
                from?: double(name='From', description='The start time of the clip.', example='1.4'),
                image?: string(name='Image', description='The image that contains the most face information.', example='https://service-****-public.oss-cn-hangzhou.aliyuncs.com/1563457****438522/service-image/f788974f-9595-43b2-a478-7c7a1afb****.jpg'),
                score?: double(name='Score', description='The score.', example='0.75287705'),
                tableBatchSeqId?: string(name='TableBatchSeqId', description='The sequence ID of the vector table.', example='85010D1**'),
                to?: double(name='To', description='The end time of the clip.', example='2.5'),
                tracks?: [ 
                  {
                    position?: string(name='Position', description='The coordinates of the bounding box.', example='468.0;67.0;615.0;267.0'),
                    size?: double(name='Size', description='The size of the bounding box.', example='50'),
                    timestamp?: double(name='Timestamp', description='The timestamp of the track.', example='1.4'),
                  }
                ](name='Tracks', description='The tracks.'),
              }
            ](name='Occurrences', description='The information about the clips.'),
            source?: string(name='Source', description='The source.', example='vision'),
          }
        ](name='AiLabelInfo', description='The tags of the AI job.'),
        asrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB****'),
            content?: string(name='Content', description='The content of the audio.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='AsrInfo', description='The information about audio files.'),
        ocrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB****'),
            content?: string(name='Content', description='The content of the text.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='OcrInfo', description='The information about subtitle files.'),
      }(name='AiData', description='The details of the AI job.'),
      appId?: string(name='AppId', description='The ID of the application. Default value: app-1000000.', example='app-1000000'),
      coverUrl?: string(name='CoverUrl', description='The URL of the thumbnail.', example='http://example.aliyundoc.com/snapshot/****.jpg?auth_key=1498476426-0-0-f00b9455c49a423ce69cf4e27333****'),
      creationTime?: string(name='CreationTime', description='The time when the media asset was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:15:50Z'),
      description?: string(name='Description', description='The description of the media asset.'),
      duration?: float(name='Duration', description='The duration. Unit: seconds.', example='12.2'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='1c6ce34007d571ed94667630a6bc****'),
      modificationTime?: string(name='ModificationTime', description='The time when the media asset was updated. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:15:50Z'),
      size?: long(name='Size', description='The size of the source file. Unit: bytes.', example='10897890'),
      snapshots?: [ string ](name='Snapshots', description='The array of video snapshot URLs.'),
      status?: string(name='Status', description='The status of the video.

Valid values:

*   PrepareFail
*   UploadFail
*   Init
*   UploadSucc
*   Transcoding
*   TranscodeFail
*   Deleted
*   Normal
*   Uploading
*   Preparing
*   Blocked
*   Checking', example='Normal'),
      storageLocation?: string(name='StorageLocation', description='The storage address.', example='out-****.oss-cn-shanghai.aliyuncs.com'),
      tags?: string(name='Tags', description='The tags of the media asset.'),
      title?: string(name='Title', description='The title of the media asset.'),
    }
  ](name='MediaList', description='The media assets that contain the specified content.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request was successful.', example='true'),
  total?: long(name='Total', description='The total number of audio and video files that meet the conditions.', example='30'),
}

model SearchMediaByAILabelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByAILabelResponseBody(name='body'),
}

/**
  * @description You can call this operation to query media assets or media asset clips based on character names, subtitles, or AI categories.
  * @param request  the request parameters of SearchMediaByAILabel  SearchMediaByAILabelRequest
  * @return SearchMediaByAILabelResponse
 */
async function searchMediaByAILabel(request: SearchMediaByAILabelRequest): SearchMediaByAILabelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchMediaByAILabel', 'POST', '/', 'json', false, 'json', request);
}

model SearchMediaByFaceRequest {
  regionId?: string(name='RegionId', position='Host'),
  customFilters?: string(name='CustomFilters', example='{}', position='Query'),
  entityId?: string(name='EntityId', description='The ID of the entity.', example='2d3bf1e35a1e42b5ab338d701efa****', position='Query'),
  faceSearchToken: string(name='FaceSearchToken', description='The token that is used to identify the query. You can use this parameter in the SearchMediaClipByFace operation to specify the same query conditions.

This parameter is required.', example='zxtest-huangxuan-2023-3-7-V1', position='Query'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

*   image
*   video', example='video', position='Query'),
  namespace?: string(name='Namespace', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10', position='Query'),
  personImageUrl: string(name='PersonImageUrl', description='The URL of the face image.

This parameter is required.', example='https://****.oss-cn-shanghai.aliyuncs.com/input/huangxuan****.jpg', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1', position='Query'),
  utcCreate?: string(name='UtcCreate', example='{}', position='Query'),
}

model SearchMediaByFaceResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaInfoList?: [ 
    {
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='3b187b3620c8490886cfc2a9578c****'),
    }
  ](name='MediaInfoList', description='The media assets that meet the conditions.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='7CA7D615-CFB1-5437-9A12-2D185C3EE6CB'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
  total?: long(name='Total', description='The total number of data records that meet the specified filter condition.', example='163'),
}

model SearchMediaByFaceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByFaceResponseBody(name='body'),
}

/**
  * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
  * @param request  the request parameters of SearchMediaByFace  SearchMediaByFaceRequest
  * @return SearchMediaByFaceResponse
 */
async function searchMediaByFace(request: SearchMediaByFaceRequest): SearchMediaByFaceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchMediaByFace', 'POST', '/', 'json', false, 'json', request);
}

model SearchMediaByHybridRequest {
  regionId?: string(name='RegionId', position='Host'),
  customFilters?: string(name='CustomFilters', example='{}', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. If provided, the details of the media asset are returned.', example='****c469e944b5a856828dc2****', position='Query'),
  mediaType?: string(name='MediaType', description='The type of media assets. Valid values:
- image
- video', example='video', position='Query'),
  namespace?: string(name='Namespace', description='The namespace.', example='name-1', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 50. Default value: 10.', example='20', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library', example='test-1', position='Query'),
  text?: string(name='Text', description='The natural language search query.', example='Two pandas are fighting', position='Query'),
  utcCreate?: string(name='UtcCreate', example='{}', position='Query'),
}

model SearchMediaByHybridResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaList?: [ 
    {
      clipInfo?: [ 
        {
          from?: double(name='From', description='The start time of the relevant clip.', example='2'),
          score?: double(name='Score', description='The relevance score of the clip for the query.', example='0.99'),
          to?: double(name='To', description='The end time of the relevant clip.', example='4'),
        }
      ](name='ClipInfo', description='The information about the relevant clips.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='a18936e0e28771edb59ae6f6f47a****'),
    }
  ](name='MediaList', description='The media assets that match the search query.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values: true and false.', example='true'),
  total?: long(name='Total', description='The total number of media assets that match the search criteria.', example='30'),
}

model SearchMediaByHybridResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByHybridResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SearchMediaByHybrid  SearchMediaByHybridRequest
  * @return SearchMediaByHybridResponse
 */
async function searchMediaByHybrid(request: SearchMediaByHybridRequest): SearchMediaByHybridResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchMediaByHybrid', 'POST', '/', 'json', false, 'json', request);
}

model SearchMediaByMultimodalRequest {
  regionId?: string(name='RegionId', position='Host'),
  customFilters?: string(name='CustomFilters', example='{}', position='Query'),
  mediaType?: string(name='MediaType', description='The type of the media assets.

Valid values:

*   image
*   video (default)', example='video', position='Query'),
  namespace?: string(name='Namespace', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='test-1', position='Query'),
  text?: string(name='Text', description='The content that you want to query. You can describe the content in natural language.', position='Query'),
  utcCreate?: string(name='UtcCreate', example='{}', position='Query'),
}

model SearchMediaByMultimodalResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaList?: [ 
    {
      clipInfo?: [ 
        {
          from?: double(name='From', description='The start time of the clip.', example='2'),
          score?: double(name='Score', description='The score.', example='1.2'),
          to?: double(name='To', description='The end time of the clip.', example='4'),
        }
      ](name='ClipInfo', description='The information about the clip.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='a18936e0e28771edb59ae6f6f47a****'),
    }
  ](name='MediaList', description='The media assets that contain the specified content.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
  total?: long(name='Total', description='The total number of data records that meet the specified filter condition.', example='20'),
}

model SearchMediaByMultimodalResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByMultimodalResponseBody(name='body'),
}

/**
  * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
  * @param request  the request parameters of SearchMediaByMultimodal  SearchMediaByMultimodalRequest
  * @return SearchMediaByMultimodalResponse
 */
async function searchMediaByMultimodal(request: SearchMediaByMultimodalRequest): SearchMediaByMultimodalResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchMediaByMultimodal', 'POST', '/', 'json', false, 'json', request);
}

model SearchMediaClipByFaceRequest {
  regionId?: string(name='RegionId', position='Host'),
  entityId?: string(name='EntityId', description='The ID of the entity.', example='2d3bf1e35a1e42b5ab338d701efa****', position='Query'),
  faceSearchToken: string(name='FaceSearchToken', description='The value of this parameter is the same as that of the FaceSearchToken parameter in the SearchMediaByFace request. This specifies to return media asset clips that meet the same query conditions.

This parameter is required.', example='zxtest-huangxuan-2023-3-7-V1', position='Query'),
  mediaId: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='3b187b3620c8490886cfc2a9578c****', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1', position='Query'),
}

model SearchMediaClipByFaceResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaClipList?: [ 
    {
      category?: string(name='Category', description='The type of the character. Valid values: celebrity sensitive politician custom unknown', example='celebrity'),
      entityId?: string(name='EntityId', description='The ID of the entity, which is the same as the entity ID returned in tag analysis.', example='1031025****'),
      labelName?: string(name='LabelName', description='The name of the entity.'),
      occurrencesInfos?: [ 
        {
          endTime?: float(name='EndTime', description='The end time of the clip. Unit: seconds. The value is of the Float type.', example='69.06635'),
          expression?: string(name='Expression'),
          startTime?: float(name='StartTime', description='The start time of the clip. Unit: seconds. The value is of the Float type.', example='61.066353'),
          trackData?: [ 
            {
              boxPosition?: {
                h?: int32(name='H', description='The height of the rectangle frame. Unit: pixels.', example='168'),
                w?: int32(name='W', description='The width of the rectangle frame. Unit: pixels.', example='128'),
                x?: int32(name='X', description='The x-axis coordinate of the upper-left corner. Unit: pixels.', example='517'),
                y?: int32(name='Y', description='The y-axis coordinate of the upper-left corner. Unit: pixels.', example='409'),
              }(name='BoxPosition', description='The coordinates of the face.'),
              timestamp?: float(name='Timestamp', description='The timestamp when the face appears in the clip. Unit: seconds. The value is of the Float type.', example='62.03302'),
            }
          ](name='TrackData', description='The information about the face in the clip.'),
        }
      ](name='OccurrencesInfos', description='The information about clips related to the face.'),
      score?: float(name='Score', description='The score of the clip. The value is of the Float type. The value is in the range of [0,1].', example='0.99041677'),
    }
  ](name='MediaClipList', description='The media asset clips that meet the requirements.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='E44FFACD-9E90-555A-A09A-6FD3B7335E39'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values: true and false.', example='true'),
  total?: long(name='Total', description='The total number of media asset clips that meet the conditions.', example='5'),
}

model SearchMediaClipByFaceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaClipByFaceResponseBody(name='body'),
}

/**
  * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
  * @param request  the request parameters of SearchMediaClipByFace  SearchMediaClipByFaceRequest
  * @return SearchMediaClipByFaceResponse
 */
async function searchMediaClipByFace(request: SearchMediaClipByFaceRequest): SearchMediaClipByFaceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchMediaClipByFace', 'POST', '/', 'json', false, 'json', request);
}

model SearchPublicMediaInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  authorized?: boolean(name='Authorized', example='true', position='Query'),
  dynamicMetaDataMatchFields?: string(name='DynamicMetaDataMatchFields', example='"ApprovalStatus=\\"Available\\"&amp;MaterialBags=\\"boutiquemusic\\"&amp;Mood=\\"Nervous\\""', position='Query'),
  entityId?: string(name='EntityId', example='Copyright_Music', position='Query'),
  favorite?: boolean(name='Favorite', example='true', position='Query'),
  mediaIds?: string(name='MediaIds', example='****20b48fb04483915d4f2cd8ac****,****15d4a4b0448391508f2cb486****', position='Query'),
  pageNo?: int32(name='PageNo', example='1', position='Query'),
  pageSize?: int32(name='PageSize', example='10', position='Query'),
  sortBy?: string(name='SortBy', example='UsageCount:Desc,UnitPrice:Asc', position='Query'),
}

model SearchPublicMediaInfoResponseBody = {
  publicMediaInfos?: [ 
    {
      authorized?: boolean(name='Authorized', example='true'),
      favorite?: boolean(name='Favorite', example='true'),
      mediaInfo?: {
        dynamicMetaData?: {
          data?: string(name='Data', example='"{\\"AuditionUrl\\": \\"http://xxx\\", \\"AuditionCount\\": 3...}"'),
          type?: string(name='Type', example='system'),
        }(name='DynamicMetaData'),
        mediaBasicInfo?: {
          businessType?: string(name='BusinessType', example='general'),
          category?: string(name='Category', example='category'),
          coverURL?: string(name='CoverURL', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
          createTime?: string(name='CreateTime', example='2020-12-26T06:04:49Z'),
          deletedTime?: string(name='DeletedTime', example='2020-12-29T06:04:49Z'),
          description?: string(name='Description', example='description'),
          mediaId?: string(name='MediaId', description='MediaId', example='icepublic-****87b921bb4a55908a72a0537e****'),
          mediaTags?: string(name='MediaTags'),
          mediaType?: string(name='MediaType', example='audio'),
          modifiedTime?: string(name='ModifiedTime', example='2020-12-26T06:04:50Z'),
          source?: string(name='Source', example='oss'),
          spriteImages?: string(name='SpriteImages', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
          status?: string(name='Status', example='Normal'),
          title?: string(name='Title', example='title'),
          userData?: string(name='UserData', example='userDataTest'),
        }(name='MediaBasicInfo', description='BasicInfo'),
        mediaId?: string(name='MediaId', example='icepublic-****87b921bb4a55908a72a0537e****'),
      }(name='MediaInfo'),
      remainingAuthTime?: string(name='RemainingAuthTime', example='100'),
    }
  ](name='PublicMediaInfos'),
  requestId?: string(name='RequestId', example='****3CFB-2767-54FD-B311-BD15A4C1****'),
  totalCount?: long(name='TotalCount', example='100'),
}

model SearchPublicMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchPublicMediaInfoResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SearchPublicMediaInfo  SearchPublicMediaInfoRequest
  * @return SearchPublicMediaInfoResponse
 */
async function searchPublicMediaInfo(request: SearchPublicMediaInfoRequest): SearchPublicMediaInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SearchPublicMediaInfo', 'POST', '/', 'json', false, 'json', request);
}

model SendAIAgentDataChannelMessageRequest {
  instanceId: string(name='InstanceId', description='The ID of the AI agent in the conversation.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
  message: string(name='Message', description='The DataChannel message you want to send. You must specify a JSON string. The value can be up to 8,192 characters in length.

This parameter is required.', example='{"key":"value"}', position='Query'),
}

model SendAIAgentDataChannelMessageResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model SendAIAgentDataChannelMessageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendAIAgentDataChannelMessageResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SendAIAgentDataChannelMessage  SendAIAgentDataChannelMessageRequest
  * @return SendAIAgentDataChannelMessageResponse
 */
async function sendAIAgentDataChannelMessage(request: SendAIAgentDataChannelMessageRequest): SendAIAgentDataChannelMessageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SendAIAgentDataChannelMessage', 'POST', '/', 'json', false, 'json', request);
}

model SendAIAgentSpeechRequest {
  enableInterrupt?: boolean(name='EnableInterrupt', description='Specifies whether the broadcast can interrupt the ongoing speech. Default value: true', example='true', position='Query'),
  instanceId: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
  text: string(name='Text', description='This parameter is required.', position='Query'),
  type?: string(name='Type', position='Query'),
}

model SendAIAgentSpeechResponseBody = {
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model SendAIAgentSpeechResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendAIAgentSpeechResponseBody(name='body'),
}

/**
  * @description You can call this operation to instruct an AI agent to broadcast the content that you specify. You can determine whether this broadcast can immediately interrupt the ongoing speech. The interruption is allowed by default.
  * **Note**
  * *   Make sure that the `InstanceId` is valid and corresponds to an existing AI agent.
  * *   The content of `Text` must comply with the specifications and does not contain sensitive or inappropriate information.
  * *   If you do not want the new broadcast to interrupt the ongoing speech, you must set `EnableInterrupt` to `false`.
  * @param request  the request parameters of SendAIAgentSpeech  SendAIAgentSpeechRequest
  * @return SendAIAgentSpeechResponse
 */
async function sendAIAgentSpeech(request: SendAIAgentSpeechRequest): SendAIAgentSpeechResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SendAIAgentSpeech', 'POST', '/', 'json', false, 'json', request);
}

model SendAIAgentTextRequest {
  instanceId: string(name='InstanceId', description='The ID of the AI agent instance.

> InstanceId is a unique identifier that is returned when the AI agent is started. To start an AI agent, call [StartAIAgentInstance ](https://help.aliyun.com/document_detail/2846201.html) or [GenerateAIAgentCall](https://help.aliyun.com/document_detail/2846209.html).

This parameter is required.', example='f27f9b9be28642a88e18****', position='Query'),
  text: string(name='Text', description='The input to the LLM.

This parameter is required.', example='Hello', position='Query'),
}

model SendAIAgentTextResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='DB488837-3****'),
}

model SendAIAgentTextResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendAIAgentTextResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SendAIAgentText  SendAIAgentTextRequest
  * @return SendAIAgentTextResponse
 */
async function sendAIAgentText(request: SendAIAgentTextRequest): SendAIAgentTextResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SendAIAgentText', 'POST', '/', 'json', false, 'json', request);
}

model SendLiveSnapshotJobCommandRequest {
  command: string(name='Command', description='The operation command.

Valid values:

*   stop
*   restart
*   start

This parameter is required.', example='start', position='Body'),
  jobId: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Body'),
}

model SendLiveSnapshotJobCommandResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SendLiveSnapshotJobCommandResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendLiveSnapshotJobCommandResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SendLiveSnapshotJobCommand  SendLiveSnapshotJobCommandRequest
  * @return SendLiveSnapshotJobCommandResponse
 */
async function sendLiveSnapshotJobCommand(request: SendLiveSnapshotJobCommandRequest): SendLiveSnapshotJobCommandResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SendLiveSnapshotJobCommand', 'POST', '/', 'json', true, 'form', request);
}

model SendLiveTranscodeJobCommandRequest {
  command: string(name='Command', description='The operation command. Only the stop command is supported. This command is used to stop a transcoding job.

This parameter is required.', example='stop', position='Query'),
  jobId: string(name='JobId', description='The ID of the transcoding job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model SendLiveTranscodeJobCommandResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model SendLiveTranscodeJobCommandResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendLiveTranscodeJobCommandResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SendLiveTranscodeJobCommand  SendLiveTranscodeJobCommandRequest
  * @return SendLiveTranscodeJobCommandResponse
 */
async function sendLiveTranscodeJobCommand(request: SendLiveTranscodeJobCommandRequest): SendLiveTranscodeJobCommandResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SendLiveTranscodeJobCommand', 'POST', '/', 'json', false, 'json', request);
}

model SendMessageChatTextRequest {
  AIAgentId: string(name='AIAgentId', description='The ID of the AI agent.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
  mode?: string(name='Mode', description='The mode of message sending. Valid values:
- online
- offline

Default value: offline.', example='online', position='Query'),
  needArchiving?: boolean(name='NeedArchiving', description='Specifies whether to archive chat records. Default value: true.', example='true', position='Query'),
  receiverId: string(name='ReceiverId', description='The ID of the user who receives the message. The ID can be up to 64 bytes in length and can contain letters and digits.

This parameter is required.', example='60000042053', position='Query'),
  sessionId: string(name='SessionId', description='The ID of the session.

This parameter is required.', example='f27f9b9be28642a88e18****', position='Query'),
  text: string(name='Text', description='The content of the message.

This parameter is required.', example='Hello', position='Query'),
  type: string(name='Type', description='The type of the message. Valid values:

- announcement: notification.
- custom: custom message.

This parameter is required.', example='announcement', position='Query'),
}

model SendMessageChatTextResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
}

model SendMessageChatTextResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendMessageChatTextResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SendMessageChatText  SendMessageChatTextRequest
  * @return SendMessageChatTextResponse
 */
async function sendMessageChatText(request: SendMessageChatTextRequest): SendMessageChatTextResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SendMessageChatText', 'POST', '/', 'json', false, 'json', request);
}

model SetAIAgentVoiceprintRequest {
  input?: {
    data?: string(name='Data', description='The media access link.', example='https://my-bucket.oss-cn-hangzhou.aliyuncs.com/audio/sample.wav'),
    format?: string(name='Format', description='The audio file format. Only WAV is supported.', example='wav'),
    type?: string(name='Type', description='Specifies the access type for the audio file. The system will verify file accessibility via HEAD or GET requests. Valid values:

*   url: An HTTP(S) link to the audio file.

*   oss: An OSS object. Supports the following formats:

    1.  OSS URI: oss://bucket-name/object-key

        Example: oss://my-bucket/audio/sample.wav

    2.  OSS public URL: http(s)://${bucket}.oss-${region}.aliyuncs.com/${object}

        Example: https://my-bucket.oss-cn-hangzhou.aliyuncs.com/audio/sample.wav

>  The OSS bucket must be in the same region as the service. Otherwise, the access fails.', example='url'),
  }(name='Input', description='The input file.', shrink='json', position='Query'),
  voiceprintId?: string(name='VoiceprintId', description='A unique identifier for the voiceprint. Generate this ID based on your own business rules. Requirement: 1 to 127 characters in length.', example='vp_1699123456_8527', position='Query'),
}

model SetAIAgentVoiceprintResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='550e8400********55440000'),
  voiceprintId?: string(name='VoiceprintId', description='The ID of the registered voiceprint.', example='vp_1699123456_8527'),
}

model SetAIAgentVoiceprintResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetAIAgentVoiceprintResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SetAIAgentVoiceprint  SetAIAgentVoiceprintRequest
  * @return SetAIAgentVoiceprintResponse
 */
async function setAIAgentVoiceprint(request: SetAIAgentVoiceprintRequest): SetAIAgentVoiceprintResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetAIAgentVoiceprint', 'POST', '/', 'json', false, 'json', request);
}

model SetContentAnalyzeConfigRequest {
  regionId?: string(name='RegionId', position='Host'),
  auto?: boolean(name='Auto', example='true', position='Query'),
  saveType?: string(name='SaveType', example='TEXT,FACE', position='Query'),
  templateId?: string(name='TemplateId', example='S00000101-100070', position='Query'),
}

model SetContentAnalyzeConfigResponseBody = {
  requestId?: string(name='RequestId', example='953CFD27-4A2C-54AD-857F-B79EF3A338E0'),
  success?: boolean(name='Success', example='true'),
}

model SetContentAnalyzeConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetContentAnalyzeConfigResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SetContentAnalyzeConfig  SetContentAnalyzeConfigRequest
  * @return SetContentAnalyzeConfigResponse
 */
async function setContentAnalyzeConfig(request: SetContentAnalyzeConfigRequest): SetContentAnalyzeConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetContentAnalyzeConfig', 'POST', '/', 'json', false, 'json', request);
}

model SetDefaultCustomTemplateRequest {
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****d80e4e4044975745c14b****', position='Query'),
}

model SetDefaultCustomTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model SetDefaultCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetDefaultCustomTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SetDefaultCustomTemplate  SetDefaultCustomTemplateRequest
  * @return SetDefaultCustomTemplateResponse
 */
async function setDefaultCustomTemplate(request: SetDefaultCustomTemplateRequest): SetDefaultCustomTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetDefaultCustomTemplate', 'POST', '/', 'json', false, 'json', request);
}

model SetDefaultStorageLocationRequest {
  regionId?: string(name='RegionId', position='Host'),
  bucket?: string(name='Bucket', example='oss-test-bucket', position='Query'),
  path?: string(name='Path', example='ims/dir', position='Query'),
  storageType?: string(name='StorageType', example='user_oss_bucket', position='Query'),
}

model SetDefaultStorageLocationResponseBody = {
  requestId?: string(name='RequestId', example='******5A-CAAC-4850-A3AF-B74606******'),
  success?: boolean(name='Success', example='true'),
}

model SetDefaultStorageLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetDefaultStorageLocationResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SetDefaultStorageLocation  SetDefaultStorageLocationRequest
  * @return SetDefaultStorageLocationResponse
 */
async function setDefaultStorageLocation(request: SetDefaultStorageLocationRequest): SetDefaultStorageLocationResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetDefaultStorageLocation', 'POST', '/', 'json', false, 'json', request);
}

model SetEventCallbackRequest {
  regionId?: string(name='RegionId', position='Host'),
  authKey?: string(name='AuthKey', description='The authentication key. The key can be up to 32 characters in length and must contain uppercase letters, lowercase letters, and digits. This parameter takes effect only if you set CallbackType to **HTTP**.', example='TestKey001', position='Query'),
  authSwitch?: string(name='AuthSwitch', description='Specifies whether to enable callback authentication. This parameter takes effect only if you set CallbackType to **HTTP**. Valid values:

*   **on**
*   **off**', example='on', position='Query'),
  callbackQueueName?: string(name='CallbackQueueName', description='The name of the Simple Message Queue (SMQ) queue in the region. The name must start with ice-callback-.', example='ice-callback-queue', position='Query'),
  callbackType?: string(name='CallbackType', description='The callback method. Valid values:

*   **HTTP**
*   **MNS**', example='HTTP', position='Query'),
  callbackURL?: string(name='CallbackURL', description='The callback URL. This parameter is required if you set CallbackType to **HTTP**. The callback URL cannot exceed 256 bytes in length. You can specify only one callback URL.', example='http://xxx.yyy/callback', position='Query'),
  eventTypeList?: string(name='EventTypeList', description='The type of the callback event. You can specify multiple values separated with commas (,). ProduceMediaComplete: indicates that the editing and production task is complete.', example='ProduceMediaComplete', position='Query'),
}

model SetEventCallbackResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the configuration was successful. Valid values: true and false.', example='true'),
}

model SetEventCallbackResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetEventCallbackResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SetEventCallback  SetEventCallbackRequest
  * @return SetEventCallbackResponse
 */
async function setEventCallback(request: SetEventCallbackRequest): SetEventCallbackResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetEventCallback', 'POST', '/', 'json', false, 'json', request);
}

model SetNotifyConfigRequest {
  AIAgentId: string(name='AIAgentId', description='The ID of the AI agent.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
  audioOssPath?: string(name='AudioOssPath', position='Query'),
  callbackUrl?: string(name='CallbackUrl', description='The URL for receiving callback notifications. By default, this parameter is left empty.', example='http://customer.com/callback', position='Query'),
  enableAudioRecording?: boolean(name='EnableAudioRecording', position='Query'),
  enableNotify: boolean(name='EnableNotify', description='Specifies whether to enable event notifications.

This parameter is required.', example='true', position='Query'),
  eventTypes?: string(name='EventTypes', description='The event types. If you do not specify this parameter, all event types are selected.

*   agent_start
*   agent_stop
*   error', example='agent_start,agent_stop,error', position='Query'),
  token?: string(name='Token', description='The authentication token for callback. The token is carried in the Authorization header of a callback request. By default, this parameter is left empty.', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx', position='Query'),
}

model SetNotifyConfigResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='771A1414-27BF-53E6-AB73-EFCB*****ACF'),
}

model SetNotifyConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetNotifyConfigResponseBody(name='body'),
}

/**
  * @description ## [](#)Request description
  * You can call this operation to configure event notifications for an AI agent. You can configure `EnableNotify` to enable or disable event notifications, configure `CallbackUrl` to specify a callback URL, and configure `EventTypes` to specify event types. You can also configure `Token` to specify an authentication token for enhanced security. The system returns a unique `RequestId` for subsequent tracing after a successful request.
  * @param request  the request parameters of SetNotifyConfig  SetNotifyConfigRequest
  * @return SetNotifyConfigResponse
 */
async function setNotifyConfig(request: SetNotifyConfigRequest): SetNotifyConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetNotifyConfig', 'POST', '/', 'json', false, 'json', request);
}

model StartAIAgentInstanceRequest {
  AIAgentId: string(name='AIAgentId', description='The ID of the AI agent created in the [IMS](https://ims.console.aliyun.com/ai/robot/list) console.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
  agentConfig?: AIAgentConfig(name='AgentConfig', shrink='json', position='Query'),
  chatSyncConfig?: {
    IMAIAgentId?: string(name='IMAIAgentId', description='IM的智能体Id。', example='******005e4f309379701645f4****'),
    receiverId?: string(name='ReceiverId', description='接收用户Id。', example='4167626d312034b2b1c3b7f2f3e41884'),
  }(name='ChatSyncConfig', description='同步聊天记录配置。', shrink='json', position='Query'),
  runtimeConfig: AIAgentRuntimeConfig(name='RuntimeConfig', description='This parameter is required.', shrink='json', position='Query'),
  sessionId?: string(name='SessionId', example='f213fbc005e4f309379701645f4****', position='Query'),
  templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', deprecated='true', shrink='json', position='Query'),
  userData?: string(name='UserData', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}', position='Query'),
}

model StartAIAgentInstanceResponseBody = {
  instanceId?: string(name='InstanceId', example='39f8e0bc005e4f309379701645f4****'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model StartAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartAIAgentInstanceResponseBody(name='body'),
}

/**
  * @description You can call this operation to start an AI agent instance for a conversation. ````````When the AI agent is started, the system returns a unique `InstanceId` for subsequent tracking and operations.
  * @param request  the request parameters of StartAIAgentInstance  StartAIAgentInstanceRequest
  * @return StartAIAgentInstanceResponse
 */
async function startAIAgentInstance(request: StartAIAgentInstanceRequest): StartAIAgentInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartAIAgentInstance', 'POST', '/', 'json', false, 'json', request);
}

model StartAIAgentOutboundCallRequest {
  AIAgentId: string(name='AIAgentId', description='This parameter is required.', example='***********e4f309379701645f4****', position='Query'),
  calledNumber: string(name='CalledNumber', description='This parameter is required.', example='173*****533', position='Query'),
  callerNumber: string(name='CallerNumber', description='This parameter is required.', example='183*****333', position='Query'),
  config?: AIAgentOutboundCallConfig(name='Config', shrink='json', position='Query'),
  imsAIAgentFreeObCall?: string(name='ImsAIAgentFreeObCall', position='Query'),
  sessionId?: string(name='SessionId', example='f213fbc005e4f309379701645f4****', position='Query'),
  userData?: string(name='UserData', position='Query'),
}

model StartAIAgentOutboundCallResponseBody = {
  instanceId?: string(name='InstanceId', example='*********296014bb58670940*********'),
  requestId?: string(name='RequestId', example='***********-4417-BDB2************'),
}

model StartAIAgentOutboundCallResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartAIAgentOutboundCallResponseBody(name='body'),
}

/**
  * @param request  the request parameters of StartAIAgentOutboundCall  StartAIAgentOutboundCallRequest
  * @return StartAIAgentOutboundCallResponse
 */
async function startAIAgentOutboundCall(request: StartAIAgentOutboundCallRequest): StartAIAgentOutboundCallResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartAIAgentOutboundCall', 'POST', '/', 'json', false, 'json', request);
}

model StartAIWorkflowRequest {
  dispatchTag?: string(name='DispatchTag', description='The tag for the task.', example='default', position='Query'),
  inputs?: string(name='Inputs', description='A JSON string containing the specific input parameters, such as information about the media assets, standard live streams, or RTC streams.', example='{
    "live_url": {
        "Url": "rtmp://test.com/test_app/test_stream?auth_key=test",
        "MaxIdleTime": 20
    },
    "source_language_id": "es"
}', position='Query'),
  userData?: string(name='UserData', description='A user-defined parameter for passing custom metadata.', example='{
"url":"https://test.com"
}', position='Query'),
  workflowId?: string(name='WorkflowId', description='The ID of the workflow template.', example='****3f44-f1f6-477e-9364-c5e6c49e****', position='Query'),
}

model StartAIWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  taskId?: string(name='TaskId', description='The ID of the workflow task.', example='********-266c-4bb8-b20c-6faa********'),
}

model StartAIWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartAIWorkflowResponseBody(name='body'),
}

/**
  * @description *   You must specify a workflow template. To create one, go to the [Intelligent Media Services (IMS)](https://ims.console.aliyun.com/ai-workflow/template) console.
  * @param request  the request parameters of StartAIWorkflow  StartAIWorkflowRequest
  * @return StartAIWorkflowResponse
 */
async function startAIWorkflow(request: StartAIWorkflowRequest): StartAIWorkflowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartAIWorkflow', 'POST', '/', 'json', false, 'json', request);
}

model StartChannelRequest {
  channelName: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel', position='Query'),
}

model StartChannelResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model StartChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartChannelResponseBody(name='body'),
}

/**
  * @param request  the request parameters of StartChannel  StartChannelRequest
  * @return StartChannelResponse
 */
async function startChannel(request: StartChannelRequest): StartChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartChannel', 'POST', '/', 'json', false, 'json', request);
}

model StartMediaLiveChannelRequest {
  channelId: string(name='ChannelId', description='The ID of the channel.

This parameter is required.', example='SEGK5KA6KYKAWQQH', position='Body'),
}

model StartMediaLiveChannelResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model StartMediaLiveChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartMediaLiveChannelResponseBody(name='body'),
}

/**
  * @description *   You can call this operation only when the channel is idle. You cannot start a channel repeatedly.
  * ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you will experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of StartMediaLiveChannel  StartMediaLiveChannelRequest
  * @return StartMediaLiveChannelResponse
 */
async function startMediaLiveChannel(request: StartMediaLiveChannelRequest): StartMediaLiveChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartMediaLiveChannel', 'POST', '/', 'json', true, 'form', request);
}

model StartRtcRobotInstanceRequest {
  authToken: string(name='AuthToken', description='This parameter is required.', example='**********', position='Query'),
  channelId: string(name='ChannelId', description='This parameter is required.', example='testId', position='Query'),
  config?: {
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt', example='true'),
    greeting?: string(name='Greeting'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    voiceId?: string(name='VoiceId', example='zhixiaoxia'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
  }(name='Config', shrink='json', position='Query'),
  robotId: string(name='RobotId', description='This parameter is required.', example='ca28b08ad3464ebcb42e5c0f7c6d2e89', position='Query'),
  userData?: string(name='UserData', example='{}', position='Query'),
  userId: string(name='UserId', description='This parameter is required.', example='my-robot', position='Query'),
}

model StartRtcRobotInstanceResponseBody = {
  instanceId?: string(name='InstanceId', example='727dc0e296014bb58670940a3da95592'),
  requestId?: string(name='RequestId', description='Id of the request', example='11DE0AB3-603B-5055-8A72-9C424854F983'),
}

model StartRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartRtcRobotInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of StartRtcRobotInstance  StartRtcRobotInstanceRequest
  * @return StartRtcRobotInstanceResponse
 */
async function startRtcRobotInstance(request: StartRtcRobotInstanceRequest): StartRtcRobotInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartRtcRobotInstance', 'POST', '/', 'json', false, 'json', request);
}

model StartWorkflowRequest {
  skipInputVerification?: boolean(name='SkipInputVerification', position='Query'),
  taskInput?: string(name='TaskInput', description='The workflow input. Only media assets are supported.', example='{
      "Type": "Media",
      "Media": "******30706071edbfe290b488******"
}', position='Query'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which cannot be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).', position='Query'),
  workflowId?: string(name='WorkflowId', description='The ID of the workflow template. To view the template ID, log on to the [IMS console](https://ims.console.aliyun.com/settings/workflow/list) and choose Configurations > Workflow Template.', example='******f0e54971ecbffd472190******', position='Query'),
}

model StartWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******42-E8E1-4FBB-8E52-F4225C******'),
  taskId?: string(name='TaskId', description='The ID of the workflow task.', example='******22dad741d086a50325f9******'),
}

model StartWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartWorkflowResponseBody(name='body'),
}

/**
  * @description *   Only media assets from Intelligent Media Services (IMS) or ApsaraVideo VOD can be used as the input of a workflow.
  * *   When you submit a workflow task, you must specify a workflow template. You can create a workflow template in the [IMS console](https://ims.console.aliyun.com/settings/workflow/list) or use a preset workflow template.
  * @param request  the request parameters of StartWorkflow  StartWorkflowRequest
  * @return StartWorkflowResponse
 */
async function startWorkflow(request: StartWorkflowRequest): StartWorkflowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartWorkflow', 'POST', '/', 'json', false, 'json', request);
}

model StopAIAgentInstanceRequest {
  instanceId: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
}

model StopAIAgentInstanceResponseBody = {
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model StopAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopAIAgentInstanceResponseBody(name='body'),
}

/**
  * @description *   When you no longer need an AI agent to participate in a conversation or task, you can call this operation to stop the running agent and release relevant resources.****
  * *   You must specify the unique ID of the AI agent that you want to stop by using InstanceId.****
  * *   ****
  * @param request  the request parameters of StopAIAgentInstance  StopAIAgentInstanceRequest
  * @return StopAIAgentInstanceResponse
 */
async function stopAIAgentInstance(request: StopAIAgentInstanceRequest): StopAIAgentInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopAIAgentInstance', 'POST', '/', 'json', false, 'json', request);
}

model StopAIWorkflowTaskRequest {
  taskId?: string(name='TaskId', description='The ID of the workflow task.', example='********-266c-4bb8-b20c-6faa********', position='Query'),
}

model StopAIWorkflowTaskResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  taskId?: string(name='TaskId', description='The ID of the workflow task.', example='********-266c-4bb8-b20c-6faa********'),
}

model StopAIWorkflowTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopAIWorkflowTaskResponseBody(name='body'),
}

/**
  * @description This operation is only used to stop workflow tasks in real-time scenarios such as live streaming and RTC. It cannot be used to stop tasks in offline scenarios.
  * @param request  the request parameters of StopAIWorkflowTask  StopAIWorkflowTaskRequest
  * @return StopAIWorkflowTaskResponse
 */
async function stopAIWorkflowTask(request: StopAIWorkflowTaskRequest): StopAIWorkflowTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopAIWorkflowTask', 'POST', '/', 'json', false, 'json', request);
}

model StopChannelRequest {
  channelName: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel', position='Query'),
}

model StopChannelResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model StopChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopChannelResponseBody(name='body'),
}

/**
  * @param request  the request parameters of StopChannel  StopChannelRequest
  * @return StopChannelResponse
 */
async function stopChannel(request: StopChannelRequest): StopChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopChannel', 'POST', '/', 'json', false, 'json', request);
}

model StopMediaLiveChannelRequest {
  channelId: string(name='ChannelId', description='The ID of the channel.

This parameter is required.', example='SEGK5KA6KYKAWQQH', position='Body'),
}

model StopMediaLiveChannelResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model StopMediaLiveChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopMediaLiveChannelResponseBody(name='body'),
}

/**
  * @description ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of StopMediaLiveChannel  StopMediaLiveChannelRequest
  * @return StopMediaLiveChannelResponse
 */
async function stopMediaLiveChannel(request: StopMediaLiveChannelRequest): StopMediaLiveChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopMediaLiveChannel', 'POST', '/', 'json', true, 'form', request);
}

model StopRtcRobotInstanceRequest {
  instanceId: string(name='InstanceId', description='This parameter is required.', example='727dc0e296014bb58670940a3da95592', position='Query'),
}

model StopRtcRobotInstanceResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='AC84E5DD-AB56-56C0-A992-07ECB82008CA'),
}

model StopRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopRtcRobotInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of StopRtcRobotInstance  StopRtcRobotInstanceRequest
  * @return StopRtcRobotInstanceResponse
 */
async function stopRtcRobotInstance(request: StopRtcRobotInstanceRequest): StopRtcRobotInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopRtcRobotInstance', 'POST', '/', 'json', false, 'json', request);
}

model SubmitAIAgentVideoAuditTaskRequest {
  AIAgentId: string(name='AIAgentId', description='The ID of the AI agent.

This parameter is required.', example='*******3b3d94abda22******', position='Query'),
  auditInterval?: int32(name='AuditInterval', description='The interval, in milliseconds, at which to submit captured frames to the AI agent. Valid values: 0 to 5000. Default value: 3000. If it is set to 0, all captured frames are sent to the model in a single batch request. Otherwise, frames are sent sequentially with the specified interval between each request.', example='3000', position='Query'),
  callbackConfig?: {
    token?: string(name='Token', description='The authentication token for callback.', example='Bearer Token'),
    url?: string(name='Url', description='The URL for receiving callback notifications.', example='https://yourcallback'),
  }(name='CallbackConfig', description='Callback configurations.', example='{"Url":"https://yourcallback","Token":"yourtoken"}', shrink='json', position='Query'),
  capturePolicies: [ 
    {
      duration?: int32(name='Duration', description='The duration over which to capture the specified number of frames. Unit: seconds.', example='10'),
      frameCount?: int32(name='FrameCount', description='The number of frames to capture.', example='2'),
      prompt?: string(name='Prompt', description='The text prompt to send to the MLLM along with the captured frames.'),
      startTime?: int32(name='StartTime', description='The timestamp in the video at which to start capturing frames. Unit: seconds.', example='0'),
    }
  ](name='CapturePolicies', description='An array of frame-capturing policies. Each policy defines a set of frames to be analyzed and will generate a separate result from the model.

This parameter is required.', shrink='json', position='Query'),
  input: {
    media?: string(name='Media', description='The OSS URL of the input file. Format:

http(s)://{BucketName}.{Endpoint}/{ObjectName}', example='http://my-bucket.cn-shanghai.aliyuncs.com/object-id.mp4'),
    type?: string(name='Type', description='The type of the input file. Valid values:

*   OSS: an OSS object.', example='OSS'),
  }(name='Input', description='The details of the input file.

This parameter is required.', shrink='json', position='Query'),
  userData?: string(name='UserData', description='The user-defined data.', position='Query'),
}

model SubmitAIAgentVideoAuditTaskResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='**********fb04483915d4f2**********'),
  requestId?: string(name='RequestId', description='The request ID.', example='**********-586A-AC29-742247******'),
}

model SubmitAIAgentVideoAuditTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitAIAgentVideoAuditTaskResponseBody(name='body'),
}

/**
  * @description Call SubmitAIAgentVideoAuditTask to submit a video moderation task with configurations such as a video URL, frame-capturing policies, and review interval. The system returns a unique JobId for tracking. When the task is complete, the service will push the results, including the moderation status and AI-generated analysis, to the configured callback URL. Only OSS URLs are supported as input. The underlying multi-modal large language model (MLLM) only supports interaction via the non-streaming OpenAI protocol.
  * @param request  the request parameters of SubmitAIAgentVideoAuditTask  SubmitAIAgentVideoAuditTaskRequest
  * @return SubmitAIAgentVideoAuditTaskResponse
 */
async function submitAIAgentVideoAuditTask(request: SubmitAIAgentVideoAuditTaskRequest): SubmitAIAgentVideoAuditTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitAIAgentVideoAuditTask', 'POST', '/', 'json', false, 'json', request);
}

model SubmitASRJobRequest {
  description?: string(name='Description', description='The job description, which can up to 128 bytes in length.', example='测试描述', position='Query'),
  duration?: string(name='Duration', description='The speech duration.', example='00:00:10', position='Query'),
  editingConfig?: string(name='EditingConfig', position='Query'),
  inputFile?: string(name='InputFile', description='The input file. You can specify an Object Storage Service (OSS) URL or the ID of a media asset in the media asset library.', example='oss://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4 或 ****20b48fb04483915d4f2cd8ac****', position='Query'),
  startTime?: string(name='StartTime', description='The start time of the speech to recognize.', example='00:00:00', position='Query'),
  title?: string(name='Title', description='The job title, which can be up to 128 bytes in length.', example='测试标题', position='Query'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format. You can specify your business information, such as the business environment and job information.', example='{
      "user": "data",
      "env": "prod"
}', position='Query'),
}

model SubmitASRJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  state?: string(name='State', description='The job state. Valid values:

*   Created
*   Executing
*   Finished
*   Failed', example='Finished'),
}

model SubmitASRJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitASRJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitASRJob  SubmitASRJobRequest
  * @return SubmitASRJobResponse
 */
async function submitASRJob(request: SubmitASRJobRequest): SubmitASRJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitASRJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitAudioProduceJobRequest {
  description?: string(name='Description', description='The job description.

*   The job description can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.', example='任务描述  长度不超过1024字节  UTF8编码', position='Query'),
  editingConfig: string(name='EditingConfig', description='The audio editing configurations.

*   voice: the [voice type](https://help.aliyun.com/document_detail/449563.html).
*   customizedVoice: the ID of the personalized human voice.
*   format: the format of the output file. Valid values: PCM, WAV, and MP3.
*   volume: the volume. Default value: 50. Valid values: 0 to 100.
*   speech_rate: the speech tempo. Default value: 0. Value range: -500 to 500.
*   pitch_rate: the intonation. Default value: 0. Value range: -500 to 500.

>  If you specify both voice and customizedVoice, customizedVoice takes precedence over voice.

This parameter is required.', example='{"voice":"Siqi","format":"MP3","volume":50}', position='Query'),
  inputConfig: string(name='InputConfig', description='The text content. A maximum of 2,000 characters are supported. The [Speech Synthesis Markup Language (SSML)](https://help.aliyun.com/document_detail/2672807.html) is supported.

This parameter is required.', example='测试文本', position='Query'),
  outputConfig: string(name='OutputConfig', description='The output audio configurations.

This parameter is required.', example='{"bucket":"bucket","object":"objeck"}', position='Query'),
  overwrite?: boolean(name='Overwrite', description='Specifies whether to overwrite the existing Object Storage Service (OSS) object.', example='true', position='Query'),
  title?: string(name='Title', description='The job title. If you do not specify this parameter, the system generates a title based on the current date.

*   The job title can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='任务标题。若不提供，根据日期自动生成默认title  长度不超过128字节  UTF8编码', position='Query'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).', example='{"user":"data"}', position='Query'),
}

model SubmitAudioProduceJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****2bcbfcfa30fccb36f72dca22****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  state?: string(name='State', description='The job state. Valid values:

*   Created
*   Executing
*   Finished
*   Failed', example='Created'),
}

model SubmitAudioProduceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitAudioProduceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitAudioProduceJob  SubmitAudioProduceJobRequest
  * @return SubmitAudioProduceJobResponse
 */
async function submitAudioProduceJob(request: SubmitAudioProduceJobRequest): SubmitAudioProduceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitAudioProduceJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitAvatarTrainingJobRequest {
  jobId: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model SubmitAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****29faef8144638ba42eb8e037****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model SubmitAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitAvatarTrainingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitAvatarTrainingJob  SubmitAvatarTrainingJobRequest
  * @return SubmitAvatarTrainingJobResponse
 */
async function submitAvatarTrainingJob(request: SubmitAvatarTrainingJobRequest): SubmitAvatarTrainingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitAvatarTrainingJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitAvatarVideoJobRequest {
  description?: string(name='Description', description='The task description. Max length: 128 bytes.', example='test', position='Query'),
  editingConfig?: string(name='EditingConfig', description='The avatar configurations, including the avatar ID, voice, and speech rate.', example='{"AvatarId":"yunqiao"}', position='Query'),
  inputConfig?: string(name='InputConfig', description='The input configurations of the video rendering task for an avatar. You can specify text, the Object Storage Service (OSS) URL of an audio file, or the ID of a media asset. The audio file must be in the MP3 or WAV format.

>Notice: The text must be at least five characters in length.', example='{"Text": "To be, or not to be, that is the question."}', position='Query'),
  outputConfig?: string(name='OutputConfig', description='The output configurations, including the destination URL for the rendered video.', example='{"MediaURL":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/xxx.mp4"}', position='Query'),
  title?: string(name='Title', description='The task name. Max length: 128 bytes.', example='test', position='Query'),
  userData?: string(name='UserData', description='A user-defined JSON string for passing custom business information, such as environment details or task metadata.', example='{"user":"data","env":"prod"}', position='Query'),
}

model SubmitAvatarVideoJobResponseBody = {
  jobId?: string(name='JobId', description='The task ID.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='******70dcc471edaf00e6f6f4******'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitAvatarVideoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitAvatarVideoJobResponseBody(name='body'),
}

/**
  * @description - The input supports only text or a human voice audio file in MP3 or WAV format.
  * - The output supports MP4 and WebM formats. For the MP4 format, the task produces two videos: one with the avatar on a green screen background and a separate alpha mask video. This is ideal for post-production. For the WebM format, the task produces a single video with a transparent alpha channel, suitable for direct web front-end display. Rendering WebM is slower due to encoding complexity.
  * - The final output includes sentence-level timestamps, which are useful for subsequent video editing.
  * @param request  the request parameters of SubmitAvatarVideoJob  SubmitAvatarVideoJobRequest
  * @return SubmitAvatarVideoJobResponse
 */
async function submitAvatarVideoJob(request: SubmitAvatarVideoJobRequest): SubmitAvatarVideoJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitAvatarVideoJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitBatchMediaProducingJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****', position='Query'),
  editingConfig?: string(name='EditingConfig', description='The editing configurations. For more information, see [EditingConfig](~~2692547#1be9bba03b7qu~~).', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}', position='Body'),
  inputConfig?: string(name='InputConfig', description='The input configurations. For more information, see [InputConfig](~~2692547#2faed1559549n~~).', position='Body'),
  outputConfig?: string(name='OutputConfig', description='The output configurations. For more information, see [OutputConfig](~~2692547#447b928fcbuoa~~).', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 20,
  "MaxDuration": 15,
  "Width": 1080,
  "Height": 1920,
  "Video": {"Crf": 27}
}', position='Query'),
  templateConfig?: string(name='TemplateConfig', position='Query'),
  userData?: string(name='UserData', description='The user-defined data, including the business and callback configurations. For more information, see [UserData](https://help.aliyun.com/document_detail/357745.html).', position='Query'),
}

model SubmitBatchMediaProducingJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the quick video production job.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model SubmitBatchMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitBatchMediaProducingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitBatchMediaProducingJob  SubmitBatchMediaProducingJobRequest
  * @return SubmitBatchMediaProducingJobResponse
 */
async function submitBatchMediaProducingJob(request: SubmitBatchMediaProducingJobRequest): SubmitBatchMediaProducingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitBatchMediaProducingJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitCopyrightExtractJobRequest {
  input: {
    media: string(name='Media', description='The specific information for the input file, which can be an OSS URL or a media asset ID. OSS URL formats:

1\\. oss://bucket/object

2\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

where bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object path in OSS.

This parameter is required.', example='oss://bucket/object'),
    type: string(name='Type', description='The type of the source file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The source video file from which to extract the watermark.

> The OSS object or media asset must reside in the same region as the IMS service region.

This parameter is required.', shrink='json', position='Query'),
  params?: string(name='Params', description='Additional parameters for the watermark job, provided as a JSON string. Supported parameter:

*   algoType: The algorithm type. Defaults to v1. The extraction algorithm must match the one used for embedding.

    *   v1: Copyright watermark extraction algorithm for long videos.
    *   v2: Copyright watermark extraction algorithm for short videos.', example='{"algoType":"v2"}', position='Query'),
  userData?: string(name='UserData', description='The custom data, which can be up to 1,024 bytes in size.', example='123', position='Query'),
}

model SubmitCopyrightExtractJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The job ID.', example='bfb786c63****4d80648792021eff90'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The message returned.', example='ok'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
  statusCode?: long(name='StatusCode', description='The status code.', example='200'),
}

model SubmitCopyrightExtractJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitCopyrightExtractJobResponseBody(name='body'),
}

/**
  * @description *   This operation is supported only in the China (Shanghai) and China (Beijing) regions.
  * @param request  the request parameters of SubmitCopyrightExtractJob  SubmitCopyrightExtractJobRequest
  * @return SubmitCopyrightExtractJobResponse
 */
async function submitCopyrightExtractJob(request: SubmitCopyrightExtractJobRequest): SubmitCopyrightExtractJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitCopyrightExtractJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitCopyrightJobRequest {
  description?: string(name='Description', description='The description of the watermark.', example='Description', position='Query'),
  input: {
    media: string(name='Media', description='This parameter is required.'),
    type: string(name='Type', description='This parameter is required.'),
  }(name='Input', description='The source video file that you want to add a watermark to.

> The OSS object or media asset must reside in the same region as the IMS service region.

This parameter is required.', example='{"Bucket":"example-bucket","Location":"oss-cn-shanghai","Object":"example.mp4"}', shrink='json', position='Query'),
  level?: long(name='Level', description='The watermark level, which specifies the channel to embed watermarks. Valid values: 0 specifies the 0u channel, 1 specifies the 1uv channel, and 2 specifies the 2yuv channel.', example='0', position='Query'),
  message: string(name='Message', description='The information about the watermark to be added.

This parameter is required.', example='Test', position='Query'),
  output: {
    media: string(name='Media', description='This parameter is required.'),
    type: string(name='Type', description='This parameter is required.'),
  }(name='Output', description='The URL of the output file.

> The OSS bucket must reside in the same region as the IMS service region.

This parameter is required.', example='{"Bucket":"example-bucket","Location":"oss-cn-shanghai","Object":"example_result.mp4"}', shrink='json', position='Query'),
  params?: string(name='Params', description='The parameters related to watermark jobs. The value is a JSON string. Supported parameter:

*   algoType: the algorithm type. Default value: v1.

    *   v1: watermarking for long videos that last at least 3 minutes.
    *   v2: watermarking for videos shorter than 3 minutes.', example='{"algoType":"v2"}', position='Query'),
  startTime?: long(name='StartTime', description='The start time of the watermark. Unit: seconds. If you do not specify this parameter, the default value 0 is used.', example='0', position='Query'),
  totalTime?: long(name='TotalTime', description='The end time of the watermark. Unit: seconds. If you do not specify this parameter, the default value is the video duration.', example='10', position='Query'),
  userData?: string(name='UserData', description='The custom data, which can be up to 1,024 bytes in size.', example='123', position='Query'),
}

model SubmitCopyrightJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The job ID.', example='bfb786c63****f4d80648792021eff90'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The message returned.', example='ok'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='FA258E67-09B8-4EAA-8F33-BA567834A2C3'),
  statusCode?: long(name='StatusCode', description='The status code.', example='200'),
}

model SubmitCopyrightJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitCopyrightJobResponseBody(name='body'),
}

/**
  * @description *   You can call this operation to add a copyright watermark to a video that lasts at least 3 minutes. If the video is too short, the call may fail, or no output may be returned. To add a copyright watermark to a video shorter than 3 minutes, specify the Params parameter to change the algorithm.
  * *   Each API call supports processing only one video.
  * *   This API is supported only in the China (Shanghai) and China (Beijing) regions.
  * @param request  the request parameters of SubmitCopyrightJob  SubmitCopyrightJobRequest
  * @return SubmitCopyrightJobResponse
 */
async function submitCopyrightJob(request: SubmitCopyrightJobRequest): SubmitCopyrightJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitCopyrightJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitCustomizedVoiceJobRequest {
  demoAudioMediaURL?: string(name='DemoAudioMediaURL', description='The URL of the sample audio file.

*   If this parameter is specified, a sample audio file is generated at the specified Object Storage Service (OSS) URL after the training is complete.

*   If this parameter is not specified, no sample audio file is generated.

    **

    **Note**: The URL must be a valid public OSS URL within your Alibaba Cloud account.', example='https://your-bucket.oss-cn-shanghai.aliyuncs.com/demo.MP3', position='Query'),
  voiceId: string(name='VoiceId', description='The voice ID.

This parameter is required.', example='xiaozhuan', maxLength=32, position='Query'),
}

model SubmitCustomizedVoiceJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****d718e2ff4f018ccf419a7b71****'),
    voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model SubmitCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitCustomizedVoiceJob  SubmitCustomizedVoiceJobRequest
  * @return SubmitCustomizedVoiceJobResponse
 */
async function submitCustomizedVoiceJob(request: SubmitCustomizedVoiceJobRequest): SubmitCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitDNAJobRequest {
  config?: string(name='Config', description='The configurations of the media fingerprint analysis job. The value is a JSON object. If you specify this parameter, the template parameters are overwritten.', example='{"SaveType": "save","MediaType"":"video"}', position='Query'),
  DBId: string(name='DBId', description='The ID of the media fingerprint library. If you do not specify this parameter, the default media fingerprint library is used. For more information about how to create a media fingerprint library, see [CreateDNADB](https://help.aliyun.com/document_detail/479275.html).

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****', position='Query'),
  input: {
    media: string(name='Media', description='The input file. The file can be an OSS object or a media asset. You can specify the path of an OSS object in one of the following formats:

1\\. oss://bucket/object

2\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the preceding paths, bucket indicates an OSS bucket that resides in the same region as the current project, and object indicates the path of the object in the bucket.

This parameter is required.', example='1b1b9cd148034739af413150fded****'),
    type: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: Object Storage Service (OSS) object.
2.  Media: media asset.

This parameter is required.', example='Media'),
  }(name='Input', description='The input file for media fingerprint analysis.

This parameter is required.', shrink='json', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the media fingerprint analysis job is submitted.', example='5246b8d12a62433ab77845074039****', position='Query'),
  primaryKey: string(name='PrimaryKey', description='The primary key of the video. You must make sure that each primary key is unique.

This parameter is required.', example='3ca84a39a9024f19853b21be9cf9****', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID.', example='S00000101-100060', position='Query'),
  userData?: string(name='UserData', description='The user-defined data. The data can be up to 128 bytes in length.', example='userData', position='Query'),
}

model SubmitDNAJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the media fingerprint analysis job. We recommend that you save this ID for subsequent calls of other operations.', example='88c6ca184c0e47098a5b665e2****'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model SubmitDNAJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitDNAJobResponseBody(name='body'),
}

/**
  * @description *   SubmitDNAJob is an asynchronous operation. After a request is sent, the system returns a request ID and a job ID and runs the task in the background.
  * *   You can call this operation only in the China (Beijing), China (Hangzhou), and China (Shanghai) regions.
  * *   You can submit a text fingerprint analysis job only in the China (Shanghai) region.
  * @param request  the request parameters of SubmitDNAJob  SubmitDNAJobRequest
  * @return SubmitDNAJobResponse
 */
async function submitDNAJob(request: SubmitDNAJobRequest): SubmitDNAJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitDNAJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitDynamicChartJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  axisParams?: string(name='AxisParams', description='The axis configurations. If XAxisFontInterval is set to 0 or left empty, the system automatically determines an optimal interval.', example='{"FontFile":"Microsoft YaHei","XAxisFontSize":"30","YAxisFontSize":"30","XAxisFontInterval":"30","AxisColor":"30"}', position='Query'),
  background?: string(name='Background', description='The chart background.', example='{"Color":"#000000","ImageUrl":"http://your-bucket.oss-cn-shanghai.aliyuncs.com/obj.jpg"}', position='Query'),
  chartConfig?: string(name='ChartConfig', description='The chart configurations.', example='{"Style":"Normal","TitleStartTime":"3000","ChartStartTime":"3000","VideoDuration":"15000"}', position='Query'),
  chartTitle?: string(name='ChartTitle', description='The chart title.', position='Query'),
  chartType: string(name='ChartType', description='The chart type.

Valid values:

*   Line: line chart
*   Histogram: bar chart
*   Pie: pie chart

This parameter is required.', example='Line', position='Query'),
  dataSource?: string(name='DataSource', description='The data source.', position='Query'),
  description?: string(name='Description', description='The job description.', position='Query'),
  input: string(name='Input', description='The input data for the chart.

This parameter is required.', example='{"XlsFile":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/obj.xls"}', position='Query'),
  outputConfig: string(name='OutputConfig', description='The output configurations.

This parameter is required.', example='{"MediaURL":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/obj.mp4","Bitrate":2000,"Width":800,"Height":680}', position='Query'),
  subtitle?: string(name='Subtitle', description='The subtitle.', position='Query'),
  title?: string(name='Title', description='The job title.', position='Query'),
  unit?: string(name='Unit', description='Unit', position='Query'),
  userData?: string(name='UserData', description='The custom data in JSON format.', example='{"user":"data"}', position='Query'),
}

model SubmitDynamicChartJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitDynamicChartJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitDynamicChartJobResponseBody(name='body'),
}

/**
  * @description This feature is available only in the China (Shanghai) region.
  * *   You can add a title, subtitle, data source, and unit to a chart and specify the font and font size. For supported fonts, see [Fonts](https://help.aliyun.com/document_detail/449567.html).
  * *   This feature provides five styles of animated charts: normal, mystery, lively, business, and green.
  * *   You can set the background color or image.
  * *   You can set the animation duration, size, and bitrate.
  * Examples
  * *   Line chart: [Sample datasheet](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/line.xlsx), [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/line.mp4)
  * *   Bar chart: [Sample datasheet](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/histgram.xlsx), [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/histgram.mp4)
  * *   Pie chart: [Sample datasheet](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/pie.xlsx), [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/pie.mp4)
  * *   Normal: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Normal.mp4)
  * *   Mystery: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Mystery.mp4)
  * *   Lively: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Lively.mp4)
  * *   Business: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Business.mp4)
  * *   Green: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Green.mp4)
  * @param request  the request parameters of SubmitDynamicChartJob  SubmitDynamicChartJobRequest
  * @return SubmitDynamicChartJobResponse
 */
async function submitDynamicChartJob(request: SubmitDynamicChartJobRequest): SubmitDynamicChartJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitDynamicChartJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitDynamicImageJobRequest {
  input: {
    media: string(name='Media', description='The input file. If Type is set to OSS, set this parameter to the URL of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

This parameter is required.', example='oss://bucket/object.mp4'),
    type: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The input of the job.

This parameter is required.', shrink='json', position='Query'),
  name?: string(name='Name', description='The name of the job.', example='SampleJob', position='Query'),
  output: {
    media: string(name='Media', description='The output file. The file can be an OSS object or a media asset. The URL of an OSS object can be in one of the following formats:

*   oss://bucket/object
*   http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the IMS console.

This parameter is required.', example='****96e8864746a0b6f3****'),
    type: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

This parameter is required.', example='Media'),
  }(name='Output', description='The output of the job.

This parameter is required.', shrink='json', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****96e8864746a0b6f3****'),
    priority?: int32(name='Priority', description='The priority. Valid values: 1 to 10. Default value: 6. A greater value specifies a higher priority.', example='6'),
  }(name='ScheduleConfig', description='The scheduling settings.', shrink='json', position='Query'),
  templateConfig: {
    overwriteParams?: {
      format?: string(name='Format', description='The format of the animated image. Valid values:

*   **gif**
*   **webp**', example='gif'),
      fps?: int32(name='Fps', description='The frame rate. Valid values: [1,60].', example='15'),
      height?: int32(name='Height', description='The height of the animated image. Valid values: [128,4096].', example='720'),
      longShortMode?: boolean(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature. Valid values:

*   **true**
*   **false**

Default value: **true**.

>  If this feature is enabled, the width of the output video corresponds to the long side of the input video, which is the height of the input video in portrait mode. The height of the output video corresponds to the short side of the input video, which is the width of the input video in portrait mode.', example='false'),
      scanMode?: string(name='ScanMode', description='The scan mode. Valid values:

*   **interlaced**
*   **progressive** This is the default value.', example='progressive'),
      timeSpan?: {
        duration?: string(name='Duration', description='The length of the clip.

*   Format: `hh:mm:ss[.SSS]` or `sssss[.SSS]`.
*   Valid values: `[00:00:00.000,23:59:59.999]` or `[0.000,86399.999]`.', example='01:59:59.999 or 32000.23'),
        end?: string(name='End', description='The length of the ending part of the original clip to be cropped out. If you specify this parameter, the Duration parameter becomes invalid.

*   Format: `hh:mm:ss[.SSS]` or `sssss[.SSS]`.
*   Valid values: `[00:00:00.000,23:59:59.999]` or `[0.000,86399.999]`.', example='01:59:59.999 or 32000.23'),
        seek?: string(name='Seek', description='The start point of the clip.

*   Format: `hh:mm:ss[.SSS]` or `sssss[.SSS]`.
*   Valid values: `[00:00:00.000,23:59:59.999]` or `[0.000,86399.999]`.', example='01:59:59.999 or 32000.23'),
      }(name='TimeSpan', description='The timeline parameters.'),
      width?: int32(name='Width', description='The width of the animated image. Valid values: [128,4096].', example='1024'),
    }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters.'),
    templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
  }(name='TemplateConfig', description='The snapshot template configuration.

This parameter is required.', shrink='json', position='Query'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"SampleKey": "SampleValue"}', position='Query'),
}

model SubmitDynamicImageJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitDynamicImageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitDynamicImageJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitDynamicImageJob  SubmitDynamicImageJobRequest
  * @return SubmitDynamicImageJobResponse
 */
async function submitDynamicImageJob(request: SubmitDynamicImageJobRequest): SubmitDynamicImageJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitDynamicImageJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitHighlightExtractionJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  clientToken?: string(name='ClientToken', description='The client token used to ensure the idempotency of the request.', example='****12e8864746a0a398****', position='Query'),
  inputConfig?: string(name='InputConfig', description='The input configuration.', example='{
	"MediaArray": [{
		"MediaId": "ceb72f00e****1ef8216e7e6c64a6302"
	}, {
		"MediaId": "ce450c40e****1ef8216e7e6c64a6302"
	}, {
		"MediaId": "ce49a020e****1ef81c1e6f6d5686302"
	}, {
		"MediaId": "d047e120e****1ef81c1e6f6d5686302"
	}, {
		"MediaId": "cfe2ddc0e****1ef81c1e6f6d5686302"
	}],
	"Strategy": {
		"Count": 5,
		"ClipDuration": 15
	}
}', position='Body'),
  outputConfig?: string(name='OutputConfig', description='The output configuration.', example='{
	"NeedExport": true,
	"OutputMediaTarget": "oss-object",
	"Bucket": "test-bucket",
	"ObjectKey": "path/to/test_{index}.mp4",
	"Width": 1920,
	"Height": 1080,
	"ExportAsNewMedia": false
}', position='Query'),
  userData?: string(name='UserData', description='The user-defined data, including the business and callback configurations. For more information, see [UserData](~~357745#section-urj-v3f-0s1~~).', position='Query'),
}

model SubmitHighlightExtractionJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the highlight extraction task.', example='****cdb3e74639973036bc84****'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
}

model SubmitHighlightExtractionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitHighlightExtractionJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitHighlightExtractionJob  SubmitHighlightExtractionJobRequest
  * @return SubmitHighlightExtractionJobResponse
 */
async function submitHighlightExtractionJob(request: SubmitHighlightExtractionJobRequest): SubmitHighlightExtractionJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitHighlightExtractionJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitIProductionJobRequest {
  functionName: string(name='FunctionName', description='The name of the algorithm that you want to use for the job. Valid values:

*   **Cover**: This algorithm intelligently generates a thumbnail image for a video.
*   **VideoClip**: This algorithm intelligently generates a summary for a video.
*   **VideoDelogo**: This algorithm removes logos from a video.
*   **VideoDetext**: This algorithm removes captions from a video.
*   **CaptionExtraction**: This algorithm extracts captions from a video and generates the caption file.
*   **VideoGreenScreenMatting**: This algorithm performs green-screen image matting on a video and generates a new video.
*   **FaceBeauty**: This algorithm performs video retouching.
*   **VideoH2V**: This algorithm transforms a video from the landscape mode to the portrait mode.
*   **MusicSegmentDetect**: This algorithm detects the chorus of a song.
*   **AudioBeatDetection**: This algorithm detects rhythms.
*   **AudioQualityAssessment**: This algorithm assesses the audio quality.
*   **SpeechDenoise**: This algorithm performs noise reduction.
*   **AudioMixing**: This algorithm mixes audio streams.

This parameter is required.', example='Cover', position='Query'),
  input: {
    media: string(name='Media', description='The input file. The file can be an OSS object or a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[regionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.

This parameter is required.', example='oss://bucket/object'),
    type: string(name='Type', description='The media type. Valid values:

*   OSS: OSS object
*   Media: media asset

This parameter is required.', example='OSS'),
  }(name='Input', description='The input file. The file can be an Object Storage Service (OSS) object or a media asset.

This parameter is required.', shrink='json', position='Query'),
  jobParams?: string(name='JobParams', description='The algorithm-specific parameters. The parameters are specified as JSON objects and vary based on the algorithm. For more information, see the "Parameters of JobParams" section of this topic.', example='{"Model":"gif"}', position='Query'),
  modelId?: string(name='ModelId', position='Query'),
  name?: string(name='Name', description='The name of the intelligent production job. The name can be up to 100 characters in length.', position='Query'),
  output: {
    biz?: string(name='Biz'),
    media: string(name='Media', description='The output file. If Type is set to OSS, set this parameter to the path of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.

This parameter is required.', example='oss://bucket/object'),
    outputUrl?: string(name='OutputUrl'),
    type: string(name='Type', description='The media type. Valid values:

*   OSS: OSS object
*   Media: media asset

This parameter is required.', example='OSS'),
  }(name='Output', description='The output file. The file can be an OSS object or a media asset.

This parameter is required.', shrink='json', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue.', example='5246b8d12a62433ab77845074039c3dc'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. A smaller value indicates a higher priority.', example='6'),
  }(name='ScheduleConfig', description='The scheduling configuration.', shrink='json', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  userData?: string(name='UserData', description='The user-defined data that is returned in the response. The value can be up to 1,024 bytes in length.', example='{"test":1}', position='Query'),
}

model SubmitIProductionJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the intelligent production job.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='C1849434-FC47-5DC1-92B6-F7EAAFE3851E'),
}

model SubmitIProductionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitIProductionJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitIProductionJob  SubmitIProductionJobRequest
  * @return SubmitIProductionJobResponse
 */
async function submitIProductionJob(request: SubmitIProductionJobRequest): SubmitIProductionJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitIProductionJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitLiveEditingJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  clips: string(name='Clips', description='The clips in the JSON array format. The output video is created by merging these clips sequentially.

Each clip has a start time and an end time. If no live stream parameters are specified, the outer live stream configurations apply. The start and end timestamps are in UTC. For more information about the parameters, see the "Clip" section of this topic.

This parameter is required.', example='[{\\"StartTime\\": \\" 2021-06-21T08:01:00Z\\",  \\"EndTime\\": \\" 2021-06-21T08:03:00Z\\" ,  "AppName": "app", "DomainName": "domain.com", "StreamName": "stream"},  {\\"StartTime\\": \\" 2021-06-21T08:05:00Z\\",  \\"EndTime\\": \\" 2021-06-21T08:09:00Z\\" }]', position='Query'),
  liveStreamConfig?: string(name='LiveStreamConfig', description='The live stream configurations, in the JSON format. The configurations must include the following parameters:

*   AppName: the name of the application to which the live stream belongs.
*   DomainName: the domain name of the application.
*   StreamName: the name of the live stream.', example='{ "AppName": "app", "DomainName": "domain.com", "StreamName": "stream"  }', position='Query'),
  mediaProduceConfig?: string(name='MediaProduceConfig', description='The production configurations, in the JSON format. Mode specifies the editing mode. Valid values:

*   **AccurateFast** (default): fast editing. It is faster than the Accurate mode. The resolution of the output file is the same as that of the source stream. You cannot specify the width and height of the output file.
*   **Accurate**: accurate editing. In this mode, you can specify the width and height of the output file.
*   **Rough**: rough editing. The minimum precision is one TS segment. The output file comprises all segments within the specified time range. You can specify the width and height of the output file.
*   **RoughFast**: fast rough editing. It is faster than the Accurate mode. The minimum precision is one TS segment. The output file comprises all segments within the specified time range. The resolution of the output file is the same as that of the source stream. You cannot specify the width and height of the output file.', example='{ "Mode": "AccurateFast"}', position='Query'),
  outputMediaConfig?: string(name='OutputMediaConfig', description='The configurations of the output file, in the JSON format. You can specify an OSS URL or a storage location in a storage bucket of ApsaraVideo VOD.

*   To store the output file in OSS, you must specify MediaURL.
*   To store the output file in ApsaraVideo VOD, you must specify StorageLocation and FileName.', position='Query'),
  outputMediaTarget?: string(name='OutputMediaTarget', description='The type of the output file. Valid values:

*   oss-object: OSS object in an OSS bucket.
*   vod-media: media asset in Alibaba Cloud VOD.', example='oss-object', position='Query'),
  projectId?: string(name='ProjectId', description='The ID of the live editing project. If this parameter is specified, the system reads the storage configurations of the project. If this parameter is not specified, the specified storage configurations take precedence.', example='****fddd7748b58bf1d47e95****', position='Query'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length.', example='{"key": "value"}', position='Query'),
}

model SubmitLiveEditingJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the live editing job.', example='****d80e4e4044975745c14b****'),
  mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****c469e944b5a856828dc2****'),
  mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://test-bucket.cn-shanghai.aliyuncs.com/test.mp4'),
  projectId?: string(name='ProjectId', description='The ID of the live editing project.', example='****fddd7748b58bf1d47e95****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
  vodMediaId?: string(name='VodMediaId', description='The media asset ID of the output file in ApsaraVideo VOD if the output file is stored in ApsaraVideo VOD.', example='****d7578s4h75ci945c14b****'),
}

model SubmitLiveEditingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveEditingJobResponseBody(name='body'),
}

/**
  * @description Live editing is supported for live streams that are recorded and stored in Object Storage Service (OSS) and ApsaraVideo VOD. If multiple live streams are involved in a single job, only those recorded within the same application are supported for mixed editing. The streams must all be recorded either in OSS or ApsaraVideo VOD.
  * @param request  the request parameters of SubmitLiveEditingJob  SubmitLiveEditingJobRequest
  * @return SubmitLiveEditingJobResponse
 */
async function submitLiveEditingJob(request: SubmitLiveEditingJobRequest): SubmitLiveEditingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitLiveEditingJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitLiveRecordJobRequest {
  name: string(name='Name', description='The name of the recording job.

This parameter is required.', example='live stream record 1', position='Body'),
  notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify', position='Body'),
  recordOutput: {
    bucket?: string(name='Bucket', description='The bucket name.', example='imsbucket1'),
    endpoint?: string(name='Endpoint', description='The endpoint of the storage service.', example='oss-cn-hangzhou.aliyuncs.com'),
    type: string(name='Type', description='The type of the storage address.

This parameter is required.', example='oss'),
  }(name='RecordOutput', description='The storage address of the recording.

This parameter is required.', shrink='json', position='Body'),
  streamInput: {
    type: string(name='Type', description='The type of the live stream URL. The value can only be rtmp.

This parameter is required.', example='rtmp'),
    url?: string(name='Url', description='The URL of the live stream.', example='rtmp://example.com/live/stream1'),
  }(name='StreamInput', description='The URL of the live stream.

This parameter is required.', shrink='json', position='Body'),
  templateId: string(name='TemplateId', description='The ID of the recording template.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66', position='Body'),
}

model SubmitLiveRecordJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the recording job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
}

model SubmitLiveRecordJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveRecordJobResponseBody(name='body'),
}

/**
  * @description You can call this operation to record live streams of ApsaraVideo Live or third-party Real-Time Messaging Protocol (RTMP) live streams. We recommend that you ingest a stream before you call this operation to submit a recording job. If no stream is pulled from the streaming URL, the job attempts to pull a stream for 3 minutes. If the attempt times out, the recording service stops.
  * Before you submit a recording job, you must prepare an Object Storage Service (OSS) or ApsaraVideo VOD bucket. We recommend that you use a storage address configured in Intelligent Media Services (IMS) to facilitate the management and processing of generated recording files.
  * If the preset recording template does not meet your requirements, you can create a custom recording template.
  * @param request  the request parameters of SubmitLiveRecordJob  SubmitLiveRecordJobRequest
  * @return SubmitLiveRecordJobResponse
 */
async function submitLiveRecordJob(request: SubmitLiveRecordJobRequest): SubmitLiveRecordJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitLiveRecordJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitLiveSnapshotJobRequest {
  callbackUrl?: string(name='CallbackUrl', description='The snapshot callback URL.

*   It cannot exceed 255 characters in length.
*   Both HTTP and HTTPS URLs are supported.', example='http://www.aliyun.com/snapshot/callback', position='Body'),
  jobName: string(name='JobName', description='The name of the job.

*   It cannot exceed 128 characters in length.

This parameter is required.', position='Body'),
  snapshotOutput: {
    bucket: string(name='Bucket', description='The bucket of the snapshot output endpoint.

This parameter is required.', example='testbucket'),
    endpoint: string(name='Endpoint', description='The output endpoint of the snapshot.

This parameter is required.', example='oss-cn-shanghai.aliyuncs.com'),
    storageType: string(name='StorageType', description='The storage type of the snapshot. The value can only be oss.

This parameter is required.', example='oss'),
  }(name='SnapshotOutput', description='The information about the output snapshot.

This parameter is required.', shrink='json', position='Body'),
  streamInput: {
    type: string(name='Type', description='The type of the input stream. The value can only be rtmp.

This parameter is required.', example='rtmp'),
    url: string(name='Url', description='The URL of the input stream.

*   It cannot exceed 255 characters in length.

This parameter is required.', example='rtmp://www.aliyun.com/stream'),
  }(name='StreamInput', description='The information about the input stream.

This parameter is required.', shrink='json', position='Body'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Body'),
}

model SubmitLiveSnapshotJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287666****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitLiveSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveSnapshotJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitLiveSnapshotJob  SubmitLiveSnapshotJobRequest
  * @return SubmitLiveSnapshotJobResponse
 */
async function submitLiveSnapshotJob(request: SubmitLiveSnapshotJobRequest): SubmitLiveSnapshotJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitLiveSnapshotJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitLiveTranscodeJobRequest {
  name: string(name='Name', description='The name of the transcoding job.

This parameter is required.', example='task1', minLength=1, maxLength=128, position='Query'),
  startMode: int32(name='StartMode', description='The start mode of the transcoding job.

*   0: The transcoding job immediately starts.
*   1: The transcoding job starts at the scheduled time.

This parameter is required.', example='0', position='Query'),
  streamInput: {
    inputUrl: string(name='InputUrl', description='The URL of the input stream.

This parameter is required.', example='rtmp://mydomain/app/stream1'),
    type: string(name='Type', description='The type of the input stream. The value can only be rtmp.

This parameter is required.', example='rtmp'),
  }(name='StreamInput', description='The information about the input stream.

This parameter is required.', shrink='json', position='Query'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****', position='Query'),
  timedConfig?: {
    endTime?: string(name='EndTime', description='The stop time of the transcoding job. Note: The time span between the stop time and the current time cannot exceed seven days.', example='2022-07-20T08:20:32Z'),
    startTime?: string(name='StartTime', description='The start time of the transcoding job. Note: The time span between the start time and the current time cannot exceed seven days.', example='2022-02-21T00:00:00Z'),
  }(name='TimedConfig', description='The configuration of a timed transcoding job. This parameter is required if you set StartMode to 1.', shrink='json', position='Query'),
  transcodeOutput: {
    domainName?: string(name='DomainName', description='The streaming domain name of ApsaraVideo Live.', example='mydomain'),
    type: string(name='Type', description='The type of the output stream. A value of LiveCenter indicates that the URL of the output stream is generated based on the domain name of ApsaraVideo Live. The value can only be LiveCenter.

This parameter is required.', example='LiveCenter'),
  }(name='TranscodeOutput', description='The information about the transcoding output.

This parameter is required.', shrink='json', position='Query'),
}

model SubmitLiveTranscodeJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the transcoding job.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model SubmitLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveTranscodeJobResponseBody(name='body'),
}

/**
  * @description *   When you submit a transcoding job that immediately takes effect, make sure that the input stream can be streamed.
  * *   When you submit a timed transcoding job, make sure that the input stream can be streamed before the specified time.
  * @param request  the request parameters of SubmitLiveTranscodeJob  SubmitLiveTranscodeJobRequest
  * @return SubmitLiveTranscodeJobResponse
 */
async function submitLiveTranscodeJob(request: SubmitLiveTranscodeJobRequest): SubmitLiveTranscodeJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitLiveTranscodeJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitMediaAiAnalysisJobRequest {
  analysisParams?: string(name='AnalysisParams', description='The analysis parameters.', example='{"nlpParams":{"sourceLanguage":"cn","diarizationEnabled":true,"speakerCount":0,"summarizationEnabled":false,"translationEnabled":false}}', position='Query'),
  input?: string(name='Input', description='The media asset that you want to analyze. You can specify an Object Storage Service (OSS) URL, a media asset ID, or an external URL.', example='{"MediaType":"video","Media":"https://xxx.com/your_movie.mp4"}', position='Query'),
  userData?: string(name='UserData', position='Query'),
}

model SubmitMediaAiAnalysisJobResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model SubmitMediaAiAnalysisJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaAiAnalysisJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitMediaAiAnalysisJob  SubmitMediaAiAnalysisJobRequest
  * @return SubmitMediaAiAnalysisJobResponse
 */
async function submitMediaAiAnalysisJob(request: SubmitMediaAiAnalysisJobRequest): SubmitMediaAiAnalysisJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitMediaAiAnalysisJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitMediaCensorJobRequest {
  barrages?: string(name='Barrages', description='The live comments of the video.

>  If this parameter is specified, the system checks the live comments specified by this parameter instead of the live comments of the input file specified by Media.', example='hello world', position='Query'),
  coverImages?: string(name='CoverImages', description='The Object Storage Service (OSS) objects that are used as the thumbnails. Specify the thumbnails in a JSON array. A maximum of five thumbnails are supported.

>  If this parameter is specified, the system checks the thumbnails specified by this parameter instead of the thumbnails of the input file specified by **Media**.', example='[{"Bucket":"example-bucket-****","Location":"oss-cn-shanghai","Object":"example-****.jpeg","RoleArn":"acs:ram::1997018457688683:role/AliyunICEDefaultRole"}]', position='Query'),
  description?: string(name='Description', description='The video description, which can be up to 128 bytes in length.

>  If this parameter is specified, the system checks the description specified by this parameter instead of the description of the input file specified by Media.', example='example description', position='Query'),
  input?: {
    media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. You can specify the path of an OSS object in one of the following formats:

1\\. oss://bucket/object

2\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the preceding paths, bucket indicates an OSS bucket that resides in the same region as the current project, and object indicates the path of the object in the bucket.', example='1b1b9cd148034739af413150fded****'),
    type?: string(name='Type', description='The type of the input file. Valid values:

OSS: OSS object.

Media: media asset.', example='Media'),
  }(name='Input', description='The information about the file to be moderated.', shrink='json', position='Query'),
  notifyUrl?: string(name='NotifyUrl', description='The callback URL. Simple Message Queue (SMQ, formerly MNS) and HTTP callbacks are supported.', example='mns://125340688170****.oss-cn-shanghai.aliyuncs.com/queues/example-pipeline', position='Query'),
  output?: string(name='Output', description='The output snapshots. The moderation job generates output snapshots and the result JSON file in the path corresponding to the input file.

*   File name format of output snapshots: oss://bucket/snapshot-{Count}.jpg. In the path, bucket indicates an OSS bucket that resides in the same region as the current project, and {Count} is the sequence number of the snapshot.
*   The detailed moderation results are stored in the {jobId}.output file in the same OSS folder as the output snapshots. For more information about the parameters in the output file, see [Output parameters of media moderation jobs](https://help.aliyun.com/document_detail/609211.html).', example='oss://sashimi-cn-shanghai/censor/snapshot-{Count}.jpg', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the job is submitted.', example='5246b8d12a62433ab77845074039****'),
    priority?: int32(name='Priority', description='The job priority. A larger value indicates a higher priority. Valid values: 1 to 10.', example='6'),
  }(name='ScheduleConfig', description='The scheduling configurations.', shrink='json', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID. If this parameter is not specified, the default template is used for moderation.', example='S00000001-100060', position='Query'),
  title?: string(name='Title', description='The video title, which can be up to 64 bytes in length.

>  If this parameter is specified, the system checks the title specified by this parameter instead of the title of the input file specified by Media.', example='Hello World', position='Query'),
  userData?: string(name='UserData', description='The user-defined data, which can be up to 128 bytes in length.', example='UserDatatestid-001-****', position='Query'),
}

model SubmitMediaCensorJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the content moderation job. We recommend that you save this ID for subsequent calls of other operations.', example='88c6ca184c0e47098a5b665e2****'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model SubmitMediaCensorJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaCensorJobResponseBody(name='body'),
}

/**
  * @description The job that you submit by calling this operation is run in asynchronous mode. The job is added to an ApsaraVideo Media Processing (MPS) queue to be scheduled and run. You can call the [QueryMediaCensorJobDetail](https://help.aliyun.com/document_detail/444847.html) operation or configure an asynchronous notification to obtain the job results.
  * @param request  the request parameters of SubmitMediaCensorJob  SubmitMediaCensorJobRequest
  * @return SubmitMediaCensorJobResponse
 */
async function submitMediaCensorJob(request: SubmitMediaCensorJobRequest): SubmitMediaCensorJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitMediaCensorJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitMediaConvertJobRequest {
  clientToken?: string(name='ClientToken', description='The idempotency key that is used to ensure repeated requests have the same effect as a single request.', example='86f8e525-9d73-4dac-88aa-7aa4e950c00a', position='Query'),
  config: string(name='Config', description='The configurations of the transcoding task.

This parameter is required.', position='Query'),
  pipelineId?: string(name='PipelineId', description='The ID of the queue.', example='e197ecfb103e4849922b054d3032f954', position='Query'),
  userData?: string(name='UserData', description='The user data.', example='{"videoId":"abcd"}', position='Query'),
}

model SubmitMediaConvertJobResponseBody = {
  job?: {
    clientToken?: string(name='ClientToken', description='The idempotency key of the request for creating the transcoding task.', example='FB7F25E9-AD9B-1603-8AF6-F1E42DF2E706'),
    code?: string(name='Code', description='The error code returned when the transcoding task failed.', example='200'),
    config?: {
      inputs?: [
        MediaConvertInput
      ](name='Inputs', description='The inputs of the transcoding task.'),
      jobName?: string(name='JobName', description='The name of the job.', example='insx6-1310'),
      outputGroups?: [
        MediaConvertOutputGroup
      ](name='OutputGroups', description='The output group configurations.'),
      outputs?: [
        MediaConvertOutput
      ](name='Outputs', description='The output configurations.'),
    }(name='Config', description='The configurations of the transcoding task.'),
    jobId?: string(name='JobId', description='The ID of the transcoding task.', example='****20b48fb04483915d4f2cd8ac****'),
    message?: string(name='Message', description='The error message returned when the transcoding task failed.', example='ok'),
    outputDetails?: [
      MediaConvertOutputDetail
    ](name='OutputDetails', description='The details of the transcoded outputs.'),
    outputGroupDetails?: [
      MediaConvertOutputGroupDetail
    ](name='OutputGroupDetails', description='The details of the output groups.'),
    pipelineId?: string(name='PipelineId', description='The ID of the queue.', example='3780049'),
    requestId?: string(name='RequestId', description='The ID of the request.', example='A2129C9F-CE95-58B5-B8C1-07758FF6C86F'),
    state?: string(name='State', description='The status of the transcoding task. Valid values:

*   Inited: The task is initialized.
*   Running
*   Complete
*   Error
*   Cancelled', example='Inited'),
    userData?: string(name='UserData', description='The user data.', example='{"videoId":"abcd"}'),
  }(name='Job', description='The transcoding task.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitMediaConvertJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaConvertJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitMediaConvertJob  SubmitMediaConvertJobRequest
  * @return SubmitMediaConvertJobResponse
 */
async function submitMediaConvertJob(request: SubmitMediaConvertJobRequest): SubmitMediaConvertJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitMediaConvertJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitMediaInfoJobRequest {
  input: {
    media: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
    type: string(name='Type', description='The type of the media object. Valid values: OSS and Media. A value of OSS indicates an Object Storage Service (OSS) object. A value of Media indicates a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The input of the job.

This parameter is required.', shrink='json', position='Query'),
  name?: string(name='Name', description='The job name.', example='job-name', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling parameters.', shrink='json', position='Query'),
  userData?: string(name='UserData', description='The user data.', example='user-data', position='Query'),
}

model SubmitMediaInfoJobResponseBody = {
  mediaInfoJob?: {
    async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
    input?: {
      media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values: OSS and Media. A value of OSS indicates an OSS object. A value of Media indicates a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    mediaInfoProperty?: {
      audioStreamInfoList?: [ 
        {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
          channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
          codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
          codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
          codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
          codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
          duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
          index?: string(name='Index', description='The sequence number of the stream.', example='1'),
          lang?: string(name='Lang', description='The language of the stream.', example='us'),
          sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
          sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
          startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
          timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
        }
      ](name='AudioStreamInfoList', description='The information about the audio stream.'),
      fileBasicInfo?: {
        bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
        duration?: string(name='Duration', description='The duration of the video.', example='403.039999'),
        fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
        fileSize?: string(name='FileSize', description='The file size.', example='31737'),
        fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
        fileType?: string(name='FileType', description='The file type.', example='source_file'),
        fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
        formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
        height?: string(name='Height', description='The height of the output video.', example='478'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='2b36bd19c13f4145b094c0cad80dbce5'),
        region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
        width?: string(name='Width', description='The width of the output video.', example='848'),
      }(name='FileBasicInfo', description='The basic file information.'),
      videoStreamInfoList?: [ 
        {
          avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
          bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
          codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
          codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
          codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
          codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
          codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
          dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          fps?: string(name='Fps', description='The frame rate.', example='25.0'),
          hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
          height?: string(name='Height', description='The height of the output video.', example='478'),
          index?: string(name='Index', description='The sequence number of the stream.', example='0'),
          lang?: string(name='Lang', description='The language of the stream.', example='zh'),
          level?: string(name='Level', description='The codec level.', example='31'),
          numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
          pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
          profile?: string(name='Profile', description='The encoder profile.', example='High'),
          rotate?: string(name='Rotate', description='The rotation angle of the video image.', example='0'),
          sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
          startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
          timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
          width?: string(name='Width', description='The width of the output video.', example='848'),
        }
      ](name='VideoStreamInfoList', description='The information about the video stream.'),
    }(name='MediaInfoProperty', description='The details of the media information.'),
    name?: string(name='Name', description='The job name.', example='job-name'),
    requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling information.'),
    status?: string(name='Status', description='The state of the job. Valid values: Init (the job is submitted), Success (the job is successful), and Fail (the job failed).', example='Init'),
    submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.', example='{}'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='MediaInfoJob', description='MediaInfoJobDTO'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model SubmitMediaInfoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaInfoJobResponseBody(name='body'),
}

/**
  * @description You can call this operation to analyze an input media file by using a callback mechanism or initiating subsequent queries. This operation is suitable for scenarios in which real-time performance is less critical and high concurrency is expected.
  * @param request  the request parameters of SubmitMediaInfoJob  SubmitMediaInfoJobRequest
  * @return SubmitMediaInfoJobResponse
 */
async function submitMediaInfoJob(request: SubmitMediaInfoJobRequest): SubmitMediaInfoJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitMediaInfoJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitMediaProducingJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****', position='Query'),
  clipsParam?: string(name='ClipsParam', description='The material parameters of the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified. For more information, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html) and [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).', position='Query'),
  editingProduceConfig?: string(name='EditingProduceConfig', description='The parameters for editing and production. For more information, see [EditingProduceConfig](https://help.aliyun.com/document_detail/357745.html).

>  If no thumbnail is specified in EditingProduceConfig, the first frame of the video is used as the thumbnail.

*   AutoRegisterInputVodMedia: specifies whether to automatically register the ApsaraVideo VOD media assets in your timeline with IMS. Default value: true.
*   OutputWebmTransparentChannel: specifies whether the output video contains alpha channels. Default value: false.
*   CoverConfig: the custom thumbnail parameters.
*', example='{
      "AutoRegisterInputVodMedia": "true",
      "OutputWebmTransparentChannel": "true"
}', position='Query'),
  mediaMetadata?: string(name='MediaMetadata', description='The metadata of the produced video, in the JSON format. For more information about the parameters, see [MediaMetadata](https://help.aliyun.com/document_detail/357745.html).', example='{
      "Title":"test-title",
      "Tags":"test-tags1,tags2"
}', position='Query'),
  outputMediaConfig: string(name='OutputMediaConfig', description='The configurations of the output file, in the JSON format. You can specify an OSS URL or a storage location in a storage bucket of ApsaraVideo VOD.

To store the output file in OSS, you must specify MediaURL. To store the output file in ApsaraVideo VOD, you must specify StorageLocation and FileName.

For more information, see [OutputMediaConfig](https://help.aliyun.com/document_detail/357745.html).

This parameter is required.', example='{"MediaURL":"https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4"}', position='Query'),
  outputMediaTarget?: string(name='OutputMediaTarget', description='The type of the output file. Valid values:

*   oss-object: OSS object in an OSS bucket.
*   vod-media: media asset in ApsaraVideo VOD.
*   S3: output file based on the Amazon Simple Storage Service (S3) protocol.', example='oss-object', position='Query'),
  projectId?: string(name='ProjectId', description='The ID of the editing project.

> : You must specify one of ProgectId, Timeline, and TempalteId and leave the other two parameters empty.', example='xxxxxfb2101cb318xxxxx', position='Query'),
  projectMetadata?: string(name='ProjectMetadata', description='The metadata of the editing project, in the JSON format. For more information about the parameters, see [ProjectMetadata](https://help.aliyun.com/document_detail/357745.html).', position='Query'),
  source?: string(name='Source', description='The source of the editing and production request. Valid values:

*   OpenAPI
*   AliyunConsole
*   WebSDK', example='OPENAPI', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID. The template is used to build a timeline with ease.

> : You must specify one of ProgectId, Timeline, and TempalteId and leave the other two parameters empty. If TemplateId is specified, ClipsParam must also be specified.', example='****96e8864746a0b6f3****', position='Query'),
  timeline?: string(name='Timeline', position='Body'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).', example='{"NotifyAddress":"https://xx.com/xx","RegisterMediaNotifyAddress":"https://xxx.com/xx"}', position='Query'),
}

model SubmitMediaProducingJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
  mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****c469e944b5a856828dc2****'),
  projectId?: string(name='ProjectId', description='The ID of the editing project.', example='****b4549d46c88681030f6e****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
  vodMediaId?: string(name='VodMediaId', description='The media asset ID of the output file in ApsaraVideo VOD if the output file is stored in ApsaraVideo VOD.', example='****d8s4h75ci975745c14b****'),
}

model SubmitMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaProducingJobResponseBody(name='body'),
}

/**
  * @description *   This operation returns only the submission result of a media editing and production job. When the submission result is returned, the job may still be in progress. After a media editing and production job is submitted, the job is queued in the background for asynchronous processing.
  * *   The materials referenced in the timeline of an online editing project can be media assets in the media asset library or Object Storage Service (OSS) objects. External URLs or Alibaba Cloud Content Delivery Network (CDN) URLs are not supported. To use an OSS object as a material, you must set MediaUrl to an OSS URL, such as https://your-bucket.oss-region-name.aliyuncs.com/your-object.ext.
  * *   After the production is complete, the output file is automatically registered as a media asset. The media asset first needs to be analyzed. After the media asset is analyzed, you can query the duration and resolution information based on the media asset ID.
  * ## [](#)Limits
  * *   The throttling threshold of this operation is 30 queries per second (QPS).
  *     **
  *     **Note** If the threshold is exceeded, a "Throttling.User" error is returned when you submit an editing job. For more information about how to resolve this issue, see the [FAQ](https://help.aliyun.com/document_detail/453484.html).
  * *   You can create up to 100 video tracks, 100 image tracks, and 100 subtitle tracks in a project.
  * *   The total size of material files cannot exceed 1 TB.
  * *   The OSS buckets in which the materials reside and where the output media assets are stored must be in the same region as the region in which Intelligent Media Services (IMS) is activated.
  * *   An output video must meet the following requirements:
  *     *   Both the width and height must be at least 128 pixels.
  *     *   Both the width and height cannot exceed 4,096 pixels.
  *     *   The shorter side of the video cannot exceed 2,160 pixels.
  * @param request  the request parameters of SubmitMediaProducingJob  SubmitMediaProducingJobRequest
  * @return SubmitMediaProducingJobResponse
 */
async function submitMediaProducingJob(request: SubmitMediaProducingJobRequest): SubmitMediaProducingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitMediaProducingJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitPackageJobRequest {
  inputs: [ 
    {
      input: {
        media: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
        type: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
      }(name='Input', description='The information about the input stream file.

This parameter is required.'),
    }
  ](name='Inputs', description='The input of the job.

This parameter is required.', shrink='json', position='Query'),
  name?: string(name='Name', description='The name of the job.', example='job-name', position='Query'),
  output: {
    media: string(name='Media', description='The media object. If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
    type: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Output', description='The output of the job.

This parameter is required.', shrink='json', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling settings.', shrink='json', position='Query'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}', position='Query'),
}

model SubmitPackageJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='2d705f385b704ee5b*******a36d93e0'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model SubmitPackageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitPackageJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitPackageJob  SubmitPackageJobRequest
  * @return SubmitPackageJobResponse
 */
async function submitPackageJob(request: SubmitPackageJobRequest): SubmitPackageJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitPackageJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitProjectExportJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  exportType?: string(name='ExportType', description='The export type. Valid values:

*   **BaseTimeline**: exports the timeline.
*   **AdobePremierePro**: exports an Adobe Premiere Pro project.', example='BaseTimeline', position='Query'),
  outputMediaConfig: string(name='OutputMediaConfig', description='The output path for the exported project and generated intermediate files, in JSON format. The export destination only supports OSS. Path fields:

*   **Bucket**: Required. The OSS bucket name.
*   **Prefix**: Optional. The path prefix. If not specified, it defaults to the root directory.
*   **Width**: Optional. The width of the output. The value must be a positive integer. If not provided, the system automatically calculates the value based on the input project or timeline.
*   **Height**: Optional. The height of the output. The value must be a positive integer. If not provided, the system automatically calculates the value based on the input project or timeline.

This parameter is required.', example='{
	"Bucket": "example-bucket",
        "Prefix": "example_prefix",
        "Width": 1920,
        "Height": 1080
}', position='Query'),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.
>Notice: Either ProjectId or Timeline must be provided.', example='*****67ae06542b9b93e0d1c387*****', position='Query'),
  timeline?: string(name='Timeline', description='The timeline of the online editing job. For data structure, see [Timeline](https://help.aliyun.com/document_detail/198823.html).
>Notice: Either ProjectId or Timeline must be provided.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}', position='Body'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"NotifyAddress":"http://xx.xx.xxx","Key":"Valuexxx"}', position='Query'),
}

model SubmitProjectExportJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the project export task.', example='****cdb3e74639973036bc84****'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitProjectExportJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitProjectExportJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitProjectExportJob  SubmitProjectExportJobRequest
  * @return SubmitProjectExportJobResponse
 */
async function submitProjectExportJob(request: SubmitProjectExportJobRequest): SubmitProjectExportJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitProjectExportJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitSceneBatchEditingJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  outputConfig: string(name='OutputConfig', description='This parameter is required.', example='{
  "MediaURL": "http://test-bucket.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Width": 1080,
  "Height": 1920
}', position='Query'),
  projectIds: string(name='ProjectIds', description='This parameter is required.', example='****ae91539d46bb9000f74b40b80dd2,****ae91539000f74b40b80dd9d46bb', position='Query'),
  userData?: string(name='UserData', position='Query'),
}

model SubmitSceneBatchEditingJobResponseBody = {
  jobId?: string(name='JobId', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', example='****C702-41BE-467E-AF2E-883D4517****'),
}

model SubmitSceneBatchEditingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSceneBatchEditingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitSceneBatchEditingJob  SubmitSceneBatchEditingJobRequest
  * @return SubmitSceneBatchEditingJobResponse
 */
async function submitSceneBatchEditingJob(request: SubmitSceneBatchEditingJobRequest): SubmitSceneBatchEditingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSceneBatchEditingJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitSceneMediaSelectionJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  editingConfig?: string(name='EditingConfig', description='The editing configuration. Its structure depends on the value of JobType.

*   When JobType is set to Smart_Mix_Media_Select, see [Image-text matching](https://help.aliyun.com/zh/ims/use-cases/intelligent-graphic-matching-into-a-piece/?spm=a2c4g.11186623.help-menu-193643.d_3_2_0_1.7c3d6997qndkZj).
*   When JobType is set to Screen_Media_Highlights_Media_Select, see [Highlight mashup](https://help.aliyun.com/zh/ims/use-cases/create-highlight-videos?spm=a2c4g.11186623.help-menu-193643.d_3_2_0_3.84b5661bIcQULE).', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}', position='Body'),
  inputConfig: string(name='InputConfig', description='The input configuration. Its structure and required fields depend on the value of JobType.

*   When JobType is set to Smart_Mix_Media_Select, see [Image-text matching](https://help.aliyun.com/zh/ims/use-cases/intelligent-graphic-matching-into-a-piece/?spm=a2c4g.11186623.help-menu-193643.d_3_2_0_1.7c3d6997qndkZj).
*   When JobType is set to Screen_Media_Highlights_Media_Select, see [Highlight mashup](https://help.aliyun.com/zh/ims/use-cases/create-highlight-videos?spm=a2c4g.11186623.help-menu-193643.d_3_2_0_3.84b5661bIcQULE).

This parameter is required.', example='{
	"BackgroundMusic": "****75c3936f3a8743850f2da942****",
	"MediaArray": [
		"https://test-bucket.oss-cn-shanghai.aliyuncs.com/test.mp4"
	],
	"SpeechTextArray": [
		"Grand opening! A Freshippo store opens today at the nearby mall.",
		"Great deals on snacks and drinks. Stop by!"
	]
}', position='Body'),
  jobType: string(name='JobType', description='The job type. Valid values:

*   Smart_Mix_Media_Select
*   Screen_Media_Highlights_Media_Select

Differences:

*   Smart_Mix_Media_Select: Matches voiceover scripts with provided video/image materials to select the most relevant clips and returns the matching results. Two options are available: Common mode, which is suitable for general-purpose materials like lifestyle vlogs, travel videos, and marketing content; Movie collections, which is optimized for materials with a coherent plot and specific characters, such as TV series and movies.
*   Screen_Media_Highlights_Media_Select: Automatically identifies and selects clips that are exciting or represent key story points from longer video materials.

This parameter is required.', example='Smart_Mix_Media_Select', position='Query'),
  outputConfig: string(name='OutputConfig', description='The output configuration. Its structure and required fields depend on the value of JobType.

*   When JobType is set to Smart_Mix_Media_Select, see [Image-text matching](https://help.aliyun.com/zh/ims/use-cases/intelligent-graphic-matching-into-a-piece/?spm=a2c4g.11186623.help-menu-193643.d_3_2_0_1.7c3d6997qndkZj).
*   When JobType is set to Screen_Media_Highlights_Media_Select, see [Highlight mashup](https://help.aliyun.com/zh/ims/use-cases/create-highlight-videos?spm=a2c4g.11186623.help-menu-193643.d_3_2_0_3.84b5661bIcQULE).

This parameter is required.', example='{
  "MediaURL": "http://test-bucket.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 1,
  "Width": 1080,
  "Height": 1920
}', position='Query'),
  userData?: string(name='UserData', description='The user-defined data, including the business and callback configurations. For more information, see [UserData](~~357745#section-urj-v3f-0s1~~).', example='{"NotifyAddress":"http://xx.xx.xxx"} or {"NotifyAddress":"https://xx.xx.xxx"} or {"NotifyAddress":"ice-callback-demo"}', position='Query'),
}

model SubmitSceneMediaSelectionJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
}

model SubmitSceneMediaSelectionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSceneMediaSelectionJobResponseBody(name='body'),
}

/**
  * @description *   After a job is submitted, you can call [ListBatchMediaProducingJob](https://help.aliyun.com/document_detail/2803751.html) to query submitted jobs, or [GetBatchMediaProducingJob](https://help.aliyun.com/document_detail/2693269.html) to query the job status and results.
  * - The feature is in public preview and charges no fees.
  * @param request  the request parameters of SubmitSceneMediaSelectionJob  SubmitSceneMediaSelectionJobRequest
  * @return SubmitSceneMediaSelectionJobResponse
 */
async function submitSceneMediaSelectionJob(request: SubmitSceneMediaSelectionJobRequest): SubmitSceneMediaSelectionJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSceneMediaSelectionJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitSceneTimelineOrganizationJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  editingConfig?: string(name='EditingConfig', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}', position='Body'),
  inputConfig: string(name='InputConfig', description='This parameter is required.', position='Body'),
  jobType: string(name='JobType', description='This parameter is required.', example='Smart_Mix_Timeline_Organize', position='Query'),
  mediaSelectResult: string(name='MediaSelectResult', description='This parameter is required.', position='Query'),
  outputConfig: string(name='OutputConfig', description='This parameter is required.', example='{
  "MediaURL": "http://test-bucket.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 1,
  "Width": 1080,
  "Height": 1920
}', position='Query'),
  userData?: string(name='UserData', position='Query'),
}

model SubmitSceneTimelineOrganizationJobResponseBody = {
  jobId?: string(name='JobId', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitSceneTimelineOrganizationJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSceneTimelineOrganizationJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitSceneTimelineOrganizationJob  SubmitSceneTimelineOrganizationJobRequest
  * @return SubmitSceneTimelineOrganizationJobResponse
 */
async function submitSceneTimelineOrganizationJob(request: SubmitSceneTimelineOrganizationJobRequest): SubmitSceneTimelineOrganizationJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSceneTimelineOrganizationJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitScreenMediaHighlightsJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  editingConfig?: string(name='EditingConfig', description='The editing configuration. For detailed parameters, see [EditingConfig](~~2863940#9b05519d46e0x~~).', example='{
	"MediaConfig": {
		"Volume": 1
	},
	"ProcessConfig": {
		"AllowTransition": true,
		"TransitionList": ["fadecolor"]
	}
}', position='Body'),
  inputConfig?: string(name='InputConfig', description='The input configuration. For detailed parameters, see [InputConfig](~~2863940#dda38bf6ec2pk~~).', example='{
	"MediaArray": [
		"****9d46c886b45481030f6e****",
		"****6c886b4549d481030f6e****"
	]
}', position='Body'),
  outputConfig?: string(name='OutputConfig', description='The output configuration. For detailed parameters, see [OutputConfig](~~2863940#4111a373d0xbz~~).', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 1,
  "Width": 1080,
  "Height": 1920
}', position='Query'),
  userData?: string(name='UserData', description='The user-defined data, including the business and callback configurations. For more information, see [UserData](https://help.aliyun.com/document_detail/357745.html).', position='Query'),
}

model SubmitScreenMediaHighlightsJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the task.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model SubmitScreenMediaHighlightsJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitScreenMediaHighlightsJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitScreenMediaHighlightsJob  SubmitScreenMediaHighlightsJobRequest
  * @return SubmitScreenMediaHighlightsJobResponse
 */
async function submitScreenMediaHighlightsJob(request: SubmitScreenMediaHighlightsJobRequest): SubmitScreenMediaHighlightsJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitScreenMediaHighlightsJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitSegmentationJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****', position='Query'),
  inputConfig?: string(name='InputConfig', description='The input configuration. For detailed parameters, see [InputConfig](~~2874121#cc59ad3082jbx~~).', example='{
	"Type": "OSS",
	"Media": "http://test-bucket.oss-cn-shanghai.aliyuncs.com/test.mp4"
}
or {
	"Type": "Media",
	"Media": "ce49a020e****1ef81c1e6f6d5686302"
}', position='Body'),
  jobParams?: string(name='JobParams', description='The task parameters. For details, see [JobParams](~~2874121#a60357f2d5iix~~).', example='{
	"Mode": "UserDefined",
	"Ranges": [{
		"In": 10,
		"Out": 20
	}, {
		"In": 35,
		"Out": 50
	}]
}', position='Query'),
  outputConfig?: string(name='OutputConfig', description='The output configuration. For detailed parameters, see [OutputConfig](~~2874121#cef23186a8d6w~~).', example='{
	"OutputMediaTarget": "oss-object",
	"Bucket": "test-bucket",
	"ObjectKey": "path/to/test_{index}.mp4",
	"Width": 1920,
	"Height": 1080,
	"ExportAsNewMedia": false
}', position='Query'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length.', example='{"test": "22"}', position='Query'),
}

model SubmitSegmentationJobResponseBody = {
  jobId?: string(name='JobId', description='The task ID.', example='****cdb3e74639973036bc84****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model SubmitSegmentationJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSegmentationJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitSegmentationJob  SubmitSegmentationJobRequest
  * @return SubmitSegmentationJobResponse
 */
async function submitSegmentationJob(request: SubmitSegmentationJobRequest): SubmitSegmentationJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSegmentationJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitSmarttagJobRequest {
  content?: string(name='Content', description='The video description. The description can contain letters, digits, and hyphens (-) and cannot start with a special character. The description can be up to 1 KB in length.', example='example content ****', position='Query'),
  contentAddr?: string(name='ContentAddr', description='This parameter is discontinued.', example='http://123.com/testVideo.mp4', position='Query'),
  contentType?: string(name='ContentType', description='This parameter is discontinued.', example='application/zip', position='Query'),
  input?: {
    media?: string(name='Media', description='If Type is set to OSS, specify an OSS path. Example: OSS://test-bucket/video/202208/test.mp4.

If Type is set to Media, specify a media asset ID. Example: c5c62d8f0361337cab312dce8e77dc6d.

If Type is set to URL, specify an HTTP URL. Example: https://zc-test.oss-cn-shanghai.aliyuncs.com/test/unknowFace.mp4.', example='c5c62d8f0361337cab312dce8e77dc6d'),
    type?: string(name='Type', description='The media type. Valid values:

*   OSS
*   Media
*   URL', example='Media'),
  }(name='Input', description='The job input.', shrink='json', position='Query'),
  notifyUrl?: string(name='NotifyUrl', description='The URL for receiving callbacks. Set the value to an HTTP URL or an HTTPS URL.', example='https://example.com/endpoint/aliyun/ai?id=76401125000***', position='Query'),
  params?: string(name='Params', description='The additional request parameters. The value is a JSON string. Example: {"needAsrData":true, "needOcrData":false}. The following parameters are supported:

*   needAsrData: specifies whether to query the automatic speech recognition (ASR) data. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   needOcrData: specifies whether to query the optical character recognition (OCR) data. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   needMetaData: specifies whether to query the metadata. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   nlpParams: the input parameters of the natural language processing (NLP) operator. The value is a JSON object. This parameter is empty by default, which indicates that the NLP operator is not used. For more information, see the "nlpParams" section of this topic.', example='{"needAsrData":true, "needOcrData":false}', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which you want to submit the smart tagging job. The MPS queue is bound to an SMQ queue. This parameter specifies the default MPS queue. By default, an MPS queue can process a maximum of two concurrent smart tagging jobs. To increase the limit, submit a ticket.', example='acdbfe4323bcfdae'),
    priority?: string(name='Priority', description='The job priority. This parameter is not implemented. You can leave this parameter empty or enter a random value.', example='4'),
  }(name='ScheduleConfig', description='The scheduling configurations.', shrink='json', position='Query'),
  templateConfig?: string(name='TemplateConfig', position='Query'),
  templateId?: string(name='TemplateId', description='The ID of the template that specifies the analysis algorithms. For more information about template operations, see [Configure templates](https://help.aliyun.com/document_detail/445702.html).', example='39f8e0bc005e4f309379701645f4', position='Query'),
  title?: string(name='Title', description='The video title. The title can contain letters, digits, and hyphens (-) and cannot start with a special character. The title can be up to 256 bytes in length.', example='example-title-****', position='Query'),
  userData?: string(name='UserData', description='The data to be passed through Simple Message Queue (SMQ, formerly MNS) during callbacks. The data can be up to 1 KB in length. For more information about how to specify an SMQ queue for receiving callbacks, see UpdatePipeline.', example='{“a”:"test"}', position='Query'),
}

model SubmitSmarttagJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the smart tagging job. We recommend that you save this ID for subsequent calls of other operations.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitSmarttagJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSmarttagJobResponseBody(name='body'),
}

/**
  * @description Before you call this operation to submit a smart tagging job, you must add a smart tagging template and specify the analysis types that you want to use in the template. For more information, see CreateCustomTemplate. You can use the smart tagging feature only in the China (Beijing), China (Shanghai), and China (Hangzhou) regions. By default, an ApsaraVideo Media Processing (MPS) queue can process a maximum of two concurrent smart tagging jobs. If you need to process more concurrent smart tagging jobs, submit a ticket to contact Alibaba Cloud Technical Support for evaluation and configuration.
  * @param request  the request parameters of SubmitSmarttagJob  SubmitSmarttagJobRequest
  * @return SubmitSmarttagJobResponse
 */
async function submitSmarttagJob(request: SubmitSmarttagJobRequest): SubmitSmarttagJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSmarttagJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitSnapshotJobRequest {
  input: {
    media: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

This parameter is required.', example='oss://bucket/object.mp4'),
    type: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.

This parameter is required.', example='Media'),
  }(name='Input', description='The snapshot input.

This parameter is required.', shrink='json', position='Query'),
  name?: string(name='Name', description='The name of the job.', example='SampleJob', position='Query'),
  output: {
    media: string(name='Media', description='The output file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS. If multiple static snapshots were captured, the object must contain the "{Count}" placeholder. In the case of a sprite, the object must contain the "{TileCount}" placeholder. The suffix of the WebVTT snapshot objects must be ".vtt".

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the IMS console.

This parameter is required.', example='oss://test-bucket/output-{Count}.jpg'),
    type: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Output', description='The snapshot output.

This parameter is required.', shrink='json', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='****96e8864746a0b6f3****'),
  }(name='ScheduleConfig', description='The scheduling settings.', shrink='json', position='Query'),
  templateConfig: {
    overwriteParams?: {
      blackLevel?: int32(name='BlackLevel', description='The threshold that is used to filter out black frames for the first snapshot to be captured. This feature is available if you request the system to capture multiple snapshots.', example='30'),
      count?: long(name='Count', description='The number of snapshots.', example='5'),
      frameType?: string(name='FrameType', description='The type of the frame.', example='intra'),
      height?: int32(name='Height', description='The height of a captured snapshot.', example='480'),
      interval?: long(name='Interval', description='The interval at which snapshots are captured.', example='10'),
      isSptFrag?: boolean(name='IsSptFrag', description='The WebVTT snapshot configuration that specifies whether to merge the output snapshots.', example='true'),
      pixelBlackThreshold?: int32(name='PixelBlackThreshold', description='The color value threshold that determines whether a pixel is black.', example='70'),
      spriteSnapshotConfig?: {
        cellHeight?: int32(name='CellHeight', description='The height of a single snapshot before tiling. The default value is the height of the output snapshot.', example='480'),
        cellWidth?: int32(name='CellWidth', description='The width of a single snapshot before tiling. The default value is the width of the output snapshot.', example='720'),
        color?: string(name='Color', description='The background color.', example='#000000'),
        columns?: int32(name='Columns', description='The number of columns that the image sprite contains.', example='20'),
        lines?: int32(name='Lines', description='The number of rows that the image sprite contains.', example='20'),
        margin?: int32(name='Margin', description='The width of the frame. Default value: 0. Unit: pixels.', example='20'),
        padding?: int32(name='Padding', description='The spacing between two adjacent snapshots. Default value: 0. Unit: pixels.', example='20'),
      }(name='SpriteSnapshotConfig', description='The configuration of the sprite snapshot.'),
      time?: long(name='Time', description='The point in time at which the system starts to capture snapshots in the input video.', example='1000'),
      type?: string(name='Type', description='The snapshot type. Valid values:', example='Sprite'),
      width?: int32(name='Width', description='The width of a captured snapshot.', example='720'),
    }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters.'),
    templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
  }(name='TemplateConfig', description='The snapshot template configuration.

This parameter is required.', shrink='json', position='Query'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"test parameter": "test value"}', position='Query'),
}

model SubmitSnapshotJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSnapshotJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitSnapshotJob  SubmitSnapshotJobRequest
  * @return SubmitSnapshotJobResponse
 */
async function submitSnapshotJob(request: SubmitSnapshotJobRequest): SubmitSnapshotJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSnapshotJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitSportsHighlightsJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****', position='Query'),
  inputConfig?: string(name='InputConfig', description='The input configurations.', position='Body'),
  outputConfig?: string(name='OutputConfig', description='The output configurations.', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 1,
  "Width": 1080,
  "Height": 1920
}', position='Query'),
  userData?: string(name='UserData', description='The user-defined data.', position='Query'),
}

model SubmitSportsHighlightsJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the sports highlights job.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model SubmitSportsHighlightsJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSportsHighlightsJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitSportsHighlightsJob  SubmitSportsHighlightsJobRequest
  * @return SubmitSportsHighlightsJobResponse
 */
async function submitSportsHighlightsJob(request: SubmitSportsHighlightsJobRequest): SubmitSportsHighlightsJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSportsHighlightsJob', 'POST', '/', 'json', true, 'form', request);
}

model SubmitStandardCustomizedVoiceJobRequest {
  audios?: string(name='Audios', description='*   The material assets IDs of the materials for training.
*   Separate multiple media IDs with commas (,).

> : The total duration of all materials must be within 15 to 30 minutes. The duration of each material must be greater than 1 minute.', example='****571c704445f9a0ee011406c2****,****571c704445f9a0ee011406c2****,****571c704445f9a0ee011406c2****', position='Query'),
  authentication?: string(name='Authentication', description='*   The media asset ID of the authentication audio.

*   Upload an audio file for identity authentication. If the voiceprint extracted from the uploaded file differs from that of the training file, the job fails.

    **

    **Note**: Clearly read and record the following text: I confirm to customize human voice cloning and provide audio files that contain my voice for training. I promise that I am responsible for the customized content and that the content complies with laws and regulations.', example='****571c704445f9a0ee011406c2****', position='Query'),
  demoAudioMediaURL?: string(name='DemoAudioMediaURL', description='The URL of the sample audio file.

*   If this parameter is specified, a sample audio file is generated at the specified Object Storage Service (OSS) URL after the training is complete.

*   If this parameter is not specified, no sample audio file is generated.

    **

    **Note**: The URL must be a valid public OSS URL within your Alibaba Cloud account.', example='https://your-bucket.oss-cn-shanghai.aliyuncs.com/demo.mp3', position='Query'),
  gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female', position='Query'),
  voiceName?: string(name='VoiceName', description='The voice name.

*   The name can be up to 32 characters in length.', position='Query'),
}

model SubmitStandardCustomizedVoiceJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model SubmitStandardCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitStandardCustomizedVoiceJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitStandardCustomizedVoiceJob  SubmitStandardCustomizedVoiceJobRequest
  * @return SubmitStandardCustomizedVoiceJobResponse
 */
async function submitStandardCustomizedVoiceJob(request: SubmitStandardCustomizedVoiceJobRequest): SubmitStandardCustomizedVoiceJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitStandardCustomizedVoiceJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitSyncMediaInfoJobRequest {
  input: {
    media: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
    type: string(name='Type', description='The type of the media object.

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The input of the job.

This parameter is required.', shrink='json', position='Query'),
  name?: string(name='Name', description='The job name.', example='job-name', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling parameters. This parameter is optional.', shrink='json', position='Query'),
  userData?: string(name='UserData', description='The user data.', example='user-data', position='Query'),
}

model SubmitSyncMediaInfoJobResponseBody = {
  mediaInfoJob?: {
    async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    input?: {
      media?: string(name='Media', description='The media object. If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    mediaInfoProperty?: {
      audioStreamInfoList?: [ 
        {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
          channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
          codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
          codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
          codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
          codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          index?: string(name='Index', description='The sequence number of the stream.', example='1'),
          lang?: string(name='Lang', description='The language of the stream.', example='us'),
          sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
          sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
          startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
          timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
        }
      ](name='AudioStreamInfoList', description='The information about the audio stream.'),
      fileBasicInfo?: {
        bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
        duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
        fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
        fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
        fileStatus?: string(name='FileStatus', description='The state of the file. Valid values:

*   Normal', example='Normal'),
        fileType?: string(name='FileType', description='The file type.', example='source_file'),
        fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
        formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
        height?: string(name='Height', description='The height of the output video.', example='478'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='999e68259c924f52a6be603cbb3f91cc'),
        region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
        width?: string(name='Width', description='The width of the output video.', example='848'),
      }(name='FileBasicInfo', description='The basic file information.'),
      videoStreamInfoList?: [ 
        {
          avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
          bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
          codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
          codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
          codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
          codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
          codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
          dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          fps?: string(name='Fps', description='The frame rate.', example='25.0'),
          hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
          height?: string(name='Height', description='The height of the output video.', example='478'),
          index?: string(name='Index', description='The sequence number of the stream.', example='0'),
          lang?: string(name='Lang', description='The language of the stream.', example='zh'),
          level?: string(name='Level', description='The codec level.', example='31'),
          numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
          pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
          profile?: string(name='Profile', description='The encoder profile.', example='High'),
          rotate?: string(name='Rotate', description='The rotation angle of the video image.', example='0'),
          sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
          startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
          timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
          width?: string(name='Width', description='The width of the output video.', example='848'),
        }
      ](name='VideoStreamInfoList', description='The information about the video stream.'),
    }(name='MediaInfoProperty', description='The details of the media information.'),
    name?: string(name='Name', description='The job name.', example='job-name'),
    requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling information.'),
    status?: string(name='Status', description='The state of the job. Valid values: Init (the job is submitted), Success (the job is successful), and Fail (the job failed).', example='Init'),
    submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.', example='{}'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='MediaInfoJob', description='MediaInfoJobDTO'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model SubmitSyncMediaInfoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSyncMediaInfoJobResponseBody(name='body'),
}

/**
  * @description You can call this operation to analyze an input media file in synchronous mode. This operation is suitable for scenarios that require high real-time performance and low concurrency. If it takes an extended period of time to obtain the media information about the input media file, the request may time out or the obtained information may be inaccurate. We recommend that you call the [SubmitMediaInfoJob](https://help.aliyun.com/document_detail/441222.html) operation to obtain media information.
  * @param request  the request parameters of SubmitSyncMediaInfoJob  SubmitSyncMediaInfoJobRequest
  * @return SubmitSyncMediaInfoJobResponse
 */
async function submitSyncMediaInfoJob(request: SubmitSyncMediaInfoJobRequest): SubmitSyncMediaInfoJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSyncMediaInfoJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitTextGenerateJobRequest {
  description?: string(name='Description', description='The job description, which can be up to 1,024 bytes in length and must be encoded in UTF-8.', position='Query'),
  generateConfig?: string(name='GenerateConfig', description='The text generation configurations, including keywords and the requirements for the word count and number of output copies.', position='Query'),
  title?: string(name='Title', description='The job title.

The job title can be up to 128 bytes in length.

The value must be encoded in UTF-8.', position='Query'),
  type?: string(name='Type', description='The job type.

Valid values:

*   MarketingCopy: the marketing copy.
*   Title: the short video title.', example='MarketingCopy', position='Query'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).', position='Query'),
}

model SubmitTextGenerateJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitTextGenerateJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTextGenerateJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitTextGenerateJob  SubmitTextGenerateJobRequest
  * @return SubmitTextGenerateJobResponse
 */
async function submitTextGenerateJob(request: SubmitTextGenerateJobRequest): SubmitTextGenerateJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitTextGenerateJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitTraceAbJobRequest {
  cipherBase64ed?: string(name='CipherBase64ed', description='The key that is encoded by using the Base64 algorithm.', example='Qh6OdgIMcliQSI1fReOw****', position='Query'),
  input: {
    media: string(name='Media', description='The source file. The file can be an OSS object or a media asset. You can specify the path of an OSS object in one of the following formats:

1\\. oss://bucket/object

2\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

where bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object path in OSS.

This parameter is required.', example='oss://bucket/object'),
    type: string(name='Type', description='The type of the source file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The source video file for A/B watermarking.

> OSS object or media asset must reside in the same region as the IMS service region. This API supports only videos that last at least 3 minutes. If the video is too short, the call may fail, or no output may be returned.

This parameter is required.', shrink='json', position='Query'),
  level?: long(name='Level', description='The watermark level, which specifies the channel to embed watermarks. Valid values: 0 specifies the 0u channel, 1 specifies the 1uv channel, and 2 specifies the 2yuv channel.', example='0', position='Query'),
  output: {
    media: string(name='Media', description='The output file. The file can be an OSS object or a media asset. OSS URL formats:

1\\. oss://bucket/dir/

2\\. http(s)://bucket.oss-[regionId].aliyuncs.com/dir/

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and dir specifies the object path in OSS.

This parameter is required.', example='oss://bucket/dir/'),
    type: string(name='Type', description='The type of the output file. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Output', description='The output directory path.

This parameter is required.', shrink='json', position='Query'),
  startTime?: long(name='StartTime', description='The start point of watermark embedding. Unit: seconds.', example='0', position='Query'),
  totalTime?: long(name='TotalTime', description='The duration of the watermark embedding. Unit: seconds.', example='360', position='Query'),
  userData?: string(name='UserData', description='The custom data, which can be up to 1,024 bytes in size.', example='123', position='Query'),
}

model SubmitTraceAbJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The job ID.', example='bfb786c639894f4d80648792021e****'),
    traceMediaId?: string(name='TraceMediaId', description='The media ID.', example='bf53333264f4d80648792021e****'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The message returned.', example='ok'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******36-3C1E-4417-BDB2-1E034F******'),
  statusCode?: long(name='StatusCode', description='The status code.', example='200'),
}

model SubmitTraceAbJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTraceAbJobResponseBody(name='body'),
}

/**
  * @description *   This API supports only videos that last at least 3 minutes. If the video is too short, the call may fail, or no output may be returned.
  * @param request  the request parameters of SubmitTraceAbJob  SubmitTraceAbJobRequest
  * @return SubmitTraceAbJobResponse
 */
async function submitTraceAbJob(request: SubmitTraceAbJobRequest): SubmitTraceAbJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitTraceAbJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitTraceExtractJobRequest {
  input: {
    media: string(name='Media', description='The specific information for the source file, which can be an OSS URL or a media asset ID. OSS URL formats:

1\\. oss://bucket/object

2\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

where bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object path in OSS.

This parameter is required.', example='oss://bucket/object'),
    type: string(name='Type', description='The type of the source file. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The source video file from which to extract the watermark.

> The OSS object or media asset must reside in the same region as the IMS service region.

This parameter is required.', shrink='json', position='Query'),
  params?: string(name='Params', description='Additional parameters for the watermark job, provided as a JSON string. Supported parameter:

*   m3u8Type: The extraction algorithm type. Defaults to v1.

    *   v1: Extracts from an M3U8 with absolute paths.
    *   v2: Extracts from an M3U8 with relative paths.', example='{"m3u8Type":"v1"}', position='Query'),
  userData?: string(name='UserData', description='The custom data, which can be up to 1,024 bytes in size.', example='123', position='Query'),
}

model SubmitTraceExtractJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The job ID.', example='bfb786c639894f4d80648792021e****'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The message returned.', example='ok'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  statusCode?: long(name='StatusCode', description='The status code.', example='200'),
}

model SubmitTraceExtractJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTraceExtractJobResponseBody(name='body'),
}

/**
  * @description *   This operation is supported only in the China (Shanghai) and China (Beijing) regions.
  * *   The input video must be 3 minutes or longer. Jobs submitted with shorter videos will fail.
  * @param request  the request parameters of SubmitTraceExtractJob  SubmitTraceExtractJobRequest
  * @return SubmitTraceExtractJobResponse
 */
async function submitTraceExtractJob(request: SubmitTraceExtractJobRequest): SubmitTraceExtractJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitTraceExtractJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitTraceM3u8JobRequest {
  keyUri?: string(name='KeyUri', description='The URI of the key server.', example='https://cipher.abc.com', position='Query'),
  output: {
    media: string(name='Media', description='The OSS path where the output file is saved. You can specify the path in one of the following formats:

1\\. oss://bucket/object

2\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object where bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object path in OSS.

This parameter is required.', example='oss://bucket/object'),
    type: string(name='Type', description='The type of the output file. Valid value:

1.  OSS: an OSS object.

This parameter is required.', example='OSS'),
  }(name='Output', description='The OSS URL of the output M3U8 file.

> The OSS bucket must reside in the same region as the service region.

This parameter is required.', shrink='json', position='Query'),
  params?: string(name='Params', description='Additional parameters for the watermark job, provided as a JSON string. Supported parameter:

*   m3u8Type: The type of M3U8 to generate. Defaults to v1.

    *   v1: Generates an M3U8 with absolute paths, playable directly. The signed URL for access is valid for 24 hours. If you need to use it after expiration, you must call this API again.
    *   v2: Generates an M3U8 with relative paths. It must be placed in the same directory as the TS segment files to be playable.', example='{"m3u8Type":"v1"}', position='Query'),
  trace?: string(name='Trace', description='The specific trace watermark information.', position='Query'),
  traceMediaId?: string(name='TraceMediaId', description='The media ID for the trace watermark. You can obtain this from the response of the SubmitTraceAbJob operation.', example='437bd2b516ffda105d07b12a9a82****', position='Query'),
}

model SubmitTraceM3u8JobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The job ID.', example='bfb786c639894f4d8064879202****'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The response message.', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitTraceM3u8JobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTraceM3u8JobResponseBody(name='body'),
}

/**
  * @description *   Before you call this operation, you must call SubmitTraceAbJob to get the TraceMediaId from its response.
  * *   This operation is supported only in the China (Shanghai) and China (Beijing) regions.
  * *   The M3U8 file generated by this job has a signed URL with an authentication validity period of 24 hours, starting from the moment the job is completed. Once the signature expires, you will no longer be able to trace the watermark information using that specific M3U8 file. If you need to use it after expiration, you must call this API again to generate a new M3U8 file.
  * @param request  the request parameters of SubmitTraceM3u8Job  SubmitTraceM3u8JobRequest
  * @return SubmitTraceM3u8JobResponse
 */
async function submitTraceM3u8Job(request: SubmitTraceM3u8JobRequest): SubmitTraceM3u8JobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitTraceM3u8Job', 'POST', '/', 'json', false, 'json', request);
}

model SubmitTranscodeJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****', position='Query'),
  inputGroup: [ 
    {
      inputUrl?: string(name='InputUrl', description='The URL of the input stream.

*   This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an input.
*   The system checks whether the input URL exists within the media asset.', example='oss://bucket/path/to/video.mp4'),
      media: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
      type: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
    }
  ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.

This parameter is required.', example='job-name', shrink='json', position='Query'),
  name?: string(name='Name', description='The job name.', example='job-name', position='Query'),
  outputGroup: [ 
    {
      output: {
        media: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the IMS console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
        outputUrl?: string(name='OutputUrl', description='The URL of the output stream.\\
This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an output.\\
Supported placeholders:

*   {MediaId}: the ID of the media asset.
*   {JobId}: the ID of the transcoding subjob.
*   {MediaBucket}: the bucket to which the media asset belongs.
*   {ExtName}: the file suffix, which uses the output format of the transcoding template.
*   {DestMd5}: the MD5 value of the transcoded output file.\\
    Notes:

1.  This parameter must contain the {MediaId} and {JobId} placeholders.
2.  The output bucket is the same as the bucket to which the media asset belongs.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
        type: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
      }(name='Output', description='The output file configuration.

This parameter is required.'),
      processConfig: {
        combineConfigs?: [ 
          {
            audioIndex: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
            duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
            start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
            videoIndex: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
          }
        ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
        encryption?: {
          cipherText?: string(name='CipherText', description='The ciphertext of HTTP Live Streaming (HLS) encryption.', example='MTYi00NDU0LTg5O****'),
          decryptKeyUri?: string(name='DecryptKeyUri', description='The address of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
          encryptType?: string(name='EncryptType', description='Specifies the encryption type. Valid values:

*   PrivateEncryption: Alibaba Cloud proprietary cryptography
*   HLSEncryption: HTTP Live Streaming (HLS) encryption', example='PrivateEncryption'),
          keyServiceType?: string(name='KeyServiceType', description='The key service type for HLS encryption. Valid values:

*   KMS
*   Base64', example='KMS'),
        }(name='Encryption', description='The encryption settings.'),
        imageWatermarks?: [ 
          {
            overwriteParams?: {
              dx?: string(name='Dx', description='The horizontal offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the horizontal offset to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
              dy?: string(name='Dy', description='The vertical offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the vertical offset to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
              file?: {
                media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
              }(name='File', description='The watermark image file.'),
              height?: string(name='Height', description='The height of the watermark image in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark height.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark height to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
              referPos?: string(name='ReferPos', description='The position of the watermark.

*   Valid values: TopRight, TopLeft, BottomRight, and BottomLeft.
*   Default value: TopRight.', example='TopLeft'),
              timeline?: {
                duration?: string(name='Duration', description='The time range in which the watermark is displayed.

*   Valid values: integers and ToEND.
*   Default value: ToEND.', example='ToEND'),
                start?: string(name='Start', description='The beginning of the time range in which the watermark is displayed.

*   Unit: seconds.
*   Value values: integers.
*   Default value: 0.', example='00:00:05'),
              }(name='Timeline', description='The time settings of the dynamic watermark.'),
              width?: string(name='Width', description='The width of the watermark in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark width.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark width to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }
        ](name='ImageWatermarks', description='The watermark configuration of an image.'),
        subtitles?: [ 
          {
            overwriteParams?: {
              charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
              file?: {
                media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
              }(name='File', description='The subtitle file.'),
              format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }
        ](name='Subtitles', description='The subtitle configuration.'),
        textWatermarks?: [ 
          {
            overwriteParams?: {
              adaptive?: string(name='Adaptive', description='Specifies whether to the font size based on the output video dimensions. true / false, default: false', example='false'),
              borderColor?: string(name='BorderColor', description='The outline color of the text watermark. Default value: black. For more information, see BorderColor.', example='#006400'),
              borderWidth?: int32(name='BorderWidth', description='The outline width of the text watermark.

*   Default value: 0.
*   Valid values: (0,4096].', example='0'),
              content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
              fontAlpha?: string(name='FontAlpha', description='The transparency of the text.

*   Valid values: (0,1].
*   Default value: 1.', example='1.0'),
              fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
              fontName?: string(name='FontName', description='The font of the text. Default value: SimSun.', example='SimSun'),
              fontSize?: int32(name='FontSize', description='The size of the text.

*   Default value: 16.
*   Valid values: (4,120).', example='16'),
              left?: string(name='Left', description='The left margin of the text watermark.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
              top?: string(name='Top', description='The top margin of the text.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }
        ](name='TextWatermarks', description='The configurations of the text watermark.'),
        transcode: {
          overwriteParams?: {
            audio?: {
              bitrate?: string(name='Bitrate', description='The audio bitrate of the output file. Valid values: [8,1000]. Unit: Kbit/s. Default value: 128.', example='128'),
              channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
              codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
              profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
              remove?: string(name='Remove', description='Specifies whether to delete the audio stream.', example='false'),
              samplerate?: string(name='Samplerate', description='The sampling rate. Valid values: 22050, 32000, 44100, 48000, and 96000. Default value: 44100. Unit: Hz.', example='44100'),
              volume?: {
                integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
              }(name='Volume', description='The volume configurations.'),
            }(name='Audio', description='The audio settings.'),
            container?: {
              format?: string(name='Format', description='The container format.', example='mp4'),
            }(name='Container', description='The encapsulation format settings.'),
            muxConfig?: {
              segment?: {
                duration?: string(name='Duration', description='The segment length.', example='10'),
                forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
              }(name='Segment', description='The segment settings.'),
            }(name='MuxConfig', description='The encapsulation settings.'),
            transConfig?: {
              adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
              isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false: does not check the video resolution.

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
              isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckReso?: string(name='IsCheckReso', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckResoFail?: string(name='IsCheckResoFail', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
            }(name='TransConfig', description='The conditional transcoding configurations.'),
            video?: {
              abrMax?: string(name='AbrMax', description='The maximum adaptive bitrate (ABR). This parameter takes effect only for Narrowband HD 1.0. Valid values: [10,50000]. Unit: Kbit/s.', example='6000'),
              bitrate?: string(name='Bitrate', description='The average video bitrate. Valid values: [10,50000]. Unit: Kbit/s.', example='3000'),
              bufsize?: string(name='Bufsize', description='The buffer size. Valid values: [1000,128000]. Default value: 6000. Unit: KB.', example='6000'),
              codec?: string(name='Codec', description='The encoding format.', example='H.264'),
              crf?: string(name='Crf', description='The constant rate factor (CRF). Valid values: [0,51]. Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.

>  If this parameter is specified, the setting of the bitrate becomes invalid.', example='23'),
              crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
              fps?: string(name='Fps', description='The frame rate. Valid values:(0,60]. Default value: the frame rate of the input file.

>  The value is 60 if the frame rate of the input file exceeds 60.', example='25'),
              gop?: string(name='Gop', description='The maximum number of frames between keyframes. Valid values: [1,1080000]. Default value: 250.', example='250'),
              height?: string(name='Height', description='The height of the video. Valid values: [128,4096]. Unit: pixels. Default value: the original height of the video.', example='1080'),
              longShortMode?: string(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature.', example='false'),
              maxrate?: string(name='Maxrate', description='The maximum bitrate of the video. Valid values: [10,50000]. Unit: Kbit/s.', example='9000'),
              pad?: string(name='Pad', description='The black bars added to the video. Format: width:height:left:top. Example: 1280:800:0:140.', example='1280:800:0:140'),
              pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
              preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
              profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
              remove?: string(name='Remove', description='Specifies whether to remove the video.', example='false'),
              scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
              width?: string(name='Width', description='The width of the video. Valid values: [128,4096]. Unit: pixels. Default value: the original width of the video.', example='1920'),
            }(name='Video', description='The video settings.'),
          }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
          templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
        }(name='Transcode', description='The transcoding configuration.

This parameter is required.'),
      }(name='ProcessConfig', description='The job processing configuration.

This parameter is required.'),
    }
  ](name='OutputGroup', description='The output group of the job.

This parameter is required.', example='user-data', shrink='json', position='Query'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling information about the job.', example='job-name', shrink='json', position='Query'),
  userData?: string(name='UserData', description='The custom settings. The value must be in the JSON format and can be up to 512 bytes in length. You can specify a [custom callback URL](https://help.aliyun.com/document_detail/451631.html).', example='user-data', position='Query'),
}

model SubmitTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
  transcodeParentJob?: {
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    inputGroup?: [ 
      {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
      }
    ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
    jobCount?: int32(name='JobCount', description='The number of subjobs.', example='1'),
    name?: string(name='Name', description='The job name.', example='transcode-job'),
    outputGroup?: [ 
      {
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HLS encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The address of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='Specifies the encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The horizontal offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the horizontal offset to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                dy?: string(name='Dy', description='The vertical offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the vertical offset to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the watermark image in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark height.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark height to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
                referPos?: string(name='ReferPos', description='The position of the watermark.

*   Valid values: TopRight, TopLeft, BottomRight, and BottomLeft.
*   Default value: TopRight.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The time range in which the watermark is displayed.

*   Valid values: integers and ToEND.
*   Default value: ToEND.', example='ToEND'),
                  start?: string(name='Start', description='The beginning of the time range in which the watermark is displayed.

*   Unit: seconds.
*   Value values: integers.
*   Default value: 0.', example='00:00:05'),
                }(name='Timeline', description='The time settings of the dynamic watermark.'),
                width?: string(name='Width', description='The width of the watermark in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark width.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark width to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object. If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Specifies whether to the font size based on the output video dimensions.

*   true: false
*   default: false', example='false'),
                borderColor?: string(name='BorderColor', description='The outline color of the text watermark. Default value: black. For more information, see BorderColor.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The outline width of the text watermark.

*   Default value: 0.
*   Valid values: (0,4096].', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the text.

*   Valid values: (0,1].
*   Default value: 1.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text. Default value: SimSun.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.

*   Default value: 16.
*   Valid values: (4,120).', example='16'),
                left?: string(name='Left', description='The left margin of the text watermark.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
                top?: string(name='Top', description='The top margin of the text.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Specifies whether to delete the audio stream.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Valid values: 22050, 32000, 44100, 48000, and 96000. Default value: 44100.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false: does not check the video resolution.

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum ABR. This parameter takes effect only for Narrowband HD 1.0.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or Default value when the Codec parameter is set to H.265: 26.

If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Specifies whether to remove the video.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The job processing configuration.'),
      }
    ](name='OutputGroup', description='The output group of the job.'),
    parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
    percent?: int32(name='Percent', description='The completion percentage of the job.', example='0'),
    requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling configuration of the job.'),
    status?: string(name='Status', description='The state of the job. Success: At least one of the subjobs is successful. Fail: All subjobs failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    transcodeJobList?: [ 
      {
        createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-01-12T08:49:41Z'),
        finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
        inputGroup?: [ 
          {
            inputUrl?: string(name='InputUrl', description='The URL of the input stream:

*   This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an input.
*   The system checks whether the input URL exists within the media asset.', example='oss://bucket/path/to/video.mp4'),
            media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
            type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
          }
        ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
        jobId?: string(name='JobId', description='The subjob ID.', example='7d6a7e0d4db2457a8d45ff5d43e1bf0a'),
        jobIndex?: int32(name='JobIndex', description='The index number of the subjob in the entire job.', example='0'),
        name?: string(name='Name', description='The job name.', example='transcode-job'),
        outFileMeta?: {
          audioStreamInfoList?: [ 
            {
              bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
              channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
              channels?: string(name='Channels', description='The number of sound channels.', example='2'),
              codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
              codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
              codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
              codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
              codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              index?: string(name='Index', description='The sequence number of the stream.', example='1'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
              sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
              startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
              timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
            }
          ](name='AudioStreamInfoList', description='The information about the audio stream.'),
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
            duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
            fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
            fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
            fileType?: string(name='FileType', description='The file type. Valid values: source_file and transcode_file.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
            formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
            height?: string(name='Height', description='The height of the output video.', example='478'),
            mediaId?: string(name='MediaId', description='The ID of the media asset.', example='73e07de0f77171eca3fc7035d0b26402'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width of the output video.', example='848'),
          }(name='FileBasicInfo', description='The basic file information.'),
          videoStreamInfoList?: [ 
            {
              avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
              bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
              codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
              codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
              codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
              codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
              codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
              dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              fps?: string(name='Fps', description='The frame rate.', example='25.0'),
              hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
              height?: string(name='Height', description='The height of the output video.', example='478'),
              index?: string(name='Index', description='The sequence number of the stream.', example='0'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              level?: string(name='Level', description='The codec level.', example='31'),
              numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
              pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
              profile?: string(name='Profile', description='The encoder profile.', example='High'),
              rotate?: string(name='Rotate', description='The rotation angle of the video image. Valid values: 0, 90, 180, and 270. Default value: 0.', example='0'),
              sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
              startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
              timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
              width?: string(name='Width', description='The width of the output video.', example='848'),
            }
          ](name='VideoStreamInfoList', description='The information about the video stream.'),
        }(name='OutFileMeta', description='The media information about the video generated by the job.'),
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
          outputUrl?: string(name='OutputUrl', description='The URL of the output stream.\\
This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an output.\\
Supported placeholders:

*   {MediaId}: the ID of the media asset.
*   {JobId}: the ID of the transcoding subjob.
*   {MediaBucket}: the bucket to which the media asset belongs.
*   {ExtName}: the file suffix, which uses the output format of the transcoding template.
*   {DestMd5}: the MD5 value of the transcoded output file.\\
    Notes:

1.  This parameter must contain the {MediaId} and {JobId} placeholders.
2.  The output bucket is the same as the bucket to which the media asset belongs.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HLS encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The address of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='Specifies the encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The horizontal offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the horizontal offset to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                dy?: string(name='Dy', description='The vertical offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the vertical offset to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the watermark image in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark height.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark height to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
                referPos?: string(name='ReferPos', description='The position of the watermark.

*   Valid values: TopRight, TopLeft, BottomRight, and BottomLeft.
*   Default value: TopRight.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The time range in which the watermark is displayed.

*   Valid values: integers and ToEND.
*   Default value: ToEND.', example='ToEND'),
                  start?: string(name='Start', description='The beginning of the time range in which the watermark is displayed.

*   Unit: seconds.
*   Value values: integers.
*   Default value: 0.', example='00:00:05'),
                }(name='Timeline', description='The time settings of the dynamic watermark.'),
                width?: string(name='Width', description='The width of the watermark in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark width.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark width to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Specifies whether to the font size based on the output video dimensions. true / false, default: false', example='false'),
                borderColor?: string(name='BorderColor', description='The outline color of the text watermark. Default value: black. For more information, see BorderColor.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The outline width of the text watermark.

*   Default value: 0.
*   Valid values: (0,4096].', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the text.

*   Valid values: (0,1].
*   Default value: 1.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text. Default value: SimSun.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.

*   Default value: 16.
*   Valid values: (4,120).', example='16'),
                left?: string(name='Left', description='The left margin of the text watermark.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
                top?: string(name='Top', description='The top margin of the text.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Specifies whether to delete the audio stream.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100.
*   Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false: does not check the video resolution.

Default values:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution. This is the default value.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. This is the default value. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum ABR. This parameter takes effect only for Narrowband HD 1.0. Valid values: [10,50000]. Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or Default value when the Codec parameter is set to H.265: 26.

If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video. Valid values: [10,50000]. Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Specifies whether to remove the video.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The transcoding configuration.'),
        requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
        scheduleConfig?: {
          pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
          priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
        }(name='ScheduleConfig', description='The scheduling information about the job.'),
        status?: string(name='Status', description='The state of the transcoding job. Valid values:

*   Init: The job is submitted.
*   Processing: The job is in progress.
*   Success: The job is successful.
*   Fail: The job failed.
*   Deleted: The job is deleted.', example='Init'),
        submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission result.', example='{}'),
        submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
        userData?: string(name='UserData', description='The user data.', example='user-data'),
      }
    ](name='TranscodeJobList', description='The list of subjobs.'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='TranscodeParentJob', description='TranscodeParentJobWithSubJobDTO'),
}

model SubmitTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTranscodeJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitTranscodeJob  SubmitTranscodeJobRequest
  * @return SubmitTranscodeJobResponse
 */
async function submitTranscodeJob(request: SubmitTranscodeJobRequest): SubmitTranscodeJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitTranscodeJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitVideoCognitionJobRequest {
  input?: {
    media?: string(name='Media', description='If Type is set to OSS, specify an OSS path. Example: OSS://test-bucket/video/202208/test.mp4.

If Type is set to Media, specify a media asset ID. Example: c5c62d8f0361337cab312dce8e77dc6d.

If Type is set to URL, specify an HTTP URL. Example: https://zc-test.oss-cn-shanghai.aliyuncs.com/test/unknowFace.mp4.', example='c5c62d8f03613************c6d'),
    type?: string(name='Type', description='The type of media input. Valid values:

*   OSS
*   Media
*   URL', example='Media'),
  }(name='Input', description='The media input object.', shrink='json', position='Query'),
  params?: string(name='Params', description='Additional request parameters, provided as a JSON string. This is used to pass specific settings for various AI analysis modules, such as Natural Language Processing (NLP), shot segmentation, tagging, and action recognition.', example='{
	"nlpParams": {
		"sourceLanguage": "cn",
		"diarizationEnabled": true,
		"speakerCount": 2,
		"summarizationEnabled": true,
		"summarizationTypes": "Paragraph,Conversational,QuestionsAnswering,MindMap",
		"translationEnabled": true,
		"targetLanguages": "en",
		"autoChaptersEnabled": true,
		"meetingAssistanceEnabled": true
	}
}', position='Query'),
  templateConfig?: string(name='TemplateConfig', position='Query'),
  templateId?: string(name='TemplateId', description='The ID of the template that specifies the analysis algorithms to be used. For details, see [CreateCustomTemplate](https://help.aliyun.com/zh/ims/developer-reference/api-ice-2020-11-09-createcustomtemplate?spm=a2c4g.11186623.help-menu-193643.d_5_0_3_3_0_0.17b66afamjKySv) and [smart tagging template](https://help.aliyun.com/zh/ims/user-guide/smart-tagging-template?spm=a2c4g.11186623.0.i15).', example='39f8e0bc00***************', position='Query'),
  title?: string(name='Title', description='The video title. It supports letters, digits, and hyphens (-), and cannot start with a special character. Max length: 256 bytes.', example='example-title-****', position='Query'),
  userData?: string(name='UserData', description='The user-defined data that is passed through and returned as-is in the response. Max length: 1,024 bytes.', example='{"test":1}', position='Query'),
}

model SubmitVideoCognitionJobResponseBody = {
  jobId?: string(name='JobId', description='The task ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitVideoCognitionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitVideoCognitionJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitVideoCognitionJob  SubmitVideoCognitionJobRequest
  * @return SubmitVideoCognitionJobResponse
 */
async function submitVideoCognitionJob(request: SubmitVideoCognitionJobRequest): SubmitVideoCognitionJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitVideoCognitionJob', 'POST', '/', 'json', false, 'json', request);
}

model SubmitVideoTranslationJobRequest {
  clientToken?: string(name='ClientToken', description='*   The client token.', position='Query'),
  description?: string(name='Description', description='*   The job description.', position='Query'),
  editingConfig?: string(name='EditingConfig', description='*   The configuration parameters of the video translation job.
*   The value must be in the JSON format.', example='{"SourceLanguage":"zh","TargetLanguage":"en","DetextArea":"Auto"}', position='Query'),
  inputConfig?: string(name='InputConfig', description='*   The input parameters of the video translation job.
*   A video translation job takes a video or subtitle file as the input.
*   The value must be in the JSON format.', example='{"Type":"Video","Media":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/xxx.mp4"}', position='Query'),
  outputConfig?: string(name='OutputConfig', description='*   The output parameters of the video translation job.
*   A video translation job can generate a video or subtitle file as the output.', example='{"MediaURL": "https://your-bucket.oss-cn-shanghai.aliyuncs.com/your-object.mp4"}', position='Query'),
  signature?: string(name='Signature', position='Query'),
  signatureMehtod?: string(name='SignatureMehtod', position='Query'),
  signatureNonce?: string(name='SignatureNonce', position='Query'),
  signatureType?: string(name='SignatureType', position='Query'),
  signatureVersion?: string(name='SignatureVersion', position='Query'),
  title?: string(name='Title', description='*   The job title.', position='Query'),
  userData?: string(name='UserData', description='*   The user-defined data.
*   The data must be in the JSON format, and can be up to 512 characters in length.', example='{"NotifyAddress":"http://xx.xx.xxx"}', position='Query'),
}

model SubmitVideoTranslationJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the video translation job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.

Valid values:

*   true
*   false', example='true'),
}

model SubmitVideoTranslationJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitVideoTranslationJobResponseBody(name='body'),
}

/**
  * @description After you call this operation to submit a video translation job, the system returns a job ID. You can call the GetSmartHandleJob operation based on the job ID to obtain the status and result information of the job.
  * @param request  the request parameters of SubmitVideoTranslationJob  SubmitVideoTranslationJobRequest
  * @return SubmitVideoTranslationJobResponse
 */
async function submitVideoTranslationJob(request: SubmitVideoTranslationJobRequest): SubmitVideoTranslationJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitVideoTranslationJob', 'POST', '/', 'json', false, 'json', request);
}

model TakeoverAIAgentCallRequest {
  humanAgentUserId?: string(name='HumanAgentUserId', description='The ID of the human agent that will take over the AI agent (UserId in ARTC). If you do not specify this parameter, it is automatically generated and returned.', example='uid2', position='Query'),
  instanceId?: string(name='InstanceId', description='The ID of the AI agent that will be taken over.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
  requireToken?: boolean(name='RequireToken', description='Specifies whether to return the ARTC token. Default value: false.', example='false', position='Query'),
}

model TakeoverAIAgentCallResponseBody = {
  channelId?: string(name='ChannelId', description='The ID of the ARTC channel.', example='70f22d5784194938a7e387052f2b3208'),
  humanAgentUserId?: string(name='HumanAgentUserId', description='The ID of the human agent.', example='uid2'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
  token?: string(name='Token', description='The ARTC token.', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx'),
}

model TakeoverAIAgentCallResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: TakeoverAIAgentCallResponseBody(name='body'),
}

/**
  * @param request  the request parameters of TakeoverAIAgentCall  TakeoverAIAgentCallRequest
  * @return TakeoverAIAgentCallResponse
 */
async function takeoverAIAgentCall(request: TakeoverAIAgentCallRequest): TakeoverAIAgentCallResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'TakeoverAIAgentCall', 'POST', '/', 'json', false, 'json', request);
}

model UpdateAIAgentInstanceRequest {
  agentConfig?: AIAgentConfig(name='AgentConfig', shrink='json', position='Query'),
  instanceId: string(name='InstanceId', description='The ID of the AI agent that you want to update.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****', position='Query'),
  templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', description='The template configurations of the AI agent. The configurations are merged with the template configurations that are used to start the AI agent. For more information, see the definition of TemplateConfig.', deprecated='true', shrink='json', position='Query'),
  userData?: string(name='UserData', example='{"VoiceId":"xiaoxia"}', position='Query'),
}

model UpdateAIAgentInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model UpdateAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAIAgentInstanceResponseBody(name='body'),
}

/**
  * @description ## [](#)Request description
  * You can call this operation to update the configurations of an AI agent, such as the tone, by specifying the agent ID and configurations.
  * @param request  the request parameters of UpdateAIAgentInstance  UpdateAIAgentInstanceRequest
  * @return UpdateAIAgentInstanceResponse
 */
async function updateAIAgentInstance(request: UpdateAIAgentInstanceRequest): UpdateAIAgentInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateAIAgentInstance', 'POST', '/', 'json', false, 'json', request);
}

model UpdateAdInsertionRequest {
  adMarkerPassthrough?: string(name='AdMarkerPassthrough', description='Specifies whether to enable ad marker passthrough. Default value: OFF.

Valid values:

*   OFF: Disable.
*   ON: Enable.', example='ON', position='Body'),
  adsUrl: string(name='AdsUrl', description='The request URL of the ad decision server (ADS). HTTP and HTTPS are supported. The maximum length is 2,048 characters.

This parameter is required.', example='http://ads.com/ad1?param1=[palyer_params.p1]', position='Body'),
  cdnAdSegmentUrlPrefix?: string(name='CdnAdSegmentUrlPrefix', description='The CDN prefix for ad segments. HTTP and HTTPS are supported. The maximum length is 512 characters.', example='http://cdn.com/', position='Body'),
  cdnContentSegmentUrlPrefix?: string(name='CdnContentSegmentUrlPrefix', description='The CDN prefix for content segments. HTTP and HTTPS are supported. The maximum length is 512 characters.', example='http://cdn.com/', position='Body'),
  configAliases?: string(name='ConfigAliases', description='A JSON string that specifies the player parameter variables and aliases. Format: { "player_params.{name}": { "{key}": "{value}" } }. You can add up to 20 player_params.{name} entries. The name field can be up to 150 characters in length. Each player parameter can include up to 50 key-value pairs. A key can be up to 150 characters long, and a value can be up to 500 characters.', example='{ "player_params.p1": { "1": "abc" } }', position='Body'),
  contentUrlPrefix: string(name='ContentUrlPrefix', description='The URL prefix for the source content. HTTP and HTTPS are supported. The maximum length is 512 characters.

This parameter is required.', example='https://source.com/', position='Body'),
  name: string(name='Name', description='The configuration name, which cannot be modified.

This parameter is required.', example='my_ad', position='Body'),
  personalizationThreshold?: int32(name='PersonalizationThreshold', description='Specifies the maximum duration of underfilled time allowed in an ad break. Unit: seconds. Default value: 8 seconds.', example='5', position='Body'),
  slateAdUrl?: string(name='SlateAdUrl', description='The HTTP or HTTPS URL of the slate ad. Only MP4 format is supported. The maximum length is 2,048 characters.', example='http://storage.com/slate1.mp4', position='Body'),
}

model UpdateAdInsertionResponseBody = {
  config?: {
    adMarkerPassthrough?: string(name='AdMarkerPassthrough', description='Indicates whether ad marker passthrough is enabled.', example='ON'),
    adsUrl?: string(name='AdsUrl', description='The request URL of ADS.', example='http://ads.com/ad1?param1=[palyer_params.p1]'),
    cdnConfig?: {
      adSegmentUrlPrefix?: string(name='AdSegmentUrlPrefix', description='The CDN prefix for ad segments.', example='http://cdn.com/'),
      contentSegmentUrlPrefix?: string(name='ContentSegmentUrlPrefix', description='The CDN prefix for content segments.', example='http://cdn.com/'),
    }(name='CdnConfig', description='The CDN configurations.'),
    configAliases?: string(name='ConfigAliases', description='The player parameter variables and aliases.', example='{ "player_params.p1": { "1": "abc" } }'),
    contentUrlPrefix?: string(name='ContentUrlPrefix', description='The URL prefix for the source content.', example='https://source.com/'),
    createTime?: string(name='CreateTime', description='The time when the configuration was created.', example='2024-06-13T08:26:09Z'),
    lastModified?: string(name='LastModified', description='The time when the configuration was last modified.', example='2024-06-13T08:26:09Z'),
    manifestEndpointConfig?: {
      dashPrefix?: string(name='DashPrefix', description='DASH清单播放端点前缀'),
      hlsPrefix?: string(name='HlsPrefix', description='The prefix of the playback endpoint for HLS manifests.'),
    }(name='ManifestEndpointConfig', description='The playback endpoint configuration.'),
    name?: string(name='Name', description='The name of the ad insertion configuration.', example='my_ad'),
    personalizationThreshold?: int32(name='PersonalizationThreshold', description='The personalization threshold.', example='5'),
    slateAdUrl?: string(name='SlateAdUrl', description='The URL of the slate ad.', example='http://storage.com/slate1.mp4'),
  }(name='Config', description='The ad insertion configuration.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model UpdateAdInsertionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAdInsertionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateAdInsertion  UpdateAdInsertionRequest
  * @return UpdateAdInsertionResponse
 */
async function updateAdInsertion(request: UpdateAdInsertionRequest): UpdateAdInsertionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateAdInsertion', 'POST', '/', 'json', true, 'form', request);
}

model UpdateAvatarTrainingJobRequest {
  avatarDescription?: string(name='AvatarDescription', description='*   The description of the digital human.
*   The description can be up to 1,000 characters in length.', maxLength=1024, position='Query'),
  avatarName?: string(name='AvatarName', description='*   The name of the digital human.
*   The name can be up to seven characters in length.', maxLength=7, position='Query'),
  jobId: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****cdb3e74639973036bc84****', position='Query'),
  portrait?: string(name='Portrait', description='*   The media asset ID of the portrait image.
*   The value must be 32 characters in length.', example='****571c704445f9a0ee011406c2****', minLength=32, maxLength=32, position='Query'),
  thumbnail?: string(name='Thumbnail', description='*   The thumbnail URL.
*   After the digital human is trained, the thumbnail is uploaded to this URL.
*   The URL must be a valid public Object Storage Service (OSS) URL.
*   The URL can be up to 512 characters in length.
*   The URL cannot be updated after the digital human is trained.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png', maxLength=512, position='Query'),
  transparent?: boolean(name='Transparent', description='*   Indicates whether the input video supports alpha channels.

*   You can modify this parameter only if the job is in the Init or Fail state.

    **

    **Note**: Make sure that the current settings are consistent with those of the submitted training video. Otherwise, the digital human may malfunction.', example='True', position='Query'),
  video?: string(name='Video', description='*   The ID of the video used for training.
*   The value must be 32 characters in length.
*   Supported formats: MP4, MOV, and WebM.
*   The duration of the video must be 5 to 15 minutes.
*   The resolution of the video must be 1920×1080 or 1080×1920.', example='****571c704445f9a0ee011406c2****', minLength=32, maxLength=32, position='Query'),
}

model UpdateAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAvatarTrainingJobResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateAvatarTrainingJob  UpdateAvatarTrainingJobRequest
  * @return UpdateAvatarTrainingJobResponse
 */
async function updateAvatarTrainingJob(request: UpdateAvatarTrainingJobRequest): UpdateAvatarTrainingJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateAvatarTrainingJob', 'POST', '/', 'json', false, 'json', request);
}

model UpdateCategoryRequest {
  regionId?: string(name='RegionId', position='Host'),
  cateId: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of CateId returned by the AddCategory operation that you called to create a category.
*   View the value of CateId returned by the GetCategories operation that you called to query a category.

This parameter is required.', example='43', position='Query'),
  cateName: string(name='CateName', description='The category name.

This parameter is required.', position='Query'),
}

model UpdateCategoryResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
}

model UpdateCategoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateCategoryResponseBody(name='body'),
}

/**
  * @description After you create a media asset category, you can call this operation to find the category based on the category ID and change the name of the category.
  * @param request  the request parameters of UpdateCategory  UpdateCategoryRequest
  * @return UpdateCategoryResponse
 */
async function updateCategory(request: UpdateCategoryRequest): UpdateCategoryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateCategory', 'POST', '/', 'json', false, 'json', request);
}

model UpdateChannelRequest {
  accessPolicy?: boolean(name='AccessPolicy', description='Specifies whether to enable access control.', example='true', position='Query'),
  accessToken?: string(name='AccessToken', description='The token for accessing the channel.', example='xxxxx', position='Query'),
  channelName: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel', position='Query'),
  fillerSourceLocationName?: string(name='FillerSourceLocationName', description='The source location of the filler slate.', example='MySourceLocation', position='Query'),
  fillerSourceName?: string(name='FillerSourceName', description='The name of the filler slate.', example='MySource', position='Query'),
  outPutConfigList: string(name='OutPutConfigList', description='The channel output configurations.

This parameter is required.', example='[{
	"ManifestName": "manifest-1",
	"Format": "HLS",
	"SourceGroupName": "source-group-1",
	"ManifestSettings": {
		"WindowDuration": 60,
		"AdMarkType": "Daterange"
	}
}]', position='Query'),
}

model UpdateChannelResponseBody = {
  channel?: ChannelAssemblyChannel(name='Channel', description='The channel information.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
}

model UpdateChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateChannelResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateChannel  UpdateChannelRequest
  * @return UpdateChannelResponse
 */
async function updateChannel(request: UpdateChannelRequest): UpdateChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateChannel', 'POST', '/', 'json', false, 'json', request);
}

model UpdateCustomTemplateRequest {
  name?: string(name='Name', description='The template name.', example='test-template', position='Query'),
  templateConfig?: string(name='TemplateConfig', description='The [template parameters](https://help.aliyun.com/document_detail/448291.html).', example='{"param": "sample"}', position='Query'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****', position='Query'),
}

model UpdateCustomTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateCustomTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateCustomTemplate  UpdateCustomTemplateRequest
  * @return UpdateCustomTemplateResponse
 */
async function updateCustomTemplate(request: UpdateCustomTemplateRequest): UpdateCustomTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateCustomTemplate', 'POST', '/', 'json', false, 'json', request);
}

model UpdateCustomizedVoiceRequest {
  demoAudioMediaId?: string(name='DemoAudioMediaId', description='The media asset ID of the sample audio file.', example='****4d5e829d498aaf966b119348****', position='Query'),
  voiceId: string(name='VoiceId', description='The voice ID.

This parameter is required.', example='xiaozhuan', position='Query'),
}

model UpdateCustomizedVoiceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateCustomizedVoiceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateCustomizedVoiceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateCustomizedVoice  UpdateCustomizedVoiceRequest
  * @return UpdateCustomizedVoiceResponse
 */
async function updateCustomizedVoice(request: UpdateCustomizedVoiceRequest): UpdateCustomizedVoiceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateCustomizedVoice', 'POST', '/', 'json', false, 'json', request);
}

model UpdateEditingProjectRequest {
  businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

*   Reserving
*   ReservationCanceled', example='Reserving', position='Query'),
  clipsParam?: string(name='ClipsParam', description='The material parameter corresponding to the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified.', position='Query'),
  coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='https://****.com/6AB4D0E1E1C7446888****.png', position='Query'),
  description?: string(name='Description', description='The description of the online editing project.', example='testtimeline001desciption', position='Query'),
  projectId: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='****4ee4b97e27b525142a6b2****', position='Query'),
  templateId?: string(name='TemplateId', description='The template ID. This parameter is used to quickly build a timeline with ease. Note: Only one of ProjectId, Timeline, and TemplateId can be specified. If TemplateId is specified, ClipsParam must also be specified.', example='****96e8864746a0b6f3****', position='Query'),
  timeline?: string(name='Timeline', position='Body'),
  title?: string(name='Title', description='The title of the online editing project.', example='testtimeline', position='Query'),
}

model UpdateEditingProjectResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****25818875-5F78-4AF6-D7393642CA58****'),
}

model UpdateEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateEditingProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateEditingProject  UpdateEditingProjectRequest
  * @return UpdateEditingProjectResponse
 */
async function updateEditingProject(request: UpdateEditingProjectRequest): UpdateEditingProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateEditingProject', 'POST', '/', 'json', true, 'form', request);
}

model UpdateHotwordLibraryRequest {
  description?: string(name='Description', description='The description of the hotword library. It can be up to 200 characters in length.', example='存放名人的词库', position='Query'),
  hotwordLibraryId: string(name='HotwordLibraryId', description='The ID of the hotword library.

This parameter is required.', example='*a0052ff71efbfd4e7e6c66*', position='Query'),
  hotwords?: [
    Hotword
  ](name='Hotwords', description='The hotword list. You can add up to 300 hotword entries to a single library.', shrink='json', position='Query'),
  name?: string(name='Name', description='The name of the hotword library. It can be up to 100 characters in length.', example='my_hotwords', position='Query'),
}

model UpdateHotwordLibraryResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='*3B-0E1A-586A-AC29-742247*'),
  success?: string(name='Success', description='The ID of the hotword library.', example='****96e8864746a0b6f3****'),
}

model UpdateHotwordLibraryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateHotwordLibraryResponseBody(name='body'),
}

/**
  * @description ## [](#)
  * *   You can call this operation to modify a specified hotword library.
  * *   The hotword library ID (`HotwordLibraryId`) is required to identify the library that requires modification.
  * *   You can modify its name (`Name` ), description (`Description` ), and hotword list (`HotWords`).
  * *   Each hotword in the list can also be modified, including its content (`Text`), weight (`Weight`), language (`Language`), and translation results (`TranspositionResultList`).
  * *   A single account supports up to 100 hotword libraries, each containing a maximum of 300 hotword entries. In a library, the combination of `language` and `text` of an entry must be unique. The combination of `TranslatedText` and `TargetLanguage` in `TranspositionResultList` must also be unique.
  * @param request  the request parameters of UpdateHotwordLibrary  UpdateHotwordLibraryRequest
  * @return UpdateHotwordLibraryResponse
 */
async function updateHotwordLibrary(request: UpdateHotwordLibraryRequest): UpdateHotwordLibraryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateHotwordLibrary', 'POST', '/', 'json', false, 'json', request);
}

model UpdateLivePackageChannelRequest {
  channelName: string(name='ChannelName', description='The channel name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='channel-1', position='Body'),
  description?: string(name='Description', description='The channel description. It can be up to 1,000 characters in length.', position='Body'),
  groupName: string(name='GroupName', description='The channel group name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='channel-group-1', position='Body'),
  protocol: string(name='Protocol', description='The ingest protocol. Only HLS is supported.

This parameter is required.', example='HLS', position='Body'),
  segmentCount: int32(name='SegmentCount', description='The number of M3U8 segments. Valid values: 2 to 100.

This parameter is required.', example='3', position='Body'),
  segmentDuration: int32(name='SegmentDuration', description='The segment duration. Valid values: 1 to 30.

This parameter is required.', example='6', position='Body'),
}

model UpdateLivePackageChannelResponseBody = {
  livePackageChannel?: {
    channelName?: string(name='ChannelName', description='The channel name.', example='channel-1'),
    createTime?: string(name='CreateTime', description='The time when the channel was created.', example='2024-07-16T02:24:42Z'),
    description?: string(name='Description', description='The channel description. It can be up to 1,000 characters in length.'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    ingestEndpoints?: [ 
      {
        id?: string(name='Id', description='The ingest endpoint ID.', example='ingest1'),
        password?: string(name='Password', description='The password.', example='2F9e******b569c8'),
        url?: string(name='Url', description='The ingest endpoint URL.', example='http://xxx-1.packagepush-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
        username?: string(name='Username', description='The username.', example='us12******das'),
      }
    ](name='IngestEndpoints', description='The ingest endpoints.'),
    lastModified?: string(name='LastModified', description='The time when the channel was last modified.', example='2024-07-16T02:24:42Z'),
    protocol?: string(name='Protocol', description='The ingest protocol. Only HLS is supported.', example='HLS'),
    segmentCount?: int32(name='SegmentCount', description='The number of segments.', example='3'),
    segmentDuration?: int32(name='SegmentDuration', description='The segment duration.', example='5'),
  }(name='LivePackageChannel', description='The information about the live package channel.'),
  requestId?: string(name='RequestId', description='The request ID.', example='771A1414-27BF-53E6-AB73-EFCB*****ACF'),
}

model UpdateLivePackageChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLivePackageChannelResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * You need to provide the name of the channel group to which the channel belongs, channel name, protocol, segment duration, and number of segments to update. In addition, you can choose to add or modify the description of the channel. Make sure that the provided channel group name and channel name conform to the naming conventions.
  * @param request  the request parameters of UpdateLivePackageChannel  UpdateLivePackageChannelRequest
  * @return UpdateLivePackageChannelResponse
 */
async function updateLivePackageChannel(request: UpdateLivePackageChannelRequest): UpdateLivePackageChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateLivePackageChannel', 'POST', '/', 'json', true, 'form', request);
}

model UpdateLivePackageChannelCredentialsRequest {
  channelName: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1', position='Body'),
  groupName: string(name='GroupName', description='The channel group name.

This parameter is required.', example='group-1', position='Body'),
  rotateCredentials: int32(name='RotateCredentials', description='Specifies whether to update the credentials. 1: updates the credentials of endpoint 1. 2: updates the credentials of endpoint 2. 3: updates the credentials of endpoints 1 and 2.

This parameter is required.', example='3', position='Body'),
}

model UpdateLivePackageChannelCredentialsResponseBody = {
  ingestEndpoints?: [ 
    {
      id?: string(name='Id', description='The ingest endpoint ID. `input1` indicates primary and `input2` indicates secondary.', example='input1'),
      password?: string(name='Password', description='The password.', example='examplePassword123'),
      url?: string(name='Url', description='The ingest endpoint URL.', example='rtmp://example.com/live/input1'),
      username?: string(name='Username', description='The username.', example='user1'),
    }
  ](name='IngestEndpoints', description='The information about the ingest endpoint.'),
  requestId?: string(name='RequestId', description='The request ID.', example='771A1414-27BF-53E6-AB73-EFCB*****ACF'),
}

model UpdateLivePackageChannelCredentialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLivePackageChannelCredentialsResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * You can choose to update the primary endpoint, secondary endpoint, or both. The response includes the updated ingest endpoint URL, username, and password for the ingest device to reconfigure.
  * @param request  the request parameters of UpdateLivePackageChannelCredentials  UpdateLivePackageChannelCredentialsRequest
  * @return UpdateLivePackageChannelCredentialsResponse
 */
async function updateLivePackageChannelCredentials(request: UpdateLivePackageChannelCredentialsRequest): UpdateLivePackageChannelCredentialsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateLivePackageChannelCredentials', 'POST', '/', 'json', true, 'form', request);
}

model UpdateLivePackageChannelGroupRequest {
  description?: string(name='Description', description='The channel group description. It can be up to 1,000 characters in length.', position='Body'),
  groupName: string(name='GroupName', description='The channel group name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='channel-group-1', position='Body'),
}

model UpdateLivePackageChannelGroupResponseBody = {
  livePackageChannelGroup?: {
    createTime?: string(name='CreateTime', description='The time when the channel group was created. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The channel group description.', example='Updated description of the channel group.'),
    groupName?: string(name='GroupName', description='The channel group name.', example='example-group-name'),
    lastModified?: string(name='LastModified', description='The time when the channel group was last modified. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    originDomain?: string(name='OriginDomain', description='The origin domain.', example='example-origin.com'),
  }(name='LivePackageChannelGroup', description='The information about the channel group.'),
  requestId?: string(name='RequestId', description='The request ID.', example='request-1234567890'),
}

model UpdateLivePackageChannelGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLivePackageChannelGroupResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * This API operation allows you to modify the name and description of a live package channel group. The channel group name must conform to the naming conventions and can be up to 1,000 characters. The API response includes the updated channel group details and unique identifier of the request.
  * @param request  the request parameters of UpdateLivePackageChannelGroup  UpdateLivePackageChannelGroupRequest
  * @return UpdateLivePackageChannelGroupResponse
 */
async function updateLivePackageChannelGroup(request: UpdateLivePackageChannelGroupRequest): UpdateLivePackageChannelGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateLivePackageChannelGroup', 'POST', '/', 'json', true, 'form', request);
}

model UpdateLivePackageOriginEndpointRequest {
  authorizationCode?: string(name='AuthorizationCode', description='The authorization code. It can be up to 200 characters in length. You must configure AuthorizationCode, IpWhitelist, or both. Format: [A-Za-z0-9-_.]+', example='Abc123Def456', position='Body'),
  channelName: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1', position='Body'),
  description?: string(name='Description', description='The endpoint description.', position='Body'),
  endpointName: string(name='EndpointName', description='The origin endpoint name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='endpoint-1', position='Body'),
  groupName: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1', position='Body'),
  ipBlacklist?: string(name='IpBlacklist', description='The IP address blacklist. It supports subnet masks. Separate multiple IP addresses with commas (,).', example='103.0.0.0/8', position='Body'),
  ipWhitelist?: string(name='IpWhitelist', description='The IP address whitelist. It supports subnet masks. 0.0.0.0/0 is not allowed. It can be up to 1,000 characters in length. Separate multiple IP addresses with commas (,). You must configure AuthorizationCode, IpWhitelist, or both.', example='192.168.1.0/24,10.0.0.1', position='Body'),
  livePackagingConfig?: LivePackagingConfig(name='LivePackagingConfig', shrink='json', position='Body'),
  manifestName?: string(name='ManifestName', description='The playlist name. Default value: manifest.', example='manifest', position='Body'),
  protocol: string(name='Protocol', description='The protocol. Only HLS is supported.

This parameter is required.', example='HLS', position='Body'),
  timeshiftVision?: int32(name='TimeshiftVision', description='The number of days that time-shifted content is available. Maximum value: 30.', example='5', position='Body'),
}

model UpdateLivePackageOriginEndpointResponseBody = {
  livePackageOriginEndpoint?: {
    authorizationCode?: string(name='AuthorizationCode', description='The authorization code.', example='Abc123Def456'),
    channelName?: string(name='ChannelName', description='The channel name.', example='channel-1'),
    createTime?: string(name='CreateTime', description='The time when the endpoint was created.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The endpoint description.'),
    endpointName?: string(name='EndpointName', description='The endpoint name.', example='endpoint-1'),
    endpointUrl?: string(name='EndpointUrl', description='The endpoint URL.', example='https://xxx.packagepull-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    ipBlacklist?: string(name='IpBlacklist', description='The IP address blacklist. It supports subnet masks. Multiple IP addresses are separated by commas (,).', example='10.21.222.1/32,192.168.100.0/24'),
    ipWhitelist?: string(name='IpWhitelist', description='The IP address whitelist. It supports subnet masks. Multiple IP addresses are separated by commas (,).', example='192.168.1.0/24,10.0.0.1/24'),
    lastModified?: string(name='LastModified', description='The time when the endpoint was last modified.', example='2023-04-01T12:00:00Z'),
    livePackagingConfig?: LivePackagingConfig(name='LivePackagingConfig'),
    manifestName?: string(name='ManifestName', description='The playlist name. Default value: manifest.', example='manifest'),
    protocol?: string(name='Protocol', description='The protocol. Only HLS is supported.', example='HLS'),
    timeshiftVision?: int32(name='TimeshiftVision', description='The number of days that time-shifted content is available. Maximum value: 30.', example='5'),
  }(name='LivePackageOriginEndpoint', description='The information about the origin endpoint.'),
  requestId?: string(name='RequestId', description='The request ID.', example='b1f8d6c4-a123-4cd5-9e88-d0819e3bfa70'),
}

model UpdateLivePackageOriginEndpointResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLivePackageOriginEndpointResponseBody(name='body'),
}

/**
  * @description ## [](#)Usage notes
  * You can call this operation to modify the origin protocol, set the number of days that time-shifted content is available, define playlist names, and configure the IP address blacklist and whitelist, allowing for fine-grained control over streaming media distribution. Some parameters are required. You must configure IpWhitelist, AuthorizationCode, or both.
  * @param request  the request parameters of UpdateLivePackageOriginEndpoint  UpdateLivePackageOriginEndpointRequest
  * @return UpdateLivePackageOriginEndpointResponse
 */
async function updateLivePackageOriginEndpoint(request: UpdateLivePackageOriginEndpointRequest): UpdateLivePackageOriginEndpointResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateLivePackageOriginEndpoint', 'POST', '/', 'json', true, 'form', request);
}

model UpdateLiveRecordTemplateRequest {
  name: string(name='Name', description='The template name.

This parameter is required.', example='test template', position='Body'),
  recordFormat: [ 
    {
      cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds If you do not specify this parameter, the default value 6 hours is used.

> 

*   If a live stream is interrupted during a recording cycle but is resumed within 3 minutes, the stream is recorded in the same recording before and after the interruption.

*   If a live stream is interrupted for more than 3 minutes, a new recording is generated. To change the default stream interruption time, submit a ticket.', example='3600'),
      format: string(name='Format', description='The format of recording files.

>  If you set this parameter to m3u8, you must also specify the SliceOssObjectPrefix and SliceDuration parameters.

This parameter is required.', example='m3u8'),
      ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording that is stored in Object Storage Service (OSS).

*   The name must be less than 256 bytes in length and can contain the {JobId}, {Sequence}, {StartTime}, {EndTime}, {EscapedStartTime}, and {EscapedEndTime} variables.
*   The name must contain the {StartTime} and {EndTime} variables or the {EscapedStartTime} and {EscapedEndTime} variables.', example='record/{JobId}/{Sequence}_{EscapedStartTime}_{EscapedEndTime}'),
      sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds

>  This parameter takes effect only if you set Format to m3u8.

If you do not specify this parameter, the default value 30 seconds is used. Valid values: 5 to 30.', example='30'),
      sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.

>  This parameter is required only if you set Format to m3u8. By default, the duration of a segment is 30 seconds. The segment name must be less than 256 bytes in length and can contain the {JobId}, {UnixTimestamp}, and {Sequence} variables.

The segment name must contain the {UnixTimestamp} and {Sequence} variables.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
    }
  ](name='RecordFormat', description='The list of recording formats.

This parameter is required.', shrink='json', position='Body'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66', position='Body'),
}

model UpdateLiveRecordTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0F3D5C03-4B6E-5F40-B7F6-B1956776E7D3'),
}

model UpdateLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveRecordTemplateResponseBody(name='body'),
}

/**
  * @description Only user-created templates can be updated. The preset template cannot be updated.
  * @param request  the request parameters of UpdateLiveRecordTemplate  UpdateLiveRecordTemplateRequest
  * @return UpdateLiveRecordTemplateResponse
 */
async function updateLiveRecordTemplate(request: UpdateLiveRecordTemplateRequest): UpdateLiveRecordTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateLiveRecordTemplate', 'POST', '/', 'json', true, 'form', request);
}

model UpdateLiveSnapshotTemplateRequest {
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   The value cannot exceed 255 characters in length.
*   The {JobId} placeholder is supported. It specifies the ID of the snapshot job.
*   Placeholders such as {UnixTimestamp}, {Sequence}, and {Date} are not allowed.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}.jpg', position='Body'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   The value cannot exceed 255 characters in length.
*   The {JobId}, {Date}, {UnixTimestamp}, and {Sequence} placeholders are supported. {JobId} specifies the ID of the snapshot job. {Date} specifies the date on which the snapshot is captured. {UnixTimestamp} specifies the timestamp of the snapshot. {Sequence} specifies the sequence number of the snapshot. You must specify at least one of the {UnixTimestamp} and {Sequence} placeholders.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}/{UnixTimestamp}.jpg', position='Body'),
  templateId: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****', position='Body'),
  templateName: string(name='TemplateName', description='The name of the template.

*   It cannot exceed 128 characters in length.

This parameter is required.', position='Body'),
  timeInterval: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.

*   Valid values: [5,3600].

This parameter is required.', example='5', position='Body'),
}

model UpdateLiveSnapshotTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveSnapshotTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateLiveSnapshotTemplate  UpdateLiveSnapshotTemplateRequest
  * @return UpdateLiveSnapshotTemplateResponse
 */
async function updateLiveSnapshotTemplate(request: UpdateLiveSnapshotTemplateRequest): UpdateLiveSnapshotTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateLiveSnapshotTemplate', 'POST', '/', 'json', true, 'form', request);
}

model UpdateLiveTranscodeJobRequest {
  jobId: string(name='JobId', description='The job ID.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  name?: string(name='Name', description='The name of the job.', example='mytest3', minLength=1, maxLength=128, position='Query'),
  streamInput?: {
    inputUrl: string(name='InputUrl', description='The URL of the input stream.

This parameter is required.', example='rtmp://mydomain/app/stream1'),
    type: string(name='Type', description='The type of the input stream. The value can only be rtmp.

This parameter is required.', example='rtmp'),
  }(name='StreamInput', description='The information about the input stream.', shrink='json', position='Query'),
  timedConfig?: {
    endTime?: string(name='EndTime', description='The stop time of the transcoding job. Note: The time span between the stop time and the current time cannot exceed seven days.', example='2022-08-05T06:08:31Z'),
    startTime?: string(name='StartTime', description='The start time of the transcoding job. Note: The time span between the start time and the current time cannot exceed seven days.', example='2022-06-19T02:16:41Z'),
  }(name='TimedConfig', description='The configuration of a timed transcoding job.', shrink='json', position='Query'),
  transcodeOutput?: {
    domainName: string(name='DomainName', description='The streaming domain name of ApsaraVideo Live.

This parameter is required.', example='mydomain'),
    type: string(name='Type', description='The type of the output stream. A value of LiveCenter indicates that the URL of the output stream is generated based on the domain name of ApsaraVideo Live. The value can only be LiveCenter.

This parameter is required.', example='LiveCenter'),
  }(name='TranscodeOutput', description='The information about the transcoding output.', shrink='json', position='Query'),
}

model UpdateLiveTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model UpdateLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveTranscodeJobResponseBody(name='body'),
}

/**
  * @description *   For a non-timed transcoding job, you can modify the Name parameter of the job, regardless of the job state.
  * *   For a timed job, you can modify the Name, StreamInput, TranscodeOutput, and TimedConfig parameters. However, the StreamInput, TranscodeOutput, and TimedConfig parameters can be modified only when the job is not started.
  * @param request  the request parameters of UpdateLiveTranscodeJob  UpdateLiveTranscodeJobRequest
  * @return UpdateLiveTranscodeJobResponse
 */
async function updateLiveTranscodeJob(request: UpdateLiveTranscodeJobRequest): UpdateLiveTranscodeJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateLiveTranscodeJob', 'POST', '/', 'json', false, 'json', request);
}

model UpdateLiveTranscodeTemplateRequest {
  name?: string(name='Name', description='The template name.', position='Query'),
  templateConfig?: {
    audioParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output audio. Unit: Kbit/s. Valid values: 1 to 1000.', example='100'),
      channels?: string(name='Channels', description='The number of sound channels. Valid values: 1: mono 2: binaural', example='2'),
      codec?: string(name='Codec', description='The audio codec. Valid values: AAC MP3', example='AAC'),
      profile?: string(name='Profile', description='The audio codec profile. Valid values when the Codec parameter is set to AAC:

*   aac_low
*   aac_he
*   aac_he_v2
*   aac_ld', example='aac_low'),
      samplerate?: string(name='Samplerate', description='The audio sampling rate. Valid values: 22050 to 96000.

Note If you set AudioProfile to aac_ld, the audio sampling rate cannot exceed 44100.', example='44100'),
    }(name='AudioParams', description='The audio parameters.'),
    videoParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output video. Unit: Kbit/s. Valid values: 1 to 6000.', example='2500'),
      codec?: string(name='Codec', description='The encoding type. Valid values:

*   H.264
*   H.265', example='H.264'),
      fps?: string(name='Fps', description='The frame rate of the output video. Unit: frames per second (FPS). Valid values: 1 to 60.', example='30'),
      gop?: string(name='Gop', description='The group of pictures (GOP) of the output video. Unit: frame. Valid values: 1 to 3000.', example='1000'),
      height?: string(name='Height', description='The height of the output video. Valid values:

*   Height ≥ 128
*   max (Height,Width) ≤ 2560
*   min（Height,Width）≤ 1440

>  The resolution of a video transcoded by using the H.265 Narrowband HD template cannot exceed 1,280 × 720 pixels.', example='720'),
      profile?: string(name='Profile', description='The video encoding profile. The profile determines how a video is encoded. In most cases, a greater value indicates better image quality and higher resource consumption. Valid values:

*   1: baseline. This value is suitable for mobile devices.
*   2: main. This value is suitable for standard-definition devices.
*   3: high. This value is suitable for high-definition devices.', example='2'),
      width?: string(name='Width', description='The width of the output video. Valid values:

*   Width ≥ 128
*   max (Height,Width) ≤ 2560
*   min（Height,Width）≤ 1440

>  The resolution of a video transcoded by using the H.265 Narrowband HD template cannot exceed 1,280 × 720 pixels.', example='1280'),
    }(name='VideoParams', description='The video parameters.'),
  }(name='TemplateConfig', description='The configuration of the template.', shrink='json', position='Query'),
  templateId: string(name='TemplateId', description='The template ID. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com/summary), choose Real-time Media Processing > Template Management, and then click the Transcoding tab. Alternatively, find the ID from the response parameters of the [CreateLiveTranscodeTemplate](https://help.aliyun.com/document_detail/449217.html) operation.

This parameter is required.', example='****96e8864746a0b6f3****', position='Query'),
}

model UpdateLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model UpdateLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveTranscodeTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateLiveTranscodeTemplate  UpdateLiveTranscodeTemplateRequest
  * @return UpdateLiveTranscodeTemplateResponse
 */
async function updateLiveTranscodeTemplate(request: UpdateLiveTranscodeTemplateRequest): UpdateLiveTranscodeTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateLiveTranscodeTemplate', 'POST', '/', 'json', false, 'json', request);
}

model UpdateMediaConnectFlowInputRequest {
  cidrs?: string(name='Cidrs', description='The IP address whitelist.', example='19.168.1.1/32,18.168.1.1/16', position='Query'),
  flowId: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f', position='Query'),
  inputFromUrl?: string(name='InputFromUrl', description='The source URL. You can modify this parameter only when the source type is RTMP-PULL or SRT-Listener.', example='rtmp://pull.test.alivecdn.com/live/alitest', position='Query'),
  inputName?: string(name='InputName', position='Query'),
  maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s.', example='2000000', position='Query'),
  srtLatency?: int32(name='SrtLatency', description='The latency for the SRT stream. You can modify this parameter only when the source type is SRT-Listener or SRT-Caller.', example='1000', position='Query'),
  srtPassphrase?: string(name='SrtPassphrase', description='The SRT key. You can modify this parameter only when the source type is SRT-Listener or SRT-Caller.', example='FICUBPX4Q77DYHRF', position='Query'),
  srtPbkeyLen?: int32(name='SrtPbkeyLen', description='The encryption key length. You can modify this parameter only when the source type is SRT-Listener or SRT-Caller.', example='32', position='Query'),
}

model UpdateMediaConnectFlowInputResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='52451256-FFEA-5D2E-AA60-EE7053000F22'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model UpdateMediaConnectFlowInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaConnectFlowInputResponseBody(name='body'),
}

/**
  * @description *   You can modify the source only when the flow is in the offline state.
  * *   The source type cannot be modified.
  * @param request  the request parameters of UpdateMediaConnectFlowInput  UpdateMediaConnectFlowInputRequest
  * @return UpdateMediaConnectFlowInputResponse
 */
async function updateMediaConnectFlowInput(request: UpdateMediaConnectFlowInputRequest): UpdateMediaConnectFlowInputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMediaConnectFlowInput', 'POST', '/', 'json', false, 'json', request);
}

model UpdateMediaConnectFlowOutputRequest {
  cidrs?: string(name='Cidrs', description='The IP address whitelist.', example='19.168.1.1/32,18.168.1.1/16', position='Query'),
  flowId: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f', position='Query'),
  outputName: string(name='OutputName', description='The output name.

This parameter is required.', example='AliTestOutput', position='Query'),
  outputToUrl?: string(name='OutputToUrl', description='The output URL. You can modify this parameter only when the output type is RTMP-PUSH or SRT-Caller.', example='rtmp://push.test.alivecdn.com/live/alitest', position='Query'),
  playerLimit?: string(name='PlayerLimit', description='The maximum number of viewers.', example='5', position='Query'),
  srtLatency?: string(name='SrtLatency', description='The latency for the SRT stream. You can modify this parameter only when the source type is SRT-Listener or SRT-Caller.', example='1000', position='Query'),
  srtPassphrase?: string(name='SrtPassphrase', description='The SRT key. You can modify this parameter only when the source type is SRT-Listener or SRT-Caller.', example='FICUBPX4Q77DYHRF', position='Query'),
  srtPbkeyLen?: string(name='SrtPbkeyLen', description='The encryption key length. You can modify this parameter only when the source type is SRT-Listener or SRT-Caller.', example='32', position='Query'),
}

model UpdateMediaConnectFlowOutputResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D737D0BC-4CB5-55AA-8119-B540C95DFE6A'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model UpdateMediaConnectFlowOutputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaConnectFlowOutputResponseBody(name='body'),
}

/**
  * @description *   You can modify an output only when the flow is in the offline state.
  * *   The output type cannot be modified.
  * @param request  the request parameters of UpdateMediaConnectFlowOutput  UpdateMediaConnectFlowOutputRequest
  * @return UpdateMediaConnectFlowOutputResponse
 */
async function updateMediaConnectFlowOutput(request: UpdateMediaConnectFlowOutputRequest): UpdateMediaConnectFlowOutputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMediaConnectFlowOutput', 'POST', '/', 'json', false, 'json', request);
}

model UpdateMediaConnectFlowStatusRequest {
  flowId: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f', position='Query'),
  status: string(name='Status', description='The flow state. Valid values:

*   online: starts the flow.
*   offline: stops the flow.

This parameter is required.', example='online', position='Query'),
}

model UpdateMediaConnectFlowStatusResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='ok'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='20B3A1B6-4BD2-5DE6-BCBC-098C9B4F4E91'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates that the call is successful.', example='0'),
}

model UpdateMediaConnectFlowStatusResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaConnectFlowStatusResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateMediaConnectFlowStatus  UpdateMediaConnectFlowStatusRequest
  * @return UpdateMediaConnectFlowStatusResponse
 */
async function updateMediaConnectFlowStatus(request: UpdateMediaConnectFlowStatusRequest): UpdateMediaConnectFlowStatusResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMediaConnectFlowStatus', 'POST', '/', 'json', false, 'json', request);
}

model UpdateMediaInfoRequest {
  regionId?: string(name='RegionId', position='Host'),
  appendTags?: boolean(name='AppendTags', description='Specifies whether to append tags. Default value: false. Valid values:

*   true: updates the MediaTags parameter by appending new tags.
*   false: updates the MediaTags parameter by overwriting existing tags with new tags.', example='true', position='Query'),
  businessType?: string(name='BusinessType', description='The business type. Valid values:

*   subtitles
*   watermark
*   opening
*   ending
*   general', example='video', position='Query'),
  cateId?: long(name='CateId', description='The category ID.', example='3048', position='Query'),
  category?: string(name='Category', description='The category.

*   The value can be up to 64 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultCategory', position='Query'),
  coverURL?: string(name='CoverURL', description='The URL of the thumbnail.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png', position='Query'),
  description?: string(name='Description', description='The content description.

*   The value can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultDescription', position='Query'),
  inputURL?: string(name='InputURL', description='The input URL of the media asset in another service. The URL must be bound to the ID of the media asset in IMS. The URL cannot be modified once registered.

For a media asset from Object Storage Service (OSS), the URL may have one of the following formats:

1\\. http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4

2\\. oss://example-bucket/example.mp4. This format indicates that the region in which the OSS bucket of the media asset resides is the same as the region in which OSS is activated.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. If this parameter is left empty, you must specify the input URL of the media asset, which has been registered in the IMS content library.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  mediaTags?: string(name='MediaTags', description='The tags.

*   Up to 16 tags are supported.
*   Separate multiple tags with commas (,).
*   Each tag can be up to 32 bytes in length.
*   The value must be encoded in UTF-8.', example='updateTags1,updateTags2', position='Query'),
  referenceId?: string(name='ReferenceId', description='The custom ID. The ID can be 6 to 64 characters in length and can contain only letters, digits, hyphens (-), and underscores (_). Make sure that the ID is unique among users.', example='123-123', position='Query'),
  title?: string(name='Title', description='The title.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultTitle', position='Query'),
  userData?: string(name='UserData', description='The user data. It can be up to 1,024 bytes in size.', example='userData', position='Query'),
}

model UpdateMediaInfoResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset in IMS.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaInfoResponseBody(name='body'),
}

/**
  * @description If the MediaId parameter is specified, the MediaId parameter is preferentially used for the query. If the MediaId parameter is left empty, the InputURL parameter must be specified. The request ID and media asset ID are returned. You cannot modify the input URL of a media asset by specifying the ID of the media asset.
  * @param request  the request parameters of UpdateMediaInfo  UpdateMediaInfoRequest
  * @return UpdateMediaInfoResponse
 */
async function updateMediaInfo(request: UpdateMediaInfoRequest): UpdateMediaInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMediaInfo', 'POST', '/', 'json', false, 'json', request);
}

model UpdateMediaLiveChannelRequest {
  audioSettings?: [ 
    {
      audioCodec?: string(name='AudioCodec', description='The audio codec. If it is not specified, the source specification is used. Valid values: aac and libfdk_aac.', example='libfdk_aac'),
      audioCodecSetting?: {
        bitrate?: int32(name='Bitrate', description='The audio bitrate. Unit: bit/s. Valid values: 8000 to 1000000. The value must be divisible by 1000.', example='200000'),
        profile?: string(name='Profile', description='The audio codec profile. When AudioCodec is set to aac, AAC-LOW and AAC-MAIN are supported. When AudioCodec is set to libfdk_aac, AAC-LOW, AAC-HE, and AAC-HEV2 are supported.', example='AAC-LOW'),
        sampleRate?: int32(name='SampleRate', description='The audio sample rate. Unit: Hz. Valid values: 22050, 32000, 44100, 48000, and 96000.', example='44100'),
      }(name='AudioCodecSetting', description='The audio encoding settings.'),
      audioSelectorName?: string(name='AudioSelectorName', description='The name of the audio selector.', example='a1'),
      languageCode?: string(name='LanguageCode', description='Enter a three-letter ISO 639-2 language code. If the audio track selected by the audio selector has a language code, the language code specified in the audio selector is used. If the selected audio track does not have a language code, or if the audio selector cannot find a track that matches its criteria, this language code is used.', example='eng'),
      languageName?: string(name='LanguageName', description='The tag that identifies the language of the RTMP input. It can be referenced by the output. The maximum length is 32 characters. Supported characters:

*   Unicode letters
*   Digits (0-9)
*   Underscore (_)
*   Hyphen (-)
*   Space (a space cannot be at the beginning or end)', example='English'),
      name: string(name='Name', description='The name of the audio settings. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='audio1'),
    }
  ](name='AudioSettings', description='The audio settings.', shrink='json', position='Body'),
  channelId: string(name='ChannelId', description='The ID of the channel.

This parameter is required.', example='SEGK5KA6KYKAWQQH', position='Body'),
  inputAttachments: [ 
    {
      audioSelectors?: [ 
        {
          audioLanguageSelection?: {
            languageCode: string(name='LanguageCode', description='Enter a three-letter ISO 639-2 language code from within an audio source.

This parameter is required.', example='eng'),
          }(name='AudioLanguageSelection', description='The audio language selection.'),
          audioPidSelection?: {
            pid: long(name='Pid', description='Enter a specific PID from within a source.

This parameter is required.', example='123'),
          }(name='AudioPidSelection', description='The audio PID selection.'),
          audioTrackSelection?: [ 
            {
              trackId: long(name='TrackId', description='Specify one or more audio tracks from within a source using Track ID.

This parameter is required.', example='1'),
            }
          ](name='AudioTrackSelection', description='The audio track selection.'),
          name: string(name='Name', description='The name of the audio selector. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='myselector'),
        }
      ](name='AudioSelectors', description='The audio selectors.'),
      inputId: string(name='InputId', description='The ID of the associated input.

This parameter is required.', example='myinput'),
      languageName?: string(name='LanguageName', description='The tag that identifies the language of the RTMP input. It can be referenced by the output. The maximum length is 32 characters. Supported characters:

*   Unicode letters
*   Digits (0-9)
*   Underscore (_)
*   Hyphen (-)
*   Space (a space cannot be at the beginning or end)', example='English'),
    }
  ](name='InputAttachments', description='The inputs associated with the channel.

This parameter is required.', shrink='json', position='Body'),
  name: string(name='Name', description='The name of the channel. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='mych', position='Body'),
  outputGroups: [ 
    {
      mediaPackageGroupSetting?: {
        channelName: string(name='ChannelName', description='ChannelName in MediaPackage.

This parameter is required.', example='myPackageChannel'),
        groupName: string(name='GroupName', description='GroupName in MediaPackage.

This parameter is required.', example='myPackageGroup'),
      }(name='MediaPackageGroupSetting', description='The MediaPackage destination.'),
      name: string(name='Name', description='The name of the output group. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='group1'),
      outputs: [ 
        {
          audioSettingNames?: [ string ](name='AudioSettingNames', description='The referenced AudioSettings.'),
          mediaPackageOutputSetting?: {
            audioGroupId?: string(name='AudioGroupId', description='The manifest audio group ID. To associate several audio tracks into one group, assign the same audio group ID. Viewers can select a track as needed. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 40 characters in length.', example='audiogroup'),
            nameModifier?: string(name='NameModifier', description='The manifest name modifier. The child manifests include this modifier in their M3U8 file names. Letters, digits, hyphens (-), and underscores (_) are supported. The maximum length is 40 characters.', example='480p'),
          }(name='MediaPackageOutputSetting', description='The settings of the output delivered to MediaPackage.'),
          mediaType?: int32(name='MediaType', description='The media type of the output. Valid values:

*   0: Audio and Video
*   1: Audio If you set the value to 1, you cannot reference VideoSettings.
*   2: Video. If you set the value to 2, you cannot reference AudioSettings.', example='0'),
          name: string(name='Name', description='The name of the output. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='output1'),
          videoSettingName?: string(name='VideoSettingName', description='The name of the referenced VideoSettings.', example='myVideo1'),
        }
      ](name='Outputs', description='The outputs in the output group.

This parameter is required.'),
      type: string(name='Type', description='The output group type. Only MediaPackage is supported.

This parameter is required.', example='MediaPackage'),
    }
  ](name='OutputGroups', description='The output groups.

This parameter is required.', shrink='json', position='Body'),
  videoSettings?: [ 
    {
      height?: int32(name='Height', description='The height of the output. If you set it to 0 or leave it empty, the height automatically adapts to the specified width to maintain the original aspect ratio.

Valid values:

*   For regular transcoding, the larger dimension cannot exceed 3840 px, and the smaller one cannot exceed 2160 px.
*   For Narrowband HD™ transcoding, the larger dimension cannot exceed 1920 px, and the smaller one cannot exceed 1080 px.', example='720'),
      name: string(name='Name', description='The name of the video settings. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='video1'),
      videoCodec?: string(name='VideoCodec', description='The video codec. Valid values: H264 and H265.', example='H264'),
      videoCodecSetting?: {
        codecDetail?: {
          level?: string(name='Level', description='The video encoding level. It is not supported yet.', example='H264_LEVEL_AUTO'),
          profile?: string(name='Profile', description='The H.264 profile. Valid values: BASELINE, HIGH, and MAIN. Default value: MAIN. The parameter takes effect only when the codec is H.264.', example='MAIN'),
        }(name='CodecDetail', description='The video encoding settings.'),
        framerate?: {
          framerateControl?: string(name='FramerateControl', description='The frame rate mode. Valid values: SPECIFIED (fixed frame rate) and FROM_SOURCE (use source specification).', example='SPECIFIED'),
          framerateDenominator?: int32(name='FramerateDenominator', description='The denominator of the fixed frame rate. The parameter is required when FramerateControl is set to SPECIFIED. Valid values: 1 to 60. The numerator must be divisible by the denominator.', example='1'),
          framerateNumerator?: int32(name='FramerateNumerator', description='The numerator of the fixed frame rate. The parameter is required when FramerateControl is set to SPECIFIED. Valid values: 1 to 60. The numerator must be divisible by the denominator.', example='25'),
        }(name='Framerate', description='The frame rate. If it is not specified, the source specification is used.'),
        gop?: {
          bframesNum?: int32(name='BframesNum', description='The number of B frames. Valid values: 1 to 3.', example='3'),
          gopSize?: int32(name='GopSize', description='The GOP size. When GopSizeUnits is set to SECONDS, the value range is from 1 to 20. When GopSizeUnits is set to FRAMES, the value range is from 1 to 3000.', example='90'),
          gopSizeUnits?: string(name='GopSizeUnits', description='The GOP size unit. Valid values: FRAMES and SECONDS.', example='FRAMES'),
        }(name='Gop', description='The GOP setting. If it is not specified, the source specification is used.'),
        rate?: {
          bitrate?: int32(name='Bitrate', description='The video bitrate. Unit: bit/s. If you set it to 0 or leave it empty, the source specification is used. Valid values: 50000 to 6000000. The value must be divisible by 1000.', example='2500000'),
          bufferSize?: int32(name='BufferSize', description='The video buffer size. Unit: bit/s. Valid values: 100000 to 6000000. The value must be divisible by 1000.', example='6000000'),
          maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s. Valid values: 100000 to 6000000. The value must be divisible by 1000.', example='6000000'),
          rateControlMode?: string(name='RateControlMode', description='The bitrate control mode. Valid values: CBR, ABR, and VBR.', example='ABR'),
        }(name='Rate', description='The video encoding rate. If it is not specified, the source specification is used.'),
      }(name='VideoCodecSetting', description='The video encoding settings.'),
      videoCodecType?: string(name='VideoCodecType', description='The video transcoding method. Valid values:

*   NORMAL: regular transcoding
*   NBHD: Narrowband HD™ transcoding

If not specified, regular transcoding is used by default.', example='NORMAL'),
      width?: int32(name='Width', description='The width of the output. If you set it to 0 or leave it empty, the width automatically adapts to the specified height to maintain the original aspect ratio.

Valid values:

*   For regular transcoding, the larger dimension cannot exceed 3840 px, and the smaller one cannot exceed 2160 px.
*   For Narrowband HD™ transcoding, the larger dimension cannot exceed 1920 px, and the smaller one cannot exceed 1080 px.', example='1280'),
    }
  ](name='VideoSettings', description='The video settings.', shrink='json', position='Body'),
}

model UpdateMediaLiveChannelResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateMediaLiveChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaLiveChannelResponseBody(name='body'),
}

/**
  * @description *   You can modify a MediaLive channel only when it is not running.
  * ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of UpdateMediaLiveChannel  UpdateMediaLiveChannelRequest
  * @return UpdateMediaLiveChannelResponse
 */
async function updateMediaLiveChannel(request: UpdateMediaLiveChannelRequest): UpdateMediaLiveChannelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMediaLiveChannel', 'POST', '/', 'json', true, 'form', request);
}

model UpdateMediaLiveInputRequest {
  inputId: string(name='InputId', description='The ID of the input.

This parameter is required.', example='SEGK5KA6KYKAWQQH', position='Body'),
  inputSettings: [ 
    {
      flowId?: string(name='FlowId', description='The ID of the flow from MediaConnect. This parameter is required when Type is set to MEDIA_CONNECT.', example='******81-9693-40dc-bbab-db5e49******'),
      flowOutputName?: string(name='FlowOutputName', description='The output name of the MediaConnect flow. This parameter is required when Type is set to MEDIA_CONNECT.', example='myFlowOutputName'),
      sourceUrl?: string(name='SourceUrl', description='The source URL from which the stream is pulled. This parameter is required for PULL inputs.', example='rtmp://domain/app/stream'),
      srtLatency?: int32(name='SrtLatency'),
      srtMaxBitrate?: int32(name='SrtMaxBitrate'),
      srtPassphrase?: string(name='SrtPassphrase'),
      srtPbKeyLen?: int32(name='SrtPbKeyLen'),
      streamName?: string(name='StreamName', description='The name of the pushed stream. This parameter is required for PUSH inputs. It can be up to 255 characters in length.', example='mystream'),
    }
  ](name='InputSettings', description='The input settings. An input can have up to two sources: primary and backup sources.

This parameter is required.', shrink='json', position='Query'),
  name: string(name='Name', description='The name of the input. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='myinput', position='Body'),
  securityGroupIds?: [ string ](name='SecurityGroupIds', description='The IDs of the security groups to be associated with the input. This parameter is required for PUSH inputs.', example='["G6G4X5T4SZYPSTT5"]', shrink='json', position='Query'),
}

model UpdateMediaLiveInputResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
}

model UpdateMediaLiveInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaLiveInputResponseBody(name='body'),
}

/**
  * @description *   You can modify an input only when it is not associated with a MediaLive channel.
  * ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of UpdateMediaLiveInput  UpdateMediaLiveInputRequest
  * @return UpdateMediaLiveInputResponse
 */
async function updateMediaLiveInput(request: UpdateMediaLiveInputRequest): UpdateMediaLiveInputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMediaLiveInput', 'POST', '/', 'json', true, 'form', request);
}

model UpdateMediaLiveInputSecurityGroupRequest {
  name: string(name='Name', description='The name of the security group. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='mysg', position='Body'),
  securityGroupId: string(name='SecurityGroupId', description='The ID of the security group.

This parameter is required.', example='SEGK5KA6KYKAWQQH', position='Body'),
  whitelistRules: [ string ](name='WhitelistRules', description='The security group rules.

This parameter is required.', shrink='json', position='Body'),
}

model UpdateMediaLiveInputSecurityGroupResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateMediaLiveInputSecurityGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaLiveInputSecurityGroupResponseBody(name='body'),
}

/**
  * @description *   You can modify a security group only when it is not associated with a MediaLive input.
  * ## QPS limit
  * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
  * @param request  the request parameters of UpdateMediaLiveInputSecurityGroup  UpdateMediaLiveInputSecurityGroupRequest
  * @return UpdateMediaLiveInputSecurityGroupResponse
 */
async function updateMediaLiveInputSecurityGroup(request: UpdateMediaLiveInputSecurityGroupRequest): UpdateMediaLiveInputSecurityGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMediaLiveInputSecurityGroup', 'POST', '/', 'json', true, 'form', request);
}

model UpdateMediaMarksRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='53afdf003a******6a16b5feac6402', position='Query'),
  mediaMarks: string(name='MediaMarks', description='The marks of the media asset.

This parameter is required.', position='Query'),
}

model UpdateMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='53afdf003a******6a16b5feac6402'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The IDs of the successfully modified marks.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaMarksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateMediaMarks  UpdateMediaMarksRequest
  * @return UpdateMediaMarksResponse
 */
async function updateMediaMarks(request: UpdateMediaMarksRequest): UpdateMediaMarksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMediaMarks', 'POST', '/', 'json', false, 'json', request);
}

model UpdateMediaToSearchLibRequest {
  regionId?: string(name='RegionId', position='Host'),
  mediaId: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='****019b82e24b37a1c2958dec38****', position='Query'),
  msgBody: string(name='MsgBody', description='The message body.

This parameter is required.', example='{}', position='Query'),
  namespace?: string(name='Namespace', position='Query'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1', position='Query'),
}

model UpdateMediaToSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateMediaToSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaToSearchLibResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateMediaToSearchLib  UpdateMediaToSearchLibRequest
  * @return UpdateMediaToSearchLibResponse
 */
async function updateMediaToSearchLib(request: UpdateMediaToSearchLibRequest): UpdateMediaToSearchLibResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMediaToSearchLib', 'POST', '/', 'json', false, 'json', request);
}

model UpdatePipelineRequest {
  name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline', position='Query'),
  pipelineId: string(name='PipelineId', description='The ID of the MPS queue.

This parameter is required.', example='****d80e4e4044975745c14b****', position='Query'),
  priority?: int32(name='Priority', description='The priority of the MPS queue. Valid values: 1 to 10.', example='6', position='Query'),
  status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Paused', position='Query'),
}

model UpdatePipelineResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdatePipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdatePipelineResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdatePipeline  UpdatePipelineRequest
  * @return UpdatePipelineResponse
 */
async function updatePipeline(request: UpdatePipelineRequest): UpdatePipelineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdatePipeline', 'POST', '/', 'json', false, 'json', request);
}

model UpdateProgramRequest {
  adBreaks?: string(name='AdBreaks', description='The information about ad breaks.', example='[{"MessageType":"SPLICE_INSERT","OffsetMillis":1000,"SourceLocationName":"MySourceLocation","SourceName":"MyAdSource","SpliceInsertSettings":{"AvailNumber":0,"AvailExpected":0,"SpliceEventID":1,"UniqueProgramID":0}}]', position='Query'),
  channelName: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel', position='Query'),
  clipRange?: string(name='ClipRange', description='Extracts a clip from the source.', example='{StartOffsetMillis: 213123, EndOffsetMillis: 213134}', position='Query'),
  programName: string(name='ProgramName', description='The name of the program.

This parameter is required.', example='program1', position='Query'),
  sourceLocationName?: string(name='SourceLocationName', description='The name of the source location.', example='MySourceLcation', position='Query'),
  sourceName?: string(name='SourceName', description='The name of the source.', example='MySource', position='Query'),
  sourceType?: string(name='SourceType', description='The source type of the program. Valid values: vodSource and liveSource.', example='vodSource', position='Query'),
  transition?: string(name='Transition', description='The program transition method.', example='{"Type": "RELATIVE", "RelativePosition": "AFTER_PROGRAM", "RelativeProgram": "program2"}', position='Query'),
}

model UpdateProgramResponseBody = {
  program?: ChannelAssemblyProgram(name='Program', description='The information about the program.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
}

model UpdateProgramResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateProgramResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateProgram  UpdateProgramRequest
  * @return UpdateProgramResponse
 */
async function updateProgram(request: UpdateProgramRequest): UpdateProgramResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateProgram', 'POST', '/', 'json', false, 'json', request);
}

model UpdateRtcRobotInstanceRequest {
  config?: {
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt', example='false'),
    greeting?: string(name='Greeting'),
    voiceId?: string(name='VoiceId', example='zhixiaoxia'),
  }(name='Config', shrink='json', position='Query'),
  instanceId: string(name='InstanceId', description='This parameter is required.', example='727dc0e296014bb58670940a3da95592', position='Query'),
}

model UpdateRtcRobotInstanceResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='7707F0A2-C6FD-5959-87EB-7C4D02384FD4'),
}

model UpdateRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateRtcRobotInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateRtcRobotInstance  UpdateRtcRobotInstanceRequest
  * @return UpdateRtcRobotInstanceResponse
 */
async function updateRtcRobotInstance(request: UpdateRtcRobotInstanceRequest): UpdateRtcRobotInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateRtcRobotInstance', 'POST', '/', 'json', false, 'json', request);
}

model UpdateSourceRequest {
  httpPackageConfigurations: string(name='HttpPackageConfigurations', description='The source configurations.

This parameter is required.', example='[{
	"sourceGroupName": "mySourceGroup-1",
	"relativePath": "group1/hls.m3u8",
	"packageType": "hls"
}]', position='Query'),
  sourceLocationName: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourcelocation', position='Query'),
  sourceName: string(name='SourceName', description='The name of the source.

This parameter is required.', example='MySource', position='Query'),
  sourceType: string(name='SourceType', description='The source type. Valid values: vodSource and liveSource.

This parameter is required.', example='vodSource', position='Query'),
}

model UpdateSourceResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  source?: ChannelAssemblySource(name='Source', description='The source information.'),
}

model UpdateSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateSourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateSource  UpdateSourceRequest
  * @return UpdateSourceResponse
 */
async function updateSource(request: UpdateSourceRequest): UpdateSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateSource', 'POST', '/', 'json', false, 'json', request);
}

model UpdateSourceLocationRequest {
  baseUrl?: string(name='BaseUrl', description='The protocol and hostname of the source location.', example='http://xxx.com', position='Query'),
  enableSegmentDelivery?: boolean(name='EnableSegmentDelivery', description='Specifies whether to use an independent domain name to access the segments.', example='true', position='Query'),
  segmentDeliveryUrl?: string(name='SegmentDeliveryUrl', description='The domain name used to access the segments.', example='http://xxxx.com', position='Query'),
  sourceLocationName: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourceLocation', position='Query'),
}

model UpdateSourceLocationResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  sourceLocation?: ChannelAssemblySourceLocation(name='SourceLocation', description='The source location information.'),
}

model UpdateSourceLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateSourceLocationResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateSourceLocation  UpdateSourceLocationRequest
  * @return UpdateSourceLocationResponse
 */
async function updateSourceLocation(request: UpdateSourceLocationRequest): UpdateSourceLocationResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateSourceLocation', 'POST', '/', 'json', false, 'json', request);
}

model UpdateTemplateRequest {
  config?: string(name='Config', example='参见模板Config文档', position='Body'),
  coverUrl?: string(name='CoverUrl', description='The URL of the template thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg', position='Query'),
  name?: string(name='Name', description='The name of the online editing template.', example='视频添加水印模板', position='Query'),
  previewMedia?: string(name='PreviewMedia', description='The ID of the preview video.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
  relatedMediaids?: string(name='RelatedMediaids', description='The IDs of the materials associated with the template for use by the regular template editor.', example='{"video":["******c04f1d4a06996144cc1a******","******cb7db64841b159b4f2ea******"],"audio":["******c04f1d4a06996144cc1a******"],"image":["******c04f1d4a06996144cc1a******"]}', position='Query'),
  source?: string(name='Source', description='The source from which the template is modified. Default value: OpenAPI. Valid values:

*   AliyunConsole
*   OpenAPI
*   WebSDK', example='OpenAPI', position='Query'),
  status?: string(name='Status', description='The template state. Valid values:

*   Available: The template is available.
*   Created: The template is created but not ready for use.
*   Uploading: The video is being uploaded.
*   Processing: The advanced template is being processed.
*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.

>  After an advanced template is created, it enters the Processing state. In this case, the template is unavailable. The template can be used only when it is in the Available state. The time required for template processing varies based on the size of the template file. Generally, it ranges from 10 seconds to 5 minutes.', example='Available', position='Query'),
  templateId?: string(name='TemplateId', description='The ID of the online editing template. You can obtain the template ID in the [Intelligent Media Services (IMS) console](https://ice.console.aliyun.com/production/template/list/common) or the response parameters of the [AddTemplate](https://help.aliyun.com/document_detail/441161.html) operation.', example='****20b48fb04483915d4f2cd8ac****', position='Query'),
}

model UpdateTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateTemplateResponseBody(name='body'),
}

/**
  * @description *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
  * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
  * @param request  the request parameters of UpdateTemplate  UpdateTemplateRequest
  * @return UpdateTemplateResponse
 */
async function updateTemplate(request: UpdateTemplateRequest): UpdateTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateTemplate', 'POST', '/', 'json', true, 'form', request);
}

model UploadMediaByURLRequest {
  regionId?: string(name='RegionId', position='Host'),
  appId?: string(name='AppId', description='The application ID.', example='app-1000000', position='Query'),
  entityId?: string(name='EntityId', description='The entity ID. You can call the CreateEntity operation to create an entity and specify a dynamic metadata structure.', example='d67281da3c8743b8823ad12976187***', position='Query'),
  mediaMetaData?: string(name='MediaMetaData', description='The metadata of the media file that you want to upload. The value must be a JSON string.

*   This parameter takes effect only if its value matches a URL that is specified in UploadURLs.
*   You must convert the JSON-formatted data, such as [UploadMetadata, UploadMetadata,…], into a JSON string.
*   For more information, see the "UploadMetadata" section of this topic.', example='[{"SourceURL":"https://example.aliyundoc.com/video01.mp4","Title":"urlUploadTest"}]', position='Query'),
  postProcessConfig?: string(name='PostProcessConfig', description='The postprocessing configurations. You can specify this parameter if Type is set to video or audio.

Set ProcessType to Workflow.', example='{"ProcessType": "Workflow","ProcessID":"b72a06c6beeb4dcdb898feef067b1***"}', position='Query'),
  uploadTargetConfig?: string(name='UploadTargetConfig', description='The destination storage address.

Set StorageType to oss.

Set StorageLocation to an address in ApsaraVideo VOD. You cannot set this field to an OSS URL.', example='{"StorageType":"oss","StorageLocation":"outin-***.oss-cn-shanghai.aliyuncs.com"}', position='Query'),
  uploadURLs?: string(name='UploadURLs', description='The URL of the source file.

*   The URL must contain a file name extension, such as mp4 in `https://****.mp4`.

    *   If the URL does not contain a file name extension, you can specify one by setting `FileExtension` in `UploadMetadata`.
    *   If the URL contains a file name extension and `FileExtension` is also specified, the value of `FileExtension` prevails.

*   URL encoding is required. Separate multiple URLs with commas (,). You can specify a maximum of 20 URLs.

*   Special characters may cause upload failures. Therefore, you must encode URLs before you separate them with commas (,).', example='https://diffurl.mp4', position='Query'),
  userData?: string(name='UserData', description='The user data. The value must be a JSON string. You can configure settings such as message callbacks.', example='{"MessageCallback":{"CallbackURL":"http://example.aliyundoc.com"},"Extend":{"localId":"xxx","test":"www"}}', position='Query'),
}

model UploadMediaByURLResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****83B7-7F87-4792-BFE9-63CD2137****'),
  uploadJobs?: [ 
    {
      jobId?: string(name='JobId', description='The ID of the upload job.', example='20ce1e05dba64576b96e9683879f0***'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='f476988629f54a7b8a4ba90d1a6c7***'),
      sourceURL?: string(name='SourceURL', description='The URL of the source file that is uploaded in the upload job.', example='http://example****.mp4'),
    }
  ](name='UploadJobs', description='The information about upload jobs.'),
}

model UploadMediaByURLResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UploadMediaByURLResponseBody(name='body'),
}

/**
  * @description *   If a callback is configured, you will receive an UploadByURLComplete event notification after the file is uploaded. You can query the upload status by calling the GetURLUploadInfos operation.
  * *   After a request is submitted, the upload job is queued as an asynchronous job in the cloud. You can query the status of the upload job based on information such as the URL and media asset ID that are returned in the event notification.
  * *   You can call this operation to upload media files that are not stored on a local server or device and must be uploaded by using URLs that are accessible over the Internet.
  * *   You can call this operation to upload media files only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media file to an OSS bucket, pull the file to a local directory, use [OSS SDK](https://help.aliyun.com/document_detail/32006.html) to upload the file to an OSS bucket, and then call the [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html) operation to register the file in the OSS bucket with the media asset library.
  * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
  * *   You can call this operation to upload only audio and video files.
  * @param request  the request parameters of UploadMediaByURL  UploadMediaByURLRequest
  * @return UploadMediaByURLResponse
 */
async function uploadMediaByURL(request: UploadMediaByURLRequest): UploadMediaByURLResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UploadMediaByURL', 'POST', '/', 'json', false, 'json', request);
}

model UploadStreamByURLRequest {
  regionId?: string(name='RegionId', position='Host'),
  definition?: string(name='Definition', description='The quality of the media stream. Valid values:

*   FD: low definition.
*   LD: standard definition.
*   SD: high definition.
*   HD: ultra-high definition.
*   OD: original quality.
*   2K: 2K resolution.
*   4K: 4K resolution.
*   SQ: standard sound quality.
*   HQ: high sound quality.', example='HD', position='Query'),
  fileExtension?: string(name='FileExtension', description='The file name extension of the media stream.', example='mp4', position='Query'),
  HDRType?: string(name='HDRType', description='The high dynamic range (HDR) format of the transcoded stream. Valid values:

*   HDR
*   HDR10
*   HLG
*   DolbyVision
*   HDRVivid
*   SDR+

> 

*   The value is not case-sensitive,

*   You can leave this parameter empty for non-HDR streams.', example='HDR10', position='Query'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***', position='Query'),
  streamURL?: string(name='StreamURL', description='The URL of the transcoded stream file.

If the URL of the transcoded stream requires authentication, you must specify the authentication parameters in the stream URL and make sure that the URL can be accessed over the Internet.', example='https://example.com/sample-stream.mp4', position='Query'),
  userData?: string(name='UserData', description='The user data.', example='{"MessageCallback":{"CallbackURL":"http://test.test.com"}, "Extend":{"localId":"xxx","test":"www"}}', position='Query'),
}

model UploadStreamByURLResponseBody = {
  fileURL?: string(name='FileURL', description='The OSS URL of the file.', example='http://outin-***.oss-cn-shanghai.aliyuncs.com/stream/48555e8b-181dd5a8c07/48555e8b-181dd5a8c07.mp4'),
  jobId?: string(name='JobId', description='The ID of the upload job.', example='****cdb3e74639973036bc84****'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***'),
  requestId?: string(name='RequestId', description='The request ID.', example='******89-C21D-4B78-AE24-3788B8******'),
  sourceURL?: string(name='SourceURL', description='The URL of the source file that is uploaded in the upload job.', example='https://example.com/sample-stream.mp4'),
}

model UploadStreamByURLResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UploadStreamByURLResponseBody(name='body'),
}

/**
  * @description *   You can call this operation to pull a media stream file based on a URL and upload the file. After the media stream file is uploaded, the media stream is associated with the specified media asset ID.
  * *   You can call this operation to upload media stream files only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media stream file to an OSS bucket, pull the file to a local directory, use [OSS SDK](https://help.aliyun.com/document_detail/32006.html) to upload the file to an OSS bucket, and then call the [RegisterMediaStream](https://help.aliyun.com/document_detail/440765.html) operation to associate the media stream with the specified media asset ID.
  * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
  * @param request  the request parameters of UploadStreamByURL  UploadStreamByURLRequest
  * @return UploadStreamByURLResponse
 */
async function uploadStreamByURL(request: UploadStreamByURLRequest): UploadStreamByURLResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UploadStreamByURL', 'POST', '/', 'json', false, 'json', request);
}

