/**
 *
 */
import OpenApi;
import OpenApi.OpenApiUtil;

extends OpenApi;


init(config: OpenApiUtil.Config){
  super(config);
  @signatureAlgorithm = 'v2';
  @endpointRule = 'regional';
  @endpointMap = {
    'ap-northeast-1' = 'ice.aliyuncs.com',
    'ap-northeast-2-pop' = 'ice.aliyuncs.com',
    'ap-south-1' = 'ice.aliyuncs.com',
    'ap-southeast-1' = 'ice.aliyuncs.com',
    'ap-southeast-2' = 'ice.aliyuncs.com',
    'ap-southeast-3' = 'ice.aliyuncs.com',
    'ap-southeast-5' = 'ice.aliyuncs.com',
    'cn-beijing' = 'ice.aliyuncs.com',
    'cn-beijing-finance-1' = 'ice.aliyuncs.com',
    'cn-beijing-finance-pop' = 'ice.aliyuncs.com',
    'cn-beijing-gov-1' = 'ice.aliyuncs.com',
    'cn-beijing-nu16-b01' = 'ice.aliyuncs.com',
    'cn-chengdu' = 'ice.aliyuncs.com',
    'cn-edge-1' = 'ice.aliyuncs.com',
    'cn-fujian' = 'ice.aliyuncs.com',
    'cn-haidian-cm12-c01' = 'ice.aliyuncs.com',
    'cn-hangzhou' = 'ice.aliyuncs.com',
    'cn-hangzhou-bj-b01' = 'ice.aliyuncs.com',
    'cn-hangzhou-finance' = 'ice.aliyuncs.com',
    'cn-hangzhou-internal-prod-1' = 'ice.aliyuncs.com',
    'cn-hangzhou-internal-test-1' = 'ice.aliyuncs.com',
    'cn-hangzhou-internal-test-2' = 'ice.aliyuncs.com',
    'cn-hangzhou-internal-test-3' = 'ice.aliyuncs.com',
    'cn-hangzhou-test-306' = 'ice.aliyuncs.com',
    'cn-hongkong' = 'ice.aliyuncs.com',
    'cn-hongkong-finance-pop' = 'ice.aliyuncs.com',
    'cn-huhehaote' = 'ice.aliyuncs.com',
    'cn-huhehaote-nebula-1' = 'ice.aliyuncs.com',
    'cn-north-2-gov-1' = 'ice.aliyuncs.com',
    'cn-qingdao' = 'ice.aliyuncs.com',
    'cn-qingdao-nebula' = 'ice.aliyuncs.com',
    'cn-shanghai-et15-b01' = 'ice.aliyuncs.com',
    'cn-shanghai-et2-b01' = 'ice.aliyuncs.com',
    'cn-shanghai-finance-1' = 'ice.aliyuncs.com',
    'cn-shanghai-inner' = 'ice.aliyuncs.com',
    'cn-shanghai-internal-test-1' = 'ice.aliyuncs.com',
    'cn-shenzhen' = 'ice.aliyuncs.com',
    'cn-shenzhen-finance-1' = 'ice.aliyuncs.com',
    'cn-shenzhen-inner' = 'ice.aliyuncs.com',
    'cn-shenzhen-st4-d01' = 'ice.aliyuncs.com',
    'cn-shenzhen-su18-b01' = 'ice.aliyuncs.com',
    'cn-wuhan' = 'ice.aliyuncs.com',
    'cn-wulanchabu' = 'ice.aliyuncs.com',
    'cn-yushanfang' = 'ice.aliyuncs.com',
    'cn-zhangbei' = 'ice.aliyuncs.com',
    'cn-zhangbei-na61-b01' = 'ice.aliyuncs.com',
    'cn-zhangjiakou' = 'ice.aliyuncs.com',
    'cn-zhangjiakou-na62-a01' = 'ice.aliyuncs.com',
    'cn-zhengzhou-nebula-1' = 'ice.aliyuncs.com',
    'eu-central-1' = 'ice.aliyuncs.com',
    'eu-west-1' = 'ice.aliyuncs.com',
    'eu-west-1-oxs' = 'ice.aliyuncs.com',
    'me-east-1' = 'ice.aliyuncs.com',
    'rus-west-1-pop' = 'ice.aliyuncs.com',
    'us-east-1' = 'ice.aliyuncs.com',
    'us-west-1' = 'ice.aliyuncs.com',
  };

  checkConfig(config);
  @endpoint = getEndpoint('ice', @regionId, @endpointRule, @network, @suffix, @endpointMap, @endpoint);
}

function getEndpoint(productId: string, regionId: string, endpointRule: string, network: string, suffix: string, endpointMap: map[string]string, endpoint: string) throws: string{
  if (!$isNull(endpoint)) {
    return endpoint;
  }
  
  if (!$isNull(endpointMap) && !$isNull(endpointMap[regionId])) {
    return endpointMap[regionId];
  }
  return OpenApiUtil.getEndpointRules(productId, regionId, endpointRule, network, suffix);
}

model AIAgentRuntimeConfig {
  avatarChat3D?: {
    agentUserId?: string(name='AgentUserId'),
    authToken?: string(name='AuthToken'),
    channelId?: string(name='ChannelId'),
  }(name='AvatarChat3D'),
  visionChat?: {
    agentUserId?: string(name='AgentUserId'),
    authToken?: string(name='AuthToken'),
    channelId?: string(name='ChannelId'),
  }(name='VisionChat'),
  voiceChat?: {
    agentUserId?: string(name='AgentUserId'),
    authToken?: string(name='AuthToken'),
    channelId?: string(name='ChannelId'),
  }(name='VoiceChat'),
}

model AIAgentTemplateConfig {
  avatarChat3D?: {
    asrLanguageId?: string(name='AsrLanguageId'),
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    avatarId?: string(name='AvatarId'),
    bailianAppParams?: string(name='BailianAppParams'),
    enableIntelligentSegment?: boolean(name='EnableIntelligentSegment'),
    enablePushToTalk?: boolean(name='EnablePushToTalk'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    gracefulShutdown?: boolean(name='GracefulShutdown'),
    greeting?: string(name='Greeting'),
    interruptWords?: [ string ](name='InterruptWords'),
    llmHistory?: [ 
      {
        content?: string(name='Content'),
        role?: string(name='Role'),
      }
    ](name='LlmHistory'),
    llmHistoryLimit?: int32(name='LlmHistoryLimit'),
    llmSystemPrompt?: string(name='LlmSystemPrompt'),
    maxIdleTime?: int32(name='MaxIdleTime'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    vadLevel?: int32(name='VadLevel'),
    voiceId?: string(name='VoiceId'),
    voiceIdList?: [ string ](name='VoiceIdList'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
    wakeUpQuery?: string(name='WakeUpQuery'),
    workflowOverrideParams?: string(name='WorkflowOverrideParams'),
  }(name='AvatarChat3D'),
  visionChat?: {
    asrLanguageId?: string(name='AsrLanguageId'),
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    bailianAppParams?: string(name='BailianAppParams'),
    enableIntelligentSegment?: boolean(name='EnableIntelligentSegment'),
    enablePushToTalk?: boolean(name='EnablePushToTalk'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    gracefulShutdown?: boolean(name='GracefulShutdown'),
    greeting?: string(name='Greeting'),
    interruptWords?: [ string ](name='InterruptWords'),
    llmHistory?: [ 
      {
        content?: string(name='Content'),
        role?: string(name='Role'),
      }
    ](name='LlmHistory'),
    llmHistoryLimit?: int32(name='LlmHistoryLimit'),
    llmSystemPrompt?: string(name='LlmSystemPrompt'),
    maxIdleTime?: int32(name='MaxIdleTime'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    vadLevel?: int32(name='VadLevel'),
    voiceId?: string(name='VoiceId'),
    voiceIdList?: [ string ](name='VoiceIdList'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
    wakeUpQuery?: string(name='WakeUpQuery'),
    workflowOverrideParams?: string(name='WorkflowOverrideParams'),
  }(name='VisionChat'),
  voiceChat?: {
    asrLanguageId?: string(name='AsrLanguageId'),
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    avatarUrl?: string(name='AvatarUrl'),
    avatarUrlType?: string(name='AvatarUrlType'),
    bailianAppParams?: string(name='BailianAppParams'),
    enableIntelligentSegment?: boolean(name='EnableIntelligentSegment'),
    enablePushToTalk?: boolean(name='EnablePushToTalk'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt'),
    gracefulShutdown?: boolean(name='GracefulShutdown'),
    greeting?: string(name='Greeting'),
    interruptWords?: [ string ](name='InterruptWords'),
    llmHistory?: [ 
      {
        content?: string(name='Content'),
        role?: string(name='Role'),
      }
    ](name='LlmHistory'),
    llmHistoryLimit?: int32(name='LlmHistoryLimit'),
    llmSystemPrompt?: string(name='LlmSystemPrompt'),
    maxIdleTime?: int32(name='MaxIdleTime'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    vadLevel?: int32(name='VadLevel'),
    voiceId?: string(name='VoiceId'),
    voiceIdList?: [ string ](name='VoiceIdList'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
    wakeUpQuery?: string(name='WakeUpQuery'),
    workflowOverrideParams?: string(name='WorkflowOverrideParams'),
  }(name='VoiceChat'),
}

model AppInfoDTO {
  appName?: string(name='AppName'),
  appType?: int32(name='AppType', example='1-普通应用，2-内嵌SDK.'),
  gmtCreate?: string(name='GmtCreate'),
  itemId?: string(name='ItemId'),
  platforms?: [ 
    {
      itemId?: string(name='ItemId'),
      licenseItemIds?: [ string ](name='LicenseItemIds'),
      pkgName?: string(name='PkgName'),
      pkgSignature?: string(name='PkgSignature'),
      platformType?: long(name='PlatformType'),
      type?: long(name='Type'),
    }
  ](name='Platforms'),
  userId?: long(name='UserId'),
}

model Channel {
  accessPolicy?: boolean(name='AccessPolicy'),
  accessToken?: string(name='AccessToken'),
  arn?: string(name='Arn'),
  channelName?: string(name='ChannelName'),
  channelTier?: string(name='ChannelTier'),
  fillerSourceLocationName?: string(name='FillerSourceLocationName'),
  fillerSourceName?: string(name='FillerSourceName'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  outPutConfigList?: [ 
    {
      channelName?: string(name='ChannelName'),
      format?: string(name='Format'),
      manifestName?: string(name='ManifestName'),
      manifestSettings?: string(name='ManifestSettings'),
      playbackUrl?: string(name='PlaybackUrl'),
      sourceGroupName?: string(name='SourceGroupName'),
    }
  ](name='OutPutConfigList'),
  playbackMode?: string(name='PlaybackMode'),
  state?: int32(name='State'),
}

model ChannelAssemblyChannel {
  accessPolicy?: boolean(name='AccessPolicy'),
  accessToken?: string(name='AccessToken'),
  arn?: string(name='Arn'),
  channelName?: string(name='ChannelName'),
  channelTier?: string(name='ChannelTier'),
  fillerSourceLocationName?: string(name='FillerSourceLocationName'),
  fillerSourceName?: string(name='FillerSourceName'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  outPutConfigList?: [ 
    {
      channelName?: string(name='ChannelName'),
      format?: string(name='Format'),
      manifestName?: string(name='ManifestName'),
      manifestSettings?: string(name='ManifestSettings'),
      playbackUrl?: string(name='PlaybackUrl'),
      sourceGroupName?: string(name='SourceGroupName'),
    }
  ](name='OutPutConfigList'),
  playbackMode?: string(name='PlaybackMode'),
  state?: int32(name='State'),
}

model ChannelAssemblyProgram {
  adBreaks?: [ 
    {
      channelName?: string(name='ChannelName'),
      messageType?: string(name='MessageType'),
      offsetMillis?: long(name='OffsetMillis'),
      programName?: string(name='ProgramName'),
      sourceLocationName?: string(name='SourceLocationName'),
      sourceName?: string(name='SourceName'),
      spliceInsertSettings?: string(name='SpliceInsertSettings'),
      timeSignalSettings?: string(name='TimeSignalSettings'),
    }
  ](name='AdBreaks'),
  arn?: string(name='Arn'),
  channelName?: string(name='ChannelName'),
  clipRange?: string(name='ClipRange'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  programName?: string(name='ProgramName'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
  transition?: string(name='Transition'),
}

model ChannelAssemblyScheduleData {
  adBreaks?: [ 
    {
      messageType?: string(name='MessageType'),
      offsetMillis?: string(name='OffsetMillis'),
      sourceLocationName?: string(name='SourceLocationName'),
      sourceName?: string(name='SourceName'),
      spliceInsertSettings?: string(name='SpliceInsertSettings'),
      timeSignalSettings?: string(name='TimeSignalSettings'),
    }
  ](name='AdBreaks'),
  approximateDurationSeconds?: long(name='ApproximateDurationSeconds'),
  approximateStartTime?: string(name='ApproximateStartTime'),
  entryType?: string(name='EntryType'),
  programName?: string(name='ProgramName'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
}

model ChannelAssemblySource {
  arn?: string(name='Arn'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  httpPackageConfigurations?: string(name='HttpPackageConfigurations'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
  state?: int32(name='State'),
}

model ChannelAssemblySourceLocation {
  arn?: string(name='Arn'),
  baseUrl?: string(name='BaseUrl'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  segmentDeliveryConfigurations?: string(name='SegmentDeliveryConfigurations'),
  sourceLocationName?: string(name='SourceLocationName'),
  state?: int32(name='State'),
}

model LicenseInstanceAppDTO {
  appId?: string(name='AppId'),
  beginOn?: string(name='BeginOn'),
  contractNo?: string(name='ContractNo'),
  creationTime?: string(name='CreationTime'),
  expiredOn?: string(name='ExpiredOn'),
  instanceId?: string(name='InstanceId'),
  itemId?: string(name='ItemId'),
  licenseConfigs?: [ 
    {
      businessType?: string(name='BusinessType'),
      featureIds?: string(name='FeatureIds'),
      isTrial?: boolean(name='IsTrial'),
      sdkId?: int32(name='SdkId'),
      sdkName?: string(name='SdkName'),
      subscription?: string(name='Subscription'),
      subscriptionImp?: string(name='SubscriptionImp'),
      subscriptionPkg?: string(name='SubscriptionPkg'),
    }
  ](name='LicenseConfigs'),
  modificationTime?: string(name='ModificationTime'),
  status?: string(name='Status'),
  userId?: long(name='UserId'),
}

model LiveManifestConfig {
  adMarkers?: string(name='AdMarkers'),
  dateTimeInterval?: int32(name='DateTimeInterval'),
  manifestName?: string(name='ManifestName'),
  maxVideoBitrate?: int32(name='MaxVideoBitrate'),
  minBufferTime?: int32(name='MinBufferTime'),
  minVideoBitrate?: int32(name='MinVideoBitrate'),
  protocol?: string(name='Protocol'),
  segmentNum?: int32(name='SegmentNum'),
  streamOrder?: string(name='StreamOrder'),
  useAudioRenditionGroups?: boolean(name='UseAudioRenditionGroups'),
}

model LivePackagingConfig {
  drmConfig?: {
    encryptionMethod?: string(name='EncryptionMethod'),
    IV?: string(name='IV'),
    systemIds?: [ string ](name='SystemIds'),
    url?: string(name='Url'),
  }(name='DrmConfig'),
  liveManifestConfigs?: [
    LiveManifestConfig
  ](name='LiveManifestConfigs'),
  segmentDuration?: int32(name='SegmentDuration'),
  useAudioRenditionGroups?: boolean(name='UseAudioRenditionGroups'),
}

model MediaConvertAudio {
  bitrate?: long(name='Bitrate'),
  channels?: long(name='Channels'),
  codec?: string(name='Codec'),
  profile?: string(name='Profile'),
  remove?: boolean(name='Remove'),
  samplerate?: string(name='Samplerate'),
}

model MediaConvertInput {
  inputFile?: MediaObject(name='InputFile'),
  name?: string(name='Name'),
}

model MediaConvertMuxConfig {
  segment?: MediaConvertSegment(name='Segment'),
}

model MediaConvertOutput {
  features?: string(name='Features'),
  name?: string(name='Name'),
  outputFile?: MediaObject(name='OutputFile'),
  overrideParams?: string(name='OverrideParams'),
  priority?: int32(name='Priority'),
  templateId?: string(name='TemplateId'),
}

model MediaConvertOutputDetail {
  code?: string(name='Code'),
  message?: string(name='Message'),
  name?: string(name='Name'),
  status?: string(name='Status'),
  taskId?: string(name='TaskId'),
}

model MediaConvertOutputGroup {
  groupConfig?: MediaConvertOutputGroupConfig(name='GroupConfig'),
  name?: string(name='Name'),
  outputs?: [
    MediaConvertOutputGroupOutput
  ](name='Outputs'),
}

model MediaConvertOutputGroupConfig {
  manifestName?: string(name='ManifestName'),
  outputFileBase?: MediaObject(name='OutputFileBase'),
  type?: string(name='Type'),
}

model MediaConvertOutputGroupDetail {
  code?: string(name='Code'),
  message?: string(name='Message'),
  name?: string(name='Name'),
  outputs?: [
    MediaConvertOutputDetail
  ](name='Outputs'),
  status?: string(name='Status'),
  taskId?: string(name='TaskId'),
}

model MediaConvertOutputGroupOutput {
  features?: string(name='Features'),
  name?: string(name='Name'),
  outputFileName?: string(name='OutputFileName'),
  overrideParams?: string(name='OverrideParams'),
  priority?: int32(name='Priority'),
  templateId?: string(name='TemplateId'),
}

model MediaConvertSegment {
  duration?: int32(name='Duration'),
  forceSegTime?: string(name='ForceSegTime'),
}

model MediaConvertTransConfig {
  adjDarMethod?: string(name='AdjDarMethod'),
  isCheckAudioBitrate?: boolean(name='IsCheckAudioBitrate'),
  isCheckAudioBitrateFail?: boolean(name='IsCheckAudioBitrateFail'),
  isCheckReso?: boolean(name='IsCheckReso'),
  isCheckResoFail?: boolean(name='IsCheckResoFail'),
  isCheckVideoBitrate?: boolean(name='IsCheckVideoBitrate'),
  isCheckVideoBitrateFail?: boolean(name='IsCheckVideoBitrateFail'),
  transMode?: string(name='TransMode'),
}

model MediaConvertVideo {
  bitrate?: int32(name='Bitrate'),
  bufsize?: int32(name='Bufsize'),
  codec?: string(name='Codec'),
  crf?: any(name='Crf'),
  crop?: string(name='Crop'),
  fps?: any(name='Fps'),
  gop?: any(name='Gop'),
  height?: int32(name='Height'),
  longShortMode?: boolean(name='LongShortMode'),
  maxFps?: any(name='MaxFps'),
  maxrate?: int32(name='Maxrate'),
  pad?: string(name='Pad'),
  profile?: string(name='Profile'),
  qscale?: int32(name='Qscale'),
  remove?: boolean(name='Remove'),
  scanMode?: string(name='ScanMode'),
  width?: int32(name='Width'),
}

model MediaConvertVolume {
  integratedLoudnessTarget?: int32(name='IntegratedLoudnessTarget'),
  level?: int32(name='Level'),
  loudnessRangeTarget?: int32(name='LoudnessRangeTarget'),
  method?: string(name='Method'),
  truePeak?: int32(name='TruePeak'),
}

model MediaObject {
  media?: string(name='Media'),
  type?: string(name='Type'),
  url?: string(name='Url'),
}

model Program {
  adBreaks?: [ 
    {
      channelName?: string(name='ChannelName'),
      messageType?: string(name='MessageType'),
      offsetMillis?: long(name='OffsetMillis'),
      programName?: string(name='ProgramName'),
      sourceLocationName?: string(name='SourceLocationName'),
      sourceName?: string(name='SourceName'),
      spliceInsertSettings?: string(name='SpliceInsertSettings'),
      timeSignalSettings?: string(name='TimeSignalSettings'),
    }
  ](name='AdBreaks'),
  arn?: string(name='Arn'),
  channelName?: string(name='ChannelName'),
  clipRange?: string(name='ClipRange'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  programName?: string(name='ProgramName'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
  transition?: string(name='Transition'),
}

model ScheduleData {
  adBreaks?: [ 
    {
      messageType?: string(name='MessageType'),
      offsetMillis?: string(name='OffsetMillis'),
      sourceLocationName?: string(name='SourceLocationName'),
      sourceName?: string(name='SourceName'),
      spliceInsertSettings?: string(name='SpliceInsertSettings'),
      timeSignalSettings?: string(name='TimeSignalSettings'),
    }
  ](name='AdBreaks'),
  approximateDurationSeconds?: long(name='ApproximateDurationSeconds'),
  approximateStartTime?: string(name='ApproximateStartTime'),
  entryType?: string(name='EntryType'),
  programName?: string(name='ProgramName'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
}

model Source {
  arn?: string(name='Arn'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  httpPackageConfigurations?: string(name='HttpPackageConfigurations'),
  sourceLocationName?: string(name='SourceLocationName'),
  sourceName?: string(name='SourceName'),
  sourceType?: string(name='SourceType'),
  state?: int32(name='State'),
}

model SourceLocation {
  arn?: string(name='Arn'),
  baseUrl?: string(name='BaseUrl'),
  gmtCreate?: string(name='GmtCreate'),
  gmtModified?: string(name='GmtModified'),
  segmentDeliveryConfigurations?: string(name='SegmentDeliveryConfigurations'),
  sourceLocationName?: string(name='SourceLocationName'),
  state?: int32(name='State'),
}

model VodPackagingAsset {
  assetName?: string(name='AssetName'),
  contentId?: string(name='ContentId'),
  createTime?: string(name='CreateTime'),
  groupName?: string(name='GroupName'),
  input?: {
    media?: string(name='Media'),
    type?: string(name='Type'),
  }(name='Input'),
}

model VodPackagingConfig {
  drmProvider?: {
    encryptionMethod?: string(name='EncryptionMethod'),
    IV?: string(name='IV'),
    systemIds?: [ string ](name='SystemIds'),
    url?: string(name='Url'),
  }(name='DrmProvider'),
  manifestName?: string(name='ManifestName'),
  segmentDuration?: long(name='SegmentDuration'),
  streamSelection?: {
    maxVideoBitsPerSecond?: long(name='MaxVideoBitsPerSecond'),
    minVideoBitsPerSecond?: long(name='MinVideoBitsPerSecond'),
    streamOrder?: string(name='StreamOrder'),
  }(name='StreamSelection'),
}

model VodPackagingConfiguration {
  configurationName?: string(name='ConfigurationName'),
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  groupName?: string(name='GroupName'),
  packageConfig?: VodPackagingConfig(name='PackageConfig'),
  protocol?: string(name='Protocol'),
}

model VodPackagingGroup {
  approximateAssetCount?: long(name='ApproximateAssetCount'),
  configurationCount?: long(name='ConfigurationCount'),
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  domainName?: string(name='DomainName'),
  groupName?: string(name='GroupName'),
}

model AddAdInsertionRequest {
  adMarkerPassthrough?: string(name='AdMarkerPassthrough', description='Specifies whether to enable ad marker passthrough. Default value: OFF.

Valid values:

*   OFF: Disable.
*   ON: Enable.', example='ON'),
  adsUrl?: string(name='AdsUrl', description='The request URL of the ad decision server (ADS). HTTP and HTTPS are supported. The maximum length is 2,048 characters.

This parameter is required.', example='http://ads.com/ad1?param1=[palyer_params.p1]'),
  cdnAdSegmentUrlPrefix?: string(name='CdnAdSegmentUrlPrefix', description='The CDN prefix for ad segments. HTTP and HTTPS are supported. The maximum length is 512 characters.', example='http://cdn.com/'),
  cdnContentSegmentUrlPrefix?: string(name='CdnContentSegmentUrlPrefix', description='The CDN prefix for content segments. HTTP and HTTPS are supported. The maximum length is 512 characters.', example='http://cdn.com/'),
  clientToken?: string(name='ClientToken', description='The idempotency key that is used to avoid repeated submission. The value can be up to 200 characters in length.', example='****0311a423d11a5f7dee713535****'),
  configAliases?: string(name='ConfigAliases', description='A JSON string that specifies the player parameter variables and aliases. You can add up to 20 player_params.{name} entries. The name field can be up to 150 characters in length. Each player parameter can include up to 50 key-value pairs. A key can be up to 150 characters long, and a value can be up to 500 characters. Example: { "player_params.{name}": { "{key}": "{value}" } }', example='{ "player_params.p1": { "1": "abc" } }'),
  contentUrlPrefix?: string(name='ContentUrlPrefix', description='The URL prefix for the source content. HTTP and HTTPS are supported. The maximum length is 512 characters.

This parameter is required.', example='https://source.com/'),
  name?: string(name='Name', description='The name of the configuration. The name must be unique and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.

This parameter is required.', example='my_ad'),
  personalizationThreshold?: int32(name='PersonalizationThreshold', description='Specifies the maximum duration of underfilled time allowed in an ad break. Unit: seconds. Default value: 8 seconds.', example='5'),
  slateAdUrl?: string(name='SlateAdUrl', description='The HTTP or HTTPS URL of the slate ad. Only MP4 format is supported. The maximum length is 2,048 characters.', example='http://storage.com/slate1.mp4'),
}

model AddAdInsertionResponseBody = {
  config?: {
    adMarkerPassthrough?: string(name='AdMarkerPassthrough', description='Indicates whether ad marker passthrough is enabled.', example='ON'),
    adsUrl?: string(name='AdsUrl', description='The request URL of ADS.', example='http://ads.com/ad1?param1=[palyer_params.p1]'),
    cdnConfig?: {
      adSegmentUrlPrefix?: string(name='AdSegmentUrlPrefix', description='The CDN prefix for ad segments.', example='http://cdn.com/'),
      contentSegmentUrlPrefix?: string(name='ContentSegmentUrlPrefix', description='The CDN prefix for content segments.', example='http://cdn.com/'),
    }(name='CdnConfig', description='The CDN configurations.'),
    configAliases?: string(name='ConfigAliases', description='The player parameter variables and aliases.', example='{ "player_params.p1": { "1": "abc" } }'),
    contentUrlPrefix?: string(name='ContentUrlPrefix', description='The URL prefix for the source content.', example='https://source.com/'),
    createTime?: string(name='CreateTime', description='The time when the configuration was created.', example='2024-06-13T08:26:09Z'),
    lastModified?: string(name='LastModified', description='The time when the configuration was last modified.', example='2024-06-13T08:26:09Z'),
    manifestEndpointConfig?: {
      hlsPrefix?: string(name='HlsPrefix', description='The prefix of the playback endpoint for HLS manifests.'),
    }(name='ManifestEndpointConfig', description='The playback endpoint configuration.'),
    name?: string(name='Name', description='The name of the ad insertion configuration.', example='my_ad'),
    personalizationThreshold?: int32(name='PersonalizationThreshold', description='The personalization threshold.', example='5'),
    slateAdUrl?: string(name='SlateAdUrl', description='The URL of the slate ad.', example='http://storage.com/slate1.mp4'),
  }(name='Config', description='The ad insertion configuration.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
}

model AddAdInsertionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddAdInsertionResponseBody(name='body'),
}

/**
 * @summary Adds an ad insertion configuration.
 *
 * @param request AddAdInsertionRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AddAdInsertionResponse
 */
async function addAdInsertionWithOptions(request: AddAdInsertionRequest, runtime: $RuntimeOptions): AddAdInsertionResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.adMarkerPassthrough)) {
    body['AdMarkerPassthrough'] = request.adMarkerPassthrough;
  }
  if (!$isNull(request.adsUrl)) {
    body['AdsUrl'] = request.adsUrl;
  }
  if (!$isNull(request.cdnAdSegmentUrlPrefix)) {
    body['CdnAdSegmentUrlPrefix'] = request.cdnAdSegmentUrlPrefix;
  }
  if (!$isNull(request.cdnContentSegmentUrlPrefix)) {
    body['CdnContentSegmentUrlPrefix'] = request.cdnContentSegmentUrlPrefix;
  }
  if (!$isNull(request.clientToken)) {
    body['ClientToken'] = request.clientToken;
  }
  if (!$isNull(request.configAliases)) {
    body['ConfigAliases'] = request.configAliases;
  }
  if (!$isNull(request.contentUrlPrefix)) {
    body['ContentUrlPrefix'] = request.contentUrlPrefix;
  }
  if (!$isNull(request.name)) {
    body['Name'] = request.name;
  }
  if (!$isNull(request.personalizationThreshold)) {
    body['PersonalizationThreshold'] = request.personalizationThreshold;
  }
  if (!$isNull(request.slateAdUrl)) {
    body['SlateAdUrl'] = request.slateAdUrl;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'AddAdInsertion',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Adds an ad insertion configuration.
 *
 * @param request AddAdInsertionRequest
 * @return AddAdInsertionResponse
 */
async function addAdInsertion(request: AddAdInsertionRequest): AddAdInsertionResponse {
  var runtime = new $RuntimeOptions{};
  return addAdInsertionWithOptions(request, runtime);
}

model AddCategoryRequest {
  cateName?: string(name='CateName', description='The category name.

*   The value can be up to 64 bytes in length.
*   The value must be encoded in UTF-8.

This parameter is required.'),
  parentId?: long(name='ParentId', description='The ID of the parent category.', example='5'),
  type?: string(name='Type', description='The type of the category. Valid values:

*   default: audio, video, and image files. This is the default value.
*   material: short video materials.', example='default'),
}

model AddCategoryResponseBody = {
  category?: {
    cateId?: long(name='CateId', description='The ID of the created category.', example='45'),
    cateName?: string(name='CateName', description='The category name.'),
    level?: long(name='Level', description='The level of the category. A value of **0** indicates a level-1 category, a value of **1** indicates a level-2 category, and a value of **2** indicates a level-3 category.', example='0'),
    parentId?: long(name='ParentId', description='The ID of the parent category. By default, if ParentId is left empty or less than 1, -1 is returned, which indicates that the created category is the root directory.', example='-1'),
    type?: string(name='Type', description='The type of the category. Valid values:

*   **default**: audio, video, and image files. This is the default value.
*   **material**: short video materials.', example='default'),
  }(name='Category', description='The information about the category.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model AddCategoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddCategoryResponseBody(name='body'),
}

/**
 * @summary Creates a category.
 *
 * @description You can create at most three levels of categories. Each category level can contain a maximum of 100 subcategories.
 *
 * @param request AddCategoryRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AddCategoryResponse
 */
async function addCategoryWithOptions(request: AddCategoryRequest, runtime: $RuntimeOptions): AddCategoryResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.cateName)) {
    query['CateName'] = request.cateName;
  }
  if (!$isNull(request.parentId)) {
    query['ParentId'] = request.parentId;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'AddCategory',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a category.
 *
 * @description You can create at most three levels of categories. Each category level can contain a maximum of 100 subcategories.
 *
 * @param request AddCategoryRequest
 * @return AddCategoryResponse
 */
async function addCategory(request: AddCategoryRequest): AddCategoryResponse {
  var runtime = new $RuntimeOptions{};
  return addCategoryWithOptions(request, runtime);
}

model AddEditingProjectMaterialsRequest {
  materialMaps?: string(name='MaterialMaps', description='The material ID. Separate multiple material IDs with commas (,). Each type supports up to 10 material IDs. The following material types are supported:

*   video
*   audio
*   image
*   liveStream
*   editingProject

This parameter is required.', example='{"video":"*****2e057304fcd9b145c5cafc*****", "image":"****8021a8d493da643c8acd98*****,*****cb6307a4edea614d8b3f3c*****", "liveStream": "[{\\\\"appName\\\\":\\\\"testrecord\\\\",\\\\"domainName\\\\":\\\\"test.alivecdn.com\\\\",\\\\"liveUrl\\\\":\\\\"rtmp://test.alivecdn.com/testrecord/teststream\\\\",\\\\"streamName\\\\":\\\\"teststream\\\\"}]", "editingProject": "*****9b145c5cafc2e057304fcd*****"}'),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='*****b2101cb318c*****'),
}

model AddEditingProjectMaterialsResponseBody = {
  liveMaterials?: [ 
    {
      appName?: string(name='AppName', description='The application name of the live stream.', example='testrecord'),
      domainName?: string(name='DomainName', description='The domain name of the live stream.', example='test.alivecdn.com'),
      liveUrl?: string(name='LiveUrl', description='The URL of the live stream.', example='rtmp://test.alivecdn.com/testrecord/teststream'),
      streamName?: string(name='StreamName', description='The name of the live stream.', example='teststream'),
    }
  ](name='LiveMaterials', description='The materials associated with the live stream.'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
            duration?: string(name='Duration', description='The duration.', example='216.206667'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
            fileStatus?: string(name='FileStatus', description='The file status.

\\\\-Uploading

\\\\-Normal

\\\\-UploadFail

\\\\-Disable

\\\\-Deleted', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='540'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='960'),
          }(name='FileBasicInfo', description='The basic information of the file, including the duration and size.'),
        }
      ](name='FileInfoList', description='FileInfos'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.', example='audio'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-23T03:32:59Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-23T03:32:59Z'),
        description?: string(name='Description', description='The description of the media asset.', example='sample_description'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/file.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****5cb2e35433198daae94a72*****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='sample_tag'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='Video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-23T03:32:59Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='null'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite of the media asset.', example='http://outin-example.oss-cn-shanghai.aliyuncs.com/test.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        status?: string(name='Status', description='The status of the media asset. Valid values:

\\\\- Init

\\\\- Preparing

\\\\- PrepareFail

\\\\- Normal', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.', example='default_title_2020-12-23T03:32:59Z'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information of the media assets.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****5cb2e35433198daae94a72*****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='*****67ae06542b9b93e0d1c387*****'),
  projectMaterials?: [ string ](name='ProjectMaterials', description='The materials associated with the editing project. A live stream editing project will be associated with a regular editing project after the live streaming ends.', example='*****9b145c5cafc2e057304fcd*****'),
  requestId?: string(name='RequestId', description='The request ID.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
}

model AddEditingProjectMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddEditingProjectMaterialsResponseBody(name='body'),
}

/**
 * @summary Adds one or more materials to an online editing project.
 *
 * @param request AddEditingProjectMaterialsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AddEditingProjectMaterialsResponse
 */
async function addEditingProjectMaterialsWithOptions(request: AddEditingProjectMaterialsRequest, runtime: $RuntimeOptions): AddEditingProjectMaterialsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.materialMaps)) {
    query['MaterialMaps'] = request.materialMaps;
  }
  if (!$isNull(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'AddEditingProjectMaterials',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Adds one or more materials to an online editing project.
 *
 * @param request AddEditingProjectMaterialsRequest
 * @return AddEditingProjectMaterialsResponse
 */
async function addEditingProjectMaterials(request: AddEditingProjectMaterialsRequest): AddEditingProjectMaterialsResponse {
  var runtime = new $RuntimeOptions{};
  return addEditingProjectMaterialsWithOptions(request, runtime);
}

model AddFavoritePublicMediaRequest {
  mediaIds?: string(name='MediaIds', example='icepublic-****7213c6050cbc66750b469701****,icepublic-****0b4697017213c6050cbc6675****'),
}

model AddFavoritePublicMediaResponseBody = {
  ignoredList?: [ string ](name='IgnoredList'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model AddFavoritePublicMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddFavoritePublicMediaResponseBody(name='body'),
}

/**
 * @summary 收藏公共媒资
 *
 * @param request AddFavoritePublicMediaRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AddFavoritePublicMediaResponse
 */
async function addFavoritePublicMediaWithOptions(request: AddFavoritePublicMediaRequest, runtime: $RuntimeOptions): AddFavoritePublicMediaResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaIds)) {
    query['MediaIds'] = request.mediaIds;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'AddFavoritePublicMedia',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 收藏公共媒资
 *
 * @param request AddFavoritePublicMediaRequest
 * @return AddFavoritePublicMediaResponse
 */
async function addFavoritePublicMedia(request: AddFavoritePublicMediaRequest): AddFavoritePublicMediaResponse {
  var runtime = new $RuntimeOptions{};
  return addFavoritePublicMediaWithOptions(request, runtime);
}

model AddMediaConnectFlowInputRequest {
  cidrs?: string(name='Cidrs', description='The IP address whitelist in CIDR format. Separate multiple CIDR blocks with commas (,).', example='19.168.1.1/32,18.168.1.1/16'),
  flowId?: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f'),
  inputFromUrl?: string(name='InputFromUrl', description='The source URL. This parameter is required when the source type is RTMP-PULL or SRT-Listener.', example='rtmp://pull.test.alivecdn.com/live/alitest'),
  inputName?: string(name='InputName', description='The source name.

This parameter is required.', example='AliTestInput'),
  inputProtocol?: string(name='InputProtocol', description='The source type.

Valid values:

*   RTMP-PUSH
*   SRT-Caller
*   RTMP-PULL
*   SRT-Listener
*   Flow

This parameter is required.', example='RTMP-PUSH'),
  maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s.', example='2000000'),
  pairFlowId?: string(name='PairFlowId', description='The ID of the source flow. This parameter is required when the source type is Flow.', example='805fbdd0-575e-4146-b35d-ec7f63937b20'),
  pairOutputName?: string(name='PairOutputName', description='The output of the source flow. This parameter is required when the source type is Flow.', example='AliTestOutput'),
  srtLatency?: int32(name='SrtLatency', description='The latency for the SRT stream. This parameter is required the source type is SRT-Listener or SRT-Caller.', example='1000'),
  srtPassphrase?: string(name='SrtPassphrase', description='The SRT key. This parameter is required when the source type is SRT-Listener or SRT-Caller.', example='BETTERG08S01'),
  srtPbkeyLen?: string(name='SrtPbkeyLen', description='The encryption key length. This parameter is required when the source type is SRT-Listener or SRT-Caller.

Valid values:

*   0
*   16
*   24
*   32', example='32'),
}

model AddMediaConnectFlowInputResponseBody = {
  content?: {
    inputUrl?: string(name='InputUrl', description='The source URL.', example='rtmp://1.2.3.4:1935/live/AliTestInput_8666ec062190f00e263012666319a5be'),
  }(name='Content', description='The response body.'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='11357BE8-4C54-58EA-890A-5AB646EDE4B2'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model AddMediaConnectFlowInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddMediaConnectFlowInputResponseBody(name='body'),
}

/**
 * @summary Creates a source for a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 * *   A flow can have only one source.
 * ### [](#)Source type
 * *   RTMP-PUSH: An input that you can push to the returned URL over the RTMP protocol.
 * *   RTMP-PULL: An input that the MediaConnect flow pulls from the specified server over the RTMP protocol.
 * *   SRT-Listener: An input that you can push to the returned URL over the SRT protocol.
 * *   SRT-Caller: An input that the MediaConnect flow pulls from the specified server over the SRT protocol.
 * *   Flow: An input that uses the output of another upstream flow. You must specify an upstream flow and its output. The output type of the upstream flow must be SRT-Listener or RTMP-PULL. By default, a dedicated line is used when flows are cascaded. This allows for cross-region distribution among multiple flows.
 *
 * @param request AddMediaConnectFlowInputRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AddMediaConnectFlowInputResponse
 */
async function addMediaConnectFlowInputWithOptions(request: AddMediaConnectFlowInputRequest, runtime: $RuntimeOptions): AddMediaConnectFlowInputResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.cidrs)) {
    query['Cidrs'] = request.cidrs;
  }
  if (!$isNull(request.flowId)) {
    query['FlowId'] = request.flowId;
  }
  if (!$isNull(request.inputFromUrl)) {
    query['InputFromUrl'] = request.inputFromUrl;
  }
  if (!$isNull(request.inputName)) {
    query['InputName'] = request.inputName;
  }
  if (!$isNull(request.inputProtocol)) {
    query['InputProtocol'] = request.inputProtocol;
  }
  if (!$isNull(request.maxBitrate)) {
    query['MaxBitrate'] = request.maxBitrate;
  }
  if (!$isNull(request.pairFlowId)) {
    query['PairFlowId'] = request.pairFlowId;
  }
  if (!$isNull(request.pairOutputName)) {
    query['PairOutputName'] = request.pairOutputName;
  }
  if (!$isNull(request.srtLatency)) {
    query['SrtLatency'] = request.srtLatency;
  }
  if (!$isNull(request.srtPassphrase)) {
    query['SrtPassphrase'] = request.srtPassphrase;
  }
  if (!$isNull(request.srtPbkeyLen)) {
    query['SrtPbkeyLen'] = request.srtPbkeyLen;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'AddMediaConnectFlowInput',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a source for a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 * *   A flow can have only one source.
 * ### [](#)Source type
 * *   RTMP-PUSH: An input that you can push to the returned URL over the RTMP protocol.
 * *   RTMP-PULL: An input that the MediaConnect flow pulls from the specified server over the RTMP protocol.
 * *   SRT-Listener: An input that you can push to the returned URL over the SRT protocol.
 * *   SRT-Caller: An input that the MediaConnect flow pulls from the specified server over the SRT protocol.
 * *   Flow: An input that uses the output of another upstream flow. You must specify an upstream flow and its output. The output type of the upstream flow must be SRT-Listener or RTMP-PULL. By default, a dedicated line is used when flows are cascaded. This allows for cross-region distribution among multiple flows.
 *
 * @param request AddMediaConnectFlowInputRequest
 * @return AddMediaConnectFlowInputResponse
 */
async function addMediaConnectFlowInput(request: AddMediaConnectFlowInputRequest): AddMediaConnectFlowInputResponse {
  var runtime = new $RuntimeOptions{};
  return addMediaConnectFlowInputWithOptions(request, runtime);
}

model AddMediaConnectFlowOutputRequest {
  cidrs?: string(name='Cidrs', description='The IP address whitelist in CIDR format. Separate multiple CIDR blocks with commas (,).', example='83.17.231.31/32'),
  flowId?: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f'),
  outputName?: string(name='OutputName', description='The output name.

This parameter is required.', example='AliTestOutput'),
  outputProtocol?: string(name='OutputProtocol', description='The output type.

Valid values:

*   RTMP-PUSH
*   SRT-Caller
*   RTMP-PULL
*   SRT-Listener
*   Flow

This parameter is required.', example='RTMP-PULL'),
  outputToUrl?: string(name='OutputToUrl', description='The output URL. This parameter is required when OutputProtocol is set to RTMP-PUSH or SRT-Caller.', example='rtmp://push.test.alivecdn.com/live/alitest'),
  pairFlowId?: string(name='PairFlowId', description='The ID of the destination flow. This parameter is required when OutputProtocol is set to Flow.', example='8666ec062190f00e263012666319a5be'),
  pairInputName?: string(name='PairInputName', description='The source name of the destination flow. This parameter is required when OutputProtocol is set to Flow.', example='AliTestInput'),
  playerLimit?: int32(name='PlayerLimit', description='The maximum number of viewers.', example='5'),
  srtLatency?: int32(name='SrtLatency', description='The latency for the SRT stream. This parameter is required when the source type is SRT-Listener or SRT-Caller.', example='1000'),
  srtPassphrase?: string(name='SrtPassphrase', description='The SRT key. This parameter is required when the source type is SRT-Listener or SRT-Caller.', example='BETTERG08S01'),
  srtPbkeyLen?: string(name='SrtPbkeyLen', description='The encryption key length. This parameter is required when the source type is SRT-Listener or SRT-Caller.', example='32'),
}

model AddMediaConnectFlowOutputResponseBody = {
  content?: {
    outputUrl?: string(name='OutputUrl', description='The output URL.', example='srt://1.2.3.4:1025'),
  }(name='Content', description='The response body.'),
  description?: string(name='Description', description='The call description.', example='ok'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='11AA9E73-FBA0-58DC-97BA-D606D847BCB6'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates that the call is successful.', example='0'),
}

model AddMediaConnectFlowOutputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddMediaConnectFlowOutputResponseBody(name='body'),
}

/**
 * @summary Creates an output for a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 * *   A flow can have a maximum of four outputs.
 * *   The output names in the same flow cannot be duplicated.
 * *   You can set an upper limit on the number of concurrent viewers for each output. If this limit is exceeded, any new playback requests will fail. Each output supports up to five streams.
 * ### [](#)Output types
 * *   RTMP-PUSH: An output that the MediaConnect flow pushes to the server you specified over the RTMP protocol.
 * *   RTMP-PULL: An output that you can pull using the returned streaming URL over the RTMP protocol.
 * *   SRT-Caller: An output that the MediaConnect flow pushes to the server you specified over the SRT protocol.
 * *   SRT-Listener: An output that you can pull using the returned streaming URL over the SRT protocol.
 * *   Flow: An output that is pushed to the source URL of another MediaConnect flow. The source type of the destination flow must be SRT-Listener or RTMP-PUSH. By default, a dedicated line is used when flows are cascaded. This allows for cross-region distribution among multiple flows.
 *
 * @param request AddMediaConnectFlowOutputRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AddMediaConnectFlowOutputResponse
 */
async function addMediaConnectFlowOutputWithOptions(request: AddMediaConnectFlowOutputRequest, runtime: $RuntimeOptions): AddMediaConnectFlowOutputResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.cidrs)) {
    query['Cidrs'] = request.cidrs;
  }
  if (!$isNull(request.flowId)) {
    query['FlowId'] = request.flowId;
  }
  if (!$isNull(request.outputName)) {
    query['OutputName'] = request.outputName;
  }
  if (!$isNull(request.outputProtocol)) {
    query['OutputProtocol'] = request.outputProtocol;
  }
  if (!$isNull(request.outputToUrl)) {
    query['OutputToUrl'] = request.outputToUrl;
  }
  if (!$isNull(request.pairFlowId)) {
    query['PairFlowId'] = request.pairFlowId;
  }
  if (!$isNull(request.pairInputName)) {
    query['PairInputName'] = request.pairInputName;
  }
  if (!$isNull(request.playerLimit)) {
    query['PlayerLimit'] = request.playerLimit;
  }
  if (!$isNull(request.srtLatency)) {
    query['SrtLatency'] = request.srtLatency;
  }
  if (!$isNull(request.srtPassphrase)) {
    query['SrtPassphrase'] = request.srtPassphrase;
  }
  if (!$isNull(request.srtPbkeyLen)) {
    query['SrtPbkeyLen'] = request.srtPbkeyLen;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'AddMediaConnectFlowOutput',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates an output for a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 * *   A flow can have a maximum of four outputs.
 * *   The output names in the same flow cannot be duplicated.
 * *   You can set an upper limit on the number of concurrent viewers for each output. If this limit is exceeded, any new playback requests will fail. Each output supports up to five streams.
 * ### [](#)Output types
 * *   RTMP-PUSH: An output that the MediaConnect flow pushes to the server you specified over the RTMP protocol.
 * *   RTMP-PULL: An output that you can pull using the returned streaming URL over the RTMP protocol.
 * *   SRT-Caller: An output that the MediaConnect flow pushes to the server you specified over the SRT protocol.
 * *   SRT-Listener: An output that you can pull using the returned streaming URL over the SRT protocol.
 * *   Flow: An output that is pushed to the source URL of another MediaConnect flow. The source type of the destination flow must be SRT-Listener or RTMP-PUSH. By default, a dedicated line is used when flows are cascaded. This allows for cross-region distribution among multiple flows.
 *
 * @param request AddMediaConnectFlowOutputRequest
 * @return AddMediaConnectFlowOutputResponse
 */
async function addMediaConnectFlowOutput(request: AddMediaConnectFlowOutputRequest): AddMediaConnectFlowOutputResponse {
  var runtime = new $RuntimeOptions{};
  return addMediaConnectFlowOutputWithOptions(request, runtime);
}

model AddMediaMarksRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='53afdf003a2171ed9c6a16b5feac6402'),
  mediaMarks?: string(name='MediaMarks', description='The mark information. The value must be a JSONArray.

This parameter is required.'),
}

model AddMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='53afdf003a******6a16b5feac6402'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The IDs of the marks that are added.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
  requestId?: string(name='RequestId', description='The request ID.', example='771A1414-27BF-53E6-AB73-EFCB*****ACF'),
}

model AddMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddMediaMarksResponseBody(name='body'),
}

/**
 * @summary Adds marks for a media asset.
 *
 * @param request AddMediaMarksRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AddMediaMarksResponse
 */
async function addMediaMarksWithOptions(request: AddMediaMarksRequest, runtime: $RuntimeOptions): AddMediaMarksResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.mediaMarks)) {
    query['MediaMarks'] = request.mediaMarks;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'AddMediaMarks',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Adds marks for a media asset.
 *
 * @param request AddMediaMarksRequest
 * @return AddMediaMarksResponse
 */
async function addMediaMarks(request: AddMediaMarksRequest): AddMediaMarksResponse {
  var runtime = new $RuntimeOptions{};
  return addMediaMarksWithOptions(request, runtime);
}

model AddTemplateRequest {
  config?: string(name='Config', example='参见Timeline模板Config文档'),
  coverUrl?: string(name='CoverUrl', description='The URL of the template thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
  name?: string(name='Name', description='The name of the custom template.', example='视频添加水印模板'),
  previewMedia?: string(name='PreviewMedia', description='The ID of the template preview video.', example='****01bf24bf41c78b2754cb3187****'),
  relatedMediaids?: string(name='RelatedMediaids', description='The IDs of the materials associated with the template for use by the regular template editor.', example='{"video":["1805a0c6ca544fb395a06ca683619655"]}'),
  source?: string(name='Source', description='The source from which the template is created. Valid values:

*   OpenAPI
*   AliyunConsole
*   WebSDK

<!---->', example='OpenAPI'),
  status?: string(name='Status', description='The template state. Valid values:

*   Available: The template is available.
*   Created: The template is created but not ready for use.
*   Uploading: The video is being uploaded.
*   Processing: The advanced template is being processed.
*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.

<!---->', example='Available'),
  type?: string(name='Type', description='The template type. Valid values:

*   Timeline: a regular template created based on the timeline of a video editing project, in which multiple materials are arranged in sequence across multiple layers. It can be used to convert text and images into videos, create photo albums, add opening and closing parts, and apply the default watermark.
*   VETemplate: an advanced template created using effects of Adobe After Effects (AE). It can be used to produce complex animations and advanced media effects.

<!---->', example='Timeline'),
}

model AddTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
  template?: {
    config?: string(name='Config', description='The template configurations.', example='参见Timeline模板Config文档'),
    coverUrl?: string(name='CoverUrl', description='The URL of the template thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
    createSource?: string(name='CreateSource', description='The source from which the template was created.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
    modifiedSource?: string(name='ModifiedSource', description='The source from which the template was modified.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
    name?: string(name='Name', description='The template name.', example='视频添加水印模板'),
    previewMedia?: string(name='PreviewMedia', description='The ID of the preview video.', example='****01bf24bf41c78b2754cb3187****'),
    status?: string(name='Status', description='The template state.

Valid values:

*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.
*   Available: The template is available.
*   Uploading: The video is being uploaded.
*   Created: The template is created but not ready for use.
*   Processing: The advanced template is being processed.', example='Available'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****01bf24bf41c78b2754cb3187****'),
    type?: string(name='Type', description='The template type.

Valid values:

*   Timeline: regular template.
*   VETemplate: advanced template.', example='Timeline'),
  }(name='Template', description='The template information.'),
}

model AddTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddTemplateResponseBody(name='body'),
}

/**
 * @summary Creates a template.
 *
 * @description *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 * *   After an advanced template is created, it enters the Processing state. In this case, the template is unavailable. The template can be used only when it is in the Available state. The time required for template processing varies based on the size of the template file. Generally, it ranges from 10 seconds to 5 minutes.
 *
 * @param request AddTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AddTemplateResponse
 */
async function addTemplateWithOptions(request: AddTemplateRequest, runtime: $RuntimeOptions): AddTemplateResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.coverUrl)) {
    query['CoverUrl'] = request.coverUrl;
  }
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.previewMedia)) {
    query['PreviewMedia'] = request.previewMedia;
  }
  if (!$isNull(request.relatedMediaids)) {
    query['RelatedMediaids'] = request.relatedMediaids;
  }
  if (!$isNull(request.source)) {
    query['Source'] = request.source;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  var body : map[string]any = {};
  if (!$isNull(request.config)) {
    body['Config'] = request.config;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'AddTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a template.
 *
 * @description *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 * *   After an advanced template is created, it enters the Processing state. In this case, the template is unavailable. The template can be used only when it is in the Available state. The time required for template processing varies based on the size of the template file. Generally, it ranges from 10 seconds to 5 minutes.
 *
 * @param request AddTemplateRequest
 * @return AddTemplateResponse
 */
async function addTemplate(request: AddTemplateRequest): AddTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return addTemplateWithOptions(request, runtime);
}

model AlterSearchIndexRequest {
  indexConfig?: string(name='IndexConfig', description='The configurations of the index.

>  You must specify either IndexStatus or IndexConfig.', example='{}'),
  indexStatus?: string(name='IndexStatus', description='The state of the index. Valid values:

*   active (default): the index is enabled.
*   Deactive: the index is not enabled.

>  You must specify either IndexStatus or IndexConfig.', example='Active'),
  indexType?: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.

This parameter is required.', example='mm'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

*   If you leave this parameter empty, the search index is created in the default search library of Intelligent Media Service (IMS). Default value: ims-default-search-lib.
*   To query information about an existing search library, call the [QuerySearchLib](https://help.aliyun.com/document_detail/2584455.html) API operation.', example='test1'),
}

model AlterSearchIndexResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model AlterSearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AlterSearchIndexResponseBody(name='body'),
}

/**
 * @summary Modifies search index information including index status and configurations.
 *
 * @param request AlterSearchIndexRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return AlterSearchIndexResponse
 */
async function alterSearchIndexWithOptions(request: AlterSearchIndexRequest, runtime: $RuntimeOptions): AlterSearchIndexResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.indexConfig)) {
    query['IndexConfig'] = request.indexConfig;
  }
  if (!$isNull(request.indexStatus)) {
    query['IndexStatus'] = request.indexStatus;
  }
  if (!$isNull(request.indexType)) {
    query['IndexType'] = request.indexType;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'AlterSearchIndex',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies search index information including index status and configurations.
 *
 * @param request AlterSearchIndexRequest
 * @return AlterSearchIndexResponse
 */
async function alterSearchIndex(request: AlterSearchIndexRequest): AlterSearchIndexResponse {
  var runtime = new $RuntimeOptions{};
  return alterSearchIndexWithOptions(request, runtime);
}

model BatchCreateVodPackagingAssetRequest {
  assets?: [ 
    {
      assetName?: string(name='AssetName', description='The name of the asset. The name must be unique and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='30min_movie'),
      contentId?: string(name='ContentId', description='The content ID in the digital rights management (DRM) system. The maximum length is 256 characters. Letters, digits, underscores (_), and hyphens (-) are supported.', example='movie'),
      input?: {
        media?: string(name='Media', description='The URL of the media file. You can only specify a M3U8 file stored in Object Storage Service (OSS).'),
        type?: string(name='Type', description='The input type. Only OSS is supported.', example='OSS'),
      }(name='Input', description='The asset input configurations.'),
    }
  ](name='Assets', description='The assets that you want to ingest.'),
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls'),
}

model BatchCreateVodPackagingAssetShrinkRequest {
  assetsShrink?: string(name='Assets', description='The assets that you want to ingest.'),
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls'),
}

model BatchCreateVodPackagingAssetResponseBody = {
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
  resultList?: [ 
    {
      asset?: VodPackagingAsset(name='Asset', description='The information about the ingested asset.'),
      code?: string(name='Code', description='The error code for failed ingestion.', example='InvalidParameter.PackagingAssetAlreadyExists'),
      message?: string(name='Message', description='The error message for failed ingestion.', example='The specified packagingAsset "inputMovie" already exists'),
    }
  ](name='ResultList', description='The results of asset ingestion.'),
}

model BatchCreateVodPackagingAssetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: BatchCreateVodPackagingAssetResponseBody(name='body'),
}

/**
 * @summary Ingests multiple assets for VOD packaging.
 *
 * @param tmpReq BatchCreateVodPackagingAssetRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return BatchCreateVodPackagingAssetResponse
 */
async function batchCreateVodPackagingAssetWithOptions(tmpReq: BatchCreateVodPackagingAssetRequest, runtime: $RuntimeOptions): BatchCreateVodPackagingAssetResponse {
  tmpReq.validate();
  var request = new BatchCreateVodPackagingAssetShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.assets)) {
    request.assetsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.assets, 'Assets', 'json');
  }
  var query = {};
  if (!$isNull(request.assetsShrink)) {
    query['Assets'] = request.assetsShrink;
  }
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'BatchCreateVodPackagingAsset',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Ingests multiple assets for VOD packaging.
 *
 * @param request BatchCreateVodPackagingAssetRequest
 * @return BatchCreateVodPackagingAssetResponse
 */
async function batchCreateVodPackagingAsset(request: BatchCreateVodPackagingAssetRequest): BatchCreateVodPackagingAssetResponse {
  var runtime = new $RuntimeOptions{};
  return batchCreateVodPackagingAssetWithOptions(request, runtime);
}

model BatchGetMediaInfosRequest {
  additionType?: string(name='AdditionType', description='The additional information that you want to query about the media assets. By default, only BasicInfo is returned. The following additional information can be queried:

\\\\- FileInfo

\\\\- DynamicMetaData', example='FileInfo,DynamicMetaData'),
  mediaIds?: string(name='MediaIds', description='The IDs of the media assets that you want to query. Separate the IDs with commas (,).', example='******b48fb04483915d4f2cd8******,******c48fb37407365d4f2cd8******'),
}

model BatchGetMediaInfosResponseBody = {
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
            duration?: string(name='Duration', description='The duration.', example='200'),
            fileName?: string(name='FileName', description='The file name.', example='example'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='1080'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='1920'),
          }(name='FileBasicInfo', description='The basic information of the file, including the duration and size.'),
        }
      ](name='FileInfoList', description='FileInfos'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-26T04:11:10Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-26T04:11:10Z'),
        description?: string(name='Description', description='The description of the media asset.'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        mediaId?: string(name='MediaId', description='MediaId', example='******c48fb37407365d4f2cd8******'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.'),
        mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

\\\\- image

\\\\- video

\\\\- audio

\\\\- text', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-26T04:11:12Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='[{"bucket":"example-bucket","count":"3","iceJobId":"******f48f0e4154976b2b8c45******","location":"oss-cn-beijing","snapshotRegular":"example.jpg","templateId":"******e6a6440b29eb60bd7c******"}]'),
        source?: string(name='Source', description='The source of the media asset. Valid values:

\\\\- oss

\\\\- vod', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite.', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userDataTest'),
      }(name='MediaBasicInfo', description='The basic information of the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******c48fb37407365d4f2cd8******'),
    }
  ](name='MediaInfos', description='The queried media assets.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model BatchGetMediaInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: BatchGetMediaInfosResponseBody(name='body'),
}

/**
 * @summary Queries the information about multiple media assets at a time based on media asset IDs.
 *
 * @param request BatchGetMediaInfosRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return BatchGetMediaInfosResponse
 */
async function batchGetMediaInfosWithOptions(request: BatchGetMediaInfosRequest, runtime: $RuntimeOptions): BatchGetMediaInfosResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.additionType)) {
    query['AdditionType'] = request.additionType;
  }
  if (!$isNull(request.mediaIds)) {
    query['MediaIds'] = request.mediaIds;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'BatchGetMediaInfos',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about multiple media assets at a time based on media asset IDs.
 *
 * @param request BatchGetMediaInfosRequest
 * @return BatchGetMediaInfosResponse
 */
async function batchGetMediaInfos(request: BatchGetMediaInfosRequest): BatchGetMediaInfosResponse {
  var runtime = new $RuntimeOptions{};
  return batchGetMediaInfosWithOptions(request, runtime);
}

model CancelDNAJobRequest {
  jobId?: string(name='JobId', description='The ID of the media fingerprint analysis job that you want to cancel.

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model CancelDNAJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='2288c6ca184c0e47098a5b665e2a12****'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model CancelDNAJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CancelDNAJobResponseBody(name='body'),
}

/**
 * @summary Cancels a media fingerprint analysis job.
 *
 * @description *   You can cancel a media fingerprint analysis job only if the job is in the Queuing state.
 * *   We recommend that you call the **UpdatePipeline** operation to set the status of the ApsaraVideo Media Processing (MPS) queue to Paused before you cancel a job. This suspends job scheduling in the MPS queue. After the job is canceled, you must set the status of the MPS queue back to Active so that the other jobs in the MPS queue can be scheduled.
 *
 * @param request CancelDNAJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CancelDNAJobResponse
 */
async function cancelDNAJobWithOptions(request: CancelDNAJobRequest, runtime: $RuntimeOptions): CancelDNAJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!$isNull(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!$isNull(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!$isNull(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CancelDNAJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Cancels a media fingerprint analysis job.
 *
 * @description *   You can cancel a media fingerprint analysis job only if the job is in the Queuing state.
 * *   We recommend that you call the **UpdatePipeline** operation to set the status of the ApsaraVideo Media Processing (MPS) queue to Paused before you cancel a job. This suspends job scheduling in the MPS queue. After the job is canceled, you must set the status of the MPS queue back to Active so that the other jobs in the MPS queue can be scheduled.
 *
 * @param request CancelDNAJobRequest
 * @return CancelDNAJobResponse
 */
async function cancelDNAJob(request: CancelDNAJobRequest): CancelDNAJobResponse {
  var runtime = new $RuntimeOptions{};
  return cancelDNAJobWithOptions(request, runtime);
}

model CancelFavoritePublicMediaRequest {
  mediaIds?: string(name='MediaIds', example='icepublic-****7213c6050cbc66750b469701****,icepublic-****0b4697017213c6050cbc6675****'),
}

model CancelFavoritePublicMediaResponseBody = {
  ignoredList?: [ string ](name='IgnoredList'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model CancelFavoritePublicMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CancelFavoritePublicMediaResponseBody(name='body'),
}

/**
 * @summary 取消收藏公共媒资
 *
 * @param request CancelFavoritePublicMediaRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CancelFavoritePublicMediaResponse
 */
async function cancelFavoritePublicMediaWithOptions(request: CancelFavoritePublicMediaRequest, runtime: $RuntimeOptions): CancelFavoritePublicMediaResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaIds)) {
    query['MediaIds'] = request.mediaIds;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CancelFavoritePublicMedia',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 取消收藏公共媒资
 *
 * @param request CancelFavoritePublicMediaRequest
 * @return CancelFavoritePublicMediaResponse
 */
async function cancelFavoritePublicMedia(request: CancelFavoritePublicMediaRequest): CancelFavoritePublicMediaResponse {
  var runtime = new $RuntimeOptions{};
  return cancelFavoritePublicMediaWithOptions(request, runtime);
}

model CreateAuditRequest {
  auditContent?: string(name='AuditContent', description='The review results. You can specify the results for a maximum of 20 videos at a time. The value must be converted to a string. For more information about the parameters in AuditContent, see the "AuditContent" section of this topic.

This parameter is required.', example='[
      {
            "MediaId": "93ab850b4f*****b54b6e91d24d81d4",
            "Status": "Normal"
      },
      {
            "MediaId": "f867fbfb58*****8bbab65c4480ae1d",
            "Status": "Blocked",
            "Reason": "xxxx",
            "Comment": "xxxx"
      }
]'),
}

model CreateAuditResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateAuditResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateAuditResponseBody(name='body'),
}

/**
 * @summary Submits manual review results for media assets.
 *
 * @param request CreateAuditRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateAuditResponse
 */
async function createAuditWithOptions(request: CreateAuditRequest, runtime: $RuntimeOptions): CreateAuditResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.auditContent)) {
    query['AuditContent'] = request.auditContent;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateAudit',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits manual review results for media assets.
 *
 * @param request CreateAuditRequest
 * @return CreateAuditResponse
 */
async function createAudit(request: CreateAuditRequest): CreateAuditResponse {
  var runtime = new $RuntimeOptions{};
  return createAuditWithOptions(request, runtime);
}

model CreateAvatarTrainingJobRequest {
  avatarDescription?: string(name='AvatarDescription', description='*   The description of the digital human.
*   The description can be up to 1,000 characters in length.'),
  avatarName?: string(name='AvatarName', description='*   The name of the digital human.
*   The name can be up to seven characters in length.

This parameter is required.'),
  avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
  portrait?: string(name='Portrait', description='*   The media asset ID of the portrait image.
*   The value must be 32 characters in length.', example='****571c704445f9a0ee011406c2****'),
  thumbnail?: string(name='Thumbnail', description='*   The thumbnail URL.
*   After the digital human is trained, the thumbnail is uploaded to this URL.
*   The URL must be a valid public Object Storage Service (OSS) URL.
*   The URL can be up to 512 characters in length.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
  transparent?: boolean(name='Transparent', description='*   Specifies whether the training video supports alpha channels.

    **

    **Note**: Make sure that the current settings are consistent with those of the submitted training video. Otherwise, the digital human may malfunction.', example='True'),
  video?: string(name='Video', description='*   The ID of the video used for training.
*   The value must be 32 characters in length.
*   Supported formats: MP4, MOV, and WebM.
*   The duration of the video must be 5 to 15 minutes.
*   The resolution of the video must be 1920×1080 or 1080×1920.', example='****571c704445f9a0ee011406c2****'),
}

model CreateAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateAvatarTrainingJobResponseBody(name='body'),
}

/**
 * @summary Creates a digital human training job. You can configure the basic information of the digital human and the materials required for the training. Note: This operation is used to initialize the training job. It does not submit the training job. To submit the training job, call the SubmitAvatarTrainingJob operation.
 *
 * @param request CreateAvatarTrainingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateAvatarTrainingJobResponse
 */
async function createAvatarTrainingJobWithOptions(request: CreateAvatarTrainingJobRequest, runtime: $RuntimeOptions): CreateAvatarTrainingJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.avatarDescription)) {
    query['AvatarDescription'] = request.avatarDescription;
  }
  if (!$isNull(request.avatarName)) {
    query['AvatarName'] = request.avatarName;
  }
  if (!$isNull(request.avatarType)) {
    query['AvatarType'] = request.avatarType;
  }
  if (!$isNull(request.portrait)) {
    query['Portrait'] = request.portrait;
  }
  if (!$isNull(request.thumbnail)) {
    query['Thumbnail'] = request.thumbnail;
  }
  if (!$isNull(request.transparent)) {
    query['Transparent'] = request.transparent;
  }
  if (!$isNull(request.video)) {
    query['Video'] = request.video;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateAvatarTrainingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a digital human training job. You can configure the basic information of the digital human and the materials required for the training. Note: This operation is used to initialize the training job. It does not submit the training job. To submit the training job, call the SubmitAvatarTrainingJob operation.
 *
 * @param request CreateAvatarTrainingJobRequest
 * @return CreateAvatarTrainingJobResponse
 */
async function createAvatarTrainingJob(request: CreateAvatarTrainingJobRequest): CreateAvatarTrainingJobResponse {
  var runtime = new $RuntimeOptions{};
  return createAvatarTrainingJobWithOptions(request, runtime);
}

model CreateChannelRequest {
  accessPolicy?: boolean(name='AccessPolicy', description='Specifies whether to enable access control.', example='false'),
  accessToken?: string(name='AccessToken', description='The token for accessing the channel.', example='xxxxx'),
  channelName?: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel'),
  channelTier?: string(name='ChannelTier', description='The tier of the channel. Valid values: basic and standard.

This parameter is required.', example='basic'),
  fillerSourceLocationName?: string(name='FillerSourceLocationName', description='The source location of the filler slate.', example='MySourceLocation'),
  fillerSourceName?: string(name='FillerSourceName', description='The name of the filler slate.', example='FillerSource'),
  outPutConfigList?: string(name='OutPutConfigList', description='The channel output configurations.

This parameter is required.', example='[{
	"ManifestName": "manifest-1",
	"Format": "HLS",
	"SourceGroupName": "source-group-1",
	"ManifestSettings": {
		"WindowDuration": 60,
		"AdMarkType": "Daterange"
	}
}]'),
  playbackMode?: string(name='PlaybackMode', description='The playback mode. Valid values: loop and linear.

This parameter is required.', example='loop'),
}

model CreateChannelResponseBody = {
  channel?: ChannelAssemblyChannel(name='Channel', description='The channel information.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
}

model CreateChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateChannelResponseBody(name='body'),
}

/**
 * @summary Creates a channel in MediaWeaver.
 *
 * @param request CreateChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateChannelResponse
 */
async function createChannelWithOptions(request: CreateChannelRequest, runtime: $RuntimeOptions): CreateChannelResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.accessPolicy)) {
    query['AccessPolicy'] = request.accessPolicy;
  }
  if (!$isNull(request.accessToken)) {
    query['AccessToken'] = request.accessToken;
  }
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.channelTier)) {
    query['ChannelTier'] = request.channelTier;
  }
  if (!$isNull(request.fillerSourceLocationName)) {
    query['FillerSourceLocationName'] = request.fillerSourceLocationName;
  }
  if (!$isNull(request.fillerSourceName)) {
    query['FillerSourceName'] = request.fillerSourceName;
  }
  if (!$isNull(request.outPutConfigList)) {
    query['OutPutConfigList'] = request.outPutConfigList;
  }
  if (!$isNull(request.playbackMode)) {
    query['PlaybackMode'] = request.playbackMode;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a channel in MediaWeaver.
 *
 * @param request CreateChannelRequest
 * @return CreateChannelResponse
 */
async function createChannel(request: CreateChannelRequest): CreateChannelResponse {
  var runtime = new $RuntimeOptions{};
  return createChannelWithOptions(request, runtime);
}

model CreateCustomTemplateRequest {
  name?: string(name='Name', description='The template name.

This parameter is required.', example='test-template'),
  subtype?: int32(name='Subtype', description='The template subtype.

Valid values for transcoding templates:

*   1 (Normal): regular template.
*   2 (AudioTranscode): audio transcoding template.
*   3 (Remux): container format conversion template.
*   4 (NarrowBandV1): Narrowband HD 1.0 template.
*   5 (NarrowBandV2): Narrowband HD 2.0 template.

Valid values for snapshot templates:

*   1 (Normal): regular template.
*   2 (Sprite): sprite template.
*   3 (WebVtt): WebVTT template.

Valid values for AI-assisted content moderation templates:

*   1 (Video): video moderation template.
*   2 (Audio): audio moderation template.
*   3 (Image): image moderation template.

Valid values for AI-assisted intelligent erasure templates.

*   1 (VideoDelogo): logo erasure template.
*   2 (VideoDetext): subtitle erasure template.', example='1'),
  templateConfig?: string(name='TemplateConfig', description='The template configurations. For more information, see [Template parameters](https://help.aliyun.com/document_detail/448291.html).

This parameter is required.', example='{"Container":{"Format":"flv"},"Video":{},"Audio":{}}'),
  type?: int32(name='Type', description='The template type. Valid values:

*   1: transcoding template.
*   2: snapshot template.
*   3: animated image template.
*   4\\\\. image watermark template.
*   5: text watermark template.
*   6: subtitle template.
*   7: AI-assisted content moderation template.
*   8: AI-assisted intelligent thumbnail template.
*   9: AI-assisted intelligent erasure template.
*   10: AI-assisted media fingerprint analysis template.
*   11: AI-assisted smart tagging template.

This parameter is required.', example='1'),
}

model CreateCustomTemplateResponseBody = {
  customTemplate?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-04-19T02:04:31Z'),
    isDefault?: boolean(name='IsDefault', description='Indicates whether the template is the default template.', example='true'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-04-19T02:04:31Z'),
    status?: string(name='Status', description='The template state.', example='Normal'),
    subtype?: string(name='Subtype', description='The subtype name of the template.', example='Remux'),
    templateConfig?: string(name='TemplateConfig', description='The template configurations.', example='{"Container":{"Format":"flv"},"Video":{},"Audio":{}}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
    templateName?: string(name='TemplateName', description='The template name.', example='test-template'),
    type?: int32(name='Type', description='The type ID of the template.', example='1'),
    typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
  }(name='CustomTemplate', description='The template information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateCustomTemplateResponseBody(name='body'),
}

/**
 * @summary Creates a custom template.
 *
 * @param request CreateCustomTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateCustomTemplateResponse
 */
async function createCustomTemplateWithOptions(request: CreateCustomTemplateRequest, runtime: $RuntimeOptions): CreateCustomTemplateResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.subtype)) {
    query['Subtype'] = request.subtype;
  }
  if (!$isNull(request.templateConfig)) {
    query['TemplateConfig'] = request.templateConfig;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateCustomTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a custom template.
 *
 * @param request CreateCustomTemplateRequest
 * @return CreateCustomTemplateResponse
 */
async function createCustomTemplate(request: CreateCustomTemplateRequest): CreateCustomTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return createCustomTemplateWithOptions(request, runtime);
}

model CreateCustomizedVoiceJobRequest {
  gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male

This parameter is required.', example='female'),
  scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation

This parameter is required.', example='story'),
  voiceDesc?: string(name='VoiceDesc', description='The voice description.

*   The description can be up to 256 characters in length.'),
  voiceId?: string(name='VoiceId', description='The voice ID. It can be the English name or Chinese Pinyin of the voice.

*   The value must be a unique ID that is not used by other custom voices.
*   The ID can be up to 32 characters in length.
*   Only letters and digits are supported.

This parameter is required.', example='xiaozhuan'),
  voiceName?: string(name='VoiceName', description='The voice name.

*   The name can be up to 32 characters in length.'),
}

model CreateCustomizedVoiceJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****29faef8144638ba42eb8e037****'),
    voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
}

model CreateCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Creates a human voice cloning job. You can configure the basic information of the human voice cloning job.
 *
 * @param request CreateCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateCustomizedVoiceJobResponse
 */
async function createCustomizedVoiceJobWithOptions(request: CreateCustomizedVoiceJobRequest, runtime: $RuntimeOptions): CreateCustomizedVoiceJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.gender)) {
    query['Gender'] = request.gender;
  }
  if (!$isNull(request.scenario)) {
    query['Scenario'] = request.scenario;
  }
  if (!$isNull(request.voiceDesc)) {
    query['VoiceDesc'] = request.voiceDesc;
  }
  if (!$isNull(request.voiceId)) {
    query['VoiceId'] = request.voiceId;
  }
  if (!$isNull(request.voiceName)) {
    query['VoiceName'] = request.voiceName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a human voice cloning job. You can configure the basic information of the human voice cloning job.
 *
 * @param request CreateCustomizedVoiceJobRequest
 * @return CreateCustomizedVoiceJobResponse
 */
async function createCustomizedVoiceJob(request: CreateCustomizedVoiceJobRequest): CreateCustomizedVoiceJobResponse {
  var runtime = new $RuntimeOptions{};
  return createCustomizedVoiceJobWithOptions(request, runtime);
}

model CreateDNADBRequest {
  description?: string(name='Description', description='The description of the media fingerprint library.'),
  model?: string(name='Model', description='The model of the media fingerprint library. Valid values:

*   **Video**
*   **Audio**
*   **Image**
*   **Text** (supported only in the China (Shanghai) region)', example='Video'),
  name?: string(name='Name', description='The name of the media fingerprint library.

This parameter is required.', example='example name'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model CreateDNADBResponseBody = {
  DBInfo?: {
    DBId?: string(name='DBId', description='The ID of the media fingerprint library. We recommend that you save this ID for subsequent calls of other operations.', example='88c6ca184c0e47098a5b665e2a12****'),
    description?: string(name='Description', description='The description of the media fingerprint library.'),
    model?: string(name='Model', description='The model of the media fingerprint library.', example='Video'),
    name?: string(name='Name', description='The name of the media fingerprint library.', example='example name'),
    status?: string(name='Status', description='The state of the media fingerprint library. After a media fingerprint library is created, it enters the offline state. After the media fingerprint library is processed at the backend, it enters the active state.', example='offline'),
  }(name='DBInfo', description='The details of the media fingerprint library.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model CreateDNADBResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDNADBResponseBody(name='body'),
}

/**
 * @summary Creates media fingerprint libraries.
 *
 * @description *   You can create up to five media fingerprint libraries within an account. To increase the quota, submit a ticket. You can call the DeleteDNADB operation to delete the fingerprint libraries that you no longer need.
 *
 * @param request CreateDNADBRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateDNADBResponse
 */
async function createDNADBWithOptions(request: CreateDNADBRequest, runtime: $RuntimeOptions): CreateDNADBResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.model)) {
    query['Model'] = request.model;
  }
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!$isNull(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!$isNull(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!$isNull(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateDNADB',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates media fingerprint libraries.
 *
 * @description *   You can create up to five media fingerprint libraries within an account. To increase the quota, submit a ticket. You can call the DeleteDNADB operation to delete the fingerprint libraries that you no longer need.
 *
 * @param request CreateDNADBRequest
 * @return CreateDNADBResponse
 */
async function createDNADB(request: CreateDNADBRequest): CreateDNADBResponse {
  var runtime = new $RuntimeOptions{};
  return createDNADBWithOptions(request, runtime);
}

model CreateEditingProjectRequest {
  businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.

For a live stream editing project, observe the following rules: OutputMediaConfig.StorageLocation is required. OutputMediaConfig.Path is optional. If you do not specify this option, the live streaming clips are stored in the root directory by default.

Valid values of OutputMediaTarget include vod-media and oss-object. If you do not specify OutputMediaTarget, the default value oss-object is used.

If you set OutputMediaTarget to vod-media, the setting of OutputMediaConfig.Path does not take effect.', example='{ "OutputMediaConfig" : { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path" }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
  clipsParam?: string(name='ClipsParam', description='The material parameter corresponding to the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified. For more information<props="china">, see [Create and use a regular template](https://help.aliyun.com/document_detail/328557.html) and [Create and use an advanced template](https://help.aliyun.com/document_detail/291418.html).'),
  coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='https://example.com/example.png'),
  description?: string(name='Description', description='The description of the online editing project.', example='描述'),
  materialMaps?: string(name='MaterialMaps', description='The material associated with the project. Separate multiple material IDs with commas (,). Each type supports up to 10 material IDs.', example='{"video":"*****2e057304fcd9b145c5cafc*****", "image":"****8021a8d493da643c8acd98*****,*****cb6307a4edea614d8b3f3c*****", "liveStream": "[{\\\\"appName\\\\":\\\\"testrecord\\\\",\\\\"domainName\\\\":\\\\"test.alivecdn.com\\\\",\\\\"liveUrl\\\\":\\\\"rtmp://test.alivecdn.com/testrecord/teststream\\\\",\\\\"streamName\\\\":\\\\"teststream\\\\"}]", "editingProject": "*****9b145c5cafc2e057304fcd*****"}'),
  projectType?: string(name='ProjectType', description='The type of the editing project. Valid values: EditingProject and LiveEditingProject. A value of EditingProject indicates a regular editing project, and a value of LiveEditingProject indicates a live stream editing project.', example='LiveEditingProject'),
  templateId?: string(name='TemplateId', description='The template ID. This parameter is used to quickly build a timeline with ease. Note: Only one of Timeline and TemplateId can be specified. If TemplateId is specified, ClipsParam must also be specified.', example='****96e8864746a0b6f3****'),
  templateType?: string(name='TemplateType', description='The template type. This parameter is required if you create a template-based online editing project. Default value: Timeline. Valid values:

*   Timeline: a regular template.
*   VETemplate: an advanced template.', example='Timeline'),
  timeline?: string(name='Timeline', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
  title?: string(name='Title', description='The title of the online editing project.

This parameter is required.', example='example'),
}

model CreateEditingProjectResponseBody = {
  project?: {
    businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{ "OutputMediaConfig" :    { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path"   }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
    businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

*   Reserving
*   ReservationCanceled
*   BroadCasting
*   LoadingFailed
*   LiveFinished', example='Reserving'),
    clipsParam?: string(name='ClipsParam', description='The template material parameters.'),
    coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
    createSource?: string(name='CreateSource', description='The method for creating the online editing project. Valid values:

\\\\- OpenAPI

\\\\- AliyunConsole

\\\\- WebSDK

\\\\- LiveEditingOpenAPI

\\\\- LiveEditingConsole', example='WebSDK'),
    createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2021-01-08T16:52:07Z'),
    description?: string(name='Description', description='The description of the online editing project.', example='example_description'),
    duration?: float(name='Duration', description='The duration of the online editing project.', example='3.4200000'),
    modifiedSource?: string(name='ModifiedSource', description='The method for editing the online editing project. Valid values:

\\\\- OpenAPI

\\\\- AliyunConsole

\\\\- WebSDK

\\\\- LiveEditingOpenAPI

\\\\- LiveEditingConsole', example='WebSDK'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last edited.', example='2021-01-08T16:52:07Z'),
    projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****01bf24bf41c78b2754cb3187****'),
    projectType?: string(name='ProjectType', description='The type of the editing project. Default value: EditingProject. Valid values:

\\\\- EditingProject: a regular editing project.

\\\\- LiveEditingProject: a live stream editing project.', example='LiveEditingProject'),
    status?: long(name='Status', description='The status of the online editing project.

Valid values:

\\\\- 1: Draft

\\\\- 2: Editing

\\\\- 3: Producing

\\\\- 4: Produced

\\\\- 5: ProduceFailed

\\\\- 7: Deleted', example='2'),
    statusName?: string(name='StatusName', description='The status of the online editing project. For more information, see the status list.', example='Editing'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
    templateType?: string(name='TemplateType', description='The template type of the online editing project. Valid values:

\\\\- Timeline

\\\\- VETemplate', example='Timeline'),
    timeline?: string(name='Timeline', description='The timeline of the online editing project, in the JSON format.<props="china">For more information about objects in a timeline, see [Timeline configurations](https://help.aliyun.com/document_detail/198823.htm?spm=a2c4g.11186623.2.9.90dc653dF67srN#topic-2024662).  If you leave this parameter empty, an empty timeline is created and the duration of the online editing project is zero.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
    title?: string(name='Title', description='The title of the online editing project.', example='example_title'),
  }(name='Project', description='The information about the online editing project.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model CreateEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateEditingProjectResponseBody(name='body'),
}

/**
 * @summary Creates an online editing project. You can specify configurations such as the title, description, timeline, and thumbnail for the project.
 *
 * @param request CreateEditingProjectRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateEditingProjectResponse
 */
async function createEditingProjectWithOptions(request: CreateEditingProjectRequest, runtime: $RuntimeOptions): CreateEditingProjectResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.businessConfig)) {
    query['BusinessConfig'] = request.businessConfig;
  }
  if (!$isNull(request.clipsParam)) {
    query['ClipsParam'] = request.clipsParam;
  }
  if (!$isNull(request.coverURL)) {
    query['CoverURL'] = request.coverURL;
  }
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.materialMaps)) {
    query['MaterialMaps'] = request.materialMaps;
  }
  if (!$isNull(request.projectType)) {
    query['ProjectType'] = request.projectType;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!$isNull(request.templateType)) {
    query['TemplateType'] = request.templateType;
  }
  if (!$isNull(request.title)) {
    query['Title'] = request.title;
  }
  var body : map[string]any = {};
  if (!$isNull(request.timeline)) {
    body['Timeline'] = request.timeline;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateEditingProject',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates an online editing project. You can specify configurations such as the title, description, timeline, and thumbnail for the project.
 *
 * @param request CreateEditingProjectRequest
 * @return CreateEditingProjectResponse
 */
async function createEditingProject(request: CreateEditingProjectRequest): CreateEditingProjectResponse {
  var runtime = new $RuntimeOptions{};
  return createEditingProjectWithOptions(request, runtime);
}

model CreateLivePackageChannelRequest {
  channelName?: string(name='ChannelName', description='The channel name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='channel-1'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****'),
  description?: string(name='Description', description='The channel description. It can be up to 1,000 characters in length.'),
  groupName?: string(name='GroupName', description='The channel group name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='channel-group-1'),
  protocol?: string(name='Protocol', description='The ingest protocol. Only HLS is supported.

This parameter is required.', example='HLS'),
  segmentCount?: int32(name='SegmentCount', description='The number of M3U8 segments. Valid values: 2 to 100.

This parameter is required.', example='3'),
  segmentDuration?: int32(name='SegmentDuration', description='The segment duration. Valid values: 1 to 30.

This parameter is required.', example='6'),
}

model CreateLivePackageChannelResponseBody = {
  livePackageChannel?: {
    channelName?: string(name='ChannelName', description='The channel name.', example='example-channel'),
    createTime?: string(name='CreateTime', description='The time when the channel was created. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The channel description.'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    ingestEndpoints?: [ 
      {
        id?: string(name='Id', description='The ingest endpoint ID.', example='ingest1'),
        password?: string(name='Password', description='The password.', example='2F9e******b569c8'),
        url?: string(name='Url', description='The ingest endpoint URL.', example='http://xxx-1.packagepush-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
        username?: string(name='Username', description='The username.', example='us12******das'),
      }
    ](name='IngestEndpoints', description='The ingest endpoints.'),
    lastModified?: string(name='LastModified', description='The time when the channel was last modified. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    protocol?: string(name='Protocol', description='The ingest protocol. Only HLS is supported.', example='HLS'),
    segmentCount?: int32(name='SegmentCount', description='The number of M3U8 segments.', example='3'),
    segmentDuration?: int32(name='SegmentDuration', description='The segment duration.', example='5'),
  }(name='LivePackageChannel', description='The information about the live package channel.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model CreateLivePackageChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLivePackageChannelResponseBody(name='body'),
}

/**
 * @summary Creates a live package channel.
 *
 * @description ## [](#)Usage notes
 * After you call this operation to create a live package channel, the system will automatically generate the ingest endpoint URL, and username and password required for authentication.
 * ### [](#)Precautions
 * *   Channel group names and channel names can contain only letters, digits, underscores (_), and hyphens (-).
 * *   Only `HLS` is supported.
 * *   The segment duration must be from 1 to 30 seconds.
 * *   The number of M3U8 segments must be from 2 to 100.
 * If the request succeeds, the system will return the details of the newly created channel, including the channel name, creation time, modification time, and ingest endpoint details.
 *
 * @param request CreateLivePackageChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateLivePackageChannelResponse
 */
async function createLivePackageChannelWithOptions(request: CreateLivePackageChannelRequest, runtime: $RuntimeOptions): CreateLivePackageChannelResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  var body : map[string]any = {};
  if (!$isNull(request.channelName)) {
    body['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.description)) {
    body['Description'] = request.description;
  }
  if (!$isNull(request.groupName)) {
    body['GroupName'] = request.groupName;
  }
  if (!$isNull(request.protocol)) {
    body['Protocol'] = request.protocol;
  }
  if (!$isNull(request.segmentCount)) {
    body['SegmentCount'] = request.segmentCount;
  }
  if (!$isNull(request.segmentDuration)) {
    body['SegmentDuration'] = request.segmentDuration;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateLivePackageChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a live package channel.
 *
 * @description ## [](#)Usage notes
 * After you call this operation to create a live package channel, the system will automatically generate the ingest endpoint URL, and username and password required for authentication.
 * ### [](#)Precautions
 * *   Channel group names and channel names can contain only letters, digits, underscores (_), and hyphens (-).
 * *   Only `HLS` is supported.
 * *   The segment duration must be from 1 to 30 seconds.
 * *   The number of M3U8 segments must be from 2 to 100.
 * If the request succeeds, the system will return the details of the newly created channel, including the channel name, creation time, modification time, and ingest endpoint details.
 *
 * @param request CreateLivePackageChannelRequest
 * @return CreateLivePackageChannelResponse
 */
async function createLivePackageChannel(request: CreateLivePackageChannelRequest): CreateLivePackageChannelResponse {
  var runtime = new $RuntimeOptions{};
  return createLivePackageChannelWithOptions(request, runtime);
}

model CreateLivePackageChannelGroupRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****'),
  description?: string(name='Description', description='The channel group description. It can be up to 1,000 characters in length.'),
  groupName?: string(name='GroupName', description='The channel group name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='channel-group-01'),
}

model CreateLivePackageChannelGroupResponseBody = {
  livePackageChannelGroup?: {
    createTime?: string(name='CreateTime', description='The time when the channel group was created. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The channel group description.'),
    groupName?: string(name='GroupName', description='The channel group name.', example='example-group'),
    lastModified?: string(name='LastModified', description='The time when the channel group was last modified. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    originDomain?: string(name='OriginDomain', description='The origin domain.', example='example.com'),
  }(name='LivePackageChannelGroup', description='The information about the channel group.'),
  requestId?: string(name='RequestId', description='The request ID.', example='123e4567-e89b-12d3-a456-426614174000'),
}

model CreateLivePackageChannelGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLivePackageChannelGroupResponseBody(name='body'),
}

/**
 * @summary Creates a live package channel group with a custom name and description.
 *
 * @description After you create a channel group, the assigned origin domain is returned.
 *
 * @param request CreateLivePackageChannelGroupRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateLivePackageChannelGroupResponse
 */
async function createLivePackageChannelGroupWithOptions(request: CreateLivePackageChannelGroupRequest, runtime: $RuntimeOptions): CreateLivePackageChannelGroupResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  var body : map[string]any = {};
  if (!$isNull(request.groupName)) {
    body['GroupName'] = request.groupName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateLivePackageChannelGroup',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a live package channel group with a custom name and description.
 *
 * @description After you create a channel group, the assigned origin domain is returned.
 *
 * @param request CreateLivePackageChannelGroupRequest
 * @return CreateLivePackageChannelGroupResponse
 */
async function createLivePackageChannelGroup(request: CreateLivePackageChannelGroupRequest): CreateLivePackageChannelGroupResponse {
  var runtime = new $RuntimeOptions{};
  return createLivePackageChannelGroupWithOptions(request, runtime);
}

model CreateLivePackageOriginEndpointRequest {
  authorizationCode?: string(name='AuthorizationCode', description='The authorization code. It can be up to 200 characters in length. You must configure AuthorizationCode, IpWhitelist, or both. Format: [A-Za-z0-9-_.]+', example='AbcDef123'),
  channelName?: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****0311a423d11a5f7dee713535****'),
  description?: string(name='Description', description='The endpoint description.'),
  endpointName?: string(name='EndpointName', description='The origin endpoint name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='endpoint-1'),
  groupName?: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1'),
  ipBlacklist?: string(name='IpBlacklist', description='The IP address blacklist. It supports subnet masks. 0.0.0.0/0 is not allowed. It can be up to 1,000 characters in length. Separate multiple IP addresses with commas (,).', example='103.21.222.1/32,192.168.100.0/24'),
  ipWhitelist?: string(name='IpWhitelist', description='The IP address whitelist. It supports subnet masks. 0.0.0.0/0 is not allowed. It can be up to 1,000 characters in length. Separate multiple IP addresses with commas (,). You must configure AuthorizationCode, IpWhitelist, or both.', example='192.168.1.0/24,10.0.0.1/24'),
  manifestName?: string(name='ManifestName', description='The playlist name. Default value: manifest.', example='manifest'),
  protocol?: string(name='Protocol', description='The distribution protocol.

This parameter is required.', example='HLS'),
  timeshiftVision?: int32(name='TimeshiftVision', description='The number of days that time-shifted content is available. Maximum value: 30. Default value: 0, which indicates that time shifting is not supported.', example='1'),
}

model CreateLivePackageOriginEndpointResponseBody = {
  livePackageOriginEndpoint?: {
    authorizationCode?: string(name='AuthorizationCode', description='The authorization code.', example='Abcded123'),
    channelName?: string(name='ChannelName', description='The channel name.', example='channel-1'),
    createTime?: string(name='CreateTime', description='The time when the endpoint was created.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The endpoint description.'),
    endpointName?: string(name='EndpointName', description='The endpoint name.', example='endpoint-1'),
    endpointUrl?: string(name='EndpointUrl', description='The endpoint URL.', example='https://xxx.packagepull-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    ipBlacklist?: string(name='IpBlacklist', description='The IP address blacklist.', example='103.21.222.1/32,192.168.100.0/24'),
    ipWhitelist?: string(name='IpWhitelist', description='The IP address whitelist.', example='192.168.1.0/24,10.0.0.1/24'),
    lastModified?: string(name='LastModified', description='The time when the endpoint was last modified.', example='2023-04-01T12:00:00Z'),
    manifestName?: string(name='ManifestName', description='The playlist name.', example='manifest'),
    protocol?: string(name='Protocol', description='The protocol. Only HLS is supported.', example='HLS'),
    timeshiftVision?: int32(name='TimeshiftVision', description='The number of days that time-shifted content is available. Maximum value: 30.', example='1'),
  }(name='LivePackageOriginEndpoint', description='The information about the origin endpoint.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateLivePackageOriginEndpointResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLivePackageOriginEndpointResponseBody(name='body'),
}

/**
 * @summary Creates an origin endpoint for a live package channel to deliver live streams in HLS format.
 *
 * @description ## [](#)Usage notes
 * This API operation is mainly used to configure origin settings, security policies including the IP address blacklist and whitelist and authorization code, and time shifting settings for channels. Before you create an origin endpoint, you must create a live package channel group and channel. After you create the endpoint, the endpoint URL and other configuration details are returned.
 *
 * @param request CreateLivePackageOriginEndpointRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateLivePackageOriginEndpointResponse
 */
async function createLivePackageOriginEndpointWithOptions(request: CreateLivePackageOriginEndpointRequest, runtime: $RuntimeOptions): CreateLivePackageOriginEndpointResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  var body : map[string]any = {};
  if (!$isNull(request.authorizationCode)) {
    body['AuthorizationCode'] = request.authorizationCode;
  }
  if (!$isNull(request.channelName)) {
    body['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.description)) {
    body['Description'] = request.description;
  }
  if (!$isNull(request.endpointName)) {
    body['EndpointName'] = request.endpointName;
  }
  if (!$isNull(request.groupName)) {
    body['GroupName'] = request.groupName;
  }
  if (!$isNull(request.ipBlacklist)) {
    body['IpBlacklist'] = request.ipBlacklist;
  }
  if (!$isNull(request.ipWhitelist)) {
    body['IpWhitelist'] = request.ipWhitelist;
  }
  if (!$isNull(request.manifestName)) {
    body['ManifestName'] = request.manifestName;
  }
  if (!$isNull(request.protocol)) {
    body['Protocol'] = request.protocol;
  }
  if (!$isNull(request.timeshiftVision)) {
    body['TimeshiftVision'] = request.timeshiftVision;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateLivePackageOriginEndpoint',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates an origin endpoint for a live package channel to deliver live streams in HLS format.
 *
 * @description ## [](#)Usage notes
 * This API operation is mainly used to configure origin settings, security policies including the IP address blacklist and whitelist and authorization code, and time shifting settings for channels. Before you create an origin endpoint, you must create a live package channel group and channel. After you create the endpoint, the endpoint URL and other configuration details are returned.
 *
 * @param request CreateLivePackageOriginEndpointRequest
 * @return CreateLivePackageOriginEndpointResponse
 */
async function createLivePackageOriginEndpoint(request: CreateLivePackageOriginEndpointRequest): CreateLivePackageOriginEndpointResponse {
  var runtime = new $RuntimeOptions{};
  return createLivePackageOriginEndpointWithOptions(request, runtime);
}

model CreateLiveRecordTemplateRequest {
  name?: string(name='Name', description='The name of the template.

This parameter is required.'),
  recordFormat?: [ 
    {
      cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds. If you do not specify this parameter, the default value 6 hours is used.

> 

*   If a live stream is interrupted during a recording cycle but is resumed within 3 minutes, the stream is recorded in the same recording before and after the interruption.

*   If a live stream is interrupted for more than 3 minutes, a new recording is generated. To change the default stream interruption time, submit a ticket.', example='3600'),
      format?: string(name='Format', description='The format.

>  If you set this parameter to m3u8, you must also specify the SliceOssObjectPrefix and SliceDuration parameters.

This parameter is required.', example='m3u8'),
      ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording file that is stored in Object Storage Service (OSS).

*   The name must be less than 256 bytes in length and can contain the {JobId}, {Sequence}, {StartTime}, {EndTime}, {EscapedStartTime}, and {EscapedEndTime} variables.
*   The name must contain the {StartTime} and {EndTime} variables or the {EscapedStartTime} and {EscapedEndTime} variables.', example='record/{JobId}/{Sequence}_{EscapedStartTime}_{EscapedEndTime}'),
      sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds.

>  This parameter takes effect only if you set Format to m3u8.

If you do not specify this parameter, the default value 30 seconds is used. Valid values: 5 to 30.', example='30'),
      sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.

>  This parameter is required only if you set Format to m3u8.

*   By default, the duration of a segment is 30 seconds. The segment name must be less than 256 bytes in length and can contain the {JobId}, {UnixTimestamp}, and {Sequence} variables.
*   The segment name must contain the {UnixTimestamp} and {Sequence} variables.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
    }
  ](name='RecordFormat', description='The list of recording formats.

This parameter is required.'),
}

model CreateLiveRecordTemplateShrinkRequest {
  name?: string(name='Name', description='The name of the template.

This parameter is required.'),
  recordFormatShrink?: string(name='RecordFormat', description='The list of recording formats.

This parameter is required.'),
}

model CreateLiveRecordTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
}

model CreateLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLiveRecordTemplateResponseBody(name='body'),
}

/**
 * @summary Creates a live stream recording template to submit live stream recording jobs.
 *
 * @description You must specify a recording template for live stream recording. You can configure information such as the format and duration of a recording in a recording template. The recording format can be M3U8, MP4, or FLV.
 *
 * @param tmpReq CreateLiveRecordTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateLiveRecordTemplateResponse
 */
async function createLiveRecordTemplateWithOptions(tmpReq: CreateLiveRecordTemplateRequest, runtime: $RuntimeOptions): CreateLiveRecordTemplateResponse {
  tmpReq.validate();
  var request = new CreateLiveRecordTemplateShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.recordFormat)) {
    request.recordFormatShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.recordFormat, 'RecordFormat', 'json');
  }
  var body : map[string]any = {};
  if (!$isNull(request.name)) {
    body['Name'] = request.name;
  }
  if (!$isNull(request.recordFormatShrink)) {
    body['RecordFormat'] = request.recordFormatShrink;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateLiveRecordTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a live stream recording template to submit live stream recording jobs.
 *
 * @description You must specify a recording template for live stream recording. You can configure information such as the format and duration of a recording in a recording template. The recording format can be M3U8, MP4, or FLV.
 *
 * @param request CreateLiveRecordTemplateRequest
 * @return CreateLiveRecordTemplateResponse
 */
async function createLiveRecordTemplate(request: CreateLiveRecordTemplateRequest): CreateLiveRecordTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return createLiveRecordTemplateWithOptions(request, runtime);
}

model CreateLiveSnapshotTemplateRequest {
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   It cannot exceed 255 characters in length.
*   The {JobId} placeholder is supported. It specifies the ID of the snapshot job.
*   Placeholders such as {UnixTimestamp}, {Sequence}, and {Date} are not allowed.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}.jpg'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   It cannot exceed 255 characters in length.
*   The {JobId}, {Date}, {UnixTimestamp}, and {Sequence} placeholders are supported. {JobId} specifies the ID of the snapshot job. {Date} specifies the date on which the snapshot is captured. {UnixTimestamp} specifies the timestamp of the snapshot. {Sequence} specifies the sequence number of the snapshot. You must specify at least one of the {UnixTimestamp} and {Sequence} placeholders.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}/{UnixTimestamp}.jpg'),
  templateName?: string(name='TemplateName', description='The name of the template.

*   It cannot exceed 128 characters in length.

This parameter is required.'),
  timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.

*   Valid values: [5,3600].

This parameter is required.', example='5'),
}

model CreateLiveSnapshotTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287782****'),
}

model CreateLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLiveSnapshotTemplateResponseBody(name='body'),
}

/**
 * @summary Create a live stream snapshot template to facilitate the creation of snapshot jobs.
 *
 * @param request CreateLiveSnapshotTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateLiveSnapshotTemplateResponse
 */
async function createLiveSnapshotTemplateWithOptions(request: CreateLiveSnapshotTemplateRequest, runtime: $RuntimeOptions): CreateLiveSnapshotTemplateResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.overwriteFormat)) {
    body['OverwriteFormat'] = request.overwriteFormat;
  }
  if (!$isNull(request.sequenceFormat)) {
    body['SequenceFormat'] = request.sequenceFormat;
  }
  if (!$isNull(request.templateName)) {
    body['TemplateName'] = request.templateName;
  }
  if (!$isNull(request.timeInterval)) {
    body['TimeInterval'] = request.timeInterval;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateLiveSnapshotTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Create a live stream snapshot template to facilitate the creation of snapshot jobs.
 *
 * @param request CreateLiveSnapshotTemplateRequest
 * @return CreateLiveSnapshotTemplateResponse
 */
async function createLiveSnapshotTemplate(request: CreateLiveSnapshotTemplateRequest): CreateLiveSnapshotTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return createLiveSnapshotTemplateWithOptions(request, runtime);
}

model CreateLiveTranscodeTemplateRequest {
  name?: string(name='Name', description='The name of the template.

This parameter is required.', example='my template'),
  templateConfig?: {
    audioParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output audio. Unit: Kbit/s. Valid values: 1 to 1000.', example='100'),
      channels?: string(name='Channels', description='The number of sound channels. Valid values: 1: mono 2: binaural', example='2'),
      codec?: string(name='Codec', description='The audio codec. Valid values:

*   AAC
*   MP3', example='AAC'),
      profile?: string(name='Profile', description='The audio codec profile. Valid values when the Codec parameter is set to AAC:

*   aac_low
*   aac_he
*   aac_he_v2
*   aac_ld', example='aaclow'),
      samplerate?: string(name='Samplerate', description='The audio sampling rate. Valid values: 22050 to 96000.

Note: If you set AudioProfile to aac_ld, the audio sampling rate cannot exceed 44,100.', example='44100'),
    }(name='AudioParams', description='The audio parameters.'),
    videoParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output video. Unit: Kbit/s. Valid values: 1 to 6000.', example='2500'),
      codec?: string(name='Codec', description='The encoding type. Valid values:

*   H.264
*   H.265', example='H.264'),
      fps?: string(name='Fps', description='The frame rate of the output video. Unit: frames per second (FPS). Valid values: 1 to 60.', example='25'),
      gop?: string(name='Gop', description='The group of pictures (GOP) of the output video. Unit: frame. Valid values: 1 to 3000.', example='1000'),
      height?: string(name='Height', description='The height of the output video. Valid values: Height ≥ 128 max (Height,Width) ≤ 2560 min (Height,Width) ≤ 1440

Note: The resolution of the output video that is transcoded by using the H.265 Narrowband HD transcoding template cannot exceed 1280 × 720 pixels.', example='720'),
      profile?: string(name='Profile', description='The encoding profile. The profile determines how a video is encoded. In most cases, a greater value indicates better image quality and higher resource consumption. Valid values: 1: baseline. This value is suitable for mobile devices. 2: main. This value is suitable for standard-definition devices. 3: high. This value is suitable for high-definition devices.', example='2'),
      width?: string(name='Width', description='The width of the output video. Valid values: Width ≥ 128 max (Height,Width) ≤ 2560 min (Height,Width) ≤ 1440

Note: The resolution of the output video that is transcoded by using the H.265 Narrowband HD transcoding template cannot exceed 1280 × 720 pixels.', example='1280'),
    }(name='VideoParams', description='The video parameters.'),
  }(name='TemplateConfig', description='The configuration of the template.'),
  type?: string(name='Type', description='The type of the template. Valid values:

*   normal
*   narrow-band
*   audio-only
*   origin

This parameter is required.', example='normal'),
}

model CreateLiveTranscodeTemplateShrinkRequest {
  name?: string(name='Name', description='The name of the template.

This parameter is required.', example='my template'),
  templateConfigShrink?: string(name='TemplateConfig', description='The configuration of the template.'),
  type?: string(name='Type', description='The type of the template. Valid values:

*   normal
*   narrow-band
*   audio-only
*   origin

This parameter is required.', example='normal'),
}

model CreateLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  templateId?: string(name='TemplateId', description='The ID of the template.', example='****20b48fb04483915d4f2cd8ac****'),
}

model CreateLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLiveTranscodeTemplateResponseBody(name='body'),
}

/**
 * @summary Creates a live stream transcoding template to submit live stream transcoding jobs.
 *
 * @param tmpReq CreateLiveTranscodeTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateLiveTranscodeTemplateResponse
 */
async function createLiveTranscodeTemplateWithOptions(tmpReq: CreateLiveTranscodeTemplateRequest, runtime: $RuntimeOptions): CreateLiveTranscodeTemplateResponse {
  tmpReq.validate();
  var request = new CreateLiveTranscodeTemplateShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateLiveTranscodeTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a live stream transcoding template to submit live stream transcoding jobs.
 *
 * @param request CreateLiveTranscodeTemplateRequest
 * @return CreateLiveTranscodeTemplateResponse
 */
async function createLiveTranscodeTemplate(request: CreateLiveTranscodeTemplateRequest): CreateLiveTranscodeTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return createLiveTranscodeTemplateWithOptions(request, runtime);
}

model CreateMediaConnectFlowRequest {
  flowName?: string(name='FlowName', description='The flow name.

This parameter is required.', example='AliTestFlow'),
  flowRegion?: string(name='FlowRegion', description='The region in which the flow resides.

This parameter is required.', example='ap-southeast-1'),
}

model CreateMediaConnectFlowResponseBody = {
  content?: {
    flowId?: string(name='FlowId', description='The flow ID.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f'),
  }(name='Content', description='The response body.'),
  description?: string(name='Description', description='The returned message.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='86D92F9D-65E8-58A2-85D1-9DEEECC172E8'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model CreateMediaConnectFlowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateMediaConnectFlowResponseBody(name='body'),
}

/**
 * @summary Creates a MediaConnect flow.
 *
 * @description *   The flow names cannot be duplicated in the same region.
 * *   Take note of the returned flow ID. You may reference it in other API operations.
 *
 * @param request CreateMediaConnectFlowRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateMediaConnectFlowResponse
 */
async function createMediaConnectFlowWithOptions(request: CreateMediaConnectFlowRequest, runtime: $RuntimeOptions): CreateMediaConnectFlowResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.flowName)) {
    query['FlowName'] = request.flowName;
  }
  if (!$isNull(request.flowRegion)) {
    query['FlowRegion'] = request.flowRegion;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateMediaConnectFlow',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a MediaConnect flow.
 *
 * @description *   The flow names cannot be duplicated in the same region.
 * *   Take note of the returned flow ID. You may reference it in other API operations.
 *
 * @param request CreateMediaConnectFlowRequest
 * @return CreateMediaConnectFlowResponse
 */
async function createMediaConnectFlow(request: CreateMediaConnectFlowRequest): CreateMediaConnectFlowResponse {
  var runtime = new $RuntimeOptions{};
  return createMediaConnectFlowWithOptions(request, runtime);
}

model CreateMediaLiveChannelRequest {
  audioSettings?: [ 
    {
      audioCodec?: string(name='AudioCodec', description='The audio codec. If it is not specified, the source specification is used. Valid values: aac and libfdk_aac.', example='libfdk_aac'),
      audioCodecSetting?: {
        bitrate?: int32(name='Bitrate', description='The audio bitrate. Unit: bit/s. Valid values: 8000 to 1000000. The value must be divisible by 1000.', example='200000'),
        profile?: string(name='Profile', description='The audio codec profile. When AudioCodec is set to aac, AAC-LOW and AAC-MAIN are supported. When AudioCodec is set to libfdk_aac, AAC-LOW, AAC-HE, and AAC-HEV2 are supported.', example='AAC-LOW'),
        sampleRate?: int32(name='SampleRate', description='The audio sample rate. Unit: Hz. Valid values: 22050, 32000, 44100, 48000, and 96000.', example='44100'),
      }(name='AudioCodecSetting', description='The audio encoding settings.'),
      audioSelectorName?: string(name='AudioSelectorName', description='The name of the audio selector.', example='a1'),
      languageCode?: string(name='LanguageCode', description='Enter a three-letter ISO 639-2 language code. If the audio track selected by the audio selector has a language code, the language code specified in the audio selector is used. If the selected audio track does not have a language code, or if the audio selector cannot find a track that matches its criteria, this language code is used.', example='eng'),
      languageName?: string(name='LanguageName', description='The tag that identifies the language of the RTMP input. It can be referenced by the output. The maximum length is 32 characters. Supported characters:

*   Unicode letters
*   Digits (0-9)
*   Underscore (_)
*   Hyphen (-)
*   Space (a space cannot be at the beginning or end)', example='English'),
      name?: string(name='Name', description='The name of the audio settings. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='audio1'),
    }
  ](name='AudioSettings', description='The audio settings.'),
  inputAttachments?: [ 
    {
      audioSelectors?: [ 
        {
          audioLanguageSelection?: {
            languageCode?: string(name='LanguageCode', description='Enter a three-letter ISO 639-2 language code from within an audio source.

This parameter is required.', example='eng'),
          }(name='AudioLanguageSelection', description='The audio language selection.'),
          audioPidSelection?: {
            pid?: long(name='Pid', description='Enter a specific PID from within a source.

This parameter is required.', example='123'),
          }(name='AudioPidSelection', description='The audio PID selection.'),
          audioTrackSelection?: [ 
            {
              trackId?: long(name='TrackId', description='Specify one or more audio tracks from within a source using Track ID.

This parameter is required.', example='1'),
            }
          ](name='AudioTrackSelection', description='The audio track selection.'),
          name?: string(name='Name', description='The name of the audio selector. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='myselector'),
        }
      ](name='AudioSelectors', description='The audio selectors.'),
      inputId?: string(name='InputId', description='The ID of the associated input.

This parameter is required.', example='myinput'),
      languageName?: string(name='LanguageName', description='The tag that identifies the language of the RTMP input. It can be referenced by the output. The maximum length is 32 characters. Supported characters:

*   Unicode letters
*   Digits (0-9)
*   Underscore (_)
*   Hyphen (-)
*   Space (a space cannot be at the beginning or end)', example='English'),
    }
  ](name='InputAttachments', description='The associated inputs.

This parameter is required.'),
  name?: string(name='Name', description='The name of the channel. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='mych'),
  outputGroups?: [ 
    {
      mediaPackageGroupSetting?: {
        channelName?: string(name='ChannelName', description='ChannelName in MediaPackage.

This parameter is required.', example='myPackageChannel'),
        groupName?: string(name='GroupName', description='GroupName in MediaPackage.

This parameter is required.', example='myPackageGroup'),
      }(name='MediaPackageGroupSetting', description='The MediaPackage destination.'),
      name?: string(name='Name', description='The name of the output group. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='group1'),
      outputs?: [ 
        {
          audioSettingNames?: [ string ](name='AudioSettingNames', description='The referenced AudioSettings.'),
          mediaPackageOutputSetting?: {
            audioGroupId?: string(name='AudioGroupId', description='The manifest audio group ID. To associate several audio tracks into one group, assign the same audio group ID. Viewers can select a track as needed. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 40 characters in length.', example='audiogroup'),
            nameModifier?: string(name='NameModifier', description='The manifest name modifier. The child manifests include this modifier in their M3U8 file names. Letters, digits, hyphens (-), and underscores (_) are supported. The maximum length is 40 characters.', example='480p'),
          }(name='MediaPackageOutputSetting', description='The settings of the output delivered to MediaPackage.'),
          mediaType?: int32(name='MediaType', description='The media type of the output. Valid values:

*   0: Audio and Video.
*   1: Audio. If you set the value to 1, you cannot reference VideoSettings.
*   2: Video. If you set the value to 2, you cannot reference AudioSettings.', example='0'),
          name?: string(name='Name', description='The name of the output. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='output1'),
          videoSettingName?: string(name='VideoSettingName', description='The name of the referenced VideoSettings.', example='myVideo1'),
        }
      ](name='Outputs', description='The outputs in the output group.

This parameter is required.'),
      type?: string(name='Type', description='The output group type. Only MediaPackage is supported.

This parameter is required.', example='MediaPackage'),
    }
  ](name='OutputGroups', description='The output groups.

This parameter is required.'),
  videoSettings?: [ 
    {
      height?: int32(name='Height', description='The height of the output. Valid values: 0 to 2000. If you set it to 0 or leave it empty, the height automatically adapts to the specified width to maintain the original aspect ratio.', example='720'),
      name?: string(name='Name', description='The name of the video settings. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='video1'),
      videoCodec?: string(name='VideoCodec', description='The video codec. Valid values: H264 and H265.', example='H264'),
      videoCodecSetting?: {
        codecDetail?: {
          level?: string(name='Level', description='The video encoding level. It is not supported yet.', example='H264_LEVEL_AUTO'),
          profile?: string(name='Profile', description='The H.264 profile. Valid values: BASELINE, HIGH, and MAIN. Default value: MAIN. The parameter takes effect only when the codec is H.264.', example='MAIN'),
        }(name='CodecDetail', description='The video encoding settings.'),
        framerate?: {
          framerateControl?: string(name='FramerateControl', description='The frame rate mode. Valid values: SPECIFIED (fixed frame rate) and FROM_SOURCE (use source specification).', example='SPECIFIED'),
          framerateDenominator?: int32(name='FramerateDenominator', description='The denominator of the fixed frame rate. The parameter is required when FramerateControl is set to SPECIFIED. Valid values: 1 to 60. The numerator must be divisible by the denominator.', example='1'),
          framerateNumerator?: int32(name='FramerateNumerator', description='The numerator of the fixed frame rate. The parameter is required when FramerateControl is set to SPECIFIED. Valid values: 1 to 60. The numerator must be divisible by the denominator.', example='25'),
        }(name='Framerate', description='The frame rate. If it is not specified, the source specification is used.'),
        gop?: {
          bframesNum?: int32(name='BframesNum', description='The number of B frames. Valid values: 1 to 3.', example='3'),
          gopSize?: int32(name='GopSize', description='The GOP size. When GopSizeUnits is set to SECONDS, the value range is from 1 to 20. When GopSizeUnits is set to FRAMES, the value range is from 1 to 3000.', example='90'),
          gopSizeUnits?: string(name='GopSizeUnits', description='The GOP size unit. Valid values: FRAMES and SECONDS.', example='FRAMES'),
        }(name='Gop', description='The GOP setting. If it is not specified, the source specification is used.'),
        rate?: {
          bitrate?: int32(name='Bitrate', description='The video bitrate. Unit: bit/s. If you set it to 0 or leave it empty, the source specification is used. Valid values: 50000 to 6000000. The value must be divisible by 1000.', example='2500000'),
          bufferSize?: int32(name='BufferSize', description='The video buffer size. Unit: bit/s. Valid values: 100000 to 6000000. The value must be divisible by 1000.', example='6000000'),
          maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s. Valid values: 100000 to 6000000. The value must be divisible by 1000.', example='6000000'),
          rateControlMode?: string(name='RateControlMode', description='The bitrate control mode. Valid values: CBR, ABR, and VBR.', example='ABR'),
        }(name='Rate', description='The video encoding rate. If it is not specified, the source specification is used.'),
      }(name='VideoCodecSetting', description='The video encoding settings.'),
      width?: int32(name='Width', description='The width of the output. Valid values: 0 to 2000. If you set it to 0 or leave it empty, the width automatically adapts to the specified height to maintain the original aspect ratio.', example='1280'),
    }
  ](name='VideoSettings', description='The video settings.'),
}

model CreateMediaLiveChannelShrinkRequest {
  audioSettingsShrink?: string(name='AudioSettings', description='The audio settings.'),
  inputAttachmentsShrink?: string(name='InputAttachments', description='The associated inputs.

This parameter is required.'),
  name?: string(name='Name', description='The name of the channel. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='mych'),
  outputGroupsShrink?: string(name='OutputGroups', description='The output groups.

This parameter is required.'),
  videoSettingsShrink?: string(name='VideoSettings', description='The video settings.'),
}

model CreateMediaLiveChannelResponseBody = {
  channelId?: string(name='ChannelId', description='The ID of the channel.', example='SEGK5KA6KYKAWQQH'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateMediaLiveChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateMediaLiveChannelResponseBody(name='body'),
}

/**
 * @summary Creates a MediaLive channel.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param tmpReq CreateMediaLiveChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateMediaLiveChannelResponse
 */
async function createMediaLiveChannelWithOptions(tmpReq: CreateMediaLiveChannelRequest, runtime: $RuntimeOptions): CreateMediaLiveChannelResponse {
  tmpReq.validate();
  var request = new CreateMediaLiveChannelShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.audioSettings)) {
    request.audioSettingsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.audioSettings, 'AudioSettings', 'json');
  }
  if (!$isNull(tmpReq.inputAttachments)) {
    request.inputAttachmentsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.inputAttachments, 'InputAttachments', 'json');
  }
  if (!$isNull(tmpReq.outputGroups)) {
    request.outputGroupsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.outputGroups, 'OutputGroups', 'json');
  }
  if (!$isNull(tmpReq.videoSettings)) {
    request.videoSettingsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.videoSettings, 'VideoSettings', 'json');
  }
  var body : map[string]any = {};
  if (!$isNull(request.audioSettingsShrink)) {
    body['AudioSettings'] = request.audioSettingsShrink;
  }
  if (!$isNull(request.inputAttachmentsShrink)) {
    body['InputAttachments'] = request.inputAttachmentsShrink;
  }
  if (!$isNull(request.name)) {
    body['Name'] = request.name;
  }
  if (!$isNull(request.outputGroupsShrink)) {
    body['OutputGroups'] = request.outputGroupsShrink;
  }
  if (!$isNull(request.videoSettingsShrink)) {
    body['VideoSettings'] = request.videoSettingsShrink;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateMediaLiveChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a MediaLive channel.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request CreateMediaLiveChannelRequest
 * @return CreateMediaLiveChannelResponse
 */
async function createMediaLiveChannel(request: CreateMediaLiveChannelRequest): CreateMediaLiveChannelResponse {
  var runtime = new $RuntimeOptions{};
  return createMediaLiveChannelWithOptions(request, runtime);
}

model CreateMediaLiveInputRequest {
  inputSettings?: [ 
    {
      flowId?: string(name='FlowId'),
      flowOutputName?: string(name='FlowOutputName'),
      sourceUrl?: string(name='SourceUrl', description='The source URL where the stream is pulled from. This parameter is required for PULL inputs.', example='rtmp://domain/app/stream'),
      streamName?: string(name='StreamName', description='The name of the pushed stream. This parameter is required for PUSH inputs. It can be up to 255 characters in length.', example='mystream'),
    }
  ](name='InputSettings', description='The input settings. An input can have up to two sources: primary and backup sources.

This parameter is required.'),
  name?: string(name='Name', description='The name of the input. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='myinput'),
  securityGroupIds?: [ string ](name='SecurityGroupIds', description='The IDs of the security groups to be associated with the input. This parameter is required for PUSH inputs.', example='["G6G4X5T4SZYPSTT5"]'),
  type?: string(name='Type', description='The input type. Valid values: RTMP_PUSH, RTMP_PULL, SRT_PUSH, and SRT_PULL.

This parameter is required.', example='RTMP_PUSH'),
}

model CreateMediaLiveInputShrinkRequest {
  inputSettingsShrink?: string(name='InputSettings', description='The input settings. An input can have up to two sources: primary and backup sources.

This parameter is required.'),
  name?: string(name='Name', description='The name of the input. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='myinput'),
  securityGroupIdsShrink?: string(name='SecurityGroupIds', description='The IDs of the security groups to be associated with the input. This parameter is required for PUSH inputs.', example='["G6G4X5T4SZYPSTT5"]'),
  type?: string(name='Type', description='The input type. Valid values: RTMP_PUSH, RTMP_PULL, SRT_PUSH, and SRT_PULL.

This parameter is required.', example='RTMP_PUSH'),
}

model CreateMediaLiveInputResponseBody = {
  inputId?: string(name='InputId', description='The ID of the input.', example='SEGK5KA6KYKAWQQH'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateMediaLiveInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateMediaLiveInputResponseBody(name='body'),
}

/**
 * @summary Creates a MediaLive input.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param tmpReq CreateMediaLiveInputRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateMediaLiveInputResponse
 */
async function createMediaLiveInputWithOptions(tmpReq: CreateMediaLiveInputRequest, runtime: $RuntimeOptions): CreateMediaLiveInputResponse {
  tmpReq.validate();
  var request = new CreateMediaLiveInputShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.inputSettings)) {
    request.inputSettingsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.inputSettings, 'InputSettings', 'json');
  }
  if (!$isNull(tmpReq.securityGroupIds)) {
    request.securityGroupIdsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.securityGroupIds, 'SecurityGroupIds', 'json');
  }
  var body : map[string]any = {};
  if (!$isNull(request.inputSettingsShrink)) {
    body['InputSettings'] = request.inputSettingsShrink;
  }
  if (!$isNull(request.name)) {
    body['Name'] = request.name;
  }
  if (!$isNull(request.securityGroupIdsShrink)) {
    body['SecurityGroupIds'] = request.securityGroupIdsShrink;
  }
  if (!$isNull(request.type)) {
    body['Type'] = request.type;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateMediaLiveInput',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a MediaLive input.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request CreateMediaLiveInputRequest
 * @return CreateMediaLiveInputResponse
 */
async function createMediaLiveInput(request: CreateMediaLiveInputRequest): CreateMediaLiveInputResponse {
  var runtime = new $RuntimeOptions{};
  return createMediaLiveInputWithOptions(request, runtime);
}

model CreateMediaLiveInputSecurityGroupRequest {
  name?: string(name='Name', description='The name of the security group. Letters, digits, hyphens (-), and underscores (_) are supported. The maximum length is 64 characters.

This parameter is required.', example='mysg'),
  whitelistRules?: [ string ](name='WhitelistRules', description='The security group rules.

This parameter is required.', example='["10.1.1.0/24", "11.11.11.11/0"]'),
}

model CreateMediaLiveInputSecurityGroupShrinkRequest {
  name?: string(name='Name', description='The name of the security group. Letters, digits, hyphens (-), and underscores (_) are supported. The maximum length is 64 characters.

This parameter is required.', example='mysg'),
  whitelistRulesShrink?: string(name='WhitelistRules', description='The security group rules.

This parameter is required.', example='["10.1.1.0/24", "11.11.11.11/0"]'),
}

model CreateMediaLiveInputSecurityGroupResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  securityGroupId?: string(name='SecurityGroupId', description='The ID of the security group.', example='SEGK5KA6KYKAWQQH'),
}

model CreateMediaLiveInputSecurityGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateMediaLiveInputSecurityGroupResponseBody(name='body'),
}

/**
 * @summary Creates a security group in MediaLive.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param tmpReq CreateMediaLiveInputSecurityGroupRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateMediaLiveInputSecurityGroupResponse
 */
async function createMediaLiveInputSecurityGroupWithOptions(tmpReq: CreateMediaLiveInputSecurityGroupRequest, runtime: $RuntimeOptions): CreateMediaLiveInputSecurityGroupResponse {
  tmpReq.validate();
  var request = new CreateMediaLiveInputSecurityGroupShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.whitelistRules)) {
    request.whitelistRulesShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.whitelistRules, 'WhitelistRules', 'json');
  }
  var body : map[string]any = {};
  if (!$isNull(request.name)) {
    body['Name'] = request.name;
  }
  if (!$isNull(request.whitelistRulesShrink)) {
    body['WhitelistRules'] = request.whitelistRulesShrink;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateMediaLiveInputSecurityGroup',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a security group in MediaLive.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request CreateMediaLiveInputSecurityGroupRequest
 * @return CreateMediaLiveInputSecurityGroupResponse
 */
async function createMediaLiveInputSecurityGroup(request: CreateMediaLiveInputSecurityGroupRequest): CreateMediaLiveInputSecurityGroupResponse {
  var runtime = new $RuntimeOptions{};
  return createMediaLiveInputSecurityGroupWithOptions(request, runtime);
}

model CreatePipelineRequest {
  name?: string(name='Name', description='The name of the MPS queue.

This parameter is required.', example='test-pipeline'),
  priority?: int32(name='Priority', description='The priority. Default value: 6. Valid values: 1 to 10. A greater value specifies a higher priority.', example='6'),
  speed?: string(name='Speed', description='The type of the MPS queue. Valid values:

1.  Standard: standard MPS queue.
2.  Boost: MPS queue with transcoding speed boosted.
3.  NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.

This parameter is required.', example='Standard'),
}

model CreatePipelineResponseBody = {
  pipeline?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
    name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.', example='****20b48fb04483915d4f2cd8ac****'),
    priority?: int32(name='Priority', description='The priority of the MPS queue.', example='6'),
    speed?: string(name='Speed', description='The type of the MPS queue.

Valid values:

*   Boost: MPS queue with transcoding speed boosted.
*   Standard: standard MPS queue.
*   NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.', example='Standard'),
    status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Active'),
  }(name='Pipeline', description='The information about the MPS queue.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreatePipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreatePipelineResponseBody(name='body'),
}

/**
 * @summary Creates an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request CreatePipelineRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreatePipelineResponse
 */
async function createPipelineWithOptions(request: CreatePipelineRequest, runtime: $RuntimeOptions): CreatePipelineResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.priority)) {
    query['Priority'] = request.priority;
  }
  if (!$isNull(request.speed)) {
    query['Speed'] = request.speed;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreatePipeline',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request CreatePipelineRequest
 * @return CreatePipelineResponse
 */
async function createPipeline(request: CreatePipelineRequest): CreatePipelineResponse {
  var runtime = new $RuntimeOptions{};
  return createPipelineWithOptions(request, runtime);
}

model CreateProgramRequest {
  adBreaks?: string(name='AdBreaks', description='The information about ad breaks.', example='[{"MessageType":"SPLICE_INSERT","OffsetMillis":1000,"SourceLocationName":"MySourceLocation","SourceName":"MyAdSource","SpliceInsertSettings":{"AvailNumber":0,"AvailExpected":0,"SpliceEventID":1,"UniqueProgramID":0}}]'),
  channelName?: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel'),
  clipRange?: string(name='ClipRange', description='Extracts a clip from the source.', example='{StartOffsetMillis: 213123, EndOffsetMillis: 213134}'),
  programName?: string(name='ProgramName', description='The name of the program.

This parameter is required.', example='program1'),
  sourceLocationName?: string(name='SourceLocationName', description='The source location.

This parameter is required.', example='MySourceLcation'),
  sourceName?: string(name='SourceName', description='The name of the source.

This parameter is required.', example='MySource'),
  sourceType?: string(name='SourceType', description='The source type of the program.

This parameter is required.', example='vodSource'),
  transition?: string(name='Transition', description='The program transition method.

This parameter is required.', example='{"Type": "RELATIVE", "RelativePosition": "AFTER_PROGRAM", "RelativeProgram": "program2"}'),
}

model CreateProgramResponseBody = {
  program?: ChannelAssemblyProgram(name='Program', description='The information about the program.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
}

model CreateProgramResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateProgramResponseBody(name='body'),
}

/**
 * @summary Creates a program in a MediaWeaver channel.
 *
 * @param request CreateProgramRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateProgramResponse
 */
async function createProgramWithOptions(request: CreateProgramRequest, runtime: $RuntimeOptions): CreateProgramResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.adBreaks)) {
    query['AdBreaks'] = request.adBreaks;
  }
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.clipRange)) {
    query['ClipRange'] = request.clipRange;
  }
  if (!$isNull(request.programName)) {
    query['ProgramName'] = request.programName;
  }
  if (!$isNull(request.sourceLocationName)) {
    query['SourceLocationName'] = request.sourceLocationName;
  }
  if (!$isNull(request.sourceName)) {
    query['SourceName'] = request.sourceName;
  }
  if (!$isNull(request.sourceType)) {
    query['SourceType'] = request.sourceType;
  }
  if (!$isNull(request.transition)) {
    query['Transition'] = request.transition;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateProgram',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a program in a MediaWeaver channel.
 *
 * @param request CreateProgramRequest
 * @return CreateProgramResponse
 */
async function createProgram(request: CreateProgramRequest): CreateProgramResponse {
  var runtime = new $RuntimeOptions{};
  return createProgramWithOptions(request, runtime);
}

model CreateSearchIndexRequest {
  indexConfig?: string(name='IndexConfig', example='{}'),
  indexStatus?: string(name='IndexStatus', example='Active'),
  indexType?: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model. You can use this model to describe complex visual features and identify and search for specific actions, movements, and events in videos, such as when athletes score a goal or get injured.

>  This feature is in the public preview phase. You can use this feature for free for 1,000 hours of videos.

*   face: face recognition. You can use the face recognition technology to describe face characteristics and automatically mark or search for faces in videos.
*   aiLabel: smart tagging. The smart tagging category is used to describe content such as subtitles and audio in videos. You can use the speech recognition technology to automatically extract, mark, and search for subtitles and dialog content from videos. This helps you quickly locate the video content that is related to specific topics or keywords.

This parameter is required.', example='mm'),
  searchLibName?: string(name='SearchLibName', example='test1'),
}

model CreateSearchIndexResponseBody = {
  code?: string(name='Code', example='200'),
  requestId?: string(name='RequestId', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  success?: string(name='Success', example='true'),
}

model CreateSearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSearchIndexResponseBody(name='body'),
}

/**
 * @summary 创建搜索索引
 *
 * @description The large visual model feature is still in the public preview phase. You can use this feature for free for 1,000 hours of videos.
 *
 * @param request CreateSearchIndexRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateSearchIndexResponse
 */
async function createSearchIndexWithOptions(request: CreateSearchIndexRequest, runtime: $RuntimeOptions): CreateSearchIndexResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.indexConfig)) {
    query['IndexConfig'] = request.indexConfig;
  }
  if (!$isNull(request.indexStatus)) {
    query['IndexStatus'] = request.indexStatus;
  }
  if (!$isNull(request.indexType)) {
    query['IndexType'] = request.indexType;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateSearchIndex',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 创建搜索索引
 *
 * @description The large visual model feature is still in the public preview phase. You can use this feature for free for 1,000 hours of videos.
 *
 * @param request CreateSearchIndexRequest
 * @return CreateSearchIndexResponse
 */
async function createSearchIndex(request: CreateSearchIndexRequest): CreateSearchIndexResponse {
  var runtime = new $RuntimeOptions{};
  return createSearchIndexWithOptions(request, runtime);
}

model CreateSearchLibRequest {
  searchLibName?: string(name='SearchLibName', description='The name of the search library. The name can contain letters and digits and must start with a letter.

This parameter is required.', example='test1'),
}

model CreateSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model CreateSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSearchLibResponseBody(name='body'),
}

/**
 * @summary Creates a search library to store media assets.
 *
 * @param request CreateSearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateSearchLibResponse
 */
async function createSearchLibWithOptions(request: CreateSearchLibRequest, runtime: $RuntimeOptions): CreateSearchLibResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateSearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a search library to store media assets.
 *
 * @param request CreateSearchLibRequest
 * @return CreateSearchLibResponse
 */
async function createSearchLib(request: CreateSearchLibRequest): CreateSearchLibResponse {
  var runtime = new $RuntimeOptions{};
  return createSearchLibWithOptions(request, runtime);
}

model CreateSourceRequest {
  httpPackageConfigurations?: string(name='HttpPackageConfigurations', description='The source configurations.

This parameter is required.', example='“[{
	"sourceGroupName": "mySourceGroup-1",
	"relativePath": "group1/hls.m3u8",
	"type": "hls"
}]”'),
  sourceLocationName?: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourceLocation'),
  sourceName?: string(name='SourceName', description='The name of the source.

This parameter is required.', example='MyVodSource'),
  sourceType?: string(name='SourceType', description='The source type. Valid values: vodSource and liveSource.

This parameter is required.', example='vodSource'),
}

model CreateSourceResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  source?: ChannelAssemblySource(name='Source', description='The source information.'),
}

model CreateSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSourceResponseBody(name='body'),
}

/**
 * @summary Creates a source in MediaWeaver.
 *
 * @param request CreateSourceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateSourceResponse
 */
async function createSourceWithOptions(request: CreateSourceRequest, runtime: $RuntimeOptions): CreateSourceResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.httpPackageConfigurations)) {
    query['HttpPackageConfigurations'] = request.httpPackageConfigurations;
  }
  if (!$isNull(request.sourceLocationName)) {
    query['SourceLocationName'] = request.sourceLocationName;
  }
  if (!$isNull(request.sourceName)) {
    query['SourceName'] = request.sourceName;
  }
  if (!$isNull(request.sourceType)) {
    query['SourceType'] = request.sourceType;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateSource',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a source in MediaWeaver.
 *
 * @param request CreateSourceRequest
 * @return CreateSourceResponse
 */
async function createSource(request: CreateSourceRequest): CreateSourceResponse {
  var runtime = new $RuntimeOptions{};
  return createSourceWithOptions(request, runtime);
}

model CreateSourceLocationRequest {
  baseUrl?: string(name='BaseUrl', description='The protocol and hostname of the source location.

This parameter is required.', example='http://xxx.com'),
  enableSegmentDelivery?: boolean(name='EnableSegmentDelivery', description='Specifies whether to use an independent domain name to access the segments.', example='true'),
  segmentDeliveryUrl?: string(name='SegmentDeliveryUrl', description='The domain name used to access the segments.', example='http://xxxxx.com'),
  sourceLocationName?: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourcelocation'),
}

model CreateSourceLocationResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  sourceLocation?: ChannelAssemblySourceLocation(name='SourceLocation', description='The source location information.'),
}

model CreateSourceLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSourceLocationResponseBody(name='body'),
}

/**
 * @summary Creates a source location.
 *
 * @param request CreateSourceLocationRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateSourceLocationResponse
 */
async function createSourceLocationWithOptions(request: CreateSourceLocationRequest, runtime: $RuntimeOptions): CreateSourceLocationResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.baseUrl)) {
    query['BaseUrl'] = request.baseUrl;
  }
  if (!$isNull(request.enableSegmentDelivery)) {
    query['EnableSegmentDelivery'] = request.enableSegmentDelivery;
  }
  if (!$isNull(request.segmentDeliveryUrl)) {
    query['SegmentDeliveryUrl'] = request.segmentDeliveryUrl;
  }
  if (!$isNull(request.sourceLocationName)) {
    query['SourceLocationName'] = request.sourceLocationName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateSourceLocation',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a source location.
 *
 * @param request CreateSourceLocationRequest
 * @return CreateSourceLocationResponse
 */
async function createSourceLocation(request: CreateSourceLocationRequest): CreateSourceLocationResponse {
  var runtime = new $RuntimeOptions{};
  return createSourceLocationWithOptions(request, runtime);
}

model CreateUploadMediaRequest {
  appId?: string(name='AppId', description='The application ID. Default value: app-1000000.', example='app-1000000'),
  entityId?: string(name='EntityId', description='The entity ID. You can call the CreateEntity operation to create an entity and specify a dynamic metadata structure.', example='9e177cac2fb44f8b8c67b199fcc7bffd'),
  fileInfo?: string(name='FileInfo', description='The file information, which is in the JSON format and contains the following fields:

*   Type: required. The file type. Valid values: video, image, audio, text, and other.
*   Name: required. The file name without the extension.
*   Size: optional. The file size.
*   Ext: required. The file name extension.', example='{\\\\"Type\\\\":\\\\"video\\\\",\\\\"Name\\\\":\\\\"test.mp4\\\\",\\\\"Size\\\\":108078336,\\\\"Ext\\\\":\\\\"mp4\\\\"}'),
  mediaMetaData?: string(name='MediaMetaData', description='The metadata of the media asset, which is a JSON string that contains the following fields:

Title: required.

*   The value can be up to 128 characters in length.
*   The value must be encoded in UTF-8.

Description: optional.

*   The value can be up to 1,024 characters in length.
*   The value must be encoded in UTF-8.

CateId: optional.

Tags: optional.

BusinessType: required. Valid values:

*   opening or ending if Type is set to video
*   default or cover if Type is set to image
*   subtitles or font if Type is set to text
*   watermark if Type is set to material
*   general CoverURL: optional.

DynamicMetaData: The value is a string.', example='{\\\\"Title\\\\": \\\\"UploadTest\\\\", \\\\"Description\\\\": \\\\"UploadImageTest\\\\", \\\\"Tags\\\\": \\\\"tag1,tag2\\\\",\\\\"BusinessType\\\\":\\\\"cover\\\\"}'),
  postProcessConfig?: string(name='PostProcessConfig', description='The postprocessing configurations. You can specify this parameter if Type is set to video or audio.

Set ProcessType to Workflow.', example='{\\\\"ProcessType\\\\":\\\\"Workflow\\\\",\\\\"ProcessID\\\\":\\\\"74ba870f1a4873a3ba238e0bf6fa9***\\\\"}'),
  uploadTargetConfig?: string(name='UploadTargetConfig', description='The destination storage address.

Set StorageType to oss.

Set StorageLocation to an address in ApsaraVideo VOD. You cannot set this field to an OSS URL.', example='{\\\\"StorageType\\\\":\\\\"oss\\\\",\\\\"StorageLocation\\\\":\\\\"outin-***.oss-cn-shanghai.aliyuncs.com\\\\"}'),
  userData?: string(name='UserData', description='The user data. The value must be a JSON string. You can configure settings such as message callbacks.', example='{"MessageCallback":{"CallbackURL":"http://example.aliyundoc.com"},"Extend":{"localId":"*****","test":"www"}}'),
}

model CreateUploadMediaResponseBody = {
  fileURL?: string(name='FileURL', description='The OSS URL of the file. The URL does not contain the information used for authentication.', example='http://outin-***.oss-cn-north-2-gov-1.aliyuncs.com/sv/40360f05-181f63c3110-0004-cd8e-27f-de3c9.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaURL?: string(name='MediaURL', description='The URL of the media asset.

>  If a domain name for Alibaba Cloud CDN (CDN) is specified, a CDN URL is returned. Otherwise, an OSS URL is returned. If the HTTP status code 403 is returned when you access the URL from your browser, the URL authentication feature of ApsaraVideo VOD is enabled. To resolve this issue, disable URL authentication or generate an authentication signature.', example='https://xxq-live-playback.oss-cn-shanghai.aliyuncs.com/capture/5d96d2b4-111b-4e5d-a0e5-20f44405bb55.mp4'),
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  uploadAddress?: string(name='UploadAddress', description='The upload URL.

>  The returned upload URL is a Base64-encoded URL. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAddress only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJFbmRwb2ludCI6Imh0dHBzOi8vb3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbSIsIkJ1Y2tldCI6InN6aGQtdmlkZW8iLCJGaWxlTmFtZSI6InZvZC0yOTYzMWEvc3YvNTBmYTJlODQtMTgxMjdhZGRiMTcvNTBmYTJlODQtMTgxMjdhZGRiM***'),
  uploadAuth?: string(name='UploadAuth', description='The upload credential.

>  The returned upload credential is a Base64-encoded value. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAuth only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJBY2Nlc3NLZXlJZCI6IkxUQUk0Rm53bTk1dHdxQjMxR3IzSE5hRCIsIkFjY2Vzc0tleVNlY3JldCI6Ik9lWllKR0dTMTlkNkZaM1E3UVpJQmdmSVdnM3BPaiIsIkV4cGlyYXRpb24iOiI***'),
}

model CreateUploadMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateUploadMediaResponseBody(name='body'),
}

/**
 * @summary Obtains the upload URL and credential of a media asset and creates information about the media asset.
 *
 * @description *   You can call this operation to obtain the upload URLs and credentials of audio and video files. You can also call this operation to obtain the upload URLs and credentials of images and auxiliary media assets.
 * *   Obtaining an upload URL and credential is essential for Intelligent Media Services (IMS) and is required in each upload operation.
 * *   If the video upload credential expires, you can call the RefreshUploadMedia operation to obtain a new upload credential. The default validity period of a video upload credential is 3,000 seconds.
 * *   After you upload a media asset, you can configure a callback to receive upload event notifications or call the GetMediaInfo operation to determine whether the media asset is uploaded based on the returned status.
 * *   The MediaId parameter returned by this operation can be used for media asset lifecycle management or media processing.
 * *   You can call this operation to upload media assets only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media asset to your own OSS bucket, you can upload the file to your OSS bucket by using [OSS SDK](https://help.aliyun.com/document_detail/32006.html), and then call the [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html) operation to register the file in the OSS bucket with the media asset library.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 *
 * @param request CreateUploadMediaRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateUploadMediaResponse
 */
async function createUploadMediaWithOptions(request: CreateUploadMediaRequest, runtime: $RuntimeOptions): CreateUploadMediaResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.appId)) {
    query['AppId'] = request.appId;
  }
  if (!$isNull(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  if (!$isNull(request.fileInfo)) {
    query['FileInfo'] = request.fileInfo;
  }
  if (!$isNull(request.mediaMetaData)) {
    query['MediaMetaData'] = request.mediaMetaData;
  }
  if (!$isNull(request.postProcessConfig)) {
    query['PostProcessConfig'] = request.postProcessConfig;
  }
  if (!$isNull(request.uploadTargetConfig)) {
    query['UploadTargetConfig'] = request.uploadTargetConfig;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateUploadMedia',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Obtains the upload URL and credential of a media asset and creates information about the media asset.
 *
 * @description *   You can call this operation to obtain the upload URLs and credentials of audio and video files. You can also call this operation to obtain the upload URLs and credentials of images and auxiliary media assets.
 * *   Obtaining an upload URL and credential is essential for Intelligent Media Services (IMS) and is required in each upload operation.
 * *   If the video upload credential expires, you can call the RefreshUploadMedia operation to obtain a new upload credential. The default validity period of a video upload credential is 3,000 seconds.
 * *   After you upload a media asset, you can configure a callback to receive upload event notifications or call the GetMediaInfo operation to determine whether the media asset is uploaded based on the returned status.
 * *   The MediaId parameter returned by this operation can be used for media asset lifecycle management or media processing.
 * *   You can call this operation to upload media assets only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media asset to your own OSS bucket, you can upload the file to your OSS bucket by using [OSS SDK](https://help.aliyun.com/document_detail/32006.html), and then call the [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html) operation to register the file in the OSS bucket with the media asset library.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 *
 * @param request CreateUploadMediaRequest
 * @return CreateUploadMediaResponse
 */
async function createUploadMedia(request: CreateUploadMediaRequest): CreateUploadMediaResponse {
  var runtime = new $RuntimeOptions{};
  return createUploadMediaWithOptions(request, runtime);
}

model CreateUploadStreamRequest {
  definition?: string(name='Definition', description='The quality of the media stream. Valid values:

*   FD: low definition.
*   LD: standard definition.
*   SD: high definition.
*   HD: ultra-high definition.
*   OD: original quality.
*   2K: 2K resolution.
*   4K: 4K resolution.
*   SQ: standard sound quality.
*   HQ: high sound quality.', example='HD'),
  fileExtension?: string(name='FileExtension', description='The file name extension of the media stream.', example='MP4'),
  HDRType?: string(name='HDRType', description='The high dynamic range (HDR) format of the transcoded stream. Valid values:

*   HDR
*   HDR10
*   HLG
*   DolbyVision
*   HDRVivid
*   SDR+

> 

*   The value is not case-sensitive,

*   You can leave this parameter empty for non-HDR streams.', example='HDR10'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  userData?: string(name='UserData', description='The user data.', example='{"MessageCallback":{"CallbackURL":"http://aliyundoc.com"}, "Extend":{"localId":"xxx","test":"www"}}'),
}

model CreateUploadStreamResponseBody = {
  fileURL?: string(name='FileURL', description='The Object Storage Service (OSS) URL of the file. The URL does not contain the information used for authentication.', example='http://outin-***.oss-cn-shanghai.aliyuncs.com/stream/48555e8b-181dd5a8c07/48555e8b-181dd5a8c07.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****c469e944b5a856828dc2****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  uploadAddress?: string(name='UploadAddress', description='The upload URL.

>  The returned upload URL is a Base64-encoded URL. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAddress only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJFbmRwb2ludCI6Imh0dHBzOi8vb3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbSIsIkJ1Y2tldCI6InN6aGQtdmlkZW8iLCJGaWxlTmFtZSI6InZvZC0yOTYzMWEvc3YvNTBmYTJlODQtMTgxMjdhZGRiMTcvNTBmYTJlODQtMTgxMjdhZGRiM***'),
  uploadAuth?: string(name='UploadAuth', description='The upload credential.

>  The returned upload credential is a Base64-encoded value. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAuth only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJBY2Nlc3NLZXlJZCI6IkxUQUk0Rm53bTk1dHdxQjMxR3IzSE5hRCIsIkFjY2Vzc0tleVNlY3JldCI6Ik9lWllKR0dTMTlkNkZaM1E3UVpJQmdmSVdnM3BPaiIsIkV4cGlyYXRpb24iOiI***'),
}

model CreateUploadStreamResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateUploadStreamResponseBody(name='body'),
}

/**
 * @summary Obtains the upload URL and credential of a media stream.
 *
 * @description *   You can call this operation to upload only a local media stream. After the media stream is uploaded, it is associated with the specified media asset ID.
 * *   You can call this operation to upload media streams only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media stream to your own OSS bucket, you can upload the file to your OSS bucket by using [OSS SDK](https://help.aliyun.com/document_detail/32006.html), and then call the [RegisterMediaStream](https://help.aliyun.com/document_detail/440765.html) operation to associate the media stream with the specified media asset ID.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 *
 * @param request CreateUploadStreamRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateUploadStreamResponse
 */
async function createUploadStreamWithOptions(request: CreateUploadStreamRequest, runtime: $RuntimeOptions): CreateUploadStreamResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.definition)) {
    query['Definition'] = request.definition;
  }
  if (!$isNull(request.fileExtension)) {
    query['FileExtension'] = request.fileExtension;
  }
  if (!$isNull(request.HDRType)) {
    query['HDRType'] = request.HDRType;
  }
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateUploadStream',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Obtains the upload URL and credential of a media stream.
 *
 * @description *   You can call this operation to upload only a local media stream. After the media stream is uploaded, it is associated with the specified media asset ID.
 * *   You can call this operation to upload media streams only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media stream to your own OSS bucket, you can upload the file to your OSS bucket by using [OSS SDK](https://help.aliyun.com/document_detail/32006.html), and then call the [RegisterMediaStream](https://help.aliyun.com/document_detail/440765.html) operation to associate the media stream with the specified media asset ID.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 *
 * @param request CreateUploadStreamRequest
 * @return CreateUploadStreamResponse
 */
async function createUploadStream(request: CreateUploadStreamRequest): CreateUploadStreamResponse {
  var runtime = new $RuntimeOptions{};
  return createUploadStreamWithOptions(request, runtime);
}

model CreateVodPackagingAssetRequest {
  assetName?: string(name='AssetName', description='The name of the asset. The name must be unique and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='hls_3s'),
  contentId?: string(name='ContentId', description='The content ID in the digital rights management (DRM) system. The maximum length is 256 characters. Letters, digits, underscores (_), and hyphens (-) are supported.', example='movie'),
  description?: string(name='Description', description='The asset description.', example='HLS 3 second packaging'),
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls'),
  input?: {
    media?: string(name='Media', description='The URL of the media file. Only M3U8 files stored in OSS are supported.'),
    type?: string(name='Type', description='The input type. Only Object Storage Service (OSS) is supported.', example='OSS'),
  }(name='Input', description='The asset input configurations.'),
}

model CreateVodPackagingAssetShrinkRequest {
  assetName?: string(name='AssetName', description='The name of the asset. The name must be unique and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='hls_3s'),
  contentId?: string(name='ContentId', description='The content ID in the digital rights management (DRM) system. The maximum length is 256 characters. Letters, digits, underscores (_), and hyphens (-) are supported.', example='movie'),
  description?: string(name='Description', description='The asset description.', example='HLS 3 second packaging'),
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls'),
  inputShrink?: string(name='Input', description='The asset input configurations.'),
}

model CreateVodPackagingAssetResponseBody = {
  asset?: VodPackagingAsset(name='Asset', description='The information about the asset.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model CreateVodPackagingAssetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateVodPackagingAssetResponseBody(name='body'),
}

/**
 * @summary Ingests an asset for VOD packaging.
 *
 * @param tmpReq CreateVodPackagingAssetRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateVodPackagingAssetResponse
 */
async function createVodPackagingAssetWithOptions(tmpReq: CreateVodPackagingAssetRequest, runtime: $RuntimeOptions): CreateVodPackagingAssetResponse {
  tmpReq.validate();
  var request = new CreateVodPackagingAssetShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  var query = {};
  if (!$isNull(request.assetName)) {
    query['AssetName'] = request.assetName;
  }
  if (!$isNull(request.contentId)) {
    query['ContentId'] = request.contentId;
  }
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  if (!$isNull(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateVodPackagingAsset',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Ingests an asset for VOD packaging.
 *
 * @param request CreateVodPackagingAssetRequest
 * @return CreateVodPackagingAssetResponse
 */
async function createVodPackagingAsset(request: CreateVodPackagingAssetRequest): CreateVodPackagingAssetResponse {
  var runtime = new $RuntimeOptions{};
  return createVodPackagingAssetWithOptions(request, runtime);
}

model CreateVodPackagingConfigurationRequest {
  configurationName?: string(name='ConfigurationName', description='The name of the packaging configuration. The name must be unique in an account and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='hls_3s'),
  description?: string(name='Description', description='The description of the packaging configuration.', example='HLS 3s vod packaging'),
  groupName?: string(name='GroupName', description='The name of the packaging group. The name can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='vod_hls'),
  packageConfig?: {
    drmProvider?: {
      encryptionMethod?: string(name='EncryptionMethod', description='The encryption method. Valid values:

*   AES_128: Advanced Encryption Standard (AES) with 128-bit key length.
*   SAMPLE_AES: an encryption method that encrypts individual media samples.', example='AES_128'),
      IV?: string(name='IV', description='A 128-bit, 16-byte hex value represented by a 32-character string that is used with the key for encrypting data blocks. If you leave this parameter empty, MediaPackage creates a constant initialization vector (IV). If it is specified, the value is passed to the DRM service.', example='00001111222233334444555566667777'),
      systemIds?: [ string ](name='SystemIds', description='The ID of the DRM system. The maximum number of system IDs allowed is determined by the protocol type. Limits:

*   DASH: 2
*   HLS: 1
*   HLS_CMAF: 2

Apple FairPlay, Google Widevine, and Microsoft PlayReady are supported. Their system IDs are as follows:

*   Apple FairPlay: 94ce86fb-07ff-4f43-adb8-93d2fa968ca2
*   Google Widevine: edef8ba9-79d6-4ace-a3c8-27dcd51d21e
*   Microsoft PlayReady: 9a04f079-9840-4286-ab92-e65be0885f95'),
      url?: string(name='Url', description='The URL of the DRM key provider.'),
    }(name='DrmProvider', description='The settings of digital rights management (DRM) encryption.', nullable=true),
    manifestName?: string(name='ManifestName', description='The manifest name. The name can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='index'),
    segmentDuration?: long(name='SegmentDuration', description='The duration of each segment in a packaged stream. Unit: seconds. MediaPackage rounds segments to the nearest multiple of the input segment duration. Valid values: 1 to 30.', example='6'),
    streamSelection?: {
      maxVideoBitsPerSecond?: long(name='MaxVideoBitsPerSecond', description='The maximum bitrate of the video stream. Unit: bit/s.', example='1000000000'),
      minVideoBitsPerSecond?: long(name='MinVideoBitsPerSecond', description='The minimum bitrate of the video stream. Unit: bit/s.', example='100000'),
      streamOrder?: string(name='StreamOrder', description='The order of manifest files in the master playlist. Valid values:

*   ORIGINAL: sorts the manifest files in the same order as the source.
*   VIDEO_BITRATE_ASCENDING: sorts the manifest files in ascending order of bitrates, from lowest to highest.
*   VIDEO_BITRATE_DESCENDING: sorts the manifest files in descending order of bitrates, from highest to lowest.', example='ORIGINAL'),
    }(name='StreamSelection', description='The settings of stream selection.'),
  }(name='PackageConfig', description='The packaging configuration.'),
  protocol?: string(name='Protocol', description='The package type.

*   HLS: packages content into TS segments for delivery over the HLS protocol.
*   HLS_CMAF: packages content into CMAF segments for delivery over the HLS protocol.
*   DASH: packages content for delivery over the DASH protocol.', example='HLS'),
}

model CreateVodPackagingConfigurationShrinkRequest {
  configurationName?: string(name='ConfigurationName', description='The name of the packaging configuration. The name must be unique in an account and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='hls_3s'),
  description?: string(name='Description', description='The description of the packaging configuration.', example='HLS 3s vod packaging'),
  groupName?: string(name='GroupName', description='The name of the packaging group. The name can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='vod_hls'),
  packageConfigShrink?: string(name='PackageConfig', description='The packaging configuration.'),
  protocol?: string(name='Protocol', description='The package type.

*   HLS: packages content into TS segments for delivery over the HLS protocol.
*   HLS_CMAF: packages content into CMAF segments for delivery over the HLS protocol.
*   DASH: packages content for delivery over the DASH protocol.', example='HLS'),
}

model CreateVodPackagingConfigurationResponseBody = {
  packagingConfiguration?: VodPackagingConfiguration(name='PackagingConfiguration', description='The packaging configuration.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateVodPackagingConfigurationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateVodPackagingConfigurationResponseBody(name='body'),
}

/**
 * @summary Creates a packaging configuration.
 *
 * @param tmpReq CreateVodPackagingConfigurationRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateVodPackagingConfigurationResponse
 */
async function createVodPackagingConfigurationWithOptions(tmpReq: CreateVodPackagingConfigurationRequest, runtime: $RuntimeOptions): CreateVodPackagingConfigurationResponse {
  tmpReq.validate();
  var request = new CreateVodPackagingConfigurationShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.packageConfig)) {
    request.packageConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.packageConfig, 'PackageConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.configurationName)) {
    query['ConfigurationName'] = request.configurationName;
  }
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  if (!$isNull(request.packageConfigShrink)) {
    query['PackageConfig'] = request.packageConfigShrink;
  }
  if (!$isNull(request.protocol)) {
    query['Protocol'] = request.protocol;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateVodPackagingConfiguration',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a packaging configuration.
 *
 * @param request CreateVodPackagingConfigurationRequest
 * @return CreateVodPackagingConfigurationResponse
 */
async function createVodPackagingConfiguration(request: CreateVodPackagingConfigurationRequest): CreateVodPackagingConfigurationResponse {
  var runtime = new $RuntimeOptions{};
  return createVodPackagingConfigurationWithOptions(request, runtime);
}

model CreateVodPackagingGroupRequest {
  description?: string(name='Description', description='The packaging group description.', example='vod hls packaging'),
  groupName?: string(name='GroupName', description='The name of the packaging group. The name must be unique in an account and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='vod_hls'),
}

model CreateVodPackagingGroupResponseBody = {
  packagingGroup?: VodPackagingGroup(name='PackagingGroup', description='The packaging group information.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model CreateVodPackagingGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateVodPackagingGroupResponseBody(name='body'),
}

/**
 * @summary Creates a packaging group.
 *
 * @param request CreateVodPackagingGroupRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateVodPackagingGroupResponse
 */
async function createVodPackagingGroupWithOptions(request: CreateVodPackagingGroupRequest, runtime: $RuntimeOptions): CreateVodPackagingGroupResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'CreateVodPackagingGroup',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates a packaging group.
 *
 * @param request CreateVodPackagingGroupRequest
 * @return CreateVodPackagingGroupResponse
 */
async function createVodPackagingGroup(request: CreateVodPackagingGroupRequest): CreateVodPackagingGroupResponse {
  var runtime = new $RuntimeOptions{};
  return createVodPackagingGroupWithOptions(request, runtime);
}

model DecryptKMSDataKeyRequest {
  ciphertextBlob?: string(name='CiphertextBlob', description='The ciphertext that you want to decrypt.

This parameter is required.', example='ODZhOWVmZDktM2QxNi00ODk0LWJkNGYtMWZjNDNmM2YyYWJmS7FmDBBQ0BkKsQrtRnidtPwirmDcS0ZuJCU41xxAAWk4Z8qsADfbV0b+i6kQmlvj79dJdGOvtX69Uycs901qOjop4bTS****'),
}

model DecryptKMSDataKeyResponseBody = {
  dataKey?: {
    keyId?: string(name='KeyId', description='The ID of the customer master key (CMK) that was used to decrypt the ciphertext.', example='202b9877-5a25-46e3-a763-e20791b5****'),
    plaintext?: string(name='Plaintext', description='The plaintext that is generated after decryption.', example='tRYXuCwgja12xxO1N/gZERDDCLw9doZEQiPDk/Bv****'),
  }(name='DataKey', description='The information about the decryption result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DecryptKMSDataKeyResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DecryptKMSDataKeyResponseBody(name='body'),
}

/**
 * @summary Decrypts the ciphertext specified by CiphertextBlob in the Key Management Service (KMS) data key.
 *
 * @param request DecryptKMSDataKeyRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DecryptKMSDataKeyResponse
 */
async function decryptKMSDataKeyWithOptions(request: DecryptKMSDataKeyRequest, runtime: $RuntimeOptions): DecryptKMSDataKeyResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.ciphertextBlob)) {
    query['CiphertextBlob'] = request.ciphertextBlob;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DecryptKMSDataKey',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Decrypts the ciphertext specified by CiphertextBlob in the Key Management Service (KMS) data key.
 *
 * @param request DecryptKMSDataKeyRequest
 * @return DecryptKMSDataKeyResponse
 */
async function decryptKMSDataKey(request: DecryptKMSDataKeyRequest): DecryptKMSDataKeyResponse {
  var runtime = new $RuntimeOptions{};
  return decryptKMSDataKeyWithOptions(request, runtime);
}

model DeleteAIAgentDialogueRequest {
  dialogueId?: string(name='DialogueId', description='This parameter is required.', example='f27f9b9be28642a88e18*******'),
  sessionId?: string(name='SessionId', description='This parameter is required.', example='6d594e7f55624c47a48789******'),
}

model DeleteAIAgentDialogueResponseBody = {
  requestId?: string(name='RequestId', example='7B117AF5-2A1******'),
}

model DeleteAIAgentDialogueResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteAIAgentDialogueResponseBody(name='body'),
}

/**
 * @summary 删除智能体的对话历史记录。
 *
 * @param request DeleteAIAgentDialogueRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteAIAgentDialogueResponse
 */
async function deleteAIAgentDialogueWithOptions(request: DeleteAIAgentDialogueRequest, runtime: $RuntimeOptions): DeleteAIAgentDialogueResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.dialogueId)) {
    query['DialogueId'] = request.dialogueId;
  }
  if (!$isNull(request.sessionId)) {
    query['SessionId'] = request.sessionId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteAIAgentDialogue',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 删除智能体的对话历史记录。
 *
 * @param request DeleteAIAgentDialogueRequest
 * @return DeleteAIAgentDialogueResponse
 */
async function deleteAIAgentDialogue(request: DeleteAIAgentDialogueRequest): DeleteAIAgentDialogueResponse {
  var runtime = new $RuntimeOptions{};
  return deleteAIAgentDialogueWithOptions(request, runtime);
}

model DeleteAdInsertionRequest {
  name?: string(name='Name', description='The name of the configuration that you want to delete.

This parameter is required.', example='my_ad'),
}

model DeleteAdInsertionResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteAdInsertionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteAdInsertionResponseBody(name='body'),
}

/**
 * @summary Deletes an ad insertion configuration.
 *
 * @param request DeleteAdInsertionRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteAdInsertionResponse
 */
async function deleteAdInsertionWithOptions(request: DeleteAdInsertionRequest, runtime: $RuntimeOptions): DeleteAdInsertionResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.name)) {
    body['Name'] = request.name;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteAdInsertion',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes an ad insertion configuration.
 *
 * @param request DeleteAdInsertionRequest
 * @return DeleteAdInsertionResponse
 */
async function deleteAdInsertion(request: DeleteAdInsertionRequest): DeleteAdInsertionResponse {
  var runtime = new $RuntimeOptions{};
  return deleteAdInsertionWithOptions(request, runtime);
}

model DeleteAvatarTrainingJobRequest {
  jobId?: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model DeleteAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteAvatarTrainingJobResponseBody(name='body'),
}

/**
 * @summary Deletes a digital human training job that is in the Init or Fail state.
 *
 * @param request DeleteAvatarTrainingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteAvatarTrainingJobResponse
 */
async function deleteAvatarTrainingJobWithOptions(request: DeleteAvatarTrainingJobRequest, runtime: $RuntimeOptions): DeleteAvatarTrainingJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteAvatarTrainingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a digital human training job that is in the Init or Fail state.
 *
 * @param request DeleteAvatarTrainingJobRequest
 * @return DeleteAvatarTrainingJobResponse
 */
async function deleteAvatarTrainingJob(request: DeleteAvatarTrainingJobRequest): DeleteAvatarTrainingJobResponse {
  var runtime = new $RuntimeOptions{};
  return deleteAvatarTrainingJobWithOptions(request, runtime);
}

model DeleteCategoryRequest {
  cateId?: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of CateId returned by the AddCategory operation that you called to create a category.
*   View the value of CateId returned by the GetCategories operation that you called to query a category.

This parameter is required.', example='46'),
}

model DeleteCategoryResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model DeleteCategoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCategoryResponseBody(name='body'),
}

/**
 * @summary Deletes a media asset category.
 *
 * @description This operation also deletes the subcategories, including the level-2 and level-3 categories, of the category.
 *
 * @param request DeleteCategoryRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteCategoryResponse
 */
async function deleteCategoryWithOptions(request: DeleteCategoryRequest, runtime: $RuntimeOptions): DeleteCategoryResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.cateId)) {
    query['CateId'] = request.cateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteCategory',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a media asset category.
 *
 * @description This operation also deletes the subcategories, including the level-2 and level-3 categories, of the category.
 *
 * @param request DeleteCategoryRequest
 * @return DeleteCategoryResponse
 */
async function deleteCategory(request: DeleteCategoryRequest): DeleteCategoryResponse {
  var runtime = new $RuntimeOptions{};
  return deleteCategoryWithOptions(request, runtime);
}

model DeleteChannelRequest {
  channelName?: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel'),
}

model DeleteChannelResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteChannelResponseBody(name='body'),
}

/**
 * @summary Deletes a channel in MediaWeaver.
 *
 * @param request DeleteChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteChannelResponse
 */
async function deleteChannelWithOptions(request: DeleteChannelRequest, runtime: $RuntimeOptions): DeleteChannelResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a channel in MediaWeaver.
 *
 * @param request DeleteChannelRequest
 * @return DeleteChannelResponse
 */
async function deleteChannel(request: DeleteChannelRequest): DeleteChannelResponse {
  var runtime = new $RuntimeOptions{};
  return deleteChannelWithOptions(request, runtime);
}

model DeleteCustomTemplateRequest {
  templateId?: string(name='TemplateId', description='The ID of the custom template.

This parameter is required.', example='****96e8864746a0b6f3****'),
}

model DeleteCustomTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCustomTemplateResponseBody(name='body'),
}

/**
 * @summary Deletes a custom template.
 *
 * @param request DeleteCustomTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteCustomTemplateResponse
 */
async function deleteCustomTemplateWithOptions(request: DeleteCustomTemplateRequest, runtime: $RuntimeOptions): DeleteCustomTemplateResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteCustomTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a custom template.
 *
 * @param request DeleteCustomTemplateRequest
 * @return DeleteCustomTemplateResponse
 */
async function deleteCustomTemplate(request: DeleteCustomTemplateRequest): DeleteCustomTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return deleteCustomTemplateWithOptions(request, runtime);
}

model DeleteCustomizedVoiceJobRequest {
  jobId?: string(name='JobId', description='The ID of the human voice cloning job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model DeleteCustomizedVoiceJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Deletes a human voice cloning job that is not in the Training or Success state.
 *
 * @param request DeleteCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteCustomizedVoiceJobResponse
 */
async function deleteCustomizedVoiceJobWithOptions(request: DeleteCustomizedVoiceJobRequest, runtime: $RuntimeOptions): DeleteCustomizedVoiceJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a human voice cloning job that is not in the Training or Success state.
 *
 * @param request DeleteCustomizedVoiceJobRequest
 * @return DeleteCustomizedVoiceJobResponse
 */
async function deleteCustomizedVoiceJob(request: DeleteCustomizedVoiceJobRequest): DeleteCustomizedVoiceJobResponse {
  var runtime = new $RuntimeOptions{};
  return deleteCustomizedVoiceJobWithOptions(request, runtime);
}

model DeleteDNADBRequest {
  DBId?: string(name='DBId', description='The ID of the media fingerprint library that you want to delete.

This parameter is required.', example='fb712a6890464059b1b2ea7c8647****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model DeleteDNADBResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model DeleteDNADBResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDNADBResponseBody(name='body'),
}

/**
 * @summary Deletes a media fingerprint library.
 *
 * @param request DeleteDNADBRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteDNADBResponse
 */
async function deleteDNADBWithOptions(request: DeleteDNADBRequest, runtime: $RuntimeOptions): DeleteDNADBResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.DBId)) {
    query['DBId'] = request.DBId;
  }
  if (!$isNull(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!$isNull(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!$isNull(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!$isNull(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteDNADB',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a media fingerprint library.
 *
 * @param request DeleteDNADBRequest
 * @return DeleteDNADBResponse
 */
async function deleteDNADB(request: DeleteDNADBRequest): DeleteDNADBResponse {
  var runtime = new $RuntimeOptions{};
  return deleteDNADBWithOptions(request, runtime);
}

model DeleteDNAFilesRequest {
  DBId?: string(name='DBId', description='The ID of the media fingerprint library from which you want to delete files.

This parameter is required.', example='fb712a6890464059b1b2ea7c8647****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  primaryKeys?: string(name='PrimaryKeys', description='The primary key values of the files that you want to delete. Separate multiple values with commas (,). You can delete up to 50 files at a time.

This parameter is required.', example='41e6536e4f2250e2e9bf26cdea19****'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model DeleteDNAFilesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model DeleteDNAFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDNAFilesResponseBody(name='body'),
}

/**
 * @summary Deletes files from a media fingerprint library.
 *
 * @param request DeleteDNAFilesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteDNAFilesResponse
 */
async function deleteDNAFilesWithOptions(request: DeleteDNAFilesRequest, runtime: $RuntimeOptions): DeleteDNAFilesResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.DBId)) {
    query['DBId'] = request.DBId;
  }
  if (!$isNull(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!$isNull(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!$isNull(request.primaryKeys)) {
    query['PrimaryKeys'] = request.primaryKeys;
  }
  if (!$isNull(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!$isNull(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteDNAFiles',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes files from a media fingerprint library.
 *
 * @param request DeleteDNAFilesRequest
 * @return DeleteDNAFilesResponse
 */
async function deleteDNAFiles(request: DeleteDNAFilesRequest): DeleteDNAFilesResponse {
  var runtime = new $RuntimeOptions{};
  return deleteDNAFilesWithOptions(request, runtime);
}

model DeleteEditingProjectMaterialsRequest {
  materialIds?: string(name='MaterialIds', description='The material ID. Separate multiple material IDs with commas (,). You can specify up to 10 IDs.

This parameter is required.', example='*****cbd721b418a89a7dafb1dc*****,*****86f5d534c95997c55c96f*****'),
  materialType?: string(name='MaterialType', description='The material type. Valid values:

\\\\- video

\\\\- image

\\\\- audio

\\\\- subtitle

\\\\- text

This parameter is required.', example='video'),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='*****fb2101cb318*****'),
}

model DeleteEditingProjectMaterialsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******36-3C1E-4417-BDB2-1E034F******'),
}

model DeleteEditingProjectMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteEditingProjectMaterialsResponseBody(name='body'),
}

/**
 * @summary Deletes one or more materials from an online editing project.
 *
 * @param request DeleteEditingProjectMaterialsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteEditingProjectMaterialsResponse
 */
async function deleteEditingProjectMaterialsWithOptions(request: DeleteEditingProjectMaterialsRequest, runtime: $RuntimeOptions): DeleteEditingProjectMaterialsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.materialIds)) {
    query['MaterialIds'] = request.materialIds;
  }
  if (!$isNull(request.materialType)) {
    query['MaterialType'] = request.materialType;
  }
  if (!$isNull(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteEditingProjectMaterials',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes one or more materials from an online editing project.
 *
 * @param request DeleteEditingProjectMaterialsRequest
 * @return DeleteEditingProjectMaterialsResponse
 */
async function deleteEditingProjectMaterials(request: DeleteEditingProjectMaterialsRequest): DeleteEditingProjectMaterialsResponse {
  var runtime = new $RuntimeOptions{};
  return deleteEditingProjectMaterialsWithOptions(request, runtime);
}

model DeleteEditingProjectsRequest {
  projectIds?: string(name='ProjectIds', description='The ID of the online editing project. You can specify multiple IDs separated with commas (,).', example='****fb2101bf24bf41cb318787dc****,****87dcfb2101bf24bf41cb3187****'),
}

model DeleteEditingProjectsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****25818875-5F78-4AF6-D7393642CA58****'),
}

model DeleteEditingProjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteEditingProjectsResponseBody(name='body'),
}

/**
 * @summary Deletes one or more online editing project.
 *
 * @param request DeleteEditingProjectsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteEditingProjectsResponse
 */
async function deleteEditingProjectsWithOptions(request: DeleteEditingProjectsRequest, runtime: $RuntimeOptions): DeleteEditingProjectsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.projectIds)) {
    query['ProjectIds'] = request.projectIds;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteEditingProjects',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes one or more online editing project.
 *
 * @param request DeleteEditingProjectsRequest
 * @return DeleteEditingProjectsResponse
 */
async function deleteEditingProjects(request: DeleteEditingProjectsRequest): DeleteEditingProjectsResponse {
  var runtime = new $RuntimeOptions{};
  return deleteEditingProjectsWithOptions(request, runtime);
}

model DeleteLivePackageChannelRequest {
  channelName?: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1'),
  groupName?: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1'),
}

model DeleteLivePackageChannelResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='20B3A1B6-4BD2-5DE6-BCBC-098C9B4F4E91'),
}

model DeleteLivePackageChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLivePackageChannelResponseBody(name='body'),
}

/**
 * @summary Deletes a live package channel by GroupName and ChannelName.
 *
 * @description ## [](#)Usage notes
 * You need to provide GroupName and ChannelName as parameters to specify exactly which channel to delete. Before you delete a channel, you must delete the origin endpoints associated with the channel.
 *
 * @param request DeleteLivePackageChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLivePackageChannelResponse
 */
async function deleteLivePackageChannelWithOptions(request: DeleteLivePackageChannelRequest, runtime: $RuntimeOptions): DeleteLivePackageChannelResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteLivePackageChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a live package channel by GroupName and ChannelName.
 *
 * @description ## [](#)Usage notes
 * You need to provide GroupName and ChannelName as parameters to specify exactly which channel to delete. Before you delete a channel, you must delete the origin endpoints associated with the channel.
 *
 * @param request DeleteLivePackageChannelRequest
 * @return DeleteLivePackageChannelResponse
 */
async function deleteLivePackageChannel(request: DeleteLivePackageChannelRequest): DeleteLivePackageChannelResponse {
  var runtime = new $RuntimeOptions{};
  return deleteLivePackageChannelWithOptions(request, runtime);
}

model DeleteLivePackageChannelGroupRequest {
  groupName?: string(name='GroupName', description='The channel group name.

This parameter is required.', example='group1'),
}

model DeleteLivePackageChannelGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='5D87B753-0250-5D9D-B248-D40C3271F864'),
}

model DeleteLivePackageChannelGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLivePackageChannelGroupResponseBody(name='body'),
}

/**
 * @summary Deletes a live package channel group by name.
 *
 * @description ## [](#)Usage notes
 * Make sure that no channels are included in the channel group before you delete it.
 *
 * @param request DeleteLivePackageChannelGroupRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLivePackageChannelGroupResponse
 */
async function deleteLivePackageChannelGroupWithOptions(request: DeleteLivePackageChannelGroupRequest, runtime: $RuntimeOptions): DeleteLivePackageChannelGroupResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteLivePackageChannelGroup',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a live package channel group by name.
 *
 * @description ## [](#)Usage notes
 * Make sure that no channels are included in the channel group before you delete it.
 *
 * @param request DeleteLivePackageChannelGroupRequest
 * @return DeleteLivePackageChannelGroupResponse
 */
async function deleteLivePackageChannelGroup(request: DeleteLivePackageChannelGroupRequest): DeleteLivePackageChannelGroupResponse {
  var runtime = new $RuntimeOptions{};
  return deleteLivePackageChannelGroupWithOptions(request, runtime);
}

model DeleteLivePackageOriginEndpointRequest {
  channelName?: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1'),
  endpointName?: string(name='EndpointName', description='The endpoint name.

This parameter is required.', example='endpoint-1'),
  groupName?: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1'),
}

model DeleteLivePackageOriginEndpointResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='5D87B753-0250-5D9D-B248-D40C3271F864'),
}

model DeleteLivePackageOriginEndpointResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLivePackageOriginEndpointResponseBody(name='body'),
}

/**
 * @summary Deletes an origin endpoint associated with a live package channel.
 *
 * @description ## [](#)Usage notes
 * This API operation is used to delete an origin endpoint associated with a live package channel by specifying `GroupName`, `ChannelName`, and `EndpointName`. This operation will permanently delete the relevant configurations. Exercise caution when you perform this operation.
 *
 * @param request DeleteLivePackageOriginEndpointRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLivePackageOriginEndpointResponse
 */
async function deleteLivePackageOriginEndpointWithOptions(request: DeleteLivePackageOriginEndpointRequest, runtime: $RuntimeOptions): DeleteLivePackageOriginEndpointResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.endpointName)) {
    query['EndpointName'] = request.endpointName;
  }
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteLivePackageOriginEndpoint',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes an origin endpoint associated with a live package channel.
 *
 * @description ## [](#)Usage notes
 * This API operation is used to delete an origin endpoint associated with a live package channel by specifying `GroupName`, `ChannelName`, and `EndpointName`. This operation will permanently delete the relevant configurations. Exercise caution when you perform this operation.
 *
 * @param request DeleteLivePackageOriginEndpointRequest
 * @return DeleteLivePackageOriginEndpointResponse
 */
async function deleteLivePackageOriginEndpoint(request: DeleteLivePackageOriginEndpointRequest): DeleteLivePackageOriginEndpointResponse {
  var runtime = new $RuntimeOptions{};
  return deleteLivePackageOriginEndpointWithOptions(request, runtime);
}

model DeleteLiveRecordFilesRequest {
  recordIds?: [ string ](name='RecordIds', description='The collection of IDs of recording files.

This parameter is required.'),
  removeFile?: boolean(name='RemoveFile', description='Specifies whether to delete the original files in OSS.', example='true'),
}

model DeleteLiveRecordFilesResponseBody = {
  deleteFileInfoList?: [ 
    {
      code?: string(name='Code', description='The code that identifies the result of the deletion.', example='OK'),
      message?: string(name='Message', description='The result of deletion.', example='OK'),
      recordId?: string(name='RecordId', description='The ID of the deleted recording file.', example='13cbb83e-043c-4728-ac35-*****'),
    }
  ](name='DeleteFileInfoList', description='The list of files deleted.'),
  message?: string(name='Message', description='The description of the state returned.', example='OK'),
  requestId?: string(name='RequestId', description='Id of the request', example='13cbb83e-043c-4728-ac35-*****'),
}

model DeleteLiveRecordFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveRecordFilesResponseBody(name='body'),
}

/**
 * @summary Deletes live stream recording files. You can choose to delete only the recording files or delete both the recording files and the original Object Storage Service (OSS) files.
 *
 * @param request DeleteLiveRecordFilesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLiveRecordFilesResponse
 */
async function deleteLiveRecordFilesWithOptions(request: DeleteLiveRecordFilesRequest, runtime: $RuntimeOptions): DeleteLiveRecordFilesResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.recordIds)) {
    query['RecordIds'] = request.recordIds;
  }
  if (!$isNull(request.removeFile)) {
    query['RemoveFile'] = request.removeFile;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteLiveRecordFiles',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes live stream recording files. You can choose to delete only the recording files or delete both the recording files and the original Object Storage Service (OSS) files.
 *
 * @param request DeleteLiveRecordFilesRequest
 * @return DeleteLiveRecordFilesResponse
 */
async function deleteLiveRecordFiles(request: DeleteLiveRecordFilesRequest): DeleteLiveRecordFilesResponse {
  var runtime = new $RuntimeOptions{};
  return deleteLiveRecordFilesWithOptions(request, runtime);
}

model DeleteLiveRecordTemplateRequest {
  templateId?: string(name='TemplateId', description='The ID of the template to be deleted. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ice.console.aliyun.com/live-processing/template/list/record), choose Real-time Media Processing > Template Management, and then click the Recording tab. Alternatively, find the ID from the response parameters of the [CreateLiveRecordTemplate](https://help.aliyun.com/document_detail/448213.html) operation.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
}

model DeleteLiveRecordTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='3E5330CF-B4C8-5BEF-AA6B-8E70BD20FAEE'),
}

model DeleteLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveRecordTemplateResponseBody(name='body'),
}

/**
 * @summary Deletes a live stream recording template without affecting existing jobs.
 *
 * @param request DeleteLiveRecordTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLiveRecordTemplateResponse
 */
async function deleteLiveRecordTemplateWithOptions(request: DeleteLiveRecordTemplateRequest, runtime: $RuntimeOptions): DeleteLiveRecordTemplateResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteLiveRecordTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a live stream recording template without affecting existing jobs.
 *
 * @param request DeleteLiveRecordTemplateRequest
 * @return DeleteLiveRecordTemplateResponse
 */
async function deleteLiveRecordTemplate(request: DeleteLiveRecordTemplateRequest): DeleteLiveRecordTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return deleteLiveRecordTemplateWithOptions(request, runtime);
}

model DeleteLiveSnapshotFilesRequest {
  createTimestampList?: [ long ](name='CreateTimestampList', description='The list of timestamps when the jobs were created. The values are UNIX timestamps representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC. A maximum of 200 jobs can be deleted at a time.

This parameter is required.'),
  deleteOriginalFile?: boolean(name='DeleteOriginalFile', description='Specifies whether to delete the original files at the same time. Default value: false.', example='true'),
  jobId?: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model DeleteLiveSnapshotFilesShrinkRequest {
  createTimestampListShrink?: string(name='CreateTimestampList', description='The list of timestamps when the jobs were created. The values are UNIX timestamps representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC. A maximum of 200 jobs can be deleted at a time.

This parameter is required.'),
  deleteOriginalFile?: boolean(name='DeleteOriginalFile', description='Specifies whether to delete the original files at the same time. Default value: false.', example='true'),
  jobId?: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model DeleteLiveSnapshotFilesResponseBody = {
  deleteFileResultList?: [ 
    {
      createTimestamp?: long(name='CreateTimestamp', description='The time when the file was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1660638613798'),
      result?: string(name='Result', description='The result of deletion. A value of OK indicates that the file is deleted. Other values indicate that the file failed to be deleted.

Valid values:

*   OK: The file was deleted.
*   NotFound: The file was not found.', example='OK'),
    }
  ](name='DeleteFileResultList', description='The list of deleted files.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
}

model DeleteLiveSnapshotFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveSnapshotFilesResponseBody(name='body'),
}

/**
 * @summary Deletes live stream snapshot files. You can choose to delete only the snapshot files or delete both the snapshot files and the original Object Storage Service (OSS) files.
 *
 * @param tmpReq DeleteLiveSnapshotFilesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLiveSnapshotFilesResponse
 */
async function deleteLiveSnapshotFilesWithOptions(tmpReq: DeleteLiveSnapshotFilesRequest, runtime: $RuntimeOptions): DeleteLiveSnapshotFilesResponse {
  tmpReq.validate();
  var request = new DeleteLiveSnapshotFilesShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.createTimestampList)) {
    request.createTimestampListShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.createTimestampList, 'CreateTimestampList', 'json');
  }
  var query = {};
  if (!$isNull(request.createTimestampListShrink)) {
    query['CreateTimestampList'] = request.createTimestampListShrink;
  }
  if (!$isNull(request.deleteOriginalFile)) {
    query['DeleteOriginalFile'] = request.deleteOriginalFile;
  }
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteLiveSnapshotFiles',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes live stream snapshot files. You can choose to delete only the snapshot files or delete both the snapshot files and the original Object Storage Service (OSS) files.
 *
 * @param request DeleteLiveSnapshotFilesRequest
 * @return DeleteLiveSnapshotFilesResponse
 */
async function deleteLiveSnapshotFiles(request: DeleteLiveSnapshotFilesRequest): DeleteLiveSnapshotFilesResponse {
  var runtime = new $RuntimeOptions{};
  return deleteLiveSnapshotFilesWithOptions(request, runtime);
}

model DeleteLiveSnapshotTemplateRequest {
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model DeleteLiveSnapshotTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveSnapshotTemplateResponseBody(name='body'),
}

/**
 * @summary Deletes a live stream snapshot template.
 *
 * @param request DeleteLiveSnapshotTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLiveSnapshotTemplateResponse
 */
async function deleteLiveSnapshotTemplateWithOptions(request: DeleteLiveSnapshotTemplateRequest, runtime: $RuntimeOptions): DeleteLiveSnapshotTemplateResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.templateId)) {
    body['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteLiveSnapshotTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a live stream snapshot template.
 *
 * @param request DeleteLiveSnapshotTemplateRequest
 * @return DeleteLiveSnapshotTemplateResponse
 */
async function deleteLiveSnapshotTemplate(request: DeleteLiveSnapshotTemplateRequest): DeleteLiveSnapshotTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return deleteLiveSnapshotTemplateWithOptions(request, runtime);
}

model DeleteLiveTranscodeJobRequest {
  jobId?: string(name='JobId', description='The ID of the transcoding job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model DeleteLiveTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model DeleteLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveTranscodeJobResponseBody(name='body'),
}

/**
 * @summary 删除指定转码任务
 *
 * @param request DeleteLiveTranscodeJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLiveTranscodeJobResponse
 */
async function deleteLiveTranscodeJobWithOptions(request: DeleteLiveTranscodeJobRequest, runtime: $RuntimeOptions): DeleteLiveTranscodeJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteLiveTranscodeJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 删除指定转码任务
 *
 * @param request DeleteLiveTranscodeJobRequest
 * @return DeleteLiveTranscodeJobResponse
 */
async function deleteLiveTranscodeJob(request: DeleteLiveTranscodeJobRequest): DeleteLiveTranscodeJobResponse {
  var runtime = new $RuntimeOptions{};
  return deleteLiveTranscodeJobWithOptions(request, runtime);
}

model DeleteLiveTranscodeTemplateRequest {
  templateId?: string(name='TemplateId', description='The template ID. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ice.console.aliyun.com/summary), choose Real-time Media Processing > Template Management, and then click the Transcoding tab. Alternatively, find the ID from the response parameters of the [CreateLiveTranscodeTemplate](https://help.aliyun.com/document_detail/449217.html) operation.

This parameter is required.', example='****d80e4e4044975745c14b****'),
}

model DeleteLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model DeleteLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLiveTranscodeTemplateResponseBody(name='body'),
}

/**
 * @summary Deletes a live stream transcoding template.
 *
 * @param request DeleteLiveTranscodeTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteLiveTranscodeTemplateResponse
 */
async function deleteLiveTranscodeTemplateWithOptions(request: DeleteLiveTranscodeTemplateRequest, runtime: $RuntimeOptions): DeleteLiveTranscodeTemplateResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteLiveTranscodeTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a live stream transcoding template.
 *
 * @param request DeleteLiveTranscodeTemplateRequest
 * @return DeleteLiveTranscodeTemplateResponse
 */
async function deleteLiveTranscodeTemplate(request: DeleteLiveTranscodeTemplateRequest): DeleteLiveTranscodeTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return deleteLiveTranscodeTemplateWithOptions(request, runtime);
}

model DeleteMediaConnectFlowRequest {
  flowId?: string(name='FlowId', description='The flow ID.

This parameter is required.', example='0381f478-7d53-4076-9d5f-27680a6f73e7'),
}

model DeleteMediaConnectFlowResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='5AEC17BD-D80B-5F78-BE1B-F07DFA0C8622'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of `0` indicates the call is successful.', example='0'),
}

model DeleteMediaConnectFlowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaConnectFlowResponseBody(name='body'),
}

/**
 * @summary Deletes a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 * *   When a flow is deleted, its source and outputs are also deleted.
 * *   When a flow is in the online state, it cannot be deleted.
 *
 * @param request DeleteMediaConnectFlowRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteMediaConnectFlowResponse
 */
async function deleteMediaConnectFlowWithOptions(request: DeleteMediaConnectFlowRequest, runtime: $RuntimeOptions): DeleteMediaConnectFlowResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.flowId)) {
    query['FlowId'] = request.flowId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteMediaConnectFlow',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 * *   When a flow is deleted, its source and outputs are also deleted.
 * *   When a flow is in the online state, it cannot be deleted.
 *
 * @param request DeleteMediaConnectFlowRequest
 * @return DeleteMediaConnectFlowResponse
 */
async function deleteMediaConnectFlow(request: DeleteMediaConnectFlowRequest): DeleteMediaConnectFlowResponse {
  var runtime = new $RuntimeOptions{};
  return deleteMediaConnectFlowWithOptions(request, runtime);
}

model DeleteMediaConnectFlowInputRequest {
  flowId?: string(name='FlowId', description='The flow ID.

This parameter is required.', example='0381f478-7d53-4076-9d5f-27680a6f73e7'),
}

model DeleteMediaConnectFlowInputResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='C0C02296-113C-5838-8FE9-8F3A32998DDC'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model DeleteMediaConnectFlowInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaConnectFlowInputResponseBody(name='body'),
}

/**
 * @summary Deletes the source of a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 * *   When a flow is in the online state, its source cannot be deleted.
 * *   You can delete the source only after all outputs of the flow have been deleted.
 *
 * @param request DeleteMediaConnectFlowInputRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteMediaConnectFlowInputResponse
 */
async function deleteMediaConnectFlowInputWithOptions(request: DeleteMediaConnectFlowInputRequest, runtime: $RuntimeOptions): DeleteMediaConnectFlowInputResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.flowId)) {
    query['FlowId'] = request.flowId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteMediaConnectFlowInput',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes the source of a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 * *   When a flow is in the online state, its source cannot be deleted.
 * *   You can delete the source only after all outputs of the flow have been deleted.
 *
 * @param request DeleteMediaConnectFlowInputRequest
 * @return DeleteMediaConnectFlowInputResponse
 */
async function deleteMediaConnectFlowInput(request: DeleteMediaConnectFlowInputRequest): DeleteMediaConnectFlowInputResponse {
  var runtime = new $RuntimeOptions{};
  return deleteMediaConnectFlowInputWithOptions(request, runtime);
}

model DeleteMediaConnectFlowOutputRequest {
  flowId?: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f'),
  outputName?: string(name='OutputName', description='The name of the output that you want to delete.

This parameter is required.', example='AliTestOutput'),
}

model DeleteMediaConnectFlowOutputResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='DF73E08E-F807-50F5-A2BD-B76391EAE8FF'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model DeleteMediaConnectFlowOutputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaConnectFlowOutputResponseBody(name='body'),
}

/**
 * @summary Deletes an output of a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 * *   When a flow is in the online state, its outputs cannot be deleted.
 *
 * @param request DeleteMediaConnectFlowOutputRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteMediaConnectFlowOutputResponse
 */
async function deleteMediaConnectFlowOutputWithOptions(request: DeleteMediaConnectFlowOutputRequest, runtime: $RuntimeOptions): DeleteMediaConnectFlowOutputResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.flowId)) {
    query['FlowId'] = request.flowId;
  }
  if (!$isNull(request.outputName)) {
    query['OutputName'] = request.outputName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteMediaConnectFlowOutput',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes an output of a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 * *   When a flow is in the online state, its outputs cannot be deleted.
 *
 * @param request DeleteMediaConnectFlowOutputRequest
 * @return DeleteMediaConnectFlowOutputResponse
 */
async function deleteMediaConnectFlowOutput(request: DeleteMediaConnectFlowOutputRequest): DeleteMediaConnectFlowOutputResponse {
  var runtime = new $RuntimeOptions{};
  return deleteMediaConnectFlowOutputWithOptions(request, runtime);
}

model DeleteMediaFromSearchLibRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
  msgBody?: string(name='MsgBody', description='The message body.', example='{}'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1'),
}

model DeleteMediaFromSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteMediaFromSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaFromSearchLibResponseBody(name='body'),
}

/**
 * @summary Deletes a specific media asset from a search library.
 *
 * @param request DeleteMediaFromSearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteMediaFromSearchLibResponse
 */
async function deleteMediaFromSearchLibWithOptions(request: DeleteMediaFromSearchLibRequest, runtime: $RuntimeOptions): DeleteMediaFromSearchLibResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.msgBody)) {
    query['MsgBody'] = request.msgBody;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteMediaFromSearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a specific media asset from a search library.
 *
 * @param request DeleteMediaFromSearchLibRequest
 * @return DeleteMediaFromSearchLibResponse
 */
async function deleteMediaFromSearchLib(request: DeleteMediaFromSearchLibRequest): DeleteMediaFromSearchLibResponse {
  var runtime = new $RuntimeOptions{};
  return deleteMediaFromSearchLibWithOptions(request, runtime);
}

model DeleteMediaInfosRequest {
  deletePhysicalFiles?: boolean(name='DeletePhysicalFiles', description='Specifies whether to delete the physical file of the media asset.

If the media asset is stored in your own OSS bucket, you must authorize the service role AliyunICEDefaultRole in advance. For more information<props="china">, see [Authorize IMS to delete recording files in OSS](https://help.aliyun.com/zh/ims/user-guide/record?spm=a2c4g.11186623.0.i8#0737d9c437bmn).', example='false'),
  inputURLs?: string(name='InputURLs', description='The URL of the media asset that you want to delete. The file corresponding to the URL must be registered with IMS. Separate multiple URLs with commas (,). The following two formats are supported:

1.  http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?
2.  OSS://example-bucket/example.mp4?\\\\
    In this format, it is considered by default that the region of the OSS bucket in which the media asset resides is the same as the region in which IMS is activated.'),
  mediaIds?: string(name='MediaIds', description='The ID of the media asset that you want to delete from Intelligent Media Services (IMS).

*   Separate multiple IDs with commas (,).

If you leave MediaIds empty, you must specify InputURLs.', example='****20b48fb04483915d4f2cd8ac****,****15d4a4b0448391508f2cb486****'),
}

model DeleteMediaInfosResponseBody = {
  forbiddenList?: [ string ](name='ForbiddenList', description='The IDs or URLs of media assets that cannot be deleted. Generally, media assets cannot be deleted if you do not have the required permissions.'),
  ignoredList?: [ string ](name='IgnoredList', description='The IDs or URLs of ignored media assets. An error occurred while obtaining such media assets.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
}

model DeleteMediaInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaInfosResponseBody(name='body'),
}

/**
 * @summary Deletes multiple media assets at a time. You can delete at most 20 media assets at a time. If MediaIds is specified, it is preferentially used. If MediaIds is empty, InputURLs must be specified.
 *
 * @param request DeleteMediaInfosRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteMediaInfosResponse
 */
async function deleteMediaInfosWithOptions(request: DeleteMediaInfosRequest, runtime: $RuntimeOptions): DeleteMediaInfosResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.deletePhysicalFiles)) {
    query['DeletePhysicalFiles'] = request.deletePhysicalFiles;
  }
  if (!$isNull(request.inputURLs)) {
    query['InputURLs'] = request.inputURLs;
  }
  if (!$isNull(request.mediaIds)) {
    query['MediaIds'] = request.mediaIds;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteMediaInfos',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes multiple media assets at a time. You can delete at most 20 media assets at a time. If MediaIds is specified, it is preferentially used. If MediaIds is empty, InputURLs must be specified.
 *
 * @param request DeleteMediaInfosRequest
 * @return DeleteMediaInfosResponse
 */
async function deleteMediaInfos(request: DeleteMediaInfosRequest): DeleteMediaInfosResponse {
  var runtime = new $RuntimeOptions{};
  return deleteMediaInfosWithOptions(request, runtime);
}

model DeleteMediaLiveChannelRequest {
  channelId?: string(name='ChannelId', description='The ID of the channel.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
}

model DeleteMediaLiveChannelResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteMediaLiveChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaLiveChannelResponseBody(name='body'),
}

/**
 * @summary Deletes a MediaLive channel.
 *
 * @description *  You can only delete a channel that is not running.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request DeleteMediaLiveChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteMediaLiveChannelResponse
 */
async function deleteMediaLiveChannelWithOptions(request: DeleteMediaLiveChannelRequest, runtime: $RuntimeOptions): DeleteMediaLiveChannelResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.channelId)) {
    body['ChannelId'] = request.channelId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteMediaLiveChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a MediaLive channel.
 *
 * @description *  You can only delete a channel that is not running.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request DeleteMediaLiveChannelRequest
 * @return DeleteMediaLiveChannelResponse
 */
async function deleteMediaLiveChannel(request: DeleteMediaLiveChannelRequest): DeleteMediaLiveChannelResponse {
  var runtime = new $RuntimeOptions{};
  return deleteMediaLiveChannelWithOptions(request, runtime);
}

model DeleteMediaLiveInputRequest {
  inputId?: string(name='InputId', description='The ID of the input.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
}

model DeleteMediaLiveInputResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteMediaLiveInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaLiveInputResponseBody(name='body'),
}

/**
 * @summary Deletes a MediaLive input.
 *
 * @description *   You can delete an input only when it is not associated with a MediaLive channel.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request DeleteMediaLiveInputRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteMediaLiveInputResponse
 */
async function deleteMediaLiveInputWithOptions(request: DeleteMediaLiveInputRequest, runtime: $RuntimeOptions): DeleteMediaLiveInputResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.inputId)) {
    body['InputId'] = request.inputId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteMediaLiveInput',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a MediaLive input.
 *
 * @description *   You can delete an input only when it is not associated with a MediaLive channel.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request DeleteMediaLiveInputRequest
 * @return DeleteMediaLiveInputResponse
 */
async function deleteMediaLiveInput(request: DeleteMediaLiveInputRequest): DeleteMediaLiveInputResponse {
  var runtime = new $RuntimeOptions{};
  return deleteMediaLiveInputWithOptions(request, runtime);
}

model DeleteMediaLiveInputSecurityGroupRequest {
  securityGroupId?: string(name='SecurityGroupId', description='The ID of the security group.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
}

model DeleteMediaLiveInputSecurityGroupResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteMediaLiveInputSecurityGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaLiveInputSecurityGroupResponseBody(name='body'),
}

/**
 * @summary Deletes a security group in MediaLive.
 *
 * @description *   You can only delete a security group not associated with an input.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request DeleteMediaLiveInputSecurityGroupRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteMediaLiveInputSecurityGroupResponse
 */
async function deleteMediaLiveInputSecurityGroupWithOptions(request: DeleteMediaLiveInputSecurityGroupRequest, runtime: $RuntimeOptions): DeleteMediaLiveInputSecurityGroupResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.securityGroupId)) {
    body['SecurityGroupId'] = request.securityGroupId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteMediaLiveInputSecurityGroup',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a security group in MediaLive.
 *
 * @description *   You can only delete a security group not associated with an input.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request DeleteMediaLiveInputSecurityGroupRequest
 * @return DeleteMediaLiveInputSecurityGroupResponse
 */
async function deleteMediaLiveInputSecurityGroup(request: DeleteMediaLiveInputSecurityGroupRequest): DeleteMediaLiveInputSecurityGroupResponse {
  var runtime = new $RuntimeOptions{};
  return deleteMediaLiveInputSecurityGroupWithOptions(request, runtime);
}

model DeleteMediaMarksRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****c469e944b5a856828dc2****'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The mark ID. You can specify multiple mark IDs separated with commas (,).

If you do not specify MediaMarkIds, all the marks of the media asset are deleted.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
}

model DeleteMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The IDs of the deleted marks separated with commas (,).', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMediaMarksResponseBody(name='body'),
}

/**
 * @summary Deletes the marks of a media asset.
 *
 * @param request DeleteMediaMarksRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteMediaMarksResponse
 */
async function deleteMediaMarksWithOptions(request: DeleteMediaMarksRequest, runtime: $RuntimeOptions): DeleteMediaMarksResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.mediaMarkIds)) {
    query['MediaMarkIds'] = request.mediaMarkIds;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteMediaMarks',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes the marks of a media asset.
 *
 * @param request DeleteMediaMarksRequest
 * @return DeleteMediaMarksResponse
 */
async function deleteMediaMarks(request: DeleteMediaMarksRequest): DeleteMediaMarksResponse {
  var runtime = new $RuntimeOptions{};
  return deleteMediaMarksWithOptions(request, runtime);
}

model DeletePipelineRequest {
  pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.

This parameter is required.', example='****96e8864746a0b6f3****'),
}

model DeletePipelineResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeletePipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeletePipelineResponseBody(name='body'),
}

/**
 * @summary Deletes an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request DeletePipelineRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeletePipelineResponse
 */
async function deletePipelineWithOptions(request: DeletePipelineRequest, runtime: $RuntimeOptions): DeletePipelineResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.pipelineId)) {
    query['PipelineId'] = request.pipelineId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeletePipeline',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request DeletePipelineRequest
 * @return DeletePipelineResponse
 */
async function deletePipeline(request: DeletePipelineRequest): DeletePipelineResponse {
  var runtime = new $RuntimeOptions{};
  return deletePipelineWithOptions(request, runtime);
}

model DeletePlayInfoRequest {
  deletePhysicalFiles?: boolean(name='DeletePhysicalFiles', description='Specifies whether to delete the physical file of the media stream.

If the media asset is stored in your own Object Storage Service (OSS) bucket, you must authorize the service role AliyunICEDefaultRole in advance. <props="china">For more information, see [Authorize IMS to delete recording files in OSS](https://help.aliyun.com/document_detail/449331.html#p-ko2-wc7-iad).

You can delete only the physical files of transcoded streams, but not the physical files of source files.', example='false'),
  fileURLs?: string(name='FileURLs', description='The URL of the media stream file that you want to delete. Separate multiple URLs with commas (,).', example='https://ice-test001.oss-cn-shanghai.aliyuncs.com/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95/%E5%B0%8F%E7%8C%AA%E4%BD%A9%E5%A5%87640*360.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='1d3518e0027d71ed80cd909598416303'),
}

model DeletePlayInfoResponseBody = {
  forbiddenList?: [ string ](name='ForbiddenList', description='The URLs of the media streams that cannot be deleted. Generally, media streams cannot be deleted if you do not have the required permissions.'),
  ignoredList?: [ string ](name='IgnoredList', description='The URLs of ignored media streams. An error occurred while obtaining such media assets because the IDs or URLs of the media assets do not exist.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeletePlayInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeletePlayInfoResponseBody(name='body'),
}

/**
 * @summary Deletes media streams such as video streams and audio streams.
 *
 * @description You can call this operation to delete multiple media streams at a time.
 *
 * @param request DeletePlayInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeletePlayInfoResponse
 */
async function deletePlayInfoWithOptions(request: DeletePlayInfoRequest, runtime: $RuntimeOptions): DeletePlayInfoResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.deletePhysicalFiles)) {
    query['DeletePhysicalFiles'] = request.deletePhysicalFiles;
  }
  if (!$isNull(request.fileURLs)) {
    query['FileURLs'] = request.fileURLs;
  }
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeletePlayInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes media streams such as video streams and audio streams.
 *
 * @description You can call this operation to delete multiple media streams at a time.
 *
 * @param request DeletePlayInfoRequest
 * @return DeletePlayInfoResponse
 */
async function deletePlayInfo(request: DeletePlayInfoRequest): DeletePlayInfoResponse {
  var runtime = new $RuntimeOptions{};
  return deletePlayInfoWithOptions(request, runtime);
}

model DeleteProgramRequest {
  channelName?: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel'),
  programName?: string(name='ProgramName', description='The name of the program.

This parameter is required.', example='program_name'),
}

model DeleteProgramResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteProgramResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteProgramResponseBody(name='body'),
}

/**
 * @summary Deletes a program from a channel.
 *
 * @param request DeleteProgramRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteProgramResponse
 */
async function deleteProgramWithOptions(request: DeleteProgramRequest, runtime: $RuntimeOptions): DeleteProgramResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.programName)) {
    query['ProgramName'] = request.programName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteProgram',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a program from a channel.
 *
 * @param request DeleteProgramRequest
 * @return DeleteProgramResponse
 */
async function deleteProgram(request: DeleteProgramRequest): DeleteProgramResponse {
  var runtime = new $RuntimeOptions{};
  return deleteProgramWithOptions(request, runtime);
}

model DeleteSmartJobRequest {
  jobId?: string(name='JobId', description='The IDs of the jobs to delete. Separate multiple IDs with commas (,).', example='******b48fb04483915d4f2cd8******,******042d5e4db6866f6289d1******'),
}

model DeleteSmartJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteSmartJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteSmartJobResponseBody(name='body'),
}

/**
 * @summary Deletes intelligent jobs based on job IDs.
 *
 * @param request DeleteSmartJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteSmartJobResponse
 */
async function deleteSmartJobWithOptions(request: DeleteSmartJobRequest, runtime: $RuntimeOptions): DeleteSmartJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteSmartJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes intelligent jobs based on job IDs.
 *
 * @param request DeleteSmartJobRequest
 * @return DeleteSmartJobResponse
 */
async function deleteSmartJob(request: DeleteSmartJobRequest): DeleteSmartJobResponse {
  var runtime = new $RuntimeOptions{};
  return deleteSmartJobWithOptions(request, runtime);
}

model DeleteSourceRequest {
  softDelete?: boolean(name='SoftDelete', description='Specifies whether to use delete markers.', example='true'),
  sourceLocationName?: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourceLocation'),
  sourceName?: string(name='SourceName', description='The name of the source.

This parameter is required.', example='MyVodSource'),
  sourceType?: string(name='SourceType', description='The source type. Valid values: vodSource and liveSource.

This parameter is required.', example='vodSource'),
}

model DeleteSourceResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteSourceResponseBody(name='body'),
}

/**
 * @summary Deletes a source from MediaWeaver.
 *
 * @param request DeleteSourceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteSourceResponse
 */
async function deleteSourceWithOptions(request: DeleteSourceRequest, runtime: $RuntimeOptions): DeleteSourceResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.softDelete)) {
    query['SoftDelete'] = request.softDelete;
  }
  if (!$isNull(request.sourceLocationName)) {
    query['SourceLocationName'] = request.sourceLocationName;
  }
  if (!$isNull(request.sourceName)) {
    query['SourceName'] = request.sourceName;
  }
  if (!$isNull(request.sourceType)) {
    query['SourceType'] = request.sourceType;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteSource',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a source from MediaWeaver.
 *
 * @param request DeleteSourceRequest
 * @return DeleteSourceResponse
 */
async function deleteSource(request: DeleteSourceRequest): DeleteSourceResponse {
  var runtime = new $RuntimeOptions{};
  return deleteSourceWithOptions(request, runtime);
}

model DeleteSourceLocationRequest {
  softDelete?: boolean(name='SoftDelete', description='Specifies whether to use delete markers.', example='true'),
  sourceLocationName?: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourceLocation'),
}

model DeleteSourceLocationResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid value:

*   true: The request succeeded.
*   false: The request failed.', example='true'),
}

model DeleteSourceLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteSourceLocationResponseBody(name='body'),
}

/**
 * @summary Deletes a source location.
 *
 * @param request DeleteSourceLocationRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteSourceLocationResponse
 */
async function deleteSourceLocationWithOptions(request: DeleteSourceLocationRequest, runtime: $RuntimeOptions): DeleteSourceLocationResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.softDelete)) {
    query['SoftDelete'] = request.softDelete;
  }
  if (!$isNull(request.sourceLocationName)) {
    query['SourceLocationName'] = request.sourceLocationName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteSourceLocation',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a source location.
 *
 * @param request DeleteSourceLocationRequest
 * @return DeleteSourceLocationResponse
 */
async function deleteSourceLocation(request: DeleteSourceLocationRequest): DeleteSourceLocationResponse {
  var runtime = new $RuntimeOptions{};
  return deleteSourceLocationWithOptions(request, runtime);
}

model DeleteTemplateRequest {
  templateIds?: string(name='TemplateIds', description='The IDs of the templates that you want to delete. Separate multiple IDs with commas (,).', example='****20b48fb04483915d4f2cd8ac****,****20b48fb04483915d4f2cd8ac****'),
}

model DeleteTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteTemplateResponseBody(name='body'),
}

/**
 * @summary Deletes templates.
 *
 * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
 * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request DeleteTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteTemplateResponse
 */
async function deleteTemplateWithOptions(request: DeleteTemplateRequest, runtime: $RuntimeOptions): DeleteTemplateResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes templates.
 *
 * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
 * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request DeleteTemplateRequest
 * @return DeleteTemplateResponse
 */
async function deleteTemplate(request: DeleteTemplateRequest): DeleteTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return deleteTemplateWithOptions(request, runtime);
}

model DeleteVodPackagingAssetRequest {
  assetName?: string(name='AssetName', description='The name of the VOD packaging asset.', example='30min_movie'),
}

model DeleteVodPackagingAssetResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteVodPackagingAssetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteVodPackagingAssetResponseBody(name='body'),
}

/**
 * @summary Deletes a VOD packaging asset.
 *
 * @param request DeleteVodPackagingAssetRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteVodPackagingAssetResponse
 */
async function deleteVodPackagingAssetWithOptions(request: DeleteVodPackagingAssetRequest, runtime: $RuntimeOptions): DeleteVodPackagingAssetResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.assetName)) {
    query['AssetName'] = request.assetName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteVodPackagingAsset',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a VOD packaging asset.
 *
 * @param request DeleteVodPackagingAssetRequest
 * @return DeleteVodPackagingAssetResponse
 */
async function deleteVodPackagingAsset(request: DeleteVodPackagingAssetRequest): DeleteVodPackagingAssetResponse {
  var runtime = new $RuntimeOptions{};
  return deleteVodPackagingAssetWithOptions(request, runtime);
}

model DeleteVodPackagingConfigurationRequest {
  configurationName?: string(name='ConfigurationName', description='The name of the packaging configuration.', example='hls_3s'),
}

model DeleteVodPackagingConfigurationResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model DeleteVodPackagingConfigurationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteVodPackagingConfigurationResponseBody(name='body'),
}

/**
 * @summary Deletes a packaging configuration.
 *
 * @param request DeleteVodPackagingConfigurationRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteVodPackagingConfigurationResponse
 */
async function deleteVodPackagingConfigurationWithOptions(request: DeleteVodPackagingConfigurationRequest, runtime: $RuntimeOptions): DeleteVodPackagingConfigurationResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.configurationName)) {
    query['ConfigurationName'] = request.configurationName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteVodPackagingConfiguration',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a packaging configuration.
 *
 * @param request DeleteVodPackagingConfigurationRequest
 * @return DeleteVodPackagingConfigurationResponse
 */
async function deleteVodPackagingConfiguration(request: DeleteVodPackagingConfigurationRequest): DeleteVodPackagingConfigurationResponse {
  var runtime = new $RuntimeOptions{};
  return deleteVodPackagingConfigurationWithOptions(request, runtime);
}

model DeleteVodPackagingGroupRequest {
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls'),
}

model DeleteVodPackagingGroupResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='13cbb83e-043c-4728-ac35-*****'),
}

model DeleteVodPackagingGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteVodPackagingGroupResponseBody(name='body'),
}

/**
 * @summary Deletes a packaging group.
 *
 * @param request DeleteVodPackagingGroupRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteVodPackagingGroupResponse
 */
async function deleteVodPackagingGroupWithOptions(request: DeleteVodPackagingGroupRequest, runtime: $RuntimeOptions): DeleteVodPackagingGroupResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DeleteVodPackagingGroup',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a packaging group.
 *
 * @param request DeleteVodPackagingGroupRequest
 * @return DeleteVodPackagingGroupResponse
 */
async function deleteVodPackagingGroup(request: DeleteVodPackagingGroupRequest): DeleteVodPackagingGroupResponse {
  var runtime = new $RuntimeOptions{};
  return deleteVodPackagingGroupWithOptions(request, runtime);
}

model DescribeAIAgentInstanceRequest {
  instanceId?: string(name='InstanceId', description='The ID of the AI agent that you want to query.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
}

model DescribeAIAgentInstanceResponseBody = {
  instance?: {
    callLogUrl?: string(name='CallLogUrl', description='The URL of the call log file.', example='https://example.com/call_logs/12345'),
    runtimeConfig?: AIAgentRuntimeConfig(name='RuntimeConfig', description='The runtime configurations of the AI agent.', example='{"VoiceChat":{"AgentUserId":"voice_agent_001","ChannelId":"voice_channel_001","AuthToken":"your_voice_chat_auth_token"}}'),
    sessionId?: string(name='SessionId'),
    status?: string(name='Status', description='The state of the AI agent. Valid values: Finished and Executing.', example='Finished'),
    templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', description='The template configurations of the AI agent.', example='{"VoiceChat": {"AppId": "your_voice_chat_app_id"}}'),
    userData?: string(name='UserData', description='The custom information.', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
  }(name='Instance', description='The information about the AI agent.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model DescribeAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAIAgentInstanceResponseBody(name='body'),
}

/**
 * @summary Queries the information about an AI agent.
 *
 * @description ## [](#)Request description
 * *   **Feature**: You can call this operation to query the information about an AI agent.
 * *   **Scenario**: If you need to monitor or analyze the performance of an AI agent in a call or debug the agent configurations, you can call this operation to obtain required data.
 *
 * @param request DescribeAIAgentInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeAIAgentInstanceResponse
 */
async function describeAIAgentInstanceWithOptions(request: DescribeAIAgentInstanceRequest, runtime: $RuntimeOptions): DescribeAIAgentInstanceResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DescribeAIAgentInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about an AI agent.
 *
 * @description ## [](#)Request description
 * *   **Feature**: You can call this operation to query the information about an AI agent.
 * *   **Scenario**: If you need to monitor or analyze the performance of an AI agent in a call or debug the agent configurations, you can call this operation to obtain required data.
 *
 * @param request DescribeAIAgentInstanceRequest
 * @return DescribeAIAgentInstanceResponse
 */
async function describeAIAgentInstance(request: DescribeAIAgentInstanceRequest): DescribeAIAgentInstanceResponse {
  var runtime = new $RuntimeOptions{};
  return describeAIAgentInstanceWithOptions(request, runtime);
}

model DescribeMeterImsEditUsageRequest {
  endTs?: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1656995036'),
  interval?: long(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='86400'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai'),
  startTs?: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1654403036'),
}

model DescribeMeterImsEditUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='1.23'),
      profile?: string(name='Profile', description='The video profile.', example='1080P'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
    }
  ](name='Data', description='The usage statistics of IMS on VOD editing.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7F3AE2C6-5CC6-5712-BAC5-5A735A157687'),
}

model DescribeMeterImsEditUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsEditUsageResponseBody(name='body'),
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on video-on-demand (VOD) editing. The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsEditUsageRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeMeterImsEditUsageResponse
 */
async function describeMeterImsEditUsageWithOptions(request: DescribeMeterImsEditUsageRequest, runtime: $RuntimeOptions): DescribeMeterImsEditUsageResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endTs)) {
    query['EndTs'] = request.endTs;
  }
  if (!$isNull(request.interval)) {
    query['Interval'] = request.interval;
  }
  if (!$isNull(request.region)) {
    query['Region'] = request.region;
  }
  if (!$isNull(request.startTs)) {
    query['StartTs'] = request.startTs;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DescribeMeterImsEditUsage',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on video-on-demand (VOD) editing. The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsEditUsageRequest
 * @return DescribeMeterImsEditUsageResponse
 */
async function describeMeterImsEditUsage(request: DescribeMeterImsEditUsageRequest): DescribeMeterImsEditUsageResponse {
  var runtime = new $RuntimeOptions{};
  return describeMeterImsEditUsageWithOptions(request, runtime);
}

model DescribeMeterImsMediaConvertUHDUsageRequest {
  endTs?: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1656995036'),
  interval?: string(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='3600'),
  regionId?: string(name='RegionId', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai'),
  startTs?: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1654403036'),
}

model DescribeMeterImsMediaConvertUHDUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='308028'),
      specification?: string(name='Specification', description='The transcoding specifications.', example='SuperResolution.Standard.1080P'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
    }
  ](name='Data', description='The usage statistics of IMS on UHD transcoding of MPS.'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
}

model DescribeMeterImsMediaConvertUHDUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsMediaConvertUHDUsageResponseBody(name='body'),
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on ultra high definition (UHD) transcoding of ApsaraVideo Media Processing (MPS). The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsMediaConvertUHDUsageRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeMeterImsMediaConvertUHDUsageResponse
 */
async function describeMeterImsMediaConvertUHDUsageWithOptions(request: DescribeMeterImsMediaConvertUHDUsageRequest, runtime: $RuntimeOptions): DescribeMeterImsMediaConvertUHDUsageResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endTs)) {
    query['EndTs'] = request.endTs;
  }
  if (!$isNull(request.interval)) {
    query['Interval'] = request.interval;
  }
  if (!$isNull(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!$isNull(request.startTs)) {
    query['StartTs'] = request.startTs;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DescribeMeterImsMediaConvertUHDUsage',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on ultra high definition (UHD) transcoding of ApsaraVideo Media Processing (MPS). The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsMediaConvertUHDUsageRequest
 * @return DescribeMeterImsMediaConvertUHDUsageResponse
 */
async function describeMeterImsMediaConvertUHDUsage(request: DescribeMeterImsMediaConvertUHDUsageRequest): DescribeMeterImsMediaConvertUHDUsageResponse {
  var runtime = new $RuntimeOptions{};
  return describeMeterImsMediaConvertUHDUsageWithOptions(request, runtime);
}

model DescribeMeterImsMediaConvertUsageRequest {
  endTs?: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp. The maximum query range is 31 days. The duration between StartTs and EndTs cannot exceed 31 days.

This parameter is required.', example='1656995036'),
  interval?: long(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='86400'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai'),
  startTs?: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp. You can query data within the last 90 days.

This parameter is required.', example='1654403036'),
}

model DescribeMeterImsMediaConvertUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='20'),
      specification?: string(name='Specification', description='The transcoding specifications.', example='H264.HD'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
    }
  ](name='Data', description='The usage statistics of IMS on VOD transcoding.'),
  requestId?: string(name='RequestId', description='The request ID.', example='FBBB5210-2B78-58FB-A6FE-9DD887BB2C61'),
}

model DescribeMeterImsMediaConvertUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsMediaConvertUsageResponseBody(name='body'),
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on video-on-demand (VOD) transcoding. The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsMediaConvertUsageRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeMeterImsMediaConvertUsageResponse
 */
async function describeMeterImsMediaConvertUsageWithOptions(request: DescribeMeterImsMediaConvertUsageRequest, runtime: $RuntimeOptions): DescribeMeterImsMediaConvertUsageResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endTs)) {
    query['EndTs'] = request.endTs;
  }
  if (!$isNull(request.interval)) {
    query['Interval'] = request.interval;
  }
  if (!$isNull(request.region)) {
    query['Region'] = request.region;
  }
  if (!$isNull(request.startTs)) {
    query['StartTs'] = request.startTs;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DescribeMeterImsMediaConvertUsage',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on video-on-demand (VOD) transcoding. The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsMediaConvertUsageRequest
 * @return DescribeMeterImsMediaConvertUsageResponse
 */
async function describeMeterImsMediaConvertUsage(request: DescribeMeterImsMediaConvertUsageRequest): DescribeMeterImsMediaConvertUsageResponse {
  var runtime = new $RuntimeOptions{};
  return describeMeterImsMediaConvertUsageWithOptions(request, runtime);
}

model DescribeMeterImsMpsAiUsageRequest {
  endTs?: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp. The maximum query range is 31 days. The duration between StartTs and EndTs cannot exceed 31 days.

This parameter is required.', example='1656995036'),
  interval?: long(name='Interval', description='The time granularity of the query. Valid values: 3600 (hour) and 86400 (day).

This parameter is required.', example='86400'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai'),
  startTs?: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp. You can query data within the last 90 days.

This parameter is required.', example='1654403036'),
}

model DescribeMeterImsMpsAiUsageResponseBody = {
  data?: [ 
    {
      duration?: long(name='Duration', description='The usage duration, in minutes.', example='644'),
      time?: long(name='Time', description='The beginning time of usage. The value is a 10-digit timestamp.', example='1656950400'),
      type?: string(name='Type', description='The AI type. Valid values:'),
    }
  ](name='Data', description='The usage statistics of IMS on AI processing of MPS.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
}

model DescribeMeterImsMpsAiUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsMpsAiUsageResponseBody(name='body'),
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on AI processing of ApsaraVideo Media Processing (MPS). The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsMpsAiUsageRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeMeterImsMpsAiUsageResponse
 */
async function describeMeterImsMpsAiUsageWithOptions(request: DescribeMeterImsMpsAiUsageRequest, runtime: $RuntimeOptions): DescribeMeterImsMpsAiUsageResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endTs)) {
    query['EndTs'] = request.endTs;
  }
  if (!$isNull(request.interval)) {
    query['Interval'] = request.interval;
  }
  if (!$isNull(request.region)) {
    query['Region'] = request.region;
  }
  if (!$isNull(request.startTs)) {
    query['StartTs'] = request.startTs;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DescribeMeterImsMpsAiUsage',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS) on AI processing of ApsaraVideo Media Processing (MPS). The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsMpsAiUsageRequest
 * @return DescribeMeterImsMpsAiUsageResponse
 */
async function describeMeterImsMpsAiUsage(request: DescribeMeterImsMpsAiUsageRequest): DescribeMeterImsMpsAiUsageResponse {
  var runtime = new $RuntimeOptions{};
  return describeMeterImsMpsAiUsageWithOptions(request, runtime);
}

model DescribeMeterImsSummaryRequest {
  endTs?: long(name='EndTs', description='The end of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1656995036'),
  region?: string(name='Region', description='This parameter does not take effect. By default, the usage data of all regions is returned.', example='cn-shanghai'),
  startTs?: long(name='StartTs', description='The beginning of the time range to query. The value is a 10-digit timestamp.

This parameter is required.', example='1654403036'),
}

model DescribeMeterImsSummaryResponseBody = {
  data?: [ 
    {
      editingDuration?: string(name='EditingDuration', description='The duration of video editing.', example='8722'),
      liveEditDuration?: string(name='LiveEditDuration', description='The duration of live editing.', example='2000'),
      liveRecordDuration?: string(name='LiveRecordDuration', description='The duration of live stream recording.', example='100'),
      liveSnapshotCount?: string(name='LiveSnapshotCount', description='The number of live stream snapshots.', example='100'),
      liveTranscodeDuration?: long(name='LiveTranscodeDuration', description='The duration of live stream transcoding.', example='12356'),
      mpsAiDuration?: long(name='MpsAiDuration', description='The duration of AI processing.', example='0'),
      mpsTranscodeDuration?: long(name='MpsTranscodeDuration', description='The duration of video-on-demand (VOD) transcoding.', example='17337'),
      mpsTranscodeUHDDuration?: long(name='MpsTranscodeUHDDuration', description='The duration of audio and video enhancement.', example='300'),
    }
  ](name='Data', description='The usage statistics of IMS.'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
}

model DescribeMeterImsSummaryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeMeterImsSummaryResponseBody(name='body'),
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS). The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsSummaryRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeMeterImsSummaryResponse
 */
async function describeMeterImsSummaryWithOptions(request: DescribeMeterImsSummaryRequest, runtime: $RuntimeOptions): DescribeMeterImsSummaryResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endTs)) {
    query['EndTs'] = request.endTs;
  }
  if (!$isNull(request.region)) {
    query['Region'] = request.region;
  }
  if (!$isNull(request.startTs)) {
    query['StartTs'] = request.startTs;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DescribeMeterImsSummary',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the usage statistics of Intelligent Media Services (IMS). The maximum query range is 31 days. You can query data within the last 90 days.
 *
 * @param request DescribeMeterImsSummaryRequest
 * @return DescribeMeterImsSummaryResponse
 */
async function describeMeterImsSummary(request: DescribeMeterImsSummaryRequest): DescribeMeterImsSummaryResponse {
  var runtime = new $RuntimeOptions{};
  return describeMeterImsSummaryWithOptions(request, runtime);
}

model DescribeNotifyConfigRequest {
  AIAgentId?: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
}

model DescribeNotifyConfigResponseBody = {
  callbackUrl?: string(name='CallbackUrl', example='http://customer.com/callback'),
  enableNotify?: boolean(name='EnableNotify', example='true'),
  eventTypes?: string(name='EventTypes', description='The event types. If this parameter is empty, all event types are selected.

*   agent_start: The agent is started.
*   agent_stop: The agent is stopped.
*   error: An error occurred.', example='agent_start,agent_stop,error'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
  token?: string(name='Token', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx'),
}

model DescribeNotifyConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeNotifyConfigResponseBody(name='body'),
}

/**
 * @summary Queries the event callback configurations of an AI agent.
 *
 * @description You can call this operation to query the detailed callback configurations of an AI agent.
 *
 * @param request DescribeNotifyConfigRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeNotifyConfigResponse
 */
async function describeNotifyConfigWithOptions(request: DescribeNotifyConfigRequest, runtime: $RuntimeOptions): DescribeNotifyConfigResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.AIAgentId)) {
    query['AIAgentId'] = request.AIAgentId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DescribeNotifyConfig',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the event callback configurations of an AI agent.
 *
 * @description You can call this operation to query the detailed callback configurations of an AI agent.
 *
 * @param request DescribeNotifyConfigRequest
 * @return DescribeNotifyConfigResponse
 */
async function describeNotifyConfig(request: DescribeNotifyConfigRequest): DescribeNotifyConfigResponse {
  var runtime = new $RuntimeOptions{};
  return describeNotifyConfigWithOptions(request, runtime);
}

model DescribePlayListRequest {
  beginTs?: string(name='BeginTs', description='This parameter is required.', example='1676170500011'),
  endTs?: string(name='EndTs', description='This parameter is required.', example='1682474405173'),
  orderName?: string(name='OrderName', example='FirstFrameDuration'),
  orderType?: string(name='OrderType', example='DESC'),
  pageNo?: int32(name='PageNo', description='This parameter is required.', example='1'),
  pageSize?: int32(name='PageSize', description='This parameter is required.', example='10'),
  playType?: string(name='PlayType', example='vod'),
  status?: string(name='Status', example='complete'),
  traceId?: string(name='TraceId', example='0bc5e70516766285805381012d271e'),
}

model DescribePlayListResponseBody = {
  pageNum?: long(name='PageNum', example='1'),
  pageSize?: long(name='PageSize', example='10'),
  playList?: [ 
    {
      firstFrameDuration?: string(name='FirstFrameDuration', example='200'),
      playDuration?: string(name='PlayDuration', example='1000'),
      playTs?: string(name='PlayTs', example='1675922209572'),
      playType?: string(name='PlayType', example='vod'),
      sessionId?: string(name='SessionId', example='91488be2-8381-40c9-8494-e8afe22c4a2d'),
      status?: string(name='Status', example='complete'),
      stuckDuration?: string(name='StuckDuration', example='20'),
      traceId?: string(name='TraceId', example='0b736abf16724820210842673d9543'),
      videoDuration?: string(name='VideoDuration', example='2000'),
      videoId?: string(name='VideoId', example='250314203f0171eebff17035d0b20102'),
    }
  ](name='PlayList'),
  requestId?: string(name='RequestId', description='Id', example='B960580D-26FA-5547-8AFC-3CDC812DBF27'),
  totalNum?: long(name='TotalNum', example='49'),
}

model DescribePlayListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribePlayListResponseBody(name='body'),
}

/**
 * @param request DescribePlayListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribePlayListResponse
 */
async function describePlayListWithOptions(request: DescribePlayListRequest, runtime: $RuntimeOptions): DescribePlayListResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.beginTs)) {
    query['BeginTs'] = request.beginTs;
  }
  if (!$isNull(request.endTs)) {
    query['EndTs'] = request.endTs;
  }
  if (!$isNull(request.orderName)) {
    query['OrderName'] = request.orderName;
  }
  if (!$isNull(request.orderType)) {
    query['OrderType'] = request.orderType;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.playType)) {
    query['PlayType'] = request.playType;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  if (!$isNull(request.traceId)) {
    query['TraceId'] = request.traceId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DescribePlayList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @param request DescribePlayListRequest
 * @return DescribePlayListResponse
 */
async function describePlayList(request: DescribePlayListRequest): DescribePlayListResponse {
  var runtime = new $RuntimeOptions{};
  return describePlayListWithOptions(request, runtime);
}

model DescribeRtcRobotInstanceRequest {
  instanceId?: string(name='InstanceId', example='727dc0e296014bb58670940a3da95592'),
}

model DescribeRtcRobotInstanceResponseBody = {
  authToken?: string(name='AuthToken', example='**********'),
  channelId?: string(name='ChannelId', example='testId'),
  config?: {
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt', example='true'),
    greeting?: string(name='Greeting'),
    voiceId?: string(name='VoiceId', example='zhixiaoxia'),
  }(name='Config'),
  requestId?: string(name='RequestId', description='Id of the request', example='20B3A1B6-4BD2-5DE6-BCBC-098C9B4F4E91'),
  status?: string(name='Status', example='Executing'),
  userData?: string(name='UserData', example='{}'),
  userId?: string(name='UserId', example='my-robot'),
}

model DescribeRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeRtcRobotInstanceResponseBody(name='body'),
}

/**
 * @summary 查询实例
 *
 * @param request DescribeRtcRobotInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DescribeRtcRobotInstanceResponse
 */
async function describeRtcRobotInstanceWithOptions(request: DescribeRtcRobotInstanceRequest, runtime: $RuntimeOptions): DescribeRtcRobotInstanceResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DescribeRtcRobotInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 查询实例
 *
 * @param request DescribeRtcRobotInstanceRequest
 * @return DescribeRtcRobotInstanceResponse
 */
async function describeRtcRobotInstance(request: DescribeRtcRobotInstanceRequest): DescribeRtcRobotInstanceResponse {
  var runtime = new $RuntimeOptions{};
  return describeRtcRobotInstanceWithOptions(request, runtime);
}

model DetectAudioForCustomizedVoiceJobRequest {
  audioRecordId?: int32(name='AudioRecordId', description='The sequence number of the recording file.

This parameter is required.', example='1'),
  recordUrl?: string(name='RecordUrl', description='The URL of the recording file.

> : The URL must be an Object Storage Service (OSS) URL within your Alibaba Cloud account. The OSS bucket must be in the same region in which IMS is activated.

> : The audio file must be in the WAV or PCM format and must be a 16-bit mono audio file at 48000 Hz.

This parameter is required.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/record1.wav'),
  voiceId?: string(name='VoiceId', description='The voice ID.

This parameter is required.', example='xiaozhuan'),
}

model DetectAudioForCustomizedVoiceJobResponseBody = {
  data?: {
    pass?: boolean(name='Pass', description='Indicates whether the audio file passes the check. Valid values:

*   true
*   false', example='false'),
    reason?: string(name='Reason', description='The reason returned if the audio file failed to pass the check.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
}

model DetectAudioForCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DetectAudioForCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Checks whether the reading of users has issues, such as noticeable pronunciation errors or background noise. After the audio is checked on the cloud, the qualified audio is temporarily stored on the cloud for subsequent training. Do not skip this step.
 *
 * @param request DetectAudioForCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DetectAudioForCustomizedVoiceJobResponse
 */
async function detectAudioForCustomizedVoiceJobWithOptions(request: DetectAudioForCustomizedVoiceJobRequest, runtime: $RuntimeOptions): DetectAudioForCustomizedVoiceJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.audioRecordId)) {
    query['AudioRecordId'] = request.audioRecordId;
  }
  if (!$isNull(request.recordUrl)) {
    query['RecordUrl'] = request.recordUrl;
  }
  if (!$isNull(request.voiceId)) {
    query['VoiceId'] = request.voiceId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DetectAudioForCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Checks whether the reading of users has issues, such as noticeable pronunciation errors or background noise. After the audio is checked on the cloud, the qualified audio is temporarily stored on the cloud for subsequent training. Do not skip this step.
 *
 * @param request DetectAudioForCustomizedVoiceJobRequest
 * @return DetectAudioForCustomizedVoiceJobResponse
 */
async function detectAudioForCustomizedVoiceJob(request: DetectAudioForCustomizedVoiceJobRequest): DetectAudioForCustomizedVoiceJobResponse {
  var runtime = new $RuntimeOptions{};
  return detectAudioForCustomizedVoiceJobWithOptions(request, runtime);
}

model DropSearchIndexRequest {
  indexType?: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.

This parameter is required.', example='mm'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

*   If you leave this parameter empty, the search index is created in the default search library of Intelligent Media Service (IMS). Default value: ims-default-search-lib.
*   To query information about an existing search library, call the [QuerySearchLib](https://help.aliyun.com/document_detail/2584455.html) API operation.', example='test1'),
}

model DropSearchIndexResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DropSearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DropSearchIndexResponseBody(name='body'),
}

/**
 * @summary Deletes a search index. After you delete a search index, the existing index data is cleared and index-based analysis, storage, and query are not supported for subsequent media assets.
 *
 * @param request DropSearchIndexRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DropSearchIndexResponse
 */
async function dropSearchIndexWithOptions(request: DropSearchIndexRequest, runtime: $RuntimeOptions): DropSearchIndexResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.indexType)) {
    query['IndexType'] = request.indexType;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DropSearchIndex',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a search index. After you delete a search index, the existing index data is cleared and index-based analysis, storage, and query are not supported for subsequent media assets.
 *
 * @param request DropSearchIndexRequest
 * @return DropSearchIndexResponse
 */
async function dropSearchIndex(request: DropSearchIndexRequest): DropSearchIndexResponse {
  var runtime = new $RuntimeOptions{};
  return dropSearchIndexWithOptions(request, runtime);
}

model DropSearchLibRequest {
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

This parameter is required.', example='test1'),
}

model DropSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DropSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DropSearchLibResponseBody(name='body'),
}

/**
 * @summary Deletes a search library and all media assets in the library.
 *
 * @param request DropSearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return DropSearchLibResponse
 */
async function dropSearchLibWithOptions(request: DropSearchLibRequest, runtime: $RuntimeOptions): DropSearchLibResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'DropSearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Deletes a search library and all media assets in the library.
 *
 * @param request DropSearchLibRequest
 * @return DropSearchLibResponse
 */
async function dropSearchLib(request: DropSearchLibRequest): DropSearchLibResponse {
  var runtime = new $RuntimeOptions{};
  return dropSearchLibWithOptions(request, runtime);
}

model GenerateAIAgentCallRequest {
  AIAgentId?: string(name='AIAgentId', description='The ID of the AI agent.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  chatSyncConfig?: {
    IMAIAgentId?: string(name='IMAIAgentId', example='******005e4f309379701645f4****'),
    receiverId?: string(name='ReceiverId', example='4167626d312034b2b1c3b7f2f3e41884'),
  }(name='ChatSyncConfig'),
  expire?: long(name='Expire', description='The time when the token expires. Unit: seconds. Default value: 3600. Valid values: 0 to 604800.', example='3600'),
  sessionId?: string(name='SessionId', example='fw1gr0bc005e4f309379701645f4****'),
  templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', description='The template configurations of the AI agent. The specified configurations are merged with the template configurations that are specified in the console. If you do not specify this parameter, the system uses the default configurations for an AI agent created in the console.'),
  userData?: string(name='UserData', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
  userId?: string(name='UserId', description='The username of the AI agent in the channel. If you do not specify this parameter, the system automatically generates a username. The value can be up to 64 characters in length.', example='877ae632caae49b1afc81c2e8194ffb4'),
}

model GenerateAIAgentCallShrinkRequest {
  AIAgentId?: string(name='AIAgentId', description='The ID of the AI agent.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  chatSyncConfigShrink?: string(name='ChatSyncConfig'),
  expire?: long(name='Expire', description='The time when the token expires. Unit: seconds. Default value: 3600. Valid values: 0 to 604800.', example='3600'),
  sessionId?: string(name='SessionId', example='fw1gr0bc005e4f309379701645f4****'),
  templateConfigShrink?: string(name='TemplateConfig', description='The template configurations of the AI agent. The specified configurations are merged with the template configurations that are specified in the console. If you do not specify this parameter, the system uses the default configurations for an AI agent created in the console.'),
  userData?: string(name='UserData', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
  userId?: string(name='UserId', description='The username of the AI agent in the channel. If you do not specify this parameter, the system automatically generates a username. The value can be up to 64 characters in length.', example='877ae632caae49b1afc81c2e8194ffb4'),
}

model GenerateAIAgentCallResponseBody = {
  AIAgentUserId?: string(name='AIAgentUserId', description='The username of the AI agent in the Alibaba Real-Time Communication (ARTC) channel.', example='877ae632caae49b1afc81c2e8194ffb4'),
  channelId?: string(name='ChannelId', description='The ARTC channel ID.', example='70f22d5784194938a7e387052f2b3208'),
  instanceId?: string(name='InstanceId', description='The ID of the AI agent.', example='39f8e0bc005e4f309379701645f4****'),
  requestId?: string(name='RequestId', description='The request ID.', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
  token?: string(name='Token', description='The ARTC token of the client.', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx'),
  userId?: string(name='UserId', description='The username in the ARTC channel.', example='user123'),
}

model GenerateAIAgentCallResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GenerateAIAgentCallResponseBody(name='body'),
}

/**
 * @summary Creates an AI agent. This operation returns the channel in which the AI agent resides, the username of the AI agent in the channel, and the token that you can use to join the channel.
 *
 * @description ## [](#)Request description
 * You can call this operation to create an AI agent based on the provided ID. You can join the channel based on the returned information and talk to the agent.
 * **Note:** Make sure that the provided AI agent ID is valid and configure optional parameters based on your business requirements.
 *
 * @param tmpReq GenerateAIAgentCallRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GenerateAIAgentCallResponse
 */
async function generateAIAgentCallWithOptions(tmpReq: GenerateAIAgentCallRequest, runtime: $RuntimeOptions): GenerateAIAgentCallResponse {
  tmpReq.validate();
  var request = new GenerateAIAgentCallShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.chatSyncConfig)) {
    request.chatSyncConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.chatSyncConfig, 'ChatSyncConfig', 'json');
  }
  if (!$isNull(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.AIAgentId)) {
    query['AIAgentId'] = request.AIAgentId;
  }
  if (!$isNull(request.chatSyncConfigShrink)) {
    query['ChatSyncConfig'] = request.chatSyncConfigShrink;
  }
  if (!$isNull(request.expire)) {
    query['Expire'] = request.expire;
  }
  if (!$isNull(request.sessionId)) {
    query['SessionId'] = request.sessionId;
  }
  if (!$isNull(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  if (!$isNull(request.userId)) {
    query['UserId'] = request.userId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GenerateAIAgentCall',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Creates an AI agent. This operation returns the channel in which the AI agent resides, the username of the AI agent in the channel, and the token that you can use to join the channel.
 *
 * @description ## [](#)Request description
 * You can call this operation to create an AI agent based on the provided ID. You can join the channel based on the returned information and talk to the agent.
 * **Note:** Make sure that the provided AI agent ID is valid and configure optional parameters based on your business requirements.
 *
 * @param request GenerateAIAgentCallRequest
 * @return GenerateAIAgentCallResponse
 */
async function generateAIAgentCall(request: GenerateAIAgentCallRequest): GenerateAIAgentCallResponse {
  var runtime = new $RuntimeOptions{};
  return generateAIAgentCallWithOptions(request, runtime);
}

model GenerateKMSDataKeyResponseBody = {
  dataKey?: {
    ciphertextBlob?: string(name='CiphertextBlob', description='The ciphertext of the encrypted data key. This parameter is used as CipherText when you create a transcoding job.', example='ODZhOWVmZDktM2QxNi00ODk0LWJkNGYtMWZjNDNmM2YyYWJmS7FmDBBQ0BkKsQrtRnidtPwirmDcS0ZuJCU41xxAAWk4Z8qsADfbV0b+i6kQmlvj79dJdGOvtX69Uycs901qOjop4bTS****'),
    keyId?: string(name='KeyId', description='The ID of the customer master key (CMK). The ID must be globally unique.', example='7906979c-8e06-46a2-be2d-68e3ccbc****'),
    plaintext?: string(name='Plaintext', description='The Base64-encoded plaintext of the data key.', example='QmFzZTY0IGVuY29kZWQgcGxhaW50****'),
  }(name='DataKey', description='The information about the data key.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GenerateKMSDataKeyResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GenerateKMSDataKeyResponseBody(name='body'),
}

/**
 * @summary Generates a random Key Management Service (KMS) data key used for HTTP Live Streaming (HLS) encryption and transcoding of videos.
 *
 * @param request GenerateKMSDataKeyRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GenerateKMSDataKeyResponse
 */
async function generateKMSDataKeyWithOptions(runtime: $RuntimeOptions): GenerateKMSDataKeyResponse {
  var req = new OpenApiUtil.OpenApiRequest{};
  var params = new OpenApiUtil.Params{
    action = 'GenerateKMSDataKey',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Generates a random Key Management Service (KMS) data key used for HTTP Live Streaming (HLS) encryption and transcoding of videos.
 *
 * @return GenerateKMSDataKeyResponse
 */
async function generateKMSDataKey(): GenerateKMSDataKeyResponse {
  var runtime = new $RuntimeOptions{};
  return generateKMSDataKeyWithOptions(runtime);
}

model GenerateMessageChatTokenRequest {
  AIAgentId?: string(name='AIAgentId', description='This parameter is required.', example='19de81b3b3d94abda22******'),
  expire?: int32(name='Expire', example='3600'),
  role?: string(name='Role', example='user'),
  userId?: string(name='UserId', description='This parameter is required.', example='YOURUSERID'),
}

model GenerateMessageChatTokenResponseBody = {
  appId?: string(name='AppId', example='***********'),
  appSign?: string(name='AppSign', example='H4sIAAAAAAAE******************'),
  nonce?: string(name='Nonce', example='AK-***********'),
  requestId?: string(name='RequestId', example='req_1234567890abcdef'),
  role?: string(name='Role', example='admin'),
  timeStamp?: long(name='TimeStamp', example='1700000000'),
  token?: string(name='Token', example='acet**********'),
  userId?: string(name='UserId', example='YOURUSERID'),
}

model GenerateMessageChatTokenResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GenerateMessageChatTokenResponseBody(name='body'),
}

/**
 * @summary 生成直播互动消息所需的token
 *
 * @param request GenerateMessageChatTokenRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GenerateMessageChatTokenResponse
 */
async function generateMessageChatTokenWithOptions(request: GenerateMessageChatTokenRequest, runtime: $RuntimeOptions): GenerateMessageChatTokenResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.AIAgentId)) {
    query['AIAgentId'] = request.AIAgentId;
  }
  if (!$isNull(request.expire)) {
    query['Expire'] = request.expire;
  }
  if (!$isNull(request.role)) {
    query['Role'] = request.role;
  }
  if (!$isNull(request.userId)) {
    query['UserId'] = request.userId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GenerateMessageChatToken',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 生成直播互动消息所需的token
 *
 * @param request GenerateMessageChatTokenRequest
 * @return GenerateMessageChatTokenResponse
 */
async function generateMessageChatToken(request: GenerateMessageChatTokenRequest): GenerateMessageChatTokenResponse {
  var runtime = new $RuntimeOptions{};
  return generateMessageChatTokenWithOptions(request, runtime);
}

model GetAdInsertionRequest {
  name?: string(name='Name', description='The name of the ad insertion configuration that you want to query.

This parameter is required.', example='my_ad'),
}

model GetAdInsertionResponseBody = {
  config?: {
    adMarkerPassthrough?: string(name='AdMarkerPassthrough', description='Indicates whether ad marker passthrough is enabled.', example='ON'),
    adsUrl?: string(name='AdsUrl', description='The URL of the ad decision server (ADS).', example='http://ads.com/ad1?param1=[palyer_params.p1]'),
    cdnConfig?: {
      adSegmentUrlPrefix?: string(name='AdSegmentUrlPrefix', description='The CDN prefix for accessing ad segments.', example='http://cdn.com/'),
      contentSegmentUrlPrefix?: string(name='ContentSegmentUrlPrefix', description='The CDN prefix for accessing content segments.', example='http://cdn.com/'),
    }(name='CdnConfig', description='The CDN configurations.'),
    configAliases?: string(name='ConfigAliases', description='The aliases for dynamic variable replacement.', example='{
      "player_params.p1": {
            "1": "abc"
      }
}'),
    contentUrlPrefix?: string(name='ContentUrlPrefix', description='The prefix of the source URL.', example='https://source.com/'),
    createTime?: string(name='CreateTime', description='The time when the configuration was created.', example='2024-06-13T08:26:09Z'),
    lastModified?: string(name='LastModified', description='The time when the configuration was last modified.', example='2024-06-13T08:26:09Z'),
    manifestEndpointConfig?: {
      hlsPrefix?: string(name='HlsPrefix', description='The playback endpoint prefix for accessing HLS manifests.'),
    }(name='ManifestEndpointConfig', description='The playback endpoint prefix for accessing manifests.'),
    name?: string(name='Name', description='The name of the configuration.', example='my_ad'),
    personalizationThreshold?: int32(name='PersonalizationThreshold', description='The personalization threshold.', example='5'),
    slateAdUrl?: string(name='SlateAdUrl', description='The URL of the slate ad.', example='http://storage.com/slate1.mp4'),
  }(name='Config', description='The ad insertion configuration.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
}

model GetAdInsertionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAdInsertionResponseBody(name='body'),
}

/**
 * @summary Obtains details of an ad insertion configuration.
 *
 * @param request GetAdInsertionRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetAdInsertionResponse
 */
async function getAdInsertionWithOptions(request: GetAdInsertionRequest, runtime: $RuntimeOptions): GetAdInsertionResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetAdInsertion',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Obtains details of an ad insertion configuration.
 *
 * @param request GetAdInsertionRequest
 * @return GetAdInsertionResponse
 */
async function getAdInsertion(request: GetAdInsertionRequest): GetAdInsertionResponse {
  var runtime = new $RuntimeOptions{};
  return getAdInsertionWithOptions(request, runtime);
}

model GetAvatarRequest {
  avatarId?: string(name='AvatarId', description='*   The ID of the digital human.

This parameter is required.', example='Avatar-XXXX'),
}

model GetAvatarResponseBody = {
  data?: {
    avatar?: {
      avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
      avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXXX'),
      avatarName?: string(name='AvatarName', description='The name of the digital human.'),
      avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
      height?: int32(name='Height', description='The height of the digital human image in pixels.', example='1920'),
      portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='****571c704445f9a0ee011406c2****'),
      thumbnail?: string(name='Thumbnail', description='The thumbnail URL.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
      transparent?: boolean(name='Transparent', description='Indicates whether the digital human supports alpha channels.', example='true'),
      width?: int32(name='Width', description='The width of the digital human image in pixels.', example='1080'),
    }(name='Avatar', description='The information about the digital human.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetAvatarResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAvatarResponseBody(name='body'),
}

/**
 * @summary Queries the information about a trained digital human.
 *
 * @param request GetAvatarRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetAvatarResponse
 */
async function getAvatarWithOptions(request: GetAvatarRequest, runtime: $RuntimeOptions): GetAvatarResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.avatarId)) {
    query['AvatarId'] = request.avatarId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetAvatar',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a trained digital human.
 *
 * @param request GetAvatarRequest
 * @return GetAvatarResponse
 */
async function getAvatar(request: GetAvatarRequest): GetAvatarResponse {
  var runtime = new $RuntimeOptions{};
  return getAvatarWithOptions(request, runtime);
}

model GetAvatarTrainingJobRequest {
  jobId?: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetAvatarTrainingJobResponseBody = {
  data?: {
    avatarTrainingJob?: {
      avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
      avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXXX'),
      avatarName?: string(name='AvatarName', description='The name of the digital human.'),
      avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
      firstTrainingTime?: string(name='FirstTrainingTime', description='*   The time when the first training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
      jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****55d86f7f4587943ce7734d6b****'),
      lastTrainingTime?: string(name='LastTrainingTime', description='*   The time when the last training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
      message?: string(name='Message', description='The status description.'),
      portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='****571c704445f9a0ee011406c2****'),
      status?: string(name='Status', description='*   The state of the digital human training job.
*   Valid values: Init, Queuing, Training, Success, and Fail.', example='Success'),
      thumbnail?: string(name='Thumbnail', description='The thumbnail URL.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
      transparent?: boolean(name='Transparent', description='Indicates whether the input video supports alpha channels.', example='true'),
      video?: string(name='Video', description='The ID of the video used for training.', example='****571c704445f9a0ee011406c2****'),
    }(name='AvatarTrainingJob', description='The information about the digital human training job.'),
  }(name='Data', description='The data returned if the request was successful.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAvatarTrainingJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a digital human training job.
 *
 * @param request GetAvatarTrainingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetAvatarTrainingJobResponse
 */
async function getAvatarTrainingJobWithOptions(request: GetAvatarTrainingJobRequest, runtime: $RuntimeOptions): GetAvatarTrainingJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetAvatarTrainingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a digital human training job.
 *
 * @param request GetAvatarTrainingJobRequest
 * @return GetAvatarTrainingJobResponse
 */
async function getAvatarTrainingJob(request: GetAvatarTrainingJobRequest): GetAvatarTrainingJobResponse {
  var runtime = new $RuntimeOptions{};
  return getAvatarTrainingJobWithOptions(request, runtime);
}

model GetBatchMediaProducingJobRequest {
  jobId?: string(name='JobId', description='The ID of the quick video production job.', example='****b4549d46c88681030f6e****'),
}

model GetBatchMediaProducingJobResponseBody = {
  editingBatchJob?: {
    completeTime?: string(name='CompleteTime', description='The time when the job was complete.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:57:07Z'),
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:47:07Z'),
    editingConfig?: string(name='EditingConfig', description='The editing configurations. For more information, see [EditingConfig](~~2692547#1be9bba03b7qu~~).', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}'),
    extend?: string(name='Extend', description='The extended information. This parameter contains the following fields:

ErrorCode: the error code of the main job.

ErrorMessage: the error message of the main job.', example='{
	"ErrorCode": "InvalidMaterial.NotFound",
	"ErrorMessage": "The specified clips id not found:[\\\\"****30d0b5e871eebb2ff7f6c75a****\\\\"]"
}'),
    inputConfig?: string(name='InputConfig', description='The input configurations. For more information, see [InputConfig](~~2692547#2faed1559549n~~).'),
    jobId?: string(name='JobId', description='The job ID.', example='****b6b2750d4308892ac3330238****'),
    jobType?: string(name='JobType'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:57:07Z'),
    outputConfig?: string(name='OutputConfig', description='The output configurations. For more information, see [OutputConfig](~~2692547#447b928fcbuoa~~).', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 20,
  "MaxDuration": 15,
  "Width": 1080,
  "Height": 1920,
  "Video": {"Crf": 27}
}'),
    status?: string(name='Status', description='The job state. Valid values:

Init: The job is initialized.

Processing: The job is in progress.

Finished: The job is complete.', example='Finished'),
    subJobList?: [ 
      {
        errorCode?: string(name='ErrorCode', description='The error code that is returned if the subjob failed. This parameter is not returned if the subjob is successful.', example='InvalidMaterial.NotFound'),
        errorMessage?: string(name='ErrorMessage', description='The error message that is returned if the subjob failed. This parameter is not returned if the subjob is successful.', example='The specified clips id not found:["****30d0b5e871eebb2ff7f6c75a****"]'),
        jobId?: string(name='JobId', description='The subjob ID.', example='****8e81933d44e3ae69e2f81485****'),
        mediaId?: string(name='MediaId', description='The ID of the output media asset.', example='****1470b11171ee9d19e7e6c66a****'),
        mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http:/xxx.oss-cn-shanghai.aliyuncs.com/xxx_0.mp4'),
        projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****7cc47fe04eaa81bd853acb6a****'),
        status?: string(name='Status', description='The subjob state. Valid values:

Init: The subjob is initialized.

Processing: The subjob is in progress.

Success: The subjob is successful.

Failed: The subjob failed.', example='Success'),
      }
    ](name='SubJobList', description='The quick video production subjobs.'),
    userData?: string(name='UserData', description='The user-defined data, including the business and callback configurations. For more information, see [UserData](https://help.aliyun.com/document_detail/357745.html).', example='{"NotifyAddress":"http://xx.xx.xxx"}'),
  }(name='EditingBatchJob', description='The information about the quick video production job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model GetBatchMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetBatchMediaProducingJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a quick video production job, including the input parameters, job state, and the IDs and URLs of the output media assets. You can call this operation to query only quick video production jobs created within the past year.
 *
 * @param request GetBatchMediaProducingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetBatchMediaProducingJobResponse
 */
async function getBatchMediaProducingJobWithOptions(request: GetBatchMediaProducingJobRequest, runtime: $RuntimeOptions): GetBatchMediaProducingJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetBatchMediaProducingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a quick video production job, including the input parameters, job state, and the IDs and URLs of the output media assets. You can call this operation to query only quick video production jobs created within the past year.
 *
 * @param request GetBatchMediaProducingJobRequest
 * @return GetBatchMediaProducingJobResponse
 */
async function getBatchMediaProducingJob(request: GetBatchMediaProducingJobRequest): GetBatchMediaProducingJobResponse {
  var runtime = new $RuntimeOptions{};
  return getBatchMediaProducingJobWithOptions(request, runtime);
}

model GetCategoriesRequest {
  cateId?: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of CateId returned by the AddCategory operation that you called to create a category.
*   View the value of CateId returned by the GetCategories operation that you called to query a category.', example='33'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values: 10 to 100.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting rule of results. Valid values:

\\\\- CreationTime:Desc (default): The results are sorted in reverse chronological order based on the creation time.

\\\\- CreationTime:Asc: The results are sorted in chronological order based on the creation time.', example='CreationTime:Desc'),
  type?: string(name='Type', description='The type of the category. Valid values: default and material. A value of default indicates audio, video, and image files. This is the default value. A value of material indicates short video materials.', example='default'),
}

model GetCategoriesResponseBody = {
  category?: {
    cateId?: long(name='CateId', description='The category ID.', example='46'),
    cateName?: string(name='CateName', description='The category name.'),
    level?: long(name='Level', description='The level of the category. A value of **0** indicates a level-1 category, a value of **1** indicates a level-2 category, and a value of **2** indicates a level-3 category.', example='0'),
    parentId?: long(name='ParentId', description='The ID of the parent category.', example='-1'),
    type?: string(name='Type', description='The type of the category. Valid values:

*   **default**: audio, video, and image files. This is the default value.
*   **material**: short video materials.', example='default'),
  }(name='Category', description='The information about the category.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  subCategories?: {
    category?: [ 
    {
      cateId?: long(name='CateId', description='The category ID.', example='129'),
      cateName?: string(name='CateName', description='The category name.

*   The value can be up to 64 bytes in length.
*   The value is encoded in UTF-8.'),
      level?: long(name='Level', description='The level of the category. A value of **0** indicates a level-1 category, a value of **1** indicates a level-2 category, and a value of **2** indicates a level-3 category.', example='1'),
      parentId?: long(name='ParentId', description='The ID of the parent category.', example='46'),
      subTotal?: long(name='SubTotal', description='The total number of subcategories.', example='100'),
      type?: string(name='Type', description='The type of the category. Valid values:

*   **default**: audio, video, and image files. This is the default value.
*   **material**: short video materials.', example='default'),
    }
  ](name='Category')
  }(name='SubCategories', description='The subcategories in the category.'),
  subTotal?: long(name='SubTotal', description='The total number of subcategories.', example='100'),
}

model GetCategoriesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCategoriesResponseBody(name='body'),
}

/**
 * @summary Queries the information about a category and its subcategories.
 *
 * @description You can call this operation to query the information about a category and its subcategories based on the category ID and category type.
 *
 * @param request GetCategoriesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetCategoriesResponse
 */
async function getCategoriesWithOptions(request: GetCategoriesRequest, runtime: $RuntimeOptions): GetCategoriesResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.cateId)) {
    query['CateId'] = request.cateId;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetCategories',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a category and its subcategories.
 *
 * @description You can call this operation to query the information about a category and its subcategories based on the category ID and category type.
 *
 * @param request GetCategoriesRequest
 * @return GetCategoriesResponse
 */
async function getCategories(request: GetCategoriesRequest): GetCategoriesResponse {
  var runtime = new $RuntimeOptions{};
  return getCategoriesWithOptions(request, runtime);
}

model GetChannelRequest {
  channelName?: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel'),
}

model GetChannelResponseBody = {
  channel?: ChannelAssemblyChannel(name='Channel', description='The channel information.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
}

model GetChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetChannelResponseBody(name='body'),
}

/**
 * @summary Queries information about a channel in MediaWeaver.
 *
 * @param request GetChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetChannelResponse
 */
async function getChannelWithOptions(request: GetChannelRequest, runtime: $RuntimeOptions): GetChannelResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries information about a channel in MediaWeaver.
 *
 * @param request GetChannelRequest
 * @return GetChannelResponse
 */
async function getChannel(request: GetChannelRequest): GetChannelResponse {
  var runtime = new $RuntimeOptions{};
  return getChannelWithOptions(request, runtime);
}

model GetContentAnalyzeConfigResponseBody = {
  contentAnalyzeConfig?: {
    auto?: boolean(name='Auto', example='true'),
    saveType?: string(name='SaveType', example='TEXT,FACE'),
    templateId?: string(name='TemplateId', example='S00000101-100070'),
  }(name='ContentAnalyzeConfig'),
  requestId?: string(name='RequestId', example='31FEC819-2344-5771-9366-9172DB0D26C9'),
}

model GetContentAnalyzeConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetContentAnalyzeConfigResponseBody(name='body'),
}

/**
 * @summary 获取内容分析搜索配置
 *
 * @param request GetContentAnalyzeConfigRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetContentAnalyzeConfigResponse
 */
async function getContentAnalyzeConfigWithOptions(runtime: $RuntimeOptions): GetContentAnalyzeConfigResponse {
  var req = new OpenApiUtil.OpenApiRequest{};
  var params = new OpenApiUtil.Params{
    action = 'GetContentAnalyzeConfig',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 获取内容分析搜索配置
 *
 * @return GetContentAnalyzeConfigResponse
 */
async function getContentAnalyzeConfig(): GetContentAnalyzeConfigResponse {
  var runtime = new $RuntimeOptions{};
  return getContentAnalyzeConfigWithOptions(runtime);
}

model GetCustomTemplateRequest {
  subtype?: int32(name='Subtype', description='The template subtype.', example='1'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
  type?: int32(name='Type', description='The ID of the template type that is used to query the default template. This parameter is required if TemplateId is not specified.', example='1'),
}

model GetCustomTemplateResponseBody = {
  customTemplate?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-01-01T10:00:00Z'),
    frontendHint?: {
      transcodeTemplateHint?: {
        bitrateControlType?: string(name='BitrateControlType'),
      }(name='TranscodeTemplateHint'),
    }(name='FrontendHint'),
    isDefault?: boolean(name='IsDefault', description='Indicates whether the template is the default template.', example='true'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-01-01T11:00:00Z'),
    status?: string(name='Status', description='The template state.', example='Normal'),
    subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='1'),
    subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='Normal'),
    templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Type":"Normal","FrameType":"normal","Time":0,"Count":10}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
    templateName?: string(name='TemplateName', description='The template name.', example='测试转码模板'),
    type?: int32(name='Type', description='The type ID of the template.', example='2'),
    typeName?: string(name='TypeName', description='The type name of the template.', example='SnapshotTemplate'),
  }(name='CustomTemplate', description='The template information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCustomTemplateResponseBody(name='body'),
}

/**
 * @summary Queries the information about a custom template.
 *
 * @description You can call this operation to query the information about a template with the ID specified by the TemplateId parameter. You can also query the information about the default template. If TemplateId is specified, other parameters are ignored and the template whose ID is specified is queried. If TemplateId is not specified, the default template is queried based on other parameters. In this case, Type is required.
 * Template types:
 * 1.  1: transcoding template.
 * 2.  2: snapshot template.
 * 3.  3: animated image template.
 * 4.  4\\. image watermark template.
 * 5.  5: text watermark template.
 * 6.  6: subtitle template.
 * 7.  7: AI-assisted content moderation template.
 * 8.  8: AI-assisted intelligent thumbnail template.
 * 9.  9: AI-assisted intelligent erasure template.
 * Subtypes of transcoding templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (AudioTranscode): audio transcoding template.
 * 3.  3 (Remux): container format conversion template.
 * 4.  4 (NarrowBandV1): Narrowband HD 1.0 template.
 * 5.  5 (NarrowBandV2): Narrowband HD 2.0 template.
 * Subtypes of snapshot templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (Sprite): sprite template.
 * 3.  3 (WebVtt): WebVTT template.
 * Subtypes of AI-assisted content moderation templates:
 * 1.  1 (Video): video moderation template.
 * 2.  2 (Audio): audio moderation template.
 * 3.  3 (Image): image moderation template.
 * Subtypes of AI-assisted intelligent erasure templates:
 * 1.  1 (VideoDelogo): logo erasure template.
 * 2.  2 (VideoDetext): subtitle erasure template.
 *
 * @param request GetCustomTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetCustomTemplateResponse
 */
async function getCustomTemplateWithOptions(request: GetCustomTemplateRequest, runtime: $RuntimeOptions): GetCustomTemplateResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.subtype)) {
    query['Subtype'] = request.subtype;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetCustomTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a custom template.
 *
 * @description You can call this operation to query the information about a template with the ID specified by the TemplateId parameter. You can also query the information about the default template. If TemplateId is specified, other parameters are ignored and the template whose ID is specified is queried. If TemplateId is not specified, the default template is queried based on other parameters. In this case, Type is required.
 * Template types:
 * 1.  1: transcoding template.
 * 2.  2: snapshot template.
 * 3.  3: animated image template.
 * 4.  4\\. image watermark template.
 * 5.  5: text watermark template.
 * 6.  6: subtitle template.
 * 7.  7: AI-assisted content moderation template.
 * 8.  8: AI-assisted intelligent thumbnail template.
 * 9.  9: AI-assisted intelligent erasure template.
 * Subtypes of transcoding templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (AudioTranscode): audio transcoding template.
 * 3.  3 (Remux): container format conversion template.
 * 4.  4 (NarrowBandV1): Narrowband HD 1.0 template.
 * 5.  5 (NarrowBandV2): Narrowband HD 2.0 template.
 * Subtypes of snapshot templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (Sprite): sprite template.
 * 3.  3 (WebVtt): WebVTT template.
 * Subtypes of AI-assisted content moderation templates:
 * 1.  1 (Video): video moderation template.
 * 2.  2 (Audio): audio moderation template.
 * 3.  3 (Image): image moderation template.
 * Subtypes of AI-assisted intelligent erasure templates:
 * 1.  1 (VideoDelogo): logo erasure template.
 * 2.  2 (VideoDetext): subtitle erasure template.
 *
 * @param request GetCustomTemplateRequest
 * @return GetCustomTemplateResponse
 */
async function getCustomTemplate(request: GetCustomTemplateRequest): GetCustomTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return getCustomTemplateWithOptions(request, runtime);
}

model GetCustomizedVoiceRequest {
  voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
}

model GetCustomizedVoiceResponseBody = {
  data?: {
    customizedVoice?: {
      demoAudioMediaId?: string(name='DemoAudioMediaId', description='The media asset ID of the sample audio file.', example='****42d3c312402982be65975f5b****'),
      gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
      scenario?: string(name='Scenario', description='The demonstration scenario.

Valid values:

*   **story**
*   **interaction**
*   **navigation**', example='interaction'),
      voiceDesc?: string(name='VoiceDesc', description='The voice description.'),
      voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
      voiceName?: string(name='VoiceName', description='The voice name.'),
    }(name='CustomizedVoice', description='The personalized human voice.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetCustomizedVoiceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCustomizedVoiceResponseBody(name='body'),
}

/**
 * @summary Queries the information about a personalized human voice.
 *
 * @param request GetCustomizedVoiceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetCustomizedVoiceResponse
 */
async function getCustomizedVoiceWithOptions(request: GetCustomizedVoiceRequest, runtime: $RuntimeOptions): GetCustomizedVoiceResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.voiceId)) {
    query['VoiceId'] = request.voiceId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetCustomizedVoice',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a personalized human voice.
 *
 * @param request GetCustomizedVoiceRequest
 * @return GetCustomizedVoiceResponse
 */
async function getCustomizedVoice(request: GetCustomizedVoiceRequest): GetCustomizedVoiceResponse {
  var runtime = new $RuntimeOptions{};
  return getCustomizedVoiceWithOptions(request, runtime);
}

model GetCustomizedVoiceJobRequest {
  jobId?: string(name='JobId', description='The ID of the human voice cloning job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetCustomizedVoiceJobResponseBody = {
  data?: {
    customizedVoiceJob?: {
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-06-07T02:27:08Z'),
      gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
      jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****571c704445f9a0ee011406c2****'),
      message?: string(name='Message', description='The status description.'),
      scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation', example='story'),
      status?: string(name='Status', description='The job state. Valid values:

*   Initialization
*   AudioDetecting
*   PreTraining
*   Training
*   Success
*   Fail', example='Fail'),
      type?: string(name='Type', description='The type of the human voice cloning job. Valid values:

*   Basic
*   Standard', example='Standard'),
      voiceDesc?: string(name='VoiceDesc', description='The voice description.', example='This is an exclusive voice'),
      voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
      voiceName?: string(name='VoiceName', description='The voice name.', example='Xiaozhuan'),
    }(name='CustomizedVoiceJob', description='The information about the human voice cloning job.'),
  }(name='Data', description='The data returned if the request was successful.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a human voice cloning job.
 *
 * @param request GetCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetCustomizedVoiceJobResponse
 */
async function getCustomizedVoiceJobWithOptions(request: GetCustomizedVoiceJobRequest, runtime: $RuntimeOptions): GetCustomizedVoiceJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a human voice cloning job.
 *
 * @param request GetCustomizedVoiceJobRequest
 * @return GetCustomizedVoiceJobResponse
 */
async function getCustomizedVoiceJob(request: GetCustomizedVoiceJobRequest): GetCustomizedVoiceJobResponse {
  var runtime = new $RuntimeOptions{};
  return getCustomizedVoiceJobWithOptions(request, runtime);
}

model GetDefaultStorageLocationResponseBody = {
  bucket?: string(name='Bucket', example='oss-test-bucket'),
  path?: string(name='Path', example='ice/dir'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
  status?: string(name='Status', example='normal'),
  storageType?: string(name='StorageType', example='user_oss_bucket'),
}

model GetDefaultStorageLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDefaultStorageLocationResponseBody(name='body'),
}

/**
 * @summary 获取用户默认存储地址
 *
 * @param request GetDefaultStorageLocationRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetDefaultStorageLocationResponse
 */
async function getDefaultStorageLocationWithOptions(runtime: $RuntimeOptions): GetDefaultStorageLocationResponse {
  var req = new OpenApiUtil.OpenApiRequest{};
  var params = new OpenApiUtil.Params{
    action = 'GetDefaultStorageLocation',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 获取用户默认存储地址
 *
 * @return GetDefaultStorageLocationResponse
 */
async function getDefaultStorageLocation(): GetDefaultStorageLocationResponse {
  var runtime = new $RuntimeOptions{};
  return getDefaultStorageLocationWithOptions(runtime);
}

model GetDemonstrationForCustomizedVoiceJobRequest {
  scenario?: string(name='Scenario', description='The demonstration scenario.

Valid values:

*   **story**
*   **interaction**
*   **navigation**

This parameter is required.', example='story'),
}

model GetDemonstrationForCustomizedVoiceJobResponseBody = {
  data?: {
    demonstrationList?: [ 
      {
        audioId?: int32(name='AudioId', description='The sequence number of the text, which corresponds to the AduioRecordId parameter to be passed during audio check.', example='2'),
        demoAudio?: string(name='DemoAudio', description='The URL of the sample audio.

*   The value is an Object Storage Service (OSS) URL.

    **

    **Note**: The URL expires in 12 hours.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/1.wav'),
        text?: string(name='Text', description='The text content to be read.'),
      }
    ](name='DemonstrationList', description='A list of 20 text entries to be read and the corresponding sample audio.'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetDemonstrationForCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDemonstrationForCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Queries the text to be read and sample audio for training a personalized human voice.
 *
 * @param request GetDemonstrationForCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetDemonstrationForCustomizedVoiceJobResponse
 */
async function getDemonstrationForCustomizedVoiceJobWithOptions(request: GetDemonstrationForCustomizedVoiceJobRequest, runtime: $RuntimeOptions): GetDemonstrationForCustomizedVoiceJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.scenario)) {
    query['Scenario'] = request.scenario;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetDemonstrationForCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the text to be read and sample audio for training a personalized human voice.
 *
 * @param request GetDemonstrationForCustomizedVoiceJobRequest
 * @return GetDemonstrationForCustomizedVoiceJobResponse
 */
async function getDemonstrationForCustomizedVoiceJob(request: GetDemonstrationForCustomizedVoiceJobRequest): GetDemonstrationForCustomizedVoiceJobResponse {
  var runtime = new $RuntimeOptions{};
  return getDemonstrationForCustomizedVoiceJobWithOptions(request, runtime);
}

model GetDynamicImageJobRequest {
  jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
}

model GetDynamicImageJobResponseBody = {
  dynamicImageJob?: {
    code?: string(name='Code', description='Error codes', example='ResourceNotFound'),
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
    input?: {
      media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://test-bucket/sample-input.mp4'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='sample-input.mp4'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
    message?: string(name='Message', description='The error message that is returned.', example='The specified resource for "CustomTemplate" could not be found.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
    name?: string(name='Name', description='The name of the job.', example='SampleJob'),
    output?: {
      media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='****d80e4e4044975745c14b****'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='sample-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='path/to/object'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the input file. Valid values: OSS: an OSS object. Media: a media asset.', example='Media'),
    }(name='Output', description='The output of the job.'),
    outputUrl?: string(name='OutputUrl', description='The URL of the output animated image.', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/output.gif'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****d80e4e4044975745c14b****'),
    status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
    templateConfig?: string(name='TemplateConfig', description='The animation template configuration.', example='{"Format":"gif","Fps":5,"Height":1080,"Width":1920}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****d80e4e4044975745c14b****'),
    triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
    userData?: string(name='UserData', description='The user-defined data.', example='{"sampleParam": "sampleValue"}'),
  }(name='DynamicImageJob', description='The information about the snapshot job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******36-3C1E-4417-BDB2-1E034F******'),
}

model GetDynamicImageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDynamicImageJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about an image animation job.
 *
 * @param request GetDynamicImageJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetDynamicImageJobResponse
 */
async function getDynamicImageJobWithOptions(request: GetDynamicImageJobRequest, runtime: $RuntimeOptions): GetDynamicImageJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetDynamicImageJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about an image animation job.
 *
 * @param request GetDynamicImageJobRequest
 * @return GetDynamicImageJobResponse
 */
async function getDynamicImageJob(request: GetDynamicImageJobRequest): GetDynamicImageJobResponse {
  var runtime = new $RuntimeOptions{};
  return getDynamicImageJobWithOptions(request, runtime);
}

model GetEditingProjectRequest {
  projectId?: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='****fb2101bf24b2754cb318787dc****'),
  requestSource?: string(name='RequestSource', description='The ID of the request source. Valid values:

\\\\- OpenAPI (default): Timeline conversion is not performed.

\\\\- WebSDK: If you specify this value, the project timeline is automatically converted into the frontend style, and the materials in the timeline are associated with the project to enable preview by using frontend web SDKs.', example='WebSDK'),
}

model GetEditingProjectResponseBody = {
  project?: {
    businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{ "OutputMediaConfig" : { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path" }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
    businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

Reserving

ReservationCanceled

BroadCasting

LoadingFailed

LiveFinished', example='Reserving'),
    clipsParam?: string(name='ClipsParam', description='The material parameter corresponding to the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified. For more information<props="china">, see [Create and use a regular template](https://help.aliyun.com/document_detail/328557.html) and [Create and use an advanced template](https://help.aliyun.com/document_detail/291418.html).'),
    coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='oss://example-bucket/example.jpg'),
    createSource?: string(name='CreateSource', description='The method for creating the online editing project. Valid values:

\\\\- OpenAPI

\\\\- AliyunConsole

\\\\- WebSDK

\\\\- LiveEditingOpenAPI

\\\\- LiveEditingConsole', example='OpenAPI'),
    createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2020-12-20T12:00:00Z'),
    description?: string(name='Description', description='The description of the online editing project.'),
    duration?: long(name='Duration', description='The total duration of the online editing project.', example='24.120000'),
    modifiedSource?: string(name='ModifiedSource', description='The method for editing the online editing project. Valid values:

\\\\- OpenAPI

\\\\- AliyunConsole

\\\\- WebSDK

\\\\- LiveEditingOpenAPI

\\\\- LiveEditingConsole', example='OpenAPI'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last modified.', example='2020-12-20T13:00:00Z'),
    projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fb2101bf24b2754cb318787dc****'),
    projectType?: string(name='ProjectType', description='The type of the editing project. Default value: EditingProject. Valid values:

\\\\- EditingProject: a regular editing project.

\\\\- LiveEditingProject: a live stream editing project.', example='EditingProject'),
    status?: string(name='Status', description='The status of the online editing project. Valid values:

\\\\- Draft

\\\\- Editing

\\\\- Producing

\\\\- Produced

\\\\- ProduceFailed

\\\\- Deleted', example='Editing'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
    templateType?: string(name='TemplateType', description='The template type of the online editing project. Valid values:

\\\\- Timeline

\\\\- VETemplate', example='Timeline'),
    timeline?: string(name='Timeline', description='The timeline of the online editing project.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****9b4d7cf14dc7b83b0e801cbe****"},{"MediaId":"****9b4d7cf14dc7b83b0e801cbe****"},{"MediaId":"****1656bca4474999c961a6d2a2****"}]}]}'),
    timelineConvertErrorMessage?: string(name='TimelineConvertErrorMessage', description='The error message returned if the project conversion failed. The error message displays the detailed information about the failure, and is returned only if the value of TimelineConvertStatus is ConvertFailed.', example='The StorageLocation must be in the same division(apiRegion) as ICE service access point.'),
    timelineConvertStatus?: string(name='TimelineConvertStatus', description='The project conversion status. Conversion of an API-style timeline into a frontend-style timeline is an asynchronous process and takes effect only if RequestSource:WebSDK is specified.

\\\\- Unconverted

\\\\- Converting

\\\\- Converted

\\\\- ConvertFailed', example='Converted'),
    title?: string(name='Title', description='The title of the online editing project.'),
  }(name='Project', description='The information about the online editing project.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model GetEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEditingProjectResponseBody(name='body'),
}

/**
 * @summary Queries the information about an online editing project.
 *
 * @param request GetEditingProjectRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetEditingProjectResponse
 */
async function getEditingProjectWithOptions(request: GetEditingProjectRequest, runtime: $RuntimeOptions): GetEditingProjectResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  if (!$isNull(request.requestSource)) {
    query['RequestSource'] = request.requestSource;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetEditingProject',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about an online editing project.
 *
 * @param request GetEditingProjectRequest
 * @return GetEditingProjectResponse
 */
async function getEditingProject(request: GetEditingProjectRequest): GetEditingProjectResponse {
  var runtime = new $RuntimeOptions{};
  return getEditingProjectWithOptions(request, runtime);
}

model GetEditingProjectMaterialsRequest {
  projectId?: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='*****fb2101cb318*****'),
}

model GetEditingProjectMaterialsResponseBody = {
  liveMaterials?: [ 
    {
      appName?: string(name='AppName', description='The application name of the live stream.', example='testrecord'),
      domainName?: string(name='DomainName', description='The domain name of the live stream.', example='test.alivecdn.com'),
      liveUrl?: string(name='LiveUrl', description='The URL of the live stream.', example='rtmp://test.alivecdn.com/testrecord/teststream'),
      streamName?: string(name='StreamName', description='The name of the live stream.', example='testrecord'),
    }
  ](name='LiveMaterials', description='The materials associated with the live stream.'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
            duration?: string(name='Duration', description='The duration.', example='216.206667'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='540'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='960'),
          }(name='FileBasicInfo', description='The basic information of the file, such as the duration and size.'),
        }
      ](name='FileInfoList', description='The information about the file.'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.', example='video'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://sample-bucket.oss-cn-shanghai.aliyuncs.com/sample-corver.jpg?Expires=1628670610&OSSAccessKeyId=AK&Signature=signature'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-26T04:11:08Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-26T04:11:08Z'),
        description?: string(name='Description', description='The description of the media asset.', example='sample_description'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/file.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****64623a94eca8516569c8f*****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-26T04:11:08Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='null'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite of the media asset', example='null'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.', example='file.mp4'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.

Valid values:

*   TranscodeSuccess: transcoding completed.
*   TranscodeFailed: transcoding failed.
*   Init: initializing.
*   Transcoding: transcoding in progress.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information of the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='*****64623a94eca8516569c8fe*****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  projectId?: string(name='ProjectId', description='The project ID.', example='*****67ae06542b9b93e0d1c387*****'),
  projectMaterials?: [ string ](name='ProjectMaterials', description='The materials associated with the editing project. A live stream editing project will be associated with a regular editing project after the live streaming ends.', example='*****9b145c5cafc2e057304fcd*****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******89-C21D-4B78-AE24-3788B8******'),
}

model GetEditingProjectMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEditingProjectMaterialsResponseBody(name='body'),
}

/**
 * @summary Queries all materials associated with an online editing project.
 *
 * @param request GetEditingProjectMaterialsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetEditingProjectMaterialsResponse
 */
async function getEditingProjectMaterialsWithOptions(request: GetEditingProjectMaterialsRequest, runtime: $RuntimeOptions): GetEditingProjectMaterialsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetEditingProjectMaterials',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries all materials associated with an online editing project.
 *
 * @param request GetEditingProjectMaterialsRequest
 * @return GetEditingProjectMaterialsResponse
 */
async function getEditingProjectMaterials(request: GetEditingProjectMaterialsRequest): GetEditingProjectMaterialsResponse {
  var runtime = new $RuntimeOptions{};
  return getEditingProjectMaterialsWithOptions(request, runtime);
}

model GetEventCallbackResponseBody = {
  authKey?: string(name='AuthKey', description='The authentication key. This parameter is returned only for HTTP callbacks.', example='TestKey001'),
  authSwitch?: string(name='AuthSwitch', description='Specifies whether callback authentication is enabled. This parameter is returned only for **HTTP** callbacks. Valid values:

*   **on**
*   **off**', example='on'),
  callbackQueueName?: string(name='CallbackQueueName', description='The name of the Simple Message Queue (SMQ) queue to which callback messages are sent.', example='ice-callback-queue'),
  callbackType?: string(name='CallbackType', description='The callback method. Valid values:

*   **HTTP**
*   **MNS**', example='HTTP'),
  callbackURL?: string(name='CallbackURL', description='The callback URL to which event notifications are sent.', example='http://xxx.yyy/callback'),
  eventTypeList?: string(name='EventTypeList', description='The type of the callback event. Multiple values are separated with commas (,). For more information about callback event types, see [Event notification content](https://help.aliyun.com/document_detail/610204.html).', example='ProduceMediaComplete,TranscodeComplete'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetEventCallbackResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEventCallbackResponseBody(name='body'),
}

/**
 * @summary Queries event callback configurations.
 *
 * @param request GetEventCallbackRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetEventCallbackResponse
 */
async function getEventCallbackWithOptions(runtime: $RuntimeOptions): GetEventCallbackResponse {
  var req = new OpenApiUtil.OpenApiRequest{};
  var params = new OpenApiUtil.Params{
    action = 'GetEventCallback',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries event callback configurations.
 *
 * @return GetEventCallbackResponse
 */
async function getEventCallback(): GetEventCallbackResponse {
  var runtime = new $RuntimeOptions{};
  return getEventCallbackWithOptions(runtime);
}

model GetLiveEditingIndexFileRequest {
  appName?: string(name='AppName', description='The application name of the live stream.', example='testrecord'),
  domainName?: string(name='DomainName', description='The domain name of the live stream.', example='test.alivecdn.com'),
  projectId?: string(name='ProjectId', description='The ID of the live stream editing project.', example='*****cb6307a4edea614d8b3f3c*****'),
  streamName?: string(name='StreamName', description='The name of the live stream.', example='teststream'),
}

model GetLiveEditingIndexFileResponseBody = {
  indexFile?: string(name='IndexFile', description='The URL of the index file.'),
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
}

model GetLiveEditingIndexFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveEditingIndexFileResponseBody(name='body'),
}

/**
 * @summary Queries the index file of a live stream. The index file is used to preview an editing project in the console.
 *
 * @param request GetLiveEditingIndexFileRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveEditingIndexFileResponse
 */
async function getLiveEditingIndexFileWithOptions(request: GetLiveEditingIndexFileRequest, runtime: $RuntimeOptions): GetLiveEditingIndexFileResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.appName)) {
    query['AppName'] = request.appName;
  }
  if (!$isNull(request.domainName)) {
    query['DomainName'] = request.domainName;
  }
  if (!$isNull(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  if (!$isNull(request.streamName)) {
    query['StreamName'] = request.streamName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetLiveEditingIndexFile',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the index file of a live stream. The index file is used to preview an editing project in the console.
 *
 * @param request GetLiveEditingIndexFileRequest
 * @return GetLiveEditingIndexFileResponse
 */
async function getLiveEditingIndexFile(request: GetLiveEditingIndexFileRequest): GetLiveEditingIndexFileResponse {
  var runtime = new $RuntimeOptions{};
  return getLiveEditingIndexFileWithOptions(request, runtime);
}

model GetLiveEditingJobRequest {
  jobId?: string(name='JobId', description='The ID of the live editing job.', example='****d80e4e4044975745c14b****'),
}

model GetLiveEditingJobResponseBody = {
  liveEditingJob?: {
    clips?: string(name='Clips', description='The clips.', example='[{\\\\"StartTime\\\\": \\\\" 2021-06-21T08:01:00Z\\\\",  \\\\"EndTime\\\\": \\\\" 2021-06-21T08:03:00Z\\\\" }]'),
    code?: string(name='Code', description='The response code. Note: Pay attention to this parameter if the job failed.', example='InvalidParameter'),
    completeTime?: string(name='CompleteTime', description='The time when the live editing job was completed. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:52Z'),
    creationTime?: string(name='CreationTime', description='The time when the live editing job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
    jobId?: string(name='JobId', description='The ID of the live editing job.', example='****cdb3e74639973036bc84****'),
    liveStreamConfig?: {
      appName?: string(name='AppName', description='The name of the application to which the live stream belongs.', example='app'),
      domainName?: string(name='DomainName', description='The domain name of the live stream.', example='domain.com'),
      streamName?: string(name='StreamName', description='The name of the live stream.', example='streamName'),
    }(name='LiveStreamConfig', description='The live editing configurations.'),
    mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****0cc6ba49eab379332c5b****'),
    mediaProduceConfig?: {
      mode?: string(name='Mode', description='The editing mode. Default value: Accurate.', example='Accurate'),
    }(name='MediaProduceConfig', description='The production configurations.'),
    mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example2.mp4'),
    message?: string(name='Message', description='The returned message. Note: Pay attention to this parameter if the job failed.', example='The specific parameter LiveStreamConfig is not valid.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the live editing job was last modified. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:49Z'),
    outputMediaConfig?: {
      bitrate?: long(name='Bitrate', description='The bitrate of the output file. Unit: Kbit/s. You can leave this parameter empty. The default value is the maximum bitrate of the input materials.', example='1000'),
      fileName?: string(name='FileName', description='If OutputMediaTarget is set to vod-media, this parameter indicates the file name of the output file. The value contains the file name extension but not the path.', example='test.mp4'),
      height?: int32(name='Height', description='The height of the output file. You can leave this parameter empty. The default value is the maximum height of the input materials.', example='480'),
      mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='https://testice-testbucket.oss-cn-shanghai.aliyuncs.com/test.mp4'),
      storageLocation?: string(name='StorageLocation', description='If OutputMediaTarget is set to vod-media, this parameter indicates the storage location of the media asset in ApsaraVideo VOD. The storage location is the path of the file in ApsaraVideo VOD, excluding the prefix http://. Example: outin-xxxxxx.oss-cn-shanghai.aliyuncs.com.', example='outin-xxxxxx.oss-cn-shanghai.aliyuncs.com'),
      vodTemplateGroupId?: string(name='VodTemplateGroupId', description='The ID of the VOD transcoding template group. If VOD transcoding is not required, set the value to VOD_NO_TRANSCODE.', example='VOD_NO_TRANSCODE'),
      width?: int32(name='Width', description='The width of the output file. You can leave this parameter empty. The default value is the maximum width of the input materials.', example='640'),
    }(name='OutputMediaConfig', description='The storage configurations of the output file.'),
    projectId?: string(name='ProjectId', description='The ID of the live editing project.', example='****fddd7748b58bf1d47e95****'),
    status?: string(name='Status', description='The state of the live editing job. Valid values: Init, Queuing, Processing, Success, and Failed.', example='Success'),
    userData?: string(name='UserData', description='The user-defined data.', example='{"key": "value\\\\"}'),
  }(name='LiveEditingJob', description='The information about the live editing job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model GetLiveEditingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveEditingJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a live editing job. The requested information includes the state, timeline, and template of the job, the ID and URL of the output file, and the configurations of the job. You can call this operation to query only live editing jobs created within the past year.
 *
 * @param request GetLiveEditingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveEditingJobResponse
 */
async function getLiveEditingJobWithOptions(request: GetLiveEditingJobRequest, runtime: $RuntimeOptions): GetLiveEditingJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetLiveEditingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a live editing job. The requested information includes the state, timeline, and template of the job, the ID and URL of the output file, and the configurations of the job. You can call this operation to query only live editing jobs created within the past year.
 *
 * @param request GetLiveEditingJobRequest
 * @return GetLiveEditingJobResponse
 */
async function getLiveEditingJob(request: GetLiveEditingJobRequest): GetLiveEditingJobResponse {
  var runtime = new $RuntimeOptions{};
  return getLiveEditingJobWithOptions(request, runtime);
}

model GetLivePackageChannelRequest {
  channelName?: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1'),
  groupName?: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1'),
}

model GetLivePackageChannelResponseBody = {
  livePackageChannel?: {
    channelName?: string(name='ChannelName', description='The channel name.', example='ch4'),
    createTime?: string(name='CreateTime', description='The time when the channel was created.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The channel description.'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    ingestEndpoints?: [ 
      {
        id?: string(name='Id', description='The ingest endpoint ID.', example='ingest1'),
        password?: string(name='Password', description='The password.', example='2F9e******b569c8'),
        url?: string(name='Url', description='The ingest endpoint URL.', example='http://xxx-1.packagepush-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
        username?: string(name='Username', description='The username.', example='us12******das'),
      }
    ](name='IngestEndpoints', description='The ingest endpoints.'),
    lastModified?: string(name='LastModified', description='The time when the endpoint was last modified.', example='2023-04-01T12:00:00Z'),
    protocol?: string(name='Protocol', description='The ingest protocol. Only HLS is supported.', example='HLS'),
    segmentCount?: int32(name='SegmentCount', description='The number of M3U8 segments.', example='3'),
    segmentDuration?: int32(name='SegmentDuration', description='The segment duration.', example='5'),
  }(name='LivePackageChannel', description='Details of the live package channel.'),
  requestId?: string(name='RequestId', description='The request ID.', example='RequestId-12345678'),
}

model GetLivePackageChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLivePackageChannelResponseBody(name='body'),
}

/**
 * @summary Queries the details of a live package channel.
 *
 * @description ## [](#)Usage notes
 * This API operation allows you to query the details of a live package channel, including the creation time, description, ingest endpoint, protocol, number of segments, and segment duration.
 *
 * @param request GetLivePackageChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLivePackageChannelResponse
 */
async function getLivePackageChannelWithOptions(request: GetLivePackageChannelRequest, runtime: $RuntimeOptions): GetLivePackageChannelResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetLivePackageChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the details of a live package channel.
 *
 * @description ## [](#)Usage notes
 * This API operation allows you to query the details of a live package channel, including the creation time, description, ingest endpoint, protocol, number of segments, and segment duration.
 *
 * @param request GetLivePackageChannelRequest
 * @return GetLivePackageChannelResponse
 */
async function getLivePackageChannel(request: GetLivePackageChannelRequest): GetLivePackageChannelResponse {
  var runtime = new $RuntimeOptions{};
  return getLivePackageChannelWithOptions(request, runtime);
}

model GetLivePackageChannelGroupRequest {
  groupName?: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1'),
}

model GetLivePackageChannelGroupResponseBody = {
  livePackageChannelGroup?: {
    createTime?: string(name='CreateTime', description='The time when the channel group was created. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The channel group description.', example='Updated description of the channel group.'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    lastModified?: string(name='LastModified', description='The time when the channel group was last modified. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    originDomain?: string(name='OriginDomain', description='The origin domain.', example='example.com'),
  }(name='LivePackageChannelGroup', description='Details of the channel group.'),
  requestId?: string(name='RequestId', description='The request ID.', example='req-abcdefg123456'),
}

model GetLivePackageChannelGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLivePackageChannelGroupResponseBody(name='body'),
}

/**
 * @summary Queries the details of a live package channel group by name.
 *
 * @description ## [](#)Usage notes
 * You can call this API operation to query the details of a specific channel group, including its name, description, origin domain, and creation and last modification timestamps.
 *
 * @param request GetLivePackageChannelGroupRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLivePackageChannelGroupResponse
 */
async function getLivePackageChannelGroupWithOptions(request: GetLivePackageChannelGroupRequest, runtime: $RuntimeOptions): GetLivePackageChannelGroupResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetLivePackageChannelGroup',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the details of a live package channel group by name.
 *
 * @description ## [](#)Usage notes
 * You can call this API operation to query the details of a specific channel group, including its name, description, origin domain, and creation and last modification timestamps.
 *
 * @param request GetLivePackageChannelGroupRequest
 * @return GetLivePackageChannelGroupResponse
 */
async function getLivePackageChannelGroup(request: GetLivePackageChannelGroupRequest): GetLivePackageChannelGroupResponse {
  var runtime = new $RuntimeOptions{};
  return getLivePackageChannelGroupWithOptions(request, runtime);
}

model GetLivePackageOriginEndpointRequest {
  channelName?: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1'),
  endpointName?: string(name='EndpointName', description='The endpoint name.

This parameter is required.', example='endpoint-1'),
  groupName?: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1'),
}

model GetLivePackageOriginEndpointResponseBody = {
  livePackageOriginEndpoint?: {
    authorizationCode?: string(name='AuthorizationCode', description='The authorization code.', example='Abc123Def456'),
    channelName?: string(name='ChannelName', description='The channel name.', example='channel-1'),
    createTime?: string(name='CreateTime', description='The time when the endpoint was created.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The endpoint description.'),
    endpointName?: string(name='EndpointName', description='The endpoint name.', example='endpoint-1'),
    endpointUrl?: string(name='EndpointUrl', description='The endpoint URL.', example='https://xxx.packagepull-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    ipBlacklist?: string(name='IpBlacklist', description='The IP address blacklist.', example='10.21.222.1/32'),
    ipWhitelist?: string(name='IpWhitelist', description='The IP address whitelist.', example='192.168.1.0/24,10.0.0.1/24'),
    lastModified?: string(name='LastModified', description='The time when the endpoint was last modified.', example='2023-04-01T12:00:00Z'),
    manifestName?: string(name='ManifestName', description='The playlist name.', example='manifest'),
    protocol?: string(name='Protocol', description='The distribution protocol.', example='HLS'),
    timeshiftVision?: int32(name='TimeshiftVision', description='The number of days that time-shifted content is available.', example='5'),
  }(name='LivePackageOriginEndpoint', description='The information about the origin endpoints.'),
  requestId?: string(name='RequestId', description='The request ID.', example='requestIdExample123'),
}

model GetLivePackageOriginEndpointResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLivePackageOriginEndpointResponseBody(name='body'),
}

/**
 * @summary Queries origin endpoints associated with a live package channel.
 *
 * @description ## [](#)Usage notes
 *
 * @param request GetLivePackageOriginEndpointRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLivePackageOriginEndpointResponse
 */
async function getLivePackageOriginEndpointWithOptions(request: GetLivePackageOriginEndpointRequest, runtime: $RuntimeOptions): GetLivePackageOriginEndpointResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.endpointName)) {
    query['EndpointName'] = request.endpointName;
  }
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetLivePackageOriginEndpoint',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries origin endpoints associated with a live package channel.
 *
 * @description ## [](#)Usage notes
 *
 * @param request GetLivePackageOriginEndpointRequest
 * @return GetLivePackageOriginEndpointResponse
 */
async function getLivePackageOriginEndpoint(request: GetLivePackageOriginEndpointRequest): GetLivePackageOriginEndpointResponse {
  var runtime = new $RuntimeOptions{};
  return getLivePackageOriginEndpointWithOptions(request, runtime);
}

model GetLiveRecordJobRequest {
  jobId?: string(name='JobId', description='The ID of the recording job.

This parameter is required.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
}

model GetLiveRecordJobResponseBody = {
  recordJob?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T02:48:58Z'),
    jobId?: string(name='JobId', description='The ID of the recording job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
    name?: string(name='Name', description='The name of the recording job.'),
    notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify'),
    recordOutput?: {
      bucket?: string(name='Bucket', description='The bucket name.', example='imsbucket1'),
      endpoint?: string(name='Endpoint', description='The endpoint of the storage service.', example='oss-cn-shanghai.aliyuncs.com'),
      type?: string(name='Type', description='The type of the storage address.

Valid values:

*   vod
*   oss', example='oss'),
    }(name='RecordOutput', description='The storage address of the recording.'),
    status?: string(name='Status', description='The state of the recording job.

Valid values:

*   paused: The job is paused.
*   initial: The job is not started.
*   started: The job is in progress.', example='paused'),
    streamInput?: {
      type?: string(name='Type', description='The type of the live stream. The value can only be rtmp.', example='rtmp'),
      url?: string(name='Url', description='The URL of the live stream.', example='rtmp://example.com/app/stream'),
    }(name='StreamInput', description='The URL of the live stream.'),
    templateId?: string(name='TemplateId', description='The ID of the recording template.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
    templateName?: string(name='TemplateName', description='The name of the recording template.', example='test template'),
  }(name='RecordJob', description='The details of the recording job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='B57A046C-CE33-5FBB-B57A-D2B89ACF6907'),
}

model GetLiveRecordJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveRecordJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a live stream recording job.
 *
 * @param request GetLiveRecordJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveRecordJobResponse
 */
async function getLiveRecordJobWithOptions(request: GetLiveRecordJobRequest, runtime: $RuntimeOptions): GetLiveRecordJobResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetLiveRecordJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a live stream recording job.
 *
 * @param request GetLiveRecordJobRequest
 * @return GetLiveRecordJobResponse
 */
async function getLiveRecordJob(request: GetLiveRecordJobRequest): GetLiveRecordJobResponse {
  var runtime = new $RuntimeOptions{};
  return getLiveRecordJobWithOptions(request, runtime);
}

model GetLiveRecordTemplateRequest {
  jobId?: string(name='JobId', description='The ID of the recording job. You can specify the JobId parameter to retrieve the snapshot of the template used by the job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
}

model GetLiveRecordTemplateResponseBody = {
  recordTemplate?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
    lastModified?: string(name='LastModified', description='The time when the template was last modified.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
    name?: string(name='Name', description='The template name.', example='test template'),
    recordFormatList?: [ 
      {
        cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds. If you do not specify this parameter, the default value 6 hours is used.', example='7200'),
        format?: string(name='Format', description='The output file format.', example='m3u8'),
        ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording file that is stored in Object Storage Service (OSS).', example='record/{JobId}/{Sequence}{EscapedStartTime}{EscapedEndTime}'),
        sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds.', example='30'),
        sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
      }
    ](name='RecordFormatList', description='The list of recording formats.'),
    templateId?: string(name='TemplateId', description='The template ID.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
    type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
  }(name='RecordTemplate', description='The recording template.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C892855F-95DF-50D6-A28C-279ABDB76810'),
}

model GetLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveRecordTemplateResponseBody(name='body'),
}

/**
 * @summary Queries the information about a live stream recording template or a snapshot of the template.
 *
 * @param request GetLiveRecordTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveRecordTemplateResponse
 */
async function getLiveRecordTemplateWithOptions(request: GetLiveRecordTemplateRequest, runtime: $RuntimeOptions): GetLiveRecordTemplateResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetLiveRecordTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a live stream recording template or a snapshot of the template.
 *
 * @param request GetLiveRecordTemplateRequest
 * @return GetLiveRecordTemplateResponse
 */
async function getLiveRecordTemplate(request: GetLiveRecordTemplateRequest): GetLiveRecordTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return getLiveRecordTemplateWithOptions(request, runtime);
}

model GetLiveSnapshotJobRequest {
  jobId?: string(name='JobId', description='The job ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model GetLiveSnapshotJobResponseBody = {
  callbackUrl?: string(name='CallbackUrl', description='The snapshot callback URL.', example='http://www.aliyun.com/snapshot/callback'),
  createTime?: string(name='CreateTime', description='The time when the file was created.', example='2022-02-02T22:22:22Z'),
  jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287782****'),
  jobName?: string(name='JobName', description='The name of the job.'),
  lastModified?: string(name='LastModified', description='The time when the file was last modified.', example='2022-02-02T22:22:22Z'),
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.', example='snapshot/{JobId}.jpg'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.', example='snapshot/{JobId}/{UnixTimestamp}.jpg'),
  snapshotOutput?: {
    bucket?: string(name='Bucket', description='The bucket of the output endpoint. If the storage type is set to oss, the OSS bucket is returned.', example='testbucket'),
    endpoint?: string(name='Endpoint', description='The output endpoint. If the storage type is set to oss, the Object Storage Service (OSS) domain name is returned.', example='oss-cn-shanghai.aliyuncs.com'),
    storageType?: string(name='StorageType', description='The storage type. The value can only be oss.', example='oss'),
  }(name='SnapshotOutput', description='The output information.'),
  status?: string(name='Status', description='The state of the job.

Valid values:

*   init: The job is not started.
*   paused: The job is paused.
*   started: The job is in progress.', example='started'),
  streamInput?: {
    type?: string(name='Type', description='The type of the input stream. The value can only be rtmp.', example='rtmp'),
    url?: string(name='Url', description='The URL of the input stream.', example='rtmp://www.aliyun.com/stream'),
  }(name='StreamInput', description='The input information.'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287666****'),
  templateName?: string(name='TemplateName', description='The name of the template.'),
  timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots.', example='5'),
}

model GetLiveSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveSnapshotJobResponseBody(name='body'),
}

/**
 * @summary Queries the information a live stream snapshot job.
 *
 * @param request GetLiveSnapshotJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveSnapshotJobResponse
 */
async function getLiveSnapshotJobWithOptions(request: GetLiveSnapshotJobRequest, runtime: $RuntimeOptions): GetLiveSnapshotJobResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetLiveSnapshotJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information a live stream snapshot job.
 *
 * @param request GetLiveSnapshotJobRequest
 * @return GetLiveSnapshotJobResponse
 */
async function getLiveSnapshotJob(request: GetLiveSnapshotJobRequest): GetLiveSnapshotJobResponse {
  var runtime = new $RuntimeOptions{};
  return getLiveSnapshotJobWithOptions(request, runtime);
}

model GetLiveSnapshotTemplateRequest {
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model GetLiveSnapshotTemplateResponseBody = {
  createTime?: string(name='CreateTime', description='The time when the configuration was modified.', example='2022-02-02T22:22:22Z'),
  lastModified?: string(name='LastModified', description='The time when the template was created.', example='2022-02-02T22:22:22Z'),
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.', example='snapshot/{JobId}.jpg'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.', example='snapshot/{JobId}/{UnixTimestamp}.jpg'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287782****'),
  templateName?: string(name='TemplateName', description='The template name.'),
  timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots.', example='5'),
  type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
}

model GetLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveSnapshotTemplateResponseBody(name='body'),
}

/**
 * @summary Queries the information about a live stream snapshot template.
 *
 * @param request GetLiveSnapshotTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveSnapshotTemplateResponse
 */
async function getLiveSnapshotTemplateWithOptions(request: GetLiveSnapshotTemplateRequest, runtime: $RuntimeOptions): GetLiveSnapshotTemplateResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetLiveSnapshotTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a live stream snapshot template.
 *
 * @param request GetLiveSnapshotTemplateRequest
 * @return GetLiveSnapshotTemplateResponse
 */
async function getLiveSnapshotTemplate(request: GetLiveSnapshotTemplateRequest): GetLiveSnapshotTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return getLiveSnapshotTemplateWithOptions(request, runtime);
}

model GetLiveTranscodeJobRequest {
  jobId?: string(name='JobId', description='The ID of the transcoding job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetLiveTranscodeJobResponseBody = {
  job?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T02:48:58Z'),
    jobId?: string(name='JobId', description='The ID of the transcoding job.', example='****20b48fb04483915d4f2cd8ac****'),
    name?: string(name='Name', description='The name of the transcoding job.', example='task1'),
    outputStream?: {
      streamInfos?: [ 
        {
          outputUrl?: string(name='OutputUrl', description='The URL of the output stream.', example='rtmp://mydomain/app/mytranscode1'),
          type?: string(name='Type', description='The type of the output stream protocol. Only the RTMP protocol is supported.', example='rtmp'),
        }
      ](name='StreamInfos', description='The information about the output stream.'),
    }(name='OutputStream', description='The information about the output stream.'),
    startMode?: int32(name='StartMode', description='The start mode of the job.', example='0'),
    status?: int32(name='Status', description='The state of the job.

*   0: The job is not started.
*   1: The job is in progress.
*   2: The job is stopped.', example='1'),
    streamInput?: {
      inputUrl?: string(name='InputUrl', description='The URL of the input stream.', example='rtmp://mydomain/app/stream1'),
      type?: string(name='Type', description='The type of the input stream.', example='rtmp'),
    }(name='StreamInput', description='The information about the input stream.'),
    templateId?: string(name='TemplateId', description='The template ID.', example='b6491d5b3e514b7d895d14b5453ea119'),
    templateName?: string(name='TemplateName', description='The template name.', example='basic'),
    templateType?: string(name='TemplateType', description='The type of the template.', example='normal'),
  }(name='Job', description='The information about the transcoding job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model GetLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveTranscodeJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a live stream transcoding job.
 *
 * @param request GetLiveTranscodeJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveTranscodeJobResponse
 */
async function getLiveTranscodeJobWithOptions(request: GetLiveTranscodeJobRequest, runtime: $RuntimeOptions): GetLiveTranscodeJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetLiveTranscodeJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a live stream transcoding job.
 *
 * @param request GetLiveTranscodeJobRequest
 * @return GetLiveTranscodeJobResponse
 */
async function getLiveTranscodeJob(request: GetLiveTranscodeJobRequest): GetLiveTranscodeJobResponse {
  var runtime = new $RuntimeOptions{};
  return getLiveTranscodeJobWithOptions(request, runtime);
}

model GetLiveTranscodeTemplateRequest {
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287666****'),
}

model GetLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  templateContent?: {
    category?: string(name='Category', description='The category of the template. Valid values:

*   system
*   customized', example='customized'),
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-25T06:15:14Z'),
    name?: string(name='Name', description='The name of the template.', example='my-template'),
    templateConfig?: {
      audioParams?: {
        bitrate?: string(name='Bitrate', description='The bitrate of the output audio.', example='1000'),
        channels?: string(name='Channels', description='The number of sound channels.', example='2'),
        codec?: string(name='Codec', description='The audio codec.', example='AAC'),
        profile?: string(name='Profile', description='The audio codec profile.', example='1'),
        samplerate?: string(name='Samplerate', description='The audio sampling rate.', example='44100'),
      }(name='AudioParams', description='The audio parameters.'),
      videoParams?: {
        bitrate?: string(name='Bitrate', description='The bitrate of the output video.', example='2500'),
        codec?: string(name='Codec', description='The encoding type.', example='H.264'),
        fps?: string(name='Fps', description='The frame rate of the output video.', example='30'),
        gop?: string(name='Gop', description='The group of pictures (GOP) of the output video.', example='1000'),
        height?: string(name='Height', description='The height of the output video.', example='720'),
        profile?: string(name='Profile', description='The encoding profile.', example='2'),
        width?: string(name='Width', description='The width of the output video.', example='1280'),
      }(name='VideoParams', description='The video parameters.'),
    }(name='TemplateConfig', description='The configuration of the template.'),
    templateId?: string(name='TemplateId', description='The template ID.', example='bcfa57950bc649b2abfb476ecd36ea4f'),
    type?: string(name='Type', description='The type of the template.', example='normal'),
  }(name='TemplateContent', description='The content of the template.'),
}

model GetLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLiveTranscodeTemplateResponseBody(name='body'),
}

/**
 * @summary Queries the information a live stream transcoding template.
 *
 * @param request GetLiveTranscodeTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetLiveTranscodeTemplateResponse
 */
async function getLiveTranscodeTemplateWithOptions(request: GetLiveTranscodeTemplateRequest, runtime: $RuntimeOptions): GetLiveTranscodeTemplateResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetLiveTranscodeTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information a live stream transcoding template.
 *
 * @param request GetLiveTranscodeTemplateRequest
 * @return GetLiveTranscodeTemplateResponse
 */
async function getLiveTranscodeTemplate(request: GetLiveTranscodeTemplateRequest): GetLiveTranscodeTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return getLiveTranscodeTemplateWithOptions(request, runtime);
}

model GetMediaConnectFlowRequest {
  flowId?: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f'),
}

model GetMediaConnectFlowResponseBody = {
  content?: {
    createTime?: string(name='CreateTime', description='The time when the flow was created.', example='2024-07-18T01:29:24Z'),
    flowId?: string(name='FlowId', description='The flow ID.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f'),
    flowName?: string(name='FlowName', description='The flow name.', example='AliTestFlow'),
    flowStatus?: string(name='FlowStatus', description='The state of the flow.', example='online'),
    startTime?: string(name='StartTime', description='The time when the flow is started.', example='2024-07-18T01:39:24Z'),
  }(name='Content', description='The response body.'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='FB503AEF-118E-1516-89E2-7B227EA1AC20'),
  retcode?: int32(name='Retcode', description='The returned code. A value of 0 indicates the call is successful.', example='0'),
}

model GetMediaConnectFlowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaConnectFlowResponseBody(name='body'),
}

/**
 * @summary Obtains information about a specific MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 * *   The returned StartTime is valid only when the flow is in the online state.
 *
 * @param request GetMediaConnectFlowRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaConnectFlowResponse
 */
async function getMediaConnectFlowWithOptions(request: GetMediaConnectFlowRequest, runtime: $RuntimeOptions): GetMediaConnectFlowResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.flowId)) {
    query['FlowId'] = request.flowId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetMediaConnectFlow',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Obtains information about a specific MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 * *   The returned StartTime is valid only when the flow is in the online state.
 *
 * @param request GetMediaConnectFlowRequest
 * @return GetMediaConnectFlowResponse
 */
async function getMediaConnectFlow(request: GetMediaConnectFlowRequest): GetMediaConnectFlowResponse {
  var runtime = new $RuntimeOptions{};
  return getMediaConnectFlowWithOptions(request, runtime);
}

model GetMediaConnectFlowInputRequest {
  flowId?: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f'),
}

model GetMediaConnectFlowInputResponseBody = {
  content?: {
    cidrs?: string(name='Cidrs', description='The IP address whitelist in CIDR format. CIDR blocks are separated with commas (,).', example='10.211.0.0/17'),
    createTime?: string(name='CreateTime', description='The time when the flow was created.', example='2024-07-18T01:29:24Z'),
    inputName?: string(name='InputName', description='The source name.', example='AliTestInput'),
    inputProtocol?: string(name='InputProtocol', description='The source type.

Valid values:

*   RTMP-PUSH
*   SRT-Caller
*   RTMP-PULL
*   SRT-Listener
*   Flow', example='RTMP-PUSH'),
    inputUrl?: string(name='InputUrl', description='The source URL.', example='rtmp://1.2.3.4:1935/live/AliTestInput_8666ec062190f00e263012666319a5be'),
    maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s.', example='2000000'),
    pairFlowId?: string(name='PairFlowId', description='The ID of the source flow. This parameter is returned when the source type is Flow.', example='05c3adf4-aa0e-421d-a991-48ceae3e642e'),
    pairOutputName?: string(name='PairOutputName', description='The output of the source flow. This parameter is returned when the source type is Flow.', example='AliTestOutput'),
    srtLatency?: int32(name='SrtLatency', description='The latency for the SRT stream. Unit: milliseconds. This parameter is returned when the source type is SRT-Listener or SRT-Caller.', example='1000'),
    srtPassphrase?: string(name='SrtPassphrase', description='The SRT key. This parameter is returned when the source type is SRT-Listener or SRT-Caller.', example='FICUBPX4Q77DYHRF'),
    srtPbkeyLen?: int32(name='SrtPbkeyLen', description='The encryption key length. This parameter is returned when the source type is SRT-Listener or SRT-Caller.

Valid values:

*   0
*   16
*   24
*   32', example='32'),
  }(name='Content', description='The response body.'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D4C231DF-103A-55FF-8D09-E699552457DE'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model GetMediaConnectFlowInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaConnectFlowInputResponseBody(name='body'),
}

/**
 * @summary Obtains information about the source of a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 *
 * @param request GetMediaConnectFlowInputRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaConnectFlowInputResponse
 */
async function getMediaConnectFlowInputWithOptions(request: GetMediaConnectFlowInputRequest, runtime: $RuntimeOptions): GetMediaConnectFlowInputResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.flowId)) {
    query['FlowId'] = request.flowId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetMediaConnectFlowInput',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Obtains information about the source of a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 *
 * @param request GetMediaConnectFlowInputRequest
 * @return GetMediaConnectFlowInputResponse
 */
async function getMediaConnectFlowInput(request: GetMediaConnectFlowInputRequest): GetMediaConnectFlowInputResponse {
  var runtime = new $RuntimeOptions{};
  return getMediaConnectFlowInputWithOptions(request, runtime);
}

model GetMediaConnectFlowOutputRequest {
  flowId?: string(name='FlowId', description='The flow ID.

This parameter is required.', example='0381f478-7d53-4076-9d5f-27680a6f73e7'),
  outputName?: string(name='OutputName', description='The name of the output that you want to query.

This parameter is required.', example='AliTestOutput'),
}

model GetMediaConnectFlowOutputResponseBody = {
  content?: {
    cidrs?: string(name='Cidrs', description='The IP address whitelist in CIDR format. CIDR blocks are separated with commas (,).', example='10.211.0.0/17'),
    createTime?: string(name='CreateTime', description='The time when the flow was created.', example='2024-07-18T01:29:24Z'),
    outputName?: string(name='OutputName', description='The output name.', example='AliTestInput'),
    outputProtocol?: string(name='OutputProtocol', description='The output type.

Valid values:

*   RTMP-PUSH
*   SRT-Caller
*   RTMP-PULL
*   SRT-Listener
*   Flow', example='SRT-PULL'),
    outputUrl?: string(name='OutputUrl', description='The output URL.', example='srt://1.2.3.4:1025'),
    pairFlowId?: string(name='PairFlowId', description='The ID of the destination flow. This parameter is returned when the output type is Flow.', example='805fbdd0-575e-4146-b35d-ec7f63937b20'),
    pairInputName?: string(name='PairInputName', description='The source name of the destination flow. This parameter is returned when the output type is Flow.', example='AliTestInput'),
    playerLimit?: int32(name='PlayerLimit', description='The maximum number of viewers.', example='5'),
    srtLatency?: int32(name='SrtLatency', description='The latency for the SRT stream. Unit: milliseconds. This parameter is returned when the source type is SRT-Listener or SRT-Caller.', example='1000'),
    srtPassphrase?: string(name='SrtPassphrase', description='The SRT key. This parameter is returned when the source type is SRT-Listener or SRT-Caller.', example='FICUBPX4Q77DYHRF'),
    srtPbkeyLen?: int32(name='SrtPbkeyLen', description='The encryption key length. This parameter is returned when the source type is SRT-Listener or SRT-Caller.

Valid values:

*   0
*   16
*   24
*   32', example='32'),
  }(name='Content', description='The response body.'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='0DB23DCE-0D69-598B-AA7C-7268D55E2F89'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model GetMediaConnectFlowOutputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaConnectFlowOutputResponseBody(name='body'),
}

/**
 * @summary Obtains information about an output of a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 *
 * @param request GetMediaConnectFlowOutputRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaConnectFlowOutputResponse
 */
async function getMediaConnectFlowOutputWithOptions(request: GetMediaConnectFlowOutputRequest, runtime: $RuntimeOptions): GetMediaConnectFlowOutputResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.flowId)) {
    query['FlowId'] = request.flowId;
  }
  if (!$isNull(request.outputName)) {
    query['OutputName'] = request.outputName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetMediaConnectFlowOutput',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Obtains information about an output of a MediaConnect flow.
 *
 * @description *   When the specified flow ID is not available, an error code is returned.
 *
 * @param request GetMediaConnectFlowOutputRequest
 * @return GetMediaConnectFlowOutputResponse
 */
async function getMediaConnectFlowOutput(request: GetMediaConnectFlowOutputRequest): GetMediaConnectFlowOutputResponse {
  var runtime = new $RuntimeOptions{};
  return getMediaConnectFlowOutputWithOptions(request, runtime);
}

model GetMediaConvertJobRequest {
  jobId?: string(name='JobId', description='The ID of the transcoding task.', example='****d80e4e4044975745c14b****'),
}

model GetMediaConvertJobResponseBody = {
  job?: {
    clientToken?: string(name='ClientToken', description='The idempotency key of the request for creating the transcoding task.', example='780018cb-55ba-466d-8acc-946c0c319a0e'),
    code?: string(name='Code', description='The error code returned when the transcoding task failed.', example='InvalidParameter.ResourceContentBad'),
    config?: {
      inputs?: [
        MediaConvertInput
      ](name='Inputs', description='The inputs of the transcoding task.'),
      outputGroups?: [
        MediaConvertOutputGroup
      ](name='OutputGroups', description='The output group configurations.'),
      outputs?: [
        MediaConvertOutput
      ](name='Outputs', description='The output configurations.'),
    }(name='Config', description='The configurations of the transcoding task.'),
    jobId?: string(name='JobId', description='The ID of the transcoding task, which is a 32-bit string.', example='******4579b5e748b99a27f6d6******'),
    message?: string(name='Message', description='The error message returned when the transcoding task failed.', example='The resource operated InputFile is bad'),
    outputDetails?: [
      MediaConvertOutputDetail
    ](name='OutputDetails', description='The details of the transcoded outputs, each corresponding to an output configuration.'),
    outputGroupDetails?: [
      MediaConvertOutputGroupDetail
    ](name='OutputGroupDetails', description='The details of the output groups, each corresponding to an output group configuration.'),
    pipelineId?: string(name='PipelineId', description='The ID of the queue.', example='83500cb2a3b94fabb0956e38d64bd16d'),
    requestId?: string(name='RequestId', description='The ID of the request for creating the transcoding task.', example='******11-DB8D-4A9A-875B-275798******'),
    state?: string(name='State', description='The status of the transcoding task. Valid values:

*   Inited: The task is initialized.
*   Running
*   Success
*   Failed
*   Cancelled', example='Success'),
    userData?: string(name='UserData', description='The user data.', example='{"videoId":"ddd333"}'),
  }(name='Job', description='The transcoding task.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='4BAEA8E8-1C16-5CD3-AC50-CCBA81A53402'),
}

model GetMediaConvertJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaConvertJobResponseBody(name='body'),
}

/**
 * @summary Obtains the details of a transcoding task.
 *
 * @param request GetMediaConvertJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaConvertJobResponse
 */
async function getMediaConvertJobWithOptions(request: GetMediaConvertJobRequest, runtime: $RuntimeOptions): GetMediaConvertJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetMediaConvertJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Obtains the details of a transcoding task.
 *
 * @param request GetMediaConvertJobRequest
 * @return GetMediaConvertJobResponse
 */
async function getMediaConvertJob(request: GetMediaConvertJobRequest): GetMediaConvertJobResponse {
  var runtime = new $RuntimeOptions{};
  return getMediaConvertJobWithOptions(request, runtime);
}

model GetMediaInfoRequest {
  inputURL?: string(name='InputURL', description='The input URL of the media asset in another service. The URL must be registered in the IMS content library and bound to the ID of the media asset in IMS.

*   For a media asset from Object Storage Service (OSS), the URL may have one of the following formats:

http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4 or

oss://example-bucket/example.mp4. The second format indicates that the region in which the OSS bucket of the media asset resides is the same as the region in which OSS is activated.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset in IMS. If this parameter is left empty, the InputURL parameter must be specified.', example='****20b48fb04483915d4f2cd8ac****'),
  outputType?: string(name='OutputType', description='The type of the URL of the media asset to return in the response. Valid values:

*   oss (default): an OSS URL.
*   cdn: a CDN URL. A CDN URL is returned only if the media asset is imported from ApsaraVideo VOD and the relevant domain name is an accelerated domain name in ApsaraVideo VOD.', example='cdn'),
  returnDetailedInfo?: string(name='ReturnDetailedInfo', description='Specifies whether to return detailed information for specific media asset attributes. Supported attributes: AiRoughData.StandardSmartTagJob, which specifies whether to return detailed tag information if a tagging job has been submitted for the media asset. Valid values for the attribute:

*   false (default): The job result is returned as a URL.
*   true: The job result is returned as text.', example='{"AiRoughData.StandardSmartTagJob": false}'),
}

model GetMediaInfoResponseBody = {
  mediaInfo?: {
    aiRoughData?: {
      aiCategory?: string(name='AiCategory', description='The AI category. Valid values:

*   Life
*   Good-looking
*   Cute pets
*   News
*   Ads
*   Environmental resources
*   Automobile'),
      aiJobId?: string(name='AiJobId', description='The ID of the AI task.', example='****483915d4f2cd8ac20b48fb04****'),
      result?: string(name='Result', description='The analysis result.', example='https://sample-bucket.cn-shanghai.aliyuncs.com/result.json'),
      saveType?: string(name='SaveType', description='The storage type. This parameter indicates the library in which the analysis data is stored. Valid values:

*   TEXT: the text library.', example='TEXT'),
      standardSmartTagJob?: {
        aiJobId?: string(name='AiJobId', description='The ID of the AI task.', example='****483915d4f2cd8ac20b48fb04****'),
        resultUrl?: string(name='ResultUrl', description='The URL of the tagging result.', example='http://xx.oss-cn-shanghai.aliyuncs.com/result2.txt'),
        results?: [ 
          {
            data?: string(name='Data', description='The result data. The value is a JSON string. For information about the data structures of different data types<props="china">, see [Description of the Results parameter](https://help.aliyun.com/zh/ims/developer-reference/api-ice-2020-11-09-querysmarttagjob?spm=a2c4g.11186623.0.0.521d48b7KfapOL#api-detail-40).', example='{"autoChapters": [...]}'),
            type?: string(name='Type', description='The tagging type. Valid values:

*   NLP: natural language processing (NLP)-based tagging', example='NLP'),
          }
        ](name='Results', description='The recognized tags.'),
        status?: string(name='Status', description='The analysis status. Valid values:

*   Analyzing
*   AnalyzeSuccess
*   AnalyzeFailed', example='Analyzing'),
      }(name='StandardSmartTagJob', description='The information about the tagging job.'),
      status?: string(name='Status', description='The analysis status. Valid values:

*   Analyzing
*   AnalyzeSuccess
*   AnalyzeFailed
*   Saving
*   SaveSuccess
*   SaveFailed
*   Deleting
*   DeleteSuccess
*   DeleteFailed', example='Analyzing'),
    }(name='AiRoughData', description='The original AI analysis data.'),
    fileInfoList?: [ 
      {
        audioStreamInfoList?: [ 
          {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='127.794'),
            channelLayout?: string(name='ChannelLayout', description='The output layout of sound channels.', example='stereo'),
            channels?: string(name='Channels', description='The number of sound channels.', example='2'),
            codecLongName?: string(name='CodecLongName', description='The full name of the codec.', example='AAC (Advanced Audio Coding)'),
            codecName?: string(name='CodecName', description='The short name of the codec.', example='aac'),
            codecTag?: string(name='CodecTag', description='The tag of the codec.', example='0x6134706d'),
            codecTagString?: string(name='CodecTagString', description='The tag string of the codec.', example='mp4a'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the codec.', example='1/24000'),
            duration?: string(name='Duration', description='The duration.', example='16.200998'),
            fps?: string(name='Fps', description='The audio frame rate.', example='8'),
            index?: string(name='Index', description='The sequence number of the audio track.', example='1'),
            lang?: string(name='Lang', description='The language.', example='und'),
            numFrames?: string(name='NumFrames', description='The number of frames.', example='10'),
            profile?: string(name='Profile', description='The codec profile.', example='High'),
            sampleFmt?: string(name='SampleFmt', description='The sampling format.', example='fltp'),
            sampleRate?: string(name='SampleRate', description='The sampling rate.', example='44100'),
            startTime?: string(name='StartTime', description='The start time.', example='0.000000'),
            timebase?: string(name='Timebase', description='The time base.', example='1/44100'),
          }
        ](name='AudioStreamInfoList', description='The information about the audio tracks. A media asset may have multiple audio tracks.'),
        fileBasicInfo?: {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='1132.68'),
          createTime?: string(name='CreateTime', description='The time when the file was created.', example='2020-12-26T04:11:08Z'),
          duration?: string(name='Duration', description='The duration.', example='216.206667'),
          fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
          fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='30611502'),
          fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
          fileType?: string(name='FileType', description='The file type.', example='source_file'),
          fileUrl?: string(name='FileUrl', description='The OSS URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
          formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
          height?: string(name='Height', description='The height.', example='540'),
          modifiedTime?: string(name='ModifiedTime', description='The time when the file was last modified.', example='2020-12-26T04:11:10Z'),
          region?: string(name='Region', description='The region in which the file is stored.', example='cn-shanghai'),
          width?: string(name='Width', description='The width.', example='960'),
        }(name='FileBasicInfo', description='The basic information about the file, including the duration and size.'),
        subtitleStreamInfoList?: [ 
          {
            codecLongName?: string(name='CodecLongName', description='The full name of the codec.', example='SubRip Text'),
            codecName?: string(name='CodecName', description='The short name of the codec.', example='srt'),
            codecTag?: string(name='CodecTag', description='The tag of the codec.', example='unicode'),
            codecTagString?: string(name='CodecTagString', description='The tag string of the codec.', example='unicode'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the codec.', example='29.97'),
            duration?: string(name='Duration', description='The duration.', example='1'),
            index?: string(name='Index', description='The sequence number of the subtitle track.', example='1'),
            lang?: string(name='Lang', description='The language.', example='und'),
            startTime?: string(name='StartTime', description='The start time.', example='0'),
            timebase?: string(name='Timebase', description='The time base.', example='30'),
          }
        ](name='SubtitleStreamInfoList', description='The information about the subtitle tracks. A media asset may have multiple subtitle tracks.'),
        videoStreamInfoList?: [ 
          {
            avgFPS?: string(name='AvgFPS', description='The average video frame rate.', example='24.0'),
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1001.594'),
            codecLongName?: string(name='CodecLongName', description='The full name of the codec.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
            codecName?: string(name='CodecName', description='The short name of the codec.', example='h264'),
            codecTag?: string(name='CodecTag', description='The tag of the codec.', example='0x0000'),
            codecTagString?: string(name='CodecTagString', description='The tag string of the codec.', example='[0][0][0][0]'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the codec.', example='1/48'),
            dar?: string(name='Dar', description='The display aspect ratio (DAR).', example='0:1'),
            duration?: string(name='Duration', description='The duration.', example='216.206706'),
            fps?: string(name='Fps', description='The video frame rate.', example='24.0'),
            hasBFrames?: string(name='HasBFrames', description='Indicates whether the video track contains bidirectional frames (B-frames).', example='2'),
            height?: string(name='Height', description='The height.', example='540'),
            index?: string(name='Index', description='The sequence number of the video track.', example='0'),
            lang?: string(name='Lang', description='The language.', example='und'),
            level?: string(name='Level', description='The codec level.', example='30'),
            nbFrames?: string(name='Nb_frames', description='The total number of frames.', example='5184'),
            numFrames?: string(name='NumFrames', description='The number of frames.', example='5184'),
            pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
            profile?: string(name='Profile', description='The codec profile.', example='High'),
            rotate?: string(name='Rotate', description='The rotation angle.', example='0'),
            sar?: string(name='Sar', description='The sample aspect ratio (SAR).', example='0:1'),
            startTime?: string(name='StartTime', description='The start time.', example='0.081706'),
            timebase?: string(name='Timebase', description='The time base.', example='1/12288'),
            width?: string(name='Width', description='The width.', example='960'),
          }
        ](name='VideoStreamInfoList', description='The information about the video tracks. A media asset may have multiple video tracks.'),
      }
    ](name='FileInfoList', description='The file information.'),
    mediaBasicInfo?: {
      biz?: string(name='Biz', description='The service to which the media asset belongs.', example='ICE'),
      businessType?: string(name='BusinessType', description='The business type.', example='general'),
      cateId?: long(name='CateId', description='The category ID.', example='3048'),
      cateName?: string(name='CateName', description='The category name.', example='cateName'),
      category?: string(name='Category', description='The category.'),
      coverURL?: string(name='CoverURL', description='The URL of the thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
      createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-26T04:11:08Z'),
      deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-26T04:11:15Z'),
      description?: string(name='Description', description='The content description.'),
      inputURL?: string(name='InputURL', description='The input URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
      mediaTags?: string(name='MediaTags', description='The tags.'),
      mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2020-12-26T04:11:10Z'),
      referenceId?: string(name='ReferenceId', description='The custom ID. The ID can be 6 to 64 characters in length and can contain only letters, digits, hyphens (-), and underscores (_). The ID is unique among users.', example='123-1234'),
      snapshots?: string(name='Snapshots', description='The snapshots.', example='[
    "http://example-bucket.oss-cn-shanghai.aliyuncs.com/snapshot-00001.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>",
    "http://example-bucket.oss-cn-shanghai.aliyuncs.com/snapshot-00002.jpg?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>",
    "http://example-bucket.oss-cn-shanghai.aliyuncs.com/snapshot-00003.jpg?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>"
]'),
      source?: string(name='Source', description='The source.', example='oss'),
      spriteImages?: string(name='SpriteImages', description='The sprite.', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
      status?: string(name='Status', description='The resource status.', example='Normal'),
      title?: string(name='Title', description='The title.'),
      uploadSource?: string(name='UploadSource', description='The upload source of the media asset.', example='general'),
      userData?: string(name='UserData', description='The user data.', example='userDataTest'),
    }(name='MediaBasicInfo', description='The basic information about the media asset.'),
    mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  }(name='MediaInfo', description='The information about the media asset.'),
  requestId?: string(name='RequestId', description='The request ID.', example='2FDE2411-DB8D-4A9A-875B-275798F14A5E'),
}

model GetMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaInfoResponseBody(name='body'),
}

/**
 * @summary Queries information about a media asset based on the ID of the media asset in Intelligent Media Services (IMS) or the input URL of the media asset.
 *
 * @description If the MediaId parameter is specified, the MediaId parameter is preferentially used for the query. If the MediaId parameter is left empty, the InputURL parameter must be specified.
 *
 * @param request GetMediaInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaInfoResponse
 */
async function getMediaInfoWithOptions(request: GetMediaInfoRequest, runtime: $RuntimeOptions): GetMediaInfoResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.inputURL)) {
    query['InputURL'] = request.inputURL;
  }
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.outputType)) {
    query['OutputType'] = request.outputType;
  }
  if (!$isNull(request.returnDetailedInfo)) {
    query['ReturnDetailedInfo'] = request.returnDetailedInfo;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetMediaInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries information about a media asset based on the ID of the media asset in Intelligent Media Services (IMS) or the input URL of the media asset.
 *
 * @description If the MediaId parameter is specified, the MediaId parameter is preferentially used for the query. If the MediaId parameter is left empty, the InputURL parameter must be specified.
 *
 * @param request GetMediaInfoRequest
 * @return GetMediaInfoResponse
 */
async function getMediaInfo(request: GetMediaInfoRequest): GetMediaInfoResponse {
  var runtime = new $RuntimeOptions{};
  return getMediaInfoWithOptions(request, runtime);
}

model GetMediaInfoJobRequest {
  jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
}

model GetMediaInfoJobResponseBody = {
  mediaInfoJob?: {
    async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
    input?: {
      media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    mediaInfoProperty?: {
      audioStreamInfoList?: [ 
        {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
          channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
          codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
          codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
          codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
          codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
          duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
          index?: string(name='Index', description='The sequence number of the stream.', example='1'),
          lang?: string(name='Lang', description='The language of the stream.', example='us'),
          sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
          sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
          startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
          timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
        }
      ](name='AudioStreamInfoList', description='The information about the audio stream.'),
      fileBasicInfo?: {
        bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
        duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
        fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
        fileSize?: string(name='FileSize', description='The file size.', example='31737'),
        fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
        fileType?: string(name='FileType', description='The file type.', example='source_file'),
        fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
        formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
        height?: string(name='Height', description='The height of the output video.', example='478'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='e520090207114cc7a392d44f0b211574'),
        region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
        width?: string(name='Width', description='The width of the output video.', example='848'),
      }(name='FileBasicInfo', description='The basic file information.'),
      videoStreamInfoList?: [ 
        {
          avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
          bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
          codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
          codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
          codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
          codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
          codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
          dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          fps?: string(name='Fps', description='The frame rate.', example='25.0'),
          hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
          height?: string(name='Height', description='The height of the output video.', example='478'),
          index?: string(name='Index', description='The sequence number of the stream.', example='0'),
          lang?: string(name='Lang', description='The language of the stream.', example='zh'),
          level?: string(name='Level', description='The codec level.', example='31'),
          numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
          pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
          profile?: string(name='Profile', description='The encoder profile.', example='High'),
          rotate?: string(name='Rotate', description='The rotation angle of the video image.', example='0'),
          sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
          startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
          timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
          width?: string(name='Width', description='The width of the output video.', example='848'),
        }
      ](name='VideoStreamInfoList', description='The information about the video stream.'),
    }(name='MediaInfoProperty', description='The details of the media information.'),
    name?: string(name='Name', description='The job name.', example='job-name'),
    requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling information.'),
    status?: string(name='Status', description='The state of the job. Valid values: Init (the job is submitted), Success (the job is successful), and Fail (the job failed).', example='Init'),
    submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='MediaInfoJob', description='MediaInfoJobDTO'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model GetMediaInfoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaInfoJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a media information analysis job.
 *
 * @param request GetMediaInfoJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaInfoJobResponse
 */
async function getMediaInfoJobWithOptions(request: GetMediaInfoJobRequest, runtime: $RuntimeOptions): GetMediaInfoJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetMediaInfoJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a media information analysis job.
 *
 * @param request GetMediaInfoJobRequest
 * @return GetMediaInfoJobResponse
 */
async function getMediaInfoJob(request: GetMediaInfoJobRequest): GetMediaInfoJobResponse {
  var runtime = new $RuntimeOptions{};
  return getMediaInfoJobWithOptions(request, runtime);
}

model GetMediaLiveChannelRequest {
  channelId?: string(name='ChannelId', description='The ID of the channel.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
}

model GetMediaLiveChannelResponseBody = {
  channel?: {
    audioSettings?: [ 
      {
        audioCodec?: string(name='AudioCodec', description='The audio codec.', example='aac'),
        audioCodecSetting?: {
          bitrate?: int32(name='Bitrate', description='The audio bitrate. Unit: bit/s.', example='200000'),
          profile?: string(name='Profile', description='The audio codec profile.', example='AAC-LOW'),
          sampleRate?: int32(name='SampleRate', description='The audio sample rate. Unit: Hz.', example='44100'),
        }(name='AudioCodecSetting', description='The audio encoding settings.'),
        audioSelectorName?: string(name='AudioSelectorName', description='The name of the audio selector.', example='myselector'),
        languageCode?: string(name='LanguageCode', description='A three-letter ISO 639-2 language code.', example='eng'),
        languageName?: string(name='LanguageName', description='The name of the language.', example='English'),
        name?: string(name='Name', description='The name of the audio settings.', example='zhuanfengzhuang'),
      }
    ](name='AudioSettings', description='The audio settings.'),
    channelId?: string(name='ChannelId', description='The ID of the channel.', example='SEGK5KA6KYKAWQQH'),
    createTime?: string(name='CreateTime', description='The time when the channel was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-12-03T06:56:42Z'),
    inputAttachments?: [ 
      {
        audioSelectors?: [ 
          {
            audioLanguageSelection?: {
              languageCode?: string(name='LanguageCode', description='A three-letter ISO 639-2 language code from within an audio source.

This parameter is required.', example='eng'),
            }(name='AudioLanguageSelection', description='The audio language selection.'),
            audioPidSelection?: {
              pid?: long(name='Pid', description='A PID from within a source.

This parameter is required.', example='123'),
            }(name='AudioPidSelection', description='The audio PID selection.'),
            audioTrackSelection?: [ 
              {
                trackId?: long(name='TrackId', description='The track ID from within a source.

This parameter is required.', example='1'),
              }
            ](name='AudioTrackSelection', description='The audio track selection.'),
            name?: string(name='Name', description='The name of the audio selector.

This parameter is required.', example='myselector'),
          }
        ](name='AudioSelectors', description='The audio selectors.'),
        inputId?: string(name='InputId', description='The ID of the associated input.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
        inputName?: string(name='InputName', description='The name of the input.', example='myinput'),
        languageName?: string(name='LanguageName', description='The language name.', example='eng'),
      }
    ](name='InputAttachments', description='The inputs associated with the channel.'),
    lastStartTime?: string(name='LastStartTime', description='The time when the channel was last started. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC. If the channel has never been started since it was created, an empty string is returned.', example='2024-12-03T06:56:42Z'),
    lastStopTime?: string(name='LastStopTime', description='The time when the channel was last stopped. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC. If the channel has never stopped since it was created, an empty string is returned.', example='2024-12-03T06:56:42Z'),
    name?: string(name='Name', description='The channel name.', example='mych'),
    outputGroups?: [ 
      {
        mediaPackageGroupSetting?: {
          channelName?: string(name='ChannelName', description='ChannelName in MediaPackage.', example='myPackageChannel'),
          groupName?: string(name='GroupName', description='GroupName in MediaPackage.', example='myPackageGroup'),
        }(name='MediaPackageGroupSetting', description='The MediaPackage destination.'),
        monitorUrl?: string(name='MonitorUrl', description='The URL for monitoring the output group. The parameter is returned only when the output gourp type is MediaPackage.', example='rtmp://xxx'),
        name?: string(name='Name', description='The name of the output group.', example='group1'),
        outputs?: [ 
          {
            audioSettingNames?: [ string ](name='AudioSettingNames', description='The referenced AudioSettings.'),
            mediaPackageOutputSetting?: {
              audioGroupId?: string(name='AudioGroupId', description='The manifest audio group ID.', example='audiogroup'),
              nameModifier?: string(name='NameModifier', description='The manifest name modifier. The child manifests include this modifier in their M3U8 file names.', example='480p'),
            }(name='MediaPackageOutputSetting', description='The settings of the output delivered to MediaPackage.'),
            mediaType?: int32(name='MediaType', description='The media type of the output.', example='0'),
            name?: string(name='Name', description='The name of the output.', example='output1'),
            videoSettingName?: string(name='VideoSettingName', description='The name of the referenced VideoSettings.', example='myVideo1'),
          }
        ](name='Outputs', description='The outputs in the output group.'),
        type?: string(name='Type', description='The output group type.', example='MediaPackage'),
      }
    ](name='OutputGroups', description='The output groups.'),
    state?: string(name='State', description='The state of the channel. Valid values: IDLE, STARTING, RUNNING, RECOVERING, and STOPPING.', example='IDLE'),
    videoSettings?: [ 
      {
        height?: int32(name='Height', description='The height of the video in pixels.', example='720'),
        name?: string(name='Name', description='The name of the video settings.', example='video1'),
        videoCodec?: string(name='VideoCodec', description='The video codec.', example='H264'),
        videoCodecSetting?: {
          codecDetail?: {
            level?: string(name='Level', description='The video encoding level. It is not supported yet.', example='H264_LEVEL_AUTO'),
            profile?: string(name='Profile', description='The H.264 profile.', example='MAIN'),
          }(name='CodecDetail', description='The video encoding settings.'),
          framerate?: {
            framerateControl?: string(name='FramerateControl', description='The frame rate mode.', example='SPECIFIED'),
            framerateDenominator?: int32(name='FramerateDenominator', description='The denominator of the fixed frame rate.', example='1'),
            framerateNumerator?: int32(name='FramerateNumerator', description='The numerator of the fixed frame rate.', example='25'),
          }(name='Framerate', description='The frame rate.'),
          gop?: {
            bframesNum?: int32(name='BframesNum', description='The number of B frames.', example='3'),
            gopSize?: int32(name='GopSize', description='The GOP size.', example='90'),
            gopSizeUnits?: string(name='GopSizeUnits', description='The GOP size unit.', example='FRAMES'),
          }(name='Gop', description='The GOP setting.'),
          rate?: {
            bitrate?: int32(name='Bitrate', description='The video bitrate. Unit: bit/s.', example='2500000'),
            bufferSize?: int32(name='BufferSize', description='The video buffer size. Unit: bit/s.', example='6000000'),
            maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s.', example='6000000'),
            rateControlMode?: string(name='RateControlMode', description='The bitrate control mode.', example='ABR'),
          }(name='Rate', description='The video encoding rate.'),
        }(name='VideoCodecSetting', description='The video encoding settings.'),
        width?: int32(name='Width', description='The width of the video in pixels.', example='1280'),
      }
    ](name='VideoSettings', description='The video settings.'),
  }(name='Channel', description='The channel information.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetMediaLiveChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaLiveChannelResponseBody(name='body'),
}

/**
 * @summary Queries a MediaLive channel.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request GetMediaLiveChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaLiveChannelResponse
 */
async function getMediaLiveChannelWithOptions(request: GetMediaLiveChannelRequest, runtime: $RuntimeOptions): GetMediaLiveChannelResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.channelId)) {
    body['ChannelId'] = request.channelId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetMediaLiveChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a MediaLive channel.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request GetMediaLiveChannelRequest
 * @return GetMediaLiveChannelResponse
 */
async function getMediaLiveChannel(request: GetMediaLiveChannelRequest): GetMediaLiveChannelResponse {
  var runtime = new $RuntimeOptions{};
  return getMediaLiveChannelWithOptions(request, runtime);
}

model GetMediaLiveInputRequest {
  inputId?: string(name='InputId', description='The ID of the input.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
}

model GetMediaLiveInputResponseBody = {
  input?: {
    channelIds?: [ string ](name='ChannelIds', description='The IDs of the channels associated with the input.'),
    createTime?: string(name='CreateTime', description='The time when the input was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-12-03T06:56:42Z'),
    inputId?: string(name='InputId', description='The ID of the input.', example='SEGK5KA6KYKAWQQH'),
    inputInfos?: [ 
      {
        destHost?: string(name='DestHost', description='The endpoint that the stream is pushed to. This parameter is returned for PUSH inputs.', example='rtmp://domain/app/stream'),
        flowId?: string(name='FlowId'),
        flowOutputName?: string(name='FlowOutputName'),
        monitorUrl?: string(name='MonitorUrl', description='The URL for input monitoring.', example='rtmp://domain/app/stream_for_monitor'),
        sourceUrl?: string(name='SourceUrl', description='The source URL where the stream is pulled from. This parameter is returned for PULL inputs.', example='rtmp://domain/app/stream'),
        streamName?: string(name='StreamName', description='The name of the pushed stream. This parameter is returned for PUSH inputs.', example='mystream'),
      }
    ](name='InputInfos', description='The input configurations.'),
    name?: string(name='Name', description='The name of the input.', example='myinput'),
    securityGroupIds?: [ string ](name='SecurityGroupIds', description='The IDs of the security groups associated with the input.'),
    type?: string(name='Type', description='The input type.', example='RTMP_PUSH'),
  }(name='Input', description='The input information.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetMediaLiveInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaLiveInputResponseBody(name='body'),
}

/**
 * @summary Queries the details of a MediaLive input.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request GetMediaLiveInputRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaLiveInputResponse
 */
async function getMediaLiveInputWithOptions(request: GetMediaLiveInputRequest, runtime: $RuntimeOptions): GetMediaLiveInputResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.inputId)) {
    body['InputId'] = request.inputId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetMediaLiveInput',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the details of a MediaLive input.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request GetMediaLiveInputRequest
 * @return GetMediaLiveInputResponse
 */
async function getMediaLiveInput(request: GetMediaLiveInputRequest): GetMediaLiveInputResponse {
  var runtime = new $RuntimeOptions{};
  return getMediaLiveInputWithOptions(request, runtime);
}

model GetMediaLiveInputSecurityGroupRequest {
  securityGroupId?: string(name='SecurityGroupId', description='The ID of the security group.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
}

model GetMediaLiveInputSecurityGroupResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  securityGroup?: {
    createTime?: string(name='CreateTime', description='The time when the security group was created. It follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-06-13T08:31:56Z'),
    inputIds?: [ string ](name='InputIds', description='The IDs of the inputs associated with the security group.'),
    name?: string(name='Name', description='The name of the security group.', example='mysg'),
    securityGroupId?: string(name='SecurityGroupId', description='The ID of the security group.', example='SEGK5KA6KYKAWQQH'),
    whitelistRules?: [ string ](name='WhitelistRules', description='The security group rules.'),
  }(name='SecurityGroup', description='The security group information.'),
}

model GetMediaLiveInputSecurityGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaLiveInputSecurityGroupResponseBody(name='body'),
}

/**
 * @summary Queries the details of a security group in MediaLive.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request GetMediaLiveInputSecurityGroupRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaLiveInputSecurityGroupResponse
 */
async function getMediaLiveInputSecurityGroupWithOptions(request: GetMediaLiveInputSecurityGroupRequest, runtime: $RuntimeOptions): GetMediaLiveInputSecurityGroupResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.securityGroupId)) {
    body['SecurityGroupId'] = request.securityGroupId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetMediaLiveInputSecurityGroup',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the details of a security group in MediaLive.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request GetMediaLiveInputSecurityGroupRequest
 * @return GetMediaLiveInputSecurityGroupResponse
 */
async function getMediaLiveInputSecurityGroup(request: GetMediaLiveInputSecurityGroupRequest): GetMediaLiveInputSecurityGroupResponse {
  var runtime = new $RuntimeOptions{};
  return getMediaLiveInputSecurityGroupWithOptions(request, runtime);
}

model GetMediaMarksRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The mark ID. You can specify multiple mark IDs separated with commas (,).', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
}

model GetMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaMarks?: string(name='MediaMarks', description='The queried marks.

*   The value is in the JSONArray format.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaMarksResponseBody(name='body'),
}

/**
 * @summary Queries the information about marks based on mark IDs.
 *
 * @param request GetMediaMarksRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaMarksResponse
 */
async function getMediaMarksWithOptions(request: GetMediaMarksRequest, runtime: $RuntimeOptions): GetMediaMarksResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.mediaMarkIds)) {
    query['MediaMarkIds'] = request.mediaMarkIds;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetMediaMarks',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about marks based on mark IDs.
 *
 * @param request GetMediaMarksRequest
 * @return GetMediaMarksResponse
 */
async function getMediaMarks(request: GetMediaMarksRequest): GetMediaMarksResponse {
  var runtime = new $RuntimeOptions{};
  return getMediaMarksWithOptions(request, runtime);
}

model GetMediaProducingJobRequest {
  jobId?: string(name='JobId', description='The ID of the media editing and production job.', example='****cdb3e74639973036bc84****'),
}

model GetMediaProducingJobResponseBody = {
  mediaProducingJob?: {
    clipsParam?: string(name='ClipsParam', description='The template parameters of the media editing and production job.', example='{"VideoArray":["****05512043f49f697f7425****","****05512043f49f697f7425****","****05512043f49f697f7425****"]}'),
    code?: string(name='Code', description='The response code

Note: Pay attention to this parameter if the job failed.', example='ExceededMaximumValue'),
    completeTime?: string(name='CompleteTime', description='The time when the media editing and production job was complete.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:52Z'),
    createTime?: string(name='CreateTime', description='The time when the media editing and production job was created.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
    duration?: float(name='Duration', description='The duration of the output file.

Note: This parameter has a value if the job is successful and the output file is an audio or video file.', example='30.500000'),
    jobId?: string(name='JobId', description='The ID of the media editing and production job.', example='****cdb3e74639973036bc84****'),
    mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****0cc6ba49eab379332c5b****'),
    mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example2.mp4'),
    message?: string(name='Message', description='The returned message.

Note: Pay attention to this parameter if the job failed.', example='The specified "Width_Height" has exceeded maximum value.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the media editing and production job was last modified.

The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:49Z'),
    progress?: int32(name='Progress'),
    projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fddd7748b58bf1d47e95****'),
    status?: string(name='Status', description='The state of the media editing and production job. Valid values:

Init

Queuing

Processing

Success

Failed', example='Failed'),
    subJobMaterials?: string(name='SubJobMaterials', description='The materials of the media editing and production job if the job is a subjob of a quick video production job, including the broadcast text and title.', example='{"Title": "Title", "SpeechText": "Broadcast text of a quick video production job"}'),
    templateId?: string(name='TemplateId', description='The ID of the template used by the media editing and production job.', example='****6e76134d739cc3e85d3e****'),
    timeline?: string(name='Timeline', description='The timeline of the media editing and production job.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
    userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"NotifyAddress":"http://xx.xx.xxx","Key":"Valuexxx"}'),
    vodMediaId?: string(name='VodMediaId', description='The media asset ID of the output file in ApsaraVideo VOD if the output file is stored in ApsaraVideo VOD.', example='****332c5b0cc6ba49eab379****'),
  }(name='MediaProducingJob', description='The information about the online editing project.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****83B7-7F87-4792-BFE9-63CD2137****'),
}

model GetMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMediaProducingJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a media editing and production job. The requested information includes the state, timeline, template, and data of the job. You can call this operation to query only media editing and production jobs created within the past year.
 *
 * @param request GetMediaProducingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetMediaProducingJobResponse
 */
async function getMediaProducingJobWithOptions(request: GetMediaProducingJobRequest, runtime: $RuntimeOptions): GetMediaProducingJobResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetMediaProducingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a media editing and production job. The requested information includes the state, timeline, template, and data of the job. You can call this operation to query only media editing and production jobs created within the past year.
 *
 * @param request GetMediaProducingJobRequest
 * @return GetMediaProducingJobResponse
 */
async function getMediaProducingJob(request: GetMediaProducingJobRequest): GetMediaProducingJobResponse {
  var runtime = new $RuntimeOptions{};
  return getMediaProducingJobWithOptions(request, runtime);
}

model GetPackageJobRequest {
  jobId?: string(name='JobId', description='The job ID. You can obtain the job ID from the response parameters of the [SubmitPackageJob](https://help.aliyun.com/document_detail/461964.html) operation.

This parameter is required.', example='ab4802364a2e49208c99efab82dfa8e8'),
}

model GetPackageJobResponseBody = {
  packageJob?: {
    code?: string(name='Code', description='The error code returned if the job fails.', example='InvalidParameter'),
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:34:05Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:44:05Z'),
    inputs?: [ 
      {
        input?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
        }(name='Input', description='The information about the input stream file.'),
      }
    ](name='Inputs', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    message?: string(name='Message', description='The error message that is returned.', example='Resource content bad.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:44:05Z'),
    name?: string(name='Name', description='The name of the job.', example='job-name'),
    output?: {
      media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.m3u8'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
    }(name='Output', description='The output of the job.'),
    outputUrl?: string(name='OutputUrl', description='The URL of the output file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/output.m3u8'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='36f3fee40aa047c0b067d0fb85edc12b'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='6'),
    status?: string(name='Status', description='The state of the job.', example='Init'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-09-08T11:34:05Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
    userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}'),
  }(name='PackageJob', description='The information about the packaging job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model GetPackageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPackageJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a packaging job.
 *
 * @param request GetPackageJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetPackageJobResponse
 */
async function getPackageJobWithOptions(request: GetPackageJobRequest, runtime: $RuntimeOptions): GetPackageJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetPackageJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a packaging job.
 *
 * @param request GetPackageJobRequest
 * @return GetPackageJobResponse
 */
async function getPackageJob(request: GetPackageJobRequest): GetPackageJobResponse {
  var runtime = new $RuntimeOptions{};
  return getPackageJobWithOptions(request, runtime);
}

model GetPipelineRequest {
  pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.

This parameter is required.', example='****96e8864746a0b6f3****'),
}

model GetPipelineResponseBody = {
  pipeline?: {
    createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
    name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.', example='****20b48fb04483915d4f2cd8ac****'),
    priority?: int32(name='Priority', description='The priority of the MPS queue. Valid values: 1 to 10.', example='6'),
    speed?: string(name='Speed', description='The type of the MPS queue.

Valid values:

*   Standard: standard MPS queue.
*   Boost: MPS queue with transcoding speed boosted.
*   NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.', example='Standard'),
    status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Active'),
  }(name='Pipeline', description='The information about the MPS queue.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetPipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPipelineResponseBody(name='body'),
}

/**
 * @summary Queries the information about an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request GetPipelineRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetPipelineResponse
 */
async function getPipelineWithOptions(request: GetPipelineRequest, runtime: $RuntimeOptions): GetPipelineResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.pipelineId)) {
    query['PipelineId'] = request.pipelineId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetPipeline',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request GetPipelineRequest
 * @return GetPipelineResponse
 */
async function getPipeline(request: GetPipelineRequest): GetPipelineResponse {
  var runtime = new $RuntimeOptions{};
  return getPipelineWithOptions(request, runtime);
}

model GetPlayInfoRequest {
  inputURL?: string(name='InputURL', description='The input URL that you specified for the media asset when you registered the media asset. For more information, see [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html).

>  You must specify at least one of the MediaId and InputURL parameters.'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.

>  You must specify at least one of the MediaId and InputURL parameters.', example='86434e152b7d4f20be480574439fe***'),
}

model GetPlayInfoResponseBody = {
  mediaBase?: {
    cateId?: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of the CateId parameter returned by the AddCategory operation that you called to create a category.
*   View the value of the CateId parameter returned by the GetCategories operation that you called to query a category.', example='4220'),
    coverURL?: string(name='CoverURL', description='The URL of the thumbnail.', example='https://***.oss-cn-shanghai.aliyuncs.com/cover/281c64d6-b5fb-4c57-97cd-84da56a8b151_large_cover_url.jpg'),
    creationTime?: string(name='CreationTime', description='The time when the media asset was created.', example='2021-09-22T10:07:31+08:00'),
    description?: string(name='Description', description='The content description.', example='desc'),
    mediaId?: string(name='MediaId', description='The ID of the media asset.', example='2eea77a61c7b4ddd95bec34a6f65b***'),
    mediaTags?: string(name='MediaTags', description='The tags.

*   Up to 16 tags are supported.
*   Multiple tags are separated by commas (,).
*   Each tag can be up to 32 bytes in length.
*   The value is encoded in UTF-8.', example='test,ccc'),
    mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

video audio', example='video'),
    status?: string(name='Status', description='The resource status. Valid values:

Init: the initial state, which indicates that the source file is not ready.

Preparing: The source file is being prepared. For example, the file is being uploaded or edited.

PrepareFail: The source file failed to be prepared. For example, the information of the source file failed to be obtained.

Normal: The source file is ready.', example='Normal'),
    title?: string(name='Title', description='The title.', example='testTitle'),
  }(name='MediaBase', description='The information about the media asset.'),
  playInfoList?: [ 
    {
      bitDepth?: int32(name='BitDepth', description='The color depth.', example='8'),
      bitrate?: string(name='Bitrate', description='The bitrate of the media stream. Unit: Kbit/s.', example='20'),
      creationTime?: string(name='CreationTime', description='The time when the media stream was created. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2022-05-10T02:28:49Z'),
      definition?: string(name='Definition', description='The quality of the media stream. Valid values:

*   **FD**: low definition
*   **LD**: standard definition
*   **SD**: high definition
*   **HD**: ultra-high definition
*   **OD**: original definition
*   **2K**
*   **4K**
*   **SQ**: standard sound quality
*   **HQ**: high sound quality
*   **AUTO**: adaptive bitrate', example='HD'),
      duration?: string(name='Duration', description='The duration of the media stream. Unit: seconds.', example='9.0464'),
      encrypt?: long(name='Encrypt', description='Indicates whether the media stream is encrypted. Valid values:

*   **0**: The media stream is not encrypted.
*   **1**: The media stream is encrypted.', example='0'),
      encryptType?: string(name='EncryptType', description='The encryption type of the media stream. Valid values:

*   **AliyunVoDEncryption**: Alibaba Cloud proprietary cryptography
*   **HLSEncryption**: HTTP Live Streaming (HLS) encryption

>  If the encryption type is AliyunVoDEncryption, only ApsaraVideo Player SDK can be used to play videos.', example='AliyunVoDEncryption'),
      fileURL?: string(name='FileURL', description='The OSS URL of the file.', example='http://outin-***.oss-cn-shanghai.aliyuncs.com/sv/43a68ee9-181809b6aba/43a68ee9-181809b6aba.mpeg'),
      format?: string(name='Format', description='The format of the media stream.

*   If the media asset is a video file, the valid values are **mp4** and **m3u8**.
*   If the media asset is an audio-only file, the value is **mp3**.', example='mp4'),
      fps?: string(name='Fps', description='The frame rate of the media stream. Unit: frames per second (FPS).', example='25'),
      HDRType?: string(name='HDRType', description='The high dynamic range (HDR) type of the media stream. Valid values:

*   HDR
*   HDR10
*   HLG
*   DolbyVision
*   HDRVivid
*   SDR+', example='HDR'),
      height?: long(name='Height', description='The height of the media stream. Unit: pixels.', example='1080'),
      jobId?: string(name='JobId', description='The task ID.', example='36c9d38e70bf43ed9f7f8f48d6356***'),
      modificationTime?: string(name='ModificationTime', description='The time when the media stream was updated. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2022-05-13T11:39:41.714+08:00'),
      narrowBandType?: string(name='NarrowBandType', description='The type of Narrowband HD™ transcoding. Valid values:

*   **0**: standard transcoding
*   **1.0**: Narrowband HD™ 1.0 transcoding
*   **2.0**: Narrowband HD™ 2.0 transcoding

This parameter is returned only when a definition that is available in the built-in Narrowband HD™ 1.0 transcoding template is specified. For more information, see the [Definition parameter in TranscodeTemplate](https://help.aliyun.com/document_detail/52839.html) table.', example='0'),
      playURL?: string(name='PlayURL', description='The playback URL of the media stream.', example='https://***.aliyuncdn.com/sv/756bee1-17f980f0945/756bee1-17f980f0945.mp4'),
      size?: long(name='Size', description='The size of the media stream. Unit: bytes.', example='418112'),
      status?: string(name='Status', description='The status of the media stream. Valid values:

*   **Normal**
*   **Invisible**', example='Normal'),
      streamTags?: string(name='StreamTags', description='The tags of the media stream, which are used to identify the transcoding type.', example='"{\\\\"ims.audioServiceType\\\\": \\\\"AudioEnhancement\\\\"}"'),
      streamType?: string(name='StreamType', description='The type of the media stream. If the media stream is a video stream, the value is **video**. If the media stream is an audio-only stream, the value is **audio**.', example='video'),
      transTemplateType?: string(name='TransTemplateType', description='The type of the transcoding template. Valid values:

*   Normal: standard transcoding
*   AudioTranscode: audio transcoding
*   Remux: container format conversion
*   NarrowBandV1: Narrowband HD™ 1.0
*   NarrowBandV2: Narrowband HD™ 2.0
*   UHD: audio and video enhancement (ultra-high definition)', example='Normal'),
      watermarkId?: string(name='WatermarkId', description='The ID of the watermark that is associated with the media stream.', example='5bed88672b1e2520ead228935ed51***'),
      width?: long(name='Width', description='The width of the media stream. Unit: pixels.', example='1024'),
    }
  ](name='PlayInfoList', description='The information about the audio or video stream.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetPlayInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPlayInfoResponseBody(name='body'),
}

/**
 * @summary Queries the playback URL of a video or audio file based on its ID.
 *
 * @description You use the ID of a video or audio file to query the playback URL of the file. Then, you can use the playback URL to play the audio or video in ApsaraVideo Player SDK (for URL-based playback) or a third-party player.
 *
 * @param request GetPlayInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetPlayInfoResponse
 */
async function getPlayInfoWithOptions(request: GetPlayInfoRequest, runtime: $RuntimeOptions): GetPlayInfoResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.inputURL)) {
    query['InputURL'] = request.inputURL;
  }
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetPlayInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the playback URL of a video or audio file based on its ID.
 *
 * @description You use the ID of a video or audio file to query the playback URL of the file. Then, you can use the playback URL to play the audio or video in ApsaraVideo Player SDK (for URL-based playback) or a third-party player.
 *
 * @param request GetPlayInfoRequest
 * @return GetPlayInfoResponse
 */
async function getPlayInfo(request: GetPlayInfoRequest): GetPlayInfoResponse {
  var runtime = new $RuntimeOptions{};
  return getPlayInfoWithOptions(request, runtime);
}

model GetProgramRequest {
  channelName?: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel'),
  programName?: string(name='ProgramName', description='The name of the program.

This parameter is required.', example='program1'),
}

model GetProgramResponseBody = {
  program?: ChannelAssemblyProgram(name='Program', description='The information about the program.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
}

model GetProgramResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetProgramResponseBody(name='body'),
}

/**
 * @summary Queries a program.
 *
 * @param request GetProgramRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetProgramResponse
 */
async function getProgramWithOptions(request: GetProgramRequest, runtime: $RuntimeOptions): GetProgramResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.programName)) {
    query['ProgramName'] = request.programName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetProgram',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a program.
 *
 * @param request GetProgramRequest
 * @return GetProgramResponse
 */
async function getProgram(request: GetProgramRequest): GetProgramResponse {
  var runtime = new $RuntimeOptions{};
  return getProgramWithOptions(request, runtime);
}

model GetProjectExportJobRequest {
  jobId?: string(name='JobId', description='This parameter is required.', example='****cdb3e74639973036bc84****'),
}

model GetProjectExportJobResponseBody = {
  projectExportJob?: {
    code?: string(name='Code', example='InvalidParameter'),
    exportResult?: {
      timeline?: string(name='Timeline', example='{"VideoTracks":[{"VideoTrackClips":[{"Type":"Video","MediaId":"****4d7cf14dc7b83b0e801c****","MediaURL":"https://test-bucket.oss-cn-shanghai.aliyuncs.com/test.mp4","TimelineIn":0.0,"TimelineOut":5.0,"In":0.0,"Out":5.0,"Speed":1.0,"Duration":5.0,"VirginDuration":13.334,"Height":1.0,"Width":1.0,"X":0.0,"Y":0.0}]}]}'),
    }(name='ExportResult'),
    exportType?: string(name='ExportType', example='BaseTimeline'),
    jobId?: string(name='JobId', example='****cdb3e74639973036bc84****'),
    message?: string(name='Message', example='The specified parameter is not valid.'),
    projectId?: string(name='ProjectId', example='****fddd7748b58bf1d47e95****'),
    status?: string(name='Status', example='Success'),
    userData?: string(name='UserData', example='{"NotifyAddress":"http://xx.xx.xxx","Key":"Valuexxx"}'),
  }(name='ProjectExportJob'),
  requestId?: string(name='RequestId', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
}

model GetProjectExportJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetProjectExportJobResponseBody(name='body'),
}

/**
 * @summary 查询工程导出任务
 *
 * @param request GetProjectExportJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetProjectExportJobResponse
 */
async function getProjectExportJobWithOptions(request: GetProjectExportJobRequest, runtime: $RuntimeOptions): GetProjectExportJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetProjectExportJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 查询工程导出任务
 *
 * @param request GetProjectExportJobRequest
 * @return GetProjectExportJobResponse
 */
async function getProjectExportJob(request: GetProjectExportJobRequest): GetProjectExportJobResponse {
  var runtime = new $RuntimeOptions{};
  return getProjectExportJobWithOptions(request, runtime);
}

model GetPublicMediaInfoRequest {
  mediaId?: string(name='MediaId', example='icepublic-****14e501538aeef0a3140176f6****'),
}

model GetPublicMediaInfoResponseBody = {
  mediaInfo?: {
    dynamicMetaData?: {
      data?: string(name='Data', example='{"AuditionUrl": "http://example-bucket.cdn.domain.com/example.mp4", "AuditionCount": 3}'),
      type?: string(name='Type', example='system'),
    }(name='DynamicMetaData'),
    fileInfoList?: [ 
      {
        audioStreamInfoList?: [ 
          {
            bitrate?: string(name='Bitrate', example='192.0'),
            channelLayout?: string(name='ChannelLayout', example='stereo'),
            channels?: string(name='Channels', example='2'),
            codecLongName?: string(name='CodecLongName', example='AAC (Advanced Audio Coding)'),
            codecName?: string(name='CodecName', example='aac'),
            codecTag?: string(name='CodecTag', example='0x6134706d'),
            codecTagString?: string(name='CodecTagString', example='mp4a'),
            codecTimeBase?: string(name='CodecTimeBase', example='1/44100'),
            duration?: string(name='Duration', example='16.2'),
            fps?: string(name='Fps', example='10'),
            index?: string(name='Index', example='1'),
            lang?: string(name='Lang', example='und'),
            numFrames?: string(name='NumFrames', example='162'),
            profile?: string(name='Profile', example='High'),
            sampleFmt?: string(name='SampleFmt', example='fltp'),
            sampleRate?: string(name='SampleRate', example='44100'),
            startTime?: string(name='StartTime', example='0.000000'),
            timebase?: string(name='Timebase', example='1/44100'),
          }
        ](name='AudioStreamInfoList'),
        fileBasicInfo?: {
          bitrate?: string(name='Bitrate', example='192.0'),
          duration?: string(name='Duration', example='16.2'),
          fileName?: string(name='FileName', example='example.mp4'),
          fileSize?: string(name='FileSize', example='27007'),
          fileStatus?: string(name='FileStatus', example='Normal'),
          fileType?: string(name='FileType', example='source_file'),
          fileUrl?: string(name='FileUrl', example='http://example-bucket.cdn.domain.com/example.mp4'),
          formatName?: string(name='FormatName', example='mp4'),
          height?: string(name='Height', example='0'),
          region?: string(name='Region', example='cn-shanghai'),
          width?: string(name='Width', example='0'),
        }(name='FileBasicInfo'),
        subtitleStreamInfoList?: [ 
          {
            codecLongName?: string(name='CodecLongName', example='SubRip Text'),
            codecName?: string(name='CodecName', example='srt'),
            codecTag?: string(name='CodecTag', example='unicode'),
            codecTagString?: string(name='CodecTagString', example='unicode'),
            codecTimeBase?: string(name='CodecTimeBase', example='29.97'),
            duration?: string(name='Duration', example='1'),
            index?: string(name='Index', example='1'),
            lang?: string(name='Lang', example='und'),
            startTime?: string(name='StartTime', example='0'),
            timebase?: string(name='Timebase', example='30'),
          }
        ](name='SubtitleStreamInfoList'),
        videoStreamInfoList?: [ 
          {
            avgFPS?: string(name='AvgFPS', example='24.0'),
            bitrate?: string(name='Bitrate', example='1001.594'),
            codecLongName?: string(name='CodecLongName', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
            codecName?: string(name='CodecName', example='h264'),
            codecTag?: string(name='CodecTag', example='0x0000'),
            codecTagString?: string(name='CodecTagString', example='[0][0][0][0]'),
            codecTimeBase?: string(name='CodecTimeBase', example='1/48'),
            dar?: string(name='Dar', example='0:1'),
            duration?: string(name='Duration', example='216.206706'),
            fps?: string(name='Fps', example='24.0'),
            hasBFrames?: string(name='HasBFrames', example='2'),
            height?: string(name='Height', example='540'),
            index?: string(name='Index', example='0'),
            lang?: string(name='Lang', example='und'),
            level?: string(name='Level', example='30'),
            nbFrames?: string(name='Nb_frames', example='5184'),
            numFrames?: string(name='NumFrames', example='5184'),
            pixFmt?: string(name='PixFmt', example='yuv420p'),
            profile?: string(name='Profile', example='High'),
            rotate?: string(name='Rotate', example='0'),
            sar?: string(name='Sar', example='0:1'),
            startTime?: string(name='StartTime', example='0.081706'),
            timebase?: string(name='Timebase', example='1/12288'),
            width?: string(name='Width', example='960'),
          }
        ](name='VideoStreamInfoList'),
      }
    ](name='FileInfoList', description='FileInfos'),
    mediaBasicInfo?: {
      businessType?: string(name='BusinessType', example='general'),
      category?: string(name='Category', example='category'),
      coverURL?: string(name='CoverURL', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
      createTime?: string(name='CreateTime', example='2020-12-26T04:11:08Z'),
      deletedTime?: string(name='DeletedTime', example='2020-12-26T04:11:15Z'),
      description?: string(name='Description', example='description'),
      mediaId?: string(name='MediaId', description='MediaId', example='icepublic-****14e501538aeef0a3140176f6****'),
      mediaTags?: string(name='MediaTags'),
      mediaType?: string(name='MediaType', example='video'),
      modifiedTime?: string(name='ModifiedTime', example='2020-12-26T04:11:10Z'),
      source?: string(name='Source', example='oss'),
      spriteImages?: string(name='SpriteImages', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
      status?: string(name='Status', example='Normal'),
      title?: string(name='Title', example='title'),
      userData?: string(name='UserData', example='{"key":"value"}'),
    }(name='MediaBasicInfo', description='BasicInfo'),
    mediaId?: string(name='MediaId', example='icepublic-****14e501538aeef0a3140176f6****'),
  }(name='MediaInfo'),
  requestId?: string(name='RequestId', description='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetPublicMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPublicMediaInfoResponseBody(name='body'),
}

/**
 * @summary 获取公共媒资内容信息
 *
 * @param request GetPublicMediaInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetPublicMediaInfoResponse
 */
async function getPublicMediaInfoWithOptions(request: GetPublicMediaInfoRequest, runtime: $RuntimeOptions): GetPublicMediaInfoResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetPublicMediaInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'Anonymous',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 获取公共媒资内容信息
 *
 * @param request GetPublicMediaInfoRequest
 * @return GetPublicMediaInfoResponse
 */
async function getPublicMediaInfo(request: GetPublicMediaInfoRequest): GetPublicMediaInfoResponse {
  var runtime = new $RuntimeOptions{};
  return getPublicMediaInfoWithOptions(request, runtime);
}

model GetSmartHandleJobRequest {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetSmartHandleJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  jobResult?: {
    aiResult?: string(name='AiResult', description='The AI analysis result.', example='Intelligent segmentation or tagging information'),
    mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
    mediaUrl?: string(name='MediaUrl'),
    usage?: string(name='Usage', description='The token usage. This parameter is returned only for keyword-based text generation jobs.', example='{"total_tokens":100}'),
  }(name='JobResult', description='The job results.'),
  output?: string(name='Output', description='The job results.', example='{}'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  smartJobInfo?: {
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2020-12-26T04:11:10Z'),
    description?: string(name='Description', description='The job description.', example='测试描述'),
    inputConfig?: {
      inputFile?: string(name='InputFile', description='The OSS URL or the ID of the material in the media asset library.', example='oss://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4 或 ******11-DB8D-4A9A-875B-275798******'),
    }(name='InputConfig', description='The input configurations.'),
    jobType?: string(name='JobType', description='The job type.', example='ASR'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2020-12-26T04:11:10Z'),
    outputConfig?: {
      bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
      object?: string(name='Object', description='The OSS object.', example='test-object'),
    }(name='OutputConfig', description='The output configurations.'),
    title?: string(name='Title', description='The job title.', example='测试标题'),
    userId?: string(name='UserId', description='The user ID.', example='1974526429******'),
  }(name='SmartJobInfo', description='The information about the intelligent job.'),
  state?: string(name='State', description='The job state.

Valid values:

*   Finished
*   Failed
*   Executing
*   Created', example='Finished'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"user":"data"}'),
}

model GetSmartHandleJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSmartHandleJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about an intelligent job and the execution results of the job based the job ID. You can call this operation to query only intelligent jobs created within the past year.
 *
 * @param request GetSmartHandleJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetSmartHandleJobResponse
 */
async function getSmartHandleJobWithOptions(request: GetSmartHandleJobRequest, runtime: $RuntimeOptions): GetSmartHandleJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetSmartHandleJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about an intelligent job and the execution results of the job based the job ID. You can call this operation to query only intelligent jobs created within the past year.
 *
 * @param request GetSmartHandleJobRequest
 * @return GetSmartHandleJobResponse
 */
async function getSmartHandleJob(request: GetSmartHandleJobRequest): GetSmartHandleJobResponse {
  var runtime = new $RuntimeOptions{};
  return getSmartHandleJobWithOptions(request, runtime);
}

model GetSnapshotJobRequest {
  jobId?: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****d80e4e4044975745c14b****'),
}

model GetSnapshotJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  snapshotJob?: {
    async?: boolean(name='Async', description='Indicates whether the snapshots were captured in asynchronous mode. Default value: true.', example='true'),
    code?: string(name='Code', description='Error codes', example='ResourceNotFound'),
    count?: int32(name='Count', description='The number of snapshots.', example='8'),
    createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
    input?: {
      media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://test-bucket/object.mp4'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='object.mp4'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
    message?: string(name='Message', description='The error message that is returned.', example='The specified resource for "Pipeline" could not be found.'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
    name?: string(name='Name', description='The name of the job.'),
    output?: {
      media?: string(name='Media', description='The output file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS. If multiple static snapshots were captured, the object must contain the "{Count}" placeholder. In the case of a sprite, the object must contain the "{TileCount}" placeholder. The suffix of the WebVTT snapshot objects must be ".vtt".', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/output-{Count}.jpg'),
      ossFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket.', example='test-bucket'),
        location?: string(name='Location', description='The OSS location.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object.', example='output-{Count}.jpg'),
      }(name='OssFile', description='The three key elements of OSS.'),
      type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.', example='OSS'),
    }(name='Output', description='The output of the job.'),
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****d80e4e4044975745c14b****'),
    status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
    templateConfig?: string(name='TemplateConfig', description='The snapshot template configuration.', example='{"Type":"Normal","FrameType":"normal","Time":0,"Count":10}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****d80e4e4044975745c14b****'),
    triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
    type?: string(name='Type', description='Snapshot types

Valid values:

*   WebVtt
*   Sprite
*   Normal', example='Sprite'),
    userData?: string(name='UserData', description='The user-defined parameters.', example='{"test parameter": "test value"}'),
  }(name='SnapshotJob', description='The information about the snapshot job.'),
}

model GetSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSnapshotJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a snapshot job.
 *
 * @param request GetSnapshotJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetSnapshotJobResponse
 */
async function getSnapshotJobWithOptions(request: GetSnapshotJobRequest, runtime: $RuntimeOptions): GetSnapshotJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetSnapshotJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a snapshot job.
 *
 * @param request GetSnapshotJobRequest
 * @return GetSnapshotJobResponse
 */
async function getSnapshotJob(request: GetSnapshotJobRequest): GetSnapshotJobResponse {
  var runtime = new $RuntimeOptions{};
  return getSnapshotJobWithOptions(request, runtime);
}

model GetSnapshotUrlsRequest {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values: Asc and Desc.

- Asc

- Desc', example='Asc'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 30. Default value: 10.', example='10'),
  timeout?: long(name='Timeout', description='The authentication timeout period. Unit: seconds Default value: 3600. Maximum value: 129600 (36 hours).', example='3600'),
}

model GetSnapshotUrlsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  snapshotUrls?: [ string ](name='SnapshotUrls', description='The list of snapshot URLs.'),
  total?: int32(name='Total', description='The total number of snapshots.', example='30'),
  webVTTUrl?: string(name='WebVTTUrl', description='The URL of the WebVTT file.', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/ouoput.vtt'),
}

model GetSnapshotUrlsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSnapshotUrlsResponseBody(name='body'),
}

/**
 * @summary Queries the accessible URLs of the output images of a snapshot job.
 *
 * @param request GetSnapshotUrlsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetSnapshotUrlsResponse
 */
async function getSnapshotUrlsWithOptions(request: GetSnapshotUrlsRequest, runtime: $RuntimeOptions): GetSnapshotUrlsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!$isNull(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.timeout)) {
    query['Timeout'] = request.timeout;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetSnapshotUrls',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the accessible URLs of the output images of a snapshot job.
 *
 * @param request GetSnapshotUrlsRequest
 * @return GetSnapshotUrlsResponse
 */
async function getSnapshotUrls(request: GetSnapshotUrlsRequest): GetSnapshotUrlsResponse {
  var runtime = new $RuntimeOptions{};
  return getSnapshotUrlsWithOptions(request, runtime);
}

model GetSourceRequest {
  sourceLocationName?: string(name='SourceLocationName', description='The source location.

This parameter is required.', example='MySourceLocation'),
  sourceName?: string(name='SourceName', description='The name of the source.

This parameter is required.', example='MyVodSource'),
  sourceType?: string(name='SourceType', description='The source type. Valid values: vodSource and liveSource.

This parameter is required.', example='vodSource'),
}

model GetSourceResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  source?: ChannelAssemblySource(name='Source', description='The source information.'),
}

model GetSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSourceResponseBody(name='body'),
}

/**
 * @summary Queries a source in MediaWeaver.
 *
 * @param request GetSourceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetSourceResponse
 */
async function getSourceWithOptions(request: GetSourceRequest, runtime: $RuntimeOptions): GetSourceResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.sourceLocationName)) {
    query['SourceLocationName'] = request.sourceLocationName;
  }
  if (!$isNull(request.sourceName)) {
    query['SourceName'] = request.sourceName;
  }
  if (!$isNull(request.sourceType)) {
    query['SourceType'] = request.sourceType;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetSource',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a source in MediaWeaver.
 *
 * @param request GetSourceRequest
 * @return GetSourceResponse
 */
async function getSource(request: GetSourceRequest): GetSourceResponse {
  var runtime = new $RuntimeOptions{};
  return getSourceWithOptions(request, runtime);
}

model GetSourceLocationRequest {
  sourceLocationName?: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourceLocation'),
}

model GetSourceLocationResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  sourceLocation?: ChannelAssemblySourceLocation(name='SourceLocation', description='The source location information.'),
}

model GetSourceLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSourceLocationResponseBody(name='body'),
}

/**
 * @summary Queries a source location.
 *
 * @param request GetSourceLocationRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetSourceLocationResponse
 */
async function getSourceLocationWithOptions(request: GetSourceLocationRequest, runtime: $RuntimeOptions): GetSourceLocationResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.sourceLocationName)) {
    query['SourceLocationName'] = request.sourceLocationName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetSourceLocation',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a source location.
 *
 * @param request GetSourceLocationRequest
 * @return GetSourceLocationResponse
 */
async function getSourceLocation(request: GetSourceLocationRequest): GetSourceLocationResponse {
  var runtime = new $RuntimeOptions{};
  return getSourceLocationWithOptions(request, runtime);
}

model GetStorageListRequest {
  appId?: string(name='AppId', example='app-****'),
  status?: string(name='Status', example='Normal'),
  storageType?: string(name='StorageType', example='vod_oss_bucket'),
}

model GetStorageListResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='******73-8B78-5D86-A50C-49B96C******'),
  storageInfoList?: [ 
    {
      appId?: string(name='AppId', example='app-****'),
      creationTime?: string(name='CreationTime', example='2024-06-06T01:55:07Z'),
      defaultStorage?: boolean(name='DefaultStorage', example='true'),
      editingTempFileStorage?: boolean(name='EditingTempFileStorage', example='false'),
      modifiedTime?: string(name='ModifiedTime', example='2024-06-06T03:07:07Z'),
      path?: string(name='Path', example='your-path/'),
      status?: string(name='Status', example='Normal'),
      storageLocation?: string(name='StorageLocation', example='your-bucket'),
      storageType?: string(name='StorageType', example='vod_oss_bucket'),
    }
  ](name='StorageInfoList'),
}

model GetStorageListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetStorageListResponseBody(name='body'),
}

/**
 * @summary 获取存储地址列表
 *
 * @param request GetStorageListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetStorageListResponse
 */
async function getStorageListWithOptions(request: GetStorageListRequest, runtime: $RuntimeOptions): GetStorageListResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.appId)) {
    query['AppId'] = request.appId;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  if (!$isNull(request.storageType)) {
    query['StorageType'] = request.storageType;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetStorageList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 获取存储地址列表
 *
 * @param request GetStorageListRequest
 * @return GetStorageListResponse
 */
async function getStorageList(request: GetStorageListRequest): GetStorageListResponse {
  var runtime = new $RuntimeOptions{};
  return getStorageListWithOptions(request, runtime);
}

model GetSystemTemplateRequest {
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='S00000001-100060'),
}

model GetSystemTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  systemTemplate?: {
    status?: string(name='Status', description='The template state.', example='Normal'),
    subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='1'),
    subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='Normal'),
    templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Container":{"Format":"m3u8"},"TransConfig":{"TransMode":"onepass"},"Video":{"Codec":"H.264","Maxrate":8000,"Preset":"medium","PixFmt":"yuv420p","Width":2048,"Bitrate":3500},"Audio":{"Codec":"aac","Bitrate":160,"Samplerate":44100,"Channels":2}}'),
    templateId?: string(name='TemplateId', description='The template ID.', example='S00000001-100060'),
    templateName?: string(name='TemplateName', description='The template name.', example='M3U8-2K'),
    type?: int32(name='Type', description='The type ID of the template.', example='1'),
    typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
  }(name='SystemTemplate', description='The template information.'),
}

model GetSystemTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSystemTemplateResponseBody(name='body'),
}

/**
 * @summary Queries the information about a system template.
 *
 * @param request GetSystemTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetSystemTemplateResponse
 */
async function getSystemTemplateWithOptions(request: GetSystemTemplateRequest, runtime: $RuntimeOptions): GetSystemTemplateResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetSystemTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a system template.
 *
 * @param request GetSystemTemplateRequest
 * @return GetSystemTemplateResponse
 */
async function getSystemTemplate(request: GetSystemTemplateRequest): GetSystemTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return getSystemTemplateWithOptions(request, runtime);
}

model GetTemplateRequest {
  relatedMediaidFlag?: string(name='RelatedMediaidFlag', description='Specifies whether to return the information about the associated materials. Default value: 0. Valid values: 0 and 1. A value of 1 specifies that the information about the associated materials is returned. This parameter is valid only for regular templates.', example='0'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  template?: {
    clipsParam?: string(name='ClipsParam', description='The clip parameters for submitting a video production job. You can replace mediaId and text with real values to submit a job. References:

*   [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html)
*   [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html)', example='{"Media1":"mediaId","Text1":"text"}'),
    config?: string(name='Config', description='The template configurations.

*   For more information about the configurations of a regular template, see [Config object of a regular template](https://help.aliyun.com/document_detail/456193.html).
*   For more information about the configurations of an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).', example='参考Timeline模板配置详解'),
    coverURL?: string(name='CoverURL', description='The thumbnail URL.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
    createSource?: string(name='CreateSource', description='The source from which the template was created. Valid values:

*   AliyunConsole
*   OpenAPI
*   WebSDK', example='OpenAPI'),
    creationTime?: string(name='CreationTime', description='The time when the template was created.', example='2020-12-26T04:11:10Z'),
    modifiedSource?: string(name='ModifiedSource', description='The source from which the template was modified. Valid values:

*   AliyunConsole
*   OpenAPI
*   WebSDK', example='OpenAPI'),
    modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2020-12-26T04:11:10Z'),
    name?: string(name='Name', description='The template name.', example='视频添加水印模板'),
    previewMedia?: string(name='PreviewMedia', description='The preview media asset.', example='****20b48fb04483915d4f2cd8ac****'),
    previewMediaStatus?: string(name='PreviewMediaStatus', description='The state of the preview media asset. Valid values:

*   Init: the initial state, which indicates that the source file is not ready.
*   Preparing: The source file is being prepared. For example, the file is being uploaded or edited.
*   PrepareFail: The source file failed to be prepared. For example, the information about the source file failed to be obtained.
*   Normal: The source file is ready.', example='Normal'),
    relatedMediaids?: string(name='RelatedMediaids', description='The IDs of the materials associated with the template for use by the regular template editor.', example='{"video":["******c04f1d4a06996144cc1a******"],"audio":["******c04f1d4a06996144cc1a******"],"image":["******c04f1d4a06996144cc1a******"]}'),
    status?: string(name='Status', description='The template state. Valid values:

*   Available
*   Created
*   Uploading
*   Processing
*   UploadFailed
*   ProcessFailed', example='Available'),
    templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
    type?: string(name='Type', description='The template type. Valid values:

*   Timeline
*   VETemplate', example='Timeline'),
  }(name='Template', description='The template information.'),
}

model GetTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTemplateResponseBody(name='body'),
}

/**
 * @summary Queries the information about a template based on the template ID. You can call this operation to query the information about an advanced template if the template is in the Available state.
 *
 * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
 * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request GetTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetTemplateResponse
 */
async function getTemplateWithOptions(request: GetTemplateRequest, runtime: $RuntimeOptions): GetTemplateResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.relatedMediaidFlag)) {
    query['RelatedMediaidFlag'] = request.relatedMediaidFlag;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a template based on the template ID. You can call this operation to query the information about an advanced template if the template is in the Available state.
 *
 * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
 * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request GetTemplateRequest
 * @return GetTemplateResponse
 */
async function getTemplate(request: GetTemplateRequest): GetTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return getTemplateWithOptions(request, runtime);
}

model GetTemplateMaterialsRequest {
  fileList?: string(name='FileList', description='The materials that you want to query.', example='["music.mp3","config.json","assets/1.jpg"]'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetTemplateMaterialsResponseBody = {
  materialUrls?: string(name='MaterialUrls', description='The URLs of the associated materials.', example='{"music.mp3":"https://bucket.oss-cn-shanghai.aliyuncs.com/music.mp3?sign=xxx","config.json":"https://bucket.oss-cn-shanghai.aliyuncs.com/config.json?sign=xxx","assets/1.jpg":"https://bucket.oss-cn-shanghai.aliyuncs.com/assets/1.jpg?sign=xxx"}'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetTemplateMaterialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTemplateMaterialsResponseBody(name='body'),
}

/**
 * @summary Queries the URLs of materials associated with an advanced template for use by the advanced template editor. The URLs expire in 30 minutes. FileList is an array of materials that you want to query. If you do not specify this parameter, the URLs of all materials are returned. A maximum of 400 URLs can be returned.
 *
 * @param request GetTemplateMaterialsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetTemplateMaterialsResponse
 */
async function getTemplateMaterialsWithOptions(request: GetTemplateMaterialsRequest, runtime: $RuntimeOptions): GetTemplateMaterialsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.fileList)) {
    query['FileList'] = request.fileList;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetTemplateMaterials',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the URLs of materials associated with an advanced template for use by the advanced template editor. The URLs expire in 30 minutes. FileList is an array of materials that you want to query. If you do not specify this parameter, the URLs of all materials are returned. A maximum of 400 URLs can be returned.
 *
 * @param request GetTemplateMaterialsRequest
 * @return GetTemplateMaterialsResponse
 */
async function getTemplateMaterials(request: GetTemplateMaterialsRequest): GetTemplateMaterialsResponse {
  var runtime = new $RuntimeOptions{};
  return getTemplateMaterialsWithOptions(request, runtime);
}

model GetTemplateParamsRequest {
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
}

model GetTemplateParamsResponseBody = {
  paramList?: [ 
    {
      content?: string(name='Content', description='The original subtitle content.'),
      coverUrl?: string(name='CoverUrl', description='The thumbnail URL of the original material.'),
      key?: string(name='Key', description='The parameter name.', example='video1'),
      mediaUrl?: string(name='MediaUrl', description='The URL of the original material.'),
      type?: string(name='Type', description='The material type.

Valid values:

*   Video
*   Text
*   Image', example='Image'),
    }
  ](name='ParamList', description='The queried parameters.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
  templateId?: string(name='TemplateId', description='The template ID.', example='******419c8741c1b4325f035b******'),
}

model GetTemplateParamsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTemplateParamsResponseBody(name='body'),
}

/**
 * @summary Queries the parameters for replaceable materials in a template, including the parameter names, default values, and material thumbnails. Only advanced templates are supported.
 *
 * @param request GetTemplateParamsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetTemplateParamsResponse
 */
async function getTemplateParamsWithOptions(request: GetTemplateParamsRequest, runtime: $RuntimeOptions): GetTemplateParamsResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetTemplateParams',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the parameters for replaceable materials in a template, including the parameter names, default values, and material thumbnails. Only advanced templates are supported.
 *
 * @param request GetTemplateParamsRequest
 * @return GetTemplateParamsResponse
 */
async function getTemplateParams(request: GetTemplateParamsRequest): GetTemplateParamsResponse {
  var runtime = new $RuntimeOptions{};
  return getTemplateParamsWithOptions(request, runtime);
}

model GetTranscodeJobRequest {
  parentJobId?: string(name='ParentJobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
}

model GetTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='9EDC30DC-0050-5459-B788-F761B2BE359B'),
  transcodeParentJob?: {
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    inputGroup?: [ 
      {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
      }
    ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
    jobCount?: int32(name='JobCount', description='The number of subjobs.', example='1'),
    name?: string(name='Name', description='The job name.', example='transcode-job'),
    outputGroup?: [ 
      {
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          outputUrl?: string(name='OutputUrl', description='The URL of the output stream.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex?: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex?: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HLS encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The endpoint of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='The encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The position of the watermark on the x-axis.', example='10'),
                dy?: string(name='Dy', description='The position of the watermark on the y-axis.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the output video.', example='32'),
                referPos?: string(name='ReferPos', description='The reference position of the watermark. Valid values: TopLeft, TopRight, BottomLeft, and BottomRight. Default value: TopLeft.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The duration of the stream. Valid values: the number of seconds or "ToEND".', example='ToEND'),
                  start?: string(name='Start', description='The start time of the stream.', example='00:00:05'),
                }(name='Timeline', description='The timeline settings.'),
                width?: string(name='Width', description='The width of the output video.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Indicates whether the text size was adjusted based on the output video dimensions. Valid values: true and false. Default value: false.', example='false'),
                borderColor?: string(name='BorderColor', description='The border color.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The border width.', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the watermark.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.', example='16'),
                left?: string(name='Left', description='The distance of the watermark from the left edge.', example='10'),
                top?: string(name='Top', description='The distance of the watermark from the top edge.', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Indicates whether the audio stream is deleted.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100.
*   Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum ABR. This parameter takes effect only for Narrowband HD 1.0.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.
*   If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values: border: automatically detects and removes black bars. A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Indicates whether the auto-rotate screen feature is enabled.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Indicates whether the video was removed.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The job processing configuration.'),
      }
    ](name='OutputGroup', description='The output group of the job.'),
    parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
    percent?: int32(name='Percent', description='The completion percentage of the job.', example='0'),
    requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the snapshot job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling configuration of the job.'),
    status?: string(name='Status', description='The state of the job.

*   Success: At least one of the subjobs is successful.
*   Fail: All subjobs failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    transcodeJobList?: [ 
      {
        createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-01-12T08:49:41Z'),
        finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
        inputGroup?: [ 
          {
            inputUrl?: string(name='InputUrl', description='The URL of the media asset. This parameter is specified only when the media asset is transcoded.', example='oss://bucket/path/to/video.mp4'),
            media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
            type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
          }
        ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
        jobId?: string(name='JobId', description='The subjob ID.', example='7d6a7e0d4db2457a8d45ff5d43e1bf0a'),
        jobIndex?: int32(name='JobIndex', description='The index number of the subjob in the entire job.', example='0'),
        name?: string(name='Name', description='The job name.', example='transcode-job'),
        outFileMeta?: {
          audioStreamInfoList?: [ 
            {
              bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
              channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
              channels?: string(name='Channels', description='The number of sound channels.', example='2'),
              codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
              codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
              codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
              codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
              codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              index?: string(name='Index', description='The sequence number of the stream.', example='1'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
              sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
              startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
              timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
            }
          ](name='AudioStreamInfoList', description='The information about the audio stream.'),
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
            duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
            fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
            fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
            fileType?: string(name='FileType', description='The file type. Valid values: source_file and transcode_file.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
            formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
            height?: string(name='Height', description='The height of the output video.', example='478'),
            mediaId?: string(name='MediaId', description='The ID of the media asset.', example='486c2890096871edba6f81848c016303'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width of the output video.', example='848'),
          }(name='FileBasicInfo', description='The basic file information.'),
          videoStreamInfoList?: [ 
            {
              avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
              bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
              codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
              codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
              codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
              codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
              codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
              dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              fps?: string(name='Fps', description='The frame rate.', example='25.0'),
              hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
              height?: string(name='Height', description='The height of the output video.', example='478'),
              index?: string(name='Index', description='The sequence number of the stream.', example='0'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              level?: string(name='Level', description='The codec level.', example='31'),
              numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
              pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
              profile?: string(name='Profile', description='The encoder profile.', example='High'),
              rotate?: string(name='Rotate', description='The rotation angle of the video image. Valid values: 0, 90, 180, and 270. Default value: 0.', example='0'),
              sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
              startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
              timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
              width?: string(name='Width', description='The width of the output video.', example='848'),
            }
          ](name='VideoStreamInfoList', description='The information about the video stream.'),
        }(name='OutFileMeta', description='The media information about the video generated by the job.'),
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          outputUrl?: string(name='OutputUrl', description='The path of the transcoded output stream. This parameter is required only when the output is a media asset.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex?: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex?: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HTTP Live Streaming (HLS) encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The endpoint of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='The encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The position of the watermark on the x-axis.', example='10'),
                dy?: string(name='Dy', description='The position of the watermark on the y-axis.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the output video.', example='32'),
                referPos?: string(name='ReferPos', description='The reference position of the watermark. Valid values: TopLeft, TopRight, BottomLeft, and BottomRight. Default value: TopLeft.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The duration of the stream. Valid values: the number of seconds or "ToEND".', example='ToEND'),
                  start?: string(name='Start', description='The start time of the stream.', example='00:00:05'),
                }(name='Timeline', description='The timeline settings.'),
                width?: string(name='Width', description='The width of the output video.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          isInheritTags?: boolean(name='IsInheritTags', description='Indicates whether the tags of the input stream are inherited in the output stream. This parameter does not take effect when the input is not a media asset. Default value: false.', example='true'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Indicates whether the text size was adjusted based on the output video dimensions. Valid values: true and false. Default value: false.', example='false'),
                borderColor?: string(name='BorderColor', description='The border color.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The border width.', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the watermark.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.', example='16'),
                left?: string(name='Left', description='The distance of the watermark from the left edge.', example='10'),
                top?: string(name='Top', description='The distance of the watermark from the top edge.', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Indicates whether the audio stream is deleted.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100. Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              tags?: map[string]string(name='Tags'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.

For more information about examples, see How do I set the resolution for an output video?', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Indicates whether the audio bitrate was checked. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Indicates whether the video resolution was checked. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false

Default value: false.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Indicates whether the video bitrate was checked. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false

Default value: false.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum adaptive bitrate (ABR). This parameter takes effect only for Narrowband HD 1.0.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: Kbit/s.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.

If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60]. The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.

Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Indicates whether the auto-rotate screen feature is enabled.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video. Format: width:height:left:top.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Indicates whether the video was removed.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.

Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The transcoding configuration.'),
        requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
        scheduleConfig?: {
          pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the snapshot job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
          priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
        }(name='ScheduleConfig', description='The scheduling information about the job.'),
        status?: string(name='Status', description='The state of the transcoding job. Valid values: Init (the job is submitted), Success (the job is successful), Fail (the job failed), and Deleted (the job is deleted).', example='Init'),
        submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission result.', example='{}'),
        submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
        userData?: string(name='UserData', description='The user data.', example='user-data'),
      }
    ](name='TranscodeJobList', description='The list of subjobs.'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='TranscodeParentJob', description='TranscodeParentJobWithSubJobDTO'),
}

model GetTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTranscodeJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a transcoding job.
 *
 * @param request GetTranscodeJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetTranscodeJobResponse
 */
async function getTranscodeJobWithOptions(request: GetTranscodeJobRequest, runtime: $RuntimeOptions): GetTranscodeJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.parentJobId)) {
    query['ParentJobId'] = request.parentJobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetTranscodeJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a transcoding job.
 *
 * @param request GetTranscodeJobRequest
 * @return GetTranscodeJobResponse
 */
async function getTranscodeJob(request: GetTranscodeJobRequest): GetTranscodeJobResponse {
  var runtime = new $RuntimeOptions{};
  return getTranscodeJobWithOptions(request, runtime);
}

model GetUrlUploadInfosRequest {
  jobIds?: string(name='JobIds', description='The IDs of the upload jobs. You can specify one or more job IDs. You can obtain the job IDs from the response parameter JobId of the [UploadMediaByURL](https://help.aliyun.com/document_detail/86311.html) operation.

*   You can specify a maximum of 10 job IDs.
*   Separate the job IDs with commas (,).

>  You must specify either JobIds or UploadURLs. If you specify both parameters, only the value of JobIds takes effect.', example='df2ac80b481346daa1db6a7c40edc7f8'),
  uploadURLs?: string(name='UploadURLs', description='The upload URLs of the source files. You can specify a maximum of 10 URLs. Separate the URLs with commas (,).

> 

*   The URLs must be encoded.

*   If a media file is uploaded multiple times, we recommend that you specify the URL of the media file only once in this parameter.

*   You must specify either JobIds or UploadURLs. If you specify both parameters, only the value of JobIds takes effect.', example='https://media.w3.org/2010/05/sintel/trailer.mp4'),
}

model GetUrlUploadInfosResponseBody = {
  nonExists?: [ string ](name='NonExists', description='The job IDs or upload URLs that do not exist.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  URLUploadInfoList?: [ 
    {
      completeTime?: string(name='CompleteTime', description='The time when the upload job was complete. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2021-11-26 21:47:37'),
      creationTime?: string(name='CreationTime', description='The time when the upload job was created. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2021-11-07T10:03:37Z'),
      errorCode?: string(name='ErrorCode', description='The error code returned if the upload job failed.', example='200'),
      errorMessage?: string(name='ErrorMessage', description='The error message returned if the upload job failed.', example='Success'),
      fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='64610'),
      jobId?: string(name='JobId', description='The ID of the upload job.', example='3829500c0fef429fa4ec1680b122d***'),
      mediaId?: string(name='MediaId', description='The ID of the uploaded media file.', example='5014ca70f08171ecbf940764a0fd6***'),
      status?: string(name='Status', description='The status of the upload job. For more information about the valid values of the parameter, see the "Status: the status of a URL-based upload job" section of the [Basic data types](https://help.aliyun.com/document_detail/52839.html) topic.', example='Normal'),
      uploadURL?: string(name='UploadURL', description='The upload URL of the source file.

>  A maximum of 100 URLs can be returned.', example='http://****.mp4'),
      userData?: string(name='UserData', description='The user data. The value is a JSON string.', example='{"MessageCallback":"{"CallbackURL":"http://example.aliyundoc.com"}", "Extend":"{"localId":"***", "test":"www"}"}'),
    }
  ](name='URLUploadInfoList', description='The details about URL-based upload jobs.'),
}

model GetUrlUploadInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetUrlUploadInfosResponseBody(name='body'),
}

/**
 * @summary Queries the information about URL-based upload jobs.
 *
 * @description You can call this operation to query the information, including the upload status, user data, creation time, and completion time, about URL-based upload jobs based on the returned job IDs or the URLs used during the upload.
 * If an upload job fails, you can view the error code and error message. If an upload job is successful, you can obtain the video ID.
 *
 * @param request GetUrlUploadInfosRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetUrlUploadInfosResponse
 */
async function getUrlUploadInfosWithOptions(request: GetUrlUploadInfosRequest, runtime: $RuntimeOptions): GetUrlUploadInfosResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobIds)) {
    query['JobIds'] = request.jobIds;
  }
  if (!$isNull(request.uploadURLs)) {
    query['UploadURLs'] = request.uploadURLs;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetUrlUploadInfos',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about URL-based upload jobs.
 *
 * @description You can call this operation to query the information, including the upload status, user data, creation time, and completion time, about URL-based upload jobs based on the returned job IDs or the URLs used during the upload.
 * If an upload job fails, you can view the error code and error message. If an upload job is successful, you can obtain the video ID.
 *
 * @param request GetUrlUploadInfosRequest
 * @return GetUrlUploadInfosResponse
 */
async function getUrlUploadInfos(request: GetUrlUploadInfosRequest): GetUrlUploadInfosResponse {
  var runtime = new $RuntimeOptions{};
  return getUrlUploadInfosWithOptions(request, runtime);
}

model GetVideoListRequest {
  cateId?: long(name='CateId', description='The ID of the category.', example='781111'),
  endTime?: string(name='EndTime', description='The end of the time range to query. The end time must be later than the start time. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-01-11T12:59:00Z'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='20'),
  sortBy?: string(name='SortBy', description='The sorting method of the results. Valid values:

*   CreationTime:Desc (default): sorts results in reverse chronological order.
*   CreationTime:Asc: sorts results in chronological order.', example='CreationTime:Asc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-01-11T12:00:00Z'),
  status?: string(name='Status', description='The status of the video. You can specify multiple video statuses and separate them with commas (,).

Valid values:

*   PrepareFail: The file is abnormal.
*   UploadFail: The video failed to be uploaded.
*   UploadSucc: The video is uploaded.
*   Transcoding: The video is being transcoded.
*   TranscodeFail: The video failed to be transcoded.
*   ProduceFail: The video failed to be produced.
*   Normal: The video is normal.
*   Uploading: The video is being uploaded.
*   Preparing: The file is being generated.
*   Blocked: The video is blocked.
*   checking: The video is being reviewed.', example='Uploading,Normal'),
}

model GetVideoListResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaList?: [ 
    {
      appId?: string(name='AppId', description='The ID of the application. Default value: app-1000000.', example='app-1000000'),
      cateId?: long(name='CateId', description='The ID of the category.', example='3679'),
      cateName?: string(name='CateName', description='The name of the category.'),
      coverUrl?: string(name='CoverUrl', description='The URL of the thumbnail.', example='http://example.aliyundoc.com/snapshot/****.jpg?auth_key=1498476426-0-0-f00b9455c49a423ce69cf4e27333****'),
      creationTime?: string(name='CreationTime', description='The time when the audio or video file was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:15:50Z'),
      description?: string(name='Description', description='The description of the audio or video file.'),
      duration?: float(name='Duration', description='The duration. Unit: seconds.', example='135.6'),
      mediaId?: string(name='MediaId', description='The ID of the audio or video file.', example='1c6ce34007d571ed94667630a6bc****'),
      modificationTime?: string(name='ModificationTime', description='The time when the audio or video file was updated. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:16:50Z'),
      size?: long(name='Size', description='The size of the source file. Unit: bytes.', example='10897890'),
      snapshots?: [ string ](name='Snapshots', description='The array of video snapshot URLs.'),
      status?: string(name='Status', description='The status of the video.

Valid values:

*   PrepareFail: The file is abnormal.
*   UploadFail: The video failed to be uploaded.
*   UploadSucc: The video is uploaded.
*   Transcoding: The video is being transcoded.
*   TranscodeFail: The video failed to be transcoded.
*   ProduceFail: The video failed to be produced.
*   Normal: The video is normal.
*   Uploading: The video is being uploaded.
*   Preparing: The file is being generated.
*   Blocked: The video is blocked.
*   checking: The video is being reviewed.', example='Normal'),
      storageLocation?: string(name='StorageLocation', description='The storage address.', example='out-****.oss-cn-shanghai.aliyuncs.com'),
      tags?: string(name='Tags', description='The tags of the audio or video file.'),
      title?: string(name='Title', description='The title of the audio or video file.'),
    }
  ](name='MediaList', description='The information about the audio and video files.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request is successful. Valid values:

*   true
*   false', example='true'),
  total?: long(name='Total', description='The total number of audio and video files that meet the conditions.', example='163'),
}

model GetVideoListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetVideoListResponseBody(name='body'),
}

/**
 * @summary Queries information about video and audio files.
 *
 * @description You can call this operation to query information about up to the first 5,000 audio and video files based on the filter condition, such as the status or category ID of the file. We recommend that you set the StartTime and EndTime parameters to narrow down the time range and perform multiple queries to obtain data.
 *
 * @param request GetVideoListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetVideoListResponse
 */
async function getVideoListWithOptions(request: GetVideoListRequest, runtime: $RuntimeOptions): GetVideoListResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.cateId)) {
    query['CateId'] = request.cateId;
  }
  if (!$isNull(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetVideoList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries information about video and audio files.
 *
 * @description You can call this operation to query information about up to the first 5,000 audio and video files based on the filter condition, such as the status or category ID of the file. We recommend that you set the StartTime and EndTime parameters to narrow down the time range and perform multiple queries to obtain data.
 *
 * @param request GetVideoListRequest
 * @return GetVideoListResponse
 */
async function getVideoList(request: GetVideoListRequest): GetVideoListResponse {
  var runtime = new $RuntimeOptions{};
  return getVideoListWithOptions(request, runtime);
}

model GetVodPackagingAssetRequest {
  assetName?: string(name='AssetName', description='The name of the VOD packaging asset.', example='30min_movie'),
}

model GetVodPackagingAssetResponseBody = {
  asset?: {
    assetName?: string(name='AssetName', description='The name of the asset.', example='30min_movie'),
    contentId?: string(name='ContentId', description='The content ID in the DRM system. The maximum length is 256 characters. Letters, digits, underscores (_), and hyphens (-) are supported.', example='movie'),
    createTime?: string(name='CreateTime', description='The time when the asset was created. It follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-11-21T06:45:32Z'),
    egressEndpoints?: [ 
      {
        configurationName?: string(name='ConfigurationName', description='The name of the packaging configuration.', example='hls_3s'),
        status?: string(name='Status', description='The asset status. Valid values:

*   Queuing: The asset is waiting for packaging.
*   Playable: The asset is packaged and playable.
*   Failed: The asset fails to be packaged.', example='Playable'),
        url?: string(name='Url', description='The playback URL. If the asset fails to be packaged, no playback URL is returned.'),
      }
    ](name='EgressEndpoints', description='The egress endpoints, each corresponding to a packaging configuration.'),
    groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls'),
    input?: {
      media?: string(name='Media', description='The URL of the media file. Only M3U8 files stored in OSS are supported.'),
      type?: string(name='Type', description='The input type. Only Object Storage Service (OSS) is supported.', example='OSS'),
    }(name='Input', description='The asset input configurations.'),
  }(name='Asset', description='The information about the asset.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='0622C702-41BE-467E-AF2E-883D4517962E'),
}

model GetVodPackagingAssetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetVodPackagingAssetResponseBody(name='body'),
}

/**
 * @summary Queries a VOD packaging asset.
 *
 * @param request GetVodPackagingAssetRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetVodPackagingAssetResponse
 */
async function getVodPackagingAssetWithOptions(request: GetVodPackagingAssetRequest, runtime: $RuntimeOptions): GetVodPackagingAssetResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.assetName)) {
    query['AssetName'] = request.assetName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetVodPackagingAsset',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a VOD packaging asset.
 *
 * @param request GetVodPackagingAssetRequest
 * @return GetVodPackagingAssetResponse
 */
async function getVodPackagingAsset(request: GetVodPackagingAssetRequest): GetVodPackagingAssetResponse {
  var runtime = new $RuntimeOptions{};
  return getVodPackagingAssetWithOptions(request, runtime);
}

model GetVodPackagingConfigurationRequest {
  configurationName?: string(name='ConfigurationName', description='The name of the packaging configuration.', example='hls_3s'),
}

model GetVodPackagingConfigurationResponseBody = {
  packagingConfiguration?: VodPackagingConfiguration(name='PackagingConfiguration', description='The information about the packaging configuration.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model GetVodPackagingConfigurationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetVodPackagingConfigurationResponseBody(name='body'),
}

/**
 * @summary Queries a packaging configuration.
 *
 * @param request GetVodPackagingConfigurationRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetVodPackagingConfigurationResponse
 */
async function getVodPackagingConfigurationWithOptions(request: GetVodPackagingConfigurationRequest, runtime: $RuntimeOptions): GetVodPackagingConfigurationResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.configurationName)) {
    query['ConfigurationName'] = request.configurationName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetVodPackagingConfiguration',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a packaging configuration.
 *
 * @param request GetVodPackagingConfigurationRequest
 * @return GetVodPackagingConfigurationResponse
 */
async function getVodPackagingConfiguration(request: GetVodPackagingConfigurationRequest): GetVodPackagingConfigurationResponse {
  var runtime = new $RuntimeOptions{};
  return getVodPackagingConfigurationWithOptions(request, runtime);
}

model GetVodPackagingGroupRequest {
  groupName?: string(name='GroupName', description='The name of the packaging group. The name must be unique and can be up to 128 characters in length. Letters, digits, underscores (_), and hyphens (-) are supported.', example='vod_hls'),
}

model GetVodPackagingGroupResponseBody = {
  packagingGroup?: VodPackagingGroup(name='PackagingGroup', description='The information about the packaging group.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model GetVodPackagingGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetVodPackagingGroupResponseBody(name='body'),
}

/**
 * @summary Queries a packaging group.
 *
 * @param request GetVodPackagingGroupRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetVodPackagingGroupResponse
 */
async function getVodPackagingGroupWithOptions(request: GetVodPackagingGroupRequest, runtime: $RuntimeOptions): GetVodPackagingGroupResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetVodPackagingGroup',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a packaging group.
 *
 * @param request GetVodPackagingGroupRequest
 * @return GetVodPackagingGroupResponse
 */
async function getVodPackagingGroup(request: GetVodPackagingGroupRequest): GetVodPackagingGroupResponse {
  var runtime = new $RuntimeOptions{};
  return getVodPackagingGroupWithOptions(request, runtime);
}

model GetWorkflowTaskRequest {
  taskId?: string(name='TaskId', description='The ID of the workflow task.', example='******4215e042b3966ca5441e******'),
}

model GetWorkflowTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******0C-7870-15FE-B96F-8880BB******'),
  workflowTask?: {
    activityResults?: string(name='ActivityResults', description='The results for all nodes of the workflow task.'),
    createTime?: string(name='CreateTime', description='The time when the task was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-01-04T02:05:17Z'),
    finishTime?: string(name='FinishTime', description='The time when the task was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-01-04T02:06:19Z'),
    status?: string(name='Status', description='The task state.

Valid values:

*   Init: The task is being initialized.
*   Failed: The task failed.
*   Canceled: The task is canceled.
*   Processing: The task is in progress.
*   Succeed: The task is successful.', example='Succeed'),
    taskId?: string(name='TaskId', description='The ID of the workflow task.', example='******4215e042b3966ca5441e******'),
    taskInput?: string(name='TaskInput', description='The input of the workflow task.', example='{
      "Type": "Media",
      "Media": "******30706071edbfe290b488******"
}'),
    userData?: string(name='UserData', description='The user-defined field that was specified when the workflow task was submitted.', example='{"NotifyAddress":"http://xx.xx.xxx"}'),
    workflow?: {
      createTime?: string(name='CreateTime', description='The time when the workflow was created.', example='2022-11-27T10:02:12Z'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the workflow was last modified.', example='2022-11-29T02:06:19Z'),
      name?: string(name='Name', description='The workflow name.'),
      status?: string(name='Status', description='The workflow state.

Valid values:

*   Active
*   Inactive', example='Active'),
      type?: string(name='Type', description='The workflow type.

Valid values:

*   Customize: custom workflow.
*   System: system workflow.
*   Common: user-created workflow.', example='Common'),
      workflowId?: string(name='WorkflowId', description='The workflow ID.', example='******63dca94c609de02ac0d1******'),
    }(name='Workflow', description='The workflow Information.'),
  }(name='WorkflowTask', description='The information about the workflow task.'),
}

model GetWorkflowTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkflowTaskResponseBody(name='body'),
}

/**
 * @summary Queries the information about a workflow task by task ID, including the workflow ID and the status and result of the task. You can query only the workflow task data of the last year.
 *
 * @param request GetWorkflowTaskRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetWorkflowTaskResponse
 */
async function getWorkflowTaskWithOptions(request: GetWorkflowTaskRequest, runtime: $RuntimeOptions): GetWorkflowTaskResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.taskId)) {
    query['TaskId'] = request.taskId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'GetWorkflowTask',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a workflow task by task ID, including the workflow ID and the status and result of the task. You can query only the workflow task data of the last year.
 *
 * @param request GetWorkflowTaskRequest
 * @return GetWorkflowTaskResponse
 */
async function getWorkflowTask(request: GetWorkflowTaskRequest): GetWorkflowTaskResponse {
  var runtime = new $RuntimeOptions{};
  return getWorkflowTaskWithOptions(request, runtime);
}

model InsertMediaToSearchLibRequest {
  input?: string(name='Input', description='The URL of the video, audio, or image file that you want to import to the search library.

Note: Make sure that you specify a correct file name and the bucket in which the file resides is in the same region where this operation is called. Otherwise, the file cannot be found or the operation may fail.

Specify an Object Storage Service (OSS) URL in the following format: oss://[Bucket name]/[File path]. For example, you can specify oss://[example-bucket-****]/[object_path-****].

Specify an HTTP URL in the following format: public endpoint. For example, you can specify http://example-test-\\\\*\\\\*\\\\*\\\\*.mp4.

This parameter is required.', example='http://example-test-****.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. Each media ID is unique. If you leave this parameter empty, a media ID is automatically generated for this parameter.', example='411bed50018971edb60b0764a0ec6***'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

*   video (default)
*   image
*   audio', example='video'),
  msgBody?: string(name='MsgBody', description='The message body.', example='{}'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1'),
}

model InsertMediaToSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model InsertMediaToSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: InsertMediaToSearchLibResponseBody(name='body'),
}

/**
 * @summary Adds a media asset in a search library. Before you call this operation, you must create a search library.
 *
 * @param request InsertMediaToSearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return InsertMediaToSearchLibResponse
 */
async function insertMediaToSearchLibWithOptions(request: InsertMediaToSearchLibRequest, runtime: $RuntimeOptions): InsertMediaToSearchLibResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.input)) {
    query['Input'] = request.input;
  }
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!$isNull(request.msgBody)) {
    query['MsgBody'] = request.msgBody;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'InsertMediaToSearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Adds a media asset in a search library. Before you call this operation, you must create a search library.
 *
 * @param request InsertMediaToSearchLibRequest
 * @return InsertMediaToSearchLibResponse
 */
async function insertMediaToSearchLib(request: InsertMediaToSearchLibRequest): InsertMediaToSearchLibResponse {
  var runtime = new $RuntimeOptions{};
  return insertMediaToSearchLibWithOptions(request, runtime);
}

model ListAIAgentDialoguesRequest {
  endTime?: long(name='EndTime', description='This parameter is required.', example='17358082464030'),
  order?: string(name='Order', example='DESC'),
  pageNumber?: long(name='PageNumber', example='1'),
  pageSize?: int32(name='PageSize', example='20'),
  sessionId?: string(name='SessionId', description='This parameter is required.', example='f27f9b9be28642a88e18****'),
  startTime?: long(name='StartTime', description='This parameter is required.', example='0'),
}

model ListAIAgentDialoguesResponseBody = {
  dialogues?: [ 
    {
      dialogueId?: string(name='DialogueId', example='19de81b3b3d94abda22****'),
      producer?: string(name='Producer', example='user'),
      reasoningText?: string(name='ReasoningText'),
      roundId?: string(name='RoundId', example='f27f9b9be28642a88e18****'),
      source?: string(name='Source'),
      text?: string(name='Text'),
      time?: long(name='Time', example='1734511087000'),
      type?: string(name='Type'),
    }
  ](name='Dialogues'),
  requestId?: string(name='RequestId', example='7B117AF5-***************'),
}

model ListAIAgentDialoguesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAIAgentDialoguesResponseBody(name='body'),
}

/**
 * @summary 列出智能体的对话历史记录。
 *
 * @param request ListAIAgentDialoguesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListAIAgentDialoguesResponse
 */
async function listAIAgentDialoguesWithOptions(request: ListAIAgentDialoguesRequest, runtime: $RuntimeOptions): ListAIAgentDialoguesResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!$isNull(request.order)) {
    query['Order'] = request.order;
  }
  if (!$isNull(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sessionId)) {
    query['SessionId'] = request.sessionId;
  }
  if (!$isNull(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListAIAgentDialogues',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 列出智能体的对话历史记录。
 *
 * @param request ListAIAgentDialoguesRequest
 * @return ListAIAgentDialoguesResponse
 */
async function listAIAgentDialogues(request: ListAIAgentDialoguesRequest): ListAIAgentDialoguesResponse {
  var runtime = new $RuntimeOptions{};
  return listAIAgentDialoguesWithOptions(request, runtime);
}

model ListAIAgentInstanceRequest {
  AIAgentId?: string(name='AIAgentId', description='The ID of the AI agent.

This parameter is required.', example='39f8e0bc005e4f309379701645f4***'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC. This parameter does not have a default value.', example='2023-01-02T00:00:00Z'),
  pageNumber?: long(name='PageNumber', description='The page number. Default value: 1. Valid values: 1 to 100.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 0 to 100.', example='10'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC. This parameter does not have a default value.', example='2023-01-01T00:00:00Z'),
}

model ListAIAgentInstanceResponseBody = {
  instances?: [ 
    {
      callLogUrl?: string(name='CallLogUrl', description='The URL of the call log file for the AI agent. The structure of the file is CallLog in the JSON format.', example='https://example.com/call_logs/12345.json'),
      runtimeConfig?: AIAgentRuntimeConfig(name='RuntimeConfig', description='The runtime configurations of the AI agent.', example='{"VoiceChat":{"AgentUserId":"voice_agent_001","ChannelId":"voice_channel_001","AuthToken":"your_voice_chat_auth_token"}}'),
      status?: string(name='Status', description='The state of the instance. Valid values:

*   Executing
*   Finished', example='Finished'),
      templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', description='The template configurations of the AI agent.', example='{"VoiceChat": {"VoiceId": "zhixiaoxia"}}'),
      userData?: string(name='UserData', description='The custom information.', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
    }
  ](name='Instances', description='The list of the AI agents.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model ListAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAIAgentInstanceResponseBody(name='body'),
}

/**
 * @summary Queries a list of AI agents.
 *
 * @description ## [](#)Request description
 * You can call this operation to query a list of AI agents based on the `AIAgentId`. The optional parameters include `StartTime`, `EndTime`, `PageSize`, and `PageNumber`. The returned result includes the status, runtime configurations, template configurations, custom information, and the URL of call log file for each AI agent.
 * **Note**:
 * *   The default value of `PageSize` is 10, and the default value of `PageNumber` is 1.
 *
 * @param request ListAIAgentInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListAIAgentInstanceResponse
 */
async function listAIAgentInstanceWithOptions(request: ListAIAgentInstanceRequest, runtime: $RuntimeOptions): ListAIAgentInstanceResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.AIAgentId)) {
    query['AIAgentId'] = request.AIAgentId;
  }
  if (!$isNull(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!$isNull(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListAIAgentInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of AI agents.
 *
 * @description ## [](#)Request description
 * You can call this operation to query a list of AI agents based on the `AIAgentId`. The optional parameters include `StartTime`, `EndTime`, `PageSize`, and `PageNumber`. The returned result includes the status, runtime configurations, template configurations, custom information, and the URL of call log file for each AI agent.
 * **Note**:
 * *   The default value of `PageSize` is 10, and the default value of `PageNumber` is 1.
 *
 * @param request ListAIAgentInstanceRequest
 * @return ListAIAgentInstanceResponse
 */
async function listAIAgentInstance(request: ListAIAgentInstanceRequest): ListAIAgentInstanceResponse {
  var runtime = new $RuntimeOptions{};
  return listAIAgentInstanceWithOptions(request, runtime);
}

model ListAdInsertionsRequest {
  keyword?: string(name='Keyword', description='The configuration name. Fuzzy match is supported.', example='ad'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to retrieve in a subsequent request. If this parameter is used, the pagination parameters become invalid. Default value: 10.', example='10'),
  nextToken?: string(name='NextToken', description='The token that is used in the next request to retrieve a new page of results. If this parameter is used, the pagination parameters become invalid.', example='******8EqYpQbZ6Eh7+Zz8DxVYoQ*****'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting order of the configurations by creation time. asc: ascending. desc: descending.', example='asc'),
}

model ListAdInsertionsResponseBody = {
  configs?: [ 
    {
      adMarkerPassthrough?: string(name='AdMarkerPassthrough', description='Indicates whether ad marker passthrough is enabled.', example='ON'),
      adsUrl?: string(name='AdsUrl', description='The request URL of the ad decision server (ADS).', example='http://ads.com/ad1?param1=[palyer_params.p1]'),
      cdnConfig?: {
        adSegmentUrlPrefix?: string(name='AdSegmentUrlPrefix', description='The CDN prefix for ad segments.', example='http://cdn.com/'),
        contentSegmentUrlPrefix?: string(name='ContentSegmentUrlPrefix', description='The CDN prefix for content segments.', example='http://cdn.com/'),
      }(name='CdnConfig', description='The CDN configurations.'),
      configAliases?: string(name='ConfigAliases', description='The player parameter variables and aliases.', example='{
      "player_params.p1": {
            "1": "abc"
      }
}'),
      contentUrlPrefix?: string(name='ContentUrlPrefix', description='The URL prefix for the source content.', example='https://source.com/'),
      createTime?: string(name='CreateTime', description='The time when the configuration was created.', example='2024-06-13T08:26:09Z'),
      lastModified?: string(name='LastModified', description='The time when the configuration was last modified.', example='2024-06-13T08:26:09Z'),
      manifestEndpointConfig?: {
        hlsPrefix?: string(name='HlsPrefix', description='The prefix of the playback endpoint for HLS manifests.'),
      }(name='ManifestEndpointConfig', description='The playback endpoint configuration.'),
      name?: string(name='Name', description='The name of the ad insertion configuration.', example='my_ad'),
      personalizationThreshold?: int32(name='PersonalizationThreshold', description='The personalization threshold that defines the maximum duration of underfilled time allowed in an ad break.', example='5'),
      slateAdUrl?: string(name='SlateAdUrl', description='The URL of the slate ad.', example='http://storage.com/slate1.mp4'),
    }
  ](name='Configs', description='Array'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to retrieve in a subsequent request. If this parameter is used, the pagination parameters become invalid.', example='10'),
  nextToken?: string(name='NextToken', description='The token that is used in the next request to retrieve a new page of results. If this parameter is used, the pagination parameters become invalid.', example='******8EqYpQbZ6Eh7+Zz8DxVYoQ*****'),
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the configurations by creation time. asc: ascending. desc: descending.', example='asc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='10'),
}

model ListAdInsertionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAdInsertionsResponseBody(name='body'),
}

/**
 * @summary Obtains ad insertion configurations.
 *
 * @param request ListAdInsertionsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListAdInsertionsResponse
 */
async function listAdInsertionsWithOptions(request: ListAdInsertionsRequest, runtime: $RuntimeOptions): ListAdInsertionsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!$isNull(request.maxResults)) {
    query['MaxResults'] = request.maxResults;
  }
  if (!$isNull(request.nextToken)) {
    query['NextToken'] = request.nextToken;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListAdInsertions',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Obtains ad insertion configurations.
 *
 * @param request ListAdInsertionsRequest
 * @return ListAdInsertionsResponse
 */
async function listAdInsertions(request: ListAdInsertionsRequest): ListAdInsertionsResponse {
  var runtime = new $RuntimeOptions{};
  return listAdInsertionsWithOptions(request, runtime);
}

model ListAlertsRequest {
  category?: string(name='Category', description='The alert type.'),
  gmtEnd?: string(name='GmtEnd', description='The end of the time range to query.', example='2024-11-22T16:10:45Z'),
  gmtStart?: string(name='GmtStart', description='The beginning of the time range to query.', example='2024-11-21T16:10:45Z'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='20'),
  resourceArn?: string(name='ResourceArn', description='The ARN of the source or program.

This parameter is required.', example='acs:ims:mediaweaver:<regionId>:<userId>:vodSource/mySourceLocation/MySource'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values: asc and desc.', example='asc'),
  sortByModifiedTime?: string(name='SortByModifiedTime', description='The sorting order by modification time. Valid values: asc and desc.', example='asc'),
}

model ListAlertsResponseBody = {
  alerts?: [ 
    {
      category?: string(name='Category', description='The alert type.'),
      code?: string(name='Code', description='The error code.', example='ScheduleError'),
      gmtCreate?: string(name='GmtCreate', description='The time when the alert was received in UTC.', example='2024-07-16T10:03Z'),
      gmtModified?: string(name='GmtModified', description='The time when the alert was modified in UTC.', example='2024-07-16T10:03Z'),
      message?: string(name='Message', description='The error message.', example='xxxxx'),
      relatedResourceArns?: string(name='RelatedResourceArns', description='The ARN of the related resource.', example='acs:ims:mediaweaver:<regionId>:<userId>:vodSource/mySourceLocation/MySource'),
      resourceArn?: string(name='ResourceArn', description='The ARN of the resource.', example='acs:ims:mediaweaver:<regionId>:<userId>:vodSource/mySourceLocation/MySource'),
    }
  ](name='Alerts', description='The alerts.'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListAlertsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAlertsResponseBody(name='body'),
}

/**
 * @summary Lists alerts received in MediaWeaver.
 *
 * @param request ListAlertsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListAlertsResponse
 */
async function listAlertsWithOptions(request: ListAlertsRequest, runtime: $RuntimeOptions): ListAlertsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.category)) {
    query['Category'] = request.category;
  }
  if (!$isNull(request.gmtEnd)) {
    query['GmtEnd'] = request.gmtEnd;
  }
  if (!$isNull(request.gmtStart)) {
    query['GmtStart'] = request.gmtStart;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.resourceArn)) {
    query['ResourceArn'] = request.resourceArn;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.sortByModifiedTime)) {
    query['SortByModifiedTime'] = request.sortByModifiedTime;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListAlerts',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Lists alerts received in MediaWeaver.
 *
 * @param request ListAlertsRequest
 * @return ListAlertsResponse
 */
async function listAlerts(request: ListAlertsRequest): ListAlertsResponse {
  var runtime = new $RuntimeOptions{};
  return listAlertsWithOptions(request, runtime);
}

model ListAllPublicMediaTagsRequest {
  businessType?: string(name='BusinessType', description='The business type of the media asset.', example='"sticker"'),
  entityId?: string(name='EntityId', description='The entity ID, which is used to distinguish between media assets of different types in the public domain.

Set this parameter to Copyright_Music, which indicates music in the public domain.', example='Copyright_Music'),
}

model ListAllPublicMediaTagsResponseBody = {
  mediaTagList?: [ 
    {
      mediaTagId?: string(name='MediaTagId', description='The ID of the media tag.', example='sticker-gif'),
      mediaTagNameChinese?: string(name='MediaTagNameChinese', description='The name of the media tag in Chinese.', example='Gif'),
      mediaTagNameEnglish?: string(name='MediaTagNameEnglish', description='The name of the material tag in English.'),
      options?: [ 
        {
          optionChineseName?: string(name='OptionChineseName', description='The option name in Chinese.'),
          optionEnglishName?: string(name='OptionEnglishName', description='The option name in English.', example='Angry'),
          optionId?: string(name='OptionId', description='The option ID.', example='Angry'),
        }
      ](name='Options', description='The options.'),
    }
  ](name='MediaTagList', description='The tags of media assets in the public media library.'),
  requestId?: string(name='RequestId', description='The request ID.', example='B45F83B7-7F87-4792-BFE9-63CD2137CAF0'),
}

model ListAllPublicMediaTagsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAllPublicMediaTagsResponseBody(name='body'),
}

/**
 * @summary Queries a list of tags of media assets in the public media library.
 *
 * @param request ListAllPublicMediaTagsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListAllPublicMediaTagsResponse
 */
async function listAllPublicMediaTagsWithOptions(request: ListAllPublicMediaTagsRequest, runtime: $RuntimeOptions): ListAllPublicMediaTagsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.businessType)) {
    query['BusinessType'] = request.businessType;
  }
  if (!$isNull(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListAllPublicMediaTags',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'Anonymous',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of tags of media assets in the public media library.
 *
 * @param request ListAllPublicMediaTagsRequest
 * @return ListAllPublicMediaTagsResponse
 */
async function listAllPublicMediaTags(request: ListAllPublicMediaTagsRequest): ListAllPublicMediaTagsResponse {
  var runtime = new $RuntimeOptions{};
  return listAllPublicMediaTagsWithOptions(request, runtime);
}

model ListAvatarTrainingJobsRequest {
  pageNo?: int32(name='PageNo', description='*   The page number.
*   Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='*   The number of entries per page.
*   Default value: 10.
*   Valid values: 1 to 100.', example='10'),
  status?: string(name='Status', description='*   The job state.
*   Valid values: Init, Queuing, Training, Success, and Fail.', example='Success'),
}

model ListAvatarTrainingJobsResponseBody = {
  data?: {
    avatarTrainingJobList?: [ 
      {
        avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
        avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXX'),
        avatarName?: string(name='AvatarName', description='The name of the digital human.'),
        avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
        createTime?: string(name='CreateTime', description='*   The time when the job was created.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
        firstTrainingTime?: string(name='FirstTrainingTime', description='*   The time when the first training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
        jobId?: string(name='JobId', description='The ID of the digital human training job.', example='*****aded114489ea02e0addf93*****'),
        lastTrainingTime?: string(name='LastTrainingTime', description='*   The time when the last training was initiated.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2020-12-23T13:33:40Z'),
        message?: string(name='Message', description='The status description.'),
        portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='*****aded114489ea02e0addf93*****'),
        status?: string(name='Status', description='The state of the digital human training job.', example='Normal'),
      }
    ](name='AvatarTrainingJobList', description='The list of digital human training jobs.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='3'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model ListAvatarTrainingJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAvatarTrainingJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of digital human training jobs.
 *
 * @param request ListAvatarTrainingJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListAvatarTrainingJobsResponse
 */
async function listAvatarTrainingJobsWithOptions(request: ListAvatarTrainingJobsRequest, runtime: $RuntimeOptions): ListAvatarTrainingJobsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListAvatarTrainingJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of digital human training jobs.
 *
 * @param request ListAvatarTrainingJobsRequest
 * @return ListAvatarTrainingJobsResponse
 */
async function listAvatarTrainingJobs(request: ListAvatarTrainingJobsRequest): ListAvatarTrainingJobsResponse {
  var runtime = new $RuntimeOptions{};
  return listAvatarTrainingJobsWithOptions(request, runtime);
}

model ListAvatarsRequest {
  avatarType?: string(name='AvatarType', description='*   The type of the digital human.
*   2DAvatar', example='2DAvatar'),
  pageNo?: int32(name='PageNo', description='*   The page number.
*   Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='*   The number of entries per page.
*   Default value: 10.', example='10'),
}

model ListAvatarsResponseBody = {
  data?: {
    avatarList?: [ 
      {
        avatarDescription?: string(name='AvatarDescription', description='The description of the digital human.'),
        avatarId?: string(name='AvatarId', description='The ID of the digital human.', example='Avatar-XXX'),
        avatarName?: string(name='AvatarName', description='The name of the digital human.'),
        avatarType?: string(name='AvatarType', description='The type of the digital human.', example='2DAvatar'),
        portrait?: string(name='Portrait', description='The media asset ID of the portrait image.', example='****571c704445f9a0ee011406c2****'),
        thumbnail?: string(name='Thumbnail', description='The thumbnail URL.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
        transparent?: boolean(name='Transparent', description='Indicates whether the digital human image supports the alpha channels.', example='true'),
      }
    ](name='AvatarList', description='The queried digital humans.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model ListAvatarsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAvatarsResponseBody(name='body'),
}

/**
 * @summary Queries a list of trained digital humans.
 *
 * @param request ListAvatarsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListAvatarsResponse
 */
async function listAvatarsWithOptions(request: ListAvatarsRequest, runtime: $RuntimeOptions): ListAvatarsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.avatarType)) {
    query['AvatarType'] = request.avatarType;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListAvatars',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of trained digital humans.
 *
 * @param request ListAvatarsRequest
 * @return ListAvatarsResponse
 */
async function listAvatars(request: ListAvatarsRequest): ListAvatarsResponse {
  var runtime = new $RuntimeOptions{};
  return listAvatarsWithOptions(request, runtime);
}

model ListBatchMediaProducingJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2023-06-05T15:59:59Z'),
  jobId?: string(name='JobId', description='The ID of the quick video production job.', example='****d80e4e4044975745c14b****'),
  jobType?: string(name='JobType', description='The job type.

Valid values:

*   Script: script-based editing job that mixes media assets.
*   Smart_Mix: intelligent editing job that mixes media assets.', example='Script'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.', example='100'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='mRZkKAovub0xWVfH14he4Q=='),
  sortBy?: string(name='SortBy', description='The sorting parameter. Valid values:

*   desc (default): sorted by creation time in descending order.
*   asc: sorted by creation time in ascending order.

<!---->', example='desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-02-02T00:00:00Z'),
  status?: string(name='Status', description='The job state.

Valid values:

*   Finished
*   Init
*   Failed
*   Processing', example='Finished'),
}

model ListBatchMediaProducingJobsResponseBody = {
  editingBatchJobList?: [ 
    {
      completeTime?: string(name='CompleteTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the *yyyy-MM-dd*T*HH:mm:ss*Z format. The time is displayed in UTC.', example='2023-06-09T06:38:09Z'),
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-06-09T06:36:48Z'),
      editingConfig?: string(name='EditingConfig', description='The editing configurations. For more information, see [EditingConfig](~~2692547#1be9bba03b7qu~~).', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}'),
      extend?: string(name='Extend', description='The extended information of the job.', example='{}'),
      inputConfig?: string(name='InputConfig', description='The input configurations.'),
      jobId?: string(name='JobId', description='The ID of the quick video production job.', example='******7ecbee4c6d9b8474498e******'),
      jobType?: string(name='JobType', description='The job type.

Valid values:

*   Script: script-based editing job that mixes media assets.
*   Smart_Mix: intelligent editing job that mixes media assets.', example='Script'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2023-06-09T06:37:58Z'),
      outputConfig?: string(name='OutputConfig', description='The output configurations. For more information, see [OutputConfig](~~2692547#447b928fcbuoa~~).', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 20,
  "MaxDuration": 15,
  "Width": 1080,
  "Height": 1920,
  "Video": {"Crf": 27}
}'),
      status?: string(name='Status', description='The job state.

Valid values:

*   Finished
*   Init
*   Failed
*   Processing', example='Finished'),
      userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).'),
    }
  ](name='EditingBatchJobList', description='The queried quick video production jobs.'),
  maxResults?: int32(name='MaxResults', description='The number of entries per page. Valid values: 1 to 100.

Default value: 10.', example='100'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model ListBatchMediaProducingJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListBatchMediaProducingJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of quick video production jobs based on conditions such as the job type and state.
 *
 * @param request ListBatchMediaProducingJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListBatchMediaProducingJobsResponse
 */
async function listBatchMediaProducingJobsWithOptions(request: ListBatchMediaProducingJobsRequest, runtime: $RuntimeOptions): ListBatchMediaProducingJobsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.jobType)) {
    query['JobType'] = request.jobType;
  }
  if (!$isNull(request.maxResults)) {
    query['MaxResults'] = request.maxResults;
  }
  if (!$isNull(request.nextToken)) {
    query['NextToken'] = request.nextToken;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListBatchMediaProducingJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of quick video production jobs based on conditions such as the job type and state.
 *
 * @param request ListBatchMediaProducingJobsRequest
 * @return ListBatchMediaProducingJobsResponse
 */
async function listBatchMediaProducingJobs(request: ListBatchMediaProducingJobsRequest): ListBatchMediaProducingJobsResponse {
  var runtime = new $RuntimeOptions{};
  return listBatchMediaProducingJobsWithOptions(request, runtime);
}

model ListChannelAlertsRequest {
  category?: string(name='Category', description='The alert type.'),
  gmtEnd?: string(name='GmtEnd', description='The end of the time range to query.', example='2024-11-21T16:10:45Z'),
  gmtStart?: string(name='GmtStart', description='The beginning of the time range to query.', example='2024-11-21T16:10:45Z'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  resourceArn?: string(name='ResourceArn', description='The ARN of the channel.

This parameter is required.', example='acs:ims:mediaweaver:<regionId>:<userId>:channel/myChannel'),
  sortByModifiedTime?: string(name='SortByModifiedTime', description='The sorting order by modification time. Valid values: asc and desc.', example='desc'),
}

model ListChannelAlertsResponseBody = {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  programAlerts?: [ 
    {
      arn?: string(name='Arn', description='The ARN of the program.', example='acs:ims:mediaweaver:<regionId>:<userId>:program/myChannel/MyProgram'),
      category?: string(name='Category', description='The alert type.'),
      count?: int32(name='Count', description='The number of alerts.', example='4'),
      gmtModified?: string(name='GmtModified', description='The time when the alert was last modified in UTC.', example='2024-07-16T10:03Z'),
      programName?: string(name='ProgramName', description='The name of the program.', example='program_name'),
    }
  ](name='ProgramAlerts', description='The alerts.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  totalCount?: int32(name='TotalCount', description='The total number of alerts returned.', example='4'),
}

model ListChannelAlertsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListChannelAlertsResponseBody(name='body'),
}

/**
 * @summary Lists alerts for resources in a MediaWeaver channel.
 *
 * @param request ListChannelAlertsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListChannelAlertsResponse
 */
async function listChannelAlertsWithOptions(request: ListChannelAlertsRequest, runtime: $RuntimeOptions): ListChannelAlertsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.category)) {
    query['Category'] = request.category;
  }
  if (!$isNull(request.gmtEnd)) {
    query['GmtEnd'] = request.gmtEnd;
  }
  if (!$isNull(request.gmtStart)) {
    query['GmtStart'] = request.gmtStart;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.resourceArn)) {
    query['ResourceArn'] = request.resourceArn;
  }
  if (!$isNull(request.sortByModifiedTime)) {
    query['SortByModifiedTime'] = request.sortByModifiedTime;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListChannelAlerts',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Lists alerts for resources in a MediaWeaver channel.
 *
 * @param request ListChannelAlertsRequest
 * @return ListChannelAlertsResponse
 */
async function listChannelAlerts(request: ListChannelAlertsRequest): ListChannelAlertsResponse {
  var runtime = new $RuntimeOptions{};
  return listChannelAlertsWithOptions(request, runtime);
}

model ListChannelsRequest {
  channelName?: string(name='ChannelName', description='The name of the channel.', example='MyChannel'),
  channelTier?: string(name='ChannelTier', description='The tier of the channel. Valid values: basic and standard.', example='basic'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='20'),
  playbackMode?: string(name='PlaybackMode', description='The playback mode. Valid values: loop and linear.', example='loop'),
  sortBy?: string(name='SortBy', description='The sorting order by creation time. Valid values: asc and desc.', example='asc'),
  sortByModifiedTime?: string(name='SortByModifiedTime', description='The sorting order by modification time. Valid values: asc and desc.', example='desc'),
  state?: int32(name='State', description='The channel status. A value of 0 specifies stopped. A value of 1 specifies started.', example='0'),
}

model ListChannelsResponseBody = {
  channelList?: [
    ChannelAssemblyChannel
  ](name='ChannelList', description='The channels.'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  totalCount?: int32(name='TotalCount', description='The total number of channels returned.', example='180'),
}

model ListChannelsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListChannelsResponseBody(name='body'),
}

/**
 * @summary Lists MediaWeaver channels.
 *
 * @param request ListChannelsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListChannelsResponse
 */
async function listChannelsWithOptions(request: ListChannelsRequest, runtime: $RuntimeOptions): ListChannelsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.channelTier)) {
    query['ChannelTier'] = request.channelTier;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.playbackMode)) {
    query['PlaybackMode'] = request.playbackMode;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.sortByModifiedTime)) {
    query['SortByModifiedTime'] = request.sortByModifiedTime;
  }
  if (!$isNull(request.state)) {
    query['State'] = request.state;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListChannels',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Lists MediaWeaver channels.
 *
 * @param request ListChannelsRequest
 * @return ListChannelsResponse
 */
async function listChannels(request: ListChannelsRequest): ListChannelsResponse {
  var runtime = new $RuntimeOptions{};
  return listChannelsWithOptions(request, runtime);
}

model ListCustomTemplatesRequest {
  name?: string(name='Name', description='The template name.', example='test-template'),
  orderBy?: string(name='OrderBy', description='The order in which the entries are sorted. Valid values:

*   CreateTimeDesc: sorted by creation time in descending order.
*   CreateTimeAsc: sorted by creation time in ascending order.', example='CreateTimeDesc'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='20'),
  subtype?: string(name='Subtype', description='The subtype ID of the template.

*   Valid values for transcoding templates:

    *   1 (Normal): regular template.
    *   2 (AudioTranscode): audio transcoding template.
    *   3 (Remux): container format conversion template.
    *   4 (NarrowBandV1): Narrowband HD 1.0 template.
    *   5 (NarrowBandV2): Narrowband HD 2.0 template.

*   Valid values for snapshot templates:

    *   1 (Normal): regular template.
    *   2 (Sprite): sprite template.
    *   3 (WebVtt): WebVTT template.

*   Valid values for AI-assisted content moderation templates:

    *   1 (Video): video moderation template.
    *   2 (Audio): audio moderation template.
    *   3 (Image): image moderation template.

*   Valid values for AI-assisted intelligent erasure templates:

    *   1 (VideoDelogo): logo erasure template.
    *   2 (VideoDetext): subtitle erasure template.', example='2'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
  type?: string(name='Type', description='The template type. Valid values:

*   1: transcoding template.
*   2: snapshot template.
*   3: animated image template.
*   4\\\\. image watermark template.
*   5: text watermark template.
*   6: subtitle template.
*   7: AI-assisted content moderation template.
*   8: AI-assisted intelligent thumbnail template.
*   9: AI-assisted intelligent erasure template.

This parameter is required.', example='1'),
}

model ListCustomTemplatesResponseBody = {
  customTemplateList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
      frontendHint?: {
        transcodeTemplateHint?: {
          bitrateControlType?: string(name='BitrateControlType'),
        }(name='TranscodeTemplateHint'),
      }(name='FrontendHint'),
      isDefault?: boolean(name='IsDefault', description='Indicates whether the template is the default template.

Valid values:

*   true
*   false', example='true'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
      status?: string(name='Status', description='The template state.

Valid values:

*   Normal', example='Normal'),
      subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='2'),
      subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='AudioTranscode'),
      templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Container":{"Format":"mp3"},"Audio":{"Codec":"mp3","Bitrate":"64","Samplerate":"22050","Channels":"2"}}'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
      templateName?: string(name='TemplateName', description='The template name.', example='test-template'),
      type?: int32(name='Type', description='The type ID of the template.', example='1'),
      typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
    }
  ](name='CustomTemplateList', description='The queried templates.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  total?: int32(name='Total', description='The total number of templates.', example='20'),
}

model ListCustomTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCustomTemplatesResponseBody(name='body'),
}

/**
 * @summary Queries a list of custom templates.
 *
 * @param request ListCustomTemplatesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListCustomTemplatesResponse
 */
async function listCustomTemplatesWithOptions(request: ListCustomTemplatesRequest, runtime: $RuntimeOptions): ListCustomTemplatesResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!$isNull(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.subtype)) {
    query['Subtype'] = request.subtype;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListCustomTemplates',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of custom templates.
 *
 * @param request ListCustomTemplatesRequest
 * @return ListCustomTemplatesResponse
 */
async function listCustomTemplates(request: ListCustomTemplatesRequest): ListCustomTemplatesResponse {
  var runtime = new $RuntimeOptions{};
  return listCustomTemplatesWithOptions(request, runtime);
}

model ListCustomizedVoiceJobsRequest {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10'),
  type?: string(name='Type', description='The type of the human voice cloning job. Valid values:

*   Basic
*   Standard

> : If you do not specify this parameter, the default value Basic is used.', example='Standard'),
}

model ListCustomizedVoiceJobsResponseBody = {
  data?: {
    customizedVoiceJobList?: [ 
      {
        createTime?: string(name='CreateTime', description='*   The time when the job was created.
*   The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-04-01T06:23:59Z'),
        gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
        gmtCreate?: string(name='GmtCreate', description='The time when the job was created.', example='2022-06-27T02:42:28Z'),
        jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='2245ab99a7fd4116a4fd3f499b7a56c5'),
        message?: string(name='Message', description='The returned message.'),
        scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation', example='story'),
        status?: string(name='Status', description='The job state. Valid values:

*   Initialization
*   AudioDetecting
*   PreTraining
*   Training
*   Success
*   Fail', example='Success'),
        type?: string(name='Type', description='*   The voice type. Valid values:

    *   Basic
    *   Standard', example='Standard'),
        voiceDesc?: string(name='VoiceDesc', description='The voice description.

*   The description can be up to 256 characters in length.'),
        voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
        voiceName?: string(name='VoiceName', description='The voice name.

*   The name can be up to 32 characters in length.'),
      }
    ](name='CustomizedVoiceJobList', description='The queried human voice cloning jobs.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='271'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
}

model ListCustomizedVoiceJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCustomizedVoiceJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of human voice cloning jobs.
 *
 * @param request ListCustomizedVoiceJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListCustomizedVoiceJobsResponse
 */
async function listCustomizedVoiceJobsWithOptions(request: ListCustomizedVoiceJobsRequest, runtime: $RuntimeOptions): ListCustomizedVoiceJobsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListCustomizedVoiceJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of human voice cloning jobs.
 *
 * @param request ListCustomizedVoiceJobsRequest
 * @return ListCustomizedVoiceJobsResponse
 */
async function listCustomizedVoiceJobs(request: ListCustomizedVoiceJobsRequest): ListCustomizedVoiceJobsResponse {
  var runtime = new $RuntimeOptions{};
  return listCustomizedVoiceJobsWithOptions(request, runtime);
}

model ListCustomizedVoicesRequest {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10'),
  type?: string(name='Type', description='*   The voice type. Valid values:

    *   Basic
    *   Standard

*   If you do not specify this parameter, the default value Basic is used.', example='Standard'),
}

model ListCustomizedVoicesResponseBody = {
  data?: {
    customizedVoiceList?: [ 
      {
        demoAudioMediaId?: string(name='DemoAudioMediaId', description='The media asset ID of the sample audio file.', example='****4d5e829d498aaf966b119348****'),
        gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='male'),
        scenario?: string(name='Scenario', description='The scenario. Valid values:

*   story
*   interaction
*   navigation', example='story'),
        type?: string(name='Type', description='*   The voice type. Valid values:

    *   Basic
    *   Standard', example='Standard'),
        voiceDesc?: string(name='VoiceDesc', description='The voice description.'),
        voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
        voiceName?: string(name='VoiceName', description='The voice name.'),
      }
    ](name='CustomizedVoiceList', description='The queried personalized human voices.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='41'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model ListCustomizedVoicesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCustomizedVoicesResponseBody(name='body'),
}

/**
 * @summary Queries a list of personalized human voices.
 *
 * @param request ListCustomizedVoicesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListCustomizedVoicesResponse
 */
async function listCustomizedVoicesWithOptions(request: ListCustomizedVoicesRequest, runtime: $RuntimeOptions): ListCustomizedVoicesResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListCustomizedVoices',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of personalized human voices.
 *
 * @param request ListCustomizedVoicesRequest
 * @return ListCustomizedVoicesResponse
 */
async function listCustomizedVoices(request: ListCustomizedVoicesRequest): ListCustomizedVoicesResponse {
  var runtime = new $RuntimeOptions{};
  return listCustomizedVoicesWithOptions(request, runtime);
}

model ListDNADBRequest {
  DBIds?: string(name='DBIds', description='The IDs of the media fingerprint libraries. We recommend that you query at most 10 libraries at a time. Separate multiple library IDs with commas (,).', example='2288c6ca184c0e47098a5b665e2a12****,78dc866518b843259669df58ed30****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model ListDNADBResponseBody = {
  DBList?: [ 
    {
      DBId?: string(name='DBId', description='The ID of the media fingerprint library.', example='88c6ca184c0e47098a5b665e2a12****'),
      description?: string(name='Description', description='The description of the media fingerprint library.'),
      model?: string(name='Model', description='The model of the media fingerprint library. Valid values:

*   **Video**
*   **Audio**
*   **Image**
*   **Text** (supported only in the China (Shanghai) region)', example='Video'),
      name?: string(name='Name', description='The name of the media fingerprint library.', example='example-name'),
      status?: string(name='Status', description='The state of the media fingerprint library. Default value: **offline**. ****Valid values:

*   **offline**: The media fingerprint library is offline.
*   **active**: The media fingerprint library is online.
*   **deleted**: The media fingerprint library is deleted.', example='active'),
    }
  ](name='DBList', description='The queried media fingerprint libraries.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model ListDNADBResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDNADBResponseBody(name='body'),
}

/**
 * @summary Queries a list of media fingerprint libraries.
 *
 * @param request ListDNADBRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListDNADBResponse
 */
async function listDNADBWithOptions(request: ListDNADBRequest, runtime: $RuntimeOptions): ListDNADBResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.DBIds)) {
    query['DBIds'] = request.DBIds;
  }
  if (!$isNull(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!$isNull(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!$isNull(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!$isNull(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListDNADB',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of media fingerprint libraries.
 *
 * @param request ListDNADBRequest
 * @return ListDNADBResponse
 */
async function listDNADB(request: ListDNADBRequest): ListDNADBResponse {
  var runtime = new $RuntimeOptions{};
  return listDNADBWithOptions(request, runtime);
}

model ListDNAFilesRequest {
  DBId?: string(name='DBId', description='The ID of the media fingerprint library.

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='ae0fd49c0840e14daf0d66a75b83****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model ListDNAFilesResponseBody = {
  fileList?: [ 
    {
      inputFile?: {
        bucket?: string(name='Bucket', description='The name of the OSS bucket in which the input file is stored.', example='example-bucket'),
        location?: string(name='Location', description='The OSS region in which the input file resides.', example='oss-cn-beijing'),
        object?: string(name='Object', description='The name of the OSS object that is used as the input file.', example='example-****.mp4'),
      }(name='InputFile', description='The Object Storage Service (OSS) information about the input file.'),
      primaryKey?: string(name='PrimaryKey', description='The primary key of the file.', example='ae0fd49c0840e14daf0d66a75b83****'),
    }
  ](name='FileList', description='The queried files.'),
  nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='ae0fd49c0840e14daf0d66a75b83****'),
  requestId?: string(name='RequestId', description='The request ID.', example='2AE89FA5-E620-56C7-9B80-75D09757385A'),
}

model ListDNAFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDNAFilesResponseBody(name='body'),
}

/**
 * @summary Queries a list of files in a media fingerprint library.
 *
 * @description You can call this operation to query files in a media fingerprint library based on the library ID. The queried results can be paginated.
 *
 * @param request ListDNAFilesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListDNAFilesResponse
 */
async function listDNAFilesWithOptions(request: ListDNAFilesRequest, runtime: $RuntimeOptions): ListDNAFilesResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.DBId)) {
    query['DBId'] = request.DBId;
  }
  if (!$isNull(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!$isNull(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!$isNull(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!$isNull(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListDNAFiles',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of files in a media fingerprint library.
 *
 * @description You can call this operation to query files in a media fingerprint library based on the library ID. The queried results can be paginated.
 *
 * @param request ListDNAFilesRequest
 * @return ListDNAFilesResponse
 */
async function listDNAFiles(request: ListDNAFilesRequest): ListDNAFilesResponse {
  var runtime = new $RuntimeOptions{};
  return listDNAFilesWithOptions(request, runtime);
}

model ListDynamicImageJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created.', example='2022-07-14T00:00:00Z'),
  jobId?: string(name='JobId', description='The job ID.', example='****cdb3e74639973036bc84****'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='cdb3e74639973036bc84'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

1.  CreateTimeAsc: sorts the jobs by creation time in ascending order.
2.  CreateTimeDesc: sorts the jobs by creation time in descending order.', example='CreateTimeDesc'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Maximum value: 100.', example='20'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created.', example='2022-07-12T00:00:00Z'),
  status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
}

model ListDynamicImageJobsResponseBody = {
  jobs?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
      input?: {
        media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[regionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://bucket/object'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.

*
*', example='OSS'),
      }(name='Input', description='The input of the job.'),
      jobId?: string(name='JobId', description='The job ID.', example='****cdb3e74639973036bc84****'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
      name?: string(name='Name', description='The name of the job.', example='SampleJob'),
      output?: {
        media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='****cdb3e74639973036bc84****'),
        type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

*
*', example='Media'),
      }(name='Output', description='The output of the job.'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****cdb3e74639973036bc84****'),
      status?: string(name='Status', description='The state of the job.

*   **Success**: The job is successful.
*   **Fail**: The job failed.
*   **Init**: The job is submitted.', example='Success'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****cdb3e74639973036bc84****'),
      triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
    }
  ](name='Jobs', description='The list of jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****cdb3e74639973036bc84****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListDynamicImageJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDynamicImageJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of image animation jobs.
 *
 * @param request ListDynamicImageJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListDynamicImageJobsResponse
 */
async function listDynamicImageJobsWithOptions(request: ListDynamicImageJobsRequest, runtime: $RuntimeOptions): ListDynamicImageJobsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endOfCreateTime)) {
    query['EndOfCreateTime'] = request.endOfCreateTime;
  }
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!$isNull(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.startOfCreateTime)) {
    query['StartOfCreateTime'] = request.startOfCreateTime;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListDynamicImageJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of image animation jobs.
 *
 * @param request ListDynamicImageJobsRequest
 * @return ListDynamicImageJobsResponse
 */
async function listDynamicImageJobs(request: ListDynamicImageJobsRequest): ListDynamicImageJobsResponse {
  var runtime = new $RuntimeOptions{};
  return listDynamicImageJobsWithOptions(request, runtime);
}

model ListEditingProjectsRequest {
  createSource?: string(name='CreateSource', description='The method for creating the online editing project. Valid values:

\\\\- OpenAPI

\\\\- AliyunConsole

\\\\- WebSDK', example='OpenAPI'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-02-02T23:59:59Z'),
  keyword?: string(name='Keyword', description='The search keyword. You can search by job ID.', example='******6f36bc45d09a9d5cde49******'),
  maxResults?: string(name='MaxResults', description='The number of entries per page. A maximum of 100 entries can be returned on each page.

Default value: 10.', example='10'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  projectType?: string(name='ProjectType', description='The type of the editing project. Valid values:

*   EditingProject: a regular editing project.
*   LiveEditingProject: a live stream editing project.', example='EditingProject'),
  sortBy?: string(name='SortBy', description='The order of sorting of the results. Valid values:

*   CreationTime:Desc (default): sorts the results in reverse chronological order.
*   CreationTime:Asc: sorts the results in chronological order.', example='CreationTime:Desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-12-21T08:00:01Z'),
  status?: string(name='Status', description='The status of the online editing project. By default, online editing projects in all states are queried.', example='Produced'),
  templateType?: string(name='TemplateType', description='The template type. This parameter is required if you create a template-based online editing project. Default value: Timeline.

*
*

Valid values:

*   Timeline: a regular template.
*   VETemplate: an advanced template.
*   None: general editing.', example='None'),
}

model ListEditingProjectsResponseBody = {
  maxResults?: int32(name='MaxResults', description='The maximum number of entries returned.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.

This parameter is required.', example='Nzv3rcKla9wHUGua9YXHNA=='),
  projectList?: [ 
    {
      businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{}'),
      businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects.', example='{}'),
      coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='https://xxx.com/cover/xxx.jpg'),
      createSource?: string(name='CreateSource', description='The method for editing the online editing project. Valid values:

\\\\- OpenAPI

\\\\- AliyunConsole

\\\\- WebSDK', example='OpenAPI'),
      createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2017-01-11T12:00:00Z'),
      description?: string(name='Description', description='The description of the online editing project.'),
      errorCode?: string(name='ErrorCode', description='The error code returned if the production of the online editing project failed.', example='InvalidParameter'),
      errorMessage?: string(name='ErrorMessage', description='The error message returned if the production of the online editing project failed.', example='The specified parameter \\\\"LiveStreamConfig\\\\" is not valid. specified parameter example is not valid.'),
      modifiedSource?: string(name='ModifiedSource', description='The method for modifying the online editing project last time.', example='OpenAPI'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last modified.', example='2017-01-11T12:00:00Z'),
      projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fddd7748b58bf1d47e95****'),
      projectType?: string(name='ProjectType', description='The type of the editing project. Valid values:

*   EditingProject: a regular editing project.
*   LiveEditingProject: a live stream editing project.', example='EditingProject'),
      status?: string(name='Status', description='The status of the online editing project. Valid values:

\\\\- Draft

\\\\- Editing

\\\\- Producing

\\\\- Produced

\\\\- ProduceFailed', example='Produced'),
      templateType?: string(name='TemplateType', description='The template type. Valid values:

*   Timeline: a regular template.
*   VETemplate: an advanced template.', example='Timeline'),
      title?: string(name='Title', description='The title of the online editing project.'),
    }
  ](name='ProjectList', description='The queried online editing projects.'),
  requestId?: string(name='RequestId', description='The request ID.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
}

model ListEditingProjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListEditingProjectsResponseBody(name='body'),
}

/**
 * @summary Queries a list of projects that meet the specified conditions. You can filter projects by project creation time.
 *
 * @param request ListEditingProjectsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListEditingProjectsResponse
 */
async function listEditingProjectsWithOptions(request: ListEditingProjectsRequest, runtime: $RuntimeOptions): ListEditingProjectsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.createSource)) {
    query['CreateSource'] = request.createSource;
  }
  if (!$isNull(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!$isNull(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!$isNull(request.maxResults)) {
    query['MaxResults'] = request.maxResults;
  }
  if (!$isNull(request.nextToken)) {
    query['NextToken'] = request.nextToken;
  }
  if (!$isNull(request.projectType)) {
    query['ProjectType'] = request.projectType;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  if (!$isNull(request.templateType)) {
    query['TemplateType'] = request.templateType;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListEditingProjects',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of projects that meet the specified conditions. You can filter projects by project creation time.
 *
 * @param request ListEditingProjectsRequest
 * @return ListEditingProjectsResponse
 */
async function listEditingProjects(request: ListEditingProjectsRequest): ListEditingProjectsResponse {
  var runtime = new $RuntimeOptions{};
  return listEditingProjectsWithOptions(request, runtime);
}

model ListLivePackageChannelGroupsRequest {
  keyword?: string(name='Keyword', description='The channel group name or description. Fuzzy match is supported.', example='channel-group'),
  pageNo?: long(name='PageNo', description='The page number. Pages start from page 1. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10'),
  sortBy?: string(name='SortBy', description='The sort order by creation time. Default value: desc.', example='desc'),
}

model ListLivePackageChannelGroupsResponseBody = {
  livePackageChannelGroups?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the channel group was created. It is in the `yyyy-MM-ddTHH:mm:ssZ` format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
      description?: string(name='Description', description='The channel group description.'),
      groupName?: string(name='GroupName', description='The channel group name.', example='testChannelGroup'),
      lastModified?: string(name='LastModified', description='The time when the channel group was last modified. It is in the `yyyy-MM-ddTHH:mm:ssZ` format and displayed in UTC.', example='2023-04-02T12:00:00Z'),
      originDomain?: string(name='OriginDomain', description='The origin domain.', example='origin.example.com'),
    }
  ](name='LivePackageChannelGroups', description='The channel groups returned.'),
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='5D87B753-0250-5D9D-B248-D40C3271F864'),
  sortBy?: string(name='SortBy', description='The sort order.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLivePackageChannelGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLivePackageChannelGroupsResponseBody(name='body'),
}

/**
 * @summary Queries live package channel groups by page. Fuzzy search by name or description and sorting are supported.
 *
 * @description ## [](#)Usage notes
 *
 * @param request ListLivePackageChannelGroupsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLivePackageChannelGroupsResponse
 */
async function listLivePackageChannelGroupsWithOptions(request: ListLivePackageChannelGroupsRequest, runtime: $RuntimeOptions): ListLivePackageChannelGroupsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListLivePackageChannelGroups',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries live package channel groups by page. Fuzzy search by name or description and sorting are supported.
 *
 * @description ## [](#)Usage notes
 *
 * @param request ListLivePackageChannelGroupsRequest
 * @return ListLivePackageChannelGroupsResponse
 */
async function listLivePackageChannelGroups(request: ListLivePackageChannelGroupsRequest): ListLivePackageChannelGroupsResponse {
  var runtime = new $RuntimeOptions{};
  return listLivePackageChannelGroupsWithOptions(request, runtime);
}

model ListLivePackageChannelsRequest {
  groupName?: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1'),
  keyword?: string(name='Keyword', description='The channel name or description. Fuzzy match is supported.', example='group-1'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  sortBy?: string(name='SortBy', description='The sort order by creation time. Default value: desc.

Valid values:

*   asc
*   desc', example='desc'),
}

model ListLivePackageChannelsResponseBody = {
  livePackageChannels?: [ 
    {
      channelName?: string(name='ChannelName', description='The channel name.', example='ch3'),
      createTime?: string(name='CreateTime', description='The time when the channel was created.', example='2023-04-01T12:00:00Z'),
      description?: string(name='Description', description='The channel description.'),
      groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
      ingestEndpoints?: [ 
        {
          id?: string(name='Id', description='The ingest endpoint ID.', example='ingest1'),
          password?: string(name='Password', description='The password.', example='2F9e9******18b569c8'),
          url?: string(name='Url', description='The ingest endpoint URL.', example='http://xxx-1.packagepush-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
          username?: string(name='Username', description='The username.', example='us12******das'),
        }
      ](name='IngestEndpoints', description='The ingest endpoints.'),
      lastModified?: string(name='LastModified', description='The time when the channel was last modified.', example='2023-04-01T12:00:00Z'),
      protocol?: string(name='Protocol', description='The ingest protocol. Only HLS is supported.', example='HLS'),
      segmentCount?: int32(name='SegmentCount', description='The number of M3U8 segments.', example='3'),
      segmentDuration?: int32(name='SegmentDuration', description='The segment duration.', example='5'),
    }
  ](name='LivePackageChannels', description='The live package channels.'),
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.'),
  sortBy?: string(name='SortBy', description='The sort order. Valid values: asc and desc (default).', example='asc/desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='15'),
}

model ListLivePackageChannelsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLivePackageChannelsResponseBody(name='body'),
}

/**
 * @summary Queries live package channels by channel group and keyword. Paging and sorting are supported.
 *
 * @description ## [](#)Usage notes
 * This API operation allows you to query live package channels by **GroupName** and **Keyword**. Keyword is optional. You can sort the channels by creation time in ascending or descending order and paginate the results. This facilitates the management of channels and retrieval of channel information.
 * *   **GroupName** is required to specify the channel group to which the channel belongs.
 * *   **Keyword** supports fuzzy match of channel names or descriptions, which helps quickly filter desired channels.
 * *   **PageNo** and **PageSize** can help control the paging of returned results to facilitate batch processing of data.
 * *   **SortBy** allows you to customize how the results are sorted. By default, the results are sorted in descending order.
 * **RequestId** in the response is used for subsequent troubleshooting. **TotalCount** indicates the total number of channels that meet the conditions.
 *
 * @param request ListLivePackageChannelsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLivePackageChannelsResponse
 */
async function listLivePackageChannelsWithOptions(request: ListLivePackageChannelsRequest, runtime: $RuntimeOptions): ListLivePackageChannelsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  if (!$isNull(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListLivePackageChannels',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries live package channels by channel group and keyword. Paging and sorting are supported.
 *
 * @description ## [](#)Usage notes
 * This API operation allows you to query live package channels by **GroupName** and **Keyword**. Keyword is optional. You can sort the channels by creation time in ascending or descending order and paginate the results. This facilitates the management of channels and retrieval of channel information.
 * *   **GroupName** is required to specify the channel group to which the channel belongs.
 * *   **Keyword** supports fuzzy match of channel names or descriptions, which helps quickly filter desired channels.
 * *   **PageNo** and **PageSize** can help control the paging of returned results to facilitate batch processing of data.
 * *   **SortBy** allows you to customize how the results are sorted. By default, the results are sorted in descending order.
 * **RequestId** in the response is used for subsequent troubleshooting. **TotalCount** indicates the total number of channels that meet the conditions.
 *
 * @param request ListLivePackageChannelsRequest
 * @return ListLivePackageChannelsResponse
 */
async function listLivePackageChannels(request: ListLivePackageChannelsRequest): ListLivePackageChannelsResponse {
  var runtime = new $RuntimeOptions{};
  return listLivePackageChannelsWithOptions(request, runtime);
}

model ListLivePackageOriginEndpointsRequest {
  channelName?: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1'),
  groupName?: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1'),
  keyword?: string(name='Keyword', description='The endpoint name or description. Fuzzy match is supported.', example='endpoint-'),
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
  sortBy?: string(name='SortBy', description='The sort order by creation time. Valid values: asc and desc (default).', example='desc'),
}

model ListLivePackageOriginEndpointsResponseBody = {
  livePackageOriginEndpoints?: [ 
    {
      authorizationCode?: string(name='AuthorizationCode', description='The authorization code.', example='Abc123Def456'),
      channelName?: string(name='ChannelName', description='The channel name.', example='channel-1'),
      createTime?: string(name='CreateTime', description='The time when the endpoint was created.', example='2023-04-01T12:00:00Z'),
      description?: string(name='Description', description='The endpoint description.'),
      endpointName?: string(name='EndpointName', description='The endpoint name.', example='endpoint-1'),
      endpointUrl?: string(name='EndpointUrl', description='The endpoint URL.', example='https://xxx.packagepull-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest.m3u8'),
      groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
      ipBlacklist?: string(name='IpBlacklist', description='The IP address blacklist.', example='10.21.222.1/32,192.168.100.0/24'),
      ipWhitelist?: string(name='IpWhitelist', description='The IP address whitelist.', example='192.168.1.0/24,10.0.0.1/24'),
      lastModified?: string(name='LastModified', description='The time when the endpoint was last modified.', example='2023-04-01T12:00:00Z'),
      manifestName?: string(name='ManifestName', description='The playlist name.', example='manifest'),
      protocol?: string(name='Protocol', description='The distribution protocol.', example='HLS'),
      timeshiftVision?: int32(name='TimeshiftVision', description='The number of days that time-shifted content is available.', example='1'),
    }
  ](name='LivePackageOriginEndpoints', description='The origin endpoints returned.'),
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='b9f90a7ac8904db28dc18e0c2a72c75d'),
  sortBy?: string(name='SortBy', description='The sort order. Valid values: `asc` and `desc` (default).', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='10'),
}

model ListLivePackageOriginEndpointsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLivePackageOriginEndpointsResponseBody(name='body'),
}

/**
 * @summary Queries origin endpoints by channel group and channel name. Paging and sorting are supported.
 *
 * @description ## [](#)Usage notes
 * This API operation allows you to query origin endpoints associated with a live package channel. The results include detailed configurations about the origin endpoints, such as access URL, protocol, and security policies. Paging and sorting by creation time are supported.
 *
 * @param request ListLivePackageOriginEndpointsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLivePackageOriginEndpointsResponse
 */
async function listLivePackageOriginEndpointsWithOptions(request: ListLivePackageOriginEndpointsRequest, runtime: $RuntimeOptions): ListLivePackageOriginEndpointsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  if (!$isNull(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListLivePackageOriginEndpoints',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries origin endpoints by channel group and channel name. Paging and sorting are supported.
 *
 * @description ## [](#)Usage notes
 * This API operation allows you to query origin endpoints associated with a live package channel. The results include detailed configurations about the origin endpoints, such as access URL, protocol, and security policies. Paging and sorting by creation time are supported.
 *
 * @param request ListLivePackageOriginEndpointsRequest
 * @return ListLivePackageOriginEndpointsResponse
 */
async function listLivePackageOriginEndpoints(request: ListLivePackageOriginEndpointsRequest): ListLivePackageOriginEndpointsResponse {
  var runtime = new $RuntimeOptions{};
  return listLivePackageOriginEndpointsWithOptions(request, runtime);
}

model ListLiveRecordFilesRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. The maximum time range to query is four days. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-12-22T08:00:00Z'),
  jobIds?: [ string ](name='JobIds', description='The list of job IDs.'),
  pageNo?: int32(name='PageNo', description='The page number of the page to return. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 5 to 30. Default value: 10.', example='10'),
  recordFormat?: string(name='RecordFormat', description='The format of the recording file. Valid values:

M3U8, FLV, and MP4', example='m3u8'),
  sortBy?: string(name='SortBy', description='The sorting order of the index files by creation time. Valid values:

asc: The query results are displayed in ascending order. This is the default value.

desc: The query results are displayed in descending order.', example='asc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-12-21T08:00:01Z'),
}

model ListLiveRecordFilesResponseBody = {
  files?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the file was created in UTC.', example='2016-05-27T09:40:56Z'),
      duration?: float(name='Duration', description='The recording length. Unit: seconds.', example='100.0'),
      endTime?: string(name='EndTime', description='The end of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2015-12-01T07:36:10Z'),
      format?: string(name='Format', description='The format of the recording file.', example='m3u8'),
      height?: int32(name='Height', description='The height of the video.', example='640'),
      jobId?: string(name='JobId', description='The ID of the recording job.', example='c4d7f0a4-b506-43f9-8de3-07732c3f****'),
      jobName?: string(name='JobName', description='The name of the recording job.', example='LiveRecordJob***'),
      recordId?: string(name='RecordId', description='The ID of the index file.', example='c4d7f0a4-b506-43f9-8de3-07732c3f****'),
      recordOutput?: string(name='RecordOutput', description='The storage information about the recording file.', example='{ "Type": "oss", "Endpoint":"oss-cn-shanghai.aliyuncs.com", "Bucket": "test-bucket" }'),
      recordUrl?: string(name='RecordUrl', description='The URL of the index file.'),
      startTime?: string(name='StartTime', description='The beginning of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2015-12-01T07:36:00Z'),
      streamUrl?: string(name='StreamUrl', description='The name of the live stream.', example='LiveStream***'),
      width?: int32(name='Width', description='The width of the video.', example='480'),
    }
  ](name='Files', description='The list of index files.'),
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='DE24625C-7C0F-4020-8448-****'),
  sortBy?: string(name='SortBy', description='The sorting order of the index files by creation time.', example='asc'),
  totalCount?: string(name='TotalCount', description='The total number of files that meet the specified conditions.', example='100'),
}

model ListLiveRecordFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveRecordFilesResponseBody(name='body'),
}

/**
 * @summary Queries all recording index files in the specified period of time.
 *
 * @param request ListLiveRecordFilesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveRecordFilesResponse
 */
async function listLiveRecordFilesWithOptions(request: ListLiveRecordFilesRequest, runtime: $RuntimeOptions): ListLiveRecordFilesResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListLiveRecordFiles',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries all recording index files in the specified period of time.
 *
 * @param request ListLiveRecordFilesRequest
 * @return ListLiveRecordFilesResponse
 */
async function listLiveRecordFiles(request: ListLiveRecordFilesRequest): ListLiveRecordFilesResponse {
  var runtime = new $RuntimeOptions{};
  return listLiveRecordFilesWithOptions(request, runtime);
}

model ListLiveRecordJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. The maximum time range between EndTime and StartTime cannot exceed 30 days. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-11T08:00:00Z'),
  keyword?: string(name='Keyword', description='The search keyword. You can use the job ID or name as the keyword to search for jobs.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='20'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results in ascending order.
*   desc: sorts the query results in descending order.', example='desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-15T08:00:00Z'),
  status?: string(name='Status', description='The state of the job. By default, the state is not filtered.

Valid values:

*   paused: The job is paused.
*   initial: The job is not started.
*   started: The job is in progress.', example='started'),
}

model ListLiveRecordJobsResponseBody = {
  liveRecordJobs?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
      jobId?: string(name='JobId', description='The ID of the recording job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
      name?: string(name='Name', description='The name of the recording job.'),
      notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify'),
      recordOutput?: {
        bucket?: string(name='Bucket', description='The bucket name.', example='imsbucket1'),
        endpoint?: string(name='Endpoint', description='The endpoint of the storage service.', example='oss-cn-hangzhou.aliyuncs.com'),
        type?: string(name='Type', description='The type of the storage address.

Valid values:

*   vod
*   oss', example='oss'),
      }(name='RecordOutput', description='The storage address of the recording.'),
      status?: string(name='Status', description='The state of the recording job.', example='paused'),
      streamInput?: {
        type?: string(name='Type', description='The type of the live stream URL.', example='rtmp'),
        url?: string(name='Url', description='The URL of the live stream.', example='rtmp://example-live.com/live/stream1'),
      }(name='StreamInput', description='The URL of the live stream.'),
      templateId?: string(name='TemplateId', description='The ID of the recording template.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
      templateName?: string(name='TemplateName', description='The name of the recording template.', example='test template'),
    }
  ](name='LiveRecordJobs', description='The list of live stream recording jobs.'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='20'),
  requestId?: string(name='RequestId', description='The request ID.', example='A27DFFA4-F272-5563-8363-CB0BC42740BA'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='180'),
}

model ListLiveRecordJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveRecordJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream recording jobs by page.
 *
 * @param request ListLiveRecordJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveRecordJobsResponse
 */
async function listLiveRecordJobsWithOptions(request: ListLiveRecordJobsRequest, runtime: $RuntimeOptions): ListLiveRecordJobsResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListLiveRecordJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of live stream recording jobs by page.
 *
 * @param request ListLiveRecordJobsRequest
 * @return ListLiveRecordJobsResponse
 */
async function listLiveRecordJobs(request: ListLiveRecordJobsRequest): ListLiveRecordJobsResponse {
  var runtime = new $RuntimeOptions{};
  return listLiveRecordJobsWithOptions(request, runtime);
}

model ListLiveRecordTemplatesRequest {
  keyword?: string(name='Keyword', description='The search keyword. You can use the template ID or name as the keyword to search for templates. If you search for templates by name, fuzzy match is supported.', example='test template'),
  pageNo?: long(name='PageNo', description='The page number. Minimum value: 1. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results in ascending order.
*   desc: sorts the query results in descending order.', example='desc'),
  templateIds?: [ string ](name='TemplateIds'),
  type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
}

model ListLiveRecordTemplatesResponseBody = {
  pageNo?: long(name='PageNo', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
  recordTemplateList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T02:48:58Z'),
      lastModified?: string(name='LastModified', description='The time when the template was last modified.

Use the UTC time format: yyyy-MM-ddTHH:mmZ', example='2022-07-20T03:26:36Z'),
      name?: string(name='Name', description='The template name.', example='test template'),
      recordFormatList?: [ 
        {
          cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds.', example='21600'),
          format?: string(name='Format', description='The output file format.', example='m3u8'),
          ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording file that is stored in Object Storage Service (OSS).', example='record/{JobId}/{Sequence}_{EscapedStartTime}_{EscapedEndTime}'),
          sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds.', example='30'),
          sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
        }
      ](name='RecordFormatList', description='The list of recording formats.'),
      templateId?: string(name='TemplateId', description='The template ID.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
      type?: string(name='Type', description='The type of the template.', example='custom'),
    }
  ](name='RecordTemplateList', description='The list of recording templates.'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results in ascending order.
*   desc: sorts the query results in descending order.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='5'),
}

model ListLiveRecordTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveRecordTemplatesResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream recording templates.
 *
 * @param request ListLiveRecordTemplatesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveRecordTemplatesResponse
 */
async function listLiveRecordTemplatesWithOptions(request: ListLiveRecordTemplatesRequest, runtime: $RuntimeOptions): ListLiveRecordTemplatesResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListLiveRecordTemplates',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of live stream recording templates.
 *
 * @param request ListLiveRecordTemplatesRequest
 * @return ListLiveRecordTemplatesResponse
 */
async function listLiveRecordTemplates(request: ListLiveRecordTemplatesRequest): ListLiveRecordTemplatesResponse {
  var runtime = new $RuntimeOptions{};
  return listLiveRecordTemplatesWithOptions(request, runtime);
}

model ListLiveSnapshotFilesRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

*   The maximum time range that can be specified is one day.

This parameter is required.', example='2022-02-02T23:59:59Z'),
  jobId?: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
  limit?: int32(name='Limit', description='The number of results to return each time. Valid values: 1 to 100. Default value: 10.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting order. Default value: asc.

Valid values:

*   asc: sorts the query results by creation time in ascending order.
*   desc: sorts the query results by creation time in descending order.', example='desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

This parameter is required.', example='2022-02-02T00:00:00Z'),
}

model ListLiveSnapshotFilesResponseBody = {
  fileList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-02-02T22:22:22Z'),
      createTimestamp?: long(name='CreateTimestamp', description='The creation timestamp that is used as an input parameter for a delete API operation.', example='1619503516000'),
      isOverlay?: boolean(name='IsOverlay', description='Specifies whether to overlay snapshots.', example='true'),
      ossBucket?: string(name='OssBucket', description='The OSS bucket.', example='testbucket'),
      ossEndpoint?: string(name='OssEndpoint', description='The Object Storage Service (OSS) domain name.', example='oss-cn-shanghai.aliyuncs.com'),
      ossObject?: string(name='OssObject', description='The location in which the OSS object is stored.'),
    }
  ](name='FileList', description='The list of files.'),
  nextStartTime?: string(name='NextStartTime', description='The start time of the next page. If no value is returned, the pagination ends.', example='2022-02-02T22:22:22Z'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListLiveSnapshotFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveSnapshotFilesResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream snapshot files by page.
 *
 * @param request ListLiveSnapshotFilesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveSnapshotFilesResponse
 */
async function listLiveSnapshotFilesWithOptions(request: ListLiveSnapshotFilesRequest, runtime: $RuntimeOptions): ListLiveSnapshotFilesResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListLiveSnapshotFiles',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of live stream snapshot files by page.
 *
 * @param request ListLiveSnapshotFilesRequest
 * @return ListLiveSnapshotFilesResponse
 */
async function listLiveSnapshotFiles(request: ListLiveSnapshotFilesRequest): ListLiveSnapshotFilesResponse {
  var runtime = new $RuntimeOptions{};
  return listLiveSnapshotFilesWithOptions(request, runtime);
}

model ListLiveSnapshotJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

*   By default, EndTime is seven days later than StartTime.
*   The time range specified by the StartTime and EndTime parameters cannot exceed 30 days.', example='2022-02-02T23:59:59Z'),
  pageNo?: int32(name='PageNo', description='The page number. Valid values: [1,n). Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10'),
  searchKeyWord?: string(name='SearchKeyWord', description='The search keyword. You can use the job ID or name as the keyword to search for jobs. If you search for jobs by name, fuzzy match is supported.

*   It cannot exceed 128 characters in length.', example='****a046-263c-3560-978a-fb287782****'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results by creation time in ascending order.
*   desc: sorts the query results by creation time in descending order.', example='desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

*   The default value is seven days ago.
*   The time range specified by the StartTime and EndTime parameters cannot exceed 30 days.', example='2022-02-02T00:00:00Z'),
  status?: string(name='Status', description='The job state filter. By default, all jobs are queried.

Valid values:

*   init: The job is not started.
*   paused: The job is paused.
*   started: The job is in progress.'),
}

model ListLiveSnapshotJobsResponseBody = {
  jobList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-20T02:48:58Z'),
      jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287782****'),
      jobName?: string(name='JobName', description='The name of the job.'),
      snapshotOutput?: {
        bucket?: string(name='Bucket', description='The bucket of the output endpoint. If the storage type is set to oss, the OSS bucket is returned.', example='testbucket'),
        endpoint?: string(name='Endpoint', description='The output endpoint. If the storage type is set to oss, the Object Storage Service (OSS) domain name is returned.', example='oss-cn-shanghai.aliyuncs.com'),
        storageType?: string(name='StorageType', description='The storage type. The value can only be oss.', example='oss'),
      }(name='SnapshotOutput', description='The output information.'),
      status?: string(name='Status', description='The state of the job.

Valid values:

*   init: The job is not started.
*   paused: The job is paused.
*   started: The job is in progress.', example='started'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287666****'),
      templateName?: string(name='TemplateName', description='The template name.'),
      timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.', example='5'),
    }
  ](name='JobList', description='The list of jobs.'),
  pageNo?: int32(name='PageNo', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the jobs by creation time.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveSnapshotJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveSnapshotJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream snapshot jobs by page.
 *
 * @param request ListLiveSnapshotJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveSnapshotJobsResponse
 */
async function listLiveSnapshotJobsWithOptions(request: ListLiveSnapshotJobsRequest, runtime: $RuntimeOptions): ListLiveSnapshotJobsResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListLiveSnapshotJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of live stream snapshot jobs by page.
 *
 * @param request ListLiveSnapshotJobsRequest
 * @return ListLiveSnapshotJobsResponse
 */
async function listLiveSnapshotJobs(request: ListLiveSnapshotJobsRequest): ListLiveSnapshotJobsResponse {
  var runtime = new $RuntimeOptions{};
  return listLiveSnapshotJobsWithOptions(request, runtime);
}

model ListLiveSnapshotTemplatesRequest {
  pageNo?: int32(name='PageNo', description='The page number. Valid values: [1,n). Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10'),
  searchKeyWord?: string(name='SearchKeyWord', description='The search keyword. You can use the template ID or name as the keyword to search for templates. If you search for templates by name, fuzzy match is supported.

*   It cannot exceed 128 characters in length.', example='****a046-263c-3560-978a-fb287782****'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.

Valid values:

*   asc: sorts the query results by creation time in ascending order.
*   desc: sorts the query results by creation time in descending order.', example='desc'),
  templateIds?: [ string ](name='TemplateIds', description='The template IDs.

*   If you specify the SearchKeyWord parameter, this condition does not take effect.
*   The maximum length of the array is 200.'),
  type?: string(name='Type', description='The type of the template. By default, all types are queried.

Valid values:

*   system
*   custom', example='custom'),
}

model ListLiveSnapshotTemplatesResponseBody = {
  pageNo?: int32(name='PageNo', description='The number of the returned page.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the results by creation time.', example='desc'),
  templateList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T02:48:58Z'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****a046-263c-3560-978a-fb287782****'),
      templateName?: string(name='TemplateName', description='The template name.'),
      timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.', example='10'),
      type?: string(name='Type', description='The type of the template.

Valid values:

*   system
*   custom', example='custom'),
    }
  ](name='TemplateList', description='The list of the templates.'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveSnapshotTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveSnapshotTemplatesResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream snapshot templates by page.
 *
 * @param request ListLiveSnapshotTemplatesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveSnapshotTemplatesResponse
 */
async function listLiveSnapshotTemplatesWithOptions(request: ListLiveSnapshotTemplatesRequest, runtime: $RuntimeOptions): ListLiveSnapshotTemplatesResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListLiveSnapshotTemplates',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of live stream snapshot templates by page.
 *
 * @param request ListLiveSnapshotTemplatesRequest
 * @return ListLiveSnapshotTemplatesResponse
 */
async function listLiveSnapshotTemplates(request: ListLiveSnapshotTemplatesRequest): ListLiveSnapshotTemplatesResponse {
  var runtime = new $RuntimeOptions{};
  return listLiveSnapshotTemplatesWithOptions(request, runtime);
}

model ListLiveTranscodeJobsRequest {
  keyWord?: string(name='KeyWord', description='The search keyword. You can use the job ID or name as the keyword to search for jobs. If you search for jobs by name, fuzzy match is supported.', example='24ecbb5c-4f98-4194-9400-f17102e27fc5'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='20'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values:

*   asc
*   desc', example='asc'),
  startMode?: int32(name='StartMode', description='The start mode of the transcoding job.

*   0: The transcoding job immediately starts.
*   1: The transcoding job starts at the scheduled time.', example='0'),
  status?: int32(name='Status', description='The state of the job.

0: The job is not started. 1: The job is in progress. 2: The job is stopped.', example='1'),
  type?: string(name='Type', description='The type of the template used by the transcoding job.

*   normal
*   narrow-band
*   audio-only
*   origin', example='normal'),
}

model ListLiveTranscodeJobsResponseBody = {
  jobList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T02:48:58Z'),
      jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287782****'),
      name?: string(name='Name', description='The name of the transcoding job.', example='mytask'),
      outputStream?: {
        streamInfos?: [ 
          {
            outputUrl?: string(name='OutputUrl', description='The URL of the output stream.', example='rtmp://mydomain/app/mytranscode1'),
            type?: string(name='Type', description='The type of the output stream protocol. Only the RTMP protocol is supported.', example='rtmp'),
          }
        ](name='StreamInfos', description='The list of stream URLs.'),
      }(name='OutputStream', description='The information about the output stream.'),
      startMode?: int32(name='StartMode', description='The start mode of the job.', example='0'),
      status?: int32(name='Status', description='The state of the job.', example='1'),
      streamInput?: {
        inputUrl?: string(name='InputUrl', description='The URL of the input stream.', example='rtmp://mydomain/app/stream1'),
        type?: string(name='Type', description='The type of the input stream.', example='rtmp'),
      }(name='StreamInput', description='The information about the input stream.'),
      templateId?: string(name='TemplateId', description='The ID of the transcoding template used by the transcoding job.', example='****a046-263c-3560-978a-fb287666****'),
      templateName?: string(name='TemplateName', description='The template name.'),
      templateType?: string(name='TemplateType', description='The type of the transcoding template used by the transcoding job.', example='normal'),
    }
  ](name='JobList', description='The list of transcoding jobs.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveTranscodeJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveTranscodeJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream transcoding jobs.
 *
 * @param request ListLiveTranscodeJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveTranscodeJobsResponse
 */
async function listLiveTranscodeJobsWithOptions(request: ListLiveTranscodeJobsRequest, runtime: $RuntimeOptions): ListLiveTranscodeJobsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.keyWord)) {
    query['KeyWord'] = request.keyWord;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.startMode)) {
    query['StartMode'] = request.startMode;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListLiveTranscodeJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of live stream transcoding jobs.
 *
 * @param request ListLiveTranscodeJobsRequest
 * @return ListLiveTranscodeJobsResponse
 */
async function listLiveTranscodeJobs(request: ListLiveTranscodeJobsRequest): ListLiveTranscodeJobsResponse {
  var runtime = new $RuntimeOptions{};
  return listLiveTranscodeJobsWithOptions(request, runtime);
}

model ListLiveTranscodeTemplatesRequest {
  category?: string(name='Category', description='The category of the template. Valid values:

*   system
*   customized', example='customized'),
  keyWord?: string(name='KeyWord', description='The search keyword. You can use the template ID or name as the keyword to search for templates. If you search for templates by name, fuzzy match is supported.', example='my_template'),
  pageNo?: int32(name='PageNo', description='The page number of the page to return. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='20'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values:

*   asc
*   desc', example='asc'),
  type?: string(name='Type', description='The type of the template. Valid values:

*   normal
*   narrow-band
*   audio-only
*   origin', example='normal'),
  videoCodec?: string(name='VideoCodec', description='The video codec. Valid values:

*   H.264
*   H.265', example='H.264'),
}

model ListLiveTranscodeTemplatesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  templateContentList?: [ 
    {
      category?: string(name='Category', description='The category of the template. Valid values:', example='system'),
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-20T03:26:36Z'),
      name?: string(name='Name', description='The template name.', example='my_template'),
      templateConfig?: {
        audioParams?: {
          bitrate?: string(name='Bitrate', description='The audio bitrate.', example='1000'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codec?: string(name='Codec', description='The audio codec.', example='AAC'),
          profile?: string(name='Profile', description='The encoding profile.', example='aac_low'),
          samplerate?: string(name='Samplerate', description='The audio sampling rate.', example='44100'),
        }(name='AudioParams', description='The audio parameters.'),
        videoParams?: {
          bitrate?: string(name='Bitrate', description='The video bitrate.', example='2500'),
          codec?: string(name='Codec', description='The encoding format.', example='264'),
          fps?: string(name='Fps', description='The video frame rate.', example='30'),
          gop?: string(name='Gop', description='The group of pictures (GOP) of the output video. Unit: frame.', example='1000'),
          height?: string(name='Height', description='The vertical resolution of the video.', example='1280'),
          profile?: string(name='Profile', description='The encoding profile.', example='3'),
          width?: string(name='Width', description='The horizontal resolution of the video.', example='720'),
        }(name='VideoParams', description='The video parameters.'),
      }(name='TemplateConfig', description='The configuration of the template.'),
      templateId?: string(name='TemplateId', description='The template ID.', example='9b1571b513cb44f7a1ba6ae561ff46f7'),
      type?: string(name='Type', description='The type of the template.', example='normal'),
    }
  ](name='TemplateContentList', description='The list of transcoding templates.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListLiveTranscodeTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLiveTranscodeTemplatesResponseBody(name='body'),
}

/**
 * @summary Queries a list of live stream transcoding templates.
 *
 * @param request ListLiveTranscodeTemplatesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListLiveTranscodeTemplatesResponse
 */
async function listLiveTranscodeTemplatesWithOptions(request: ListLiveTranscodeTemplatesRequest, runtime: $RuntimeOptions): ListLiveTranscodeTemplatesResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.category)) {
    query['Category'] = request.category;
  }
  if (!$isNull(request.keyWord)) {
    query['KeyWord'] = request.keyWord;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  if (!$isNull(request.videoCodec)) {
    query['VideoCodec'] = request.videoCodec;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListLiveTranscodeTemplates',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of live stream transcoding templates.
 *
 * @param request ListLiveTranscodeTemplatesRequest
 * @return ListLiveTranscodeTemplatesResponse
 */
async function listLiveTranscodeTemplates(request: ListLiveTranscodeTemplatesRequest): ListLiveTranscodeTemplatesResponse {
  var runtime = new $RuntimeOptions{};
  return listLiveTranscodeTemplatesWithOptions(request, runtime);
}

model ListMediaBasicInfosRequest {
  businessType?: string(name='BusinessType', description='The business type of the media asset. Valid values:

\\\\- subtitles

\\\\- watermark

\\\\- opening

\\\\- ending

\\\\- general', example='opening'),
  endTime?: string(name='EndTime', description='The end time of utcCreated.

\\\\- The value is the end of the left-open right-closed interval.

\\\\- Specify the time in the ISO 8601 standard in the YYYY-MM-DDThh:mm:ssZ format. For example, 2017-01-11T12:00:00Z indicates 20:00:00 on January 11, 2017 (UTC +8).', example='2020-12-20T13:00:00Z'),
  includeFileBasicInfo?: boolean(name='IncludeFileBasicInfo', description='Specifies whether to return the basic information of the source file.', example='true'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.

Maximum value: 100. Default value: 10.', example='5'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

\\\\- image

\\\\- video

\\\\- audio

\\\\- text', example='video'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='pSa1SQ0wCe5pzVrQ6mWZEw=='),
  sortBy?: string(name='SortBy', description='The order of sorting by utcCreated. Default value: desc. Valid values:

\\\\- desc

\\\\- asc', example='desc'),
  source?: string(name='Source', description='The source of the media asset. Valid values:

\\\\- oss: Object Storage Service (OSS).

\\\\- vod: ApsaraVideo VOD.

\\\\- live: ApsaraVideo Live.

\\\\- general: other sources. This is the default value.', example='oss'),
  startTime?: string(name='StartTime', description='The start time of utcCreated.

\\\\- The value is the beginning of a left-open right-closed interval.

\\\\- Specify the time in the ISO 8601 standard in the YYYY-MM-DDThh:mm:ssZ format. For example, 2017-01-11T12:00:00Z indicates 20:00:00 on January 11, 2017 (UTC +8).', example='2020-12-20T12:00:00Z'),
  status?: string(name='Status', description='The status of the media asset. Valid values:

\\\\- Init: the initial state, which indicates that the source file is not ready.

\\\\- Preparing: The source file is being prepared. For example, the file is being uploaded or edited.

\\\\- PrepareFail: The source file failed to be prepared. For example, the information of the source file failed to be obtained.

\\\\- Normal: The source file is ready.', example='Normal'),
}

model ListMediaBasicInfosResponseBody = {
  maxResults?: int32(name='MaxResults', description='The maximum number of entries returned in the query.', example='2'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='1912.13'),
            createTime?: string(name='CreateTime', description='The time when the file was created.', example='2021-01-08T16:52:04Z'),
            duration?: string(name='Duration', description='The duration.', example='60.00000'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='14340962'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The OSS URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example2.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='720'),
            modifiedTime?: string(name='ModifiedTime', description='The time when the file was last modified.', example='2021-01-08T16:52:07Z'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='1280'),
          }(name='FileBasicInfo', description='The basic information of the file, including the duration and size.'),
        }
      ](name='FileInfoList', description='FileInfos'),
      mediaBasicInfo?: {
        biz?: string(name='Biz', description='The service to which the media asset belongs.', example='ICE'),
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='opening'),
        cateId?: long(name='CateId', description='The category ID.', example='3049'),
        category?: string(name='Category', description='The category of the media asset.'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2021-01-08T16:52:04Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2021-01-08T16:52:07Z'),
        description?: string(name='Description', description='The description of the media asset.'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='tags,tags2'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2021-01-08T16:52:07Z'),
        referenceId?: string(name='ReferenceId', description='The custom ID of the media asset. The ID is a string that contains 6 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are supported. The ID is unique among users.', example='123-123'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='[{"bucket":"example-bucket","count":"3","iceJobId":"******f48f0e4154976b2b8c45******","location":"oss-cn-beijing","snapshotRegular":"example.jpg","templateId":"******e6a6440b29eb60bd7c******"}]'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The sprite.', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        uploadSource?: string(name='UploadSource', description='The upload source of the media asset.', example='general'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='BasicInfo'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******B7-7F87-4792-BFE9-63CD21******'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='4'),
}

model ListMediaBasicInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaBasicInfosResponseBody(name='body'),
}

/**
 * @summary Queries the basic information of all media assets that meet the specified conditions.
 *
 * @description If includeFileBasicInfo is set to true, the basic information, such as the duration and file size, of the source file is also returned. At most the first 100 entries that meet the specified conditions are returned. All media assets must exactly match all non-empty fields. The fields that support exact match include MediaType, Source, BusinessType, Category, and Status. If all information cannot be returned at a time, you can use NextToken to initiate a request to retrieve a new page of results.
 *
 * @param request ListMediaBasicInfosRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListMediaBasicInfosResponse
 */
async function listMediaBasicInfosWithOptions(request: ListMediaBasicInfosRequest, runtime: $RuntimeOptions): ListMediaBasicInfosResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.businessType)) {
    query['BusinessType'] = request.businessType;
  }
  if (!$isNull(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!$isNull(request.includeFileBasicInfo)) {
    query['IncludeFileBasicInfo'] = request.includeFileBasicInfo;
  }
  if (!$isNull(request.maxResults)) {
    query['MaxResults'] = request.maxResults;
  }
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!$isNull(request.nextToken)) {
    query['NextToken'] = request.nextToken;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.source)) {
    query['Source'] = request.source;
  }
  if (!$isNull(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListMediaBasicInfos',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the basic information of all media assets that meet the specified conditions.
 *
 * @description If includeFileBasicInfo is set to true, the basic information, such as the duration and file size, of the source file is also returned. At most the first 100 entries that meet the specified conditions are returned. All media assets must exactly match all non-empty fields. The fields that support exact match include MediaType, Source, BusinessType, Category, and Status. If all information cannot be returned at a time, you can use NextToken to initiate a request to retrieve a new page of results.
 *
 * @param request ListMediaBasicInfosRequest
 * @return ListMediaBasicInfosResponse
 */
async function listMediaBasicInfos(request: ListMediaBasicInfosRequest): ListMediaBasicInfosResponse {
  var runtime = new $RuntimeOptions{};
  return listMediaBasicInfosWithOptions(request, runtime);
}

model ListMediaInfoJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-15T00:00:00Z'),
  jobId?: string(name='JobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb11cbe'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='ab4802364a2e49208c99efab82dfa8e8'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

*   CreateTimeDesc: sorts the query results by creation time in descending order.
*   CreateTimeAsc: sorts the query results by creation time in ascending order.', example='CreateTimeDesc'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-01T00:00:00Z'),
  status?: string(name='Status', description='The state of the job. Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
}

model ListMediaInfoJobsResponseBody = {
  jobs?: [ 
    {
      async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      input?: {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
      }(name='Input', description='The input of the job.'),
      jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
      mediaInfoProperty?: {
        audioStreamInfoList?: [ 
          {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
            channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
            channels?: string(name='Channels', description='The number of sound channels.', example='2'),
            codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
            codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
            codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
            codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
            codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
            duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
            index?: string(name='Index', description='The sequence number of the stream.', example='1'),
            lang?: string(name='Lang', description='The language of the stream.', example='cn'),
            sampleFmt?: string(name='SampleFmt', description='The sampling format.', example='fltp'),
            sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
            startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
            timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
          }
        ](name='AudioStreamInfoList', description='The information about the audio stream.'),
        fileBasicInfo?: {
          bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
          duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
          fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
          fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
          fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
          fileType?: string(name='FileType', description='The file type. Valid values: source_file and transcode_file.', example='source_file'),
          fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
          formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
          height?: string(name='Height', description='The height.', example='478'),
          mediaId?: string(name='MediaId', description='The ID of the media asset.', example='4765337007f571edbfdf81848c016303'),
          region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
          width?: string(name='Width', description='The width.', example='848'),
        }(name='FileBasicInfo', description='The basic file information.'),
        videoStreamInfoList?: [ 
          {
            avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
            bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
            codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
            codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
            codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
            codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
            codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
            dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
            duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
            fps?: string(name='Fps', description='The frame rate.', example='25.0'),
            hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
            height?: string(name='Height', description='The height.', example='478'),
            index?: string(name='Index', description='The sequence number of the stream.', example='0'),
            lang?: string(name='Lang', description='The language of the stream.', example='cn'),
            level?: string(name='Level', description='The codec level.', example='31'),
            numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
            pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
            profile?: string(name='Profile', description='The encoder profile.', example='High'),
            rotate?: string(name='Rotate', description='The rotation angle of the video image.

*   Valid values: 0, 90, 180, and 270.
*   Default value: 0.', example='0'),
            sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
            startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
            timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
            width?: string(name='Width', description='The width.', example='848'),
          }
        ](name='VideoStreamInfoList', description='The information about the video stream.'),
      }(name='MediaInfoProperty', description='The details of the media information.'),
      name?: string(name='Name', description='The job name.', example='job-name'),
      requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
      scheduleConfig?: {
        pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
        priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
      }(name='ScheduleConfig', description='The scheduling information.'),
      status?: string(name='Status', description='The state of the job. Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Init'),
      submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
      userData?: string(name='UserData', description='The user data.', example='user-data'),
    }
  ](name='Jobs', description='The list of media information analysis jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. The token of the next page is returned after you call this operation for the first time.', example='019daf5780f74831b0e1a767c9f1c178'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model ListMediaInfoJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaInfoJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of media information analysis jobs.
 *
 * @param request ListMediaInfoJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListMediaInfoJobsResponse
 */
async function listMediaInfoJobsWithOptions(request: ListMediaInfoJobsRequest, runtime: $RuntimeOptions): ListMediaInfoJobsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endOfCreateTime)) {
    query['EndOfCreateTime'] = request.endOfCreateTime;
  }
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!$isNull(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.startOfCreateTime)) {
    query['StartOfCreateTime'] = request.startOfCreateTime;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListMediaInfoJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of media information analysis jobs.
 *
 * @param request ListMediaInfoJobsRequest
 * @return ListMediaInfoJobsResponse
 */
async function listMediaInfoJobs(request: ListMediaInfoJobsRequest): ListMediaInfoJobsResponse {
  var runtime = new $RuntimeOptions{};
  return listMediaInfoJobsWithOptions(request, runtime);
}

model ListMediaLiveChannelsRequest {
  keyword?: string(name='Keyword', description='The keyword of the query. You can perform a fuzzy search on channel ID or name.', example='123'),
  maxResults?: int32(name='MaxResults', description='The number of entries per page. Valid values: 1 to 100. Default value:

*   If you do not specify this parameter or if you set a value smaller than 10, the default value is 10.
*   If you set a value greater than 100, the default value is 100.', example='10'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='caeba0bbb2be03f84eb48b699f0a4883'),
  skip?: int32(name='Skip', description='The number of entries to be skipped in the query. If the number of entries you attempt to skip exceeds the number of entries that meet the condition, an empty list is returned.', example='20'),
  sortOrder?: string(name='SortOrder', description='The sorting order of the channels by creation time. Default value: asc. Valid values: desc and asc. asc indicates the ascending order, and desc indicates the descending order.', example='desc'),
  states?: string(name='States', description='The state of channels you want to query. You can separate multiple states with commas (,) in a JSON array.', example='["IDLE","RUNNING"]'),
}

model ListMediaLiveChannelsResponseBody = {
  channels?: [ 
    {
      audioSettings?: [ 
        {
          audioCodec?: string(name='AudioCodec', description='The audio codec.', example='aac'),
          audioCodecSetting?: {
            bitrate?: int32(name='Bitrate', description='The audio bitrate. Unit: bit/s.', example='200000'),
            profile?: string(name='Profile', description='The audio codec profile.', example='AAC-LOW'),
            sampleRate?: int32(name='SampleRate', description='The audio sample rate. Unit: Hz.', example='44100'),
          }(name='AudioCodecSetting', description='The audio encoding settings.'),
          audioSelectorName?: string(name='AudioSelectorName', description='The name of the audio selector.', example='myselector'),
          languageCode?: string(name='LanguageCode', description='A three-letter ISO 639-2 language code.', example='eng'),
          languageName?: string(name='LanguageName', description='The name of the language.', example='English'),
          name?: string(name='Name', description='The name of the audio settings.', example='zhuanfengzhuang'),
        }
      ](name='AudioSettings', description='The audio settings.'),
      channelId?: string(name='ChannelId', description='The ID of the channel.', example='SEGK5KA6KYKAWQQH'),
      createTime?: string(name='CreateTime', description='The time when the channel was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-12-03T06:56:42Z'),
      inputAttachments?: [ 
        {
          audioSelectors?: [ 
            {
              audioLanguageSelection?: {
                languageCode?: string(name='LanguageCode', description='A three-letter ISO 639-2 language code from within an audio source.

This parameter is required.', example='eng'),
              }(name='AudioLanguageSelection', description='The audio language selection.'),
              audioPidSelection?: {
                pid?: long(name='Pid', description='A PID from within a source.

This parameter is required.', example='123'),
              }(name='AudioPidSelection', description='The audio PID selection.'),
              audioTrackSelection?: [ 
                {
                  trackId?: long(name='TrackId', description='The track ID from within a source.

This parameter is required.', example='1'),
                }
              ](name='AudioTrackSelection', description='The audio track selection.'),
              name?: string(name='Name', description='The name of the audio selector.

This parameter is required.', example='myselector'),
            }
          ](name='AudioSelectors', description='The audio selectors.'),
          inputId?: string(name='InputId', description='The ID of the input.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
          inputName?: string(name='InputName', description='The name of the input.', example='myinput'),
          languageName?: string(name='LanguageName', description='The name of the language.', example='eng'),
        }
      ](name='InputAttachments', description='The inputs associated with the channel.'),
      lastStartTime?: string(name='LastStartTime', description='The time when the channel was last started. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC. If the channel has never been started since it was created, an empty string is returned.', example='2024-12-03T06:56:42Z'),
      lastStopTime?: string(name='LastStopTime', description='The time when the channel was last stopped. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC. If the channel has never stopped since it was created, an empty string is returned.', example='2024-12-03T06:56:42Z'),
      name?: string(name='Name', description='The name of the channel.', example='mych'),
      outputGroups?: [ 
        {
          mediaPackageGroupSetting?: {
            channelName?: string(name='ChannelName', description='ChannelName in MediaPackage.', example='myPackageChannel'),
            groupName?: string(name='GroupName', description='GroupName in MediaPackage.', example='myPackageGroup'),
          }(name='MediaPackageGroupSetting', description='The MediaPackage destination.'),
          monitorUrl?: string(name='MonitorUrl', description='The URL for monitoring the output group. The parameter is returned only when the output gourp type is MediaPackage.', example='rtmp://xxx'),
          name?: string(name='Name', description='The name of the output group.', example='group1'),
          outputs?: [ 
            {
              audioSettingNames?: [ string ](name='AudioSettingNames', description='The referenced AudioSettings.'),
              mediaPackageOutputSetting?: {
                audioGroupId?: string(name='AudioGroupId', description='The manifest audio group ID.', example='audiogroup'),
                nameModifier?: string(name='NameModifier', description='The manifest name modifier. The child manifests include this modifier in their M3U8 file names.', example='480p'),
              }(name='MediaPackageOutputSetting', description='The settings of the output delivered to MediaPackage.'),
              mediaType?: int32(name='MediaType', description='The media type of the output.', example='0'),
              name?: string(name='Name', description='The name of the output.', example='output1'),
              videoSettingName?: string(name='VideoSettingName', description='The name of the referenced VideoSettings.', example='myVideo1'),
            }
          ](name='Outputs', description='The outputs in the output group.'),
          type?: string(name='Type', description='The output group type.', example='MediaPackage'),
        }
      ](name='OutputGroups', description='The output groups.'),
      state?: string(name='State', description='The state of the channel. Valid values: IDLE, STARTING, RUNNING, RECOVERING, and STOPPING.', example='IDLE'),
      videoSettings?: [ 
        {
          height?: int32(name='Height', description='The height of the video in pixels.', example='720'),
          name?: string(name='Name', description='The name of the video settings.', example='video1'),
          videoCodec?: string(name='VideoCodec', description='The video codec.', example='H264'),
          videoCodecSetting?: {
            codecDetail?: {
              level?: string(name='Level', description='The video encoding level. It is not supported yet.', example='H264_LEVEL_AUTO'),
              profile?: string(name='Profile', description='The H.264 profile.', example='MAIN'),
            }(name='CodecDetail', description='The video encoding settings.'),
            framerate?: {
              framerateControl?: string(name='FramerateControl', description='The frame rate mode.', example='SPECIFIED'),
              framerateDenominator?: int32(name='FramerateDenominator', description='The denominator of the fixed frame rate.', example='1'),
              framerateNumerator?: int32(name='FramerateNumerator', description='The numerator of the fixed frame rate.', example='25'),
            }(name='Framerate', description='The frame rate.'),
            gop?: {
              bframesNum?: int32(name='BframesNum', description='The number of B frames.', example='3'),
              gopSize?: int32(name='GopSize', description='The GOP size.', example='90'),
              gopSizeUnits?: string(name='GopSizeUnits', description='The GOP size unit.', example='FRAMES'),
            }(name='Gop', description='The GOP setting.'),
            rate?: {
              bitrate?: int32(name='Bitrate', description='The video bitrate. Unit: bit/s.', example='2500000'),
              bufferSize?: int32(name='BufferSize', description='The video buffer size. Unit: bit/s.', example='6000000'),
              maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s.', example='6000000'),
              rateControlMode?: string(name='RateControlMode', description='The bitrate control mode.', example='ABR'),
            }(name='Rate', description='The video encoding rate.'),
          }(name='VideoCodecSetting', description='The video encoding settings.'),
          width?: int32(name='Width', description='The width of the video in pixels.', example='1280'),
        }
      ](name='VideoSettings', description='The video settings.'),
    }
  ](name='Channels', description='The channels.'),
  maxResults?: int32(name='MaxResults', description='The number of entries returned per page.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='caeba0bbb2be03f84eb48b699f0a4883'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListMediaLiveChannelsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaLiveChannelsResponseBody(name='body'),
}

/**
 * @summary Queries MediaLive channels.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request ListMediaLiveChannelsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListMediaLiveChannelsResponse
 */
async function listMediaLiveChannelsWithOptions(request: ListMediaLiveChannelsRequest, runtime: $RuntimeOptions): ListMediaLiveChannelsResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.keyword)) {
    body['Keyword'] = request.keyword;
  }
  if (!$isNull(request.maxResults)) {
    body['MaxResults'] = request.maxResults;
  }
  if (!$isNull(request.nextToken)) {
    body['NextToken'] = request.nextToken;
  }
  if (!$isNull(request.skip)) {
    body['Skip'] = request.skip;
  }
  if (!$isNull(request.sortOrder)) {
    body['SortOrder'] = request.sortOrder;
  }
  if (!$isNull(request.states)) {
    body['States'] = request.states;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListMediaLiveChannels',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries MediaLive channels.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request ListMediaLiveChannelsRequest
 * @return ListMediaLiveChannelsResponse
 */
async function listMediaLiveChannels(request: ListMediaLiveChannelsRequest): ListMediaLiveChannelsResponse {
  var runtime = new $RuntimeOptions{};
  return listMediaLiveChannelsWithOptions(request, runtime);
}

model ListMediaLiveInputSecurityGroupsRequest {
  keyword?: string(name='Keyword', description='The keyword of the query. You can perform a fuzzy search on security group ID or name.', example='123'),
  maxResults?: int32(name='MaxResults', description='The number of entries per page. Valid values: 1 to 100. Default value: If you do not specify this parameter or if you set a value smaller than 10, the default value is 10. If you set a value greater than 100, the default value is 100.', example='10'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='caeba0bbb2be03f84eb48b699f0a4883'),
  skip?: int32(name='Skip', description='The number of entries to be skipped in the query. If the number of entries you attempt to skip exceeds the number of entries that meet the condition, an empty list is returned.', example='20'),
  sortOrder?: string(name='SortOrder', description='The sorting order of the security groups by creation time. Default value: asc. Valid values: desc and asc. asc indicates the ascending order, and desc indicates the descending order.', example='desc'),
}

model ListMediaLiveInputSecurityGroupsResponseBody = {
  maxResults?: int32(name='MaxResults', description='The number of entries returned per page.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='caeba0bbb2be03f84eb48b699f0a4883'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='123e4567-e89b-12d3-a456-426614174000'),
  securityGroups?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the security group was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-12-03T06:56:42Z'),
      inputIds?: [ string ](name='InputIds', description='The IDs of the inputs associated with the security group.'),
      name?: string(name='Name', description='The security group name.', example='mysg'),
      securityGroupId?: string(name='SecurityGroupId', description='The ID of the security group.', example='SEGK5KA6KYKAWQQH'),
      whitelistRules?: [ string ](name='WhitelistRules', description='The security group rules.'),
    }
  ](name='SecurityGroups', description='The security groups.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListMediaLiveInputSecurityGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaLiveInputSecurityGroupsResponseBody(name='body'),
}

/**
 * @summary Queries the security groups in MediaLive.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request ListMediaLiveInputSecurityGroupsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListMediaLiveInputSecurityGroupsResponse
 */
async function listMediaLiveInputSecurityGroupsWithOptions(request: ListMediaLiveInputSecurityGroupsRequest, runtime: $RuntimeOptions): ListMediaLiveInputSecurityGroupsResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.keyword)) {
    body['Keyword'] = request.keyword;
  }
  if (!$isNull(request.maxResults)) {
    body['MaxResults'] = request.maxResults;
  }
  if (!$isNull(request.nextToken)) {
    body['NextToken'] = request.nextToken;
  }
  if (!$isNull(request.skip)) {
    body['Skip'] = request.skip;
  }
  if (!$isNull(request.sortOrder)) {
    body['SortOrder'] = request.sortOrder;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListMediaLiveInputSecurityGroups',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the security groups in MediaLive.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request ListMediaLiveInputSecurityGroupsRequest
 * @return ListMediaLiveInputSecurityGroupsResponse
 */
async function listMediaLiveInputSecurityGroups(request: ListMediaLiveInputSecurityGroupsRequest): ListMediaLiveInputSecurityGroupsResponse {
  var runtime = new $RuntimeOptions{};
  return listMediaLiveInputSecurityGroupsWithOptions(request, runtime);
}

model ListMediaLiveInputsRequest {
  keyword?: string(name='Keyword', description='The keyword of the query. You can perform a fuzzy search on input ID or name.', example='123'),
  maxResults?: int32(name='MaxResults', description='The number of entries per page. Valid values: 1 to 100. Default value: If you do not specify this parameter or if you set a value smaller than 10, the default value is 10. If you set a value greater than 100, the default value is 100.', example='10'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='caeba0bbb2be03f84eb48b699f0a4883'),
  skip?: int32(name='Skip', description='The number of entries to be skipped in the query. If the number of entries you attempt to skip exceeds the number of entries that meet the condition, an empty list is returned.', example='20'),
  sortOrder?: string(name='SortOrder', description='The sorting order of the inputs by creation time. Default value: asc. Valid values: desc and asc. asc indicates the ascending order, and desc indicates the descending order.', example='desc'),
  types?: string(name='Types', description='The type of inputs you want to query. You can separate multiple input types with commas (,) in a JSON array.', example='["RTMP_PUSH","SRT_PULL"]'),
}

model ListMediaLiveInputsResponseBody = {
  inputs?: [ 
    {
      channelIds?: [ string ](name='ChannelIds', description='The IDs of the channels associated with the input.'),
      createTime?: string(name='CreateTime', description='The time when the input was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-12-03T06:56:42Z'),
      inputId?: string(name='InputId', description='The ID of the input.', example='SEGK5KA6KYKAWQQH'),
      inputInfos?: [ 
        {
          destHost?: string(name='DestHost', description='The endpoint that the stream is pushed to. This parameter is returned for PUSH inputs.', example='rtmp://domain/app/stream'),
          flowId?: string(name='FlowId'),
          flowOutputName?: string(name='FlowOutputName'),
          monitorUrl?: string(name='MonitorUrl', description='The URL for input monitoring.', example='rtmp://domain/app/stream_for_monitor'),
          sourceUrl?: string(name='SourceUrl', description='The source URL where the stream is pulled from. This parameter is returned for PULL inputs.', example='rtmp://domain/app/stream'),
          streamName?: string(name='StreamName', description='The name of the pushed stream. This parameter is returned for PUSH inputs.', example='mystream'),
        }
      ](name='InputInfos', description='The input configurations.'),
      name?: string(name='Name', description='The name of the input.', example='myinput'),
      securityGroupIds?: [ string ](name='SecurityGroupIds', description='The IDs of the security groups associated with the input.'),
      type?: string(name='Type', description='The input type.', example='RTMP_PUSH'),
    }
  ](name='Inputs', description='The inputs.'),
  maxResults?: int32(name='MaxResults', description='The number of entries returned per page.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='caeba0bbb2be03f84eb48b699f0a4883'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='200'),
}

model ListMediaLiveInputsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaLiveInputsResponseBody(name='body'),
}

/**
 * @summary Queries MediaLive inputs.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request ListMediaLiveInputsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListMediaLiveInputsResponse
 */
async function listMediaLiveInputsWithOptions(request: ListMediaLiveInputsRequest, runtime: $RuntimeOptions): ListMediaLiveInputsResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.keyword)) {
    body['Keyword'] = request.keyword;
  }
  if (!$isNull(request.maxResults)) {
    body['MaxResults'] = request.maxResults;
  }
  if (!$isNull(request.nextToken)) {
    body['NextToken'] = request.nextToken;
  }
  if (!$isNull(request.skip)) {
    body['Skip'] = request.skip;
  }
  if (!$isNull(request.sortOrder)) {
    body['SortOrder'] = request.sortOrder;
  }
  if (!$isNull(request.types)) {
    body['Types'] = request.types;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListMediaLiveInputs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries MediaLive inputs.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request ListMediaLiveInputsRequest
 * @return ListMediaLiveInputsResponse
 */
async function listMediaLiveInputs(request: ListMediaLiveInputsRequest): ListMediaLiveInputsResponse {
  var runtime = new $RuntimeOptions{};
  return listMediaLiveInputsWithOptions(request, runtime);
}

model ListMediaMarksRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The mark ID. You can specify multiple IDs separated with commas (,). This parameter is discontinued.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
}

model ListMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  mediaMarks?: string(name='MediaMarks', description='The marks of the media asset, in the JSONArray format.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaMarksResponseBody(name='body'),
}

/**
 * @summary Queries a list of marks of a media asset.
 *
 * @param request ListMediaMarksRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListMediaMarksResponse
 */
async function listMediaMarksWithOptions(request: ListMediaMarksRequest, runtime: $RuntimeOptions): ListMediaMarksResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.mediaMarkIds)) {
    query['MediaMarkIds'] = request.mediaMarkIds;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListMediaMarks',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of marks of a media asset.
 *
 * @param request ListMediaMarksRequest
 * @return ListMediaMarksResponse
 */
async function listMediaMarks(request: ListMediaMarksRequest): ListMediaMarksResponse {
  var runtime = new $RuntimeOptions{};
  return listMediaMarksWithOptions(request, runtime);
}

model ListMediaProducingJobsRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. The maximum time range between EndTime and StartTime cannot exceed 30 days. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-02-02T23:59:59Z'),
  jobType?: string(name='JobType', description='The job type.

Valid values:

*   LiveEditingJob: live editing job.
*   EditingJob: regular template-based editing job
*   VETemplateJob: advanced template-based editing job.', example='EditingJob'),
  keyword?: string(name='Keyword', description='The search keyword. For example, you can use a job ID as the keyword to search for jobs.', example='****20b48fb04483915d4f2cd8ac****'),
  masterJobId?: string(name='MasterJobId', description='The ID of the quick video production job. If this parameter is specified, the subjobs of the quick video production job are queried.', example='******8750b54e3c976a47da6f******'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.

Default value: 10. Valid values: 1 to 100.', example='100'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='******927cfb53d05b96c1bfe1******'),
  sortBy?: string(name='SortBy', description='The sorting parameter. By default, the query results are sorted by creation time in descending order.

Valid values:

*   CreationTime:Asc: sorted by creation time in ascending order.
*   CreationTime:Desc: sorted by creation time in descending order.', example='CreationTime:Desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2017-01-11T12:00:00Z'),
  status?: string(name='Status', description='The job state.

Valid values:

*   Init: The job is initialized.
*   Failed: The job failed.
*   Success: The job is successful.
*   Processing: The job is in progress.', example='Success'),
}

model ListMediaProducingJobsResponseBody = {
  maxResults?: string(name='MaxResults', description='The maximum number of entries returned.

Default value: 10. Valid values: 1 to 100.', example='100'),
  mediaProducingJobList?: [ 
    {
      clipsParam?: string(name='ClipsParam', description='The template material parameters.', example='{"Text1":"text","Text0":"text","Media1":"mediaId","Media0":"mediaId"}'),
      code?: string(name='Code', description='The response code.', example='Success'),
      completeTime?: string(name='CompleteTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-03-21T16:40:30Z'),
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-03-21T16:40:00Z'),
      duration?: float(name='Duration', description='The duration of the output file. Unit: seconds.', example='15.5'),
      jobId?: string(name='JobId', description='The ID of the online editing job.', example='******8750b54e3c976a47da6f******'),
      mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='0ce4ea70f52471edab61f7e7d6786302'),
      mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://your-bucket.oss-cn-shanghai.aliyuncs.com/your-video.mp4'),
      message?: string(name='Message', description='The returned message. Note: Pay attention to this parameter if the job failed.', example='The resource operated InputFile is bad'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-03-21T16:41:00Z'),
      projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='******faa3b542f5a6135217e3******'),
      status?: string(name='Status', description='The job state.', example='Sucess'),
      templateId?: string(name='TemplateId', description='The ID of the online editing template.', example='cb786a39c5d44cecb23d8c864facffc1'),
      userData?: string(name='UserData', description='The user-defined data in the JSON format.', example='{"key":"value"}'),
    }
  ](name='MediaProducingJobList', description='The queried media editing and production jobs.'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListMediaProducingJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMediaProducingJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of media editing and production jobs that meet the specified conditions. You can query the jobs based on the job state and type.
 *
 * @param request ListMediaProducingJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListMediaProducingJobsResponse
 */
async function listMediaProducingJobsWithOptions(request: ListMediaProducingJobsRequest, runtime: $RuntimeOptions): ListMediaProducingJobsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!$isNull(request.jobType)) {
    query['JobType'] = request.jobType;
  }
  if (!$isNull(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!$isNull(request.masterJobId)) {
    query['MasterJobId'] = request.masterJobId;
  }
  if (!$isNull(request.maxResults)) {
    query['MaxResults'] = request.maxResults;
  }
  if (!$isNull(request.nextToken)) {
    query['NextToken'] = request.nextToken;
  }
  if (!$isNull(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListMediaProducingJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of media editing and production jobs that meet the specified conditions. You can query the jobs based on the job state and type.
 *
 * @param request ListMediaProducingJobsRequest
 * @return ListMediaProducingJobsResponse
 */
async function listMediaProducingJobs(request: ListMediaProducingJobsRequest): ListMediaProducingJobsResponse {
  var runtime = new $RuntimeOptions{};
  return listMediaProducingJobsWithOptions(request, runtime);
}

model ListPackageJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-15T00:00:00Z'),
  jobId?: string(name='JobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb11cbe'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='ab4802364a2e49208c99efab82dfa8e8'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

*   CreateTimeDesc: sorts the jobs by creation time in descending order.
*   CreateTimeAsc: sorts the jobs by creation time in ascending order.', example='CreateTimeDesc'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 0 to 100. Default value: 20.', example='10'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-01T00:00:00Z'),
  status?: string(name='Status', description='The state of the job.

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
}

model ListPackageJobsResponseBody = {
  packageJobList?: {
    nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. The token of the next page is returned after you call this operation for the first time.', example='019daf5780f74831b0e1a767c9f1c178'),
    packageJobs?: [ 
      {
        code?: string(name='Code', description='The error code returned if the job fails.', example='InvalidParameter'),
        createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T14:00:32Z'),
        finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T15:00:32Z'),
        inputs?: [ 
          {
            input?: {
              media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
              type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
            }(name='Input', description='The information about the input stream file.'),
          }
        ](name='Inputs', description='The input of the job.'),
        jobId?: string(name='JobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb11cbe'),
        message?: string(name='Message', description='The error message that is returned.', example='Resource content bad.'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T15:00:32Z'),
        name?: string(name='Name', description='The name of the job.', example='job-name'),
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output of the job.'),
        pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='5b40833e4c3e4d4e95a866abb9a42510'),
        priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority. Default value: 6.', example='6'),
        status?: string(name='Status', description='The state of the job.', example='Success'),
        submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-07-07T14:00:32Z'),
        triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
        userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}'),
      }
    ](name='PackageJobs', description='The list of packaging jobs.'),
  }(name='PackageJobList', description='The list of packaging jobs.'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model ListPackageJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPackageJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of packaging jobs.
 *
 * @param request ListPackageJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListPackageJobsResponse
 */
async function listPackageJobsWithOptions(request: ListPackageJobsRequest, runtime: $RuntimeOptions): ListPackageJobsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endOfCreateTime)) {
    query['EndOfCreateTime'] = request.endOfCreateTime;
  }
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!$isNull(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.startOfCreateTime)) {
    query['StartOfCreateTime'] = request.startOfCreateTime;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListPackageJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of packaging jobs.
 *
 * @param request ListPackageJobsRequest
 * @return ListPackageJobsResponse
 */
async function listPackageJobs(request: ListPackageJobsRequest): ListPackageJobsResponse {
  var runtime = new $RuntimeOptions{};
  return listPackageJobsWithOptions(request, runtime);
}

model ListPipelinesRequest {
  speed?: string(name='Speed', description='The type of the MPS queue.

Valid values:

*   Boost: MPS queue with transcoding speed boosted.
*   Standard: standard MPS queue.
*   NarrowBandHDV2: MPS queue that supports Narrowband HD 2.0.', example='Standard'),
}

model ListPipelinesResponseBody = {
  pipelineList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the template was created.', example='2022-07-12T16:17:54Z'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2022-07-12T16:17:54Z'),
      name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.', example='****20b48fb04483915d4f2cd8ac****'),
      priority?: int32(name='Priority', description='The priority of the MPS queue.', example='6'),
      speed?: string(name='Speed', description='The type of the MPS queue.', example='Standard'),
      status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Active'),
    }
  ](name='PipelineList', description='The queried MPS queues.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListPipelinesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPipelinesResponseBody(name='body'),
}

/**
 * @summary Queries a list of ApsaraVideo Media Processing (MPS) queues.
 *
 * @param request ListPipelinesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListPipelinesResponse
 */
async function listPipelinesWithOptions(request: ListPipelinesRequest, runtime: $RuntimeOptions): ListPipelinesResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.speed)) {
    query['Speed'] = request.speed;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListPipelines',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of ApsaraVideo Media Processing (MPS) queues.
 *
 * @param request ListPipelinesRequest
 * @return ListPipelinesResponse
 */
async function listPipelines(request: ListPipelinesRequest): ListPipelinesResponse {
  var runtime = new $RuntimeOptions{};
  return listPipelinesWithOptions(request, runtime);
}

model ListProgramsRequest {
  channelName?: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel'),
  pageNo?: string(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10'),
  programName?: string(name='ProgramName', description='The name of the program.', example='program1'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values:

*   asc: ascending order.
*   desc: descending order.', example='desc'),
}

model ListProgramsResponseBody = {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10'),
  programs?: [
    ChannelAssemblyProgram
  ](name='Programs', description='The programs.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  totalCount?: int32(name='TotalCount', description='The total number of programs returned.', example='100'),
}

model ListProgramsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListProgramsResponseBody(name='body'),
}

/**
 * @summary Lists programs.
 *
 * @param request ListProgramsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListProgramsResponse
 */
async function listProgramsWithOptions(request: ListProgramsRequest, runtime: $RuntimeOptions): ListProgramsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.programName)) {
    query['ProgramName'] = request.programName;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListPrograms',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Lists programs.
 *
 * @param request ListProgramsRequest
 * @return ListProgramsResponse
 */
async function listPrograms(request: ListProgramsRequest): ListProgramsResponse {
  var runtime = new $RuntimeOptions{};
  return listProgramsWithOptions(request, runtime);
}

model ListPublicMediaBasicInfosRequest {
  businessType?: string(name='BusinessType', description='The business type of the media asset. Valid values:

*   sticker
*   bgm
*   bgi', example='sticker'),
  includeFileBasicInfo?: boolean(name='IncludeFileBasicInfo', description='Specifies whether to return the basic information of the media asset.', example='true'),
  maxResults?: int32(name='MaxResults', description='The maximum number of entries to return.

Maximum value: 100. Default value: 10.', example='5'),
  mediaTagId?: string(name='MediaTagId', description='The media tag. All media assets that contain the specified media tag are returned. Valid values:

*   Sticker tags:

    *   sticker-atmosphere
    *   sticker-bubble
    *   sticker-cute
    *   sticker-daily
    *   sticker-expression
    *   sticker-gif

*   Background music (BGM) tags:

    *   bgm-romantic
    *   bgm-cuisine
    *   bgm-chinese-style
    *   bgm-upbeat
    *   bgm-dynamic
    *   bgm-relaxing
    *   bgm-quirky
    *   bgm-beauty

*   Background image (BGI) tags:

    *   bgi-grad
    *   bgi-solid
    *   bgi-pic', example='ticker-atmosphere'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='pSa1SQ0wCe5pzVrQ6mWZEw=='),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10'),
}

model ListPublicMediaBasicInfosResponseBody = {
  maxResults?: int32(name='MaxResults', description='The maximum number of entries returned.', example='2'),
  mediaInfos?: [ 
    {
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate.', example='270112.12'),
            duration?: string(name='Duration', description='The duration.', example='10.040000'),
            fileName?: string(name='FileName', description='The file name.', example='example.mp4'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='338990717'),
            fileStatus?: string(name='FileStatus', description='The file status.', example='Normal'),
            fileType?: string(name='FileType', description='The file type.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
            formatName?: string(name='FormatName', description='The container format.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height.', example='1080'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width.', example='1920'),
          }(name='FileBasicInfo', description='The basic information of the file, such as the duration and size.'),
        }
      ](name='FileInfoList', description='The file information of the media asset.'),
      mediaBasicInfo?: {
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='general'),
        category?: string(name='Category', description='The category of the media asset.', example='video'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2021-01-08T16:52:04Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2021-01-08T16:52:04Z'),
        description?: string(name='Description', description='The description of the media asset.', example='description'),
        inputURL?: string(name='InputURL', description='The URL of the media asset in another service.', example='https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='sticker-daily'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was last modified.', example='2021-01-08T16:52:04Z'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='null'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        status?: string(name='Status', description='The status of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information of the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****019b82e24b37a1c2958dec38****'),
    }
  ](name='MediaInfos', description='The media assets that meet the specified conditions.'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='8EqYpQbZ6Eh7+Zz8DxVYoQ=='),
  requestId?: string(name='RequestId', description='The request ID.', example='******B7-7F87-4792-BFE9-63CD21******'),
  totalCount?: long(name='TotalCount', description='The total number of media assets that meet the specified conditions.', example='2'),
}

model ListPublicMediaBasicInfosResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPublicMediaBasicInfosResponseBody(name='body'),
}

/**
 * @summary Queries a list of media assets in the public media library that meet the specified conditions. A maximum of 100 media assets can be returned.
 *
 * @param request ListPublicMediaBasicInfosRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListPublicMediaBasicInfosResponse
 */
async function listPublicMediaBasicInfosWithOptions(request: ListPublicMediaBasicInfosRequest, runtime: $RuntimeOptions): ListPublicMediaBasicInfosResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.businessType)) {
    query['BusinessType'] = request.businessType;
  }
  if (!$isNull(request.includeFileBasicInfo)) {
    query['IncludeFileBasicInfo'] = request.includeFileBasicInfo;
  }
  if (!$isNull(request.maxResults)) {
    query['MaxResults'] = request.maxResults;
  }
  if (!$isNull(request.mediaTagId)) {
    query['MediaTagId'] = request.mediaTagId;
  }
  if (!$isNull(request.nextToken)) {
    query['NextToken'] = request.nextToken;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListPublicMediaBasicInfos',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'Anonymous',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of media assets in the public media library that meet the specified conditions. A maximum of 100 media assets can be returned.
 *
 * @param request ListPublicMediaBasicInfosRequest
 * @return ListPublicMediaBasicInfosResponse
 */
async function listPublicMediaBasicInfos(request: ListPublicMediaBasicInfosRequest): ListPublicMediaBasicInfosResponse {
  var runtime = new $RuntimeOptions{};
  return listPublicMediaBasicInfosWithOptions(request, runtime);
}

model ListSchedulesRequest {
  channelName?: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  windowDurationSeconds?: long(name='WindowDurationSeconds', description='The time window of the program schedule.

This parameter is required.', example='14400'),
}

model ListSchedulesResponseBody = {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10'),
  programs?: [
    ChannelAssemblyScheduleData
  ](name='Programs', description='The program schedule.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='5'),
}

model ListSchedulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSchedulesResponseBody(name='body'),
}

/**
 * @summary Lists the program schedule of a MediaWeaver channel.
 *
 * @param request ListSchedulesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSchedulesResponse
 */
async function listSchedulesWithOptions(request: ListSchedulesRequest, runtime: $RuntimeOptions): ListSchedulesResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.windowDurationSeconds)) {
    query['WindowDurationSeconds'] = request.windowDurationSeconds;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListSchedules',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Lists the program schedule of a MediaWeaver channel.
 *
 * @param request ListSchedulesRequest
 * @return ListSchedulesResponse
 */
async function listSchedules(request: ListSchedulesRequest): ListSchedulesResponse {
  var runtime = new $RuntimeOptions{};
  return listSchedulesWithOptions(request, runtime);
}

model ListSearchLibRequest {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10'),
}

model ListSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  searchLibInfoList?: [ 
    {
      indexInfo?: [ 
        {
          indexReadiness?: string(name='IndexReadiness'),
          indexStatus?: string(name='IndexStatus'),
          indexType?: string(name='IndexType'),
        }
      ](name='IndexInfo'),
      searchLibName?: string(name='SearchLibName', description='The search library.', example='faceSearchLib'),
      status?: string(name='Status', description='The status of the search library.

*   normal
*   deleting
*   deleteFail', example='normal'),
    }
  ](name='SearchLibInfoList', description='Information about search libraries.'),
  success?: string(name='Success', description='Indicates whether the request was successful.', example='true'),
  total?: long(name='Total', description='总数。', example='8'),
}

model ListSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSearchLibResponseBody(name='body'),
}

/**
 * @summary Queries the information about search libraries.
 *
 * @param request ListSearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSearchLibResponse
 */
async function listSearchLibWithOptions(request: ListSearchLibRequest, runtime: $RuntimeOptions): ListSearchLibResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListSearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about search libraries.
 *
 * @param request ListSearchLibRequest
 * @return ListSearchLibResponse
 */
async function listSearchLib(request: ListSearchLibRequest): ListSearchLibResponse {
  var runtime = new $RuntimeOptions{};
  return listSearchLibWithOptions(request, runtime);
}

model ListSmartJobsRequest {
  jobState?: string(name='JobState', description='The job state.

Valid values:

*   Finished: The job is complete.
*   Failed: The job failed.
*   Executing: The job is in progress.
*   Created: The job is created.', example='Finished'),
  jobType?: string(name='JobType', description='The job type.

Valid values:

*   ASR: automatic speech recognition(job) job.
*   DynamicChart: dynamic chart job.
*   VideoTranslation: video translation job.
*   TextToSpeech: intelligent audio production job.', example='ASR'),
  maxResults?: long(name='MaxResults', description='The maximum number of entries to return.

Default value: 10. Valid values: 1 to 100.', example='10'),
  nextToken?: string(name='NextToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****73f33c91-d59383e8280b****'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting parameter. By default, the query results are sorted by creation time in descending order.

Valid values:

*   CreationTime:Asc: sorted by creation time in ascending order.
*   CreationTime:Desc: sorted by creation time in descending order.', example='CreationTime:Desc'),
}

model ListSmartJobsResponseBody = {
  maxResults?: string(name='MaxResults', description='The maximum number of entries returned on a single page. The value is set to the maximum number of entries returned on each page except for the last page. Valid example: 10,10,5. Invalid example: 10,5,10.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='CBB6BC61D08'),
  requestId?: string(name='RequestId', description='The request ID.', example='****9262E3DA-07FA-4862-FCBB6BC61D08*****'),
  smartJobList?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2020-12-26T04:11:10Z'),
      description?: string(name='Description', description='The job description.', example='测试描述'),
      editingConfig?: string(name='EditingConfig', description='The editing configurations.', example='{"AudioConfig":{},"InputConfig":""}'),
      inputConfig?: {
        inputFile?: string(name='InputFile', description='The information about the input file.', example='oss://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
        keyword?: string(name='Keyword', description='The keyword information.', example='测试关键词'),
      }(name='InputConfig', description='The input configurations.'),
      jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
      jobState?: string(name='JobState', description='The job state.

Valid values:

*   Finished: The job is complete.
*   Failed: The job failed.
*   Executing: The job is in progress.
*   Created: The job is created.', example='Finished'),
      jobType?: string(name='JobType', description='The job type.

Valid values:

*   ASR: ASR job.
*   DynamicChart: dynamic chart job.
*   TextToSpeech: intelligent audio production job.', example='ASR'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2020-12-26T04:11:10Z'),
      outputConfig?: {
        bucket?: string(name='Bucket', description='The Object Storage Service (OSS) bucket.', example='test-bucket'),
        object?: string(name='Object', description='The OSS object.', example='test-object'),
      }(name='OutputConfig', description='The output configurations.'),
      title?: string(name='Title', description='The job title.', example='测试标题'),
      userData?: string(name='UserData', description='The user-defined data.', example='{"user":"data"}'),
      userId?: long(name='UserId', description='The user ID.', example='1084506228******'),
    }
  ](name='SmartJobList', description='The queried intelligent jobs.'),
  totalCount?: string(name='TotalCount', description='Optional. The total number of entries returned. By default, this parameter is not returned.', example='110'),
}

model ListSmartJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSmartJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of intelligent jobs based on specified parameters.
 *
 * @param request ListSmartJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSmartJobsResponse
 */
async function listSmartJobsWithOptions(request: ListSmartJobsRequest, runtime: $RuntimeOptions): ListSmartJobsResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListSmartJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of intelligent jobs based on specified parameters.
 *
 * @param request ListSmartJobsRequest
 * @return ListSmartJobsResponse
 */
async function listSmartJobs(request: ListSmartJobsRequest): ListSmartJobsResponse {
  var runtime = new $RuntimeOptions{};
  return listSmartJobsWithOptions(request, runtime);
}

model ListSmartSysAvatarModelsRequest {
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10'),
  sdkVersion?: string(name='SdkVersion'),
}

model ListSmartSysAvatarModelsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  smartSysAvatarModelList?: [ 
    {
      avatarId?: string(name='AvatarId', description='The ID of the digital human. The ID is required to submit a separate digital human rendering job or use the digital human image in an intelligent timeline.', example='yunqiao'),
      avatarName?: string(name='AvatarName', description='The name of the digital human.'),
      bitrate?: int32(name='Bitrate', description='The video bitrate.', example='4000'),
      coverUrl?: string(name='CoverUrl', description='The sample thumbnail URL of the digital human.', example='http://ice-pub-media.myalicdn.com/smart/avatarModel/coverDemo/yunqiao.mp4'),
      height?: int32(name='Height', description='The video height.', example='1920'),
      outputMask?: boolean(name='OutputMask', description='Indicates whether portrait mask rendering is supported.', example='false'),
      videoUrl?: string(name='VideoUrl', description='The sample video URL of the digital human.', example='http://ice-pub-media.myalicdn.com/smart/avatarModel/videoDemo/yunqiao.mp4'),
      width?: int32(name='Width', description='The video width.', example='1080'),
    }
  ](name='SmartSysAvatarModelList', description='The queried digital humans.'),
  totalCount?: int32(name='TotalCount', description='The total number of system digital human images returned.', example='4'),
}

model ListSmartSysAvatarModelsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSmartSysAvatarModelsResponseBody(name='body'),
}

/**
 * @summary Queries a list of system digital humans. This operation supports paged queries.
 *
 * @param request ListSmartSysAvatarModelsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSmartSysAvatarModelsResponse
 */
async function listSmartSysAvatarModelsWithOptions(request: ListSmartSysAvatarModelsRequest, runtime: $RuntimeOptions): ListSmartSysAvatarModelsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sdkVersion)) {
    query['SdkVersion'] = request.sdkVersion;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListSmartSysAvatarModels',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of system digital humans. This operation supports paged queries.
 *
 * @param request ListSmartSysAvatarModelsRequest
 * @return ListSmartSysAvatarModelsResponse
 */
async function listSmartSysAvatarModels(request: ListSmartSysAvatarModelsRequest): ListSmartSysAvatarModelsResponse {
  var runtime = new $RuntimeOptions{};
  return listSmartSysAvatarModelsWithOptions(request, runtime);
}

model ListSmartVoiceGroupsRequest {
  voiceType?: string(name='VoiceType'),
}

model ListSmartVoiceGroupsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='627B30EB-1D0A-5C6D-8467-431626E0FA10'),
  voiceGroups?: [ 
    {
      type?: string(name='Type', description='The name of the speaker group.'),
      voiceList?: [ 
        {
          desc?: string(name='Desc', description='The speaker description.'),
          name?: string(name='Name', description='The speaker name.'),
          remark?: string(name='Remark', description='The remarks of the speaker.'),
          supportSampleRate?: string(name='SupportSampleRate'),
          tag?: string(name='Tag', description='The tag of the speaker type.'),
          voice?: string(name='Voice', description='The speaker ID.', example='zhitian'),
          voiceType?: string(name='VoiceType', description='The speaker type.

Valid values:

*   Male
*   Female
*   Boy
*   Girl', example='Female'),
          voiceUrl?: string(name='VoiceUrl', description='The URL of the sample audio file.', example='https://***.com/zhiqing.mp3'),
        }
      ](name='VoiceList', description='The speakers.'),
    }
  ](name='VoiceGroups', description='The queried speaker groups.'),
}

model ListSmartVoiceGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSmartVoiceGroupsResponseBody(name='body'),
}

/**
 * @summary Queries a list of speaker groups, including the name, gender, and sample audio of each speaker. The list is grouped by scenario.
 *
 * @param request ListSmartVoiceGroupsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSmartVoiceGroupsResponse
 */
async function listSmartVoiceGroupsWithOptions(request: ListSmartVoiceGroupsRequest, runtime: $RuntimeOptions): ListSmartVoiceGroupsResponse {
  request.validate();
  var query = OpenApiUtil.query(request.toMap());
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListSmartVoiceGroups',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of speaker groups, including the name, gender, and sample audio of each speaker. The list is grouped by scenario.
 *
 * @param request ListSmartVoiceGroupsRequest
 * @return ListSmartVoiceGroupsResponse
 */
async function listSmartVoiceGroups(request: ListSmartVoiceGroupsRequest): ListSmartVoiceGroupsResponse {
  var runtime = new $RuntimeOptions{};
  return listSmartVoiceGroupsWithOptions(request, runtime);
}

model ListSnapshotJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created.', example='2022-07-14T00:00:00Z'),
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****20b48fb04483915d4f2cd8ac****'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results.

1.  CreateTimeDesc
2.  CreateTimeAsc

Valid values:

*   CreateTimeDesc: sorts the jobs by creation time in descending order
*   CreateTimeAsc: sorts the jobs by creation time in ascending order.', example='CreateTimeDesc'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Maximum value: 100.', example='20'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created.', example='2022-07-12T00:00:00Z'),
  status?: string(name='Status', description='The state of the job.

Valid values:

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
}

model ListSnapshotJobsResponseBody = {
  jobs?: [ 
    {
      async?: boolean(name='Async', description='Indicates whether the snapshots were captured in asynchronous mode.', example='true'),
      count?: int32(name='Count', description='The number of snapshots.', example='10'),
      createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-12T16:17:54Z'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-07-12T16:30:54Z'),
      input?: {
        media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats: 1. OSS://bucket/object 2. http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.', example='oss://bucket/object.mp4'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.', example='OSS'),
      }(name='Input', description='The input of the job.'),
      jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the job was last modified.', example='2022-07-12T16:30:54Z'),
      name?: string(name='Name', description='The name of the job.', example='SampleJob'),
      output?: {
        media?: string(name='Media', description='The output file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  OSS://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS. If multiple static snapshots were captured, the object must contain the "{Count}" placeholder. In the case of a sprite, the object must contain the "{TileCount}" placeholder. The suffix of the WebVTT snapshot objects must be ".vtt".', example='http://test-bucket.oss-cn-shanghai.aliyuncs.com/output-{Count}.jpg'),
        type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.', example='OSS'),
      }(name='Output', description='The output of the job.'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****20b48fb04483915d4f2cd8ac****'),
      status?: string(name='Status', description='The state of the job.

*   **Success**: The job is successful.
*   **Fail**: The job failed.
*   **Init**: The job is submitted.', example='Success'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-07-12T16:17:54Z'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
      triggerSource?: string(name='TriggerSource', description='The request trigger source.

Valid values:

*   Console
*   Workflow
*   API', example='API'),
      type?: string(name='Type', description='The type of the job.

Valid values:

*   WebVtt
*   Sprite
*   Normal', example='Sprite'),
    }
  ](name='Jobs', description='The list of jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model ListSnapshotJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSnapshotJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of snapshot jobs.
 *
 * @param request ListSnapshotJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSnapshotJobsResponse
 */
async function listSnapshotJobsWithOptions(request: ListSnapshotJobsRequest, runtime: $RuntimeOptions): ListSnapshotJobsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endOfCreateTime)) {
    query['EndOfCreateTime'] = request.endOfCreateTime;
  }
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!$isNull(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.startOfCreateTime)) {
    query['StartOfCreateTime'] = request.startOfCreateTime;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListSnapshotJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of snapshot jobs.
 *
 * @param request ListSnapshotJobsRequest
 * @return ListSnapshotJobsResponse
 */
async function listSnapshotJobs(request: ListSnapshotJobsRequest): ListSnapshotJobsResponse {
  var runtime = new $RuntimeOptions{};
  return listSnapshotJobsWithOptions(request, runtime);
}

model ListSourceLocationsRequest {
  filterState?: boolean(name='FilterState', description='Specifies whether to ignore source locations marked as deleted. A value of true means ignoring source locations marked as deleted.', example='true'),
  pageNo?: int32(name='PageNo', description='*   The page number.
*   Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order.', example='desc'),
  sortByModifiedTime?: string(name='SortByModifiedTime', description='The sorting order of the source locations based on the time when they were last modified.', example='desc'),
  sourceLocationName?: string(name='SourceLocationName', description='The name of the source location.', example='MySourceLocation'),
}

model ListSourceLocationsResponseBody = {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='10'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  sourceLocationList?: [
    ChannelAssemblySourceLocation
  ](name='SourceLocationList', description='The source locations.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListSourceLocationsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSourceLocationsResponseBody(name='body'),
}

/**
 * @summary Lists source locations.
 *
 * @param request ListSourceLocationsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSourceLocationsResponse
 */
async function listSourceLocationsWithOptions(request: ListSourceLocationsRequest, runtime: $RuntimeOptions): ListSourceLocationsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.filterState)) {
    query['FilterState'] = request.filterState;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.sortByModifiedTime)) {
    query['SortByModifiedTime'] = request.sortByModifiedTime;
  }
  if (!$isNull(request.sourceLocationName)) {
    query['SourceLocationName'] = request.sourceLocationName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListSourceLocations',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Lists source locations.
 *
 * @param request ListSourceLocationsRequest
 * @return ListSourceLocationsResponse
 */
async function listSourceLocations(request: ListSourceLocationsRequest): ListSourceLocationsResponse {
  var runtime = new $RuntimeOptions{};
  return listSourceLocationsWithOptions(request, runtime);
}

model ListSourcesRequest {
  filterState?: boolean(name='FilterState', description='Specifies whether to ignore sources marked as deleted.', example='true'),
  pageNo?: string(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting order. By default, the query results are sorted by creation time in descending order. Valid values: asc and desc.', example='asc'),
  sortByModifiedTime?: string(name='SortByModifiedTime', description='The sorting order by modification time. Valid values: asc and desc.', example='desc'),
  sourceLocationName?: string(name='SourceLocationName', description='The name of the source location.', example='MySourceLocation'),
  sourceName?: string(name='SourceName', description='The name of the source.', example='MyVodSource'),
  sourceType?: string(name='SourceType', description='The source type. Valid values: vodSource and liveSource.', example='vodSource'),
}

model ListSourcesResponseBody = {
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='20'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  sourceList?: [
    ChannelAssemblySource
  ](name='SourceList', description='The sources.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListSourcesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSourcesResponseBody(name='body'),
}

/**
 * @summary Lists sources in MediaWeaver.
 *
 * @param request ListSourcesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSourcesResponse
 */
async function listSourcesWithOptions(request: ListSourcesRequest, runtime: $RuntimeOptions): ListSourcesResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.filterState)) {
    query['FilterState'] = request.filterState;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.sortByModifiedTime)) {
    query['SortByModifiedTime'] = request.sortByModifiedTime;
  }
  if (!$isNull(request.sourceLocationName)) {
    query['SourceLocationName'] = request.sourceLocationName;
  }
  if (!$isNull(request.sourceName)) {
    query['SourceName'] = request.sourceName;
  }
  if (!$isNull(request.sourceType)) {
    query['SourceType'] = request.sourceType;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListSources',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Lists sources in MediaWeaver.
 *
 * @param request ListSourcesRequest
 * @return ListSourcesResponse
 */
async function listSources(request: ListSourcesRequest): ListSourcesResponse {
  var runtime = new $RuntimeOptions{};
  return listSourcesWithOptions(request, runtime);
}

model ListSystemTemplatesRequest {
  name?: string(name='Name', description='The template name.', example='SampleTemplate'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20 Valid values: 1 to 100.', example='20'),
  status?: string(name='Status', description='The template state. Valid values: Normal, Invisible, and All.', example='Normal'),
  subtype?: string(name='Subtype', description='The subtype ID of the template.', example='1'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
  type?: string(name='Type', description='The template type. Separate multiple types with commas (,).

This parameter is required.', example='1,2'),
}

model ListSystemTemplatesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  systemTemplateList?: [ 
    {
      status?: string(name='Status', description='The template state.', example='Normal'),
      subtype?: int32(name='Subtype', description='The subtype ID of the template.', example='1'),
      subtypeName?: string(name='SubtypeName', description='The subtype name of the template.', example='Remux'),
      templateConfig?: string(name='TemplateConfig', description='The template parameters.', example='{"Container":{"Format":"flv"},"Video":{},"Audio":{}}'),
      templateId?: string(name='TemplateId', description='The template ID.', example='S00000001-000000'),
      templateName?: string(name='TemplateName', description='The template name.', example='FLV-COPY'),
      type?: int32(name='Type', description='The type ID of the template.', example='1'),
      typeName?: string(name='TypeName', description='The type name of the template.', example='TranscodeTemplate'),
    }
  ](name='SystemTemplateList', description='The queried templates.'),
  total?: int32(name='Total', description='The total number of templates.', example='20'),
}

model ListSystemTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSystemTemplatesResponseBody(name='body'),
}

/**
 * @summary Queries a list of system templates.
 *
 * @description Template types:
 * 1.  1: transcoding template.
 * 2.  2: snapshot template.
 * 3.  3: animated image template.
 * 4.  4\\. image watermark template.
 * 5.  5: text watermark template.
 * 6.  6: subtitle template.
 * 7.  7: AI-assisted content moderation template.
 * 8.  8: AI-assisted intelligent thumbnail template.
 * 9.  9: AI-assisted intelligent erasure template.
 * Subtypes of transcoding templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (AudioTranscode): audio transcoding template.
 * 3.  3 (Remux): container format conversion template.
 * 4.  4 (NarrowBandV1): Narrowband HD 1.0 template.
 * 5.  5 (NarrowBandV2): Narrowband HD 2.0 template.
 * Subtypes of snapshot templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (Sprite): sprite template.
 * 3.  3 (WebVtt): WebVTT template.
 * Subtypes of AI-assisted content moderation templates:
 * 1.  1 (Video): video moderation template.
 * 2.  2 (Audio): audio moderation template.
 * 3.  3 (Image): image moderation template.
 * Subtypes of AI-assisted intelligent erasure templates:
 * 1.  1 (VideoDelogo): logo erasure template.
 * 2.  2 (VideoDetext): subtitle erasure template.
 *
 * @param request ListSystemTemplatesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListSystemTemplatesResponse
 */
async function listSystemTemplatesWithOptions(request: ListSystemTemplatesRequest, runtime: $RuntimeOptions): ListSystemTemplatesResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  if (!$isNull(request.subtype)) {
    query['Subtype'] = request.subtype;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListSystemTemplates',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of system templates.
 *
 * @description Template types:
 * 1.  1: transcoding template.
 * 2.  2: snapshot template.
 * 3.  3: animated image template.
 * 4.  4\\. image watermark template.
 * 5.  5: text watermark template.
 * 6.  6: subtitle template.
 * 7.  7: AI-assisted content moderation template.
 * 8.  8: AI-assisted intelligent thumbnail template.
 * 9.  9: AI-assisted intelligent erasure template.
 * Subtypes of transcoding templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (AudioTranscode): audio transcoding template.
 * 3.  3 (Remux): container format conversion template.
 * 4.  4 (NarrowBandV1): Narrowband HD 1.0 template.
 * 5.  5 (NarrowBandV2): Narrowband HD 2.0 template.
 * Subtypes of snapshot templates:
 * 1.  1 (Normal): regular template.
 * 2.  2 (Sprite): sprite template.
 * 3.  3 (WebVtt): WebVTT template.
 * Subtypes of AI-assisted content moderation templates:
 * 1.  1 (Video): video moderation template.
 * 2.  2 (Audio): audio moderation template.
 * 3.  3 (Image): image moderation template.
 * Subtypes of AI-assisted intelligent erasure templates:
 * 1.  1 (VideoDelogo): logo erasure template.
 * 2.  2 (VideoDetext): subtitle erasure template.
 *
 * @param request ListSystemTemplatesRequest
 * @return ListSystemTemplatesResponse
 */
async function listSystemTemplates(request: ListSystemTemplatesRequest): ListSystemTemplatesResponse {
  var runtime = new $RuntimeOptions{};
  return listSystemTemplatesWithOptions(request, runtime);
}

model ListTemplatesRequest {
  createSource?: string(name='CreateSource', description='The source from which the template was created.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
  keyword?: string(name='Keyword', description='The search keyword. You can use the template ID or title as the keyword to search for templates.', example='****20b48fb04483915d4f2cd8ac****'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 20. Valid values: 1 to 100.', example='20'),
  sortType?: string(name='SortType', description='The sorting parameter. By default, the query results are sorted by creation time in descending order.

Valid values:

*   CreationTime:Asc: sorted by creation time in ascending order.
*   CreationTime:Desc: sorted by creation time in descending order.', example='CreationTime:Desc'),
  status?: string(name='Status', description='The template state.

Valid values:

*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.
*   Available: The template is available.
*   Uploading: The video is being uploaded.
*   Created: The template is created but not ready for use.
*   Processing: The advanced template is being processed.', example='Available'),
  type?: string(name='Type', description='The template type.

Valid values:

*   Timeline
*   VETemplate', example='Timeline'),
}

model ListTemplatesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  templates?: [ 
    {
      clipsParam?: string(name='ClipsParam', description='The clip parameters.', example='{"Media1":"mediaId","Text1":"text"}'),
      config?: string(name='Config', description='The template configurations.', example='参考Timeline模板配置详解'),
      coverURL?: string(name='CoverURL', description='The thumbnail URL.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
      createSource?: string(name='CreateSource', description='The source from which the template was created.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
      creationTime?: string(name='CreationTime', description='The time when the template was created.', example='2020-12-26T04:11:10Z'),
      modifiedSource?: string(name='ModifiedSource', description='The source from which the template was modified.

Valid values:

*   AliyunConsole
*   WebSDK
*   OpenAPI', example='OpenAPI'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the template was last modified.', example='2020-12-26T04:11:10Z'),
      name?: string(name='Name', description='The template name.', example='视频添加水印模板'),
      previewMedia?: string(name='PreviewMedia', description='The preview media asset.', example='****20b48fb04483915d4f2cd8ac****'),
      previewMediaStatus?: string(name='PreviewMediaStatus', description='The state of the preview media asset.

Valid values:

*   PrepareFail
*   Init
*   Normal
*   Preparing', example='Normal'),
      status?: string(name='Status', description='The template state.

Valid values:

*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.
*   Available: The template is available.
*   Uploading: The video is being uploaded.
*   Created: The template is created but not ready for use.
*   Processing: The advanced template is being processed.', example='Available'),
      templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
      type?: string(name='Type', description='The template type.

Valid values:

*   Timeline: regular template.
*   VETemplate: advanced template.', example='Timeline'),
    }
  ](name='Templates', description='The queried templates.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTemplatesResponseBody(name='body'),
}

/**
 * @summary Queries a list of templates that meet the specified conditions. You can query templates based on information such as the template status and creation source.
 *
 * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
 * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request ListTemplatesRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListTemplatesResponse
 */
async function listTemplatesWithOptions(request: ListTemplatesRequest, runtime: $RuntimeOptions): ListTemplatesResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.createSource)) {
    query['CreateSource'] = request.createSource;
  }
  if (!$isNull(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortType)) {
    query['SortType'] = request.sortType;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListTemplates',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of templates that meet the specified conditions. You can query templates based on information such as the template status and creation source.
 *
 * @description A template is an encapsulation of the timeline of a media editing and production job. You can define a common timeline as a template. When you have the same requirements, you need to only specify key parameters and materials to produce videos.
 * *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request ListTemplatesRequest
 * @return ListTemplatesResponse
 */
async function listTemplates(request: ListTemplatesRequest): ListTemplatesResponse {
  var runtime = new $RuntimeOptions{};
  return listTemplatesWithOptions(request, runtime);
}

model ListTranscodeJobsRequest {
  endOfCreateTime?: string(name='EndOfCreateTime', description='The end of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-15T00:00:00Z'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request.', example='ab4802364a2e49208c99efab82dfa8e8'),
  orderBy?: string(name='OrderBy', description='The order that you use to sort the query results. Valid values:

*   CreateTimeDesc: sorts the query results by creation time in descending order.
*   CreateTimeAsc: sorts the query results by creation time in ascending order.', example='CreateTimeDesc'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 0 to 100. Default value: 20.', example='10'),
  parentJobId?: string(name='ParentJobId', description='The job ID.', example='7b38a5d86f1e47838927b6e7ccb1****'),
  startOfCreateTime?: string(name='StartOfCreateTime', description='The beginning of the time range during which the jobs to be queried were created. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-07-01T00:00:00Z'),
  status?: string(name='Status', description='The state of the job.

*   Init: The job is submitted.
*   Success: The job is successful.
*   Fail: The job failed.', example='Success'),
}

model ListTranscodeJobsResponseBody = {
  jobs?: [ 
    {
      createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      inputGroup?: [ 
        {
          inputUrl?: string(name='InputUrl', description='The URL of the media asset. This parameter is specified only when the media asset is transcoded.', example='oss://bucket/path/to/video.mp4'),
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.', example='OSS'),
        }
      ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
      jobCount?: int32(name='JobCount', description='The number of subjobs.', example='1'),
      name?: string(name='Name', description='The job name.', example='transcode-job'),
      outputGroup?: [ 
        {
          output?: {
            media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
            outputUrl?: string(name='OutputUrl', description='The URL of the transcoded output stream. This parameter is required only when the output is a media asset.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
            type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
          }(name='Output', description='The output file configuration.'),
          processConfig?: {
            combineConfigs?: [ 
              {
                audioIndex?: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
                duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
                start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
                videoIndex?: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
              }
            ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
            encryption?: {
              cipherText?: string(name='CipherText', description='The ciphertext of HTTP Live Streaming (HLS) encryption.', example='MTYi00NDU0LTg5O****'),
              decryptKeyUri?: string(name='DecryptKeyUri', description='The endpoint of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
              encryptType?: string(name='EncryptType', description='The encryption type.', example='PrivateEncryption'),
            }(name='Encryption', description='The encryption settings.'),
            imageWatermarks?: [ 
              {
                overwriteParams?: {
                  dx?: string(name='Dx', description='The position of the watermark on the x-axis.', example='10'),
                  dy?: string(name='Dy', description='The position of the watermark on the y-axis.', example='10'),
                  file?: {
                    media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                    type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                  }(name='File', description='The watermark image file.'),
                  height?: string(name='Height', description='The height of the output video.', example='32'),
                  referPos?: string(name='ReferPos', description='The reference position of the watermark. Valid values: TopLeft, TopRight, BottomLeft, and BottomRight. Default value: TopLeft.', example='TopLeft'),
                  timeline?: {
                    duration?: string(name='Duration', description='The duration of the stream. Valid values: the number of seconds or "ToEND".', example='ToEND'),
                    start?: string(name='Start', description='The beginning of the time range for which data was queried.', example='00:00:05'),
                  }(name='Timeline', description='The timeline settings.'),
                  width?: string(name='Width', description='The width of the output video.', example='32'),
                }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
                templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
              }
            ](name='ImageWatermarks', description='The watermark configuration for an image.'),
            isInheritTags?: boolean(name='IsInheritTags', description='Indicates whether the tags of the input stream are inherited in the output stream. This parameter does not take effect when the input is not a media asset. Default value: false.'),
            subtitles?: [ 
              {
                overwriteParams?: {
                  charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                  file?: {
                    media?: string(name='Media', description='The media object.

*   If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, the ID of a media asset is returned.', example='oss://bucket/path/to/video.mp4'),
                    type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                  }(name='File', description='The subtitle file.'),
                  format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
                }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
                templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
              }
            ](name='Subtitles', description='The subtitle configuration.'),
            textWatermarks?: [ 
              {
                overwriteParams?: {
                  adaptive?: string(name='Adaptive', description='Indicates whether the text size was adjusted based on the output video dimensions. true / false, default: false', example='false'),
                  borderColor?: string(name='BorderColor', description='The border color.', example='#006400'),
                  borderWidth?: int32(name='BorderWidth', description='The border width.', example='0'),
                  content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                  fontAlpha?: string(name='FontAlpha', description='The transparency of the watermark.', example='1.0'),
                  fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                  fontName?: string(name='FontName', description='The font of the text.', example='SimSun'),
                  fontSize?: int32(name='FontSize', description='The size of the text.', example='16'),
                  left?: string(name='Left', description='The distance of the watermark from the left edge.', example='10'),
                  top?: string(name='Top', description='The distance of the watermark from the top edge.', example='10'),
                }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
                templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
              }
            ](name='TextWatermarks', description='The configurations of the text watermarks.'),
            transcode?: {
              overwriteParams?: {
                audio?: {
                  bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                  channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                  codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                  profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                  remove?: string(name='Remove', description='Indicates whether the audio stream is deleted.', example='false'),
                  samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100.
*   Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                  volume?: {
                    integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                    loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                    method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                    truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                  }(name='Volume', description='The volume configurations.'),
                }(name='Audio', description='The audio settings.'),
                container?: {
                  format?: string(name='Format', description='The container format.', example='mp4'),
                }(name='Container', description='The encapsulation format settings.'),
                muxConfig?: {
                  segment?: {
                    duration?: string(name='Duration', description='The segment length.', example='10'),
                    forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                  }(name='Segment', description='The segment settings.'),
                }(name='MuxConfig', description='The encapsulation settings.'),
                tags?: map[string]string(name='Tags'),
                video?: {
                  abrMax?: string(name='AbrMax', description='The maximum adaptive bitrate (ABR). This parameter takes effect only for Narrowband HD 1.0. Valid values: [10,50000]. Unit: Kbit/s.', example='6000'),
                  bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                  bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                  codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                  crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.

If this parameter is set, the value of Bitrate becomes invalid.', example='23'),
                  crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                  fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                  gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                  height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                  longShortMode?: string(name='LongShortMode', description='Indicates whether the auto-rotate screen feature is enabled.', example='false'),
                  maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video. Valid values: [10,50000]. Unit: Kbit/s.', example='9000'),
                  pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                  pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                  preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                  profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                  remove?: string(name='Remove', description='Indicates whether the video was removed.', example='false'),
                  scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                  width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
                }(name='Video', description='The video settings.'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }(name='Transcode', description='The transcoding configuration.'),
          }(name='ProcessConfig', description='The job processing configuration.'),
        }
      ](name='OutputGroup', description='The output group of the job.'),
      parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
      percent?: int32(name='Percent', description='The completion percentage of the job.', example='0'),
      requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
      scheduleConfig?: {
        pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
        priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
      }(name='ScheduleConfig', description='The scheduling configuration of the job.'),
      status?: string(name='Status', description='The state of the job.

*   Success: At least one of the subjobs is successful.
*   Fail: All subjobs failed.', example='Success'),
      submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
      triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values:

*   API
*   WorkFlow
*   Console', example='API'),
      userData?: string(name='UserData', description='The user data.', example='user-data'),
    }
  ](name='Jobs', description='The list of jobs.'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. The token of the next page is returned after you call this operation for the first time.', example='019daf5780f74831b0e1a767c9f1c178'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model ListTranscodeJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTranscodeJobsResponseBody(name='body'),
}

/**
 * @summary Queries a list of transcoding jobs.
 *
 * @param request ListTranscodeJobsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListTranscodeJobsResponse
 */
async function listTranscodeJobsWithOptions(request: ListTranscodeJobsRequest, runtime: $RuntimeOptions): ListTranscodeJobsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endOfCreateTime)) {
    query['EndOfCreateTime'] = request.endOfCreateTime;
  }
  if (!$isNull(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!$isNull(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.parentJobId)) {
    query['ParentJobId'] = request.parentJobId;
  }
  if (!$isNull(request.startOfCreateTime)) {
    query['StartOfCreateTime'] = request.startOfCreateTime;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListTranscodeJobs',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of transcoding jobs.
 *
 * @param request ListTranscodeJobsRequest
 * @return ListTranscodeJobsResponse
 */
async function listTranscodeJobs(request: ListTranscodeJobsRequest): ListTranscodeJobsResponse {
  var runtime = new $RuntimeOptions{};
  return listTranscodeJobsWithOptions(request, runtime);
}

model ListVodPackagingAssetsRequest {
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls'),
  keyword?: string(name='Keyword', description='The search keyword. The names of the returned assets are prefixed with this keyword.', example='movie'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting order of the assets based on the time when they were ingested. Valid values:

*   desc (default): descending order.
*   asc: ascending order.', example='desc'),
}

model ListVodPackagingAssetsResponseBody = {
  assets?: [ 
    {
      assetName?: string(name='AssetName', description='The name of the VOD packaging asset.', example='30min_movie'),
      createTime?: string(name='CreateTime', description='The time when the asset was ingested. It follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2024-11-21T06:45:32Z'),
      description?: string(name='Description', description='The asset description.', example='movie 30min'),
      groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls'),
      input?: {
        media?: string(name='Media', description='The URL of the media file. Only M3U8 files stored in OSS are supported.'),
        type?: string(name='Type', description='The input type. Only Object Storage Service (OSS) is supported.', example='OSS'),
      }(name='Input', description='The asset input configurations.'),
    }
  ](name='Assets', description='The VOD packaging assets.'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the assets based on the time when they were ingested. Valid values:

*   desc: descending order.
*   asc: ascending order.', example='desc'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model ListVodPackagingAssetsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListVodPackagingAssetsResponseBody(name='body'),
}

/**
 * @summary Lists VOD packaging assets.
 *
 * @param request ListVodPackagingAssetsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListVodPackagingAssetsResponse
 */
async function listVodPackagingAssetsWithOptions(request: ListVodPackagingAssetsRequest, runtime: $RuntimeOptions): ListVodPackagingAssetsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  if (!$isNull(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListVodPackagingAssets',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Lists VOD packaging assets.
 *
 * @param request ListVodPackagingAssetsRequest
 * @return ListVodPackagingAssetsResponse
 */
async function listVodPackagingAssets(request: ListVodPackagingAssetsRequest): ListVodPackagingAssetsResponse {
  var runtime = new $RuntimeOptions{};
  return listVodPackagingAssetsWithOptions(request, runtime);
}

model ListVodPackagingConfigurationsRequest {
  groupName?: string(name='GroupName', description='The name of the packaging group.', example='vod_hls'),
  keyword?: string(name='Keyword', description='The search keyword. The names of the returned packaging configurations contain the keyword.', example='hls'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting order of the packaging configurations based on the time when they were created. Valid values:

*   desc (default): descending order.
*   asc: ascending order.', example='desc'),
}

model ListVodPackagingConfigurationsResponseBody = {
  packagingConfigurations?: [
    VodPackagingConfiguration
  ](name='PackagingConfigurations', description='The packaging configurations.'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the packaging configurations based on the time when they were created. Valid values:

*   desc: descending order.
*   asc: ascending order.', example='desc'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='5'),
}

model ListVodPackagingConfigurationsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListVodPackagingConfigurationsResponseBody(name='body'),
}

/**
 * @summary Lists packaging configurations.
 *
 * @param request ListVodPackagingConfigurationsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListVodPackagingConfigurationsResponse
 */
async function listVodPackagingConfigurationsWithOptions(request: ListVodPackagingConfigurationsRequest, runtime: $RuntimeOptions): ListVodPackagingConfigurationsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  if (!$isNull(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListVodPackagingConfigurations',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Lists packaging configurations.
 *
 * @param request ListVodPackagingConfigurationsRequest
 * @return ListVodPackagingConfigurationsResponse
 */
async function listVodPackagingConfigurations(request: ListVodPackagingConfigurationsRequest): ListVodPackagingConfigurationsResponse {
  var runtime = new $RuntimeOptions{};
  return listVodPackagingConfigurationsWithOptions(request, runtime);
}

model ListVodPackagingGroupsRequest {
  keyword?: string(name='Keyword', description='The search keyword. The names of the returned packaging groups contain the keyword.', example='hls'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  sortBy?: string(name='SortBy', description='The sorting order of the packaging groups based on the time when they were created. Valid values:

*   desc (default): descending order.
*   asc: ascending order.', example='desc'),
}

model ListVodPackagingGroupsResponseBody = {
  packagingGroups?: [
    VodPackagingGroup
  ](name='PackagingGroups', description='The packaging groups.'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  sortBy?: string(name='SortBy', description='The sorting order of the packaging groups based on the time when they were created. Valid values:

*   desc: descending order.
*   asc: ascending order.', example='desc'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='5'),
}

model ListVodPackagingGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListVodPackagingGroupsResponseBody(name='body'),
}

/**
 * @summary Lists packaging groups.
 *
 * @param request ListVodPackagingGroupsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListVodPackagingGroupsResponse
 */
async function listVodPackagingGroupsWithOptions(request: ListVodPackagingGroupsRequest, runtime: $RuntimeOptions): ListVodPackagingGroupsResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'ListVodPackagingGroups',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Lists packaging groups.
 *
 * @param request ListVodPackagingGroupsRequest
 * @return ListVodPackagingGroupsResponse
 */
async function listVodPackagingGroups(request: ListVodPackagingGroupsRequest): ListVodPackagingGroupsResponse {
  var runtime = new $RuntimeOptions{};
  return listVodPackagingGroupsWithOptions(request, runtime);
}

model QueryCopyrightExtractJobRequest {
  jobId?: string(name='JobId', description='This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****'),
}

model QueryCopyrightExtractJobResponseBody = {
  data?: {
    message?: string(name='Message'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  statusCode?: long(name='StatusCode', example='200'),
}

model QueryCopyrightExtractJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryCopyrightExtractJobResponseBody(name='body'),
}

/**
 * @summary 查询版权水印提取任务
 *
 * @param request QueryCopyrightExtractJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryCopyrightExtractJobResponse
 */
async function queryCopyrightExtractJobWithOptions(request: QueryCopyrightExtractJobRequest, runtime: $RuntimeOptions): QueryCopyrightExtractJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'QueryCopyrightExtractJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 查询版权水印提取任务
 *
 * @param request QueryCopyrightExtractJobRequest
 * @return QueryCopyrightExtractJobResponse
 */
async function queryCopyrightExtractJob(request: QueryCopyrightExtractJobRequest): QueryCopyrightExtractJobResponse {
  var runtime = new $RuntimeOptions{};
  return queryCopyrightExtractJobWithOptions(request, runtime);
}

model QueryCopyrightJobListRequest {
  createTimeEnd?: long(name='CreateTimeEnd', example='1627357325'),
  createTimeStart?: long(name='CreateTimeStart', example='1627357322'),
  jobId?: string(name='JobId', example='****cdb3e74639973036bc84****'),
  level?: long(name='Level', example='0'),
  pageNumber?: long(name='PageNumber', example='0'),
  pageSize?: long(name='PageSize', example='10'),
}

model QueryCopyrightJobListResponseBody = {
  data?: [ 
    {
      gmtCreate?: long(name='GmtCreate', example='1627357322'),
      gmtModified?: long(name='GmtModified', example='1627357322'),
      input?: {
        media?: string(name='Media', example='oss://bucket/object'),
        type?: string(name='Type', example='OSS'),
      }(name='Input'),
      jobId?: string(name='JobId', example='bfb786c639894f4d80648792021****'),
      level?: long(name='Level', example='2'),
      message?: string(name='Message', example='test'),
      output?: {
        media?: string(name='Media', example='oss://bucket/object'),
        type?: string(name='Type', example='OSS'),
      }(name='Output'),
      result?: string(name='Result', example='{"Code":"success","Message":"ok"}'),
      status?: string(name='Status', example='success'),
      userData?: string(name='UserData', example='123'),
      userId?: long(name='UserId', example='1346693***'),
    }
  ](name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='******36-3C1E-4417-BDB2-1E034F******'),
  statusCode?: long(name='StatusCode', example='200'),
}

model QueryCopyrightJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryCopyrightJobListResponseBody(name='body'),
}

/**
 * @summary 查询视频版权水印任务列表
 *
 * @param request QueryCopyrightJobListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryCopyrightJobListResponse
 */
async function queryCopyrightJobListWithOptions(request: QueryCopyrightJobListRequest, runtime: $RuntimeOptions): QueryCopyrightJobListResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.createTimeEnd)) {
    query['CreateTimeEnd'] = request.createTimeEnd;
  }
  if (!$isNull(request.createTimeStart)) {
    query['CreateTimeStart'] = request.createTimeStart;
  }
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.level)) {
    query['Level'] = request.level;
  }
  if (!$isNull(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'QueryCopyrightJobList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 查询视频版权水印任务列表
 *
 * @param request QueryCopyrightJobListRequest
 * @return QueryCopyrightJobListResponse
 */
async function queryCopyrightJobList(request: QueryCopyrightJobListRequest): QueryCopyrightJobListResponse {
  var runtime = new $RuntimeOptions{};
  return queryCopyrightJobListWithOptions(request, runtime);
}

model QueryDNAJobListRequest {
  jobIds?: string(name='JobIds', description='The IDs of the media fingerprint analysis jobs that you want to query. We recommend that you query at most 10 jobs at a time. Separate multiple job IDs with commas (,).', example='88c6ca184c0e47098a5b665e2a12****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model QueryDNAJobListResponseBody = {
  jobList?: [ 
    {
      code?: string(name='Code', description='The response code.', example='"InvalidParameter.ResourceNotFound"'),
      config?: string(name='Config', description='The configurations of the media fingerprint analysis job.', example='{"SaveType": "save","MediaType"":"video"}'),
      creationTime?: string(name='CreationTime', description='The time when the job was created.', example='2022-12-28T03:21:37Z'),
      DBId?: string(name='DBId', description='The ID of the media fingerprint library.', example='2288c6ca184c0e47098a5b665e2a12****'),
      DNAResult?: string(name='DNAResult', description='The URL of the media fingerprint analysis result.', example='http://test_bucket.oss-cn-shanghai.aliyuncs.com/fingerprint/video/search_result/5/5.txt'),
      finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-12-28T03:21:44Z'),
      id?: string(name='Id', description='The job ID.', example='88c6ca184c0e47098a5b665e2a12****'),
      input?: {
        media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. The path of an OSS object can be in one of the following formats:

1\\\\. oss://bucket/object

2\\\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the preceding paths, bucket indicates an OSS bucket that resides in the same region as the current project, and object indicates the path of the object in the bucket.', example='1b1b9cd148034739af413150fded****'),
        type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: Object Storage Service (OSS) object.
2.  Media: media asset.', example='Media'),
      }(name='Input', description='The details of the input file.'),
      message?: string(name='Message', description='The returned message.', example='"The resource operated \\\\"a887d0b***d805ef6f7f6786302\\\\" cannot be found"'),
      primaryKey?: string(name='PrimaryKey', description='The primary key of the video. You must make sure that each primary key is unique.', example='3ca84a39a9024f19853b21be9cf9****'),
      status?: string(name='Status', description='The job state. Valid values:

*   **Queuing**: The job is waiting in the queue.
*   **Analysing**: The job is in progress.
*   **Success**: The job is successful.
*   **Fail**: The job failed.', example='Queuing'),
      userData?: string(name='UserData', description='The user-defined data.', example='testdna'),
    }
  ](name='JobList', description='The queried media fingerprint analysis jobs.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model QueryDNAJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryDNAJobListResponseBody(name='body'),
}

/**
 * @summary Queries a list of media fingerprint analysis jobs.
 *
 * @param request QueryDNAJobListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryDNAJobListResponse
 */
async function queryDNAJobListWithOptions(request: QueryDNAJobListRequest, runtime: $RuntimeOptions): QueryDNAJobListResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobIds)) {
    query['JobIds'] = request.jobIds;
  }
  if (!$isNull(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!$isNull(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!$isNull(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!$isNull(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'QueryDNAJobList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of media fingerprint analysis jobs.
 *
 * @param request QueryDNAJobListRequest
 * @return QueryDNAJobListResponse
 */
async function queryDNAJobList(request: QueryDNAJobListRequest): QueryDNAJobListResponse {
  var runtime = new $RuntimeOptions{};
  return queryDNAJobListWithOptions(request, runtime);
}

model QueryIProductionJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.'),
  jobId?: string(name='JobId', description='The ID of the intelligent production job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model QueryIProductionJobResponseBody = {
  createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-07-07T07:16:11Z'),
  finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2021-11-26T14:50:25Z'),
  functionName?: string(name='FunctionName', description='The name of the algorithm that you want to use for the job. Valid values:

*   **Cover**: This algorithm intelligently generates a thumbnail image for a video.
*   **VideoClip**: This algorithm intelligently generates a summary for a video.
*   **VideoDelogo**: This algorithm removes logos from a video.
*   **VideoDetext**: This algorithm removes captions from a video.', example='Cover'),
  input?: {
    media?: string(name='Media', description='The input file. If Type is set to OSS, set this parameter to the path of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.', example='oss://bucket/object'),
    type?: string(name='Type', description='The media type. Valid values:

1.  OSS: Object Storage Service (OSS) object
2.  Media: media asset', example='OSS'),
  }(name='Input', description='The input file.'),
  jobId?: string(name='JobId', description='The ID of the intelligent production job.', example='****20b48fb04483915d4f2cd8ac****'),
  jobParams?: string(name='JobParams', description='The algorithm-specific parameters. The parameters are specified as JSON objects and vary based on the algorithm.', example='{"Model":"gif"}'),
  name?: string(name='Name', description='The name of the intelligent production job.'),
  output?: {
    media?: string(name='Media', description='The output file. If Type is set to OSS, set this parameter to the path of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.', example='oss://bucket/object'),
    type?: string(name='Type', description='The media type. Valid values:

*   OSS: OSS object
*   Media: media asset', example='OSS'),
  }(name='Output', description='The output file.'),
  outputFiles?: [ string ](name='OutputFiles', description='The output files.'),
  outputUrls?: [ string ](name='OutputUrls', description='The URLs of the output files.'),
  requestId?: string(name='RequestId', description='The ID of the request.'),
  result?: string(name='Result', description='The output of the algorithm. The output is in JSON format and varies based on the algorithm. For more information, see the "Parameters of Result" section of this topic.', example='{}'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue.', example='a54fdc9c9aab413caef0d1150f565e86'),
    priority?: int32(name='Priority', description='The priority of the job in the MPS queue to which the job is added.

*   A value of 10 indicates the highest priority.
*   Default value: **6**.', example='6'),
  }(name='ScheduleConfig', description='The scheduling configuration.'),
  status?: string(name='Status', description='The status of the job. Valid values:

*   Queuing: The job is waiting in the queue.
*   Analysing: The job is in progress.
*   Fail: The job failed.
*   Success: The job was successful.', example='Success'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****96e8864746a0b6f3****'),
  userData?: string(name='UserData', description='The user-defined data that is returned in the response.', example='{"test":1}'),
}

model QueryIProductionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryIProductionJobResponseBody(name='body'),
}

/**
 * @summary Queries the status and result of an intelligent production job.
 *
 * @param request QueryIProductionJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryIProductionJobResponse
 */
async function queryIProductionJobWithOptions(request: QueryIProductionJobRequest, runtime: $RuntimeOptions): QueryIProductionJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'QueryIProductionJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the status and result of an intelligent production job.
 *
 * @param request QueryIProductionJobRequest
 * @return QueryIProductionJobResponse
 */
async function queryIProductionJob(request: QueryIProductionJobRequest): QueryIProductionJobResponse {
  var runtime = new $RuntimeOptions{};
  return queryIProductionJobWithOptions(request, runtime);
}

model QueryMediaCensorJobDetailRequest {
  jobId?: string(name='JobId', description='The ID of the content moderation job. You can obtain the job ID from the response parameters of the [SubmitMediaCensorJob](https://help.aliyun.com/document_detail/444848.html) operation.

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****'),
  maximumPageSize?: long(name='MaximumPageSize', description='The number of entries per page.

*   Default value: **30**.
*   Valid values: **1 to 300**.', example='30'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='ae0fd49c0840e14daf0d66a75b83****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model QueryMediaCensorJobDetailResponseBody = {
  mediaCensorJobDetail?: {
    barrageCensorResult?: {
      label?: string(name='Label', description='The label of the moderation result. Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='normal'),
      rate?: string(name='Rate', description='The score.', example='99.91'),
      scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
    }(name='BarrageCensorResult', description='The moderation results of live comments.'),
    code?: string(name='Code', description='The error code returned if the job failed. This parameter is not returned if the job is successful.', example='InvalidParameter.ResourceNotFound'),
    coverImageCensorResults?: {
      coverImageCensorResult?: [ 
      {
        bucket?: string(name='Bucket', description='The OSS bucket in which the thumbnail is stored.', example='bucket-out-test-****'),
        location?: string(name='Location', description='The OSS region in which the thumbnail resides.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The Object Storage Service (OSS) object that is used as the thumbnail.', example='test/ai/censor/v2/vme-****.jpg'),
        results?: {
          result?: [ 
          {
            label?: string(name='Label', description='The label of the moderation result.

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live broadcasting in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='Normal'),
            rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
            scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='Antispam'),
            suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
          }
        ](name='Result')
        }(name='Results', description='The moderation results.'),
      }
    ](name='CoverImageCensorResult')
    }(name='CoverImageCensorResults', description='The moderation results of thumbnails.'),
    creationTime?: string(name='CreationTime', description='The time when the content moderation job was created.', example='2018-09-13T16:32:24Z'),
    descCensorResult?: {
      label?: string(name='Label', description='The label of the moderation result. Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='terrorism'),
      rate?: string(name='Rate', description='The score.', example='100'),
      scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='review'),
    }(name='DescCensorResult', description='The moderation results of descriptions.'),
    finishTime?: string(name='FinishTime', description='The time when the content moderation job was complete.', example='2018-09-13T16:38:24Z'),
    input?: {
      bucket?: string(name='Bucket', description='The name of the OSS bucket in which the input file is stored.', example='bucket-test-in-****'),
      location?: string(name='Location', description='The OSS region in which the input file resides.', example='oss-cn-shanghai'),
      object?: string(name='Object', description='The name of the OSS object that is used as the input file.', example='test/ai/censor/test-****.mp4'),
    }(name='Input', description='The information about the job input.'),
    jobId?: string(name='JobId', description='The ID of the content moderation job.', example='f8f166eea7a44e9bb0a4aecf9543****'),
    message?: string(name='Message', description='The error message returned if the job failed. This parameter is not returned if the job is successful.', example='The resource operated cannot be found'),
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the job was submitted.', example='c5b30b7c0d0e4a0abde1d5f9e751****'),
    state?: string(name='State', description='The job state.', example='Success'),
    suggestion?: string(name='Suggestion', description='The overall result of the content moderation job. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.

>  If the moderation result of any type of content is review, the overall result is review. If the moderation result of any type of content is block, the overall result is block.', example='block'),
    titleCensorResult?: {
      label?: string(name='Label', description='The label of the moderation result. Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='meaningless'),
      rate?: string(name='Rate', description='The score.', example='99.91'),
      scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
    }(name='TitleCensorResult', description='The moderation results of titles.'),
    userData?: string(name='UserData', description='The user-defined data.', example='example userdata ****'),
    vensorCensorResult?: {
      censorResults?: {
        censorResult?: [ 
        {
          label?: string(name='Label', description='The label of the moderation result.

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live broadcasting in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='meaningless'),
          rate?: string(name='Rate', description='The score.', example='100'),
          scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='terrorism'),
          suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='review'),
        }
      ](name='CensorResult')
      }(name='CensorResults', description='A collection of moderation results. The information includes the summary about various scenarios such as pornographic content moderation and terrorist content moderation.'),
      nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='ea04afcca7cd4e80b9ece8fbb251****'),
      videoTimelines?: {
        videoTimeline?: [ 
        {
          censorResults?: {
            censorResult?: [ 
            {
              label?: string(name='Label', description='The label of the moderation result.

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live broadcasting in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='flood'),
              rate?: string(name='Rate', description='The score.', example='99.99'),
              scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='porn'),
              suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
            }
          ](name='CensorResult')
          }(name='CensorResults', description='The moderation results that include information such as labels and scores.'),
          object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg`, `output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
          timestamp?: string(name='Timestamp', description='The position in the video. Format: `hh:mm:ss[.SSS]`.', example='00:02:59.999'),
        }
      ](name='VideoTimeline')
      }(name='VideoTimelines', description='The moderation results that are sorted in ascending order by time.'),
    }(name='VensorCensorResult', description='The moderation results of videos.'),
    videoCensorConfig?: {
      bizType?: string(name='BizType', description='The custom business type. Default value: common.', example='common'),
      outputFile?: {
        bucket?: string(name='Bucket', description='The OSS bucket in which the output snapshot is stored.', example='test-bucket-****'),
        location?: string(name='Location', description='The OSS region in which the output snapshot resides.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg`, `output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
      }(name='OutputFile', description='The information about output snapshots.'),
      videoCensor?: string(name='VideoCensor', description='Indicates whether the video content needs to be moderated. Default value: **true**. Valid values:

*   **true**: The video content needs to be moderated.
*   **false**: The video content does not need to be moderated.', example='true'),
    }(name='VideoCensorConfig', description='The video moderation configurations.'),
  }(name='MediaCensorJobDetail', description='The results of the content moderation job.'),
  requestId?: string(name='RequestId', description='The request ID.', example='B42299E6-F71F-465F-8FE9-4FC2E3D3C2CA'),
}

model QueryMediaCensorJobDetailResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryMediaCensorJobDetailResponseBody(name='body'),
}

/**
 * @summary Queries the information about a content moderation job.
 *
 * @description In the content moderation results, the moderation results of the video are sorted in ascending order by time into a timeline. If the video is long, the content moderation results are paginated, and the first page is returned. You can call this operation again to query the remaining moderation results of the video.
 *
 * @param request QueryMediaCensorJobDetailRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryMediaCensorJobDetailResponse
 */
async function queryMediaCensorJobDetailWithOptions(request: QueryMediaCensorJobDetailRequest, runtime: $RuntimeOptions): QueryMediaCensorJobDetailResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.maximumPageSize)) {
    query['MaximumPageSize'] = request.maximumPageSize;
  }
  if (!$isNull(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!$isNull(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!$isNull(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!$isNull(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!$isNull(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'QueryMediaCensorJobDetail',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a content moderation job.
 *
 * @description In the content moderation results, the moderation results of the video are sorted in ascending order by time into a timeline. If the video is long, the content moderation results are paginated, and the first page is returned. You can call this operation again to query the remaining moderation results of the video.
 *
 * @param request QueryMediaCensorJobDetailRequest
 * @return QueryMediaCensorJobDetailResponse
 */
async function queryMediaCensorJobDetail(request: QueryMediaCensorJobDetailRequest): QueryMediaCensorJobDetailResponse {
  var runtime = new $RuntimeOptions{};
  return queryMediaCensorJobDetailWithOptions(request, runtime);
}

model QueryMediaCensorJobListRequest {
  endOfJobCreatedTimeRange?: string(name='EndOfJobCreatedTimeRange', description='The end of the time range to query.

*   Specify the time in the ISO 8601 standard. The time must be in UTC.
*   Format: yyyy-MM-ddTHH:mm:ssZ.', example='2022-02-14T02:16:07Z'),
  jobIds?: string(name='JobIds', description='The IDs of the content moderation jobs. You can obtain the ID of a content moderation job from the response parameters of the SubmitMediaCensorJob operation. Separate multiple IDs with commas (,).', example='fa9c34be3bcf42919ac4d1775239****,78dc866518b843259669df58ed30****'),
  maximumPageSize?: long(name='MaximumPageSize', description='The number of entries per page.

*   Default value: **30**.
*   Valid values: **1 to 300**.', example='20'),
  nextPageToken?: string(name='NextPageToken', description='The pagination token that is used in the next request to retrieve a new page of results. You do not need to specify this parameter for the first request. You must specify the token that is obtained from the previous query as the value of NextToken.', example='79aff3eee82242e092899db5f669'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the jobs were submitted.', example='c5b30b7c0d0e4a0abde1d5f9e751****'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
  startOfJobCreatedTimeRange?: string(name='StartOfJobCreatedTimeRange', description='The beginning of the time range to query.

*   Specify the time in the ISO 8601 standard. The time must be in UTC.
*   Format: yyyy-MM-ddTHH:mm:ssZ.', example='2021-12-22T03:48:05Z'),
  state?: string(name='State', description='The state of the jobs that you want to query. Valid values:

*   **All**: all jobs.
*   **Queuing**: the jobs that are waiting in the queue.
*   **Analysing**: the jobs that are in progress.
*   **Fail**: failed jobs.
*   **Success**: successful jobs.', example='All'),
}

model QueryMediaCensorJobListResponseBody = {
  mediaCensorJobList?: {
    mediaCensorJob?: [ 
    {
      barrageCensorResult?: {
        label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,). Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='normal'),
        rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='99.91'),
        scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
        suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
      }(name='BarrageCensorResult', description='The moderation results of live comments.'),
      code?: string(name='Code', description='The error code returned if the job failed. This parameter is not returned if the job is successful.', example='InvalidParameter.ResourceNotFound'),
      coverImageCensorResults?: {
        coverImageCensorResult?: [ 
        {
          bucket?: string(name='Bucket', description='The OSS bucket in which the thumbnail is stored.', example='example-Bucket-****'),
          location?: string(name='Location', description='The OSS region in which the thumbnail resides.', example='oss-cn-shanghai'),
          object?: string(name='Object', description='The Object Storage Service (OSS) object that is used as the thumbnail.', example='test/ai/censor/v2/vme-****.jpg'),
          results?: {
            result?: [ 
            {
              label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,).

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live streaming in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='normal'),
              rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
              scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='live'),
              suggestion?: string(name='Suggestion', description='The overall result of the moderation job. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.

>  If the moderation result of any type of content is review, the overall result is review. If the moderation result of any type of content is block, the overall result is block.', example='pass'),
            }
          ](name='Result')
          }(name='Results', description='The moderation results.'),
        }
      ](name='CoverImageCensorResult')
      }(name='CoverImageCensorResults', description='The moderation results of thumbnails.'),
      creationTime?: string(name='CreationTime', description='The time when the content moderation job was created.', example='2021-11-04T07:25:48Z'),
      descCensorResult?: {
        label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,). Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='normal'),
        rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
        scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
        suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
      }(name='DescCensorResult', description='The moderation results of descriptions.'),
      finishTime?: string(name='FinishTime', description='The time when the content moderation job was complete.', example='2021-11-04T07:25:50Z'),
      input?: {
        bucket?: string(name='Bucket', description='The name of the OSS bucket in which the input file is stored.', example='bucket-test-in-****'),
        location?: string(name='Location', description='The OSS region in which the input file resides.', example='oss-cn-shanghai'),
        object?: string(name='Object', description='The name of the OSS object that is used as the input file.', example='test/ai/censor/test-****.mp4'),
      }(name='Input', description='The information about the job input.'),
      jobId?: string(name='JobId', description='The ID of the content moderation job.', example='f8f166eea7a44e9bb0a4aecf9543'),
      message?: string(name='Message', description='The error message returned if the job failed. This parameter is not returned if the job is successful.', example='The resource operated cannot be found'),
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='c5b30b7c0d0e4a0abde1d5f9e751****'),
      state?: string(name='State', description='The job state.', example='Success'),
      suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
      titleCensorResult?: {
        label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,). Valid values:

*   **normal**: normal content.
*   **spam**: spam.
*   **ad**: ads.
*   **abuse**: abuse content.
*   **flood**: excessive junk content.
*   **contraband**: prohibited content.
*   **meaningless**: meaningless content.', example='meaningless'),
        rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
        scene?: string(name='Scene', description='The moderation scenario. The value is **antispam**.', example='antispam'),
        suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
      }(name='TitleCensorResult', description='The moderation results of titles.'),
      userData?: string(name='UserData', description='The user-defined data.', example='example userdata ****'),
      vensorCensorResult?: {
        censorResults?: {
          censorResult?: [ 
          {
            label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,).

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live streaming in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='meaningless'),
            rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
            scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='ad'),
            suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='pass'),
          }
        ](name='CensorResult')
        }(name='CensorResults', description='A collection of moderation results. The information includes the summary about various scenarios such as pornographic content moderation and terrorist content moderation.'),
        nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results.', example='ea04afcca7cd4e80b9ece8fbb251'),
        videoTimelines?: {
          videoTimeline?: [ 
          {
            censorResults?: {
              censorResult?: [ 
              {
                label?: string(name='Label', description='The label of the moderation result. Separate multiple labels with commas (,).

*   Valid values in the pornographic content moderation scenario:

    *   **normal**: normal content.
    *   **sexy**: sexy content.
    *   **porn**: pornographic content.

*   Valid values in the terrorist content moderation scenario:

    *   **normal**: normal content.
    *   **bloody**: bloody content.
    *   **explosion**: explosion and smoke.
    *   **outfit**: special costume.
    *   **logo**: special logo.
    *   **weapon**: weapon.
    *   **politics**: political content.
    *   **violence**: violence.
    *   **crowd**: crowd.
    *   **parade**: parade.
    *   **carcrash**: car accident.
    *   **flag**: flag.
    *   **location**: landmark.
    *   **others**: other content.

*   Valid values in the ad moderation scenario:

    *   **normal**: normal content.
    *   **ad**: other ads.
    *   **politics**: political content in text.
    *   **porn**: pornographic content in text.
    *   **abuse**: abuse in text.
    *   **terrorism**: terrorist content in text.
    *   **contraband**: prohibited content in text.
    *   **spam**: spam in text.
    *   **npx**: illegal ad.
    *   **qrcode**: QR code.
    *   **programCode**: mini program code.

*   Valid values in the undesirable scene moderation scenario:

    *   **normal**: normal content.
    *   **meaningless**: meaningless content, such as a black or white screen.
    *   **PIP**: picture-in-picture.
    *   **smoking**: smoking.
    *   **drivelive**: live streaming in a running vehicle.

*   Valid values in the logo moderation scenario:

    *   **normal**: normal content.
    *   **TV**: controlled logo.
    *   **trademark**: trademark.', example='normal'),
                rate?: string(name='Rate', description='The score. Valid values: 0 to 100.', example='100'),
                scene?: string(name='Scene', description='The moderation scenario. Valid values:

*   **porn**: pornographic content moderation.
*   **terrorism**: terrorist content moderation.
*   **ad**: ad moderation.
*   **live**: undesirable scene moderation.
*   **logo**: logo moderation.', example='porn'),
                suggestion?: string(name='Suggestion', description='The recommended subsequent operation. Valid values:

*   **pass**: The content passes the moderation.
*   **review**: The content needs to be manually reviewed.
*   **block**: The content needs to be blocked.', example='block'),
              }
            ](name='CensorResult')
            }(name='CensorResults', description='The moderation results that include information such as labels and scores.'),
            object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg`, `output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
            timestamp?: string(name='Timestamp', description='The position in the video. Format: `hh:mm:ss[.SSS]`.', example='00:02:59.999'),
          }
        ](name='VideoTimeline')
        }(name='VideoTimelines', description='The moderation results that are sorted in ascending order by time.'),
      }(name='VensorCensorResult', description='The moderation results of videos.'),
      videoCensorConfig?: {
        bizType?: string(name='BizType', description='The moderation template. Default value: common. The default value indicates that the default template is used.

>  If the moderation template is not specified, the default value common is returned. If a custom moderation template that is created by submitting a ticket is specified, the UID of the template is returned.', example='common'),
        outputFile?: {
          bucket?: string(name='Bucket', description='The OSS bucket in which the output snapshot is stored.', example='test-bucket-****'),
          location?: string(name='Location', description='The ID of the region in which the output snapshot resides.', example='oss-cn-shanghai'),
          object?: string(name='Object', description='The OSS object that is generated as the output snapshot.

>  In the example, {Count} is a placeholder. The OSS objects that are generated as output snapshots are named `output00001-****.jpg, output00002-****.jpg`, and so on.', example='output{Count}.jpg'),
        }(name='OutputFile', description='The information about output snapshots.'),
        videoCensor?: string(name='VideoCensor', description='Indicates whether the video content needs to be moderated. Default value: **true**. Valid values:

*   **true**: The video content needs to be moderated.
*   **false**: The video content does not need to be moderated.', example='true'),
      }(name='VideoCensorConfig', description='The video moderation configurations.'),
    }
  ](name='MediaCensorJob')
  }(name='MediaCensorJobList', description='The queried content moderation jobs.'),
  nextPageToken?: string(name='NextPageToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. The value is 32-character UUID. If the returned query results cannot be displayed within one page, this parameter is returned. The value of this parameter is updated for each query.', example='9b1a42bc6e8d46e6a1383b7e7f01****'),
  nonExistIds?: {
    string?: [ string ](name='String')
  }(name='NonExistIds', description='The IDs of the jobs that do not exist. This parameter is not returned if all the specified jobs are found.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D1D5C080-8E2F-5030-8AB4-13092F17631B'),
}

model QueryMediaCensorJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryMediaCensorJobListResponseBody(name='body'),
}

/**
 * @summary Queries a list of content moderation jobs.
 *
 * @description You can call this operation to query only the content moderation jobs within the most recent three months.
 *
 * @param request QueryMediaCensorJobListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryMediaCensorJobListResponse
 */
async function queryMediaCensorJobListWithOptions(request: QueryMediaCensorJobListRequest, runtime: $RuntimeOptions): QueryMediaCensorJobListResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.endOfJobCreatedTimeRange)) {
    query['EndOfJobCreatedTimeRange'] = request.endOfJobCreatedTimeRange;
  }
  if (!$isNull(request.jobIds)) {
    query['JobIds'] = request.jobIds;
  }
  if (!$isNull(request.maximumPageSize)) {
    query['MaximumPageSize'] = request.maximumPageSize;
  }
  if (!$isNull(request.nextPageToken)) {
    query['NextPageToken'] = request.nextPageToken;
  }
  if (!$isNull(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!$isNull(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!$isNull(request.pipelineId)) {
    query['PipelineId'] = request.pipelineId;
  }
  if (!$isNull(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!$isNull(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  if (!$isNull(request.startOfJobCreatedTimeRange)) {
    query['StartOfJobCreatedTimeRange'] = request.startOfJobCreatedTimeRange;
  }
  if (!$isNull(request.state)) {
    query['State'] = request.state;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'QueryMediaCensorJobList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries a list of content moderation jobs.
 *
 * @description You can call this operation to query only the content moderation jobs within the most recent three months.
 *
 * @param request QueryMediaCensorJobListRequest
 * @return QueryMediaCensorJobListResponse
 */
async function queryMediaCensorJobList(request: QueryMediaCensorJobListRequest): QueryMediaCensorJobListResponse {
  var runtime = new $RuntimeOptions{};
  return queryMediaCensorJobListWithOptions(request, runtime);
}

model QueryMediaIndexJobRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='c2e77390f75271ec802f0674a2ce6***'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1'),
}

model QueryMediaIndexJobResponseBody = {
  code?: string(name='Code', description='The response code.', example='200'),
  indexJobInfoList?: [ 
    {
      gmtFinish?: string(name='GmtFinish', description='The end time of the indexing job.', example='2023-11-21 11:33:51'),
      gmtSubmit?: string(name='GmtSubmit', description='The time when the index job was submitted.', example='2023-11-21 11:33:50'),
      indexType?: string(name='IndexType', description='The index type. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.', example='mm'),
      status?: string(name='Status', description='The job status. Valid values:

*   Running
*   Success
*   Fail', example='Success'),
    }
  ](name='IndexJobInfoList', description='The indexing jobs enabled for the media asset.'),
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model QueryMediaIndexJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryMediaIndexJobResponseBody(name='body'),
}

/**
 * @summary Queries the indexing jobs enabled for a media asset.
 *
 * @param request QueryMediaIndexJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryMediaIndexJobResponse
 */
async function queryMediaIndexJobWithOptions(request: QueryMediaIndexJobRequest, runtime: $RuntimeOptions): QueryMediaIndexJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'QueryMediaIndexJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the indexing jobs enabled for a media asset.
 *
 * @param request QueryMediaIndexJobRequest
 * @return QueryMediaIndexJobResponse
 */
async function queryMediaIndexJob(request: QueryMediaIndexJobRequest): QueryMediaIndexJobResponse {
  var runtime = new $RuntimeOptions{};
  return queryMediaIndexJobWithOptions(request, runtime);
}

model QuerySearchIndexRequest {
  indexType?: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.

This parameter is required.', example='mm'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

*   If you leave this parameter empty, the search index is created in the default search library of Intelligent Media Service (IMS). Default value: ims-default-search-lib.
*   To query information about an existing search library, call the [QuerySearchLib](https://help.aliyun.com/document_detail/2584455.html) API operation.', example='test1'),
}

model QuerySearchIndexResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  indexStatus?: string(name='IndexStatus', description='The state of the index. Valid values:

*   active: the index is enabled.
*   Deactive: the index is not enabled.', example='Active'),
  indexType?: string(name='IndexType', description='The category of the index. Valid values:

*   mm: large visual model.
*   face: face recognition.
*   aiLabel: smart tagging.', example='mm'),
  mediaTotal?: string(name='MediaTotal', description='The total number of media assets.', example='12'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model QuerySearchIndexResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QuerySearchIndexResponseBody(name='body'),
}

/**
 * @summary Queries the details of a search index.
 *
 * @param request QuerySearchIndexRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QuerySearchIndexResponse
 */
async function querySearchIndexWithOptions(request: QuerySearchIndexRequest, runtime: $RuntimeOptions): QuerySearchIndexResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.indexType)) {
    query['IndexType'] = request.indexType;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'QuerySearchIndex',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the details of a search index.
 *
 * @param request QuerySearchIndexRequest
 * @return QuerySearchIndexResponse
 */
async function querySearchIndex(request: QuerySearchIndexRequest): QuerySearchIndexResponse {
  var runtime = new $RuntimeOptions{};
  return querySearchIndexWithOptions(request, runtime);
}

model QuerySearchLibRequest {
  searchLibName?: string(name='SearchLibName', description='The name of the search library.

This parameter is required.', example='test1'),
}

model QuerySearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  indexInfo?: [ 
    {
      indexReadiness?: string(name='IndexReadiness'),
      indexStatus?: string(name='IndexStatus'),
      indexType?: string(name='IndexType'),
    }
  ](name='IndexInfo'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
  status?: string(name='Status', description='The status of the search library.

Valid values:

*   normal
*   deleting
*   deleteFail', example='normal'),
  success?: string(name='Success', description='Indicates whether the call was successful. Valid values:

*   true
*   false', example='true'),
}

model QuerySearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QuerySearchLibResponseBody(name='body'),
}

/**
 * @summary Queries the information about a search library.
 *
 * @param request QuerySearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QuerySearchLibResponse
 */
async function querySearchLibWithOptions(request: QuerySearchLibRequest, runtime: $RuntimeOptions): QuerySearchLibResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'QuerySearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a search library.
 *
 * @param request QuerySearchLibRequest
 * @return QuerySearchLibResponse
 */
async function querySearchLib(request: QuerySearchLibRequest): QuerySearchLibResponse {
  var runtime = new $RuntimeOptions{};
  return querySearchLibWithOptions(request, runtime);
}

model QuerySmarttagJobRequest {
  jobId?: string(name='JobId', description='The ID of the smart tagging job that you want to query. You can obtain the job ID from the response parameters of the SubmitSmarttagJob operation.

This parameter is required.', example='88c6ca184c0e47098a5b665e2****'),
  params?: string(name='Params', description='The extra parameters that you want to query in the request. The value is a JSON string. Example: {"labelResultType":"auto"}. The value of labelResultType is of the STRING type. Valid values:

*   auto: machine tagging
*   hmi: tagging by human and machine', example='{"labelResultType":"auto"}'),
}

model QuerySmarttagJobResponseBody = {
  jobStatus?: string(name='JobStatus', description='The status of the job. Valid values:

*   **Success**: The job was successful.
*   **Fail**: The job failed.
*   **Processing**: The job is in progress.
*   **Submitted**: The job is submitted and waiting to be processed.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  results?: {
    result?: [ 
    {
      data?: string(name='Data', description='The details of the analysis result. The value is a JSON string. For more information about the parameters of different result types, see the "Parameters of different result types" section of this topic.', example='{"title":"example-title-****"}'),
      type?: string(name='Type', description='The type of the analysis result.

*   The type of the analysis result based on Smart tagging V1.0. Valid values:

1.  TextLabel: the text tag.
2.  VideoLabel: the video tag.
3.  ASR: the original result of automatic speech recognition (ASR). By default, this type of result is not returned.
4.  OCR: the original result of optical character recognition (OCR). By default, this type of result is not returned.
5.  NLP: the natural language processing (NLP)-based result. By default, this type of result is not returned.

*   The type of the analysis result based on Smart tagging V2.0. Valid values:

1.  CPVLabel
2.  Meta: the information about the video file, such as the title of the video. By default, this type of information is not returned.

*   The type of the analysis result based on Smart tagging V2.0-custom. Valid values:

1.  CPVLabel
2.  Meta: the information about the video file, such as the title of the video. By default, this type of information is not returned.', example='Meta'),
    }
  ](name='Result')
  }(name='Results', description='The analysis results of the smart tagging job. The value is an array.'),
  userData?: string(name='UserData', description='The content of callback messages that are sent to Simple Message Queue (SMQ) when the information of the smart tagging job changes. For more information about the parameters contained in the callback message, see the "Callback parameters" section of this topic.', example='{"userId":"123432412831"}'),
}

model QuerySmarttagJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QuerySmarttagJobResponseBody(name='body'),
}

/**
 * @summary Queries the information about a smart tagging job.
 *
 * @param request QuerySmarttagJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QuerySmarttagJobResponse
 */
async function querySmarttagJobWithOptions(request: QuerySmarttagJobRequest, runtime: $RuntimeOptions): QuerySmarttagJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.params)) {
    query['Params'] = request.params;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'QuerySmarttagJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about a smart tagging job.
 *
 * @param request QuerySmarttagJobRequest
 * @return QuerySmarttagJobResponse
 */
async function querySmarttagJob(request: QuerySmarttagJobRequest): QuerySmarttagJobResponse {
  var runtime = new $RuntimeOptions{};
  return querySmarttagJobWithOptions(request, runtime);
}

model QueryTraceAbJobListRequest {
  createTimeEnd?: long(name='CreateTimeEnd', example='1627357325'),
  createTimeStart?: long(name='CreateTimeStart', example='1627357322'),
  jobId?: string(name='JobId', example='****d80e4e4044975745c14b****'),
  pageNumber?: long(name='PageNumber', example='0'),
  pageSize?: long(name='PageSize', example='10'),
  traceMediaId?: string(name='TraceMediaId', example='****437bd2b51105d07b12a9****'),
}

model QueryTraceAbJobListResponseBody = {
  data?: [ 
    {
      gmtCreate?: long(name='GmtCreate', example='1627357322'),
      gmtModified?: long(name='GmtModified', example='1627357322'),
      input?: {
        media?: string(name='Media', example='oss://bucket/object'),
        type?: string(name='Type', example='OSS'),
      }(name='Input'),
      jobId?: string(name='JobId', example='bfb786c639894f4d80648792021eff90'),
      level?: long(name='Level', example='2'),
      output?: {
        media?: string(name='Media', example='oss://bucket/dir/'),
        type?: string(name='Type', example='OSS'),
      }(name='Output'),
      result?: string(name='Result', example='{"Code":"success","Message":"ok"}'),
      status?: string(name='Status', example='success'),
      traceMediaId?: string(name='TraceMediaId', example='****437bd2b51105d07b12a9****'),
      userData?: string(name='UserData', example='123'),
      userId?: long(name='UserId', example='13466932****'),
    }
  ](name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='******11-DB8D-4A9A-875B-275798******'),
  statusCode?: long(name='StatusCode', example='200'),
}

model QueryTraceAbJobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryTraceAbJobListResponseBody(name='body'),
}

/**
 * @summary 查询视频溯源水印ab流任务
 *
 * @param request QueryTraceAbJobListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryTraceAbJobListResponse
 */
async function queryTraceAbJobListWithOptions(request: QueryTraceAbJobListRequest, runtime: $RuntimeOptions): QueryTraceAbJobListResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.createTimeEnd)) {
    query['CreateTimeEnd'] = request.createTimeEnd;
  }
  if (!$isNull(request.createTimeStart)) {
    query['CreateTimeStart'] = request.createTimeStart;
  }
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.traceMediaId)) {
    query['TraceMediaId'] = request.traceMediaId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'QueryTraceAbJobList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 查询视频溯源水印ab流任务
 *
 * @param request QueryTraceAbJobListRequest
 * @return QueryTraceAbJobListResponse
 */
async function queryTraceAbJobList(request: QueryTraceAbJobListRequest): QueryTraceAbJobListResponse {
  var runtime = new $RuntimeOptions{};
  return queryTraceAbJobListWithOptions(request, runtime);
}

model QueryTraceExtractJobRequest {
  jobId?: string(name='JobId', description='This parameter is required.', example='31fa3c9ca8134fb4b0b0f7878301****'),
}

model QueryTraceExtractJobResponseBody = {
  data?: {
    trace?: string(name='Trace'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  statusCode?: long(name='StatusCode', example='200'),
}

model QueryTraceExtractJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryTraceExtractJobResponseBody(name='body'),
}

/**
 * @summary 查询溯源水印提取任务
 *
 * @param request QueryTraceExtractJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryTraceExtractJobResponse
 */
async function queryTraceExtractJobWithOptions(request: QueryTraceExtractJobRequest, runtime: $RuntimeOptions): QueryTraceExtractJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'QueryTraceExtractJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 查询溯源水印提取任务
 *
 * @param request QueryTraceExtractJobRequest
 * @return QueryTraceExtractJobResponse
 */
async function queryTraceExtractJob(request: QueryTraceExtractJobRequest): QueryTraceExtractJobResponse {
  var runtime = new $RuntimeOptions{};
  return queryTraceExtractJobWithOptions(request, runtime);
}

model QueryTraceM3u8JobListRequest {
  createTimeEnd?: long(name='CreateTimeEnd', example='1627357325'),
  createTimeStart?: long(name='CreateTimeStart', example='1627357322'),
  jobId?: string(name='JobId', example='****20b48fb04483915d4f2cd8ac****'),
  pageNumber?: long(name='PageNumber', example='0'),
  pageSize?: long(name='PageSize', example='10'),
}

model QueryTraceM3u8JobListResponseBody = {
  data?: [ 
    {
      gmtCreate?: long(name='GmtCreate', example='1627357322'),
      gmtModified?: long(name='GmtModified', example='1627357322'),
      jobId?: string(name='JobId', example='****d718e2ff4f018ccf419a7b71****'),
      output?: {
        media?: string(name='Media', example='oss://bucket/object'),
        type?: string(name='Type', example='OSS'),
      }(name='Output'),
      status?: string(name='Status', example='success'),
      trace?: string(name='Trace', example='test'),
      traceMediaId?: string(name='TraceMediaId', example='****437bd2b105d07b12a9a82****'),
      userData?: string(name='UserData', example='112'),
      userId?: long(name='UserId', example='1346693276****'),
    }
  ](name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='******11-DB8D-4A9A-875B-275798******'),
  statusCode?: long(name='StatusCode', example='200'),
}

model QueryTraceM3u8JobListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: QueryTraceM3u8JobListResponseBody(name='body'),
}

/**
 * @summary 查询视频溯源水印m3u8任务
 *
 * @param request QueryTraceM3u8JobListRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return QueryTraceM3u8JobListResponse
 */
async function queryTraceM3u8JobListWithOptions(request: QueryTraceM3u8JobListRequest, runtime: $RuntimeOptions): QueryTraceM3u8JobListResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.createTimeEnd)) {
    query['CreateTimeEnd'] = request.createTimeEnd;
  }
  if (!$isNull(request.createTimeStart)) {
    query['CreateTimeStart'] = request.createTimeStart;
  }
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'QueryTraceM3u8JobList',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 查询视频溯源水印m3u8任务
 *
 * @param request QueryTraceM3u8JobListRequest
 * @return QueryTraceM3u8JobListResponse
 */
async function queryTraceM3u8JobList(request: QueryTraceM3u8JobListRequest): QueryTraceM3u8JobListResponse {
  var runtime = new $RuntimeOptions{};
  return queryTraceM3u8JobListWithOptions(request, runtime);
}

model RefreshUploadMediaRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***'),
}

model RefreshUploadMediaResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='c2e77390f75271ec802f0674a2ce6***'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  uploadAddress?: string(name='UploadAddress', description='The upload URL.

>  The returned upload URL is a Base64-encoded URL. You must decode the Base64-encoded upload URL before you use an SDK or call an API operation to upload media files. You need to parse UploadAddress only if you use Object Storage Service (OSS) SDK or call an OSS API operation to upload media files.', example='eyJFbmRwb2ludCI6Imh0dHBzOi8vb3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbSIsIkJ1Y2tldCI6InN6aGQtdmlkZW8iLCJGaWxlTmFtZSI6InZvZC0yOTYzMWEvc3YvNTBmYTJlODQtMTgxMjdhZGRiMTcvNTBmYTJlODQtMTgxMjdhZGRiM***'),
  uploadAuth?: string(name='UploadAuth', description='The upload credential.

>  The returned upload credential is a Base64-encoded value. You must decode the Base64-encoded upload credential before you use an SDK or call an API operation to upload media files. You need to parse UploadAuth only if you use OSS SDK or call an OSS API operation to upload media files.', example='eyJBY2Nlc3NLZXlJZCI6IkxUQUk0Rm53bTk1dHdxQjMxR3IzSE5hRCIsIkFjY2Vzc0tleVNlY3JldCI6Ik9lWllKR0dTMTlkNkZaM1E3UVpJQmdmSVdnM3BPaiIsIkV4cGlyYXRpb24iOiI***'),
}

model RefreshUploadMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RefreshUploadMediaResponseBody(name='body'),
}

/**
 * @summary Obtain a new upload credential for a media asset after its upload credential expires.
 *
 * @description You can also call this operation to overwrite media files. After you obtain the upload URL of a media file, you can upload the media file again without changing the audio or video ID.
 *
 * @param request RefreshUploadMediaRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return RefreshUploadMediaResponse
 */
async function refreshUploadMediaWithOptions(request: RefreshUploadMediaRequest, runtime: $RuntimeOptions): RefreshUploadMediaResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'RefreshUploadMedia',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Obtain a new upload credential for a media asset after its upload credential expires.
 *
 * @description You can also call this operation to overwrite media files. After you obtain the upload URL of a media file, you can upload the media file again without changing the audio or video ID.
 *
 * @param request RefreshUploadMediaRequest
 * @return RefreshUploadMediaResponse
 */
async function refreshUploadMedia(request: RefreshUploadMediaRequest): RefreshUploadMediaResponse {
  var runtime = new $RuntimeOptions{};
  return refreshUploadMediaWithOptions(request, runtime);
}

model RegisterMediaInfoRequest {
  businessType?: string(name='BusinessType', description='The business type of the media asset. Valid values:

*   subtitles
*   watermark
*   opening
*   ending
*   general', example='opening'),
  cateId?: long(name='CateId', description='The category ID.', example='3048'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request. The value must be a UUID that contains 32 characters.', example='****0311a423d11a5f7dee713535****'),
  coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png'),
  description?: string(name='Description', description='The description of the media asset.

*   The value can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultDescription'),
  inputURL?: string(name='InputURL', description='The URL of the media asset in another service. The URL is associated with the ID of the media asset in IMS. The URL cannot be modified once registered. The following types of URLs are supported:

*   OSS URL in one of the following formats:

http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4

oss://example-bucket/example.mp4: In this format, it is considered by default that the region of the OSS bucket in which the media asset resides is the same as the region in which IMS is activated.

*   URL of an ApsaraVideo VOD media asset

vod://\\\\*\\\\*\\\\*20b48fb04483915d4f2cd8ac\\\\*\\\\*\\\\*\\\\*

This parameter is required.'),
  mediaTags?: string(name='MediaTags', description='The tags of the media asset.

*   Up to 16 tags are supported.
*   Separate multiple tags with commas (,).
*   Each tag can be up to 32 bytes in length.
*   The value must be encoded in UTF-8.', example='tag1,tag2'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

*   image
*   video
*   audio
*   text

We recommend that you specify this parameter based on your business requirements. If you set InputURL to an OSS URL, the media asset type can be automatically determined based on the file name extension. For more information
<props="china">, see [File formats](https://help.aliyun.com/document_detail/466207.html).', example='video'),
  overwrite?: boolean(name='Overwrite', description='Specifies whether to overwrite the media asset that has been registered by using the same URL. Default value: false. Valid values:

\\\\- true: If a media asset has been registered by using the same URL, the original media asset is deleted and the new media asset is registered.

\\\\- false: If a media asset has been registered by using the same URL, the new media asset is not registered. A URL cannot be used to register multiple media assets.', example='true'),
  referenceId?: string(name='ReferenceId', description='The custom ID. The ID can be 6 to 64 characters in length and can contain only letters, digits, hyphens (-), and underscores (_). Make sure that the ID is unique among users.', example='123-123'),
  registerConfig?: string(name='RegisterConfig', description='The registration configurations.

By default, a sprite is generated for the media asset. You can set NeedSprite to false to disable automatic sprite generation.

By default, a snapshot is generated for the media asset. You can set NeedSnapshot to false to disable automatic snapshot generation.', example='{
      "NeedSprite": "false"
}'),
  smartTagTemplateId?: string(name='SmartTagTemplateId', description='The ID of the smart tagging template. Valid values:

*   S00000101-300080: the system template that supports natural language processing (NLP) for content recognition.
*   S00000103-000001: the system template that supports NLP for content recognition and all tagging capabilities.
*   S00000103-000002: the system template that supports all tagging capabilities but does not support NLP for content recognition.

After you configure this parameter, a smart tag analysis task is automatically initiated after the media asset is registered. For more information about the billable items<props="china">, see [Smart tagging](https://help.aliyun.com/zh/ims/media-ai-billing?spm=a2c4g.11186623.0.0.3147392dWwlSjL#p-k38-3rb-dug).', example='S00000101-300080'),
  title?: string(name='Title', description='The title. If you do not specify this parameter, a default title is automatically generated based on the date.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultTitle'),
  userData?: string(name='UserData', description='The user data. You can specify a custom callback URL. For more information<props="china"> ,see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).

*   The value can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.
*   The value must be in the JSON format.'),
  workflowId?: string(name='WorkflowId', description='The workflow ID.', example='******b4fb044839815d4f2cd8******'),
}

model RegisterMediaInfoResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset in IMS.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The request ID.', example='******5A-CAAC-4850-A3AF-B74606******'),
}

model RegisterMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RegisterMediaInfoResponseBody(name='body'),
}

/**
 * @summary Registers a media asset with Intelligent Media Services (IMS). IMS assigns an ID to the media asset. This operation asynchronously accesses the media asset service in which the media asset is stored to obtain the file information of the media asset based on the input URL. You can also specify basic information, such as the title, tags, and description, for the media asset. This operation returns the ID of the media asset. You can call the GetMediaInfo operation based on the ID to query the details of the media asset. You can set InputURL only to the URL of an Object Storage Service (OSS) file or an ApsaraVideo VOD media asset.
 *
 * @description Registering a media asset is an asynchronous job that takes 2 to 3 seconds. When the operation returns the ID of the media asset, the registration may have not be completed. If you call the GetMediaInfo operation at this time, you may fail to obtain the information about the media asset.
 *
 * @param request RegisterMediaInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return RegisterMediaInfoResponse
 */
async function registerMediaInfoWithOptions(request: RegisterMediaInfoRequest, runtime: $RuntimeOptions): RegisterMediaInfoResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.businessType)) {
    query['BusinessType'] = request.businessType;
  }
  if (!$isNull(request.cateId)) {
    query['CateId'] = request.cateId;
  }
  if (!$isNull(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!$isNull(request.coverURL)) {
    query['CoverURL'] = request.coverURL;
  }
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.inputURL)) {
    query['InputURL'] = request.inputURL;
  }
  if (!$isNull(request.mediaTags)) {
    query['MediaTags'] = request.mediaTags;
  }
  if (!$isNull(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!$isNull(request.overwrite)) {
    query['Overwrite'] = request.overwrite;
  }
  if (!$isNull(request.referenceId)) {
    query['ReferenceId'] = request.referenceId;
  }
  if (!$isNull(request.registerConfig)) {
    query['RegisterConfig'] = request.registerConfig;
  }
  if (!$isNull(request.smartTagTemplateId)) {
    query['SmartTagTemplateId'] = request.smartTagTemplateId;
  }
  if (!$isNull(request.title)) {
    query['Title'] = request.title;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  if (!$isNull(request.workflowId)) {
    query['WorkflowId'] = request.workflowId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'RegisterMediaInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Registers a media asset with Intelligent Media Services (IMS). IMS assigns an ID to the media asset. This operation asynchronously accesses the media asset service in which the media asset is stored to obtain the file information of the media asset based on the input URL. You can also specify basic information, such as the title, tags, and description, for the media asset. This operation returns the ID of the media asset. You can call the GetMediaInfo operation based on the ID to query the details of the media asset. You can set InputURL only to the URL of an Object Storage Service (OSS) file or an ApsaraVideo VOD media asset.
 *
 * @description Registering a media asset is an asynchronous job that takes 2 to 3 seconds. When the operation returns the ID of the media asset, the registration may have not be completed. If you call the GetMediaInfo operation at this time, you may fail to obtain the information about the media asset.
 *
 * @param request RegisterMediaInfoRequest
 * @return RegisterMediaInfoResponse
 */
async function registerMediaInfo(request: RegisterMediaInfoRequest): RegisterMediaInfoResponse {
  var runtime = new $RuntimeOptions{};
  return registerMediaInfoWithOptions(request, runtime);
}

model RegisterMediaStreamRequest {
  inputURL?: string(name='InputURL', description='The URL of the media asset in another service. The URL is associated with the ID of the media asset in IMS. The URL cannot be modified once registered.

Set this parameter to the OSS URL of the media asset. The following formats are supported:

http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4

oss://example-bucket/example.mp4: In this format, it is considered by default that the region of the OSS bucket in which the media asset resides is the same as the region in which IMS is activated.'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='5e778ec0027b71ed80a8909598506***'),
  userData?: string(name='UserData', description='The user data.', example='{"MessageCallback":{"CallbackURL":"http://test.test.com"}, "Extend":{"localId":"xxx","test":"www"}}'),
}

model RegisterMediaStreamResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='5e778ec0027b71ed80a8909598506302'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model RegisterMediaStreamResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RegisterMediaStreamResponseBody(name='body'),
}

/**
 * @summary Registers a media stream.
 *
 * @description You can call this operation to register a media stream file in an Object Storage Service (OSS) bucket with Intelligent Media Services (IMS) and associate the media stream with the specified media asset ID.
 *
 * @param request RegisterMediaStreamRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return RegisterMediaStreamResponse
 */
async function registerMediaStreamWithOptions(request: RegisterMediaStreamRequest, runtime: $RuntimeOptions): RegisterMediaStreamResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.inputURL)) {
    query['InputURL'] = request.inputURL;
  }
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'RegisterMediaStream',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Registers a media stream.
 *
 * @description You can call this operation to register a media stream file in an Object Storage Service (OSS) bucket with Intelligent Media Services (IMS) and associate the media stream with the specified media asset ID.
 *
 * @param request RegisterMediaStreamRequest
 * @return RegisterMediaStreamResponse
 */
async function registerMediaStream(request: RegisterMediaStreamRequest): RegisterMediaStreamResponse {
  var runtime = new $RuntimeOptions{};
  return registerMediaStreamWithOptions(request, runtime);
}

model SearchEditingProjectRequest {
  createSource?: string(name='CreateSource', description='The source of the project.

\\\\-OpenAPI

\\\\-AliyunConsole

\\\\-WebSDK

Valid values:

*   AliyunConsole: The project is created in the Alibaba Cloud console.
*   WebSDK: The project is created by using the SDK for Web.
*   OpenAPI: The project is created by calling API operations.', example='WebSDK'),
  endTime?: string(name='EndTime', description='The end of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-01-11T12:00:00Z'),
  pageNo?: long(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10'),
  projectType?: string(name='ProjectType', description='The type of the editing project. Default value: EditingProject. Valid values:

*   EditingProject: a regular editing project.
*   LiveEditingProject: a live stream editing project.', example='EditingProject'),
  sortBy?: string(name='SortBy', description='The sorting rule of results. Valid values:

\\\\- CreationTime:Desc (default): The results are sorted in reverse chronological order based on the creation time.

\\\\- CreationTime:Asc: The results are sorted in chronological order based on the creation time.', example='CreationTime:Desc'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-01-11T12:00:00Z'),
  status?: string(name='Status', description='The status of the online editing project. Separate multiple values with commas (,). By default, all online editing projects are queried.

Valid values:

\\\\-Draft

\\\\-Producing

\\\\-Produced

\\\\-ProduceFailed', example='Producing'),
  templateType?: string(name='TemplateType', description='The template type. Valid values:

\\\\-Timeline

\\\\-VETemplate

Valid values:

*   Timeline: regular template.
*   VETemplate: advanced template.
*   None: No template is used.', example='Timeline'),
}

model SearchEditingProjectResponseBody = {
  maxResults?: long(name='MaxResults', description='The maximum number of entries returned on a single page. The value is set to the maximum number of entries returned on each page except for the last page.

Examples:

Valid example: 10,10,5. Invalid example: 10,5,10.', example='10'),
  nextToken?: string(name='NextToken', description='A pagination token. It can be used in the next request to retrieve a new page of results. If NextToken is empty, no next page exists.', example='null'),
  projectList?: [ 
    {
      businessConfig?: string(name='BusinessConfig', description='The business configuration of the project. This parameter can be ignored for general editing projects.', example='{ "OutputMediaConfig" : { "StorageLocation": "test-bucket.oss-cn-shanghai.aliyuncs.com", "Path": "test-path" }, "OutputMediaTarget": "oss-object", "ReservationTime": "2021-06-21T08:05:00Z" }'),
      businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

Valid values:

*   BroadCasting:
*   ReservationCanceled
*   LiveFinished
*   LoadingFailed
*   Reserving', example='Reserving'),
      coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example-cover.jpg'),
      createSource?: string(name='CreateSource', description='The method for editing the online editing project.

\\\\-OpenAPI

\\\\-AliyunConsole

\\\\-WebSDK

Valid values:

*   AliyunConsole: The project is created in the Alibaba Cloud console.
*   WebSDK: The project is created by using the SDK for Web.
*   OpenAPI: The project is created by calling API operations.', example='OpenAPI'),
      createTime?: string(name='CreateTime', description='The time when the online editing project was created.', example='2017-01-11T12:00:00Z'),
      description?: string(name='Description', description='The description of the online editing project.', example='sample description'),
      duration?: long(name='Duration', description='The total length of the online editing project. Unit: seconds.', example='30.100000'),
      errorCode?: string(name='ErrorCode', description='The error code returned if the production of the online editing project failed.', example='InvalidParameter'),
      errorMessage?: string(name='ErrorMessage', description='The error message returned if the production of the online editing project failed.', example='"EventTime":"2021-08-12T10:04:15Z","ErrorCode":"InvalidParameter","ErrorMessage":"The specified parameter \\\\"LiveStreamConfig\\\\" is not valid. specified parameter example is not valid.'),
      modifiedSource?: string(name='ModifiedSource', description='The method used when the online editing project was last modified.', example='2017-01-11T12:00:00Z'),
      modifiedTime?: string(name='ModifiedTime', description='The time when the online editing project was last modified.', example='2017-01-11T12:00:00Z'),
      projectId?: string(name='ProjectId', description='The ID of the online editing project.', example='****fddd7748b58bf1d47e95****'),
      projectType?: string(name='ProjectType', description='The type of the editing project.

Valid values:

*   LiveEditingProject: a live stream editing project.
*   EditingProject: a regular editing project.', example='EditingProject'),
      status?: string(name='Status', description='The status of the online editing project. Valid values:

\\\\-Draft

\\\\-Editing

\\\\-Producing

\\\\-Produced

\\\\-ProduceFailed

Valid values:

*   Draft
*   Produced
*   Editing
*   Producing
*   ProduceFailed', example='PRODUCE_FAILED'),
      templateType?: string(name='TemplateType', description='The type of the template.', example='Timeline'),
      timeline?: string(name='Timeline', description='The timeline of the online editing project.', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
      title?: string(name='Title', description='The title of the online editing project.', example='title'),
    }
  ](name='ProjectList', description='The queried online editing projects.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****9262E3DA-07FA-4862-FCBB6BC61D08*****'),
  totalCount?: long(name='TotalCount', description='Optional. The total number of entries returned. By default, this parameter is not returned.', example='110'),
}

model SearchEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchEditingProjectResponseBody(name='body'),
}

/**
 * @summary Queries online editing projects by creation time and status.
 *
 * @param request SearchEditingProjectRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchEditingProjectResponse
 */
async function searchEditingProjectWithOptions(request: SearchEditingProjectRequest, runtime: $RuntimeOptions): SearchEditingProjectResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.createSource)) {
    query['CreateSource'] = request.createSource;
  }
  if (!$isNull(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.projectType)) {
    query['ProjectType'] = request.projectType;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  if (!$isNull(request.templateType)) {
    query['TemplateType'] = request.templateType;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SearchEditingProject',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries online editing projects by creation time and status.
 *
 * @param request SearchEditingProjectRequest
 * @return SearchEditingProjectResponse
 */
async function searchEditingProject(request: SearchEditingProjectRequest): SearchEditingProjectResponse {
  var runtime = new $RuntimeOptions{};
  return searchEditingProjectWithOptions(request, runtime);
}

model SearchIndexJobRerunRequest {
  mediaIds?: string(name='MediaIds', description='The ID of the media asset. Separate multiple IDs with commas (,).

This parameter is required.', example='******b48fb04483915d4f2cd8******,******c48fb37407365d4f2cd8******'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='test-1'),
  task?: string(name='Task', description='The type of the job. Separate multiple types with commas (,).

*   aiLabel: smart tagging.
*   face: face recognition.
*   mm: large visual model.', example='AiLabel,Face,Mm'),
}

model SearchIndexJobRerunResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  data?: {
    mediaIdsNoExist?: [ string ](name='MediaIdsNoExist', description='The media asset IDs that do not exist.'),
  }(name='Data', description='The response data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request is successful. Valid values:

*   true
*   false', example='true'),
}

model SearchIndexJobRerunResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchIndexJobRerunResponseBody(name='body'),
}

/**
 * @summary Re-analyzes the search index jobs of media assets. You can re-run the search index jobs of up to 20 media assets in each request.
 *
 * @param request SearchIndexJobRerunRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchIndexJobRerunResponse
 */
async function searchIndexJobRerunWithOptions(request: SearchIndexJobRerunRequest, runtime: $RuntimeOptions): SearchIndexJobRerunResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaIds)) {
    query['MediaIds'] = request.mediaIds;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  if (!$isNull(request.task)) {
    query['Task'] = request.task;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SearchIndexJobRerun',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Re-analyzes the search index jobs of media assets. You can re-run the search index jobs of up to 20 media assets in each request.
 *
 * @param request SearchIndexJobRerunRequest
 * @return SearchIndexJobRerunResponse
 */
async function searchIndexJobRerun(request: SearchIndexJobRerunRequest): SearchIndexJobRerunResponse {
  var runtime = new $RuntimeOptions{};
  return searchIndexJobRerunWithOptions(request, runtime);
}

model SearchMediaRequest {
  entityId?: string(name='EntityId', description='The ID of the entity.', example='2d3bf1e35a1e42b5ab338d701efa7603'),
  match?: string(name='Match', description='The filter conditions. For more information about the parameter syntax
<props="china">, see [Media asset search protocols](https://help.aliyun.com/document_detail/2584256.html).'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='20'),
  scrollToken?: string(name='ScrollToken', description='The pagination identifier. The value can be up to 32 characters in length. The first time you call this operation for each new search, you do not need to specify this parameter. The value of this parameter is returned each time data records that meet the specified filter condition are found. The value is used to record the current position of queried data. Record the returned parameter value and set this parameter according to the following requirements during the next search: If you need to traverse all data that meets the filter criteria, you must set the ScrollToken parameter. If the value of the PageNo parameter exceeds 200, we recommend that you set this parameter to optimize search performance. You can only page backward. You can page a maximum of 1,000 entries in an operation.', example='F8C4F642184DBDA5D93907A70AAE****'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='test-1'),
  sortBy?: string(name='SortBy', description='The sort field and order. Separate multiple parameters with commas (,).', example='utcCreate:Desc, utcModified:Desc'),
}

model SearchMediaResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaInfoList?: [ 
    {
      aiData?: {
        aiLabelInfo?: [ 
          {
            category?: string(name='Category', description='The category.'),
            faceId?: string(name='FaceId', description='The face ID.', example='5FE19530C7A422197535FE74F5DB2B9F'),
            labelId?: string(name='LabelId', description='The ID of the entity.', example='10310250338'),
            labelName?: string(name='LabelName', description='The name of the entity.'),
            labelType?: string(name='LabelType', description='The type of the tag.'),
            occurrences?: [ 
              {
                content?: string(name='Content', description='The text content.'),
                finegrainId?: string(name='FinegrainId', description='The fine-grained ID of the entity.', example='10310250338'),
                finegrainName?: string(name='FinegrainName', description='The fine-grained name of the entity.'),
                from?: double(name='From', description='The start time of the clip.', example='1.4'),
                image?: string(name='Image', description='The optimal face image encoded in Base64.', example='99C64F6287'),
                score?: double(name='Score', description='The score.', example='0.75287705'),
                tableBatchSeqId?: string(name='TableBatchSeqId', description='The sequence ID of the vector table.', example='85010D1'),
                to?: double(name='To', description='The end time of the clip.', example='2.5'),
                tracks?: [ 
                  {
                    position?: string(name='Position', description='The coordinates of the bounding box.', example='468.0;67.0;615.0;267.0'),
                    size?: double(name='Size', description='The size of the bounding box.', example='50.2'),
                    timestamp?: double(name='Timestamp', description='The timestamp of the track.', example='1.4'),
                  }
                ](name='Tracks', description='The track sequence.'),
                clipId?: string(name='clipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB2B9F'),
              }
            ](name='Occurrences', description='The clips.'),
            source?: string(name='Source', description='The source.', example='vision'),
          }
        ](name='AiLabelInfo', description='The tags of the intelligent AI job.'),
        asrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB2B9F'),
            content?: string(name='Content', description='The text content.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='AsrInfo', description='The information about audio files.'),
        ocrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB2B9F'),
            content?: string(name='Content', description='The text content.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='OcrInfo', description='The subtitles.'),
      }(name='AiData', description='The details of the intelligent AI job.'),
      aiRoughData?: {
        aiCategory?: string(name='AiCategory', description='TV Series', example='TV series'),
        aiJobId?: string(name='AiJobId', description='The ID of the AI job.', example='cd35b0b0025f71edbfcb472190a9xxxx'),
        result?: string(name='Result', description='The results of the AI job.', example='http://xxxx.json'),
        saveType?: string(name='SaveType', description='The save type.', example='TEXT'),
        status?: string(name='Status', description='The data status.', example='SaveSuccess'),
      }(name='AiRoughData', description='The description of the AI job.'),
      fileInfoList?: [ 
        {
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The bitrate of the file.', example='1912.13'),
            createTime?: string(name='CreateTime', description='The time when the file was created.', example='2022-05-30T02:02:17Z'),
            duration?: string(name='Duration', description='The duration of the file.', example='60.00000'),
            fileName?: string(name='FileName', description='The name of the file.', example='164265080291300080527050.wav'),
            fileSize?: string(name='FileSize', description='The size of the file in bytes.', example='324784'),
            fileStatus?: string(name='FileStatus', description='The status of the file.', example='Normal'),
            fileType?: string(name='FileType', description='The type of the file.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The Object Storage Service (OSS) URL of the file.', example='https://outin-d3f4681ddfd911ec99a600163e1403e7.oss-cn-shanghai.aliyuncs.com/sv/23d5cdd1-18180984899/23d5cdd1-18180984899.mp4'),
            formatName?: string(name='FormatName', description='The encapsulation format of the file.', example='mov,mp4,m4a,3gp,3g2,mj2'),
            height?: string(name='Height', description='The height of the file.', example='480'),
            modifiedTime?: string(name='ModifiedTime', description='The time when the file was last modified.', example='2021-12-10T12:19Z'),
            region?: string(name='Region', description='The region in which the file is stored.', example='cn-beijing'),
            width?: string(name='Width', description='The width of the file.', example='1920'),
          }(name='FileBasicInfo', description='The basic information about the file, such as the duration and size.'),
        }
      ](name='FileInfoList', description='The information about the files.'),
      indexStatusList?: [ 
        {
          indexStatus?: string(name='IndexStatus', example='Success'),
          indexType?: string(name='IndexType', example='mm'),
        }
      ](name='IndexStatusList'),
      mediaBasicInfo?: {
        biz?: string(name='Biz', description='The business to which the media asset belongs.', example='IMS'),
        businessType?: string(name='BusinessType', description='The business type of the media asset.', example='opening'),
        cateId?: long(name='CateId', description='The ID of the category.', example='44'),
        cateName?: string(name='CateName', description='The name of the category.'),
        category?: string(name='Category', description='The category of the media asset.', example='image'),
        coverURL?: string(name='CoverURL', description='The thumbnail URL of the media asset.', example='https://dtlive-bj.oss-cn-beijing.aliyuncs.com/cover/e694372e-4f5b-4821-ae09-efd064f27b63_large_cover_url.jpg'),
        createTime?: string(name='CreateTime', description='The time when the media asset was created.', example='2020-12-01T19:48Z'),
        deletedTime?: string(name='DeletedTime', description='The time when the media asset was deleted.', example='2020-12-01T19:48Z'),
        description?: string(name='Description', description='The description of the media asset.'),
        inputURL?: string(name='InputURL', description='The address of the media asset that is waiting to be registered.', example='oss://clipres/longvideo/material/voice/prod/20220418/07d7c799f6054dc3bbef250854cf84981650248140427'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='132bd600fc3c71ec99476732a78f6402'),
        mediaTags?: string(name='MediaTags', description='The tags of the media asset.', example='tags,tags2'),
        mediaType?: string(name='MediaType', description='The type of the media asset.', example='video'),
        modifiedTime?: string(name='ModifiedTime', description='The time when the media asset was modified.', example='2020-12-01T19:48Z'),
        referenceId?: string(name='ReferenceId', description='The custom ID of the media asset. The ID is a string that contains 6 to 64 characters. Only letters, digits, hyphens (-), and underscores (_) are supported. Each custom ID is unique.', example='123-123'),
        snapshots?: string(name='Snapshots', description='The snapshots of the media asset.', example='[{"bucket":"example-bucket","count":"3","iceJobId":"******f48f0e4154976b2b8c45******","location":"oss-cn-beijing","snapshotRegular":"example.jpg","templateId":"******e6a6440b29eb60bd7c******"}]'),
        source?: string(name='Source', description='The source of the media asset.', example='oss'),
        spriteImages?: string(name='SpriteImages', description='The image sprite of the media asset', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
        status?: string(name='Status', description='The state of the media asset.', example='Normal'),
        title?: string(name='Title', description='The title of the media asset.'),
        transcodeStatus?: string(name='TranscodeStatus', description='The transcoding status of the media asset.', example='Init'),
        uploadSource?: string(name='UploadSource', description='The upload source of the media asset.', example='general'),
        userData?: string(name='UserData', description='The user data.', example='userData'),
      }(name='MediaBasicInfo', description='The basic information about the media asset.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='3b187b3620c8490886cfc2a9578c3ce6'),
    }
  ](name='MediaInfoList', description='The media assets that meet the requirements.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='6F61C357-ACC0-57FB-876E-D58795335E59'),
  scrollToken?: string(name='ScrollToken', description='The pagination identifier.', example='F8C4F642184DBDA5D93907A70AAE****'),
  success?: string(name='Success', description='Indicates whether the request was successful.', example='True'),
  total?: long(name='Total', description='The total number of media assets that meet the conditions.', example='163'),
}

model SearchMediaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaResponseBody(name='body'),
}

/**
 * @summary Queries information about media assets based on the request parameters.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchMediaResponse
 */
async function searchMediaWithOptions(request: SearchMediaRequest, runtime: $RuntimeOptions): SearchMediaResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  if (!$isNull(request.match)) {
    query['Match'] = request.match;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.scrollToken)) {
    query['ScrollToken'] = request.scrollToken;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SearchMedia',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries information about media assets based on the request parameters.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaRequest
 * @return SearchMediaResponse
 */
async function searchMedia(request: SearchMediaRequest): SearchMediaResponse {
  var runtime = new $RuntimeOptions{};
  return searchMediaWithOptions(request, runtime);
}

model SearchMediaByAILabelRequest {
  matchingMode?: string(name='MatchingMode'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. This parameter is required if you want to query media asset clips.', example='****c469e944b5a856828dc2****'),
  mediaType?: string(name='MediaType', description='The type of the media assets. Valid values:

*   image
*   video
*   audio', example='video'),
  multimodalSearchType?: string(name='MultimodalSearchType', description='The type of query. Valid values:

*   PersonName: queries media assets based on character names.
*   Ocr: queries media assets based on subtitles.
*   AiCategory: queries media assets based on AI categories.
*   FullSearch (default): queries all media assets.', example='Ocr'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='20'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test-1'),
  sortBy?: string(name='SortBy', description='The sorting method of the results. Valid values:

*   CreationTime:Desc (default): sorts results in reverse chronological order.
*   CreationTime:Asc: sorts results in chronological order.', example='CreationTime:Desc'),
  specificSearch?: boolean(name='SpecificSearch', description='Specifies whether to query media asset clips. Valid values:

*   true
*   false', example='true'),
  text?: string(name='Text', description='The content that you want to query.'),
}

model SearchMediaByAILabelResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaList?: [ 
    {
      aiData?: {
        aiLabelInfo?: [ 
          {
            category?: string(name='Category', description='The category.'),
            faceId?: string(name='FaceId', description='The ID of the face.', example='5FE19530C7A422197535FE74F5DB****'),
            labelId?: string(name='LabelId', description='The ID of the entity.', example='103102503**'),
            labelName?: string(name='LabelName', description='The name of the entity.'),
            labelType?: string(name='LabelType', description='The type of the tag.'),
            occurrences?: [ 
              {
                clipId?: string(name='ClipId', description='The ID of the clip.', example='158730355E4B82257D8AA1583A58****'),
                content?: string(name='Content', description='The content of the text.'),
                finegrainId?: string(name='FinegrainId', description='The fine-grained ID of the entity.', example='103102503**'),
                finegrainName?: string(name='FinegrainName', description='The fine-grained name of the entity.'),
                from?: double(name='From', description='The start time of the clip.', example='1.4'),
                image?: string(name='Image', description='The image that contains the most face information.', example='https://service-****-public.oss-cn-hangzhou.aliyuncs.com/1563457****438522/service-image/f788974f-9595-43b2-a478-7c7a1afb****.jpg'),
                score?: double(name='Score', description='The score.', example='0.75287705'),
                tableBatchSeqId?: string(name='TableBatchSeqId', description='The sequence ID of the vector table.', example='85010D1**'),
                to?: double(name='To', description='The end time of the clip.', example='2.5'),
                tracks?: [ 
                  {
                    position?: string(name='Position', description='The coordinates of the bounding box.', example='468.0;67.0;615.0;267.0'),
                    size?: double(name='Size', description='The size of the bounding box.', example='50'),
                    timestamp?: double(name='Timestamp', description='The timestamp of the track.', example='1.4'),
                  }
                ](name='Tracks', description='The tracks.'),
              }
            ](name='Occurrences', description='The information about the clips.'),
            source?: string(name='Source', description='The source.', example='vision'),
          }
        ](name='AiLabelInfo', description='The tags of the AI job.'),
        asrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB****'),
            content?: string(name='Content', description='The content of the audio.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='AsrInfo', description='The information about audio files.'),
        ocrInfo?: [ 
          {
            clipId?: string(name='ClipId', description='The ID of the clip.', example='5FE19530C7A422197535FE74F5DB****'),
            content?: string(name='Content', description='The content of the text.'),
            from?: double(name='From', description='The start time of the clip.', example='1.4'),
            timestamp?: double(name='Timestamp', description='The timestamp of the clip.', example='1.4'),
            to?: double(name='To', description='The end time of the clip.', example='2.5'),
          }
        ](name='OcrInfo', description='The information about subtitle files.'),
      }(name='AiData', description='The details of the AI job.'),
      appId?: string(name='AppId', description='The ID of the application. Default value: app-1000000.', example='app-1000000'),
      coverUrl?: string(name='CoverUrl', description='The URL of the thumbnail.', example='http://example.aliyundoc.com/snapshot/****.jpg?auth_key=1498476426-0-0-f00b9455c49a423ce69cf4e27333****'),
      creationTime?: string(name='CreationTime', description='The time when the media asset was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:15:50Z'),
      description?: string(name='Description', description='The description of the media asset.'),
      duration?: float(name='Duration', description='The duration. Unit: seconds.', example='12.2'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='1c6ce34007d571ed94667630a6bc****'),
      modificationTime?: string(name='ModificationTime', description='The time when the media asset was updated. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2017-11-14T09:15:50Z'),
      size?: long(name='Size', description='The size of the source file. Unit: bytes.', example='10897890'),
      snapshots?: [ string ](name='Snapshots', description='The array of video snapshot URLs.'),
      status?: string(name='Status', description='The status of the video.

Valid values:

*   PrepareFail
*   UploadFail
*   Init
*   UploadSucc
*   Transcoding
*   TranscodeFail
*   Deleted
*   Normal
*   Uploading
*   Preparing
*   Blocked
*   Checking', example='Normal'),
      storageLocation?: string(name='StorageLocation', description='The storage address.', example='out-****.oss-cn-shanghai.aliyuncs.com'),
      tags?: string(name='Tags', description='The tags of the media asset.'),
      title?: string(name='Title', description='The title of the media asset.'),
    }
  ](name='MediaList', description='The media assets that contain the specified content.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: string(name='Success', description='Indicates whether the request was successful.', example='true'),
  total?: long(name='Total', description='The total number of audio and video files that meet the conditions.', example='30'),
}

model SearchMediaByAILabelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByAILabelResponseBody(name='body'),
}

/**
 * @summary Queries media assets based on character names, subtitles, or AI categories.
 *
 * @description You can call this operation to query media assets or media asset clips based on character names, subtitles, or AI categories.
 *
 * @param request SearchMediaByAILabelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchMediaByAILabelResponse
 */
async function searchMediaByAILabelWithOptions(request: SearchMediaByAILabelRequest, runtime: $RuntimeOptions): SearchMediaByAILabelResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.matchingMode)) {
    query['MatchingMode'] = request.matchingMode;
  }
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!$isNull(request.multimodalSearchType)) {
    query['MultimodalSearchType'] = request.multimodalSearchType;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!$isNull(request.specificSearch)) {
    query['SpecificSearch'] = request.specificSearch;
  }
  if (!$isNull(request.text)) {
    query['Text'] = request.text;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SearchMediaByAILabel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries media assets based on character names, subtitles, or AI categories.
 *
 * @description You can call this operation to query media assets or media asset clips based on character names, subtitles, or AI categories.
 *
 * @param request SearchMediaByAILabelRequest
 * @return SearchMediaByAILabelResponse
 */
async function searchMediaByAILabel(request: SearchMediaByAILabelRequest): SearchMediaByAILabelResponse {
  var runtime = new $RuntimeOptions{};
  return searchMediaByAILabelWithOptions(request, runtime);
}

model SearchMediaByFaceRequest {
  entityId?: string(name='EntityId', description='The ID of the entity.', example='2d3bf1e35a1e42b5ab338d701efa****'),
  faceSearchToken?: string(name='FaceSearchToken', description='The token that is used to identify the query. You can use this parameter in the SearchMediaClipByFace operation to specify the same query conditions.

This parameter is required.', example='zxtest-huangxuan-2023-3-7-V1'),
  mediaType?: string(name='MediaType', description='The type of the media asset. Valid values:

*   image
*   video', example='video'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10'),
  personImageUrl?: string(name='PersonImageUrl', description='The URL of the face image.

This parameter is required.', example='https://****.oss-cn-shanghai.aliyuncs.com/input/huangxuan****.jpg'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
}

model SearchMediaByFaceResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaInfoList?: [ 
    {
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='3b187b3620c8490886cfc2a9578c****'),
    }
  ](name='MediaInfoList', description='The media assets that meet the conditions.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='7CA7D615-CFB1-5437-9A12-2D185C3EE6CB'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
  total?: long(name='Total', description='The total number of data records that meet the specified filter condition.', example='163'),
}

model SearchMediaByFaceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByFaceResponseBody(name='body'),
}

/**
 * @summary Queries the information about media assets that are related to a specific face.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaByFaceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchMediaByFaceResponse
 */
async function searchMediaByFaceWithOptions(request: SearchMediaByFaceRequest, runtime: $RuntimeOptions): SearchMediaByFaceResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  if (!$isNull(request.faceSearchToken)) {
    query['FaceSearchToken'] = request.faceSearchToken;
  }
  if (!$isNull(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.personImageUrl)) {
    query['PersonImageUrl'] = request.personImageUrl;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SearchMediaByFace',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about media assets that are related to a specific face.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaByFaceRequest
 * @return SearchMediaByFaceResponse
 */
async function searchMediaByFace(request: SearchMediaByFaceRequest): SearchMediaByFaceResponse {
  var runtime = new $RuntimeOptions{};
  return searchMediaByFaceWithOptions(request, runtime);
}

model SearchMediaByHybridRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset. The details of the media asset are returned.', example='****c469e944b5a856828dc2****'),
  mediaType?: string(name='MediaType', example='video'),
  pageNo?: int32(name='PageNo', example='1'),
  pageSize?: int32(name='PageSize', example='20'),
  searchLibName?: string(name='SearchLibName', example='test-1'),
  text?: string(name='Text'),
}

model SearchMediaByHybridResponseBody = {
  code?: string(name='Code', example='200'),
  mediaList?: [ 
    {
      clipInfo?: [ 
        {
          from?: double(name='From', example='2'),
          score?: double(name='Score', example='0.99'),
          to?: double(name='To', example='4'),
        }
      ](name='ClipInfo'),
      mediaId?: string(name='MediaId', example='a18936e0e28771edb59ae6f6f47a****'),
    }
  ](name='MediaList'),
  requestId?: string(name='RequestId', example='******3B-0E1A-586A-AC29-742247******'),
  success?: string(name='Success', example='true'),
  total?: long(name='Total', example='30'),
}

model SearchMediaByHybridResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByHybridResponseBody(name='body'),
}

/**
 * @summary Queries media assets by using the hybrid search feature. This operation allows you to search for media assets by using natural language based on intelligent tag text search and the search capabilities of large language models (LLMs). This implements multimodal retrieval.
 *
 * @param request SearchMediaByHybridRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchMediaByHybridResponse
 */
async function searchMediaByHybridWithOptions(request: SearchMediaByHybridRequest, runtime: $RuntimeOptions): SearchMediaByHybridResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  if (!$isNull(request.text)) {
    query['Text'] = request.text;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SearchMediaByHybrid',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries media assets by using the hybrid search feature. This operation allows you to search for media assets by using natural language based on intelligent tag text search and the search capabilities of large language models (LLMs). This implements multimodal retrieval.
 *
 * @param request SearchMediaByHybridRequest
 * @return SearchMediaByHybridResponse
 */
async function searchMediaByHybrid(request: SearchMediaByHybridRequest): SearchMediaByHybridResponse {
  var runtime = new $RuntimeOptions{};
  return searchMediaByHybridWithOptions(request, runtime);
}

model SearchMediaByMultimodalRequest {
  mediaType?: string(name='MediaType', description='The type of the media assets.

Valid values:

*   image
*   video (default)', example='video'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10'),
  searchLibName?: string(name='SearchLibName', description='The search library.', example='test-1'),
  text?: string(name='Text', description='The content that you want to query. You can describe the content in natural language.'),
}

model SearchMediaByMultimodalResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaList?: [ 
    {
      clipInfo?: [ 
        {
          from?: double(name='From', description='The start time of the clip.', example='2'),
          score?: double(name='Score', description='The score.', example='1.2'),
          to?: double(name='To', description='The end time of the clip.', example='4'),
        }
      ](name='ClipInfo', description='The information about the clip.'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='a18936e0e28771edb59ae6f6f47a****'),
    }
  ](name='MediaList', description='The media assets that contain the specified content.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values: true false', example='true'),
  total?: long(name='Total', description='The total number of data records that meet the specified filter condition.', example='20'),
}

model SearchMediaByMultimodalResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaByMultimodalResponseBody(name='body'),
}

/**
 * @summary Queries media assets by using the large visual model. You can use natural language for the query.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaByMultimodalRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchMediaByMultimodalResponse
 */
async function searchMediaByMultimodalWithOptions(request: SearchMediaByMultimodalRequest, runtime: $RuntimeOptions): SearchMediaByMultimodalResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaType)) {
    query['MediaType'] = request.mediaType;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  if (!$isNull(request.text)) {
    query['Text'] = request.text;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SearchMediaByMultimodal',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries media assets by using the large visual model. You can use natural language for the query.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaByMultimodalRequest
 * @return SearchMediaByMultimodalResponse
 */
async function searchMediaByMultimodal(request: SearchMediaByMultimodalRequest): SearchMediaByMultimodalResponse {
  var runtime = new $RuntimeOptions{};
  return searchMediaByMultimodalWithOptions(request, runtime);
}

model SearchMediaClipByFaceRequest {
  entityId?: string(name='EntityId', description='The ID of the entity.', example='2d3bf1e35a1e42b5ab338d701efa****'),
  faceSearchToken?: string(name='FaceSearchToken', description='The value of this parameter is the same as that of the FaceSearchToken parameter in the SearchMediaByFace request. This specifies to return media asset clips that meet the same query conditions.

This parameter is required.', example='zxtest-huangxuan-2023-3-7-V1'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='3b187b3620c8490886cfc2a9578c****'),
  pageNo?: int32(name='PageNo', description='The page number. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 50.', example='10'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library.', example='test1'),
}

model SearchMediaClipByFaceResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaClipList?: [ 
    {
      category?: string(name='Category', description='The type of the character. Valid values: celebrity sensitive politician custom unknown', example='celebrity'),
      entityId?: string(name='EntityId', description='The ID of the entity, which is the same as the entity ID returned in tag analysis.', example='1031025****'),
      labelName?: string(name='LabelName', description='The name of the entity.'),
      occurrencesInfos?: [ 
        {
          endTime?: float(name='EndTime', description='The end time of the clip. Unit: seconds. The value is of the Float type.', example='69.06635'),
          expression?: string(name='Expression'),
          startTime?: float(name='StartTime', description='The start time of the clip. Unit: seconds. The value is of the Float type.', example='61.066353'),
          trackData?: [ 
            {
              boxPosition?: {
                h?: int32(name='H', description='The height of the rectangle frame. Unit: pixels.', example='168'),
                w?: int32(name='W', description='The width of the rectangle frame. Unit: pixels.', example='128'),
                x?: int32(name='X', description='The x-axis coordinate of the upper-left corner. Unit: pixels.', example='517'),
                y?: int32(name='Y', description='The y-axis coordinate of the upper-left corner. Unit: pixels.', example='409'),
              }(name='BoxPosition', description='The coordinates of the face.'),
              timestamp?: float(name='Timestamp', description='The timestamp when the face appears in the clip. Unit: seconds. The value is of the Float type.', example='62.03302'),
            }
          ](name='TrackData', description='The information about the face in the clip.'),
        }
      ](name='OccurrencesInfos', description='The information about clips related to the face.'),
      score?: float(name='Score', description='The score of the clip. The value is of the Float type. The value is in the range of [0,1].', example='0.99041677'),
    }
  ](name='MediaClipList', description='The media asset clips that meet the requirements.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='E44FFACD-9E90-555A-A09A-6FD3B7335E39'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values: true and false.', example='true'),
  total?: long(name='Total', description='The total number of media asset clips that meet the conditions.', example='5'),
}

model SearchMediaClipByFaceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchMediaClipByFaceResponseBody(name='body'),
}

/**
 * @summary Queries the information about media asset clips that are related to a specific face based on the response to the SearchMediaByFace operation.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaClipByFaceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchMediaClipByFaceResponse
 */
async function searchMediaClipByFaceWithOptions(request: SearchMediaClipByFaceRequest, runtime: $RuntimeOptions): SearchMediaClipByFaceResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  if (!$isNull(request.faceSearchToken)) {
    query['FaceSearchToken'] = request.faceSearchToken;
  }
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SearchMediaClipByFace',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Queries the information about media asset clips that are related to a specific face based on the response to the SearchMediaByFace operation.
 *
 * @description If you have questions about how to use the media asset search feature in Intelligent Media Services (IMS), contact technical support in the DingTalk group (ID 30415005038).
 *
 * @param request SearchMediaClipByFaceRequest
 * @return SearchMediaClipByFaceResponse
 */
async function searchMediaClipByFace(request: SearchMediaClipByFaceRequest): SearchMediaClipByFaceResponse {
  var runtime = new $RuntimeOptions{};
  return searchMediaClipByFaceWithOptions(request, runtime);
}

model SearchPublicMediaInfoRequest {
  authorized?: boolean(name='Authorized', example='true'),
  dynamicMetaDataMatchFields?: string(name='DynamicMetaDataMatchFields', example='"ApprovalStatus=\\\\"Available\\\\"&amp;MaterialBags=\\\\"boutiquemusic\\\\"&amp;Mood=\\\\"Nervous\\\\""'),
  entityId?: string(name='EntityId', example='Copyright_Music'),
  favorite?: boolean(name='Favorite', example='true'),
  mediaIds?: string(name='MediaIds', example='****20b48fb04483915d4f2cd8ac****,****15d4a4b0448391508f2cb486****'),
  pageNo?: int32(name='PageNo', example='1'),
  pageSize?: int32(name='PageSize', example='10'),
  sortBy?: string(name='SortBy', example='UsageCount:Desc,UnitPrice:Asc'),
}

model SearchPublicMediaInfoResponseBody = {
  publicMediaInfos?: [ 
    {
      authorized?: boolean(name='Authorized', example='true'),
      favorite?: boolean(name='Favorite', example='true'),
      mediaInfo?: {
        dynamicMetaData?: {
          data?: string(name='Data', example='"{\\\\"AuditionUrl\\\\": \\\\"http://xxx\\\\", \\\\"AuditionCount\\\\": 3...}"'),
          type?: string(name='Type', example='system'),
        }(name='DynamicMetaData'),
        mediaBasicInfo?: {
          businessType?: string(name='BusinessType', example='general'),
          category?: string(name='Category', example='category'),
          coverURL?: string(name='CoverURL', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png?Expires=<ExpireTime>&OSSAccessKeyId=<OSSAccessKeyId>&Signature=<Signature>&security-token=<SecurityToken>'),
          createTime?: string(name='CreateTime', example='2020-12-26T06:04:49Z'),
          deletedTime?: string(name='DeletedTime', example='2020-12-29T06:04:49Z'),
          description?: string(name='Description', example='description'),
          mediaId?: string(name='MediaId', description='MediaId', example='icepublic-****87b921bb4a55908a72a0537e****'),
          mediaTags?: string(name='MediaTags'),
          mediaType?: string(name='MediaType', example='audio'),
          modifiedTime?: string(name='ModifiedTime', example='2020-12-26T06:04:50Z'),
          source?: string(name='Source', example='oss'),
          spriteImages?: string(name='SpriteImages', example='[{"bucket":"example-bucket","count":"32","iceJobId":"******83ec44d58b2069def2e******","location":"oss-cn-shanghai","snapshotRegular":"example/example-{Count}.jpg","spriteRegular":"example/example-{TileCount}.jpg","templateId":"******e438b14ff39293eaec25******","tileCount":"1"}]'),
          status?: string(name='Status', example='Normal'),
          title?: string(name='Title', example='title'),
          userData?: string(name='UserData', example='userDataTest'),
        }(name='MediaBasicInfo', description='BasicInfo'),
        mediaId?: string(name='MediaId', example='icepublic-****87b921bb4a55908a72a0537e****'),
      }(name='MediaInfo'),
      remainingAuthTime?: string(name='RemainingAuthTime', example='100'),
    }
  ](name='PublicMediaInfos'),
  requestId?: string(name='RequestId', example='****3CFB-2767-54FD-B311-BD15A4C1****'),
  totalCount?: long(name='TotalCount', example='100'),
}

model SearchPublicMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SearchPublicMediaInfoResponseBody(name='body'),
}

/**
 * @summary 搜索公共媒资信息
 *
 * @param request SearchPublicMediaInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SearchPublicMediaInfoResponse
 */
async function searchPublicMediaInfoWithOptions(request: SearchPublicMediaInfoRequest, runtime: $RuntimeOptions): SearchPublicMediaInfoResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.authorized)) {
    query['Authorized'] = request.authorized;
  }
  if (!$isNull(request.dynamicMetaDataMatchFields)) {
    query['DynamicMetaDataMatchFields'] = request.dynamicMetaDataMatchFields;
  }
  if (!$isNull(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  if (!$isNull(request.favorite)) {
    query['Favorite'] = request.favorite;
  }
  if (!$isNull(request.mediaIds)) {
    query['MediaIds'] = request.mediaIds;
  }
  if (!$isNull(request.pageNo)) {
    query['PageNo'] = request.pageNo;
  }
  if (!$isNull(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!$isNull(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SearchPublicMediaInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 搜索公共媒资信息
 *
 * @param request SearchPublicMediaInfoRequest
 * @return SearchPublicMediaInfoResponse
 */
async function searchPublicMediaInfo(request: SearchPublicMediaInfoRequest): SearchPublicMediaInfoResponse {
  var runtime = new $RuntimeOptions{};
  return searchPublicMediaInfoWithOptions(request, runtime);
}

model SendAIAgentDataChannelMessageRequest {
  instanceId?: string(name='InstanceId', description='The ID of the AI agent in the conversation.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  message?: string(name='Message', description='The DataChannel message you want to send. You must specify a JSON string. The value can be up to 8,192 characters in length.

This parameter is required.', example='{"key":"value"}'),
}

model SendAIAgentDataChannelMessageResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model SendAIAgentDataChannelMessageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendAIAgentDataChannelMessageResponseBody(name='body'),
}

/**
 * @summary Sends a DataChannel message to an AI agent.
 *
 * @param request SendAIAgentDataChannelMessageRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SendAIAgentDataChannelMessageResponse
 */
async function sendAIAgentDataChannelMessageWithOptions(request: SendAIAgentDataChannelMessageRequest, runtime: $RuntimeOptions): SendAIAgentDataChannelMessageResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  if (!$isNull(request.message)) {
    query['Message'] = request.message;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SendAIAgentDataChannelMessage',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Sends a DataChannel message to an AI agent.
 *
 * @param request SendAIAgentDataChannelMessageRequest
 * @return SendAIAgentDataChannelMessageResponse
 */
async function sendAIAgentDataChannelMessage(request: SendAIAgentDataChannelMessageRequest): SendAIAgentDataChannelMessageResponse {
  var runtime = new $RuntimeOptions{};
  return sendAIAgentDataChannelMessageWithOptions(request, runtime);
}

model SendAIAgentSpeechRequest {
  enableInterrupt?: boolean(name='EnableInterrupt', description='Specifies whether the broadcast can interrupt the ongoing speech. Default value: true', example='true'),
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  text?: string(name='Text', description='This parameter is required.'),
}

model SendAIAgentSpeechResponseBody = {
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model SendAIAgentSpeechResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendAIAgentSpeechResponseBody(name='body'),
}

/**
 * @summary Instructs an AI agent to immediately broadcast a text message and supports interruption settings.
 *
 * @description You can call this operation to instruct an AI agent to broadcast the content that you specify. You can determine whether this broadcast can immediately interrupt the ongoing speech. The interruption is allowed by default.
 * **Note**
 * *   Make sure that the `InstanceId` is valid and corresponds to an existing AI agent.
 * *   The content of `Text` must comply with the specifications and does not contain sensitive or inappropriate information.
 * *   If you do not want the new broadcast to interrupt the ongoing speech, you must set `EnableInterrupt` to `false`.
 *
 * @param request SendAIAgentSpeechRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SendAIAgentSpeechResponse
 */
async function sendAIAgentSpeechWithOptions(request: SendAIAgentSpeechRequest, runtime: $RuntimeOptions): SendAIAgentSpeechResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.enableInterrupt)) {
    query['EnableInterrupt'] = request.enableInterrupt;
  }
  if (!$isNull(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  if (!$isNull(request.text)) {
    query['Text'] = request.text;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SendAIAgentSpeech',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Instructs an AI agent to immediately broadcast a text message and supports interruption settings.
 *
 * @description You can call this operation to instruct an AI agent to broadcast the content that you specify. You can determine whether this broadcast can immediately interrupt the ongoing speech. The interruption is allowed by default.
 * **Note**
 * *   Make sure that the `InstanceId` is valid and corresponds to an existing AI agent.
 * *   The content of `Text` must comply with the specifications and does not contain sensitive or inappropriate information.
 * *   If you do not want the new broadcast to interrupt the ongoing speech, you must set `EnableInterrupt` to `false`.
 *
 * @param request SendAIAgentSpeechRequest
 * @return SendAIAgentSpeechResponse
 */
async function sendAIAgentSpeech(request: SendAIAgentSpeechRequest): SendAIAgentSpeechResponse {
  var runtime = new $RuntimeOptions{};
  return sendAIAgentSpeechWithOptions(request, runtime);
}

model SendAIAgentTextRequest {
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='f27f9b9be28642a88e18****'),
  text?: string(name='Text', description='This parameter is required.'),
}

model SendAIAgentTextResponseBody = {
  requestId?: string(name='RequestId', example='DB488837-3****'),
}

model SendAIAgentTextResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendAIAgentTextResponseBody(name='body'),
}

/**
 * @summary 传入消息作为LLM输入。
 *
 * @param request SendAIAgentTextRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SendAIAgentTextResponse
 */
async function sendAIAgentTextWithOptions(request: SendAIAgentTextRequest, runtime: $RuntimeOptions): SendAIAgentTextResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  if (!$isNull(request.text)) {
    query['Text'] = request.text;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SendAIAgentText',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 传入消息作为LLM输入。
 *
 * @param request SendAIAgentTextRequest
 * @return SendAIAgentTextResponse
 */
async function sendAIAgentText(request: SendAIAgentTextRequest): SendAIAgentTextResponse {
  var runtime = new $RuntimeOptions{};
  return sendAIAgentTextWithOptions(request, runtime);
}

model SendLiveSnapshotJobCommandRequest {
  command?: string(name='Command', description='The operation command.

Valid values:

*   stop
*   restart
*   start

This parameter is required.', example='start'),
  jobId?: string(name='JobId', description='The ID of the snapshot job.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model SendLiveSnapshotJobCommandResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SendLiveSnapshotJobCommandResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendLiveSnapshotJobCommandResponseBody(name='body'),
}

/**
 * @summary Sends a command to process a live stream snapshot job.
 *
 * @param request SendLiveSnapshotJobCommandRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SendLiveSnapshotJobCommandResponse
 */
async function sendLiveSnapshotJobCommandWithOptions(request: SendLiveSnapshotJobCommandRequest, runtime: $RuntimeOptions): SendLiveSnapshotJobCommandResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.command)) {
    body['Command'] = request.command;
  }
  if (!$isNull(request.jobId)) {
    body['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'SendLiveSnapshotJobCommand',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Sends a command to process a live stream snapshot job.
 *
 * @param request SendLiveSnapshotJobCommandRequest
 * @return SendLiveSnapshotJobCommandResponse
 */
async function sendLiveSnapshotJobCommand(request: SendLiveSnapshotJobCommandRequest): SendLiveSnapshotJobCommandResponse {
  var runtime = new $RuntimeOptions{};
  return sendLiveSnapshotJobCommandWithOptions(request, runtime);
}

model SendLiveTranscodeJobCommandRequest {
  command?: string(name='Command', description='The operation command. Only the stop command is supported. This command is used to stop a transcoding job.

This parameter is required.', example='stop'),
  jobId?: string(name='JobId', description='The ID of the transcoding job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model SendLiveTranscodeJobCommandResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model SendLiveTranscodeJobCommandResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendLiveTranscodeJobCommandResponseBody(name='body'),
}

/**
 * @summary Sends a command to process a live stream transcoding job.
 *
 * @param request SendLiveTranscodeJobCommandRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SendLiveTranscodeJobCommandResponse
 */
async function sendLiveTranscodeJobCommandWithOptions(request: SendLiveTranscodeJobCommandRequest, runtime: $RuntimeOptions): SendLiveTranscodeJobCommandResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.command)) {
    query['Command'] = request.command;
  }
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SendLiveTranscodeJobCommand',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Sends a command to process a live stream transcoding job.
 *
 * @param request SendLiveTranscodeJobCommandRequest
 * @return SendLiveTranscodeJobCommandResponse
 */
async function sendLiveTranscodeJobCommand(request: SendLiveTranscodeJobCommandRequest): SendLiveTranscodeJobCommandResponse {
  var runtime = new $RuntimeOptions{};
  return sendLiveTranscodeJobCommandWithOptions(request, runtime);
}

model SendMessageChatTextRequest {
  AIAgentId?: string(name='AIAgentId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  mode?: string(name='Mode', example='online'),
  needArchiving?: boolean(name='NeedArchiving', example='true'),
  receiverId?: string(name='ReceiverId', description='This parameter is required.', example='60000042053'),
  sessionId?: string(name='SessionId', description='This parameter is required.', example='f27f9b9be28642a88e18****'),
  text?: string(name='Text', description='This parameter is required.'),
  type?: string(name='Type', description='This parameter is required.', example='announcement'),
}

model SendMessageChatTextResponseBody = {
  requestId?: string(name='RequestId', example='******3B-0E1A-586A-AC29-742247******'),
}

model SendMessageChatTextResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SendMessageChatTextResponseBody(name='body'),
}

/**
 * @summary 向IM客户端发送消息。
 *
 * @param request SendMessageChatTextRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SendMessageChatTextResponse
 */
async function sendMessageChatTextWithOptions(request: SendMessageChatTextRequest, runtime: $RuntimeOptions): SendMessageChatTextResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.AIAgentId)) {
    query['AIAgentId'] = request.AIAgentId;
  }
  if (!$isNull(request.mode)) {
    query['Mode'] = request.mode;
  }
  if (!$isNull(request.needArchiving)) {
    query['NeedArchiving'] = request.needArchiving;
  }
  if (!$isNull(request.receiverId)) {
    query['ReceiverId'] = request.receiverId;
  }
  if (!$isNull(request.sessionId)) {
    query['SessionId'] = request.sessionId;
  }
  if (!$isNull(request.text)) {
    query['Text'] = request.text;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SendMessageChatText',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 向IM客户端发送消息。
 *
 * @param request SendMessageChatTextRequest
 * @return SendMessageChatTextResponse
 */
async function sendMessageChatText(request: SendMessageChatTextRequest): SendMessageChatTextResponse {
  var runtime = new $RuntimeOptions{};
  return sendMessageChatTextWithOptions(request, runtime);
}

model SetContentAnalyzeConfigRequest {
  auto?: boolean(name='Auto', example='true'),
  saveType?: string(name='SaveType', example='TEXT,FACE'),
  templateId?: string(name='TemplateId', example='S00000101-100070'),
}

model SetContentAnalyzeConfigResponseBody = {
  requestId?: string(name='RequestId', example='953CFD27-4A2C-54AD-857F-B79EF3A338E0'),
  success?: boolean(name='Success', example='true'),
}

model SetContentAnalyzeConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetContentAnalyzeConfigResponseBody(name='body'),
}

/**
 * @summary 设置内容分析搜索配置
 *
 * @param request SetContentAnalyzeConfigRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SetContentAnalyzeConfigResponse
 */
async function setContentAnalyzeConfigWithOptions(request: SetContentAnalyzeConfigRequest, runtime: $RuntimeOptions): SetContentAnalyzeConfigResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.auto)) {
    query['Auto'] = request.auto;
  }
  if (!$isNull(request.saveType)) {
    query['SaveType'] = request.saveType;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SetContentAnalyzeConfig',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 设置内容分析搜索配置
 *
 * @param request SetContentAnalyzeConfigRequest
 * @return SetContentAnalyzeConfigResponse
 */
async function setContentAnalyzeConfig(request: SetContentAnalyzeConfigRequest): SetContentAnalyzeConfigResponse {
  var runtime = new $RuntimeOptions{};
  return setContentAnalyzeConfigWithOptions(request, runtime);
}

model SetDefaultCustomTemplateRequest {
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****d80e4e4044975745c14b****'),
}

model SetDefaultCustomTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model SetDefaultCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetDefaultCustomTemplateResponseBody(name='body'),
}

/**
 * @summary Sets a custom template as the default template.
 *
 * @param request SetDefaultCustomTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SetDefaultCustomTemplateResponse
 */
async function setDefaultCustomTemplateWithOptions(request: SetDefaultCustomTemplateRequest, runtime: $RuntimeOptions): SetDefaultCustomTemplateResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SetDefaultCustomTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Sets a custom template as the default template.
 *
 * @param request SetDefaultCustomTemplateRequest
 * @return SetDefaultCustomTemplateResponse
 */
async function setDefaultCustomTemplate(request: SetDefaultCustomTemplateRequest): SetDefaultCustomTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return setDefaultCustomTemplateWithOptions(request, runtime);
}

model SetDefaultStorageLocationRequest {
  bucket?: string(name='Bucket', example='oss-test-bucket'),
  path?: string(name='Path', example='ims/dir'),
  storageType?: string(name='StorageType', example='user_oss_bucket'),
}

model SetDefaultStorageLocationResponseBody = {
  requestId?: string(name='RequestId', example='******5A-CAAC-4850-A3AF-B74606******'),
  success?: boolean(name='Success', example='true'),
}

model SetDefaultStorageLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetDefaultStorageLocationResponseBody(name='body'),
}

/**
 * @summary 设置默认存储路径
 *
 * @param request SetDefaultStorageLocationRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SetDefaultStorageLocationResponse
 */
async function setDefaultStorageLocationWithOptions(request: SetDefaultStorageLocationRequest, runtime: $RuntimeOptions): SetDefaultStorageLocationResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.bucket)) {
    query['Bucket'] = request.bucket;
  }
  if (!$isNull(request.path)) {
    query['Path'] = request.path;
  }
  if (!$isNull(request.storageType)) {
    query['StorageType'] = request.storageType;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SetDefaultStorageLocation',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 设置默认存储路径
 *
 * @param request SetDefaultStorageLocationRequest
 * @return SetDefaultStorageLocationResponse
 */
async function setDefaultStorageLocation(request: SetDefaultStorageLocationRequest): SetDefaultStorageLocationResponse {
  var runtime = new $RuntimeOptions{};
  return setDefaultStorageLocationWithOptions(request, runtime);
}

model SetEventCallbackRequest {
  authKey?: string(name='AuthKey', description='The authentication key. The key can be up to 32 characters in length and must contain uppercase letters, lowercase letters, and digits. This parameter takes effect only if you set CallbackType to **HTTP**.', example='TestKey001'),
  authSwitch?: string(name='AuthSwitch', description='Specifies whether to enable callback authentication. This parameter takes effect only if you set CallbackType to **HTTP**. Valid values:

*   **on**
*   **off**', example='on'),
  callbackQueueName?: string(name='CallbackQueueName', description='The name of the Simple Message Queue (SMQ) queue in the region. The name must start with ice-callback-.', example='ice-callback-queue'),
  callbackType?: string(name='CallbackType', description='The callback method. Valid values:

*   **HTTP**
*   **MNS**', example='HTTP'),
  callbackURL?: string(name='CallbackURL', description='The callback URL. This parameter is required if you set CallbackType to **HTTP**. The callback URL cannot exceed 256 bytes in length. You can specify only one callback URL.', example='http://xxx.yyy/callback'),
  eventTypeList?: string(name='EventTypeList', description='The type of the callback event. You can specify multiple values separated with commas (,). ProduceMediaComplete: indicates that the editing and production task is complete.', example='ProduceMediaComplete'),
}

model SetEventCallbackResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the configuration was successful. Valid values: true and false.', example='true'),
}

model SetEventCallbackResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetEventCallbackResponseBody(name='body'),
}

/**
 * @summary Configures a callback method for one or more events.
 *
 * @param request SetEventCallbackRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SetEventCallbackResponse
 */
async function setEventCallbackWithOptions(request: SetEventCallbackRequest, runtime: $RuntimeOptions): SetEventCallbackResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.authKey)) {
    query['AuthKey'] = request.authKey;
  }
  if (!$isNull(request.authSwitch)) {
    query['AuthSwitch'] = request.authSwitch;
  }
  if (!$isNull(request.callbackQueueName)) {
    query['CallbackQueueName'] = request.callbackQueueName;
  }
  if (!$isNull(request.callbackType)) {
    query['CallbackType'] = request.callbackType;
  }
  if (!$isNull(request.callbackURL)) {
    query['CallbackURL'] = request.callbackURL;
  }
  if (!$isNull(request.eventTypeList)) {
    query['EventTypeList'] = request.eventTypeList;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SetEventCallback',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Configures a callback method for one or more events.
 *
 * @param request SetEventCallbackRequest
 * @return SetEventCallbackResponse
 */
async function setEventCallback(request: SetEventCallbackRequest): SetEventCallbackResponse {
  var runtime = new $RuntimeOptions{};
  return setEventCallbackWithOptions(request, runtime);
}

model SetNotifyConfigRequest {
  AIAgentId?: string(name='AIAgentId', description='The ID of the AI agent.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  callbackUrl?: string(name='CallbackUrl', description='The URL for receiving callback notifications. By default, this parameter is left empty.', example='http://customer.com/callback'),
  enableNotify?: boolean(name='EnableNotify', description='Specifies whether to enable event notifications.

This parameter is required.', example='true'),
  eventTypes?: string(name='EventTypes', description='The event types. If you do not specify this parameter, all event types are selected.

*   agent_start
*   agent_stop
*   error', example='agent_start,agent_stop,error'),
  token?: string(name='Token', description='The authentication token for callback. The token is carried in the Authorization header of a callback request. By default, this parameter is left empty.', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx'),
}

model SetNotifyConfigResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='771A1414-27BF-53E6-AB73-EFCB*****ACF'),
}

model SetNotifyConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetNotifyConfigResponseBody(name='body'),
}

/**
 * @summary Enables or disables event notifications for an AI agent and configures the callback URL and event types.
 *
 * @description ## [](#)Request description
 * You can call this operation to configure event notifications for an AI agent. You can configure `EnableNotify` to enable or disable event notifications, configure `CallbackUrl` to specify a callback URL, and configure `EventTypes` to specify event types. You can also configure `Token` to specify an authentication token for enhanced security. The system returns a unique `RequestId` for subsequent tracing after a successful request.
 *
 * @param request SetNotifyConfigRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SetNotifyConfigResponse
 */
async function setNotifyConfigWithOptions(request: SetNotifyConfigRequest, runtime: $RuntimeOptions): SetNotifyConfigResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.AIAgentId)) {
    query['AIAgentId'] = request.AIAgentId;
  }
  if (!$isNull(request.callbackUrl)) {
    query['CallbackUrl'] = request.callbackUrl;
  }
  if (!$isNull(request.enableNotify)) {
    query['EnableNotify'] = request.enableNotify;
  }
  if (!$isNull(request.eventTypes)) {
    query['EventTypes'] = request.eventTypes;
  }
  if (!$isNull(request.token)) {
    query['Token'] = request.token;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SetNotifyConfig',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Enables or disables event notifications for an AI agent and configures the callback URL and event types.
 *
 * @description ## [](#)Request description
 * You can call this operation to configure event notifications for an AI agent. You can configure `EnableNotify` to enable or disable event notifications, configure `CallbackUrl` to specify a callback URL, and configure `EventTypes` to specify event types. You can also configure `Token` to specify an authentication token for enhanced security. The system returns a unique `RequestId` for subsequent tracing after a successful request.
 *
 * @param request SetNotifyConfigRequest
 * @return SetNotifyConfigResponse
 */
async function setNotifyConfig(request: SetNotifyConfigRequest): SetNotifyConfigResponse {
  var runtime = new $RuntimeOptions{};
  return setNotifyConfigWithOptions(request, runtime);
}

model StartAIAgentInstanceRequest {
  AIAgentId?: string(name='AIAgentId', description='The ID of the AI agent created in the [IMS](https://ims.console.aliyun.com/ai/robot/list) console.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  chatSyncConfig?: {
    IMAIAgentId?: string(name='IMAIAgentId', description='IM的智能体Id。', example='******005e4f309379701645f4****'),
    receiverId?: string(name='ReceiverId', description='接收用户Id。', example='4167626d312034b2b1c3b7f2f3e41884'),
  }(name='ChatSyncConfig', description='同步聊天记录配置。'),
  runtimeConfig?: AIAgentRuntimeConfig(name='RuntimeConfig', description='This parameter is required.'),
  sessionId?: string(name='SessionId', example='f213fbc005e4f309379701645f4****'),
  templateConfig?: AIAgentTemplateConfig(name='TemplateConfig'),
  userData?: string(name='UserData', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
}

model StartAIAgentInstanceShrinkRequest {
  AIAgentId?: string(name='AIAgentId', description='The ID of the AI agent created in the [IMS](https://ims.console.aliyun.com/ai/robot/list) console.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  chatSyncConfigShrink?: string(name='ChatSyncConfig', description='同步聊天记录配置。'),
  runtimeConfigShrink?: string(name='RuntimeConfig', description='This parameter is required.'),
  sessionId?: string(name='SessionId', example='f213fbc005e4f309379701645f4****'),
  templateConfigShrink?: string(name='TemplateConfig'),
  userData?: string(name='UserData', example='{"Email":"johndoe@example.com","Preferences":{"Language":"en"}}'),
}

model StartAIAgentInstanceResponseBody = {
  instanceId?: string(name='InstanceId', example='39f8e0bc005e4f309379701645f4****'),
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model StartAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartAIAgentInstanceResponseBody(name='body'),
}

/**
 * @summary Starts an AI agent that is configured in the Intelligent Media Services (IMS) console.
 *
 * @description You can call this operation to start an AI agent instance for a conversation. ````````When the AI agent is started, the system returns a unique `InstanceId` for subsequent tracking and operations.
 *
 * @param tmpReq StartAIAgentInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StartAIAgentInstanceResponse
 */
async function startAIAgentInstanceWithOptions(tmpReq: StartAIAgentInstanceRequest, runtime: $RuntimeOptions): StartAIAgentInstanceResponse {
  tmpReq.validate();
  var request = new StartAIAgentInstanceShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.chatSyncConfig)) {
    request.chatSyncConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.chatSyncConfig, 'ChatSyncConfig', 'json');
  }
  if (!$isNull(tmpReq.runtimeConfig)) {
    request.runtimeConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.runtimeConfig, 'RuntimeConfig', 'json');
  }
  if (!$isNull(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.AIAgentId)) {
    query['AIAgentId'] = request.AIAgentId;
  }
  if (!$isNull(request.chatSyncConfigShrink)) {
    query['ChatSyncConfig'] = request.chatSyncConfigShrink;
  }
  if (!$isNull(request.runtimeConfigShrink)) {
    query['RuntimeConfig'] = request.runtimeConfigShrink;
  }
  if (!$isNull(request.sessionId)) {
    query['SessionId'] = request.sessionId;
  }
  if (!$isNull(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'StartAIAgentInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Starts an AI agent that is configured in the Intelligent Media Services (IMS) console.
 *
 * @description You can call this operation to start an AI agent instance for a conversation. ````````When the AI agent is started, the system returns a unique `InstanceId` for subsequent tracking and operations.
 *
 * @param request StartAIAgentInstanceRequest
 * @return StartAIAgentInstanceResponse
 */
async function startAIAgentInstance(request: StartAIAgentInstanceRequest): StartAIAgentInstanceResponse {
  var runtime = new $RuntimeOptions{};
  return startAIAgentInstanceWithOptions(request, runtime);
}

model StartChannelRequest {
  channelName?: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel'),
}

model StartChannelResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model StartChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartChannelResponseBody(name='body'),
}

/**
 * @summary Starts a channel.
 *
 * @param request StartChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StartChannelResponse
 */
async function startChannelWithOptions(request: StartChannelRequest, runtime: $RuntimeOptions): StartChannelResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'StartChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Starts a channel.
 *
 * @param request StartChannelRequest
 * @return StartChannelResponse
 */
async function startChannel(request: StartChannelRequest): StartChannelResponse {
  var runtime = new $RuntimeOptions{};
  return startChannelWithOptions(request, runtime);
}

model StartMediaLiveChannelRequest {
  channelId?: string(name='ChannelId', description='The ID of the channel.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
}

model StartMediaLiveChannelResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model StartMediaLiveChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartMediaLiveChannelResponseBody(name='body'),
}

/**
 * @summary Starts a MediaLive channel.
 *
 * @description *   You can call this operation only when the channel is idle. You cannot start a channel repeatedly.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you will experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request StartMediaLiveChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StartMediaLiveChannelResponse
 */
async function startMediaLiveChannelWithOptions(request: StartMediaLiveChannelRequest, runtime: $RuntimeOptions): StartMediaLiveChannelResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.channelId)) {
    body['ChannelId'] = request.channelId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'StartMediaLiveChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Starts a MediaLive channel.
 *
 * @description *   You can call this operation only when the channel is idle. You cannot start a channel repeatedly.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you will experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request StartMediaLiveChannelRequest
 * @return StartMediaLiveChannelResponse
 */
async function startMediaLiveChannel(request: StartMediaLiveChannelRequest): StartMediaLiveChannelResponse {
  var runtime = new $RuntimeOptions{};
  return startMediaLiveChannelWithOptions(request, runtime);
}

model StartRtcRobotInstanceRequest {
  authToken?: string(name='AuthToken', description='This parameter is required.', example='**********'),
  channelId?: string(name='ChannelId', description='This parameter is required.', example='testId'),
  config?: {
    asrMaxSilence?: int32(name='AsrMaxSilence'),
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt', example='true'),
    greeting?: string(name='Greeting'),
    useVoiceprint?: boolean(name='UseVoiceprint'),
    userOfflineTimeout?: int32(name='UserOfflineTimeout'),
    userOnlineTimeout?: int32(name='UserOnlineTimeout'),
    voiceId?: string(name='VoiceId', example='zhixiaoxia'),
    voiceprintId?: string(name='VoiceprintId'),
    volume?: long(name='Volume'),
  }(name='Config'),
  robotId?: string(name='RobotId', description='This parameter is required.', example='ca28b08ad3464ebcb42e5c0f7c6d2e89'),
  userData?: string(name='UserData', example='{}'),
  userId?: string(name='UserId', description='This parameter is required.', example='my-robot'),
}

model StartRtcRobotInstanceShrinkRequest {
  authToken?: string(name='AuthToken', description='This parameter is required.', example='**********'),
  channelId?: string(name='ChannelId', description='This parameter is required.', example='testId'),
  configShrink?: string(name='Config'),
  robotId?: string(name='RobotId', description='This parameter is required.', example='ca28b08ad3464ebcb42e5c0f7c6d2e89'),
  userData?: string(name='UserData', example='{}'),
  userId?: string(name='UserId', description='This parameter is required.', example='my-robot'),
}

model StartRtcRobotInstanceResponseBody = {
  instanceId?: string(name='InstanceId', example='727dc0e296014bb58670940a3da95592'),
  requestId?: string(name='RequestId', description='Id of the request', example='11DE0AB3-603B-5055-8A72-9C424854F983'),
}

model StartRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartRtcRobotInstanceResponseBody(name='body'),
}

/**
 * @summary 开启一个机器人实例
 *
 * @param tmpReq StartRtcRobotInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StartRtcRobotInstanceResponse
 */
async function startRtcRobotInstanceWithOptions(tmpReq: StartRtcRobotInstanceRequest, runtime: $RuntimeOptions): StartRtcRobotInstanceResponse {
  tmpReq.validate();
  var request = new StartRtcRobotInstanceShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.config)) {
    request.configShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.config, 'Config', 'json');
  }
  var query = {};
  if (!$isNull(request.authToken)) {
    query['AuthToken'] = request.authToken;
  }
  if (!$isNull(request.channelId)) {
    query['ChannelId'] = request.channelId;
  }
  if (!$isNull(request.configShrink)) {
    query['Config'] = request.configShrink;
  }
  if (!$isNull(request.robotId)) {
    query['RobotId'] = request.robotId;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  if (!$isNull(request.userId)) {
    query['UserId'] = request.userId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'StartRtcRobotInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 开启一个机器人实例
 *
 * @param request StartRtcRobotInstanceRequest
 * @return StartRtcRobotInstanceResponse
 */
async function startRtcRobotInstance(request: StartRtcRobotInstanceRequest): StartRtcRobotInstanceResponse {
  var runtime = new $RuntimeOptions{};
  return startRtcRobotInstanceWithOptions(request, runtime);
}

model StartWorkflowRequest {
  taskInput?: string(name='TaskInput', description='The workflow input. Only media assets are supported.', example='{
      "Type": "Media",
      "Media": "******30706071edbfe290b488******"
}'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which cannot be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).'),
  workflowId?: string(name='WorkflowId', description='The ID of the workflow template. To view the template ID, log on to the [IMS console](https://ims.console.aliyun.com/settings/workflow/list) and choose Configurations > Workflow Template.', example='******f0e54971ecbffd472190******'),
}

model StartWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******42-E8E1-4FBB-8E52-F4225C******'),
  taskId?: string(name='TaskId', description='The ID of the workflow task.', example='******22dad741d086a50325f9******'),
}

model StartWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartWorkflowResponseBody(name='body'),
}

/**
 * @summary Submits a workflow task. You can submit a workflow task to implement automated media processing based on a workflow template.
 *
 * @description *   Only media assets from Intelligent Media Services (IMS) or ApsaraVideo VOD can be used as the input of a workflow.
 * *   When you submit a workflow task, you must specify a workflow template. You can create a workflow template in the [IMS console](https://ims.console.aliyun.com/settings/workflow/list) or use a preset workflow template.
 *
 * @param request StartWorkflowRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StartWorkflowResponse
 */
async function startWorkflowWithOptions(request: StartWorkflowRequest, runtime: $RuntimeOptions): StartWorkflowResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.taskInput)) {
    query['TaskInput'] = request.taskInput;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  if (!$isNull(request.workflowId)) {
    query['WorkflowId'] = request.workflowId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'StartWorkflow',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a workflow task. You can submit a workflow task to implement automated media processing based on a workflow template.
 *
 * @description *   Only media assets from Intelligent Media Services (IMS) or ApsaraVideo VOD can be used as the input of a workflow.
 * *   When you submit a workflow task, you must specify a workflow template. You can create a workflow template in the [IMS console](https://ims.console.aliyun.com/settings/workflow/list) or use a preset workflow template.
 *
 * @param request StartWorkflowRequest
 * @return StartWorkflowResponse
 */
async function startWorkflow(request: StartWorkflowRequest): StartWorkflowResponse {
  var runtime = new $RuntimeOptions{};
  return startWorkflowWithOptions(request, runtime);
}

model StopAIAgentInstanceRequest {
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
}

model StopAIAgentInstanceResponseBody = {
  requestId?: string(name='RequestId', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model StopAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopAIAgentInstanceResponseBody(name='body'),
}

/**
 * @summary Stops an AI agent instance.
 *
 * @description *   When you no longer need an AI agent to participate in a conversation or task, you can call this operation to stop the running agent and release relevant resources.****
 * *   You must specify the unique ID of the AI agent that you want to stop by using InstanceId.****
 * *   ****
 *
 * @param request StopAIAgentInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StopAIAgentInstanceResponse
 */
async function stopAIAgentInstanceWithOptions(request: StopAIAgentInstanceRequest, runtime: $RuntimeOptions): StopAIAgentInstanceResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'StopAIAgentInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Stops an AI agent instance.
 *
 * @description *   When you no longer need an AI agent to participate in a conversation or task, you can call this operation to stop the running agent and release relevant resources.****
 * *   You must specify the unique ID of the AI agent that you want to stop by using InstanceId.****
 * *   ****
 *
 * @param request StopAIAgentInstanceRequest
 * @return StopAIAgentInstanceResponse
 */
async function stopAIAgentInstance(request: StopAIAgentInstanceRequest): StopAIAgentInstanceResponse {
  var runtime = new $RuntimeOptions{};
  return stopAIAgentInstanceWithOptions(request, runtime);
}

model StopChannelRequest {
  channelName?: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel'),
}

model StopChannelResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model StopChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopChannelResponseBody(name='body'),
}

/**
 * @summary Stops a MediaWeaver channel.
 *
 * @param request StopChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StopChannelResponse
 */
async function stopChannelWithOptions(request: StopChannelRequest, runtime: $RuntimeOptions): StopChannelResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'StopChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Stops a MediaWeaver channel.
 *
 * @param request StopChannelRequest
 * @return StopChannelResponse
 */
async function stopChannel(request: StopChannelRequest): StopChannelResponse {
  var runtime = new $RuntimeOptions{};
  return stopChannelWithOptions(request, runtime);
}

model StopMediaLiveChannelRequest {
  channelId?: string(name='ChannelId', description='The ID of the channel.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
}

model StopMediaLiveChannelResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model StopMediaLiveChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopMediaLiveChannelResponseBody(name='body'),
}

/**
 * @summary Stops a MediaLive channel.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request StopMediaLiveChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StopMediaLiveChannelResponse
 */
async function stopMediaLiveChannelWithOptions(request: StopMediaLiveChannelRequest, runtime: $RuntimeOptions): StopMediaLiveChannelResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.channelId)) {
    body['ChannelId'] = request.channelId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'StopMediaLiveChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Stops a MediaLive channel.
 *
 * @description ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request StopMediaLiveChannelRequest
 * @return StopMediaLiveChannelResponse
 */
async function stopMediaLiveChannel(request: StopMediaLiveChannelRequest): StopMediaLiveChannelResponse {
  var runtime = new $RuntimeOptions{};
  return stopMediaLiveChannelWithOptions(request, runtime);
}

model StopRtcRobotInstanceRequest {
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='727dc0e296014bb58670940a3da95592'),
}

model StopRtcRobotInstanceResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='AC84E5DD-AB56-56C0-A992-07ECB82008CA'),
}

model StopRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopRtcRobotInstanceResponseBody(name='body'),
}

/**
 * @summary 停止一个机器人实例
 *
 * @param request StopRtcRobotInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return StopRtcRobotInstanceResponse
 */
async function stopRtcRobotInstanceWithOptions(request: StopRtcRobotInstanceRequest, runtime: $RuntimeOptions): StopRtcRobotInstanceResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'StopRtcRobotInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 停止一个机器人实例
 *
 * @param request StopRtcRobotInstanceRequest
 * @return StopRtcRobotInstanceResponse
 */
async function stopRtcRobotInstance(request: StopRtcRobotInstanceRequest): StopRtcRobotInstanceResponse {
  var runtime = new $RuntimeOptions{};
  return stopRtcRobotInstanceWithOptions(request, runtime);
}

model SubmitASRJobRequest {
  description?: string(name='Description', description='The job description, which can up to 128 bytes in length.', example='测试描述'),
  duration?: string(name='Duration', description='The speech duration.', example='00:00:10'),
  editingConfig?: string(name='EditingConfig'),
  inputFile?: string(name='InputFile', description='The input file. You can specify an Object Storage Service (OSS) URL or the ID of a media asset in the media asset library.', example='oss://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4 或 ****20b48fb04483915d4f2cd8ac****'),
  startTime?: string(name='StartTime', description='The start time of the speech to recognize.', example='00:00:00'),
  title?: string(name='Title', description='The job title, which can be up to 128 bytes in length.', example='测试标题'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format. You can specify your business information, such as the business environment and job information.', example='{
      "user": "data",
      "env": "prod"
}'),
}

model SubmitASRJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  state?: string(name='State', description='The job state. Valid values:

*   Created
*   Executing
*   Finished
*   Failed', example='Finished'),
}

model SubmitASRJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitASRJobResponseBody(name='body'),
}

/**
 * @summary Submits an automatic speech recognition (ASR) job to extract the start and end time and the corresponding text information of a speech in a video.
 *
 * @param request SubmitASRJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitASRJobResponse
 */
async function submitASRJobWithOptions(request: SubmitASRJobRequest, runtime: $RuntimeOptions): SubmitASRJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.duration)) {
    query['Duration'] = request.duration;
  }
  if (!$isNull(request.editingConfig)) {
    query['EditingConfig'] = request.editingConfig;
  }
  if (!$isNull(request.inputFile)) {
    query['InputFile'] = request.inputFile;
  }
  if (!$isNull(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!$isNull(request.title)) {
    query['Title'] = request.title;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitASRJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits an automatic speech recognition (ASR) job to extract the start and end time and the corresponding text information of a speech in a video.
 *
 * @param request SubmitASRJobRequest
 * @return SubmitASRJobResponse
 */
async function submitASRJob(request: SubmitASRJobRequest): SubmitASRJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitASRJobWithOptions(request, runtime);
}

model SubmitAudioProduceJobRequest {
  description?: string(name='Description', description='The job description.

*   The job description can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.', example='任务描述  长度不超过1024字节  UTF8编码'),
  editingConfig?: string(name='EditingConfig', description='The audio editing configurations.

*   voice: the [voice type](https://help.aliyun.com/document_detail/449563.html).
*   customizedVoice: the ID of the personalized human voice.
*   format: the format of the output file. Valid values: PCM, WAV, and MP3.
*   volume: the volume. Default value: 50. Valid values: 0 to 100.
*   speech_rate: the speech tempo. Default value: 0. Value range: -500 to 500.
*   pitch_rate: the intonation. Default value: 0. Value range: -500 to 500.

>  If you specify both voice and customizedVoice, customizedVoice takes precedence over voice.

This parameter is required.', example='{"voice":"Siqi","format":"MP3","volume":50}'),
  inputConfig?: string(name='InputConfig', description='The text content. A maximum of 2,000 characters are supported. The [Speech Synthesis Markup Language (SSML)](https://help.aliyun.com/document_detail/2672807.html) is supported.

This parameter is required.', example='测试文本'),
  outputConfig?: string(name='OutputConfig', description='The output audio configurations.

This parameter is required.', example='{"bucket":"bucket","object":"objeck"}'),
  overwrite?: boolean(name='Overwrite', description='Specifies whether to overwrite the existing Object Storage Service (OSS) object.', example='true'),
  title?: string(name='Title', description='The job title. If you do not specify this parameter, the system generates a title based on the current date.

*   The job title can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='任务标题。若不提供，根据日期自动生成默认title  长度不超过128字节  UTF8编码'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).', example='{"user":"data"}'),
}

model SubmitAudioProduceJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='****2bcbfcfa30fccb36f72dca22****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  state?: string(name='State', description='The job state. Valid values:

*   Created
*   Executing
*   Finished
*   Failed', example='Created'),
}

model SubmitAudioProduceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitAudioProduceJobResponseBody(name='body'),
}

/**
 * @summary Submits an audio production job that converts text into an audio file.
 *
 * @param request SubmitAudioProduceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitAudioProduceJobResponse
 */
async function submitAudioProduceJobWithOptions(request: SubmitAudioProduceJobRequest, runtime: $RuntimeOptions): SubmitAudioProduceJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.editingConfig)) {
    query['EditingConfig'] = request.editingConfig;
  }
  if (!$isNull(request.inputConfig)) {
    query['InputConfig'] = request.inputConfig;
  }
  if (!$isNull(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!$isNull(request.overwrite)) {
    query['Overwrite'] = request.overwrite;
  }
  if (!$isNull(request.title)) {
    query['Title'] = request.title;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitAudioProduceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits an audio production job that converts text into an audio file.
 *
 * @param request SubmitAudioProduceJobRequest
 * @return SubmitAudioProduceJobResponse
 */
async function submitAudioProduceJob(request: SubmitAudioProduceJobRequest): SubmitAudioProduceJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitAudioProduceJobWithOptions(request, runtime);
}

model SubmitAvatarTrainingJobRequest {
  jobId?: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
}

model SubmitAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****29faef8144638ba42eb8e037****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='*****ACB-44F2-5F2D-88D7-1283E70*****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model SubmitAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitAvatarTrainingJobResponseBody(name='body'),
}

/**
 * @summary Submits a digital human training job. You can call this operation to submit a job the first time or submit a job again with updated parameters if the training failed.
 *
 * @param request SubmitAvatarTrainingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitAvatarTrainingJobResponse
 */
async function submitAvatarTrainingJobWithOptions(request: SubmitAvatarTrainingJobRequest, runtime: $RuntimeOptions): SubmitAvatarTrainingJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitAvatarTrainingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a digital human training job. You can call this operation to submit a job the first time or submit a job again with updated parameters if the training failed.
 *
 * @param request SubmitAvatarTrainingJobRequest
 * @return SubmitAvatarTrainingJobResponse
 */
async function submitAvatarTrainingJob(request: SubmitAvatarTrainingJobRequest): SubmitAvatarTrainingJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitAvatarTrainingJobWithOptions(request, runtime);
}

model SubmitAvatarVideoJobRequest {
  description?: string(name='Description', example='测试描述'),
  editingConfig?: string(name='EditingConfig', example='{"AvatarId":"yunqiao"}'),
  inputConfig?: string(name='InputConfig', description='The input configurations of the video rendering job for an avatar. You can specify text, the Object Storage Service (OSS) URL of an audio file, or the ID of a media asset. The audio file must be in the MP3 or WAV format.

>  The text must be at least five words in length.'),
  outputConfig?: string(name='OutputConfig', example='{"MediaURL":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/xxx.mp4","Width":1920,"Height":1080}'),
  title?: string(name='Title', example='测试标题'),
  userData?: string(name='UserData', example='{"user":"data","env":"prod"}'),
}

model SubmitAvatarVideoJobResponseBody = {
  jobId?: string(name='JobId', example='****20b48fb04483915d4f2cd8ac****'),
  mediaId?: string(name='MediaId', example='******70dcc471edaf00e6f6f4******'),
  requestId?: string(name='RequestId', description='Id of the request', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitAvatarVideoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitAvatarVideoJobResponseBody(name='body'),
}

/**
 * @summary Submits a video rendering job for a digitized virtual human based on text or an audio file of a human voice.
 *
 * @param request SubmitAvatarVideoJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitAvatarVideoJobResponse
 */
async function submitAvatarVideoJobWithOptions(request: SubmitAvatarVideoJobRequest, runtime: $RuntimeOptions): SubmitAvatarVideoJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.editingConfig)) {
    query['EditingConfig'] = request.editingConfig;
  }
  if (!$isNull(request.inputConfig)) {
    query['InputConfig'] = request.inputConfig;
  }
  if (!$isNull(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!$isNull(request.title)) {
    query['Title'] = request.title;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitAvatarVideoJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a video rendering job for a digitized virtual human based on text or an audio file of a human voice.
 *
 * @param request SubmitAvatarVideoJobRequest
 * @return SubmitAvatarVideoJobResponse
 */
async function submitAvatarVideoJob(request: SubmitAvatarVideoJobRequest): SubmitAvatarVideoJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitAvatarVideoJobWithOptions(request, runtime);
}

model SubmitBatchMediaProducingJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****'),
  editingConfig?: string(name='EditingConfig', description='The editing configurations. For more information, see [EditingConfig](~~2692547#1be9bba03b7qu~~).', example='{
  "MediaConfig": {
      "Volume": 0
  },
  "SpeechConfig": {
      "Volume": 1
  },
 "BackgroundMusicConfig": {
      "Volume": 0.3
  }
}'),
  inputConfig?: string(name='InputConfig', description='The input configurations. For more information, see [InputConfig](~~2692547#2faed1559549n~~).'),
  outputConfig?: string(name='OutputConfig', description='The output configurations. For more information, see [OutputConfig](~~2692547#447b928fcbuoa~~).', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 20,
  "MaxDuration": 15,
  "Width": 1080,
  "Height": 1920,
  "Video": {"Crf": 27}
}'),
  templateConfig?: string(name='TemplateConfig'),
  userData?: string(name='UserData', description='The user-defined data, including the business and callback configurations. For more information, see [UserData](https://help.aliyun.com/document_detail/357745.html).'),
}

model SubmitBatchMediaProducingJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the quick video production job.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model SubmitBatchMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitBatchMediaProducingJobResponseBody(name='body'),
}

/**
 * @summary Submits a quick video production job that intelligently edits multiple video, audio, and image assets to generate multiple videos at a time.
 *
 * @param request SubmitBatchMediaProducingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitBatchMediaProducingJobResponse
 */
async function submitBatchMediaProducingJobWithOptions(request: SubmitBatchMediaProducingJobRequest, runtime: $RuntimeOptions): SubmitBatchMediaProducingJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!$isNull(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!$isNull(request.templateConfig)) {
    query['TemplateConfig'] = request.templateConfig;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var body : map[string]any = {};
  if (!$isNull(request.editingConfig)) {
    body['EditingConfig'] = request.editingConfig;
  }
  if (!$isNull(request.inputConfig)) {
    body['InputConfig'] = request.inputConfig;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitBatchMediaProducingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a quick video production job that intelligently edits multiple video, audio, and image assets to generate multiple videos at a time.
 *
 * @param request SubmitBatchMediaProducingJobRequest
 * @return SubmitBatchMediaProducingJobResponse
 */
async function submitBatchMediaProducingJob(request: SubmitBatchMediaProducingJobRequest): SubmitBatchMediaProducingJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitBatchMediaProducingJobWithOptions(request, runtime);
}

model SubmitCopyrightExtractJobRequest {
  input?: {
    media?: string(name='Media', description='This parameter is required.', example='oss://bucket/object'),
    type?: string(name='Type', description='This parameter is required.', example='OSS'),
  }(name='Input', description='This parameter is required.'),
  params?: string(name='Params', example='{"algoType":"v2"}'),
  userData?: string(name='UserData', example='123'),
}

model SubmitCopyrightExtractJobShrinkRequest {
  inputShrink?: string(name='Input', description='This parameter is required.'),
  params?: string(name='Params', example='{"algoType":"v2"}'),
  userData?: string(name='UserData', example='123'),
}

model SubmitCopyrightExtractJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', example='bfb786c63****4d80648792021eff90'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='****2876-6263-4B75-8F2C-CD0F7FCF****'),
  statusCode?: long(name='StatusCode', example='200'),
}

model SubmitCopyrightExtractJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitCopyrightExtractJobResponseBody(name='body'),
}

/**
 * @summary 提交版权水印提取作业
 *
 * @param tmpReq SubmitCopyrightExtractJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitCopyrightExtractJobResponse
 */
async function submitCopyrightExtractJobWithOptions(tmpReq: SubmitCopyrightExtractJobRequest, runtime: $RuntimeOptions): SubmitCopyrightExtractJobResponse {
  tmpReq.validate();
  var request = new SubmitCopyrightExtractJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  var query = {};
  if (!$isNull(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!$isNull(request.params)) {
    query['Params'] = request.params;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitCopyrightExtractJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 提交版权水印提取作业
 *
 * @param request SubmitCopyrightExtractJobRequest
 * @return SubmitCopyrightExtractJobResponse
 */
async function submitCopyrightExtractJob(request: SubmitCopyrightExtractJobRequest): SubmitCopyrightExtractJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitCopyrightExtractJobWithOptions(request, runtime);
}

model SubmitCopyrightJobRequest {
  description?: string(name='Description'),
  input?: {
    media?: string(name='Media', description='This parameter is required.'),
    type?: string(name='Type', description='This parameter is required.'),
  }(name='Input', description='This parameter is required.', example='{"Bucket":"example-bucket","Location":"oss-cn-shanghai","Object":"example.mp4"}'),
  level?: long(name='Level', example='0'),
  message?: string(name='Message', description='This parameter is required.'),
  output?: {
    media?: string(name='Media', description='This parameter is required.'),
    type?: string(name='Type', description='This parameter is required.'),
  }(name='Output', description='This parameter is required.', example='{"Bucket":"example-bucket","Location":"oss-cn-shanghai","Object":"example_result.mp4"}'),
  params?: string(name='Params', example='{"algoType":"v2"}'),
  startTime?: string(name='StartTime', example='0'),
  totalTime?: string(name='TotalTime', example='10'),
  userData?: string(name='UserData', example='123'),
}

model SubmitCopyrightJobShrinkRequest {
  description?: string(name='Description'),
  inputShrink?: string(name='Input', description='This parameter is required.', example='{"Bucket":"example-bucket","Location":"oss-cn-shanghai","Object":"example.mp4"}'),
  level?: long(name='Level', example='0'),
  message?: string(name='Message', description='This parameter is required.'),
  outputShrink?: string(name='Output', description='This parameter is required.', example='{"Bucket":"example-bucket","Location":"oss-cn-shanghai","Object":"example_result.mp4"}'),
  params?: string(name='Params', example='{"algoType":"v2"}'),
  startTime?: string(name='StartTime', example='0'),
  totalTime?: string(name='TotalTime', example='10'),
  userData?: string(name='UserData', example='123'),
}

model SubmitCopyrightJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', example='bfb786c63****f4d80648792021eff90'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='FA258E67-09B8-4EAA-8F33-BA567834A2C3'),
  statusCode?: long(name='StatusCode', example='200'),
}

model SubmitCopyrightJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitCopyrightJobResponseBody(name='body'),
}

/**
 * @summary 提交版权水印任务
 *
 * @param tmpReq SubmitCopyrightJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitCopyrightJobResponse
 */
async function submitCopyrightJobWithOptions(tmpReq: SubmitCopyrightJobRequest, runtime: $RuntimeOptions): SubmitCopyrightJobResponse {
  tmpReq.validate();
  var request = new SubmitCopyrightJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!$isNull(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  var query = {};
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!$isNull(request.level)) {
    query['Level'] = request.level;
  }
  if (!$isNull(request.message)) {
    query['Message'] = request.message;
  }
  if (!$isNull(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!$isNull(request.params)) {
    query['Params'] = request.params;
  }
  if (!$isNull(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!$isNull(request.totalTime)) {
    query['TotalTime'] = request.totalTime;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitCopyrightJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 提交版权水印任务
 *
 * @param request SubmitCopyrightJobRequest
 * @return SubmitCopyrightJobResponse
 */
async function submitCopyrightJob(request: SubmitCopyrightJobRequest): SubmitCopyrightJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitCopyrightJobWithOptions(request, runtime);
}

model SubmitCustomizedVoiceJobRequest {
  demoAudioMediaURL?: string(name='DemoAudioMediaURL', description='The URL of the sample audio file.

*   If this parameter is specified, a sample audio file is generated at the specified Object Storage Service (OSS) URL after the training is complete.

*   If this parameter is not specified, no sample audio file is generated.

    **

    **Note**: The URL must be a valid public OSS URL within your Alibaba Cloud account.', example='https://your-bucket.oss-cn-shanghai.aliyuncs.com/demo.MP3'),
  voiceId?: string(name='VoiceId', description='The voice ID.

This parameter is required.', example='xiaozhuan'),
}

model SubmitCustomizedVoiceJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****d718e2ff4f018ccf419a7b71****'),
    voiceId?: string(name='VoiceId', description='The voice ID.', example='xiaozhuan'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model SubmitCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Submits a human voice cloning job. The value of VoiceId must be the one used during audio check. The system uses this ID to find the cached audio file for training. After you call this operation, the JobId is returned. The training process is asynchronous. During training, you can call the GetCustomizedVoiceJob operation to query information such as the job state.
 *
 * @param request SubmitCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitCustomizedVoiceJobResponse
 */
async function submitCustomizedVoiceJobWithOptions(request: SubmitCustomizedVoiceJobRequest, runtime: $RuntimeOptions): SubmitCustomizedVoiceJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.demoAudioMediaURL)) {
    query['DemoAudioMediaURL'] = request.demoAudioMediaURL;
  }
  if (!$isNull(request.voiceId)) {
    query['VoiceId'] = request.voiceId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a human voice cloning job. The value of VoiceId must be the one used during audio check. The system uses this ID to find the cached audio file for training. After you call this operation, the JobId is returned. The training process is asynchronous. During training, you can call the GetCustomizedVoiceJob operation to query information such as the job state.
 *
 * @param request SubmitCustomizedVoiceJobRequest
 * @return SubmitCustomizedVoiceJobResponse
 */
async function submitCustomizedVoiceJob(request: SubmitCustomizedVoiceJobRequest): SubmitCustomizedVoiceJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitCustomizedVoiceJobWithOptions(request, runtime);
}

model SubmitDNAJobRequest {
  config?: string(name='Config', description='The configurations of the media fingerprint analysis job. The value is a JSON object. If you specify this parameter, the template parameters are overwritten.', example='{"SaveType": "save","MediaType"":"video"}'),
  DBId?: string(name='DBId', description='The ID of the media fingerprint library. If you do not specify this parameter, the default media fingerprint library is used. For more information about how to create a media fingerprint library, see [CreateDNADB](https://help.aliyun.com/document_detail/479275.html).

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****'),
  input?: {
    media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. You can specify the path of an OSS object in one of the following formats:

1\\\\. oss://bucket/object

2\\\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the preceding paths, bucket indicates an OSS bucket that resides in the same region as the current project, and object indicates the path of the object in the bucket.

This parameter is required.', example='1b1b9cd148034739af413150fded****'),
    type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: Object Storage Service (OSS) object.
2.  Media: media asset.

This parameter is required.', example='Media'),
  }(name='Input', description='The input file for media fingerprint analysis.

This parameter is required.'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the media fingerprint analysis job is submitted.', example='5246b8d12a62433ab77845074039****'),
  primaryKey?: string(name='PrimaryKey', description='The primary key of the video. You must make sure that each primary key is unique.

This parameter is required.', example='3ca84a39a9024f19853b21be9cf9****'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
  templateId?: string(name='TemplateId', description='The template ID.', example='S00000101-100060'),
  userData?: string(name='UserData', description='The user-defined data. The data can be up to 128 bytes in length.', example='userData'),
}

model SubmitDNAJobShrinkRequest {
  config?: string(name='Config', description='The configurations of the media fingerprint analysis job. The value is a JSON object. If you specify this parameter, the template parameters are overwritten.', example='{"SaveType": "save","MediaType"":"video"}'),
  DBId?: string(name='DBId', description='The ID of the media fingerprint library. If you do not specify this parameter, the default media fingerprint library is used. For more information about how to create a media fingerprint library, see [CreateDNADB](https://help.aliyun.com/document_detail/479275.html).

This parameter is required.', example='2288c6ca184c0e47098a5b665e2a12****'),
  inputShrink?: string(name='Input', description='The input file for media fingerprint analysis.

This parameter is required.'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the media fingerprint analysis job is submitted.', example='5246b8d12a62433ab77845074039****'),
  primaryKey?: string(name='PrimaryKey', description='The primary key of the video. You must make sure that each primary key is unique.

This parameter is required.', example='3ca84a39a9024f19853b21be9cf9****'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
  templateId?: string(name='TemplateId', description='The template ID.', example='S00000101-100060'),
  userData?: string(name='UserData', description='The user-defined data. The data can be up to 128 bytes in length.', example='userData'),
}

model SubmitDNAJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the media fingerprint analysis job. We recommend that you save this ID for subsequent calls of other operations.', example='88c6ca184c0e47098a5b665e2****'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model SubmitDNAJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitDNAJobResponseBody(name='body'),
}

/**
 * @summary Submits a media fingerprint analysis job.
 *
 * @description *   SubmitDNAJob is an asynchronous operation. After a request is sent, the system returns a request ID and a job ID and runs the task in the background.
 * *   You can call this operation only in the China (Beijing), China (Hangzhou), and China (Shanghai) regions.
 * *   You can submit a text fingerprint analysis job only in the China (Shanghai) region.
 *
 * @param tmpReq SubmitDNAJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitDNAJobResponse
 */
async function submitDNAJobWithOptions(tmpReq: SubmitDNAJobRequest, runtime: $RuntimeOptions): SubmitDNAJobResponse {
  tmpReq.validate();
  var request = new SubmitDNAJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  var query = {};
  if (!$isNull(request.config)) {
    query['Config'] = request.config;
  }
  if (!$isNull(request.DBId)) {
    query['DBId'] = request.DBId;
  }
  if (!$isNull(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!$isNull(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!$isNull(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!$isNull(request.pipelineId)) {
    query['PipelineId'] = request.pipelineId;
  }
  if (!$isNull(request.primaryKey)) {
    query['PrimaryKey'] = request.primaryKey;
  }
  if (!$isNull(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!$isNull(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitDNAJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a media fingerprint analysis job.
 *
 * @description *   SubmitDNAJob is an asynchronous operation. After a request is sent, the system returns a request ID and a job ID and runs the task in the background.
 * *   You can call this operation only in the China (Beijing), China (Hangzhou), and China (Shanghai) regions.
 * *   You can submit a text fingerprint analysis job only in the China (Shanghai) region.
 *
 * @param request SubmitDNAJobRequest
 * @return SubmitDNAJobResponse
 */
async function submitDNAJob(request: SubmitDNAJobRequest): SubmitDNAJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitDNAJobWithOptions(request, runtime);
}

model SubmitDynamicChartJobRequest {
  axisParams?: string(name='AxisParams', description='The axis configurations. If XAxisFontInterval is set to 0 or left empty, the system automatically determines an optimal interval.', example='{"FontFile":"Microsoft YaHei","XAxisFontSize":"30","YAxisFontSize":"30","XAxisFontInterval":"30","AxisColor":"30"}'),
  background?: string(name='Background', description='The chart background.', example='{"Color":"#000000","ImageUrl":"http://your-bucket.oss-cn-shanghai.aliyuncs.com/obj.jpg"}'),
  chartConfig?: string(name='ChartConfig', description='The chart configurations.', example='{"Style":"Normal","TitleStartTime":"3000","ChartStartTime":"3000","VideoDuration":"15000"}'),
  chartTitle?: string(name='ChartTitle', description='The chart title.'),
  chartType?: string(name='ChartType', description='The chart type.

Valid values:

*   Line: line chart
*   Histogram: bar chart
*   Pie: pie chart

This parameter is required.', example='Line'),
  dataSource?: string(name='DataSource', description='The data source.'),
  description?: string(name='Description', description='The job description.'),
  input?: string(name='Input', description='The input data for the chart.

This parameter is required.', example='{"XlsFile":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/obj.xls"}'),
  outputConfig?: string(name='OutputConfig', description='The output configurations.

This parameter is required.', example='{"MediaURL":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/obj.mp4","Bitrate":2000,"Width":800,"Height":680}'),
  subtitle?: string(name='Subtitle', description='The subtitle.'),
  title?: string(name='Title', description='The job title.'),
  unit?: string(name='Unit', description='Unit'),
  userData?: string(name='UserData', description='The custom data in JSON format.', example='{"user":"data"}'),
}

model SubmitDynamicChartJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitDynamicChartJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitDynamicChartJobResponseBody(name='body'),
}

/**
 * @summary Generates animated charts based on Excel datasheets, such as line, pie, and bar charts. You can modify the line color and font.
 *
 * @description This feature is available only in the China (Shanghai) region.
 * *   You can add a title, subtitle, data source, and unit to a chart and specify the font and font size. For supported fonts, see [Fonts](https://help.aliyun.com/document_detail/449567.html).
 * *   This feature provides five styles of animated charts: normal, mystery, lively, business, and green.
 * *   You can set the background color or image.
 * *   You can set the animation duration, size, and bitrate.
 * Examples
 * *   Line chart: [Sample datasheet](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/line.xlsx), [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/line.mp4)
 * *   Bar chart: [Sample datasheet](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/histgram.xlsx), [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/histgram.mp4)
 * *   Pie chart: [Sample datasheet](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/pie.xlsx), [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/pie.mp4)
 * *   Normal: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Normal.mp4)
 * *   Mystery: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Mystery.mp4)
 * *   Lively: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Lively.mp4)
 * *   Business: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Business.mp4)
 * *   Green: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Green.mp4)
 *
 * @param request SubmitDynamicChartJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitDynamicChartJobResponse
 */
async function submitDynamicChartJobWithOptions(request: SubmitDynamicChartJobRequest, runtime: $RuntimeOptions): SubmitDynamicChartJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.axisParams)) {
    query['AxisParams'] = request.axisParams;
  }
  if (!$isNull(request.background)) {
    query['Background'] = request.background;
  }
  if (!$isNull(request.chartConfig)) {
    query['ChartConfig'] = request.chartConfig;
  }
  if (!$isNull(request.chartTitle)) {
    query['ChartTitle'] = request.chartTitle;
  }
  if (!$isNull(request.chartType)) {
    query['ChartType'] = request.chartType;
  }
  if (!$isNull(request.dataSource)) {
    query['DataSource'] = request.dataSource;
  }
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.input)) {
    query['Input'] = request.input;
  }
  if (!$isNull(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!$isNull(request.subtitle)) {
    query['Subtitle'] = request.subtitle;
  }
  if (!$isNull(request.title)) {
    query['Title'] = request.title;
  }
  if (!$isNull(request.unit)) {
    query['Unit'] = request.unit;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitDynamicChartJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Generates animated charts based on Excel datasheets, such as line, pie, and bar charts. You can modify the line color and font.
 *
 * @description This feature is available only in the China (Shanghai) region.
 * *   You can add a title, subtitle, data source, and unit to a chart and specify the font and font size. For supported fonts, see [Fonts](https://help.aliyun.com/document_detail/449567.html).
 * *   This feature provides five styles of animated charts: normal, mystery, lively, business, and green.
 * *   You can set the background color or image.
 * *   You can set the animation duration, size, and bitrate.
 * Examples
 * *   Line chart: [Sample datasheet](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/line.xlsx), [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/line.mp4)
 * *   Bar chart: [Sample datasheet](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/histgram.xlsx), [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/histgram.mp4)
 * *   Pie chart: [Sample datasheet](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/pie.xlsx), [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/pie.mp4)
 * *   Normal: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Normal.mp4)
 * *   Mystery: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Mystery.mp4)
 * *   Lively: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Lively.mp4)
 * *   Business: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Business.mp4)
 * *   Green: [Effect](https://ice-public-media.oss-cn-shanghai.aliyuncs.com/smart/dynamicChart/Green.mp4)
 *
 * @param request SubmitDynamicChartJobRequest
 * @return SubmitDynamicChartJobResponse
 */
async function submitDynamicChartJob(request: SubmitDynamicChartJobRequest): SubmitDynamicChartJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitDynamicChartJobWithOptions(request, runtime);
}

model SubmitDynamicImageJobRequest {
  input?: {
    media?: string(name='Media', description='The input file. If Type is set to OSS, set this parameter to the URL of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

This parameter is required.', example='oss://bucket/object.mp4'),
    type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The name of the job.', example='SampleJob'),
  output?: {
    media?: string(name='Media', description='The output file. The file can be an OSS object or a media asset. The URL of an OSS object can be in one of the following formats:

*   oss://bucket/object
*   http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the IMS console.

This parameter is required.', example='****96e8864746a0b6f3****'),
    type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

This parameter is required.', example='Media'),
  }(name='Output', description='The output of the job.

This parameter is required.'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='****96e8864746a0b6f3****'),
    priority?: int32(name='Priority', description='The priority. Valid values: 1 to 10. Default value: 6. A greater value specifies a higher priority.', example='6'),
  }(name='ScheduleConfig', description='The scheduling settings.'),
  templateConfig?: {
    overwriteParams?: {
      format?: string(name='Format', description='The format of the animated image. Valid values:

*   **gif**
*   **webp**', example='gif'),
      fps?: int32(name='Fps', description='The frame rate. Valid values: [1,60].', example='15'),
      height?: int32(name='Height', description='The height of the animated image. Valid values: [128,4096].', example='720'),
      longShortMode?: boolean(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature. Valid values:

*   **true**
*   **false**

Default value: **true**.

>  If this feature is enabled, the width of the output video corresponds to the long side of the input video, which is the height of the input video in portrait mode. The height of the output video corresponds to the short side of the input video, which is the width of the input video in portrait mode.', example='false'),
      scanMode?: string(name='ScanMode', description='The scan mode. Valid values:

*   **interlaced**
*   **progressive** This is the default value.', example='progressive'),
      timeSpan?: {
        duration?: string(name='Duration', description='The length of the clip.

*   Format: `hh:mm:ss[.SSS]` or `sssss[.SSS]`.
*   Valid values: `[00:00:00.000,23:59:59.999]` or `[0.000,86399.999]`.', example='01:59:59.999 or 32000.23'),
        end?: string(name='End', description='The length of the ending part of the original clip to be cropped out. If you specify this parameter, the Duration parameter becomes invalid.

*   Format: `hh:mm:ss[.SSS]` or `sssss[.SSS]`.
*   Valid values: `[00:00:00.000,23:59:59.999]` or `[0.000,86399.999]`.', example='01:59:59.999 or 32000.23'),
        seek?: string(name='Seek', description='The start point of the clip.

*   Format: `hh:mm:ss[.SSS]` or `sssss[.SSS]`.
*   Valid values: `[00:00:00.000,23:59:59.999]` or `[0.000,86399.999]`.', example='01:59:59.999 or 32000.23'),
      }(name='TimeSpan', description='The timeline parameters.'),
      width?: int32(name='Width', description='The width of the animated image. Valid values: [128,4096].', example='1024'),
    }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters.'),
    templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
  }(name='TemplateConfig', description='The snapshot template configuration.

This parameter is required.'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"SampleKey": "SampleValue"}'),
}

model SubmitDynamicImageJobShrinkRequest {
  inputShrink?: string(name='Input', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The name of the job.', example='SampleJob'),
  outputShrink?: string(name='Output', description='The output of the job.

This parameter is required.'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling settings.'),
  templateConfigShrink?: string(name='TemplateConfig', description='The snapshot template configuration.

This parameter is required.'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"SampleKey": "SampleValue"}'),
}

model SubmitDynamicImageJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitDynamicImageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitDynamicImageJobResponseBody(name='body'),
}

/**
 * @summary Submits an image animation job.
 *
 * @param tmpReq SubmitDynamicImageJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitDynamicImageJobResponse
 */
async function submitDynamicImageJobWithOptions(tmpReq: SubmitDynamicImageJobRequest, runtime: $RuntimeOptions): SubmitDynamicImageJobResponse {
  tmpReq.validate();
  var request = new SubmitDynamicImageJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!$isNull(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  if (!$isNull(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  if (!$isNull(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!$isNull(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!$isNull(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitDynamicImageJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits an image animation job.
 *
 * @param request SubmitDynamicImageJobRequest
 * @return SubmitDynamicImageJobResponse
 */
async function submitDynamicImageJob(request: SubmitDynamicImageJobRequest): SubmitDynamicImageJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitDynamicImageJobWithOptions(request, runtime);
}

model SubmitHighlightExtractionJobRequest {
  clientToken?: string(name='ClientToken', example='****12e8864746a0a398****'),
  inputConfig?: string(name='InputConfig', example='{
	"MediaArray": [{
		"MediaId": "ceb72f00e****1ef8216e7e6c64a6302"
	}, {
		"MediaId": "ce450c40e****1ef8216e7e6c64a6302"
	}, {
		"MediaId": "ce49a020e****1ef81c1e6f6d5686302"
	}, {
		"MediaId": "d047e120e****1ef81c1e6f6d5686302"
	}, {
		"MediaId": "cfe2ddc0e****1ef81c1e6f6d5686302"
	}],
	"Strategy": {
		"Count": 5,
		"ClipDuration": 15
	}
}'),
  outputConfig?: string(name='OutputConfig', example='{
	"NeedExport": true,
	"OutputMediaTarget": "oss-object",
	"Bucket": "test-bucket",
	"ObjectKey": "path/to/test_{index}.mp4",
	"Width": 1920,
	"Height": 1080,
	"ExportAsNewMedia": false
}'),
  userData?: string(name='UserData'),
}

model SubmitHighlightExtractionJobResponseBody = {
  jobId?: string(name='JobId', example='****cdb3e74639973036bc84****'),
  requestId?: string(name='RequestId', description='Id of the request', example='******3B-0E1A-586A-AC29-742247******'),
}

model SubmitHighlightExtractionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitHighlightExtractionJobResponseBody(name='body'),
}

/**
 * @summary 提交高光提取任务
 *
 * @param request SubmitHighlightExtractionJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitHighlightExtractionJobResponse
 */
async function submitHighlightExtractionJobWithOptions(request: SubmitHighlightExtractionJobRequest, runtime: $RuntimeOptions): SubmitHighlightExtractionJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!$isNull(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var body : map[string]any = {};
  if (!$isNull(request.inputConfig)) {
    body['InputConfig'] = request.inputConfig;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitHighlightExtractionJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 提交高光提取任务
 *
 * @param request SubmitHighlightExtractionJobRequest
 * @return SubmitHighlightExtractionJobResponse
 */
async function submitHighlightExtractionJob(request: SubmitHighlightExtractionJobRequest): SubmitHighlightExtractionJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitHighlightExtractionJobWithOptions(request, runtime);
}

model SubmitIProductionJobRequest {
  functionName?: string(name='FunctionName', description='The name of the algorithm that you want to use for the job. Valid values:

*   **Cover**: This algorithm intelligently generates a thumbnail image for a video.
*   **VideoClip**: This algorithm intelligently generates a summary for a video.
*   **VideoDelogo**: This algorithm removes logos from a video.
*   **VideoDetext**: This algorithm removes captions from a video.
*   **CaptionExtraction**: This algorithm extracts captions from a video and generates the caption file.
*   **VideoGreenScreenMatting**: This algorithm performs green-screen image matting on a video and generates a new video.
*   **FaceBeauty**: This algorithm performs video retouching.
*   **VideoH2V**: This algorithm transforms a video from the landscape mode to the portrait mode.
*   **MusicSegmentDetect**: This algorithm detects the chorus of a song.
*   **AudioBeatDetection**: This algorithm detects rhythms.
*   **AudioQualityAssessment**: This algorithm assesses the audio quality.
*   **SpeechDenoise**: This algorithm performs noise reduction.
*   **AudioMixing**: This algorithm mixes audio streams.

This parameter is required.', example='Cover'),
  input?: {
    media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[regionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.

This parameter is required.', example='oss://bucket/object'),
    type?: string(name='Type', description='The media type. Valid values:

*   OSS: OSS object
*   Media: media asset

This parameter is required.', example='OSS'),
  }(name='Input', description='The input file. The file can be an Object Storage Service (OSS) object or a media asset.

This parameter is required.'),
  jobParams?: string(name='JobParams', description='The algorithm-specific parameters. The parameters are specified as JSON objects and vary based on the algorithm. For more information, see the "Parameters of JobParams" section of this topic.', example='{"Model":"gif"}'),
  modelId?: string(name='ModelId'),
  name?: string(name='Name', description='The name of the intelligent production job. The name can be up to 100 characters in length.'),
  output?: {
    media?: string(name='Media', description='The output file. If Type is set to OSS, set this parameter to the path of an OSS object. If Type is set to Media, set this parameter to the ID of a media asset. You can specify the path of an OSS object in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object bucket in the path specifies an OSS bucket that resides in the same region as the intelligent production job. object in the path specifies the object path in OSS.

This parameter is required.', example='oss://bucket/object'),
    type?: string(name='Type', description='The media type. Valid values:

*   OSS: OSS object
*   Media: media asset

This parameter is required.', example='OSS'),
  }(name='Output', description='The output file. The file can be an OSS object or a media asset.

This parameter is required.'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue.', example='5246b8d12a62433ab77845074039c3dc'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. A smaller value indicates a higher priority.', example='6'),
  }(name='ScheduleConfig', description='The scheduling configuration.'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
  userData?: string(name='UserData', description='The user-defined data that is returned in the response. The value can be up to 1,024 bytes in length.', example='{"test":1}'),
}

model SubmitIProductionJobShrinkRequest {
  functionName?: string(name='FunctionName', description='The name of the algorithm that you want to use for the job. Valid values:

*   **Cover**: This algorithm intelligently generates a thumbnail image for a video.
*   **VideoClip**: This algorithm intelligently generates a summary for a video.
*   **VideoDelogo**: This algorithm removes logos from a video.
*   **VideoDetext**: This algorithm removes captions from a video.
*   **CaptionExtraction**: This algorithm extracts captions from a video and generates the caption file.
*   **VideoGreenScreenMatting**: This algorithm performs green-screen image matting on a video and generates a new video.
*   **FaceBeauty**: This algorithm performs video retouching.
*   **VideoH2V**: This algorithm transforms a video from the landscape mode to the portrait mode.
*   **MusicSegmentDetect**: This algorithm detects the chorus of a song.
*   **AudioBeatDetection**: This algorithm detects rhythms.
*   **AudioQualityAssessment**: This algorithm assesses the audio quality.
*   **SpeechDenoise**: This algorithm performs noise reduction.
*   **AudioMixing**: This algorithm mixes audio streams.

This parameter is required.', example='Cover'),
  inputShrink?: string(name='Input', description='The input file. The file can be an Object Storage Service (OSS) object or a media asset.

This parameter is required.'),
  jobParams?: string(name='JobParams', description='The algorithm-specific parameters. The parameters are specified as JSON objects and vary based on the algorithm. For more information, see the "Parameters of JobParams" section of this topic.', example='{"Model":"gif"}'),
  modelId?: string(name='ModelId'),
  name?: string(name='Name', description='The name of the intelligent production job. The name can be up to 100 characters in length.'),
  outputShrink?: string(name='Output', description='The output file. The file can be an OSS object or a media asset.

This parameter is required.'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling configuration.'),
  templateId?: string(name='TemplateId', description='The template ID.', example='****20b48fb04483915d4f2cd8ac****'),
  userData?: string(name='UserData', description='The user-defined data that is returned in the response. The value can be up to 1,024 bytes in length.', example='{"test":1}'),
}

model SubmitIProductionJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the intelligent production job.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='C1849434-FC47-5DC1-92B6-F7EAAFE3851E'),
}

model SubmitIProductionJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitIProductionJobResponseBody(name='body'),
}

/**
 * @summary Submits an intelligent production job.
 *
 * @param tmpReq SubmitIProductionJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitIProductionJobResponse
 */
async function submitIProductionJobWithOptions(tmpReq: SubmitIProductionJobRequest, runtime: $RuntimeOptions): SubmitIProductionJobResponse {
  tmpReq.validate();
  var request = new SubmitIProductionJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!$isNull(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  if (!$isNull(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.functionName)) {
    query['FunctionName'] = request.functionName;
  }
  if (!$isNull(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!$isNull(request.jobParams)) {
    query['JobParams'] = request.jobParams;
  }
  if (!$isNull(request.modelId)) {
    query['ModelId'] = request.modelId;
  }
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!$isNull(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitIProductionJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits an intelligent production job.
 *
 * @param request SubmitIProductionJobRequest
 * @return SubmitIProductionJobResponse
 */
async function submitIProductionJob(request: SubmitIProductionJobRequest): SubmitIProductionJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitIProductionJobWithOptions(request, runtime);
}

model SubmitLiveEditingJobRequest {
  clips?: string(name='Clips', description='The clips in the JSON array format. The output video is created by merging these clips sequentially.

Each clip has a start time and an end time. If no live stream parameters are specified, the outer live stream configurations apply. The start and end timestamps are in UTC. For more information about the parameters, see the "Clip" section of this topic.

This parameter is required.', example='[{\\\\"StartTime\\\\": \\\\" 2021-06-21T08:01:00Z\\\\",  \\\\"EndTime\\\\": \\\\" 2021-06-21T08:03:00Z\\\\" ,  "AppName": "app", "DomainName": "domain.com", "StreamName": "stream"},  {\\\\"StartTime\\\\": \\\\" 2021-06-21T08:05:00Z\\\\",  \\\\"EndTime\\\\": \\\\" 2021-06-21T08:09:00Z\\\\" }]'),
  liveStreamConfig?: string(name='LiveStreamConfig', description='The live stream configurations, in the JSON format. The configurations must include the following parameters:

*   AppName: the name of the application to which the live stream belongs.
*   DomainName: the domain name of the application.
*   StreamName: the name of the live stream.', example='{ "AppName": "app", "DomainName": "domain.com", "StreamName": "stream"  }'),
  mediaProduceConfig?: string(name='MediaProduceConfig', description='The production configurations, in the JSON format. Mode specifies the editing mode. Valid values:

*   **AccurateFast** (default): fast editing. It is faster than the Accurate mode. The resolution of the output file is the same as that of the source stream. You cannot specify the width and height of the output file.
*   **Accurate**: accurate editing. In this mode, you can specify the width and height of the output file.
*   **Rough**: rough editing. The minimum precision is one TS segment. The output file comprises all segments within the specified time range. You can specify the width and height of the output file.
*   **RoughFast**: fast rough editing. It is faster than the Accurate mode. The minimum precision is one TS segment. The output file comprises all segments within the specified time range. The resolution of the output file is the same as that of the source stream. You cannot specify the width and height of the output file.', example='{ "Mode": "AccurateFast"}'),
  outputMediaConfig?: string(name='OutputMediaConfig', description='The configurations of the output file, in the JSON format. You can specify an OSS URL or a storage location in a storage bucket of ApsaraVideo VOD.

*   To store the output file in OSS, you must specify MediaURL.
*   To store the output file in ApsaraVideo VOD, you must specify StorageLocation and FileName.'),
  outputMediaTarget?: string(name='OutputMediaTarget', description='The type of the output file. Valid values:

*   oss-object: OSS object in an OSS bucket.
*   vod-media: media asset in Alibaba Cloud VOD.', example='oss-object'),
  projectId?: string(name='ProjectId', description='The ID of the live editing project. If this parameter is specified, the system reads the storage configurations of the project. If this parameter is not specified, the specified storage configurations take precedence.', example='****fddd7748b58bf1d47e95****'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length.', example='{"key": "value"}'),
}

model SubmitLiveEditingJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the live editing job.', example='****d80e4e4044975745c14b****'),
  mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****c469e944b5a856828dc2****'),
  mediaURL?: string(name='MediaURL', description='The URL of the output file.', example='http://test-bucket.cn-shanghai.aliyuncs.com/test.mp4'),
  projectId?: string(name='ProjectId', description='The ID of the live editing project.', example='****fddd7748b58bf1d47e95****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
  vodMediaId?: string(name='VodMediaId', description='The media asset ID of the output file in ApsaraVideo VOD if the output file is stored in ApsaraVideo VOD.', example='****d7578s4h75ci945c14b****'),
}

model SubmitLiveEditingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveEditingJobResponseBody(name='body'),
}

/**
 * @summary Submits a live editing job to merge one or more live stream clips into one video. After a live editing job is submitted, the job is queued in the background for asynchronous processing. You can call the GeLiveEditingJob operation to query the state of the job based on the job ID. You can also call the GetMediaInfo operation to query the information about the generated media asset based on the media asset ID.
 *
 * @description Live editing is supported for live streams that are recorded and stored in Object Storage Service (OSS) and ApsaraVideo VOD. If multiple live streams are involved in a single job, only those recorded within the same application are supported for mixed editing. The streams must all be recorded either in OSS or ApsaraVideo VOD.
 *
 * @param request SubmitLiveEditingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitLiveEditingJobResponse
 */
async function submitLiveEditingJobWithOptions(request: SubmitLiveEditingJobRequest, runtime: $RuntimeOptions): SubmitLiveEditingJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.clips)) {
    query['Clips'] = request.clips;
  }
  if (!$isNull(request.liveStreamConfig)) {
    query['LiveStreamConfig'] = request.liveStreamConfig;
  }
  if (!$isNull(request.mediaProduceConfig)) {
    query['MediaProduceConfig'] = request.mediaProduceConfig;
  }
  if (!$isNull(request.outputMediaConfig)) {
    query['OutputMediaConfig'] = request.outputMediaConfig;
  }
  if (!$isNull(request.outputMediaTarget)) {
    query['OutputMediaTarget'] = request.outputMediaTarget;
  }
  if (!$isNull(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitLiveEditingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a live editing job to merge one or more live stream clips into one video. After a live editing job is submitted, the job is queued in the background for asynchronous processing. You can call the GeLiveEditingJob operation to query the state of the job based on the job ID. You can also call the GetMediaInfo operation to query the information about the generated media asset based on the media asset ID.
 *
 * @description Live editing is supported for live streams that are recorded and stored in Object Storage Service (OSS) and ApsaraVideo VOD. If multiple live streams are involved in a single job, only those recorded within the same application are supported for mixed editing. The streams must all be recorded either in OSS or ApsaraVideo VOD.
 *
 * @param request SubmitLiveEditingJobRequest
 * @return SubmitLiveEditingJobResponse
 */
async function submitLiveEditingJob(request: SubmitLiveEditingJobRequest): SubmitLiveEditingJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitLiveEditingJobWithOptions(request, runtime);
}

model SubmitLiveRecordJobRequest {
  name?: string(name='Name', description='The name of the recording job.

This parameter is required.', example='live stream record 1'),
  notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify'),
  recordOutput?: {
    bucket?: string(name='Bucket', description='The bucket name.', example='imsbucket1'),
    endpoint?: string(name='Endpoint', description='The endpoint of the storage service.', example='oss-cn-hangzhou.aliyuncs.com'),
    type?: string(name='Type', description='The type of the storage address.

This parameter is required.', example='oss'),
  }(name='RecordOutput', description='The storage address of the recording.

This parameter is required.'),
  streamInput?: {
    type?: string(name='Type', description='The type of the live stream URL. The value can only be rtmp.

This parameter is required.', example='rtmp'),
    url?: string(name='Url', description='The URL of the live stream.', example='rtmp://example.com/live/stream1'),
  }(name='StreamInput', description='The URL of the live stream.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The ID of the recording template.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
}

model SubmitLiveRecordJobShrinkRequest {
  name?: string(name='Name', description='The name of the recording job.

This parameter is required.', example='live stream record 1'),
  notifyUrl?: string(name='NotifyUrl', description='The callback URL.', example='https://example.com/imsnotify'),
  recordOutputShrink?: string(name='RecordOutput', description='The storage address of the recording.

This parameter is required.'),
  streamInputShrink?: string(name='StreamInput', description='The URL of the live stream.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The ID of the recording template.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
}

model SubmitLiveRecordJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the recording job.', example='ab0e3e76-1e9d-11ed-ba64-0c42a1b73d66'),
  requestId?: string(name='RequestId', description='The request ID.', example='BEA98A0C-7870-15FE-B96F-8880BB600A2C'),
}

model SubmitLiveRecordJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveRecordJobResponseBody(name='body'),
}

/**
 * @summary Submits a live stream recording job.
 *
 * @description You can call this operation to record live streams of ApsaraVideo Live or third-party Real-Time Messaging Protocol (RTMP) live streams. We recommend that you ingest a stream before you call this operation to submit a recording job. If no stream is pulled from the streaming URL, the job attempts to pull a stream for 3 minutes. If the attempt times out, the recording service stops.
 * Before you submit a recording job, you must prepare an Object Storage Service (OSS) or ApsaraVideo VOD bucket. We recommend that you use a storage address configured in Intelligent Media Services (IMS) to facilitate the management and processing of generated recording files.
 * If the preset recording template does not meet your requirements, you can create a custom recording template.
 *
 * @param tmpReq SubmitLiveRecordJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitLiveRecordJobResponse
 */
async function submitLiveRecordJobWithOptions(tmpReq: SubmitLiveRecordJobRequest, runtime: $RuntimeOptions): SubmitLiveRecordJobResponse {
  tmpReq.validate();
  var request = new SubmitLiveRecordJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.recordOutput)) {
    request.recordOutputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.recordOutput, 'RecordOutput', 'json');
  }
  if (!$isNull(tmpReq.streamInput)) {
    request.streamInputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.streamInput, 'StreamInput', 'json');
  }
  var body : map[string]any = {};
  if (!$isNull(request.name)) {
    body['Name'] = request.name;
  }
  if (!$isNull(request.notifyUrl)) {
    body['NotifyUrl'] = request.notifyUrl;
  }
  if (!$isNull(request.recordOutputShrink)) {
    body['RecordOutput'] = request.recordOutputShrink;
  }
  if (!$isNull(request.streamInputShrink)) {
    body['StreamInput'] = request.streamInputShrink;
  }
  if (!$isNull(request.templateId)) {
    body['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitLiveRecordJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a live stream recording job.
 *
 * @description You can call this operation to record live streams of ApsaraVideo Live or third-party Real-Time Messaging Protocol (RTMP) live streams. We recommend that you ingest a stream before you call this operation to submit a recording job. If no stream is pulled from the streaming URL, the job attempts to pull a stream for 3 minutes. If the attempt times out, the recording service stops.
 * Before you submit a recording job, you must prepare an Object Storage Service (OSS) or ApsaraVideo VOD bucket. We recommend that you use a storage address configured in Intelligent Media Services (IMS) to facilitate the management and processing of generated recording files.
 * If the preset recording template does not meet your requirements, you can create a custom recording template.
 *
 * @param request SubmitLiveRecordJobRequest
 * @return SubmitLiveRecordJobResponse
 */
async function submitLiveRecordJob(request: SubmitLiveRecordJobRequest): SubmitLiveRecordJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitLiveRecordJobWithOptions(request, runtime);
}

model SubmitLiveSnapshotJobRequest {
  callbackUrl?: string(name='CallbackUrl', description='The snapshot callback URL.

*   It cannot exceed 255 characters in length.
*   Both HTTP and HTTPS URLs are supported.', example='http://www.aliyun.com/snapshot/callback'),
  jobName?: string(name='JobName', description='The name of the job.

*   It cannot exceed 128 characters in length.

This parameter is required.'),
  snapshotOutput?: {
    bucket?: string(name='Bucket', description='The bucket of the snapshot output endpoint.

This parameter is required.', example='testbucket'),
    endpoint?: string(name='Endpoint', description='The output endpoint of the snapshot.

This parameter is required.', example='oss-cn-shanghai.aliyuncs.com'),
    storageType?: string(name='StorageType', description='The storage type of the snapshot. The value can only be oss.

This parameter is required.', example='oss'),
  }(name='SnapshotOutput', description='The information about the output snapshot.

This parameter is required.'),
  streamInput?: {
    type?: string(name='Type', description='The type of the input stream. The value can only be rtmp.

This parameter is required.', example='rtmp'),
    url?: string(name='Url', description='The URL of the input stream.

*   It cannot exceed 255 characters in length.

This parameter is required.', example='rtmp://www.aliyun.com/stream'),
  }(name='StreamInput', description='The information about the input stream.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model SubmitLiveSnapshotJobShrinkRequest {
  callbackUrl?: string(name='CallbackUrl', description='The snapshot callback URL.

*   It cannot exceed 255 characters in length.
*   Both HTTP and HTTPS URLs are supported.', example='http://www.aliyun.com/snapshot/callback'),
  jobName?: string(name='JobName', description='The name of the job.

*   It cannot exceed 128 characters in length.

This parameter is required.'),
  snapshotOutputShrink?: string(name='SnapshotOutput', description='The information about the output snapshot.

This parameter is required.'),
  streamInputShrink?: string(name='StreamInput', description='The information about the input stream.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
}

model SubmitLiveSnapshotJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****a046-263c-3560-978a-fb287666****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitLiveSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveSnapshotJobResponseBody(name='body'),
}

/**
 * @summary Submits a live stream snapshot job. If the job is submitted during stream ingest, it automatically starts in asynchronous mode. Otherwise, it does not start.
 *
 * @param tmpReq SubmitLiveSnapshotJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitLiveSnapshotJobResponse
 */
async function submitLiveSnapshotJobWithOptions(tmpReq: SubmitLiveSnapshotJobRequest, runtime: $RuntimeOptions): SubmitLiveSnapshotJobResponse {
  tmpReq.validate();
  var request = new SubmitLiveSnapshotJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.snapshotOutput)) {
    request.snapshotOutputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.snapshotOutput, 'SnapshotOutput', 'json');
  }
  if (!$isNull(tmpReq.streamInput)) {
    request.streamInputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.streamInput, 'StreamInput', 'json');
  }
  var body : map[string]any = {};
  if (!$isNull(request.callbackUrl)) {
    body['CallbackUrl'] = request.callbackUrl;
  }
  if (!$isNull(request.jobName)) {
    body['JobName'] = request.jobName;
  }
  if (!$isNull(request.snapshotOutputShrink)) {
    body['SnapshotOutput'] = request.snapshotOutputShrink;
  }
  if (!$isNull(request.streamInputShrink)) {
    body['StreamInput'] = request.streamInputShrink;
  }
  if (!$isNull(request.templateId)) {
    body['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitLiveSnapshotJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a live stream snapshot job. If the job is submitted during stream ingest, it automatically starts in asynchronous mode. Otherwise, it does not start.
 *
 * @param request SubmitLiveSnapshotJobRequest
 * @return SubmitLiveSnapshotJobResponse
 */
async function submitLiveSnapshotJob(request: SubmitLiveSnapshotJobRequest): SubmitLiveSnapshotJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitLiveSnapshotJobWithOptions(request, runtime);
}

model SubmitLiveTranscodeJobRequest {
  name?: string(name='Name', description='The name of the transcoding job.

This parameter is required.', example='task1'),
  startMode?: int32(name='StartMode', description='The start mode of the transcoding job.

*   0: The transcoding job immediately starts.
*   1: The transcoding job starts at the scheduled time.

This parameter is required.', example='0'),
  streamInput?: {
    inputUrl?: string(name='InputUrl', description='The URL of the input stream.

This parameter is required.', example='rtmp://mydomain/app/stream1'),
    type?: string(name='Type', description='The type of the input stream. The value can only be rtmp.

This parameter is required.', example='rtmp'),
  }(name='StreamInput', description='The information about the input stream.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
  timedConfig?: {
    endTime?: string(name='EndTime', description='The stop time of the transcoding job. Note: The time span between the stop time and the current time cannot exceed seven days.', example='2022-07-20T08:20:32Z'),
    startTime?: string(name='StartTime', description='The start time of the transcoding job. Note: The time span between the start time and the current time cannot exceed seven days.', example='2022-02-21T00:00:00Z'),
  }(name='TimedConfig', description='The configuration of a timed transcoding job. This parameter is required if you set StartMode to 1.'),
  transcodeOutput?: {
    domainName?: string(name='DomainName', description='The streaming domain name of ApsaraVideo Live.', example='mydomain'),
    type?: string(name='Type', description='The type of the output stream. A value of LiveCenter indicates that the URL of the output stream is generated based on the domain name of ApsaraVideo Live. The value can only be LiveCenter.

This parameter is required.', example='LiveCenter'),
  }(name='TranscodeOutput', description='The information about the transcoding output.

This parameter is required.'),
}

model SubmitLiveTranscodeJobShrinkRequest {
  name?: string(name='Name', description='The name of the transcoding job.

This parameter is required.', example='task1'),
  startMode?: int32(name='StartMode', description='The start mode of the transcoding job.

*   0: The transcoding job immediately starts.
*   1: The transcoding job starts at the scheduled time.

This parameter is required.', example='0'),
  streamInputShrink?: string(name='StreamInput', description='The information about the input stream.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
  timedConfigShrink?: string(name='TimedConfig', description='The configuration of a timed transcoding job. This parameter is required if you set StartMode to 1.'),
  transcodeOutputShrink?: string(name='TranscodeOutput', description='The information about the transcoding output.

This parameter is required.'),
}

model SubmitLiveTranscodeJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the transcoding job.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model SubmitLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitLiveTranscodeJobResponseBody(name='body'),
}

/**
 * @summary Submits a live stream transcoding job.
 *
 * @description *   When you submit a transcoding job that immediately takes effect, make sure that the input stream can be streamed.
 * *   When you submit a timed transcoding job, make sure that the input stream can be streamed before the specified time.
 *
 * @param tmpReq SubmitLiveTranscodeJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitLiveTranscodeJobResponse
 */
async function submitLiveTranscodeJobWithOptions(tmpReq: SubmitLiveTranscodeJobRequest, runtime: $RuntimeOptions): SubmitLiveTranscodeJobResponse {
  tmpReq.validate();
  var request = new SubmitLiveTranscodeJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.streamInput)) {
    request.streamInputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.streamInput, 'StreamInput', 'json');
  }
  if (!$isNull(tmpReq.timedConfig)) {
    request.timedConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.timedConfig, 'TimedConfig', 'json');
  }
  if (!$isNull(tmpReq.transcodeOutput)) {
    request.transcodeOutputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.transcodeOutput, 'TranscodeOutput', 'json');
  }
  var query = {};
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.startMode)) {
    query['StartMode'] = request.startMode;
  }
  if (!$isNull(request.streamInputShrink)) {
    query['StreamInput'] = request.streamInputShrink;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!$isNull(request.timedConfigShrink)) {
    query['TimedConfig'] = request.timedConfigShrink;
  }
  if (!$isNull(request.transcodeOutputShrink)) {
    query['TranscodeOutput'] = request.transcodeOutputShrink;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitLiveTranscodeJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a live stream transcoding job.
 *
 * @description *   When you submit a transcoding job that immediately takes effect, make sure that the input stream can be streamed.
 * *   When you submit a timed transcoding job, make sure that the input stream can be streamed before the specified time.
 *
 * @param request SubmitLiveTranscodeJobRequest
 * @return SubmitLiveTranscodeJobResponse
 */
async function submitLiveTranscodeJob(request: SubmitLiveTranscodeJobRequest): SubmitLiveTranscodeJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitLiveTranscodeJobWithOptions(request, runtime);
}

model SubmitMediaAiAnalysisJobRequest {
  analysisParams?: string(name='AnalysisParams', description='The analysis parameters.', example='{"nlpParams":{"sourceLanguage":"cn","diarizationEnabled":true,"speakerCount":0,"summarizationEnabled":false,"translationEnabled":false}}'),
  input?: string(name='Input', description='The media asset that you want to analyze. You can specify an Object Storage Service (OSS) URL, a media asset ID, or an external URL.', example='{"MediaType":"video","Media":"https://xxx.com/your_movie.mp4"}'),
  userData?: string(name='UserData'),
}

model SubmitMediaAiAnalysisJobResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model SubmitMediaAiAnalysisJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaAiAnalysisJobResponseBody(name='body'),
}

/**
 * @summary Submits a structural analysis job for a media asset. For example, you can submit a job to analyze the speaker, translate the video, and obtain the paragraph summary.
 *
 * @param request SubmitMediaAiAnalysisJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitMediaAiAnalysisJobResponse
 */
async function submitMediaAiAnalysisJobWithOptions(request: SubmitMediaAiAnalysisJobRequest, runtime: $RuntimeOptions): SubmitMediaAiAnalysisJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.analysisParams)) {
    query['AnalysisParams'] = request.analysisParams;
  }
  if (!$isNull(request.input)) {
    query['Input'] = request.input;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitMediaAiAnalysisJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a structural analysis job for a media asset. For example, you can submit a job to analyze the speaker, translate the video, and obtain the paragraph summary.
 *
 * @param request SubmitMediaAiAnalysisJobRequest
 * @return SubmitMediaAiAnalysisJobResponse
 */
async function submitMediaAiAnalysisJob(request: SubmitMediaAiAnalysisJobRequest): SubmitMediaAiAnalysisJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitMediaAiAnalysisJobWithOptions(request, runtime);
}

model SubmitMediaCensorJobRequest {
  barrages?: string(name='Barrages', description='The live comments of the video.

>  If this parameter is specified, the system checks the live comments specified by this parameter instead of the live comments of the input file specified by Media.', example='hello world'),
  coverImages?: string(name='CoverImages', description='The Object Storage Service (OSS) objects that are used as the thumbnails. Specify the thumbnails in a JSON array. A maximum of five thumbnails are supported.

>  If this parameter is specified, the system checks the thumbnails specified by this parameter instead of the thumbnails of the input file specified by **Media**.', example='[{"Bucket":"example-bucket-****","Location":"oss-cn-shanghai","Object":"example-****.jpeg","RoleArn":"acs:ram::1997018457688683:role/AliyunICEDefaultRole"}]'),
  description?: string(name='Description', description='The video description, which can be up to 128 bytes in length.

>  If this parameter is specified, the system checks the description specified by this parameter instead of the description of the input file specified by Media.', example='example description'),
  input?: {
    media?: string(name='Media', description='The input file. The file can be an OSS object or a media asset. You can specify the path of an OSS object in one of the following formats:

1\\\\. oss://bucket/object

2\\\\. http(s)://bucket.oss-[regionId].aliyuncs.com/object

In the preceding paths, bucket indicates an OSS bucket that resides in the same region as the current project, and object indicates the path of the object in the bucket.', example='1b1b9cd148034739af413150fded****'),
    type?: string(name='Type', description='The type of the input file. Valid values:

OSS: OSS object.

Media: media asset.', example='Media'),
  }(name='Input', description='The information about the file to be moderated.'),
  notifyUrl?: string(name='NotifyUrl', description='The callback URL. Simple Message Queue (SMQ, formerly MNS) and HTTP callbacks are supported.', example='mns://125340688170****.oss-cn-shanghai.aliyuncs.com/queues/example-pipeline'),
  output?: string(name='Output', description='The output snapshots. The moderation job generates output snapshots and the result JSON file in the path corresponding to the input file.

*   File name format of output snapshots: oss://bucket/snapshot-{Count}.jpg. In the path, bucket indicates an OSS bucket that resides in the same region as the current project, and {Count} is the sequence number of the snapshot.
*   The detailed moderation results are stored in the {jobId}.output file in the same OSS folder as the output snapshots. For more information about the parameters in the output file, see [Output parameters of media moderation jobs](https://help.aliyun.com/document_detail/609211.html).', example='oss://sashimi-cn-shanghai/censor/snapshot-{Count}.jpg'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which the job is submitted.', example='5246b8d12a62433ab77845074039****'),
    priority?: int32(name='Priority', description='The job priority. A larger value indicates a higher priority. Valid values: 1 to 10.', example='6'),
  }(name='ScheduleConfig', description='The scheduling configurations.'),
  templateId?: string(name='TemplateId', description='The template ID. If this parameter is not specified, the default template is used for moderation.', example='S00000001-100060'),
  title?: string(name='Title', description='The video title, which can be up to 64 bytes in length.

>  If this parameter is specified, the system checks the title specified by this parameter instead of the title of the input file specified by Media.', example='Hello World'),
  userData?: string(name='UserData', description='The user-defined data, which can be up to 128 bytes in length.', example='UserDatatestid-001-****'),
}

model SubmitMediaCensorJobShrinkRequest {
  barrages?: string(name='Barrages', description='The live comments of the video.

>  If this parameter is specified, the system checks the live comments specified by this parameter instead of the live comments of the input file specified by Media.', example='hello world'),
  coverImages?: string(name='CoverImages', description='The Object Storage Service (OSS) objects that are used as the thumbnails. Specify the thumbnails in a JSON array. A maximum of five thumbnails are supported.

>  If this parameter is specified, the system checks the thumbnails specified by this parameter instead of the thumbnails of the input file specified by **Media**.', example='[{"Bucket":"example-bucket-****","Location":"oss-cn-shanghai","Object":"example-****.jpeg","RoleArn":"acs:ram::1997018457688683:role/AliyunICEDefaultRole"}]'),
  description?: string(name='Description', description='The video description, which can be up to 128 bytes in length.

>  If this parameter is specified, the system checks the description specified by this parameter instead of the description of the input file specified by Media.', example='example description'),
  inputShrink?: string(name='Input', description='The information about the file to be moderated.'),
  notifyUrl?: string(name='NotifyUrl', description='The callback URL. Simple Message Queue (SMQ, formerly MNS) and HTTP callbacks are supported.', example='mns://125340688170****.oss-cn-shanghai.aliyuncs.com/queues/example-pipeline'),
  output?: string(name='Output', description='The output snapshots. The moderation job generates output snapshots and the result JSON file in the path corresponding to the input file.

*   File name format of output snapshots: oss://bucket/snapshot-{Count}.jpg. In the path, bucket indicates an OSS bucket that resides in the same region as the current project, and {Count} is the sequence number of the snapshot.
*   The detailed moderation results are stored in the {jobId}.output file in the same OSS folder as the output snapshots. For more information about the parameters in the output file, see [Output parameters of media moderation jobs](https://help.aliyun.com/document_detail/609211.html).', example='oss://sashimi-cn-shanghai/censor/snapshot-{Count}.jpg'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling configurations.'),
  templateId?: string(name='TemplateId', description='The template ID. If this parameter is not specified, the default template is used for moderation.', example='S00000001-100060'),
  title?: string(name='Title', description='The video title, which can be up to 64 bytes in length.

>  If this parameter is specified, the system checks the title specified by this parameter instead of the title of the input file specified by Media.', example='Hello World'),
  userData?: string(name='UserData', description='The user-defined data, which can be up to 128 bytes in length.', example='UserDatatestid-001-****'),
}

model SubmitMediaCensorJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the content moderation job. We recommend that you save this ID for subsequent calls of other operations.', example='88c6ca184c0e47098a5b665e2****'),
  requestId?: string(name='RequestId', description='The request ID.', example='25818875-5F78-4A13-BEF6-D7393642CA58'),
}

model SubmitMediaCensorJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaCensorJobResponseBody(name='body'),
}

/**
 * @summary Submits a content moderation job.
 *
 * @description The job that you submit by calling this operation is run in asynchronous mode. The job is added to an ApsaraVideo Media Processing (MPS) queue to be scheduled and run. You can call the [QueryMediaCensorJobDetail](https://help.aliyun.com/document_detail/444847.html) operation or configure an asynchronous notification to obtain the job results.
 *
 * @param tmpReq SubmitMediaCensorJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitMediaCensorJobResponse
 */
async function submitMediaCensorJobWithOptions(tmpReq: SubmitMediaCensorJobRequest, runtime: $RuntimeOptions): SubmitMediaCensorJobResponse {
  tmpReq.validate();
  var request = new SubmitMediaCensorJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!$isNull(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.barrages)) {
    query['Barrages'] = request.barrages;
  }
  if (!$isNull(request.coverImages)) {
    query['CoverImages'] = request.coverImages;
  }
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!$isNull(request.notifyUrl)) {
    query['NotifyUrl'] = request.notifyUrl;
  }
  if (!$isNull(request.output)) {
    query['Output'] = request.output;
  }
  if (!$isNull(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!$isNull(request.title)) {
    query['Title'] = request.title;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitMediaCensorJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a content moderation job.
 *
 * @description The job that you submit by calling this operation is run in asynchronous mode. The job is added to an ApsaraVideo Media Processing (MPS) queue to be scheduled and run. You can call the [QueryMediaCensorJobDetail](https://help.aliyun.com/document_detail/444847.html) operation or configure an asynchronous notification to obtain the job results.
 *
 * @param request SubmitMediaCensorJobRequest
 * @return SubmitMediaCensorJobResponse
 */
async function submitMediaCensorJob(request: SubmitMediaCensorJobRequest): SubmitMediaCensorJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitMediaCensorJobWithOptions(request, runtime);
}

model SubmitMediaConvertJobRequest {
  clientToken?: string(name='ClientToken', description='The idempotency key that is used to ensure repeated requests have the same effect as a single request.', example='86f8e525-9d73-4dac-88aa-7aa4e950c00a'),
  config?: string(name='Config', description='The configurations of the transcoding task.

This parameter is required.'),
  pipelineId?: string(name='PipelineId', description='The ID of the queue.', example='e197ecfb103e4849922b054d3032f954'),
  userData?: string(name='UserData', description='The user data.', example='{"videoId":"abcd"}'),
}

model SubmitMediaConvertJobResponseBody = {
  job?: {
    clientToken?: string(name='ClientToken', description='The idempotency key of the request for creating the transcoding task.', example='FB7F25E9-AD9B-1603-8AF6-F1E42DF2E706'),
    code?: string(name='Code', description='The error code returned when the transcoding task failed.', example='200'),
    config?: {
      inputs?: [
        MediaConvertInput
      ](name='Inputs', description='The inputs of the transcoding task.'),
      outputGroups?: [
        MediaConvertOutputGroup
      ](name='OutputGroups', description='The output group configurations.'),
      outputs?: [
        MediaConvertOutput
      ](name='Outputs', description='The output configurations.'),
    }(name='Config', description='The configurations of the transcoding task.'),
    jobId?: string(name='JobId', description='The ID of the transcoding task.', example='****20b48fb04483915d4f2cd8ac****'),
    message?: string(name='Message', description='The error message returned when the transcoding task failed.', example='ok'),
    outputDetails?: [
      MediaConvertOutputDetail
    ](name='OutputDetails', description='The details of the transcoded outputs.'),
    outputGroupDetails?: [
      MediaConvertOutputGroupDetail
    ](name='OutputGroupDetails', description='The details of the output groups.'),
    pipelineId?: string(name='PipelineId', description='The ID of the queue.', example='3780049'),
    requestId?: string(name='RequestId', description='The ID of the request.', example='A2129C9F-CE95-58B5-B8C1-07758FF6C86F'),
    state?: string(name='State', description='The status of the transcoding task. Valid values:

*   Inited: The task is initialized.
*   Running
*   Success
*   Failed
*   Cancelled', example='Created'),
    userData?: string(name='UserData', description='The user data.', example='{"videoId":"abcd"}'),
  }(name='Job', description='The transcoding task.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitMediaConvertJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaConvertJobResponseBody(name='body'),
}

/**
 * @summary Submits a transcoding task.
 *
 * @param request SubmitMediaConvertJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitMediaConvertJobResponse
 */
async function submitMediaConvertJobWithOptions(request: SubmitMediaConvertJobRequest, runtime: $RuntimeOptions): SubmitMediaConvertJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!$isNull(request.config)) {
    query['Config'] = request.config;
  }
  if (!$isNull(request.pipelineId)) {
    query['PipelineId'] = request.pipelineId;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitMediaConvertJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a transcoding task.
 *
 * @param request SubmitMediaConvertJobRequest
 * @return SubmitMediaConvertJobResponse
 */
async function submitMediaConvertJob(request: SubmitMediaConvertJobRequest): SubmitMediaConvertJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitMediaConvertJobWithOptions(request, runtime);
}

model SubmitMediaInfoJobRequest {
  input?: {
    media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
    type?: string(name='Type', description='The type of the media object. Valid values: OSS and Media. A value of OSS indicates an Object Storage Service (OSS) object. A value of Media indicates a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The job name.', example='job-name'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling parameters.'),
  userData?: string(name='UserData', description='The user data.', example='user-data'),
}

model SubmitMediaInfoJobShrinkRequest {
  inputShrink?: string(name='Input', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The job name.', example='job-name'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling parameters.'),
  userData?: string(name='UserData', description='The user data.', example='user-data'),
}

model SubmitMediaInfoJobResponseBody = {
  mediaInfoJob?: {
    async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
    input?: {
      media?: string(name='Media', description='The media object. If Type is set to OSS, the URL of an OSS object is returned. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values: OSS and Media. A value of OSS indicates an OSS object. A value of Media indicates a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    mediaInfoProperty?: {
      audioStreamInfoList?: [ 
        {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
          channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
          codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
          codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
          codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
          codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
          duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
          index?: string(name='Index', description='The sequence number of the stream.', example='1'),
          lang?: string(name='Lang', description='The language of the stream.', example='us'),
          sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
          sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
          startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
          timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
        }
      ](name='AudioStreamInfoList', description='The information about the audio stream.'),
      fileBasicInfo?: {
        bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
        duration?: string(name='Duration', description='The duration of the video.', example='403.039999'),
        fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
        fileSize?: string(name='FileSize', description='The file size.', example='31737'),
        fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
        fileType?: string(name='FileType', description='The file type.', example='source_file'),
        fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
        formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
        height?: string(name='Height', description='The height of the output video.', example='478'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='2b36bd19c13f4145b094c0cad80dbce5'),
        region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
        width?: string(name='Width', description='The width of the output video.', example='848'),
      }(name='FileBasicInfo', description='The basic file information.'),
      videoStreamInfoList?: [ 
        {
          avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
          bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
          codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
          codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
          codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
          codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
          codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
          dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          fps?: string(name='Fps', description='The frame rate.', example='25.0'),
          hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
          height?: string(name='Height', description='The height of the output video.', example='478'),
          index?: string(name='Index', description='The sequence number of the stream.', example='0'),
          lang?: string(name='Lang', description='The language of the stream.', example='zh'),
          level?: string(name='Level', description='The codec level.', example='31'),
          numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
          pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
          profile?: string(name='Profile', description='The encoder profile.', example='High'),
          rotate?: string(name='Rotate', description='The rotation angle of the video image.', example='0'),
          sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
          startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
          timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
          width?: string(name='Width', description='The width of the output video.', example='848'),
        }
      ](name='VideoStreamInfoList', description='The information about the video stream.'),
    }(name='MediaInfoProperty', description='The details of the media information.'),
    name?: string(name='Name', description='The job name.', example='job-name'),
    requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling information.'),
    status?: string(name='Status', description='The state of the job. Valid values: Init (the job is submitted), Success (the job is successful), and Fail (the job failed).', example='Init'),
    submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.', example='{}'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='MediaInfoJob', description='MediaInfoJobDTO'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model SubmitMediaInfoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaInfoJobResponseBody(name='body'),
}

/**
 * @summary Submits a media information analysis job in asynchronous mode.
 *
 * @description You can call this operation to analyze an input media file by using a callback mechanism or initiating subsequent queries. This operation is suitable for scenarios in which real-time performance is less critical and high concurrency is expected.
 *
 * @param tmpReq SubmitMediaInfoJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitMediaInfoJobResponse
 */
async function submitMediaInfoJobWithOptions(tmpReq: SubmitMediaInfoJobRequest, runtime: $RuntimeOptions): SubmitMediaInfoJobResponse {
  tmpReq.validate();
  var request = new SubmitMediaInfoJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!$isNull(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitMediaInfoJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a media information analysis job in asynchronous mode.
 *
 * @description You can call this operation to analyze an input media file by using a callback mechanism or initiating subsequent queries. This operation is suitable for scenarios in which real-time performance is less critical and high concurrency is expected.
 *
 * @param request SubmitMediaInfoJobRequest
 * @return SubmitMediaInfoJobResponse
 */
async function submitMediaInfoJob(request: SubmitMediaInfoJobRequest): SubmitMediaInfoJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitMediaInfoJobWithOptions(request, runtime);
}

model SubmitMediaProducingJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****'),
  clipsParam?: string(name='ClipsParam', description='The material parameters of the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified. For more information, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html) and [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).'),
  editingProduceConfig?: string(name='EditingProduceConfig', description='The parameters for editing and production. For more information, see [EditingProduceConfig](https://help.aliyun.com/document_detail/357745.html).

>  If no thumbnail is specified in EditingProduceConfig, the first frame of the video is used as the thumbnail.

*   AutoRegisterInputVodMedia: specifies whether to automatically register the ApsaraVideo VOD media assets in your timeline with IMS. Default value: true.
*   OutputWebmTransparentChannel: specifies whether the output video contains alpha channels. Default value: false.
*   CoverConfig: the custom thumbnail parameters.
*', example='{
      "AutoRegisterInputVodMedia": "true",
      "OutputWebmTransparentChannel": "true"
}'),
  mediaMetadata?: string(name='MediaMetadata', description='The metadata of the produced video, in the JSON format. For more information about the parameters, see [MediaMetadata](https://help.aliyun.com/document_detail/357745.html).', example='{
      "Title":"test-title",
      "Tags":"test-tags1,tags2"
}'),
  outputMediaConfig?: string(name='OutputMediaConfig', description='The configurations of the output file, in the JSON format. You can specify an OSS URL or a storage location in a storage bucket of ApsaraVideo VOD.

To store the output file in OSS, you must specify MediaURL. To store the output file in ApsaraVideo VOD, you must specify StorageLocation and FileName.

For more information, see [OutputMediaConfig](https://help.aliyun.com/document_detail/357745.html).

This parameter is required.', example='{"MediaURL":"https://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4"}'),
  outputMediaTarget?: string(name='OutputMediaTarget', description='The type of the output file. Valid values:

*   oss-object: OSS object in an OSS bucket.
*   vod-media: media asset in ApsaraVideo VOD.
*   S3: output file based on the Amazon Simple Storage Service (S3) protocol.', example='oss-object'),
  projectId?: string(name='ProjectId', description='The ID of the editing project.

> : You must specify one of ProgectId, Timeline, and TempalteId and leave the other two parameters empty.', example='xxxxxfb2101cb318xxxxx'),
  projectMetadata?: string(name='ProjectMetadata', description='The metadata of the editing project, in the JSON format. For more information about the parameters, see [ProjectMetadata](https://help.aliyun.com/document_detail/357745.html).'),
  source?: string(name='Source', description='The source of the editing and production request. Valid values:

*   OpenAPI
*   AliyunConsole
*   WebSDK', example='OPENAPI'),
  templateId?: string(name='TemplateId', description='The template ID. The template is used to build a timeline with ease.

> : You must specify one of ProgectId, Timeline, and TempalteId and leave the other two parameters empty. If TemplateId is specified, ClipsParam must also be specified.', example='****96e8864746a0b6f3****'),
  timeline?: string(name='Timeline'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).', example='{"NotifyAddress":"https://xx.com/xx","RegisterMediaNotifyAddress":"https://xxx.com/xx"}'),
}

model SubmitMediaProducingJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
  mediaId?: string(name='MediaId', description='The media asset ID of the output file.', example='****c469e944b5a856828dc2****'),
  projectId?: string(name='ProjectId', description='The ID of the editing project.', example='****b4549d46c88681030f6e****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
  vodMediaId?: string(name='VodMediaId', description='The media asset ID of the output file in ApsaraVideo VOD if the output file is stored in ApsaraVideo VOD.', example='****d8s4h75ci975745c14b****'),
}

model SubmitMediaProducingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitMediaProducingJobResponseBody(name='body'),
}

/**
 * @summary Submits a media editing and production job. If you need to perform any form of post-production such as editing and production on video or audio materials, you can call this operation to automate the process.
 *
 * @description *   This operation returns only the submission result of a media editing and production job. When the submission result is returned, the job may still be in progress. After a media editing and production job is submitted, the job is queued in the background for asynchronous processing.
 * *   The materials referenced in the timeline of an online editing project can be media assets in the media asset library or Object Storage Service (OSS) objects. External URLs or Alibaba Cloud Content Delivery Network (CDN) URLs are not supported. To use an OSS object as a material, you must set MediaUrl to an OSS URL, such as https://your-bucket.oss-region-name.aliyuncs.com/your-object.ext.
 * *   After the production is complete, the output file is automatically registered as a media asset. The media asset first needs to be analyzed. After the media asset is analyzed, you can query the duration and resolution information based on the media asset ID.
 * ## [](#)Limits
 * *   The throttling threshold of this operation is 30 queries per second (QPS).
 *     **
 *     **Note** If the threshold is exceeded, a "Throttling.User" error is returned when you submit an editing job. For more information about how to resolve this issue, see the [FAQ](https://help.aliyun.com/document_detail/453484.html).
 * *   You can create up to 100 video tracks, 100 image tracks, and 100 subtitle tracks in a project.
 * *   The total size of material files cannot exceed 1 TB.
 * *   The OSS buckets in which the materials reside and where the output media assets are stored must be in the same region as the region in which Intelligent Media Services (IMS) is activated.
 * *   An output video must meet the following requirements:
 *     *   Both the width and height must be at least 128 pixels.
 *     *   Both the width and height cannot exceed 4,096 pixels.
 *     *   The shorter side of the video cannot exceed 2,160 pixels.
 *
 * @param request SubmitMediaProducingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitMediaProducingJobResponse
 */
async function submitMediaProducingJobWithOptions(request: SubmitMediaProducingJobRequest, runtime: $RuntimeOptions): SubmitMediaProducingJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!$isNull(request.clipsParam)) {
    query['ClipsParam'] = request.clipsParam;
  }
  if (!$isNull(request.editingProduceConfig)) {
    query['EditingProduceConfig'] = request.editingProduceConfig;
  }
  if (!$isNull(request.mediaMetadata)) {
    query['MediaMetadata'] = request.mediaMetadata;
  }
  if (!$isNull(request.outputMediaConfig)) {
    query['OutputMediaConfig'] = request.outputMediaConfig;
  }
  if (!$isNull(request.outputMediaTarget)) {
    query['OutputMediaTarget'] = request.outputMediaTarget;
  }
  if (!$isNull(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  if (!$isNull(request.projectMetadata)) {
    query['ProjectMetadata'] = request.projectMetadata;
  }
  if (!$isNull(request.source)) {
    query['Source'] = request.source;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var body : map[string]any = {};
  if (!$isNull(request.timeline)) {
    body['Timeline'] = request.timeline;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitMediaProducingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a media editing and production job. If you need to perform any form of post-production such as editing and production on video or audio materials, you can call this operation to automate the process.
 *
 * @description *   This operation returns only the submission result of a media editing and production job. When the submission result is returned, the job may still be in progress. After a media editing and production job is submitted, the job is queued in the background for asynchronous processing.
 * *   The materials referenced in the timeline of an online editing project can be media assets in the media asset library or Object Storage Service (OSS) objects. External URLs or Alibaba Cloud Content Delivery Network (CDN) URLs are not supported. To use an OSS object as a material, you must set MediaUrl to an OSS URL, such as https://your-bucket.oss-region-name.aliyuncs.com/your-object.ext.
 * *   After the production is complete, the output file is automatically registered as a media asset. The media asset first needs to be analyzed. After the media asset is analyzed, you can query the duration and resolution information based on the media asset ID.
 * ## [](#)Limits
 * *   The throttling threshold of this operation is 30 queries per second (QPS).
 *     **
 *     **Note** If the threshold is exceeded, a "Throttling.User" error is returned when you submit an editing job. For more information about how to resolve this issue, see the [FAQ](https://help.aliyun.com/document_detail/453484.html).
 * *   You can create up to 100 video tracks, 100 image tracks, and 100 subtitle tracks in a project.
 * *   The total size of material files cannot exceed 1 TB.
 * *   The OSS buckets in which the materials reside and where the output media assets are stored must be in the same region as the region in which Intelligent Media Services (IMS) is activated.
 * *   An output video must meet the following requirements:
 *     *   Both the width and height must be at least 128 pixels.
 *     *   Both the width and height cannot exceed 4,096 pixels.
 *     *   The shorter side of the video cannot exceed 2,160 pixels.
 *
 * @param request SubmitMediaProducingJobRequest
 * @return SubmitMediaProducingJobResponse
 */
async function submitMediaProducingJob(request: SubmitMediaProducingJobRequest): SubmitMediaProducingJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitMediaProducingJobWithOptions(request, runtime);
}

model SubmitPackageJobRequest {
  inputs?: [ 
    {
      input?: {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
      }(name='Input', description='The information about the input stream file.

This parameter is required.'),
    }
  ](name='Inputs', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The name of the job.', example='job-name'),
  output?: {
    media?: string(name='Media', description='The media object. If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
    type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Output', description='The output of the job.

This parameter is required.'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling settings.'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}'),
}

model SubmitPackageJobShrinkRequest {
  inputsShrink?: string(name='Inputs', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The name of the job.', example='job-name'),
  outputShrink?: string(name='Output', description='The output of the job.

This parameter is required.'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling settings.'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"param": "value"}'),
}

model SubmitPackageJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='2d705f385b704ee5b*******a36d93e0'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model SubmitPackageJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitPackageJobResponseBody(name='body'),
}

/**
 * @summary Submits a packaging job.
 *
 * @param tmpReq SubmitPackageJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitPackageJobResponse
 */
async function submitPackageJobWithOptions(tmpReq: SubmitPackageJobRequest, runtime: $RuntimeOptions): SubmitPackageJobResponse {
  tmpReq.validate();
  var request = new SubmitPackageJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.inputs)) {
    request.inputsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.inputs, 'Inputs', 'json');
  }
  if (!$isNull(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  if (!$isNull(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.inputsShrink)) {
    query['Inputs'] = request.inputsShrink;
  }
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!$isNull(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitPackageJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a packaging job.
 *
 * @param request SubmitPackageJobRequest
 * @return SubmitPackageJobResponse
 */
async function submitPackageJob(request: SubmitPackageJobRequest): SubmitPackageJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitPackageJobWithOptions(request, runtime);
}

model SubmitProjectExportJobRequest {
  exportType?: string(name='ExportType', example='BaseTimeline'),
  outputMediaConfig?: string(name='OutputMediaConfig', description='This parameter is required.', example='{
	"Bucket": "example-bucket",
    "Prefix": "example_prefix"
}'),
  projectId?: string(name='ProjectId', example='*****67ae06542b9b93e0d1c387*****'),
  timeline?: string(name='Timeline', example='{"VideoTracks":[{"VideoTrackClips":[{"MediaId":"****4d7cf14dc7b83b0e801c****"},{"MediaId":"****4d7cf14dc7b83b0e801c****"}]}]}'),
  userData?: string(name='UserData', example='{"NotifyAddress":"http://xx.xx.xxx","Key":"Valuexxx"}'),
}

model SubmitProjectExportJobResponseBody = {
  jobId?: string(name='JobId', example='****cdb3e74639973036bc84****'),
  requestId?: string(name='RequestId', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitProjectExportJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitProjectExportJobResponseBody(name='body'),
}

/**
 * @summary 提交工程导出任务
 *
 * @param request SubmitProjectExportJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitProjectExportJobResponse
 */
async function submitProjectExportJobWithOptions(request: SubmitProjectExportJobRequest, runtime: $RuntimeOptions): SubmitProjectExportJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.exportType)) {
    query['ExportType'] = request.exportType;
  }
  if (!$isNull(request.outputMediaConfig)) {
    query['OutputMediaConfig'] = request.outputMediaConfig;
  }
  if (!$isNull(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var body : map[string]any = {};
  if (!$isNull(request.timeline)) {
    body['Timeline'] = request.timeline;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitProjectExportJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 提交工程导出任务
 *
 * @param request SubmitProjectExportJobRequest
 * @return SubmitProjectExportJobResponse
 */
async function submitProjectExportJob(request: SubmitProjectExportJobRequest): SubmitProjectExportJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitProjectExportJobWithOptions(request, runtime);
}

model SubmitScreenMediaHighlightsJobRequest {
  editingConfig?: string(name='EditingConfig', example='{
	"MediaConfig": {
		"Volume": 1
	},
	"ProcessConfig": {
		"AllowTransition": true,
		"TransitionList": ["fadecolor"]
	}
}'),
  inputConfig?: string(name='InputConfig', example='{
	"MediaArray": [
		"****9d46c886b45481030f6e****",
		"****6c886b4549d481030f6e****"
	]
}'),
  outputConfig?: string(name='OutputConfig', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 1,
  "Width": 1080,
  "Height": 1920
}'),
  userData?: string(name='UserData'),
}

model SubmitScreenMediaHighlightsJobResponseBody = {
  jobId?: string(name='JobId', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model SubmitScreenMediaHighlightsJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitScreenMediaHighlightsJobResponseBody(name='body'),
}

/**
 * @summary 提交高燃混剪任务
 *
 * @param request SubmitScreenMediaHighlightsJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitScreenMediaHighlightsJobResponse
 */
async function submitScreenMediaHighlightsJobWithOptions(request: SubmitScreenMediaHighlightsJobRequest, runtime: $RuntimeOptions): SubmitScreenMediaHighlightsJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var body : map[string]any = {};
  if (!$isNull(request.editingConfig)) {
    body['EditingConfig'] = request.editingConfig;
  }
  if (!$isNull(request.inputConfig)) {
    body['InputConfig'] = request.inputConfig;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitScreenMediaHighlightsJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 提交高燃混剪任务
 *
 * @param request SubmitScreenMediaHighlightsJobRequest
 * @return SubmitScreenMediaHighlightsJobResponse
 */
async function submitScreenMediaHighlightsJob(request: SubmitScreenMediaHighlightsJobRequest): SubmitScreenMediaHighlightsJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitScreenMediaHighlightsJobWithOptions(request, runtime);
}

model SubmitSegmentationJobRequest {
  clientToken?: string(name='ClientToken', example='****12e8864746a0a398****'),
  inputConfig?: string(name='InputConfig'),
  jobParams?: string(name='JobParams', example='{
	"Mode": "UserDefined",
	"Ranges": [{
		"In": 10,
		"Out": 20
	}, {
		"In": 35,
		"Out": 50
	}]
}'),
  outputConfig?: string(name='OutputConfig', example='{
	"OutputMediaTarget": "oss-object",
	"Bucket": "test-bucket",
	"ObjectKey": "path/to/test_{index}.mp4",
	"Width": 1920,
	"Height": 1080,
	"ExportAsNewMedia": false
}'),
  userData?: string(name='UserData'),
}

model SubmitSegmentationJobResponseBody = {
  jobId?: string(name='JobId', example='****cdb3e74639973036bc84****'),
  requestId?: string(name='RequestId', example='******3B-0E1A-586A-AC29-742247******'),
}

model SubmitSegmentationJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSegmentationJobResponseBody(name='body'),
}

/**
 * @summary 提交拆条任务
 *
 * @param request SubmitSegmentationJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitSegmentationJobResponse
 */
async function submitSegmentationJobWithOptions(request: SubmitSegmentationJobRequest, runtime: $RuntimeOptions): SubmitSegmentationJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!$isNull(request.jobParams)) {
    query['JobParams'] = request.jobParams;
  }
  if (!$isNull(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var body : map[string]any = {};
  if (!$isNull(request.inputConfig)) {
    body['InputConfig'] = request.inputConfig;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitSegmentationJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 提交拆条任务
 *
 * @param request SubmitSegmentationJobRequest
 * @return SubmitSegmentationJobResponse
 */
async function submitSegmentationJob(request: SubmitSegmentationJobRequest): SubmitSegmentationJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitSegmentationJobWithOptions(request, runtime);
}

model SubmitSmarttagJobRequest {
  content?: string(name='Content', description='The video description. The description can contain letters, digits, and hyphens (-) and cannot start with a special character. The description can be up to 1 KB in length.', example='example content ****'),
  contentAddr?: string(name='ContentAddr', description='This parameter is discontinued.', example='http://123.com/testVideo.mp4'),
  contentType?: string(name='ContentType', description='This parameter is discontinued.', example='application/zip'),
  input?: {
    media?: string(name='Media', description='If Type is set to OSS, specify an OSS path. Example: OSS://test-bucket/video/202208/test.mp4.

If Type is set to Media, specify a media asset ID. Example: c5c62d8f0361337cab312dce8e77dc6d.

If Type is set to URL, specify an HTTP URL. Example: https://zc-test.oss-cn-shanghai.aliyuncs.com/test/unknowFace.mp4.', example='c5c62d8f0361337cab312dce8e77dc6d'),
    type?: string(name='Type', description='The media type. Valid values:

*   OSS
*   Media
*   URL', example='Media'),
  }(name='Input', description='The job input.'),
  notifyUrl?: string(name='NotifyUrl', description='The URL for receiving callbacks. Set the value to an HTTP URL or an HTTPS URL.', example='https://example.com/endpoint/aliyun/ai?id=76401125000***'),
  params?: string(name='Params', description='The additional request parameters. The value is a JSON string. Example: {"needAsrData":true, "needOcrData":false}. The following parameters are supported:

*   needAsrData: specifies whether to query the automatic speech recognition (ASR) data. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   needOcrData: specifies whether to query the optical character recognition (OCR) data. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   needMetaData: specifies whether to query the metadata. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   nlpParams: the input parameters of the natural language processing (NLP) operator. The value is a JSON object. This parameter is empty by default, which indicates that the NLP operator is not used. For more information, see the "nlpParams" section of this topic.', example='{"needAsrData":true, "needOcrData":false}'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue to which you want to submit the smart tagging job. The MPS queue is bound to an SMQ queue. This parameter specifies the default MPS queue. By default, an MPS queue can process a maximum of two concurrent smart tagging jobs. To increase the limit, submit a ticket.', example='acdbfe4323bcfdae'),
    priority?: string(name='Priority', description='The job priority. This parameter is not implemented. You can leave this parameter empty or enter a random value.', example='4'),
  }(name='ScheduleConfig', description='The scheduling configurations.'),
  templateId?: string(name='TemplateId', description='The ID of the template that specifies the analysis algorithms. For more information about template operations, see [Configure templates](https://help.aliyun.com/document_detail/445702.html).', example='39f8e0bc005e4f309379701645f4'),
  title?: string(name='Title', description='The video title. The title can contain letters, digits, and hyphens (-) and cannot start with a special character. The title can be up to 256 bytes in length.', example='example-title-****'),
  userData?: string(name='UserData', description='The data to be passed through Simple Message Queue (SMQ, formerly MNS) during callbacks. The data can be up to 1 KB in length. For more information about how to specify an SMQ queue for receiving callbacks, see UpdatePipeline.', example='{“a”:"test"}'),
}

model SubmitSmarttagJobShrinkRequest {
  content?: string(name='Content', description='The video description. The description can contain letters, digits, and hyphens (-) and cannot start with a special character. The description can be up to 1 KB in length.', example='example content ****'),
  contentAddr?: string(name='ContentAddr', description='This parameter is discontinued.', example='http://123.com/testVideo.mp4'),
  contentType?: string(name='ContentType', description='This parameter is discontinued.', example='application/zip'),
  inputShrink?: string(name='Input', description='The job input.'),
  notifyUrl?: string(name='NotifyUrl', description='The URL for receiving callbacks. Set the value to an HTTP URL or an HTTPS URL.', example='https://example.com/endpoint/aliyun/ai?id=76401125000***'),
  params?: string(name='Params', description='The additional request parameters. The value is a JSON string. Example: {"needAsrData":true, "needOcrData":false}. The following parameters are supported:

*   needAsrData: specifies whether to query the automatic speech recognition (ASR) data. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   needOcrData: specifies whether to query the optical character recognition (OCR) data. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   needMetaData: specifies whether to query the metadata. The value is of the BOOLEAN type. Default value: false. Valid values: true and false.
*   nlpParams: the input parameters of the natural language processing (NLP) operator. The value is a JSON object. This parameter is empty by default, which indicates that the NLP operator is not used. For more information, see the "nlpParams" section of this topic.', example='{"needAsrData":true, "needOcrData":false}'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling configurations.'),
  templateId?: string(name='TemplateId', description='The ID of the template that specifies the analysis algorithms. For more information about template operations, see [Configure templates](https://help.aliyun.com/document_detail/445702.html).', example='39f8e0bc005e4f309379701645f4'),
  title?: string(name='Title', description='The video title. The title can contain letters, digits, and hyphens (-) and cannot start with a special character. The title can be up to 256 bytes in length.', example='example-title-****'),
  userData?: string(name='UserData', description='The data to be passed through Simple Message Queue (SMQ, formerly MNS) during callbacks. The data can be up to 1 KB in length. For more information about how to specify an SMQ queue for receiving callbacks, see UpdatePipeline.', example='{“a”:"test"}'),
}

model SubmitSmarttagJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the smart tagging job. We recommend that you save this ID for subsequent calls of other operations.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitSmarttagJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSmarttagJobResponseBody(name='body'),
}

/**
 * @summary Submits a smart tagging job.
 *
 * @description Before you call this operation to submit a smart tagging job, you must add a smart tagging template and specify the analysis types that you want to use in the template. For more information, see CreateCustomTemplate. You can use the smart tagging feature only in the China (Beijing), China (Shanghai), and China (Hangzhou) regions. By default, an ApsaraVideo Media Processing (MPS) queue can process a maximum of two concurrent smart tagging jobs. If you need to process more concurrent smart tagging jobs, submit a ticket to contact Alibaba Cloud Technical Support for evaluation and configuration.
 *
 * @param tmpReq SubmitSmarttagJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitSmarttagJobResponse
 */
async function submitSmarttagJobWithOptions(tmpReq: SubmitSmarttagJobRequest, runtime: $RuntimeOptions): SubmitSmarttagJobResponse {
  tmpReq.validate();
  var request = new SubmitSmarttagJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!$isNull(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.content)) {
    query['Content'] = request.content;
  }
  if (!$isNull(request.contentAddr)) {
    query['ContentAddr'] = request.contentAddr;
  }
  if (!$isNull(request.contentType)) {
    query['ContentType'] = request.contentType;
  }
  if (!$isNull(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!$isNull(request.notifyUrl)) {
    query['NotifyUrl'] = request.notifyUrl;
  }
  if (!$isNull(request.params)) {
    query['Params'] = request.params;
  }
  if (!$isNull(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!$isNull(request.title)) {
    query['Title'] = request.title;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitSmarttagJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a smart tagging job.
 *
 * @description Before you call this operation to submit a smart tagging job, you must add a smart tagging template and specify the analysis types that you want to use in the template. For more information, see CreateCustomTemplate. You can use the smart tagging feature only in the China (Beijing), China (Shanghai), and China (Hangzhou) regions. By default, an ApsaraVideo Media Processing (MPS) queue can process a maximum of two concurrent smart tagging jobs. If you need to process more concurrent smart tagging jobs, submit a ticket to contact Alibaba Cloud Technical Support for evaluation and configuration.
 *
 * @param request SubmitSmarttagJobRequest
 * @return SubmitSmarttagJobResponse
 */
async function submitSmarttagJob(request: SubmitSmarttagJobRequest): SubmitSmarttagJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitSmarttagJobWithOptions(request, runtime);
}

model SubmitSnapshotJobRequest {
  input?: {
    media?: string(name='Media', description='The input file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

This parameter is required.', example='oss://bucket/object.mp4'),
    type?: string(name='Type', description='The type of the input file. Valid values:

1.  OSS: an Object Storage Service (OSS) object.
2.  Media: a media asset.

This parameter is required.', example='Media'),
  }(name='Input', description='The snapshot input.

This parameter is required.'),
  name?: string(name='Name', description='The name of the job.', example='SampleJob'),
  output?: {
    media?: string(name='Media', description='The output file. If Type is set to OSS, the URL of an OSS object is returned. If Type is set to Media, the ID of a media asset is returned. The URL of an OSS object can be in one of the following formats:

1.  oss://bucket/object
2.  http(s)://bucket.oss-[RegionId].aliyuncs.com/object

In the URL, bucket specifies an OSS bucket that resides in the same region as the job, and object specifies the object URL in OSS. If multiple static snapshots were captured, the object must contain the "{Count}" placeholder. In the case of a sprite, the object must contain the "{TileCount}" placeholder. The suffix of the WebVTT snapshot objects must be ".vtt".

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the IMS console.

This parameter is required.', example='oss://test-bucket/output-{Count}.jpg'),
    type?: string(name='Type', description='The type of the output file. Valid values:

1.  OSS: an OSS object.
2.  Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Output', description='The snapshot output.

This parameter is required.'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the ApsaraVideo Media Processing (MPS) queue that is used to run the job.', example='****96e8864746a0b6f3****'),
  }(name='ScheduleConfig', description='The scheduling settings.'),
  templateConfig?: {
    overwriteParams?: {
      blackLevel?: int32(name='BlackLevel', description='The threshold that is used to filter out black frames for the first snapshot to be captured. This feature is available if you request the system to capture multiple snapshots.', example='30'),
      count?: long(name='Count', description='The number of snapshots.', example='5'),
      frameType?: string(name='FrameType', description='The type of the frame.', example='intra'),
      height?: int32(name='Height', description='The height of a captured snapshot.', example='480'),
      interval?: long(name='Interval', description='The interval at which snapshots are captured.', example='10'),
      isSptFrag?: boolean(name='IsSptFrag', description='The WebVTT snapshot configuration that specifies whether to merge the output snapshots.', example='true'),
      pixelBlackThreshold?: int32(name='PixelBlackThreshold', description='The color value threshold that determines whether a pixel is black.', example='70'),
      spriteSnapshotConfig?: {
        cellHeight?: int32(name='CellHeight', description='The height of a single snapshot before tiling. The default value is the height of the output snapshot.', example='480'),
        cellWidth?: int32(name='CellWidth', description='The width of a single snapshot before tiling. The default value is the width of the output snapshot.', example='720'),
        color?: string(name='Color', description='The background color.', example='#000000'),
        columns?: int32(name='Columns', description='The number of columns that the image sprite contains.', example='20'),
        lines?: int32(name='Lines', description='The number of rows that the image sprite contains.', example='20'),
        margin?: int32(name='Margin', description='The width of the frame. Default value: 0. Unit: pixels.', example='20'),
        padding?: int32(name='Padding', description='The spacing between two adjacent snapshots. Default value: 0. Unit: pixels.', example='20'),
      }(name='SpriteSnapshotConfig', description='The configuration of the sprite snapshot.'),
      time?: long(name='Time', description='The point in time at which the system starts to capture snapshots in the input video.', example='1000'),
      type?: string(name='Type', description='The snapshot type. Valid values:', example='Sprite'),
      width?: int32(name='Width', description='The width of a captured snapshot.', example='720'),
    }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters.'),
    templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
  }(name='TemplateConfig', description='The snapshot template configuration.

This parameter is required.'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"test parameter": "test value"}'),
}

model SubmitSnapshotJobShrinkRequest {
  inputShrink?: string(name='Input', description='The snapshot input.

This parameter is required.'),
  name?: string(name='Name', description='The name of the job.', example='SampleJob'),
  outputShrink?: string(name='Output', description='The snapshot output.

This parameter is required.'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling settings.'),
  templateConfigShrink?: string(name='TemplateConfig', description='The snapshot template configuration.

This parameter is required.'),
  userData?: string(name='UserData', description='The user-defined data.', example='{"test parameter": "test value"}'),
}

model SubmitSnapshotJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitSnapshotJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSnapshotJobResponseBody(name='body'),
}

/**
 * @summary Submits a snapshot job.
 *
 * @param tmpReq SubmitSnapshotJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitSnapshotJobResponse
 */
async function submitSnapshotJobWithOptions(tmpReq: SubmitSnapshotJobRequest, runtime: $RuntimeOptions): SubmitSnapshotJobResponse {
  tmpReq.validate();
  var request = new SubmitSnapshotJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!$isNull(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  if (!$isNull(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  if (!$isNull(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!$isNull(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!$isNull(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitSnapshotJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a snapshot job.
 *
 * @param request SubmitSnapshotJobRequest
 * @return SubmitSnapshotJobResponse
 */
async function submitSnapshotJob(request: SubmitSnapshotJobRequest): SubmitSnapshotJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitSnapshotJobWithOptions(request, runtime);
}

model SubmitSportsHighlightsJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****'),
  inputConfig?: string(name='InputConfig', description='The input configurations.'),
  outputConfig?: string(name='OutputConfig', description='The output configurations.', example='{
  "MediaURL": "http://xxx.oss-cn-shanghai.aliyuncs.com/xxx_{index}.mp4",
  "Count": 1,
  "Width": 1080,
  "Height": 1920
}'),
  userData?: string(name='UserData', description='The user-defined data.'),
}

model SubmitSportsHighlightsJobResponseBody = {
  jobId?: string(name='JobId', description='The ID of the sports highlights job.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID.', example='****36-3C1E-4417-BDB2-1E034F****'),
}

model SubmitSportsHighlightsJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSportsHighlightsJobResponseBody(name='body'),
}

/**
 * @summary Submits a sports highlights job to generate a highlights video of an event based on event materials that contain commentary.
 *
 * @param request SubmitSportsHighlightsJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitSportsHighlightsJobResponse
 */
async function submitSportsHighlightsJobWithOptions(request: SubmitSportsHighlightsJobRequest, runtime: $RuntimeOptions): SubmitSportsHighlightsJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!$isNull(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var body : map[string]any = {};
  if (!$isNull(request.inputConfig)) {
    body['InputConfig'] = request.inputConfig;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitSportsHighlightsJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a sports highlights job to generate a highlights video of an event based on event materials that contain commentary.
 *
 * @param request SubmitSportsHighlightsJobRequest
 * @return SubmitSportsHighlightsJobResponse
 */
async function submitSportsHighlightsJob(request: SubmitSportsHighlightsJobRequest): SubmitSportsHighlightsJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitSportsHighlightsJobWithOptions(request, runtime);
}

model SubmitStandardCustomizedVoiceJobRequest {
  audios?: string(name='Audios', description='*   The material assets IDs of the materials for training.
*   Separate multiple media IDs with commas (,).

> : The total duration of all materials must be within 15 to 30 minutes. The duration of each material must be greater than 1 minute.', example='****571c704445f9a0ee011406c2****,****571c704445f9a0ee011406c2****,****571c704445f9a0ee011406c2****'),
  authentication?: string(name='Authentication', description='*   The media asset ID of the authentication audio.

*   Upload an audio file for identity authentication. If the voiceprint extracted from the uploaded file differs from that of the training file, the job fails.

    **

    **Note**: Clearly read and record the following text: I confirm to customize human voice cloning and provide audio files that contain my voice for training. I promise that I am responsible for the customized content and that the content complies with laws and regulations.', example='****571c704445f9a0ee011406c2****'),
  demoAudioMediaURL?: string(name='DemoAudioMediaURL', description='The URL of the sample audio file.

*   If this parameter is specified, a sample audio file is generated at the specified Object Storage Service (OSS) URL after the training is complete.

*   If this parameter is not specified, no sample audio file is generated.

    **

    **Note**: The URL must be a valid public OSS URL within your Alibaba Cloud account.', example='https://your-bucket.oss-cn-shanghai.aliyuncs.com/demo.mp3'),
  gender?: string(name='Gender', description='The gender. Valid values:

*   female
*   male', example='female'),
  voiceName?: string(name='VoiceName', description='The voice name.

*   The name can be up to 32 characters in length.'),
}

model SubmitStandardCustomizedVoiceJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the human voice cloning job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model SubmitStandardCustomizedVoiceJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitStandardCustomizedVoiceJobResponseBody(name='body'),
}

/**
 * @summary Submits a standard human voice cloning job. After you call this operation, the JobId is returned. The training process is asynchronous. During training, you can call the GetCustomizedVoiceJob operation to query information such as the job state.
 *
 * @param request SubmitStandardCustomizedVoiceJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitStandardCustomizedVoiceJobResponse
 */
async function submitStandardCustomizedVoiceJobWithOptions(request: SubmitStandardCustomizedVoiceJobRequest, runtime: $RuntimeOptions): SubmitStandardCustomizedVoiceJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.audios)) {
    query['Audios'] = request.audios;
  }
  if (!$isNull(request.authentication)) {
    query['Authentication'] = request.authentication;
  }
  if (!$isNull(request.demoAudioMediaURL)) {
    query['DemoAudioMediaURL'] = request.demoAudioMediaURL;
  }
  if (!$isNull(request.gender)) {
    query['Gender'] = request.gender;
  }
  if (!$isNull(request.voiceName)) {
    query['VoiceName'] = request.voiceName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitStandardCustomizedVoiceJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a standard human voice cloning job. After you call this operation, the JobId is returned. The training process is asynchronous. During training, you can call the GetCustomizedVoiceJob operation to query information such as the job state.
 *
 * @param request SubmitStandardCustomizedVoiceJobRequest
 * @return SubmitStandardCustomizedVoiceJobResponse
 */
async function submitStandardCustomizedVoiceJob(request: SubmitStandardCustomizedVoiceJobRequest): SubmitStandardCustomizedVoiceJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitStandardCustomizedVoiceJobWithOptions(request, runtime);
}

model SubmitSyncMediaInfoJobRequest {
  input?: {
    media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
    type?: string(name='Type', description='The type of the media object.

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
  }(name='Input', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The job name.', example='job-name'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling parameters. This parameter is optional.'),
  userData?: string(name='UserData', description='The user data.', example='user-data'),
}

model SubmitSyncMediaInfoJobShrinkRequest {
  inputShrink?: string(name='Input', description='The input of the job.

This parameter is required.'),
  name?: string(name='Name', description='The job name.', example='job-name'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling parameters. This parameter is optional.'),
  userData?: string(name='UserData', description='The user data.', example='user-data'),
}

model SubmitSyncMediaInfoJobResponseBody = {
  mediaInfoJob?: {
    async?: boolean(name='Async', description='Indicates whether asynchronous processing was performed.', example='true'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    input?: {
      media?: string(name='Media', description='The media object. If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
    }(name='Input', description='The input of the job.'),
    jobId?: string(name='JobId', description='The job ID.', example='ab4802364a2e49208c99efab82dfa8e8'),
    mediaInfoProperty?: {
      audioStreamInfoList?: [ 
        {
          bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
          channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
          channels?: string(name='Channels', description='The number of sound channels.', example='2'),
          codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
          codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
          codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
          codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
          codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          index?: string(name='Index', description='The sequence number of the stream.', example='1'),
          lang?: string(name='Lang', description='The language of the stream.', example='us'),
          sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
          sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
          startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
          timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
        }
      ](name='AudioStreamInfoList', description='The information about the audio stream.'),
      fileBasicInfo?: {
        bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
        duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
        fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
        fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
        fileStatus?: string(name='FileStatus', description='The state of the file. Valid values:

*   Normal', example='Normal'),
        fileType?: string(name='FileType', description='The file type.', example='source_file'),
        fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
        formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
        height?: string(name='Height', description='The height of the output video.', example='478'),
        mediaId?: string(name='MediaId', description='The ID of the media asset.', example='999e68259c924f52a6be603cbb3f91cc'),
        region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
        width?: string(name='Width', description='The width of the output video.', example='848'),
      }(name='FileBasicInfo', description='The basic file information.'),
      videoStreamInfoList?: [ 
        {
          avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
          bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
          codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
          codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
          codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
          codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
          codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
          dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
          duration?: string(name='Duration', description='The duration of the file.', example='403.039989'),
          fps?: string(name='Fps', description='The frame rate.', example='25.0'),
          hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
          height?: string(name='Height', description='The height of the output video.', example='478'),
          index?: string(name='Index', description='The sequence number of the stream.', example='0'),
          lang?: string(name='Lang', description='The language of the stream.', example='zh'),
          level?: string(name='Level', description='The codec level.', example='31'),
          numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
          pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
          profile?: string(name='Profile', description='The encoder profile.', example='High'),
          rotate?: string(name='Rotate', description='The rotation angle of the video image.', example='0'),
          sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
          startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
          timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
          width?: string(name='Width', description='The width of the output video.', example='848'),
        }
      ](name='VideoStreamInfoList', description='The information about the video stream.'),
    }(name='MediaInfoProperty', description='The details of the media information.'),
    name?: string(name='Name', description='The job name.', example='job-name'),
    requestId?: string(name='RequestId', description='The request ID.', example='4879B9DE-E4B6-19DC-91F5-9D5F4DCE4168'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling information.'),
    status?: string(name='Status', description='The state of the job. Valid values: Init (the job is submitted), Success (the job is successful), and Fail (the job failed).', example='Init'),
    submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission information.', example='{}'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='MediaInfoJob', description='MediaInfoJobDTO'),
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
}

model SubmitSyncMediaInfoJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSyncMediaInfoJobResponseBody(name='body'),
}

/**
 * @summary Submits a media file in synchronous mode for media information analysis.
 *
 * @description You can call this operation to analyze an input media file in synchronous mode. This operation is suitable for scenarios that require high real-time performance and low concurrency. If it takes an extended period of time to obtain the media information about the input media file, the request may time out or the obtained information may be inaccurate. We recommend that you call the [SubmitMediaInfoJob](https://help.aliyun.com/document_detail/441222.html) operation to obtain media information.
 *
 * @param tmpReq SubmitSyncMediaInfoJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitSyncMediaInfoJobResponse
 */
async function submitSyncMediaInfoJobWithOptions(tmpReq: SubmitSyncMediaInfoJobRequest, runtime: $RuntimeOptions): SubmitSyncMediaInfoJobResponse {
  tmpReq.validate();
  var request = new SubmitSyncMediaInfoJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!$isNull(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitSyncMediaInfoJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a media file in synchronous mode for media information analysis.
 *
 * @description You can call this operation to analyze an input media file in synchronous mode. This operation is suitable for scenarios that require high real-time performance and low concurrency. If it takes an extended period of time to obtain the media information about the input media file, the request may time out or the obtained information may be inaccurate. We recommend that you call the [SubmitMediaInfoJob](https://help.aliyun.com/document_detail/441222.html) operation to obtain media information.
 *
 * @param request SubmitSyncMediaInfoJobRequest
 * @return SubmitSyncMediaInfoJobResponse
 */
async function submitSyncMediaInfoJob(request: SubmitSyncMediaInfoJobRequest): SubmitSyncMediaInfoJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitSyncMediaInfoJobWithOptions(request, runtime);
}

model SubmitTextGenerateJobRequest {
  description?: string(name='Description', description='The job description, which can be up to 1,024 bytes in length and must be encoded in UTF-8.'),
  generateConfig?: string(name='GenerateConfig', description='The text generation configurations, including keywords and the requirements for the word count and number of output copies.'),
  title?: string(name='Title', description='The job title.

The job title can be up to 128 bytes in length.

The value must be encoded in UTF-8.'),
  type?: string(name='Type', description='The job type.

Valid values:

*   MarketingCopy: the marketing copy.
*   Title: the short video title.', example='MarketingCopy'),
  userData?: string(name='UserData', description='The user-defined data in the JSON format, which can be up to 512 bytes in length. You can specify a custom callback URL. For more information, see [Configure a callback upon editing completion](https://help.aliyun.com/document_detail/451631.html).'),
}

model SubmitTextGenerateJobResponseBody = {
  jobId?: string(name='JobId', description='The job ID.', example='****d80e4e4044975745c14b****'),
  requestId?: string(name='RequestId', description='The request ID', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitTextGenerateJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTextGenerateJobResponseBody(name='body'),
}

/**
 * @summary Submits a text generation job to generate marketing copies based on keywords and the requirements for the word count and number of output copies. The word count of the output copies may differ from the specified word count. After the job is submitted, you can call the GetSmartHandleJob operation to obtain the job state and result based on the job ID.
 *
 * @param request SubmitTextGenerateJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitTextGenerateJobResponse
 */
async function submitTextGenerateJobWithOptions(request: SubmitTextGenerateJobRequest, runtime: $RuntimeOptions): SubmitTextGenerateJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.generateConfig)) {
    query['GenerateConfig'] = request.generateConfig;
  }
  if (!$isNull(request.title)) {
    query['Title'] = request.title;
  }
  if (!$isNull(request.type)) {
    query['Type'] = request.type;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitTextGenerateJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a text generation job to generate marketing copies based on keywords and the requirements for the word count and number of output copies. The word count of the output copies may differ from the specified word count. After the job is submitted, you can call the GetSmartHandleJob operation to obtain the job state and result based on the job ID.
 *
 * @param request SubmitTextGenerateJobRequest
 * @return SubmitTextGenerateJobResponse
 */
async function submitTextGenerateJob(request: SubmitTextGenerateJobRequest): SubmitTextGenerateJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitTextGenerateJobWithOptions(request, runtime);
}

model SubmitTraceAbJobRequest {
  cipherBase64ed?: string(name='CipherBase64ed', example='Qh6OdgIMcliQSI1fReOw****'),
  input?: {
    media?: string(name='Media', description='This parameter is required.', example='oss://bucket/object'),
    type?: string(name='Type', description='This parameter is required.', example='OSS'),
  }(name='Input', description='This parameter is required.'),
  level?: long(name='Level', example='0'),
  output?: {
    media?: string(name='Media', description='This parameter is required.', example='oss://bucket/dir/'),
    type?: string(name='Type', description='This parameter is required.', example='OSS'),
  }(name='Output', description='This parameter is required.'),
  startTime?: string(name='StartTime', example='0'),
  totalTime?: string(name='TotalTime', example='360'),
  userData?: string(name='UserData', example='123'),
}

model SubmitTraceAbJobShrinkRequest {
  cipherBase64ed?: string(name='CipherBase64ed', example='Qh6OdgIMcliQSI1fReOw****'),
  inputShrink?: string(name='Input', description='This parameter is required.'),
  level?: long(name='Level', example='0'),
  outputShrink?: string(name='Output', description='This parameter is required.'),
  startTime?: string(name='StartTime', example='0'),
  totalTime?: string(name='TotalTime', example='360'),
  userData?: string(name='UserData', example='123'),
}

model SubmitTraceAbJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', example='bfb786c639894f4d80648792021e****'),
    traceMediaId?: string(name='TraceMediaId', example='bf53333264f4d80648792021e****'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='******36-3C1E-4417-BDB2-1E034F******'),
  statusCode?: long(name='StatusCode', example='200'),
}

model SubmitTraceAbJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTraceAbJobResponseBody(name='body'),
}

/**
 * @summary 提交视频溯源水印ab流任务
 *
 * @param tmpReq SubmitTraceAbJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitTraceAbJobResponse
 */
async function submitTraceAbJobWithOptions(tmpReq: SubmitTraceAbJobRequest, runtime: $RuntimeOptions): SubmitTraceAbJobResponse {
  tmpReq.validate();
  var request = new SubmitTraceAbJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  if (!$isNull(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  var query = {};
  if (!$isNull(request.cipherBase64ed)) {
    query['CipherBase64ed'] = request.cipherBase64ed;
  }
  if (!$isNull(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!$isNull(request.level)) {
    query['Level'] = request.level;
  }
  if (!$isNull(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!$isNull(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!$isNull(request.totalTime)) {
    query['TotalTime'] = request.totalTime;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitTraceAbJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 提交视频溯源水印ab流任务
 *
 * @param request SubmitTraceAbJobRequest
 * @return SubmitTraceAbJobResponse
 */
async function submitTraceAbJob(request: SubmitTraceAbJobRequest): SubmitTraceAbJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitTraceAbJobWithOptions(request, runtime);
}

model SubmitTraceExtractJobRequest {
  input?: {
    media?: string(name='Media', description='This parameter is required.', example='oss://bucket/object'),
    type?: string(name='Type', description='This parameter is required.', example='OSS'),
  }(name='Input', description='This parameter is required.'),
  params?: string(name='Params', example='{"m3u8Type":"v1"}'),
  userData?: string(name='UserData', example='123'),
}

model SubmitTraceExtractJobShrinkRequest {
  inputShrink?: string(name='Input', description='This parameter is required.'),
  params?: string(name='Params', example='{"m3u8Type":"v1"}'),
  userData?: string(name='UserData', example='123'),
}

model SubmitTraceExtractJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', example='bfb786c639894f4d80648792021e****'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
  statusCode?: long(name='StatusCode', example='200'),
}

model SubmitTraceExtractJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTraceExtractJobResponseBody(name='body'),
}

/**
 * @summary 提交溯源水印提取任务
 *
 * @param tmpReq SubmitTraceExtractJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitTraceExtractJobResponse
 */
async function submitTraceExtractJobWithOptions(tmpReq: SubmitTraceExtractJobRequest, runtime: $RuntimeOptions): SubmitTraceExtractJobResponse {
  tmpReq.validate();
  var request = new SubmitTraceExtractJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.input)) {
    request.inputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.input, 'Input', 'json');
  }
  var query = {};
  if (!$isNull(request.inputShrink)) {
    query['Input'] = request.inputShrink;
  }
  if (!$isNull(request.params)) {
    query['Params'] = request.params;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitTraceExtractJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 提交溯源水印提取任务
 *
 * @param request SubmitTraceExtractJobRequest
 * @return SubmitTraceExtractJobResponse
 */
async function submitTraceExtractJob(request: SubmitTraceExtractJobRequest): SubmitTraceExtractJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitTraceExtractJobWithOptions(request, runtime);
}

model SubmitTraceM3u8JobRequest {
  keyUri?: string(name='KeyUri', example='https://cipher.abc.com'),
  output?: {
    media?: string(name='Media', description='This parameter is required.', example='oss://bucket/object'),
    type?: string(name='Type', description='This parameter is required.', example='OSS'),
  }(name='Output', description='This parameter is required.'),
  params?: string(name='Params', example='{"m3u8Type":"v1"}'),
  trace?: string(name='Trace'),
  traceMediaId?: string(name='TraceMediaId', example='437bd2b516ffda105d07b12a9a82****'),
}

model SubmitTraceM3u8JobShrinkRequest {
  keyUri?: string(name='KeyUri', example='https://cipher.abc.com'),
  outputShrink?: string(name='Output', description='This parameter is required.'),
  params?: string(name='Params', example='{"m3u8Type":"v1"}'),
  trace?: string(name='Trace'),
  traceMediaId?: string(name='TraceMediaId', example='437bd2b516ffda105d07b12a9a82****'),
}

model SubmitTraceM3u8JobResponseBody = {
  data?: {
    jobId?: string(name='JobId', example='bfb786c639894f4d8064879202****'),
  }(name='Data'),
  message?: string(name='Message', example='ok'),
  requestId?: string(name='RequestId', description='Id of the request', example='******11-DB8D-4A9A-875B-275798******'),
}

model SubmitTraceM3u8JobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTraceM3u8JobResponseBody(name='body'),
}

/**
 * @summary 提交视频溯源水印m3u8文件任务
 *
 * @param tmpReq SubmitTraceM3u8JobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitTraceM3u8JobResponse
 */
async function submitTraceM3u8JobWithOptions(tmpReq: SubmitTraceM3u8JobRequest, runtime: $RuntimeOptions): SubmitTraceM3u8JobResponse {
  tmpReq.validate();
  var request = new SubmitTraceM3u8JobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.output)) {
    request.outputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.output, 'Output', 'json');
  }
  var query = {};
  if (!$isNull(request.keyUri)) {
    query['KeyUri'] = request.keyUri;
  }
  if (!$isNull(request.outputShrink)) {
    query['Output'] = request.outputShrink;
  }
  if (!$isNull(request.params)) {
    query['Params'] = request.params;
  }
  if (!$isNull(request.trace)) {
    query['Trace'] = request.trace;
  }
  if (!$isNull(request.traceMediaId)) {
    query['TraceMediaId'] = request.traceMediaId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitTraceM3u8Job',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 提交视频溯源水印m3u8文件任务
 *
 * @param request SubmitTraceM3u8JobRequest
 * @return SubmitTraceM3u8JobResponse
 */
async function submitTraceM3u8Job(request: SubmitTraceM3u8JobRequest): SubmitTraceM3u8JobResponse {
  var runtime = new $RuntimeOptions{};
  return submitTraceM3u8JobWithOptions(request, runtime);
}

model SubmitTranscodeJobRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****'),
  inputGroup?: [ 
    {
      inputUrl?: string(name='InputUrl', description='The URL of the input stream.

*   This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an input.
*   The system checks whether the input URL exists within the media asset.', example='oss://bucket/path/to/video.mp4'),
      media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the Intelligent Media Services (IMS) console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
      type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an Object Storage Service (OSS) object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
    }
  ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.

This parameter is required.', example='job-name'),
  name?: string(name='Name', description='The job name.', example='job-name'),
  outputGroup?: [ 
    {
      output?: {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.

>  Before you use the OSS bucket in the URL, you must add the bucket on the [Storage Management](https://help.aliyun.com/document_detail/609918.html) page of the IMS console.

*   If Type is set to Media, set this parameter to the ID of a media asset.

This parameter is required.', example='oss://bucket/path/to/video.mp4'),
        outputUrl?: string(name='OutputUrl', description='The URL of the output stream.\\\\
This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an output.\\\\
Supported placeholders:

*   {MediaId}: the ID of the media asset.
*   {JobId}: the ID of the transcoding subjob.
*   {MediaBucket}: the bucket to which the media asset belongs.
*   {ExtName}: the file suffix, which uses the output format of the transcoding template.
*   {DestMd5}: the MD5 value of the transcoded output file.\\\\
    Notes:

1.  This parameter must contain the {MediaId} and {JobId} placeholders.
2.  The output bucket is the same as the bucket to which the media asset belongs.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.

This parameter is required.', example='OSS'),
      }(name='Output', description='The output file configuration.

This parameter is required.'),
      processConfig?: {
        combineConfigs?: [ 
          {
            audioIndex?: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
            duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
            start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
            videoIndex?: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
          }
        ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
        encryption?: {
          cipherText?: string(name='CipherText', description='The ciphertext of HTTP Live Streaming (HLS) encryption.', example='MTYi00NDU0LTg5O****'),
          decryptKeyUri?: string(name='DecryptKeyUri', description='The address of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
          encryptType?: string(name='EncryptType', description='Specifies the encryption type. Valid values:

*   PrivateEncryption: Alibaba Cloud proprietary cryptography
*   HLSEncryption: HTTP Live Streaming (HLS) encryption', example='PrivateEncryption'),
          keyServiceType?: string(name='KeyServiceType', description='The key service type for HLS encryption. Valid values:

*   KMS
*   Base64', example='KMS'),
        }(name='Encryption', description='The encryption settings.'),
        imageWatermarks?: [ 
          {
            overwriteParams?: {
              dx?: string(name='Dx', description='The horizontal offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the horizontal offset to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
              dy?: string(name='Dy', description='The vertical offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the vertical offset to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
              file?: {
                media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
              }(name='File', description='The watermark image file.'),
              height?: string(name='Height', description='The height of the watermark image in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark height.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark height to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
              referPos?: string(name='ReferPos', description='The position of the watermark.

*   Valid values: TopRight, TopLeft, BottomRight, and BottomLeft.
*   Default value: TopRight.', example='TopLeft'),
              timeline?: {
                duration?: string(name='Duration', description='The time range in which the watermark is displayed.

*   Valid values: integers and ToEND.
*   Default value: ToEND.', example='ToEND'),
                start?: string(name='Start', description='The beginning of the time range in which the watermark is displayed.

*   Unit: seconds.
*   Value values: integers.
*   Default value: 0.', example='00:00:05'),
              }(name='Timeline', description='The time settings of the dynamic watermark.'),
              width?: string(name='Width', description='The width of the watermark in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark width.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark width to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }
        ](name='ImageWatermarks', description='The watermark configuration of an image.'),
        subtitles?: [ 
          {
            overwriteParams?: {
              charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
              file?: {
                media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
              }(name='File', description='The subtitle file.'),
              format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }
        ](name='Subtitles', description='The subtitle configuration.'),
        textWatermarks?: [ 
          {
            overwriteParams?: {
              adaptive?: string(name='Adaptive', description='Specifies whether to the font size based on the output video dimensions. true / false, default: false', example='false'),
              borderColor?: string(name='BorderColor', description='The outline color of the text watermark. Default value: black. For more information, see BorderColor.', example='#006400'),
              borderWidth?: int32(name='BorderWidth', description='The outline width of the text watermark.

*   Default value: 0.
*   Valid values: (0,4096].', example='0'),
              content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
              fontAlpha?: string(name='FontAlpha', description='The transparency of the text.

*   Valid values: (0,1].
*   Default value: 1.', example='1.0'),
              fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
              fontName?: string(name='FontName', description='The font of the text. Default value: SimSun.', example='SimSun'),
              fontSize?: int32(name='FontSize', description='The size of the text.

*   Default value: 16.
*   Valid values: (4,120).', example='16'),
              left?: string(name='Left', description='The left margin of the text watermark.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
              top?: string(name='Top', description='The top margin of the text.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }
        ](name='TextWatermarks', description='The configurations of the text watermark.'),
        transcode?: {
          overwriteParams?: {
            audio?: {
              bitrate?: string(name='Bitrate', description='The audio bitrate of the output file. Valid values: [8,1000]. Unit: Kbit/s. Default value: 128.', example='128'),
              channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
              codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
              profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
              remove?: string(name='Remove', description='Specifies whether to delete the audio stream.', example='false'),
              samplerate?: string(name='Samplerate', description='The sampling rate. Valid values: 22050, 32000, 44100, 48000, and 96000. Default value: 44100. Unit: Hz.', example='44100'),
              volume?: {
                integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
              }(name='Volume', description='The volume configurations.'),
            }(name='Audio', description='The audio settings.'),
            container?: {
              format?: string(name='Format', description='The container format.', example='mp4'),
            }(name='Container', description='The encapsulation format settings.'),
            muxConfig?: {
              segment?: {
                duration?: string(name='Duration', description='The segment length.', example='10'),
                forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
              }(name='Segment', description='The segment settings.'),
            }(name='MuxConfig', description='The encapsulation settings.'),
            transConfig?: {
              adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
              isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false: does not check the video resolution.

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
              isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckReso?: string(name='IsCheckReso', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckResoFail?: string(name='IsCheckResoFail', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
              transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
            }(name='TransConfig', description='The conditional transcoding configurations.'),
            video?: {
              abrMax?: string(name='AbrMax', description='The maximum adaptive bitrate (ABR). This parameter takes effect only for Narrowband HD 1.0. Valid values: [10,50000]. Unit: Kbit/s.', example='6000'),
              bitrate?: string(name='Bitrate', description='The average video bitrate. Valid values: [10,50000]. Unit: Kbit/s.', example='3000'),
              bufsize?: string(name='Bufsize', description='The buffer size. Valid values: [1000,128000]. Default value: 6000. Unit: KB.', example='6000'),
              codec?: string(name='Codec', description='The encoding format.', example='H.264'),
              crf?: string(name='Crf', description='The constant rate factor (CRF). Valid values: [0,51]. Default value: 23 if the encoding format is H.264, or 26 if the encoding format is H.265.

>  If this parameter is specified, the setting of the bitrate becomes invalid.', example='23'),
              crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
              fps?: string(name='Fps', description='The frame rate. Valid values:(0,60]. Default value: the frame rate of the input file.

>  The value is 60 if the frame rate of the input file exceeds 60.', example='25'),
              gop?: string(name='Gop', description='The maximum number of frames between keyframes. Valid values: [1,1080000]. Default value: 250.', example='250'),
              height?: string(name='Height', description='The height of the video. Valid values: [128,4096]. Unit: pixels. Default value: the original height of the video.', example='1080'),
              longShortMode?: string(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature.', example='false'),
              maxrate?: string(name='Maxrate', description='The maximum bitrate of the video. Valid values: [10,50000]. Unit: Kbit/s.', example='9000'),
              pad?: string(name='Pad', description='The black bars added to the video. Format: width:height:left:top. Example: 1280:800:0:140.', example='1280:800:0:140'),
              pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
              preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
              profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
              remove?: string(name='Remove', description='Specifies whether to remove the video.', example='false'),
              scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
              width?: string(name='Width', description='The width of the video. Valid values: [128,4096]. Unit: pixels. Default value: the original width of the video.', example='1920'),
            }(name='Video', description='The video settings.'),
          }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
          templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
        }(name='Transcode', description='The transcoding configuration.

This parameter is required.'),
      }(name='ProcessConfig', description='The job processing configuration.

This parameter is required.'),
    }
  ](name='OutputGroup', description='The output group of the job.

This parameter is required.', example='user-data'),
  scheduleConfig?: {
    pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
    priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
  }(name='ScheduleConfig', description='The scheduling information about the job.', example='job-name'),
  userData?: string(name='UserData', description='The custom settings. The value must be in the JSON format and can be up to 512 bytes in length. You can specify a [custom callback URL](https://help.aliyun.com/document_detail/451631.html).', example='user-data'),
}

model SubmitTranscodeJobShrinkRequest {
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='****12e8864746a0a398****'),
  inputGroupShrink?: string(name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.

This parameter is required.', example='job-name'),
  name?: string(name='Name', description='The job name.', example='job-name'),
  outputGroupShrink?: string(name='OutputGroup', description='The output group of the job.

This parameter is required.', example='user-data'),
  scheduleConfigShrink?: string(name='ScheduleConfig', description='The scheduling information about the job.', example='job-name'),
  userData?: string(name='UserData', description='The custom settings. The value must be in the JSON format and can be up to 512 bytes in length. You can specify a [custom callback URL](https://help.aliyun.com/document_detail/451631.html).', example='user-data'),
}

model SubmitTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
  transcodeParentJob?: {
    createTime?: string(name='CreateTime', description='The time when the job was created. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    finishTime?: string(name='FinishTime', description='The time when the job was complete. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    inputGroup?: [ 
      {
        media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
        type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
      }
    ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
    jobCount?: int32(name='JobCount', description='The number of subjobs.', example='1'),
    name?: string(name='Name', description='The job name.', example='transcode-job'),
    outputGroup?: [ 
      {
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex?: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex?: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HLS encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The address of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='Specifies the encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The horizontal offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the horizontal offset to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                dy?: string(name='Dy', description='The vertical offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the vertical offset to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the watermark image in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark height.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark height to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
                referPos?: string(name='ReferPos', description='The position of the watermark.

*   Valid values: TopRight, TopLeft, BottomRight, and BottomLeft.
*   Default value: TopRight.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The time range in which the watermark is displayed.

*   Valid values: integers and ToEND.
*   Default value: ToEND.', example='ToEND'),
                  start?: string(name='Start', description='The beginning of the time range in which the watermark is displayed.

*   Unit: seconds.
*   Value values: integers.
*   Default value: 0.', example='00:00:05'),
                }(name='Timeline', description='The time settings of the dynamic watermark.'),
                width?: string(name='Width', description='The width of the watermark in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark width.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark width to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object. If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported. If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Specifies whether to the font size based on the output video dimensions.

*   true: false
*   default: false', example='false'),
                borderColor?: string(name='BorderColor', description='The outline color of the text watermark. Default value: black. For more information, see BorderColor.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The outline width of the text watermark.

*   Default value: 0.
*   Valid values: (0,4096].', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the text.

*   Valid values: (0,1].
*   Default value: 1.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text. Default value: SimSun.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.

*   Default value: 16.
*   Valid values: (4,120).', example='16'),
                left?: string(name='Left', description='The left margin of the text watermark.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
                top?: string(name='Top', description='The top margin of the text.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Specifies whether to delete the audio stream.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Valid values: 22050, 32000, 44100, 48000, and 96000. Default value: 44100.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false: does not check the video resolution.

Default value:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution.

Default value: false.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.

Default value: onepass.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum ABR. This parameter takes effect only for Narrowband HD 1.0.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or Default value when the Codec parameter is set to H.265: 26.

If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Specifies whether to remove the video.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The job processing configuration.'),
      }
    ](name='OutputGroup', description='The output group of the job.'),
    parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
    percent?: int32(name='Percent', description='The completion percentage of the job.', example='0'),
    requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
    scheduleConfig?: {
      pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
      priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
    }(name='ScheduleConfig', description='The scheduling configuration of the job.'),
    status?: string(name='Status', description='The state of the job. Success: At least one of the subjobs is successful. Fail: All subjobs failed.', example='Success'),
    submitTime?: string(name='SubmitTime', description='The time when the job was submitted. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-01-12T08:49:41Z'),
    transcodeJobList?: [ 
      {
        createTime?: string(name='CreateTime', description='The time when the job was created.', example='2022-01-12T08:49:41Z'),
        finishTime?: string(name='FinishTime', description='The time when the job was complete.', example='2022-01-12T08:49:41Z'),
        inputGroup?: [ 
          {
            inputUrl?: string(name='InputUrl', description='The URL of the input stream:

*   This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an input.
*   The system checks whether the input URL exists within the media asset.', example='oss://bucket/path/to/video.mp4'),
            media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
            type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
          }
        ](name='InputGroup', description='The input group of the job. An input of a single file indicates a transcoding job. An input of multiple files indicates an audio and video stream merge job.'),
        jobId?: string(name='JobId', description='The subjob ID.', example='7d6a7e0d4db2457a8d45ff5d43e1bf0a'),
        jobIndex?: int32(name='JobIndex', description='The index number of the subjob in the entire job.', example='0'),
        name?: string(name='Name', description='The job name.', example='transcode-job'),
        outFileMeta?: {
          audioStreamInfoList?: [ 
            {
              bitrate?: string(name='Bitrate', description='The bitrate.', example='0.f'),
              channelLayout?: string(name='ChannelLayout', description='The sound channel layout.', example='stereo'),
              channels?: string(name='Channels', description='The number of sound channels.', example='2'),
              codecLongName?: string(name='CodecLongName', description='The name of the encoding format.', example='AAC (Advanced Audio Coding)'),
              codecName?: string(name='CodecName', description='The encoding format.', example='aac'),
              codecTag?: string(name='CodecTag', description='The encoder tag.', example='0x000f'),
              codecTagString?: string(name='CodecTagString', description='The name of the encoder tag.', example='[15][0][0][0]'),
              codecTimeBase?: string(name='CodecTimeBase', description='The time base of the encoder.', example='1/44100'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              index?: string(name='Index', description='The sequence number of the stream.', example='1'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              sampleFmt?: string(name='SampleFmt', description='The sample format.', example='fltp'),
              sampleRate?: string(name='SampleRate', description='The sampling rate. Unit: Hz.', example='44100'),
              startTime?: string(name='StartTime', description='The start time of the stream.', example='1.473556'),
              timebase?: string(name='Timebase', description='The time base.', example='1/90000'),
            }
          ](name='AudioStreamInfoList', description='The information about the audio stream.'),
          fileBasicInfo?: {
            bitrate?: string(name='Bitrate', description='The video bitrate.', example='888.563'),
            duration?: string(name='Duration', description='The duration of the video. Unit: seconds.', example='403.039999'),
            fileName?: string(name='FileName', description='The file name.', example='file.m3u8'),
            fileSize?: string(name='FileSize', description='The file size. Unit: bytes.', example='31737'),
            fileStatus?: string(name='FileStatus', description='The state of the file.', example='Normal'),
            fileType?: string(name='FileType', description='The file type. Valid values: source_file and transcode_file.', example='source_file'),
            fileUrl?: string(name='FileUrl', description='The URL of the file.', example='http://bucket.oss-cn-shanghai.aliyuncs.com/path/to/file.m3u8'),
            formatName?: string(name='FormatName', description='The name of the video format.', example='hls,applehttp'),
            height?: string(name='Height', description='The height of the output video.', example='478'),
            mediaId?: string(name='MediaId', description='The ID of the media asset.', example='73e07de0f77171eca3fc7035d0b26402'),
            region?: string(name='Region', description='The region in which the file resides.', example='cn-shanghai'),
            width?: string(name='Width', description='The width of the output video.', example='848'),
          }(name='FileBasicInfo', description='The basic file information.'),
          videoStreamInfoList?: [ 
            {
              avgFps?: string(name='Avg_fps', description='The average frame rate.', example='25.0'),
              bitRate?: string(name='Bit_rate', description='The bitrate.', example='888.563'),
              codecLongName?: string(name='Codec_long_name', description='The name of the encoding format.', example='H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10'),
              codecName?: string(name='Codec_name', description='The encoding format.', example='h264'),
              codecTag?: string(name='Codec_tag', description='The tag of the encoding format.', example='0x001b'),
              codecTagString?: string(name='Codec_tag_string', description='The tag string of the encoding format.', example='[27][0][0][0]'),
              codecTimeBase?: string(name='Codec_time_base', description='The time base of the encoder.', example='1/50'),
              dar?: string(name='Dar', description='The display aspect ratio.', example='16:9'),
              duration?: string(name='Duration', description='The duration of the stream. Unit: seconds.', example='403.039989'),
              fps?: string(name='Fps', description='The frame rate.', example='25.0'),
              hasBFrames?: string(name='Has_b_frames', description='Indicates whether the video stream contains bidirectional frames (B-frames). Valid values:

*   0: The stream contains no B-frames.
*   1: The stream contains one B-frame.
*   2: The stream contains multiple consecutive B-frames.', example='2'),
              height?: string(name='Height', description='The height of the output video.', example='478'),
              index?: string(name='Index', description='The sequence number of the stream.', example='0'),
              lang?: string(name='Lang', description='The language of the stream.', example='cn'),
              level?: string(name='Level', description='The codec level.', example='31'),
              numFrames?: string(name='NumFrames', description='The total number of frames.', example='10040'),
              pixFmt?: string(name='PixFmt', description='The pixel format.', example='yuv420p'),
              profile?: string(name='Profile', description='The encoder profile.', example='High'),
              rotate?: string(name='Rotate', description='The rotation angle of the video image. Valid values: 0, 90, 180, and 270. Default value: 0.', example='0'),
              sar?: string(name='Sar', description='The aspect ratio of the area from which the sampling points are collected.', example='478:477'),
              startTime?: string(name='Start_time', description='The start time of the stream.', example='1.473556'),
              timeBase?: string(name='Time_base', description='The time base.', example='1/90000'),
              width?: string(name='Width', description='The width of the output video.', example='848'),
            }
          ](name='VideoStreamInfoList', description='The information about the video stream.'),
        }(name='OutFileMeta', description='The media information about the video generated by the job.'),
        output?: {
          media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
          outputUrl?: string(name='OutputUrl', description='The URL of the output stream.\\\\
This parameter takes effect only when Type is set to Media. You can select a specific file within the media asset as an output.\\\\
Supported placeholders:

*   {MediaId}: the ID of the media asset.
*   {JobId}: the ID of the transcoding subjob.
*   {MediaBucket}: the bucket to which the media asset belongs.
*   {ExtName}: the file suffix, which uses the output format of the transcoding template.
*   {DestMd5}: the MD5 value of the transcoded output file.\\\\
    Notes:

1.  This parameter must contain the {MediaId} and {JobId} placeholders.
2.  The output bucket is the same as the bucket to which the media asset belongs.', example='oss://bucket/path/to/{MediaId}/{JobId}.mp4'),
          type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
        }(name='Output', description='The output file configuration.'),
        parentJobId?: string(name='ParentJobId', description='The main job ID.', example='8b2198504dd340b7b3c9842a74fc9baa'),
        processConfig?: {
          combineConfigs?: [ 
            {
              audioIndex?: string(name='AudioIndex', description='The audio stream index.

This parameter is required.', example='0 或 exclude'),
              duration?: double(name='Duration', description='The duration of the input stream. The default value is the duration of the video.', example='20.0'),
              start?: double(name='Start', description='The start time of the input stream. Default value: 0.', example='0.0'),
              videoIndex?: string(name='VideoIndex', description='The video stream index.

This parameter is required.', example='0 或 exclude'),
            }
          ](name='CombineConfigs', description='The multi-input stream merge configuration.'),
          encryption?: {
            cipherText?: string(name='CipherText', description='The ciphertext of HLS encryption.', example='MTYi00NDU0LTg5O****'),
            decryptKeyUri?: string(name='DecryptKeyUri', description='The address of the decryption service for HLS encryption.', example='https://sample.com/path?CipherText=MTYi00NDU0LTg5O****'),
            encryptType?: string(name='EncryptType', description='Specifies the encryption type.', example='PrivateEncryption'),
            keyServiceType?: string(name='KeyServiceType', description='The type of the key service. Valid values: KMS and Base64.', example='KMS'),
          }(name='Encryption', description='The encryption settings.'),
          imageWatermarks?: [ 
            {
              overwriteParams?: {
                dx?: string(name='Dx', description='The horizontal offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the horizontal offset to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                dy?: string(name='Dy', description='The vertical offset of the watermark relative to the output video. Default value: 0.

The following value types are supported:

*   Integer: the pixel value of the horizontal offset.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the vertical offset to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='10'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The watermark image file.'),
                height?: string(name='Height', description='The height of the watermark image in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark height.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark height to the height of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
                referPos?: string(name='ReferPos', description='The position of the watermark.

*   Valid values: TopRight, TopLeft, BottomRight, and BottomLeft.
*   Default value: TopRight.', example='TopLeft'),
                timeline?: {
                  duration?: string(name='Duration', description='The time range in which the watermark is displayed.

*   Valid values: integers and ToEND.
*   Default value: ToEND.', example='ToEND'),
                  start?: string(name='Start', description='The beginning of the time range in which the watermark is displayed.

*   Unit: seconds.
*   Value values: integers.
*   Default value: 0.', example='00:00:05'),
                }(name='Timeline', description='The time settings of the dynamic watermark.'),
                width?: string(name='Width', description='The width of the watermark in the output video. The following value types are supported:

*   Integer: the pixel value of the watermark width.

    *   Valid values: [8,4096].
    *   Unit: pixels.

*   Decimal: the ratio of the watermark width to the width of the output video.

    *   Valid values: (0,1).
    *   The decimal number can be accurate to four decimal places, such as 0.9999. Excessive digits are automatically discarded.', example='32'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='ImageWatermarks', description='The watermark configuration of an image.'),
          subtitles?: [ 
            {
              overwriteParams?: {
                charEnc?: string(name='CharEnc', description='The file encoding format.', example='UTF-8'),
                file?: {
                  media?: string(name='Media', description='The media object.

*   If Type is set to OSS, set this parameter to the URL of an OSS object. Both the OSS and HTTP protocols are supported.
*   If Type is set to Media, set this parameter to the ID of a media asset.', example='oss://bucket/path/to/video.mp4'),
                  type?: string(name='Type', description='The type of the media object. Valid values:

*   OSS: an OSS object.
*   Media: a media asset.', example='OSS'),
                }(name='File', description='The subtitle file.'),
                format?: string(name='Format', description='The format of the subtitle file.', example='vtt'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='Subtitles', description='The subtitle configuration.'),
          textWatermarks?: [ 
            {
              overwriteParams?: {
                adaptive?: string(name='Adaptive', description='Specifies whether to the font size based on the output video dimensions. true / false, default: false', example='false'),
                borderColor?: string(name='BorderColor', description='The outline color of the text watermark. Default value: black. For more information, see BorderColor.', example='#006400'),
                borderWidth?: int32(name='BorderWidth', description='The outline width of the text watermark.

*   Default value: 0.
*   Valid values: (0,4096].', example='0'),
                content?: string(name='Content', description='The watermark text. Base64 encoding is not required. The string must be encoded in UTF-8.', example='测试水印'),
                fontAlpha?: string(name='FontAlpha', description='The transparency of the text.

*   Valid values: (0,1].
*   Default value: 1.', example='1.0'),
                fontColor?: string(name='FontColor', description='The color of the text.', example='#006400'),
                fontName?: string(name='FontName', description='The font of the text. Default value: SimSun.', example='SimSun'),
                fontSize?: int32(name='FontSize', description='The size of the text.

*   Default value: 16.
*   Valid values: (4,120).', example='16'),
                left?: string(name='Left', description='The left margin of the text watermark.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
                top?: string(name='Top', description='The top margin of the text.

*   Default value: 0.
*   Valid values: [0,4096].', example='10'),
              }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
              templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
            }
          ](name='TextWatermarks', description='The configurations of the text watermark.'),
          transcode?: {
            overwriteParams?: {
              audio?: {
                bitrate?: string(name='Bitrate', description='The audio bitrate of the output file.

*   Valid values: [8,1000].
*   Unit: Kbit/s.
*   Default value: 128.', example='128'),
                channels?: string(name='Channels', description='The number of sound channels. Default value: 2.', example='2'),
                codec?: string(name='Codec', description='The audio codec. Valid values: AAC, MP3, VORBIS, and FLAC. Default value: AAC.', example='AAC'),
                profile?: string(name='Profile', description='The audio codec profile. If the Codec parameter is set to AAC, the valid values are aac_low, aac_he, aac_he_v2, aac_ld, and aac_eld.', example='aac_low'),
                remove?: string(name='Remove', description='Specifies whether to delete the audio stream.', example='false'),
                samplerate?: string(name='Samplerate', description='The sampling rate.

*   Default value: 44100.
*   Valid values: 22050, 32000, 44100, 48000, and 96000.
*   Unit: Hz.', example='44100'),
                volume?: {
                  integratedLoudnessTarget?: string(name='IntegratedLoudnessTarget', description='The output volume.', example='-6'),
                  loudnessRangeTarget?: string(name='LoudnessRangeTarget', description='The volume range.', example='8'),
                  method?: string(name='Method', description='The volume adjustment method. Valid values:', example='auto'),
                  truePeak?: string(name='TruePeak', description='The peak volume.', example='-1'),
                }(name='Volume', description='The volume configurations.'),
              }(name='Audio', description='The audio settings.'),
              container?: {
                format?: string(name='Format', description='The container format.', example='mp4'),
              }(name='Container', description='The encapsulation format settings.'),
              muxConfig?: {
                segment?: {
                  duration?: string(name='Duration', description='The segment length.', example='10'),
                  forceSegTime?: string(name='ForceSegTime', description='The forced segmentation point in time.', example='2,3'),
                }(name='Segment', description='The segment settings.'),
              }(name='MuxConfig', description='The encapsulation settings.'),
              transConfig?: {
                adjDarMethod?: string(name='AdjDarMethod', description='The method that is used to adjust the resolution. This parameter takes effect only if both the Width and Height parameters are specified. You can use this parameter together with the LongShortMode parameter.

Valid values: rescale, crop, pad, and none.

Default value: none.', example='none'),
                isCheckAudioBitrate?: string(name='IsCheckAudioBitrate', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the bitrate of the input audio is used for transcoding.
*   false: does not check the video resolution.

Default values:

*   If this parameter is not specified and the codec of the output audio is different from that of the input audio, the default value is false.
*   If this parameter is not specified and the codec of the output audio is the same as that of the input audio, the default value is true.', example='true'),
                isCheckAudioBitrateFail?: string(name='IsCheckAudioBitrateFail', description='Specifies whether to check the audio bitrate. You can specify only one of the IsCheckAudioBitrate and IsCheckAudioBitrateFail parameters. The priority of the IsCheckAudioBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input audio is less than that of the output audio, the transcoding job fails.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckReso?: string(name='IsCheckReso', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the resolution of the input video is used for transcoding.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckResoFail?: string(name='IsCheckResoFail', description='Specifies whether to check the video resolution. You can specify only one of the IsCheckReso and IsCheckResoFail parameters. The priority of the IsCheckResoFail parameter is higher. Valid values:

*   true: checks the video resolution. If the width or height of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckVideoBitrate?: string(name='IsCheckVideoBitrate', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the bitrate of the input video is used for transcoding.
*   false: does not check the video resolution. This is the default value.', example='true'),
                isCheckVideoBitrateFail?: string(name='IsCheckVideoBitrateFail', description='Specifies whether to check the video bitrate. You can specify only one of the IsCheckVideoBitrate and IsCheckVideoBitrateFail parameters. The priority of the IsCheckVideoBitrateFail parameter is higher. Valid values:

*   true: checks the video resolution. If the bitrate of the input video is less than that of the output video, the transcoding job fails.
*   false: does not check the video resolution. This is the default value.', example='true'),
                transMode?: string(name='TransMode', description='The video transcoding mode. Valid values:

*   onepass: You can set this parameter to onepass if the Bitrate parameter is set to ABR. This is the default value. The encoding speed of this mode is faster than that of the twopass mode.
*   twopass: You can set this parameter to twopass if the Bitrate parameter is set to VBR. The encoding speed of this mode is slower than that of the onepass mode.
*   CBR: the constant bitrate mode.', example='onepass'),
              }(name='TransConfig', description='The conditional transcoding configurations.'),
              video?: {
                abrMax?: string(name='AbrMax', description='The maximum ABR. This parameter takes effect only for Narrowband HD 1.0. Valid values: [10,50000]. Unit: Kbit/s.', example='6000'),
                bitrate?: string(name='Bitrate', description='The average bitrate of the video.

*   Valid values: [10,50000].
*   Unit: Kbit/s.', example='3000'),
                bufsize?: string(name='Bufsize', description='The buffer size.

*   Valid values: [1000,128000].
*   Default value: 6000.
*   Unit: KB.', example='6000'),
                codec?: string(name='Codec', description='The encoding format.', example='H.264'),
                crf?: string(name='Crf', description='The constant rate factor.

*   Valid values: [0,51].
*   Default value: 23 if the encoding format is H.264, or Default value when the Codec parameter is set to H.265: 26.

If this parameter is specified, the value of Bitrate becomes invalid.', example='23'),
                crop?: string(name='Crop', description='The method of video cropping. Valid values:

*   border: automatically detects and removes black bars.
*   A value in the width:height:left:top format: crops the videos based on the custom settings. Example: 1280:800:0:140.', example='1280:800:0:140'),
                fps?: string(name='Fps', description='The frame rate.

*   Valid values: (0,60].
*   The value is 60 if the frame rate of the input video exceeds 60.
*   Default value: the frame rate of the input video.', example='25'),
                gop?: string(name='Gop', description='The maximum number of frames between two keyframes.

*   Valid values: [1,1080000].
*   Default value: 250.', example='250'),
                height?: string(name='Height', description='The height of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the height of the input video.', example='1080'),
                longShortMode?: string(name='LongShortMode', description='Specifies whether to enable the auto-rotate screen feature.', example='false'),
                maxrate?: string(name='Maxrate', description='The maximum bitrate of the output video. Valid values: [10,50000]. Unit: Kbit/s.', example='9000'),
                pad?: string(name='Pad', description='The black bars added to the video.

*   Format: width:height:left:top.
*   Example: 1280:800:0:140.', example='1280:800:0:140'),
                pixFmt?: string(name='PixFmt', description='The pixel format of the video. Valid values: standard pixel formats such as yuv420p and yuvj420p.', example='yuv420p'),
                preset?: string(name='Preset', description='The preset video algorithm. This parameter takes effect only if the encoding format is H.264. Valid values: veryfast, fast, medium, slow, and slower. Default value: medium.', example='medium'),
                profile?: string(name='Profile', description='The encoding profile. Valid values: baseline, main, and high.

*   baseline: applicable to mobile devices.
*   main: applicable to standard-definition devices.
*   high: applicable to high-definition devices.

Default value: high.', example='Main'),
                remove?: string(name='Remove', description='Specifies whether to remove the video.', example='false'),
                scanMode?: string(name='ScanMode', description='The scan mode. Valid values: interlaced and progressive.', example='progressive'),
                width?: string(name='Width', description='The width of the output video.

*   Valid values: [128,4096].
*   Unit: pixels.
*   Default value: the width of the input video.', example='1920'),
              }(name='Video', description='The video settings.'),
            }(name='OverwriteParams', description='The parameters that are used to overwrite the corresponding parameters of the template.'),
            templateId?: string(name='TemplateId', description='The template ID.', example='9547c6ad97cb4f2aaa29683ebd18d410'),
          }(name='Transcode', description='The transcoding configuration.'),
        }(name='ProcessConfig', description='The transcoding configuration.'),
        requestId?: string(name='RequestId', description='The ID of the request that submitted the job.', example='31E30781-9495-5E2D-A84D-759B0A01E262'),
        scheduleConfig?: {
          pipelineId?: string(name='PipelineId', description='The ID of the MPS queue to which the job was submitted.', example='e37ebee5d98b4781897f6086e89f9c56'),
          priority?: int32(name='Priority', description='The priority of the job. Valid values: 1 to 10. The greater the value, the higher the priority.', example='5'),
        }(name='ScheduleConfig', description='The scheduling information about the job.'),
        status?: string(name='Status', description='The state of the transcoding job. Valid values:

*   Init: The job is submitted.
*   Processing: The job is in progress.
*   Success: The job is successful.
*   Fail: The job failed.
*   Deleted: The job is deleted.', example='Init'),
        submitResultJson?: map[string]any(name='SubmitResultJson', description='The job submission result.', example='{}'),
        submitTime?: string(name='SubmitTime', description='The time when the job was submitted.', example='2022-01-12T08:49:41Z'),
        userData?: string(name='UserData', description='The user data.', example='user-data'),
      }
    ](name='TranscodeJobList', description='The list of subjobs.'),
    triggerSource?: string(name='TriggerSource', description='The source of the job. Valid values: API, WorkFlow, and Console.', example='API'),
    userData?: string(name='UserData', description='The user data.', example='user-data'),
  }(name='TranscodeParentJob', description='TranscodeParentJobWithSubJobDTO'),
}

model SubmitTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitTranscodeJobResponseBody(name='body'),
}

/**
 * @summary Submits a transcoding job.
 *
 * @param tmpReq SubmitTranscodeJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitTranscodeJobResponse
 */
async function submitTranscodeJobWithOptions(tmpReq: SubmitTranscodeJobRequest, runtime: $RuntimeOptions): SubmitTranscodeJobResponse {
  tmpReq.validate();
  var request = new SubmitTranscodeJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.inputGroup)) {
    request.inputGroupShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.inputGroup, 'InputGroup', 'json');
  }
  if (!$isNull(tmpReq.outputGroup)) {
    request.outputGroupShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.outputGroup, 'OutputGroup', 'json');
  }
  if (!$isNull(tmpReq.scheduleConfig)) {
    request.scheduleConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.scheduleConfig, 'ScheduleConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!$isNull(request.inputGroupShrink)) {
    query['InputGroup'] = request.inputGroupShrink;
  }
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.outputGroupShrink)) {
    query['OutputGroup'] = request.outputGroupShrink;
  }
  if (!$isNull(request.scheduleConfigShrink)) {
    query['ScheduleConfig'] = request.scheduleConfigShrink;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitTranscodeJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a transcoding job.
 *
 * @param request SubmitTranscodeJobRequest
 * @return SubmitTranscodeJobResponse
 */
async function submitTranscodeJob(request: SubmitTranscodeJobRequest): SubmitTranscodeJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitTranscodeJobWithOptions(request, runtime);
}

model SubmitVideoTranslationJobRequest {
  clientToken?: string(name='ClientToken', description='*   The client token.'),
  description?: string(name='Description', description='*   The job description.'),
  editingConfig?: string(name='EditingConfig', description='*   The configuration parameters of the video translation job.
*   The value must be in the JSON format.', example='{"SourceLanguage":"zh","TargetLanguage":"en","DetextArea":"Auto"}'),
  inputConfig?: string(name='InputConfig', description='*   The input parameters of the video translation job.
*   A video translation job takes a video or subtitle file as the input.
*   The value must be in the JSON format.', example='{"Type":"Video","Media":"https://your-bucket.oss-cn-shanghai.aliyuncs.com/xxx.mp4"}'),
  outputConfig?: string(name='OutputConfig', description='*   The output parameters of the video translation job.
*   A video translation job can generate a video or subtitle file as the output.', example='{"MediaURL": "https://your-bucket.oss-cn-shanghai.aliyuncs.com/your-object.mp4"}'),
  signature?: string(name='Signature'),
  signatureMehtod?: string(name='SignatureMehtod'),
  signatureNonce?: string(name='SignatureNonce'),
  signatureType?: string(name='SignatureType'),
  signatureVersion?: string(name='SignatureVersion'),
  title?: string(name='Title', description='*   The job title.'),
  userData?: string(name='UserData', description='*   The user-defined data.
*   The data must be in the JSON format, and can be up to 512 characters in length.', example='{"NotifyAddress":"http://xx.xx.xxx"}'),
}

model SubmitVideoTranslationJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the video translation job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.

Valid values:

*   true
*   false', example='true'),
}

model SubmitVideoTranslationJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitVideoTranslationJobResponseBody(name='body'),
}

/**
 * @summary Submits a video translation job. You can call this operation to translate subtitles in a video and audio to a specific language. Lip-sync adaptation will be supported in the future.
 *
 * @description After you call this operation to submit a video translation job, the system returns a job ID. You can call the GetSmartHandleJob operation based on the job ID to obtain the status and result information of the job.
 *
 * @param request SubmitVideoTranslationJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return SubmitVideoTranslationJobResponse
 */
async function submitVideoTranslationJobWithOptions(request: SubmitVideoTranslationJobRequest, runtime: $RuntimeOptions): SubmitVideoTranslationJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.clientToken)) {
    query['ClientToken'] = request.clientToken;
  }
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.editingConfig)) {
    query['EditingConfig'] = request.editingConfig;
  }
  if (!$isNull(request.inputConfig)) {
    query['InputConfig'] = request.inputConfig;
  }
  if (!$isNull(request.outputConfig)) {
    query['OutputConfig'] = request.outputConfig;
  }
  if (!$isNull(request.signature)) {
    query['Signature'] = request.signature;
  }
  if (!$isNull(request.signatureMehtod)) {
    query['SignatureMehtod'] = request.signatureMehtod;
  }
  if (!$isNull(request.signatureNonce)) {
    query['SignatureNonce'] = request.signatureNonce;
  }
  if (!$isNull(request.signatureType)) {
    query['SignatureType'] = request.signatureType;
  }
  if (!$isNull(request.signatureVersion)) {
    query['SignatureVersion'] = request.signatureVersion;
  }
  if (!$isNull(request.title)) {
    query['Title'] = request.title;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'SubmitVideoTranslationJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Submits a video translation job. You can call this operation to translate subtitles in a video and audio to a specific language. Lip-sync adaptation will be supported in the future.
 *
 * @description After you call this operation to submit a video translation job, the system returns a job ID. You can call the GetSmartHandleJob operation based on the job ID to obtain the status and result information of the job.
 *
 * @param request SubmitVideoTranslationJobRequest
 * @return SubmitVideoTranslationJobResponse
 */
async function submitVideoTranslationJob(request: SubmitVideoTranslationJobRequest): SubmitVideoTranslationJobResponse {
  var runtime = new $RuntimeOptions{};
  return submitVideoTranslationJobWithOptions(request, runtime);
}

model TakeoverAIAgentCallRequest {
  humanAgentUserId?: string(name='HumanAgentUserId', description='The ID of the human agent that will take over the AI agent (UserId in ARTC). If you do not specify this parameter, it is automatically generated and returned.', example='uid2'),
  instanceId?: string(name='InstanceId', description='The ID of the AI agent that will be taken over.', example='39f8e0bc005e4f309379701645f4****'),
  requireToken?: boolean(name='RequireToken', description='Specifies whether to return the ARTC token. Default value: false.', example='false'),
}

model TakeoverAIAgentCallResponseBody = {
  channelId?: string(name='ChannelId', description='The ID of the ARTC channel.', example='70f22d5784194938a7e387052f2b3208'),
  humanAgentUserId?: string(name='HumanAgentUserId', description='The ID of the human agent.', example='uid2'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
  token?: string(name='Token', description='The ARTC token.', example='eyJhcHBpZCI6ICIxMjM0MTIzNxxxxx'),
}

model TakeoverAIAgentCallResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: TakeoverAIAgentCallResponseBody(name='body'),
}

/**
 * @summary Hands off a conversation to a human agent.
 *
 * @param request TakeoverAIAgentCallRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return TakeoverAIAgentCallResponse
 */
async function takeoverAIAgentCallWithOptions(request: TakeoverAIAgentCallRequest, runtime: $RuntimeOptions): TakeoverAIAgentCallResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.humanAgentUserId)) {
    query['HumanAgentUserId'] = request.humanAgentUserId;
  }
  if (!$isNull(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  if (!$isNull(request.requireToken)) {
    query['RequireToken'] = request.requireToken;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'TakeoverAIAgentCall',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Hands off a conversation to a human agent.
 *
 * @param request TakeoverAIAgentCallRequest
 * @return TakeoverAIAgentCallResponse
 */
async function takeoverAIAgentCall(request: TakeoverAIAgentCallRequest): TakeoverAIAgentCallResponse {
  var runtime = new $RuntimeOptions{};
  return takeoverAIAgentCallWithOptions(request, runtime);
}

model UpdateAIAgentInstanceRequest {
  instanceId?: string(name='InstanceId', description='The ID of the AI agent that you want to update.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  templateConfig?: AIAgentTemplateConfig(name='TemplateConfig', description='The template configurations of the AI agent. The configurations are merged with the template configurations that are used to start the AI agent. For more information, see the definition of TemplateConfig.'),
  userData?: string(name='UserData', example='{"VoiceId":"xiaoxia"}'),
}

model UpdateAIAgentInstanceShrinkRequest {
  instanceId?: string(name='InstanceId', description='The ID of the AI agent that you want to update.

This parameter is required.', example='39f8e0bc005e4f309379701645f4****'),
  templateConfigShrink?: string(name='TemplateConfig', description='The template configurations of the AI agent. The configurations are merged with the template configurations that are used to start the AI agent. For more information, see the definition of TemplateConfig.'),
  userData?: string(name='UserData', example='{"VoiceId":"xiaoxia"}'),
}

model UpdateAIAgentInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='7B117AF5-2A16-412C-B127-FA6175ED1AD0'),
}

model UpdateAIAgentInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAIAgentInstanceResponseBody(name='body'),
}

/**
 * @summary Updates the configurations of an AI agent.
 *
 * @description ## [](#)Request description
 * You can call this operation to update the configurations of an AI agent, such as the tone, by specifying the agent ID and configurations.
 *
 * @param tmpReq UpdateAIAgentInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateAIAgentInstanceResponse
 */
async function updateAIAgentInstanceWithOptions(tmpReq: UpdateAIAgentInstanceRequest, runtime: $RuntimeOptions): UpdateAIAgentInstanceResponse {
  tmpReq.validate();
  var request = new UpdateAIAgentInstanceShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  if (!$isNull(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateAIAgentInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates the configurations of an AI agent.
 *
 * @description ## [](#)Request description
 * You can call this operation to update the configurations of an AI agent, such as the tone, by specifying the agent ID and configurations.
 *
 * @param request UpdateAIAgentInstanceRequest
 * @return UpdateAIAgentInstanceResponse
 */
async function updateAIAgentInstance(request: UpdateAIAgentInstanceRequest): UpdateAIAgentInstanceResponse {
  var runtime = new $RuntimeOptions{};
  return updateAIAgentInstanceWithOptions(request, runtime);
}

model UpdateAdInsertionRequest {
  adMarkerPassthrough?: string(name='AdMarkerPassthrough', description='Specifies whether to enable ad marker passthrough. Default value: OFF.

Valid values:

*   OFF: Disable.
*   ON: Enable.', example='ON'),
  adsUrl?: string(name='AdsUrl', description='The request URL of the ad decision server (ADS). HTTP and HTTPS are supported. The maximum length is 2,048 characters.

This parameter is required.', example='http://ads.com/ad1?param1=[palyer_params.p1]'),
  cdnAdSegmentUrlPrefix?: string(name='CdnAdSegmentUrlPrefix', description='The CDN prefix for ad segments. HTTP and HTTPS are supported. The maximum length is 512 characters.', example='http://cdn.com/'),
  cdnContentSegmentUrlPrefix?: string(name='CdnContentSegmentUrlPrefix', description='The CDN prefix for content segments. HTTP and HTTPS are supported. The maximum length is 512 characters.', example='http://cdn.com/'),
  configAliases?: string(name='ConfigAliases', description='A JSON string that specifies the player parameter variables and aliases. Format: { "player_params.{name}": { "{key}": "{value}" } }. You can add up to 20 player_params.{name} entries. The name field can be up to 150 characters in length. Each player parameter can include up to 50 key-value pairs. A key can be up to 150 characters long, and a value can be up to 500 characters.', example='{ "player_params.p1": { "1": "abc" } }'),
  contentUrlPrefix?: string(name='ContentUrlPrefix', description='The URL prefix for the source content. HTTP and HTTPS are supported. The maximum length is 512 characters.

This parameter is required.', example='https://source.com/'),
  name?: string(name='Name', description='The configuration name, which cannot be modified.

This parameter is required.', example='my_ad'),
  personalizationThreshold?: int32(name='PersonalizationThreshold', description='Specifies the maximum duration of underfilled time allowed in an ad break. Unit: seconds. Default value: 8 seconds.', example='5'),
  slateAdUrl?: string(name='SlateAdUrl', description='The HTTP or HTTPS URL of the slate ad. Only MP4 format is supported. The maximum length is 2,048 characters.', example='http://storage.com/slate1.mp4'),
}

model UpdateAdInsertionResponseBody = {
  config?: {
    adMarkerPassthrough?: string(name='AdMarkerPassthrough', description='Indicates whether ad marker passthrough is enabled.', example='ON'),
    adsUrl?: string(name='AdsUrl', description='The request URL of ADS.', example='http://ads.com/ad1?param1=[palyer_params.p1]'),
    cdnConfig?: {
      adSegmentUrlPrefix?: string(name='AdSegmentUrlPrefix', description='The CDN prefix for ad segments.', example='http://cdn.com/'),
      contentSegmentUrlPrefix?: string(name='ContentSegmentUrlPrefix', description='The CDN prefix for content segments.', example='http://cdn.com/'),
    }(name='CdnConfig', description='The CDN configurations.'),
    configAliases?: string(name='ConfigAliases', description='The player parameter variables and aliases.', example='{ "player_params.p1": { "1": "abc" } }'),
    contentUrlPrefix?: string(name='ContentUrlPrefix', description='The URL prefix for the source content.', example='https://source.com/'),
    createTime?: string(name='CreateTime', description='The time when the configuration was created.', example='2024-06-13T08:26:09Z'),
    lastModified?: string(name='LastModified', description='The time when the configuration was last modified.', example='2024-06-13T08:26:09Z'),
    manifestEndpointConfig?: {
      hlsPrefix?: string(name='HlsPrefix', description='The prefix of the playback endpoint for HLS manifests.'),
    }(name='ManifestEndpointConfig', description='The playback endpoint configuration.'),
    name?: string(name='Name', description='The name of the ad insertion configuration.', example='my_ad'),
    personalizationThreshold?: int32(name='PersonalizationThreshold', description='The personalization threshold.', example='5'),
    slateAdUrl?: string(name='SlateAdUrl', description='The URL of the slate ad.', example='http://storage.com/slate1.mp4'),
  }(name='Config', description='The ad insertion configuration.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='****63E8B7C7-4812-46AD-0FA56029AC86****'),
}

model UpdateAdInsertionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAdInsertionResponseBody(name='body'),
}

/**
 * @summary Modifies an ad insertion configuration.
 *
 * @param request UpdateAdInsertionRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateAdInsertionResponse
 */
async function updateAdInsertionWithOptions(request: UpdateAdInsertionRequest, runtime: $RuntimeOptions): UpdateAdInsertionResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.adMarkerPassthrough)) {
    body['AdMarkerPassthrough'] = request.adMarkerPassthrough;
  }
  if (!$isNull(request.adsUrl)) {
    body['AdsUrl'] = request.adsUrl;
  }
  if (!$isNull(request.cdnAdSegmentUrlPrefix)) {
    body['CdnAdSegmentUrlPrefix'] = request.cdnAdSegmentUrlPrefix;
  }
  if (!$isNull(request.cdnContentSegmentUrlPrefix)) {
    body['CdnContentSegmentUrlPrefix'] = request.cdnContentSegmentUrlPrefix;
  }
  if (!$isNull(request.configAliases)) {
    body['ConfigAliases'] = request.configAliases;
  }
  if (!$isNull(request.contentUrlPrefix)) {
    body['ContentUrlPrefix'] = request.contentUrlPrefix;
  }
  if (!$isNull(request.name)) {
    body['Name'] = request.name;
  }
  if (!$isNull(request.personalizationThreshold)) {
    body['PersonalizationThreshold'] = request.personalizationThreshold;
  }
  if (!$isNull(request.slateAdUrl)) {
    body['SlateAdUrl'] = request.slateAdUrl;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateAdInsertion',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies an ad insertion configuration.
 *
 * @param request UpdateAdInsertionRequest
 * @return UpdateAdInsertionResponse
 */
async function updateAdInsertion(request: UpdateAdInsertionRequest): UpdateAdInsertionResponse {
  var runtime = new $RuntimeOptions{};
  return updateAdInsertionWithOptions(request, runtime);
}

model UpdateAvatarTrainingJobRequest {
  avatarDescription?: string(name='AvatarDescription', description='*   The description of the digital human.
*   The description can be up to 1,000 characters in length.'),
  avatarName?: string(name='AvatarName', description='*   The name of the digital human.
*   The name can be up to seven characters in length.'),
  jobId?: string(name='JobId', description='The ID of the digital human training job.

This parameter is required.', example='****cdb3e74639973036bc84****'),
  portrait?: string(name='Portrait', description='*   The media asset ID of the portrait image.
*   The value must be 32 characters in length.', example='****571c704445f9a0ee011406c2****'),
  thumbnail?: string(name='Thumbnail', description='*   The thumbnail URL.
*   After the digital human is trained, the thumbnail is uploaded to this URL.
*   The URL must be a valid public Object Storage Service (OSS) URL.
*   The URL can be up to 512 characters in length.
*   The URL cannot be updated after the digital human is trained.', example='https://your-bucket.oss-cn-hangzhou.aliyuncs.com/thumbnail.png'),
  transparent?: boolean(name='Transparent', description='*   Indicates whether the input video supports alpha channels.

*   You can modify this parameter only if the job is in the Init or Fail state.

    **

    **Note**: Make sure that the current settings are consistent with those of the submitted training video. Otherwise, the digital human may malfunction.', example='True'),
  video?: string(name='Video', description='*   The ID of the video used for training.
*   The value must be 32 characters in length.
*   Supported formats: MP4, MOV, and WebM.
*   The duration of the video must be 5 to 15 minutes.
*   The resolution of the video must be 1920×1080 or 1080×1920.', example='****571c704445f9a0ee011406c2****'),
}

model UpdateAvatarTrainingJobResponseBody = {
  data?: {
    jobId?: string(name='JobId', description='The ID of the digital human training job.', example='****d718e2ff4f018ccf419a7b71****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateAvatarTrainingJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAvatarTrainingJobResponseBody(name='body'),
}

/**
 * @summary Modifies a digital human training job. You can modify the basic information or update parameters such as Video and Transparent for retraining if the training failed.
 *
 * @param request UpdateAvatarTrainingJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateAvatarTrainingJobResponse
 */
async function updateAvatarTrainingJobWithOptions(request: UpdateAvatarTrainingJobRequest, runtime: $RuntimeOptions): UpdateAvatarTrainingJobResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.avatarDescription)) {
    query['AvatarDescription'] = request.avatarDescription;
  }
  if (!$isNull(request.avatarName)) {
    query['AvatarName'] = request.avatarName;
  }
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.portrait)) {
    query['Portrait'] = request.portrait;
  }
  if (!$isNull(request.thumbnail)) {
    query['Thumbnail'] = request.thumbnail;
  }
  if (!$isNull(request.transparent)) {
    query['Transparent'] = request.transparent;
  }
  if (!$isNull(request.video)) {
    query['Video'] = request.video;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateAvatarTrainingJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies a digital human training job. You can modify the basic information or update parameters such as Video and Transparent for retraining if the training failed.
 *
 * @param request UpdateAvatarTrainingJobRequest
 * @return UpdateAvatarTrainingJobResponse
 */
async function updateAvatarTrainingJob(request: UpdateAvatarTrainingJobRequest): UpdateAvatarTrainingJobResponse {
  var runtime = new $RuntimeOptions{};
  return updateAvatarTrainingJobWithOptions(request, runtime);
}

model UpdateCategoryRequest {
  cateId?: long(name='CateId', description='The category ID. You can use one of the following methods to obtain the ID:

*   Log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com) and choose **Media Asset Management** > **Category Management** to view the category ID.
*   View the value of CateId returned by the AddCategory operation that you called to create a category.
*   View the value of CateId returned by the GetCategories operation that you called to query a category.

This parameter is required.', example='43'),
  cateName?: string(name='CateName', description='The category name.

This parameter is required.'),
}

model UpdateCategoryResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
}

model UpdateCategoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateCategoryResponseBody(name='body'),
}

/**
 * @summary Updates a category.
 *
 * @description After you create a media asset category, you can call this operation to find the category based on the category ID and change the name of the category.
 *
 * @param request UpdateCategoryRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateCategoryResponse
 */
async function updateCategoryWithOptions(request: UpdateCategoryRequest, runtime: $RuntimeOptions): UpdateCategoryResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.cateId)) {
    query['CateId'] = request.cateId;
  }
  if (!$isNull(request.cateName)) {
    query['CateName'] = request.cateName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateCategory',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates a category.
 *
 * @description After you create a media asset category, you can call this operation to find the category based on the category ID and change the name of the category.
 *
 * @param request UpdateCategoryRequest
 * @return UpdateCategoryResponse
 */
async function updateCategory(request: UpdateCategoryRequest): UpdateCategoryResponse {
  var runtime = new $RuntimeOptions{};
  return updateCategoryWithOptions(request, runtime);
}

model UpdateChannelRequest {
  accessPolicy?: boolean(name='AccessPolicy', description='Specifies whether to enable access control.', example='true'),
  accessToken?: string(name='AccessToken', description='The token for accessing the channel.', example='xxxxx'),
  channelName?: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel'),
  fillerSourceLocationName?: string(name='FillerSourceLocationName', description='The source location of the filler slate.', example='MySourceLocation'),
  fillerSourceName?: string(name='FillerSourceName', description='The name of the filler slate.', example='MySource'),
  outPutConfigList?: string(name='OutPutConfigList', description='The channel output configurations.

This parameter is required.', example='[{
	"ManifestName": "manifest-1",
	"Format": "HLS",
	"SourceGroupName": "source-group-1",
	"ManifestSettings": {
		"WindowDuration": 60,
		"AdMarkType": "Daterange"
	}
}]'),
}

model UpdateChannelResponseBody = {
  channel?: ChannelAssemblyChannel(name='Channel', description='The channel information.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
}

model UpdateChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateChannelResponseBody(name='body'),
}

/**
 * @summary Modifies a MediaWeaver channel.
 *
 * @param request UpdateChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateChannelResponse
 */
async function updateChannelWithOptions(request: UpdateChannelRequest, runtime: $RuntimeOptions): UpdateChannelResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.accessPolicy)) {
    query['AccessPolicy'] = request.accessPolicy;
  }
  if (!$isNull(request.accessToken)) {
    query['AccessToken'] = request.accessToken;
  }
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.fillerSourceLocationName)) {
    query['FillerSourceLocationName'] = request.fillerSourceLocationName;
  }
  if (!$isNull(request.fillerSourceName)) {
    query['FillerSourceName'] = request.fillerSourceName;
  }
  if (!$isNull(request.outPutConfigList)) {
    query['OutPutConfigList'] = request.outPutConfigList;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies a MediaWeaver channel.
 *
 * @param request UpdateChannelRequest
 * @return UpdateChannelResponse
 */
async function updateChannel(request: UpdateChannelRequest): UpdateChannelResponse {
  var runtime = new $RuntimeOptions{};
  return updateChannelWithOptions(request, runtime);
}

model UpdateCustomTemplateRequest {
  name?: string(name='Name', description='The template name.', example='test-template'),
  templateConfig?: string(name='TemplateConfig', description='The [template parameters](https://help.aliyun.com/document_detail/448291.html).', example='{"param": "sample"}'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****96e8864746a0b6f3****'),
}

model UpdateCustomTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateCustomTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateCustomTemplateResponseBody(name='body'),
}

/**
 * @summary Updates a custom template.
 *
 * @param request UpdateCustomTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateCustomTemplateResponse
 */
async function updateCustomTemplateWithOptions(request: UpdateCustomTemplateRequest, runtime: $RuntimeOptions): UpdateCustomTemplateResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.templateConfig)) {
    query['TemplateConfig'] = request.templateConfig;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateCustomTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates a custom template.
 *
 * @param request UpdateCustomTemplateRequest
 * @return UpdateCustomTemplateResponse
 */
async function updateCustomTemplate(request: UpdateCustomTemplateRequest): UpdateCustomTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return updateCustomTemplateWithOptions(request, runtime);
}

model UpdateCustomizedVoiceRequest {
  demoAudioMediaId?: string(name='DemoAudioMediaId', description='The media asset ID of the sample audio file.', example='****4d5e829d498aaf966b119348****'),
  voiceId?: string(name='VoiceId', description='The voice ID.

This parameter is required.', example='xiaozhuan'),
}

model UpdateCustomizedVoiceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateCustomizedVoiceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateCustomizedVoiceResponseBody(name='body'),
}

/**
 * @summary Updates a personalized human voice. Only the media asset ID of the sample audio file can be modified.
 *
 * @param request UpdateCustomizedVoiceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateCustomizedVoiceResponse
 */
async function updateCustomizedVoiceWithOptions(request: UpdateCustomizedVoiceRequest, runtime: $RuntimeOptions): UpdateCustomizedVoiceResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.demoAudioMediaId)) {
    query['DemoAudioMediaId'] = request.demoAudioMediaId;
  }
  if (!$isNull(request.voiceId)) {
    query['VoiceId'] = request.voiceId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateCustomizedVoice',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates a personalized human voice. Only the media asset ID of the sample audio file can be modified.
 *
 * @param request UpdateCustomizedVoiceRequest
 * @return UpdateCustomizedVoiceResponse
 */
async function updateCustomizedVoice(request: UpdateCustomizedVoiceRequest): UpdateCustomizedVoiceResponse {
  var runtime = new $RuntimeOptions{};
  return updateCustomizedVoiceWithOptions(request, runtime);
}

model UpdateEditingProjectRequest {
  businessStatus?: string(name='BusinessStatus', description='The business status of the project. This parameter can be ignored for general editing projects. Valid values:

*   Reserving
*   ReservationCanceled', example='Reserving'),
  clipsParam?: string(name='ClipsParam', description='The material parameter corresponding to the template, in the JSON format. If TemplateId is specified, ClipsParam must also be specified.'),
  coverURL?: string(name='CoverURL', description='The thumbnail URL of the online editing project.', example='https://****.com/6AB4D0E1E1C7446888****.png'),
  description?: string(name='Description', description='The description of the online editing project.', example='testtimeline001desciption'),
  projectId?: string(name='ProjectId', description='The ID of the online editing project.

This parameter is required.', example='****4ee4b97e27b525142a6b2****'),
  templateId?: string(name='TemplateId', description='The template ID. This parameter is used to quickly build a timeline with ease. Note: Only one of ProjectId, Timeline, and TemplateId can be specified. If TemplateId is specified, ClipsParam must also be specified.', example='****96e8864746a0b6f3****'),
  timeline?: string(name='Timeline'),
  title?: string(name='Title', description='The title of the online editing project.', example='testtimeline'),
}

model UpdateEditingProjectResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****25818875-5F78-4AF6-D7393642CA58****'),
}

model UpdateEditingProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateEditingProjectResponseBody(name='body'),
}

/**
 * @summary Modifies an online editing project. You can call this operation to modify the configurations such as the title, timeline, and thumbnail of an online editing project.
 *
 * @param request UpdateEditingProjectRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateEditingProjectResponse
 */
async function updateEditingProjectWithOptions(request: UpdateEditingProjectRequest, runtime: $RuntimeOptions): UpdateEditingProjectResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.businessStatus)) {
    query['BusinessStatus'] = request.businessStatus;
  }
  if (!$isNull(request.clipsParam)) {
    query['ClipsParam'] = request.clipsParam;
  }
  if (!$isNull(request.coverURL)) {
    query['CoverURL'] = request.coverURL;
  }
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.projectId)) {
    query['ProjectId'] = request.projectId;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  if (!$isNull(request.title)) {
    query['Title'] = request.title;
  }
  var body : map[string]any = {};
  if (!$isNull(request.timeline)) {
    body['Timeline'] = request.timeline;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateEditingProject',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies an online editing project. You can call this operation to modify the configurations such as the title, timeline, and thumbnail of an online editing project.
 *
 * @param request UpdateEditingProjectRequest
 * @return UpdateEditingProjectResponse
 */
async function updateEditingProject(request: UpdateEditingProjectRequest): UpdateEditingProjectResponse {
  var runtime = new $RuntimeOptions{};
  return updateEditingProjectWithOptions(request, runtime);
}

model UpdateLivePackageChannelRequest {
  channelName?: string(name='ChannelName', description='The channel name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='channel-1'),
  description?: string(name='Description', description='The channel description. It can be up to 1,000 characters in length.'),
  groupName?: string(name='GroupName', description='The channel group name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='channel-group-1'),
  protocol?: string(name='Protocol', description='The ingest protocol. Only HLS is supported.

This parameter is required.', example='HLS'),
  segmentCount?: int32(name='SegmentCount', description='The number of M3U8 segments. Valid values: 2 to 100.

This parameter is required.', example='3'),
  segmentDuration?: int32(name='SegmentDuration', description='The segment duration. Valid values: 1 to 30.

This parameter is required.', example='6'),
}

model UpdateLivePackageChannelResponseBody = {
  livePackageChannel?: {
    channelName?: string(name='ChannelName', description='The channel name.', example='channel-1'),
    createTime?: string(name='CreateTime', description='The time when the channel was created.', example='2024-07-16T02:24:42Z'),
    description?: string(name='Description', description='The channel description. It can be up to 1,000 characters in length.'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    ingestEndpoints?: [ 
      {
        id?: string(name='Id', description='The ingest endpoint ID.', example='ingest1'),
        password?: string(name='Password', description='The password.', example='2F9e******b569c8'),
        url?: string(name='Url', description='The ingest endpoint URL.', example='http://xxx-1.packagepush-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
        username?: string(name='Username', description='The username.', example='us12******das'),
      }
    ](name='IngestEndpoints', description='The ingest endpoints.'),
    lastModified?: string(name='LastModified', description='The time when the channel was last modified.', example='2024-07-16T02:24:42Z'),
    protocol?: string(name='Protocol', description='The ingest protocol. Only HLS is supported.', example='HLS'),
    segmentCount?: int32(name='SegmentCount', description='The number of segments.', example='3'),
    segmentDuration?: int32(name='SegmentDuration', description='The segment duration.', example='5'),
  }(name='LivePackageChannel', description='The information about the live package channel.'),
  requestId?: string(name='RequestId', description='The request ID.', example='771A1414-27BF-53E6-AB73-EFCB*****ACF'),
}

model UpdateLivePackageChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLivePackageChannelResponseBody(name='body'),
}

/**
 * @summary Updates the configuration of a live package channel, including the protocol, segment duration, and number of segments.
 *
 * @description ## [](#)Usage notes
 * You need to provide the name of the channel group to which the channel belongs, channel name, protocol, segment duration, and number of segments to update. In addition, you can choose to add or modify the description of the channel. Make sure that the provided channel group name and channel name conform to the naming conventions.
 *
 * @param request UpdateLivePackageChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateLivePackageChannelResponse
 */
async function updateLivePackageChannelWithOptions(request: UpdateLivePackageChannelRequest, runtime: $RuntimeOptions): UpdateLivePackageChannelResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.channelName)) {
    body['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.description)) {
    body['Description'] = request.description;
  }
  if (!$isNull(request.groupName)) {
    body['GroupName'] = request.groupName;
  }
  if (!$isNull(request.protocol)) {
    body['Protocol'] = request.protocol;
  }
  if (!$isNull(request.segmentCount)) {
    body['SegmentCount'] = request.segmentCount;
  }
  if (!$isNull(request.segmentDuration)) {
    body['SegmentDuration'] = request.segmentDuration;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateLivePackageChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates the configuration of a live package channel, including the protocol, segment duration, and number of segments.
 *
 * @description ## [](#)Usage notes
 * You need to provide the name of the channel group to which the channel belongs, channel name, protocol, segment duration, and number of segments to update. In addition, you can choose to add or modify the description of the channel. Make sure that the provided channel group name and channel name conform to the naming conventions.
 *
 * @param request UpdateLivePackageChannelRequest
 * @return UpdateLivePackageChannelResponse
 */
async function updateLivePackageChannel(request: UpdateLivePackageChannelRequest): UpdateLivePackageChannelResponse {
  var runtime = new $RuntimeOptions{};
  return updateLivePackageChannelWithOptions(request, runtime);
}

model UpdateLivePackageChannelCredentialsRequest {
  channelName?: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1'),
  groupName?: string(name='GroupName', description='The channel group name.

This parameter is required.', example='group-1'),
  rotateCredentials?: int32(name='RotateCredentials', description='Specifies whether to update the credentials. 1: updates the credentials of endpoint 1. 2: updates the credentials of endpoint 2. 3: updates the credentials of endpoints 1 and 2.

This parameter is required.', example='3'),
}

model UpdateLivePackageChannelCredentialsResponseBody = {
  ingestEndpoints?: [ 
    {
      id?: string(name='Id', description='The ingest endpoint ID. `input1` indicates primary and `input2` indicates secondary.', example='input1'),
      password?: string(name='Password', description='The password.', example='examplePassword123'),
      url?: string(name='Url', description='The ingest endpoint URL.', example='rtmp://example.com/live/input1'),
      username?: string(name='Username', description='The username.', example='user1'),
    }
  ](name='IngestEndpoints', description='The information about the ingest endpoint.'),
  requestId?: string(name='RequestId', description='The request ID.', example='771A1414-27BF-53E6-AB73-EFCB*****ACF'),
}

model UpdateLivePackageChannelCredentialsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLivePackageChannelCredentialsResponseBody(name='body'),
}

/**
 * @summary Updates the credentials of ingest endpoints associated with a live package channel.
 *
 * @description ## [](#)Usage notes
 * You can choose to update the primary endpoint, secondary endpoint, or both. The response includes the updated ingest endpoint URL, username, and password for the ingest device to reconfigure.
 *
 * @param request UpdateLivePackageChannelCredentialsRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateLivePackageChannelCredentialsResponse
 */
async function updateLivePackageChannelCredentialsWithOptions(request: UpdateLivePackageChannelCredentialsRequest, runtime: $RuntimeOptions): UpdateLivePackageChannelCredentialsResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.channelName)) {
    body['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.groupName)) {
    body['GroupName'] = request.groupName;
  }
  if (!$isNull(request.rotateCredentials)) {
    body['RotateCredentials'] = request.rotateCredentials;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateLivePackageChannelCredentials',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates the credentials of ingest endpoints associated with a live package channel.
 *
 * @description ## [](#)Usage notes
 * You can choose to update the primary endpoint, secondary endpoint, or both. The response includes the updated ingest endpoint URL, username, and password for the ingest device to reconfigure.
 *
 * @param request UpdateLivePackageChannelCredentialsRequest
 * @return UpdateLivePackageChannelCredentialsResponse
 */
async function updateLivePackageChannelCredentials(request: UpdateLivePackageChannelCredentialsRequest): UpdateLivePackageChannelCredentialsResponse {
  var runtime = new $RuntimeOptions{};
  return updateLivePackageChannelCredentialsWithOptions(request, runtime);
}

model UpdateLivePackageChannelGroupRequest {
  description?: string(name='Description', description='The channel group description. It can be up to 1,000 characters in length.'),
  groupName?: string(name='GroupName', description='The channel group name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='channel-group-1'),
}

model UpdateLivePackageChannelGroupResponseBody = {
  livePackageChannelGroup?: {
    createTime?: string(name='CreateTime', description='The time when the channel group was created. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The channel group description.', example='Updated description of the channel group.'),
    groupName?: string(name='GroupName', description='The channel group name.', example='example-group-name'),
    lastModified?: string(name='LastModified', description='The time when the channel group was last modified. It is in the yyyy-MM-ddTHH:mm:ssZ format and displayed in UTC.', example='2023-04-01T12:00:00Z'),
    originDomain?: string(name='OriginDomain', description='The origin domain.', example='example-origin.com'),
  }(name='LivePackageChannelGroup', description='The information about the channel group.'),
  requestId?: string(name='RequestId', description='The request ID.', example='request-1234567890'),
}

model UpdateLivePackageChannelGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLivePackageChannelGroupResponseBody(name='body'),
}

/**
 * @summary Updates the information about a live package channel group including its description.
 *
 * @description ## [](#)Usage notes
 * This API operation allows you to modify the name and description of a live package channel group. The channel group name must conform to the naming conventions and can be up to 1,000 characters. The API response includes the updated channel group details and unique identifier of the request.
 *
 * @param request UpdateLivePackageChannelGroupRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateLivePackageChannelGroupResponse
 */
async function updateLivePackageChannelGroupWithOptions(request: UpdateLivePackageChannelGroupRequest, runtime: $RuntimeOptions): UpdateLivePackageChannelGroupResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.description)) {
    body['Description'] = request.description;
  }
  if (!$isNull(request.groupName)) {
    body['GroupName'] = request.groupName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateLivePackageChannelGroup',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates the information about a live package channel group including its description.
 *
 * @description ## [](#)Usage notes
 * This API operation allows you to modify the name and description of a live package channel group. The channel group name must conform to the naming conventions and can be up to 1,000 characters. The API response includes the updated channel group details and unique identifier of the request.
 *
 * @param request UpdateLivePackageChannelGroupRequest
 * @return UpdateLivePackageChannelGroupResponse
 */
async function updateLivePackageChannelGroup(request: UpdateLivePackageChannelGroupRequest): UpdateLivePackageChannelGroupResponse {
  var runtime = new $RuntimeOptions{};
  return updateLivePackageChannelGroupWithOptions(request, runtime);
}

model UpdateLivePackageOriginEndpointRequest {
  authorizationCode?: string(name='AuthorizationCode', description='The authorization code. It can be up to 200 characters in length. You must configure AuthorizationCode, IpWhitelist, or both. Format: [A-Za-z0-9-_.]+', example='Abc123Def456'),
  channelName?: string(name='ChannelName', description='The channel name.

This parameter is required.', example='channel-1'),
  description?: string(name='Description', description='The endpoint description.'),
  endpointName?: string(name='EndpointName', description='The origin endpoint name. It can contain letters, digits, hyphens (-), and underscores (_). The name must be 1 to 200 characters in length. Format: [A-Za-z0-9_-]+

This parameter is required.', example='endpoint-1'),
  groupName?: string(name='GroupName', description='The channel group name.

This parameter is required.', example='channel-group-1'),
  ipBlacklist?: string(name='IpBlacklist', description='The IP address blacklist. It supports subnet masks. Separate multiple IP addresses with commas (,).', example='103.0.0.0/8'),
  ipWhitelist?: string(name='IpWhitelist', description='The IP address whitelist. It supports subnet masks. 0.0.0.0/0 is not allowed. It can be up to 1,000 characters in length. Separate multiple IP addresses with commas (,). You must configure AuthorizationCode, IpWhitelist, or both.', example='192.168.1.0/24,10.0.0.1'),
  manifestName?: string(name='ManifestName', description='The playlist name. Default value: manifest.', example='manifest'),
  protocol?: string(name='Protocol', description='The protocol. Only HLS is supported.

This parameter is required.', example='HLS'),
  timeshiftVision?: int32(name='TimeshiftVision', description='The number of days that time-shifted content is available. Maximum value: 30.', example='5'),
}

model UpdateLivePackageOriginEndpointResponseBody = {
  livePackageOriginEndpoint?: {
    authorizationCode?: string(name='AuthorizationCode', description='The authorization code.', example='Abc123Def456'),
    channelName?: string(name='ChannelName', description='The channel name.', example='channel-1'),
    createTime?: string(name='CreateTime', description='The time when the endpoint was created.', example='2023-04-01T12:00:00Z'),
    description?: string(name='Description', description='The endpoint description.'),
    endpointName?: string(name='EndpointName', description='The endpoint name.', example='endpoint-1'),
    endpointUrl?: string(name='EndpointUrl', description='The endpoint URL.', example='https://xxx.packagepull-abcxxx.ap-southeast-1.aliyuncsiceintl.com/v1/group01/1/ch01/manifest'),
    groupName?: string(name='GroupName', description='The channel group name.', example='channel-group-1'),
    ipBlacklist?: string(name='IpBlacklist', description='The IP address blacklist. It supports subnet masks. Multiple IP addresses are separated by commas (,).', example='10.21.222.1/32,192.168.100.0/24'),
    ipWhitelist?: string(name='IpWhitelist', description='The IP address whitelist. It supports subnet masks. Multiple IP addresses are separated by commas (,).', example='192.168.1.0/24,10.0.0.1/24'),
    lastModified?: string(name='LastModified', description='The time when the endpoint was last modified.', example='2023-04-01T12:00:00Z'),
    manifestName?: string(name='ManifestName', description='The playlist name. Default value: manifest.', example='manifest'),
    protocol?: string(name='Protocol', description='The protocol. Only HLS is supported.', example='HLS'),
    timeshiftVision?: int32(name='TimeshiftVision', description='The number of days that time-shifted content is available. Maximum value: 30.', example='5'),
  }(name='LivePackageOriginEndpoint', description='The information about the origin endpoint.'),
  requestId?: string(name='RequestId', description='The request ID.', example='b1f8d6c4-a123-4cd5-9e88-d0819e3bfa70'),
}

model UpdateLivePackageOriginEndpointResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLivePackageOriginEndpointResponseBody(name='body'),
}

/**
 * @summary Updates the origin endpoint settings including the protocol, time shifting, and access control settings.
 *
 * @description ## [](#)Usage notes
 * You can call this operation to modify the origin protocol, set the number of days that time-shifted content is available, define playlist names, and configure the IP address blacklist and whitelist, allowing for fine-grained control over streaming media distribution. Some parameters are required. You must configure IpWhitelist, AuthorizationCode, or both.
 *
 * @param request UpdateLivePackageOriginEndpointRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateLivePackageOriginEndpointResponse
 */
async function updateLivePackageOriginEndpointWithOptions(request: UpdateLivePackageOriginEndpointRequest, runtime: $RuntimeOptions): UpdateLivePackageOriginEndpointResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.authorizationCode)) {
    body['AuthorizationCode'] = request.authorizationCode;
  }
  if (!$isNull(request.channelName)) {
    body['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.description)) {
    body['Description'] = request.description;
  }
  if (!$isNull(request.endpointName)) {
    body['EndpointName'] = request.endpointName;
  }
  if (!$isNull(request.groupName)) {
    body['GroupName'] = request.groupName;
  }
  if (!$isNull(request.ipBlacklist)) {
    body['IpBlacklist'] = request.ipBlacklist;
  }
  if (!$isNull(request.ipWhitelist)) {
    body['IpWhitelist'] = request.ipWhitelist;
  }
  if (!$isNull(request.manifestName)) {
    body['ManifestName'] = request.manifestName;
  }
  if (!$isNull(request.protocol)) {
    body['Protocol'] = request.protocol;
  }
  if (!$isNull(request.timeshiftVision)) {
    body['TimeshiftVision'] = request.timeshiftVision;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateLivePackageOriginEndpoint',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates the origin endpoint settings including the protocol, time shifting, and access control settings.
 *
 * @description ## [](#)Usage notes
 * You can call this operation to modify the origin protocol, set the number of days that time-shifted content is available, define playlist names, and configure the IP address blacklist and whitelist, allowing for fine-grained control over streaming media distribution. Some parameters are required. You must configure IpWhitelist, AuthorizationCode, or both.
 *
 * @param request UpdateLivePackageOriginEndpointRequest
 * @return UpdateLivePackageOriginEndpointResponse
 */
async function updateLivePackageOriginEndpoint(request: UpdateLivePackageOriginEndpointRequest): UpdateLivePackageOriginEndpointResponse {
  var runtime = new $RuntimeOptions{};
  return updateLivePackageOriginEndpointWithOptions(request, runtime);
}

model UpdateLiveRecordTemplateRequest {
  name?: string(name='Name', description='The template name.

This parameter is required.', example='test template'),
  recordFormat?: [ 
    {
      cycleDuration?: int32(name='CycleDuration', description='The duration of the recording cycle. Unit: seconds If you do not specify this parameter, the default value 6 hours is used.

> 

*   If a live stream is interrupted during a recording cycle but is resumed within 3 minutes, the stream is recorded in the same recording before and after the interruption.

*   If a live stream is interrupted for more than 3 minutes, a new recording is generated. To change the default stream interruption time, submit a ticket.', example='3600'),
      format?: string(name='Format', description='The format of recording files.

>  If you set this parameter to m3u8, you must also specify the SliceOssObjectPrefix and SliceDuration parameters.

This parameter is required.', example='m3u8'),
      ossObjectPrefix?: string(name='OssObjectPrefix', description='The name of the recording that is stored in Object Storage Service (OSS).

*   The name must be less than 256 bytes in length and can contain the {JobId}, {Sequence}, {StartTime}, {EndTime}, {EscapedStartTime}, and {EscapedEndTime} variables.
*   The name must contain the {StartTime} and {EndTime} variables or the {EscapedStartTime} and {EscapedEndTime} variables.', example='record/{JobId}/{Sequence}_{EscapedStartTime}_{EscapedEndTime}'),
      sliceDuration?: int32(name='SliceDuration', description='The duration of a single segment. Unit: seconds

>  This parameter takes effect only if you set Format to m3u8.

If you do not specify this parameter, the default value 30 seconds is used. Valid values: 5 to 30.', example='30'),
      sliceOssObjectPrefix?: string(name='SliceOssObjectPrefix', description='The name of the TS segment.

>  This parameter is required only if you set Format to m3u8. By default, the duration of a segment is 30 seconds. The segment name must be less than 256 bytes in length and can contain the {JobId}, {UnixTimestamp}, and {Sequence} variables.

The segment name must contain the {UnixTimestamp} and {Sequence} variables.', example='record/{JobId}/{UnixTimestamp}_{Sequence}'),
    }
  ](name='RecordFormat', description='The list of recording formats.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
}

model UpdateLiveRecordTemplateShrinkRequest {
  name?: string(name='Name', description='The template name.

This parameter is required.', example='test template'),
  recordFormatShrink?: string(name='RecordFormat', description='The list of recording formats.

This parameter is required.'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='69e1f9fe-1e97-11ed-ba64-0c42a1b73d66'),
}

model UpdateLiveRecordTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0F3D5C03-4B6E-5F40-B7F6-B1956776E7D3'),
}

model UpdateLiveRecordTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveRecordTemplateResponseBody(name='body'),
}

/**
 * @summary Updates the information about a live stream recording template.
 *
 * @description Only user-created templates can be updated. The preset template cannot be updated.
 *
 * @param tmpReq UpdateLiveRecordTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateLiveRecordTemplateResponse
 */
async function updateLiveRecordTemplateWithOptions(tmpReq: UpdateLiveRecordTemplateRequest, runtime: $RuntimeOptions): UpdateLiveRecordTemplateResponse {
  tmpReq.validate();
  var request = new UpdateLiveRecordTemplateShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.recordFormat)) {
    request.recordFormatShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.recordFormat, 'RecordFormat', 'json');
  }
  var body : map[string]any = {};
  if (!$isNull(request.name)) {
    body['Name'] = request.name;
  }
  if (!$isNull(request.recordFormatShrink)) {
    body['RecordFormat'] = request.recordFormatShrink;
  }
  if (!$isNull(request.templateId)) {
    body['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateLiveRecordTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates the information about a live stream recording template.
 *
 * @description Only user-created templates can be updated. The preset template cannot be updated.
 *
 * @param request UpdateLiveRecordTemplateRequest
 * @return UpdateLiveRecordTemplateResponse
 */
async function updateLiveRecordTemplate(request: UpdateLiveRecordTemplateRequest): UpdateLiveRecordTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return updateLiveRecordTemplateWithOptions(request, runtime);
}

model UpdateLiveSnapshotTemplateRequest {
  overwriteFormat?: string(name='OverwriteFormat', description='The naming format of the snapshot captured in overwrite mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   The value cannot exceed 255 characters in length.
*   The {JobId} placeholder is supported. It specifies the ID of the snapshot job.
*   Placeholders such as {UnixTimestamp}, {Sequence}, and {Date} are not allowed.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}.jpg'),
  sequenceFormat?: string(name='SequenceFormat', description='The naming format of the snapshot captured in time series mode.

*   The value cannot start with a forward slash (/). Only the suffix .jpg is supported.
*   The value cannot exceed 255 characters in length.
*   The {JobId}, {Date}, {UnixTimestamp}, and {Sequence} placeholders are supported. {JobId} specifies the ID of the snapshot job. {Date} specifies the date on which the snapshot is captured. {UnixTimestamp} specifies the timestamp of the snapshot. {Sequence} specifies the sequence number of the snapshot. You must specify at least one of the {UnixTimestamp} and {Sequence} placeholders.
*   You must specify at least one of the OverwriteFormat and SequenceFormat parameters.', example='snapshot/{JobId}/{UnixTimestamp}.jpg'),
  templateId?: string(name='TemplateId', description='The template ID.

This parameter is required.', example='****a046-263c-3560-978a-fb287782****'),
  templateName?: string(name='TemplateName', description='The name of the template.

*   It cannot exceed 128 characters in length.

This parameter is required.'),
  timeInterval?: int32(name='TimeInterval', description='The interval between two adjacent snapshots. Unit: seconds.

*   Valid values: [5,3600].

This parameter is required.', example='5'),
}

model UpdateLiveSnapshotTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateLiveSnapshotTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveSnapshotTemplateResponseBody(name='body'),
}

/**
 * @summary Updates the information about a live stream snapshot template.
 *
 * @param request UpdateLiveSnapshotTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateLiveSnapshotTemplateResponse
 */
async function updateLiveSnapshotTemplateWithOptions(request: UpdateLiveSnapshotTemplateRequest, runtime: $RuntimeOptions): UpdateLiveSnapshotTemplateResponse {
  request.validate();
  var body : map[string]any = {};
  if (!$isNull(request.overwriteFormat)) {
    body['OverwriteFormat'] = request.overwriteFormat;
  }
  if (!$isNull(request.sequenceFormat)) {
    body['SequenceFormat'] = request.sequenceFormat;
  }
  if (!$isNull(request.templateId)) {
    body['TemplateId'] = request.templateId;
  }
  if (!$isNull(request.templateName)) {
    body['TemplateName'] = request.templateName;
  }
  if (!$isNull(request.timeInterval)) {
    body['TimeInterval'] = request.timeInterval;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateLiveSnapshotTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates the information about a live stream snapshot template.
 *
 * @param request UpdateLiveSnapshotTemplateRequest
 * @return UpdateLiveSnapshotTemplateResponse
 */
async function updateLiveSnapshotTemplate(request: UpdateLiveSnapshotTemplateRequest): UpdateLiveSnapshotTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return updateLiveSnapshotTemplateWithOptions(request, runtime);
}

model UpdateLiveTranscodeJobRequest {
  jobId?: string(name='JobId', description='The job ID.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
  name?: string(name='Name', description='The name of the job.', example='mytest3'),
  streamInput?: {
    inputUrl?: string(name='InputUrl', description='The URL of the input stream.

This parameter is required.', example='rtmp://mydomain/app/stream1'),
    type?: string(name='Type', description='The type of the input stream. The value can only be rtmp.

This parameter is required.', example='rtmp'),
  }(name='StreamInput', description='The information about the input stream.'),
  timedConfig?: {
    endTime?: string(name='EndTime', description='The stop time of the transcoding job. Note: The time span between the stop time and the current time cannot exceed seven days.', example='2022-08-05T06:08:31Z'),
    startTime?: string(name='StartTime', description='The start time of the transcoding job. Note: The time span between the start time and the current time cannot exceed seven days.', example='2022-06-19T02:16:41Z'),
  }(name='TimedConfig', description='The configuration of a timed transcoding job.'),
  transcodeOutput?: {
    domainName?: string(name='DomainName', description='The streaming domain name of ApsaraVideo Live.

This parameter is required.', example='mydomain'),
    type?: string(name='Type', description='The type of the output stream. A value of LiveCenter indicates that the URL of the output stream is generated based on the domain name of ApsaraVideo Live. The value can only be LiveCenter.

This parameter is required.', example='LiveCenter'),
  }(name='TranscodeOutput', description='The information about the transcoding output.'),
}

model UpdateLiveTranscodeJobShrinkRequest {
  jobId?: string(name='JobId', description='The job ID.

This parameter is required.', example='****20b48fb04483915d4f2cd8ac****'),
  name?: string(name='Name', description='The name of the job.', example='mytest3'),
  streamInputShrink?: string(name='StreamInput', description='The information about the input stream.'),
  timedConfigShrink?: string(name='TimedConfig', description='The configuration of a timed transcoding job.'),
  transcodeOutputShrink?: string(name='TranscodeOutput', description='The information about the transcoding output.'),
}

model UpdateLiveTranscodeJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model UpdateLiveTranscodeJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveTranscodeJobResponseBody(name='body'),
}

/**
 * @summary Updates the information about a live stream transcoding job.
 *
 * @description *   For a non-timed transcoding job, you can modify the Name parameter of the job, regardless of the job state.
 * *   For a timed job, you can modify the Name, StreamInput, TranscodeOutput, and TimedConfig parameters. However, the StreamInput, TranscodeOutput, and TimedConfig parameters can be modified only when the job is not started.
 *
 * @param tmpReq UpdateLiveTranscodeJobRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateLiveTranscodeJobResponse
 */
async function updateLiveTranscodeJobWithOptions(tmpReq: UpdateLiveTranscodeJobRequest, runtime: $RuntimeOptions): UpdateLiveTranscodeJobResponse {
  tmpReq.validate();
  var request = new UpdateLiveTranscodeJobShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.streamInput)) {
    request.streamInputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.streamInput, 'StreamInput', 'json');
  }
  if (!$isNull(tmpReq.timedConfig)) {
    request.timedConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.timedConfig, 'TimedConfig', 'json');
  }
  if (!$isNull(tmpReq.transcodeOutput)) {
    request.transcodeOutputShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.transcodeOutput, 'TranscodeOutput', 'json');
  }
  var query = {};
  if (!$isNull(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.streamInputShrink)) {
    query['StreamInput'] = request.streamInputShrink;
  }
  if (!$isNull(request.timedConfigShrink)) {
    query['TimedConfig'] = request.timedConfigShrink;
  }
  if (!$isNull(request.transcodeOutputShrink)) {
    query['TranscodeOutput'] = request.transcodeOutputShrink;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateLiveTranscodeJob',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates the information about a live stream transcoding job.
 *
 * @description *   For a non-timed transcoding job, you can modify the Name parameter of the job, regardless of the job state.
 * *   For a timed job, you can modify the Name, StreamInput, TranscodeOutput, and TimedConfig parameters. However, the StreamInput, TranscodeOutput, and TimedConfig parameters can be modified only when the job is not started.
 *
 * @param request UpdateLiveTranscodeJobRequest
 * @return UpdateLiveTranscodeJobResponse
 */
async function updateLiveTranscodeJob(request: UpdateLiveTranscodeJobRequest): UpdateLiveTranscodeJobResponse {
  var runtime = new $RuntimeOptions{};
  return updateLiveTranscodeJobWithOptions(request, runtime);
}

model UpdateLiveTranscodeTemplateRequest {
  name?: string(name='Name', description='The template name.'),
  templateConfig?: {
    audioParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output audio. Unit: Kbit/s. Valid values: 1 to 1000.', example='100'),
      channels?: string(name='Channels', description='The number of sound channels. Valid values: 1: mono 2: binaural', example='2'),
      codec?: string(name='Codec', description='The audio codec. Valid values: AAC MP3', example='AAC'),
      profile?: string(name='Profile', description='The audio codec profile. Valid values when the Codec parameter is set to AAC:

*   aac_low
*   aac_he
*   aac_he_v2
*   aac_ld', example='aac_low'),
      samplerate?: string(name='Samplerate', description='The audio sampling rate. Valid values: 22050 to 96000.

Note If you set AudioProfile to aac_ld, the audio sampling rate cannot exceed 44100.', example='44100'),
    }(name='AudioParams', description='The audio parameters.'),
    videoParams?: {
      bitrate?: string(name='Bitrate', description='The bitrate of the output video. Unit: Kbit/s. Valid values: 1 to 6000.', example='2500'),
      codec?: string(name='Codec', description='The encoding type. Valid values:

*   H.264
*   H.265', example='H.264'),
      fps?: string(name='Fps', description='The frame rate of the output video. Unit: frames per second (FPS). Valid values: 1 to 60.', example='30'),
      gop?: string(name='Gop', description='The group of pictures (GOP) of the output video. Unit: frame. Valid values: 1 to 3000.', example='1000'),
      height?: string(name='Height', description='The height of the output video. Valid values:

*   Height ≥ 128
*   max (Height,Width) ≤ 2560
*   min（Height,Width）≤ 1440

>  The resolution of a video transcoded by using the H.265 Narrowband HD template cannot exceed 1,280 × 720 pixels.', example='720'),
      profile?: string(name='Profile', description='The video encoding profile. The profile determines how a video is encoded. In most cases, a greater value indicates better image quality and higher resource consumption. Valid values:

*   1: baseline. This value is suitable for mobile devices.
*   2: main. This value is suitable for standard-definition devices.
*   3: high. This value is suitable for high-definition devices.', example='2'),
      width?: string(name='Width', description='The width of the output video. Valid values:

*   Width ≥ 128
*   max (Height,Width) ≤ 2560
*   min（Height,Width）≤ 1440

>  The resolution of a video transcoded by using the H.265 Narrowband HD template cannot exceed 1,280 × 720 pixels.', example='1280'),
    }(name='VideoParams', description='The video parameters.'),
  }(name='TemplateConfig', description='The configuration of the template.'),
  templateId?: string(name='TemplateId', description='The template ID. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com/summary), choose Real-time Media Processing > Template Management, and then click the Transcoding tab. Alternatively, find the ID from the response parameters of the [CreateLiveTranscodeTemplate](https://help.aliyun.com/document_detail/449217.html) operation.

This parameter is required.', example='****96e8864746a0b6f3****'),
}

model UpdateLiveTranscodeTemplateShrinkRequest {
  name?: string(name='Name', description='The template name.'),
  templateConfigShrink?: string(name='TemplateConfig', description='The configuration of the template.'),
  templateId?: string(name='TemplateId', description='The template ID. To obtain the template ID, log on to the [Intelligent Media Services (IMS) console](https://ims.console.aliyun.com/summary), choose Real-time Media Processing > Template Management, and then click the Transcoding tab. Alternatively, find the ID from the response parameters of the [CreateLiveTranscodeTemplate](https://help.aliyun.com/document_detail/449217.html) operation.

This parameter is required.', example='****96e8864746a0b6f3****'),
}

model UpdateLiveTranscodeTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******3B-0E1A-586A-AC29-742247******'),
}

model UpdateLiveTranscodeTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateLiveTranscodeTemplateResponseBody(name='body'),
}

/**
 * @summary Updates the information about a live stream transcoding template.
 *
 * @param tmpReq UpdateLiveTranscodeTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateLiveTranscodeTemplateResponse
 */
async function updateLiveTranscodeTemplateWithOptions(tmpReq: UpdateLiveTranscodeTemplateRequest, runtime: $RuntimeOptions): UpdateLiveTranscodeTemplateResponse {
  tmpReq.validate();
  var request = new UpdateLiveTranscodeTemplateShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.templateConfig)) {
    request.templateConfigShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.templateConfig, 'TemplateConfig', 'json');
  }
  var query = {};
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.templateConfigShrink)) {
    query['TemplateConfig'] = request.templateConfigShrink;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateLiveTranscodeTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates the information about a live stream transcoding template.
 *
 * @param request UpdateLiveTranscodeTemplateRequest
 * @return UpdateLiveTranscodeTemplateResponse
 */
async function updateLiveTranscodeTemplate(request: UpdateLiveTranscodeTemplateRequest): UpdateLiveTranscodeTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return updateLiveTranscodeTemplateWithOptions(request, runtime);
}

model UpdateMediaConnectFlowInputRequest {
  cidrs?: string(name='Cidrs', description='The IP address whitelist.', example='19.168.1.1/32,18.168.1.1/16'),
  flowId?: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f'),
  inputFromUrl?: string(name='InputFromUrl', description='The source URL. You can modify this parameter only when the source type is RTMP-PULL or SRT-Listener.', example='rtmp://pull.test.alivecdn.com/live/alitest'),
  maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s.', example='2000000'),
  srtLatency?: int32(name='SrtLatency', description='The latency for the SRT stream. You can modify this parameter only when the source type is SRT-Listener or SRT-Caller.', example='1000'),
  srtPassphrase?: string(name='SrtPassphrase', description='The SRT key. You can modify this parameter only when the source type is SRT-Listener or SRT-Caller.', example='FICUBPX4Q77DYHRF'),
  srtPbkeyLen?: int32(name='SrtPbkeyLen', description='The encryption key length. You can modify this parameter only when the source type is SRT-Listener or SRT-Caller.', example='32'),
}

model UpdateMediaConnectFlowInputResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='52451256-FFEA-5D2E-AA60-EE7053000F22'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model UpdateMediaConnectFlowInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaConnectFlowInputResponseBody(name='body'),
}

/**
 * @summary Modifies the source of a MediaConnect flow.
 *
 * @description *   You can modify the source only when the flow is in the offline state.
 * *   The source type cannot be modified.
 *
 * @param request UpdateMediaConnectFlowInputRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateMediaConnectFlowInputResponse
 */
async function updateMediaConnectFlowInputWithOptions(request: UpdateMediaConnectFlowInputRequest, runtime: $RuntimeOptions): UpdateMediaConnectFlowInputResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.cidrs)) {
    query['Cidrs'] = request.cidrs;
  }
  if (!$isNull(request.flowId)) {
    query['FlowId'] = request.flowId;
  }
  if (!$isNull(request.inputFromUrl)) {
    query['InputFromUrl'] = request.inputFromUrl;
  }
  if (!$isNull(request.maxBitrate)) {
    query['MaxBitrate'] = request.maxBitrate;
  }
  if (!$isNull(request.srtLatency)) {
    query['SrtLatency'] = request.srtLatency;
  }
  if (!$isNull(request.srtPassphrase)) {
    query['SrtPassphrase'] = request.srtPassphrase;
  }
  if (!$isNull(request.srtPbkeyLen)) {
    query['SrtPbkeyLen'] = request.srtPbkeyLen;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateMediaConnectFlowInput',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies the source of a MediaConnect flow.
 *
 * @description *   You can modify the source only when the flow is in the offline state.
 * *   The source type cannot be modified.
 *
 * @param request UpdateMediaConnectFlowInputRequest
 * @return UpdateMediaConnectFlowInputResponse
 */
async function updateMediaConnectFlowInput(request: UpdateMediaConnectFlowInputRequest): UpdateMediaConnectFlowInputResponse {
  var runtime = new $RuntimeOptions{};
  return updateMediaConnectFlowInputWithOptions(request, runtime);
}

model UpdateMediaConnectFlowOutputRequest {
  cidrs?: string(name='Cidrs', description='The IP address whitelist.', example='19.168.1.1/32,18.168.1.1/16'),
  flowId?: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f'),
  outputName?: string(name='OutputName', description='The output name.

This parameter is required.', example='AliTestOutput'),
  outputToUrl?: string(name='OutputToUrl', description='The output URL. You can modify this parameter only when the output type is RTMP-PUSH or SRT-Caller.', example='rtmp://push.test.alivecdn.com/live/alitest'),
  playerLimit?: string(name='PlayerLimit', description='The maximum number of viewers.', example='5'),
  srtLatency?: string(name='SrtLatency', description='The latency for the SRT stream. You can modify this parameter only when the source type is SRT-Listener or SRT-Caller.', example='1000'),
  srtPassphrase?: string(name='SrtPassphrase', description='The SRT key. You can modify this parameter only when the source type is SRT-Listener or SRT-Caller.', example='FICUBPX4Q77DYHRF'),
  srtPbkeyLen?: string(name='SrtPbkeyLen', description='The encryption key length. You can modify this parameter only when the source type is SRT-Listener or SRT-Caller.', example='32'),
}

model UpdateMediaConnectFlowOutputResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='OK'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D737D0BC-4CB5-55AA-8119-B540C95DFE6A'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates the call is successful.', example='0'),
}

model UpdateMediaConnectFlowOutputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaConnectFlowOutputResponseBody(name='body'),
}

/**
 * @summary Modifies an output of a MediaConnect flow.
 *
 * @description *   You can modify an output only when the flow is in the offline state.
 * *   The output type cannot be modified.
 *
 * @param request UpdateMediaConnectFlowOutputRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateMediaConnectFlowOutputResponse
 */
async function updateMediaConnectFlowOutputWithOptions(request: UpdateMediaConnectFlowOutputRequest, runtime: $RuntimeOptions): UpdateMediaConnectFlowOutputResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.cidrs)) {
    query['Cidrs'] = request.cidrs;
  }
  if (!$isNull(request.flowId)) {
    query['FlowId'] = request.flowId;
  }
  if (!$isNull(request.outputName)) {
    query['OutputName'] = request.outputName;
  }
  if (!$isNull(request.outputToUrl)) {
    query['OutputToUrl'] = request.outputToUrl;
  }
  if (!$isNull(request.playerLimit)) {
    query['PlayerLimit'] = request.playerLimit;
  }
  if (!$isNull(request.srtLatency)) {
    query['SrtLatency'] = request.srtLatency;
  }
  if (!$isNull(request.srtPassphrase)) {
    query['SrtPassphrase'] = request.srtPassphrase;
  }
  if (!$isNull(request.srtPbkeyLen)) {
    query['SrtPbkeyLen'] = request.srtPbkeyLen;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateMediaConnectFlowOutput',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies an output of a MediaConnect flow.
 *
 * @description *   You can modify an output only when the flow is in the offline state.
 * *   The output type cannot be modified.
 *
 * @param request UpdateMediaConnectFlowOutputRequest
 * @return UpdateMediaConnectFlowOutputResponse
 */
async function updateMediaConnectFlowOutput(request: UpdateMediaConnectFlowOutputRequest): UpdateMediaConnectFlowOutputResponse {
  var runtime = new $RuntimeOptions{};
  return updateMediaConnectFlowOutputWithOptions(request, runtime);
}

model UpdateMediaConnectFlowStatusRequest {
  flowId?: string(name='FlowId', description='The flow ID.

This parameter is required.', example='34900dc6-90ec-4968-af3c-fcd87f231a5f'),
  status?: string(name='Status', description='The flow state. Valid values:

*   online: starts the flow.
*   offline: stops the flow.

This parameter is required.', example='online'),
}

model UpdateMediaConnectFlowStatusResponseBody = {
  content?: string(name='Content', description='The response body.', example='""'),
  description?: string(name='Description', description='The call description.', example='ok'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='20B3A1B6-4BD2-5DE6-BCBC-098C9B4F4E91'),
  retCode?: int32(name='RetCode', description='The returned error code. A value of 0 indicates that the call is successful.', example='0'),
}

model UpdateMediaConnectFlowStatusResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaConnectFlowStatusResponseBody(name='body'),
}

/**
 * @summary Modifies the state of a MediaConnect flow.
 *
 * @param request UpdateMediaConnectFlowStatusRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateMediaConnectFlowStatusResponse
 */
async function updateMediaConnectFlowStatusWithOptions(request: UpdateMediaConnectFlowStatusRequest, runtime: $RuntimeOptions): UpdateMediaConnectFlowStatusResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.flowId)) {
    query['FlowId'] = request.flowId;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateMediaConnectFlowStatus',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies the state of a MediaConnect flow.
 *
 * @param request UpdateMediaConnectFlowStatusRequest
 * @return UpdateMediaConnectFlowStatusResponse
 */
async function updateMediaConnectFlowStatus(request: UpdateMediaConnectFlowStatusRequest): UpdateMediaConnectFlowStatusResponse {
  var runtime = new $RuntimeOptions{};
  return updateMediaConnectFlowStatusWithOptions(request, runtime);
}

model UpdateMediaInfoRequest {
  appendTags?: boolean(name='AppendTags', description='Specifies whether to append tags. Default value: false. Valid values:

*   true: updates the MediaTags parameter by appending new tags.
*   false: updates the MediaTags parameter by overwriting existing tags with new tags.', example='true'),
  businessType?: string(name='BusinessType', description='The business type. Valid values:

*   subtitles
*   watermark
*   opening
*   ending
*   general', example='video'),
  cateId?: long(name='CateId', description='The category ID.', example='3048'),
  category?: string(name='Category', description='The category.

*   The value can be up to 64 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultCategory'),
  coverURL?: string(name='CoverURL', description='The URL of the thumbnail.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.png'),
  description?: string(name='Description', description='The content description.

*   The value can be up to 1,024 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultDescription'),
  inputURL?: string(name='InputURL', description='The input URL of the media asset in another service. The URL must be bound to the ID of the media asset in IMS. The URL cannot be modified once registered.

For a media asset from Object Storage Service (OSS), the URL may have one of the following formats:

1\\\\. http(s)://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4

2\\\\. oss://example-bucket/example.mp4. This format indicates that the region in which the OSS bucket of the media asset resides is the same as the region in which OSS is activated.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/example.mp4'),
  mediaId?: string(name='MediaId', description='The ID of the media asset. If this parameter is left empty, you must specify the input URL of the media asset, which has been registered in the IMS content library.', example='****20b48fb04483915d4f2cd8ac****'),
  mediaTags?: string(name='MediaTags', description='The tags.

*   Up to 16 tags are supported.
*   Separate multiple tags with commas (,).
*   Each tag can be up to 32 bytes in length.
*   The value must be encoded in UTF-8.', example='updateTags1,updateTags2'),
  referenceId?: string(name='ReferenceId', description='The custom ID. The ID can be 6 to 64 characters in length and can contain only letters, digits, hyphens (-), and underscores (_). Make sure that the ID is unique among users.', example='123-123'),
  title?: string(name='Title', description='The title.

*   The value can be up to 128 bytes in length.
*   The value must be encoded in UTF-8.', example='defaultTitle'),
  userData?: string(name='UserData', description='The user data. It can be up to 1,024 bytes in size.', example='userData'),
}

model UpdateMediaInfoResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset in IMS.', example='****20b48fb04483915d4f2cd8ac****'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateMediaInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaInfoResponseBody(name='body'),
}

/**
 * @summary Updates information about a media asset based on the ID of the media asset in Intelligent Media Services (IMS) or the input URL of the media asset.
 *
 * @description If the MediaId parameter is specified, the MediaId parameter is preferentially used for the query. If the MediaId parameter is left empty, the InputURL parameter must be specified. The request ID and media asset ID are returned. You cannot modify the input URL of a media asset by specifying the ID of the media asset.
 *
 * @param request UpdateMediaInfoRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateMediaInfoResponse
 */
async function updateMediaInfoWithOptions(request: UpdateMediaInfoRequest, runtime: $RuntimeOptions): UpdateMediaInfoResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.appendTags)) {
    query['AppendTags'] = request.appendTags;
  }
  if (!$isNull(request.businessType)) {
    query['BusinessType'] = request.businessType;
  }
  if (!$isNull(request.cateId)) {
    query['CateId'] = request.cateId;
  }
  if (!$isNull(request.category)) {
    query['Category'] = request.category;
  }
  if (!$isNull(request.coverURL)) {
    query['CoverURL'] = request.coverURL;
  }
  if (!$isNull(request.description)) {
    query['Description'] = request.description;
  }
  if (!$isNull(request.inputURL)) {
    query['InputURL'] = request.inputURL;
  }
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.mediaTags)) {
    query['MediaTags'] = request.mediaTags;
  }
  if (!$isNull(request.referenceId)) {
    query['ReferenceId'] = request.referenceId;
  }
  if (!$isNull(request.title)) {
    query['Title'] = request.title;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateMediaInfo',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates information about a media asset based on the ID of the media asset in Intelligent Media Services (IMS) or the input URL of the media asset.
 *
 * @description If the MediaId parameter is specified, the MediaId parameter is preferentially used for the query. If the MediaId parameter is left empty, the InputURL parameter must be specified. The request ID and media asset ID are returned. You cannot modify the input URL of a media asset by specifying the ID of the media asset.
 *
 * @param request UpdateMediaInfoRequest
 * @return UpdateMediaInfoResponse
 */
async function updateMediaInfo(request: UpdateMediaInfoRequest): UpdateMediaInfoResponse {
  var runtime = new $RuntimeOptions{};
  return updateMediaInfoWithOptions(request, runtime);
}

model UpdateMediaLiveChannelRequest {
  audioSettings?: [ 
    {
      audioCodec?: string(name='AudioCodec', description='The audio codec. If it is not specified, the source specification is used. Valid values: aac and libfdk_aac.', example='libfdk_aac'),
      audioCodecSetting?: {
        bitrate?: int32(name='Bitrate', description='The audio bitrate. Unit: bit/s. Valid values: 8000 to 1000000. The value must be divisible by 1000.', example='200000'),
        profile?: string(name='Profile', description='The audio codec profile. When AudioCodec is set to aac, AAC-LOW and AAC-MAIN are supported. When AudioCodec is set to libfdk_aac, AAC-LOW, AAC-HE, and AAC-HEV2 are supported.', example='AAC-LOW'),
        sampleRate?: int32(name='SampleRate', description='The audio sample rate. Unit: Hz. Valid values: 22050, 32000, 44100, 48000, and 96000.', example='44100'),
      }(name='AudioCodecSetting', description='The audio encoding settings.'),
      audioSelectorName?: string(name='AudioSelectorName', description='The name of the audio selector.', example='a1'),
      languageCode?: string(name='LanguageCode', description='Enter a three-letter ISO 639-2 language code. If the audio track selected by the audio selector has a language code, the language code specified in the audio selector is used. If the selected audio track does not have a language code, or if the audio selector cannot find a track that matches its criteria, this language code is used.', example='eng'),
      languageName?: string(name='LanguageName', description='The tag that identifies the language of the RTMP input. It can be referenced by the output. The maximum length is 32 characters. Supported characters:

*   Unicode letters
*   Digits (0-9)
*   Underscore (_)
*   Hyphen (-)
*   Space (a space cannot be at the beginning or end)', example='English'),
      name?: string(name='Name', description='The name of the audio settings. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='audio1'),
    }
  ](name='AudioSettings', description='The audio settings.'),
  channelId?: string(name='ChannelId', description='The ID of the channel.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
  inputAttachments?: [ 
    {
      audioSelectors?: [ 
        {
          audioLanguageSelection?: {
            languageCode?: string(name='LanguageCode', description='Enter a three-letter ISO 639-2 language code from within an audio source.

This parameter is required.', example='eng'),
          }(name='AudioLanguageSelection', description='The audio language selection.'),
          audioPidSelection?: {
            pid?: long(name='Pid', description='Enter a specific PID from within a source.

This parameter is required.', example='123'),
          }(name='AudioPidSelection', description='The audio PID selection.'),
          audioTrackSelection?: [ 
            {
              trackId?: long(name='TrackId', description='Specify one or more audio tracks from within a source using Track ID.

This parameter is required.', example='1'),
            }
          ](name='AudioTrackSelection', description='The audio track selection.'),
          name?: string(name='Name', description='The name of the audio selector. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='myselector'),
        }
      ](name='AudioSelectors', description='The audio selectors.'),
      inputId?: string(name='InputId', description='The ID of the associated input.

This parameter is required.', example='myinput'),
      languageName?: string(name='LanguageName', description='The tag that identifies the language of the RTMP input. It can be referenced by the output. The maximum length is 32 characters. Supported characters:

*   Unicode letters
*   Digits (0-9)
*   Underscore (_)
*   Hyphen (-)
*   Space (a space cannot be at the beginning or end)', example='English'),
    }
  ](name='InputAttachments', description='The inputs associated with the channel.

This parameter is required.'),
  name?: string(name='Name', description='The name of the channel. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='mych'),
  outputGroups?: [ 
    {
      mediaPackageGroupSetting?: {
        channelName?: string(name='ChannelName', description='ChannelName in MediaPackage.

This parameter is required.', example='myPackageChannel'),
        groupName?: string(name='GroupName', description='GroupName in MediaPackage.

This parameter is required.', example='myPackageGroup'),
      }(name='MediaPackageGroupSetting', description='The MediaPackage destination.'),
      name?: string(name='Name', description='The name of the output group. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='group1'),
      outputs?: [ 
        {
          audioSettingNames?: [ string ](name='AudioSettingNames', description='The referenced AudioSettings.'),
          mediaPackageOutputSetting?: {
            audioGroupId?: string(name='AudioGroupId', description='The manifest audio group ID. To associate several audio tracks into one group, assign the same audio group ID. Viewers can select a track as needed. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 40 characters in length.', example='audiogroup'),
            nameModifier?: string(name='NameModifier', description='The manifest name modifier. The child manifests include this modifier in their M3U8 file names. Letters, digits, hyphens (-), and underscores (_) are supported. The maximum length is 40 characters.', example='480p'),
          }(name='MediaPackageOutputSetting', description='The settings of the output delivered to MediaPackage.'),
          mediaType?: int32(name='MediaType', description='The media type of the output. Valid values:

*   0: Audio and Video
*   1: Audio If you set the value to 1, you cannot reference VideoSettings.
*   2: Video. If you set the value to 2, you cannot reference AudioSettings.', example='0'),
          name?: string(name='Name', description='The name of the output. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='output1'),
          videoSettingName?: string(name='VideoSettingName', description='The name of the referenced VideoSettings.', example='myVideo1'),
        }
      ](name='Outputs', description='The outputs in the output group.

This parameter is required.'),
      type?: string(name='Type', description='The output group type. Only MediaPackage is supported.

This parameter is required.', example='MediaPackage'),
    }
  ](name='OutputGroups', description='The output groups.

This parameter is required.'),
  videoSettings?: [ 
    {
      height?: int32(name='Height', description='The height of the output. Valid values: 0 to 2000. If you set it to 0 or leave it empty, the height automatically adapts to the specified width to maintain the original aspect ratio.', example='720'),
      name?: string(name='Name', description='The name of the video settings. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='video1'),
      videoCodec?: string(name='VideoCodec', description='The video codec. Valid values: H264 and H265.', example='H264'),
      videoCodecSetting?: {
        codecDetail?: {
          level?: string(name='Level', description='The video encoding level. It is not supported yet.', example='H264_LEVEL_AUTO'),
          profile?: string(name='Profile', description='The H.264 profile. Valid values: BASELINE, HIGH, and MAIN. Default value: MAIN. The parameter takes effect only when the codec is H.264.', example='MAIN'),
        }(name='CodecDetail', description='The video encoding settings.'),
        framerate?: {
          framerateControl?: string(name='FramerateControl', description='The frame rate mode. Valid values: SPECIFIED (fixed frame rate) and FROM_SOURCE (use source specification).', example='SPECIFIED'),
          framerateDenominator?: int32(name='FramerateDenominator', description='The denominator of the fixed frame rate. The parameter is required when FramerateControl is set to SPECIFIED. Valid values: 1 to 60. The numerator must be divisible by the denominator.', example='1'),
          framerateNumerator?: int32(name='FramerateNumerator', description='The numerator of the fixed frame rate. The parameter is required when FramerateControl is set to SPECIFIED. Valid values: 1 to 60. The numerator must be divisible by the denominator.', example='25'),
        }(name='Framerate', description='The frame rate. If it is not specified, the source specification is used.'),
        gop?: {
          bframesNum?: int32(name='BframesNum', description='The number of B frames. Valid values: 1 to 3.', example='3'),
          gopSize?: int32(name='GopSize', description='The GOP size. When GopSizeUnits is set to SECONDS, the value range is from 1 to 20. When GopSizeUnits is set to FRAMES, the value range is from 1 to 3000.', example='90'),
          gopSizeUnits?: string(name='GopSizeUnits', description='The GOP size unit. Valid values: FRAMES and SECONDS.', example='FRAMES'),
        }(name='Gop', description='The GOP setting. If it is not specified, the source specification is used.'),
        rate?: {
          bitrate?: int32(name='Bitrate', description='The video bitrate. Unit: bit/s. If you set it to 0 or leave it empty, the source specification is used. Valid values: 50000 to 6000000. The value must be divisible by 1000.', example='2500000'),
          bufferSize?: int32(name='BufferSize', description='The video buffer size. Unit: bit/s. Valid values: 100000 to 6000000. The value must be divisible by 1000.', example='6000000'),
          maxBitrate?: int32(name='MaxBitrate', description='The maximum bitrate. Unit: bit/s. Valid values: 100000 to 6000000. The value must be divisible by 1000.', example='6000000'),
          rateControlMode?: string(name='RateControlMode', description='The bitrate control mode. Valid values: CBR, ABR, and VBR.', example='ABR'),
        }(name='Rate', description='The video encoding rate. If it is not specified, the source specification is used.'),
      }(name='VideoCodecSetting', description='The video encoding settings.'),
      width?: int32(name='Width', description='The width of the output. Valid values: 0 to 2000. If you set it to 0 or leave it empty, the width automatically adapts to the specified height to maintain the original aspect ratio.', example='1280'),
    }
  ](name='VideoSettings', description='The video settings.'),
}

model UpdateMediaLiveChannelShrinkRequest {
  audioSettingsShrink?: string(name='AudioSettings', description='The audio settings.'),
  channelId?: string(name='ChannelId', description='The ID of the channel.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
  inputAttachmentsShrink?: string(name='InputAttachments', description='The inputs associated with the channel.

This parameter is required.'),
  name?: string(name='Name', description='The name of the channel. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='mych'),
  outputGroupsShrink?: string(name='OutputGroups', description='The output groups.

This parameter is required.'),
  videoSettingsShrink?: string(name='VideoSettings', description='The video settings.'),
}

model UpdateMediaLiveChannelResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateMediaLiveChannelResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaLiveChannelResponseBody(name='body'),
}

/**
 * @summary Modifies a MediaLive channel.
 *
 * @description *   You can modify a MediaLive channel only when it is not running.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param tmpReq UpdateMediaLiveChannelRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateMediaLiveChannelResponse
 */
async function updateMediaLiveChannelWithOptions(tmpReq: UpdateMediaLiveChannelRequest, runtime: $RuntimeOptions): UpdateMediaLiveChannelResponse {
  tmpReq.validate();
  var request = new UpdateMediaLiveChannelShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.audioSettings)) {
    request.audioSettingsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.audioSettings, 'AudioSettings', 'json');
  }
  if (!$isNull(tmpReq.inputAttachments)) {
    request.inputAttachmentsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.inputAttachments, 'InputAttachments', 'json');
  }
  if (!$isNull(tmpReq.outputGroups)) {
    request.outputGroupsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.outputGroups, 'OutputGroups', 'json');
  }
  if (!$isNull(tmpReq.videoSettings)) {
    request.videoSettingsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.videoSettings, 'VideoSettings', 'json');
  }
  var body : map[string]any = {};
  if (!$isNull(request.audioSettingsShrink)) {
    body['AudioSettings'] = request.audioSettingsShrink;
  }
  if (!$isNull(request.channelId)) {
    body['ChannelId'] = request.channelId;
  }
  if (!$isNull(request.inputAttachmentsShrink)) {
    body['InputAttachments'] = request.inputAttachmentsShrink;
  }
  if (!$isNull(request.name)) {
    body['Name'] = request.name;
  }
  if (!$isNull(request.outputGroupsShrink)) {
    body['OutputGroups'] = request.outputGroupsShrink;
  }
  if (!$isNull(request.videoSettingsShrink)) {
    body['VideoSettings'] = request.videoSettingsShrink;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateMediaLiveChannel',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies a MediaLive channel.
 *
 * @description *   You can modify a MediaLive channel only when it is not running.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request UpdateMediaLiveChannelRequest
 * @return UpdateMediaLiveChannelResponse
 */
async function updateMediaLiveChannel(request: UpdateMediaLiveChannelRequest): UpdateMediaLiveChannelResponse {
  var runtime = new $RuntimeOptions{};
  return updateMediaLiveChannelWithOptions(request, runtime);
}

model UpdateMediaLiveInputRequest {
  inputId?: string(name='InputId', description='The ID of the input.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
  inputSettings?: [ 
    {
      flowId?: string(name='FlowId'),
      flowOutputName?: string(name='FlowOutputName'),
      sourceUrl?: string(name='SourceUrl', description='The source URL where the stream is pulled from. This parameter is required for PULL inputs.', example='rtmp://domain/app/stream'),
      streamName?: string(name='StreamName', description='The name of the pushed stream. This parameter is required for PUSH inputs. It can be up to 255 characters in length.', example='mystream'),
    }
  ](name='InputSettings', description='The input settings. An input can have up to two sources: primary and backup sources.

This parameter is required.'),
  name?: string(name='Name', description='The name of the input. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='myinput'),
  securityGroupIds?: [ string ](name='SecurityGroupIds', description='The IDs of the security groups to be associated with the input. This parameter is required for PUSH inputs.', example='["G6G4X5T4SZYPSTT5"]'),
}

model UpdateMediaLiveInputShrinkRequest {
  inputId?: string(name='InputId', description='The ID of the input.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
  inputSettingsShrink?: string(name='InputSettings', description='The input settings. An input can have up to two sources: primary and backup sources.

This parameter is required.'),
  name?: string(name='Name', description='The name of the input. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='myinput'),
  securityGroupIdsShrink?: string(name='SecurityGroupIds', description='The IDs of the security groups to be associated with the input. This parameter is required for PUSH inputs.', example='["G6G4X5T4SZYPSTT5"]'),
}

model UpdateMediaLiveInputResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******3B-0E1A-586A-AC29-742247******'),
}

model UpdateMediaLiveInputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaLiveInputResponseBody(name='body'),
}

/**
 * @summary Modifies an input of MediaLive.
 *
 * @description *   You can modify an input only when it is not associated with a MediaLive channel.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param tmpReq UpdateMediaLiveInputRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateMediaLiveInputResponse
 */
async function updateMediaLiveInputWithOptions(tmpReq: UpdateMediaLiveInputRequest, runtime: $RuntimeOptions): UpdateMediaLiveInputResponse {
  tmpReq.validate();
  var request = new UpdateMediaLiveInputShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.inputSettings)) {
    request.inputSettingsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.inputSettings, 'InputSettings', 'json');
  }
  if (!$isNull(tmpReq.securityGroupIds)) {
    request.securityGroupIdsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.securityGroupIds, 'SecurityGroupIds', 'json');
  }
  var query = {};
  if (!$isNull(request.inputSettingsShrink)) {
    query['InputSettings'] = request.inputSettingsShrink;
  }
  if (!$isNull(request.securityGroupIdsShrink)) {
    query['SecurityGroupIds'] = request.securityGroupIdsShrink;
  }
  var body : map[string]any = {};
  if (!$isNull(request.inputId)) {
    body['InputId'] = request.inputId;
  }
  if (!$isNull(request.name)) {
    body['Name'] = request.name;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateMediaLiveInput',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies an input of MediaLive.
 *
 * @description *   You can modify an input only when it is not associated with a MediaLive channel.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request UpdateMediaLiveInputRequest
 * @return UpdateMediaLiveInputResponse
 */
async function updateMediaLiveInput(request: UpdateMediaLiveInputRequest): UpdateMediaLiveInputResponse {
  var runtime = new $RuntimeOptions{};
  return updateMediaLiveInputWithOptions(request, runtime);
}

model UpdateMediaLiveInputSecurityGroupRequest {
  name?: string(name='Name', description='The name of the security group. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='mysg'),
  securityGroupId?: string(name='SecurityGroupId', description='The ID of the security group.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
  whitelistRules?: [ string ](name='WhitelistRules', description='The security group rules.

This parameter is required.'),
}

model UpdateMediaLiveInputSecurityGroupShrinkRequest {
  name?: string(name='Name', description='The name of the security group. Letters, digits, hyphens (-), and underscores (_) are supported. It can be up to 64 characters in length.

This parameter is required.', example='mysg'),
  securityGroupId?: string(name='SecurityGroupId', description='The ID of the security group.

This parameter is required.', example='SEGK5KA6KYKAWQQH'),
  whitelistRulesShrink?: string(name='WhitelistRules', description='The security group rules.

This parameter is required.'),
}

model UpdateMediaLiveInputSecurityGroupResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateMediaLiveInputSecurityGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaLiveInputSecurityGroupResponseBody(name='body'),
}

/**
 * @summary Modifies a security group created in MediaLive.
 *
 * @description *   You can modify a security group only when it is not associated with a MediaLive input.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param tmpReq UpdateMediaLiveInputSecurityGroupRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateMediaLiveInputSecurityGroupResponse
 */
async function updateMediaLiveInputSecurityGroupWithOptions(tmpReq: UpdateMediaLiveInputSecurityGroupRequest, runtime: $RuntimeOptions): UpdateMediaLiveInputSecurityGroupResponse {
  tmpReq.validate();
  var request = new UpdateMediaLiveInputSecurityGroupShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.whitelistRules)) {
    request.whitelistRulesShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.whitelistRules, 'WhitelistRules', 'json');
  }
  var body : map[string]any = {};
  if (!$isNull(request.name)) {
    body['Name'] = request.name;
  }
  if (!$isNull(request.securityGroupId)) {
    body['SecurityGroupId'] = request.securityGroupId;
  }
  if (!$isNull(request.whitelistRulesShrink)) {
    body['WhitelistRules'] = request.whitelistRulesShrink;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateMediaLiveInputSecurityGroup',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies a security group created in MediaLive.
 *
 * @description *   You can modify a security group only when it is not associated with a MediaLive input.
 * ## QPS limit
 * This operation can be called up to 50 times per second for each Alibaba Cloud account. Requests that exceed this limit are dropped and you may experience service interruptions. We recommend that you take note of this limit when you call this operation.
 *
 * @param request UpdateMediaLiveInputSecurityGroupRequest
 * @return UpdateMediaLiveInputSecurityGroupResponse
 */
async function updateMediaLiveInputSecurityGroup(request: UpdateMediaLiveInputSecurityGroupRequest): UpdateMediaLiveInputSecurityGroupResponse {
  var runtime = new $RuntimeOptions{};
  return updateMediaLiveInputSecurityGroupWithOptions(request, runtime);
}

model UpdateMediaMarksRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='53afdf003a******6a16b5feac6402'),
  mediaMarks?: string(name='MediaMarks', description='The marks of the media asset.

This parameter is required.'),
}

model UpdateMediaMarksResponseBody = {
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='53afdf003a******6a16b5feac6402'),
  mediaMarkIds?: string(name='MediaMarkIds', description='The IDs of the successfully modified marks.', example='mark-f82d*****4994b0915948ef7e16,mark-3d56d*****4c8fa9ae2a1f9e5d2d60'),
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateMediaMarksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaMarksResponseBody(name='body'),
}

/**
 * @summary Modifies the marks of a media asset.
 *
 * @param request UpdateMediaMarksRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateMediaMarksResponse
 */
async function updateMediaMarksWithOptions(request: UpdateMediaMarksRequest, runtime: $RuntimeOptions): UpdateMediaMarksResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.mediaMarks)) {
    query['MediaMarks'] = request.mediaMarks;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateMediaMarks',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies the marks of a media asset.
 *
 * @param request UpdateMediaMarksRequest
 * @return UpdateMediaMarksResponse
 */
async function updateMediaMarks(request: UpdateMediaMarksRequest): UpdateMediaMarksResponse {
  var runtime = new $RuntimeOptions{};
  return updateMediaMarksWithOptions(request, runtime);
}

model UpdateMediaToSearchLibRequest {
  mediaId?: string(name='MediaId', description='The ID of the media asset.

This parameter is required.', example='****019b82e24b37a1c2958dec38****'),
  msgBody?: string(name='MsgBody', description='The message body.

This parameter is required.', example='{}'),
  searchLibName?: string(name='SearchLibName', description='The name of the search library. Default value: ims-default-search-lib.', example='test1'),
}

model UpdateMediaToSearchLibResponseBody = {
  code?: string(name='Code', description='The status code returned.', example='200'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='******b48fb04483915d4f2cd8******'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='4E84BE44-58A7-****-****-FBEBEA16EF94'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateMediaToSearchLibResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMediaToSearchLibResponseBody(name='body'),
}

/**
 * @summary Updates the media asset information in a search library.
 *
 * @param request UpdateMediaToSearchLibRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateMediaToSearchLibResponse
 */
async function updateMediaToSearchLibWithOptions(request: UpdateMediaToSearchLibRequest, runtime: $RuntimeOptions): UpdateMediaToSearchLibResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.msgBody)) {
    query['MsgBody'] = request.msgBody;
  }
  if (!$isNull(request.searchLibName)) {
    query['SearchLibName'] = request.searchLibName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateMediaToSearchLib',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates the media asset information in a search library.
 *
 * @param request UpdateMediaToSearchLibRequest
 * @return UpdateMediaToSearchLibResponse
 */
async function updateMediaToSearchLib(request: UpdateMediaToSearchLibRequest): UpdateMediaToSearchLibResponse {
  var runtime = new $RuntimeOptions{};
  return updateMediaToSearchLibWithOptions(request, runtime);
}

model UpdatePipelineRequest {
  name?: string(name='Name', description='The name of the MPS queue.', example='test-pipeline'),
  pipelineId?: string(name='PipelineId', description='The ID of the MPS queue.

This parameter is required.', example='****d80e4e4044975745c14b****'),
  priority?: int32(name='Priority', description='The priority of the MPS queue. Valid values: 1 to 10.', example='6'),
  status?: string(name='Status', description='The state of the MPS queue.

Valid values:

*   Active
*   Paused', example='Paused'),
}

model UpdatePipelineResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdatePipelineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdatePipelineResponseBody(name='body'),
}

/**
 * @summary Updates the information about an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request UpdatePipelineRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdatePipelineResponse
 */
async function updatePipelineWithOptions(request: UpdatePipelineRequest, runtime: $RuntimeOptions): UpdatePipelineResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.pipelineId)) {
    query['PipelineId'] = request.pipelineId;
  }
  if (!$isNull(request.priority)) {
    query['Priority'] = request.priority;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdatePipeline',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Updates the information about an ApsaraVideo Media Processing (MPS) queue.
 *
 * @param request UpdatePipelineRequest
 * @return UpdatePipelineResponse
 */
async function updatePipeline(request: UpdatePipelineRequest): UpdatePipelineResponse {
  var runtime = new $RuntimeOptions{};
  return updatePipelineWithOptions(request, runtime);
}

model UpdateProgramRequest {
  adBreaks?: string(name='AdBreaks', description='The information about ad breaks.', example='[{"MessageType":"SPLICE_INSERT","OffsetMillis":1000,"SourceLocationName":"MySourceLocation","SourceName":"MyAdSource","SpliceInsertSettings":{"AvailNumber":0,"AvailExpected":0,"SpliceEventID":1,"UniqueProgramID":0}}]'),
  channelName?: string(name='ChannelName', description='The name of the channel.

This parameter is required.', example='MyChannel'),
  clipRange?: string(name='ClipRange', description='Extracts a clip from the source.', example='{StartOffsetMillis: 213123, EndOffsetMillis: 213134}'),
  programName?: string(name='ProgramName', description='The name of the program.

This parameter is required.', example='program1'),
  sourceLocationName?: string(name='SourceLocationName', description='The name of the source location.', example='MySourceLcation'),
  sourceName?: string(name='SourceName', description='The name of the source.', example='MySource'),
  sourceType?: string(name='SourceType', description='The source type of the program. Valid values: vodSource and liveSource.', example='vodSource'),
  transition?: string(name='Transition', description='The program transition method.', example='{"Type": "RELATIVE", "RelativePosition": "AFTER_PROGRAM", "RelativeProgram": "program2"}'),
}

model UpdateProgramResponseBody = {
  program?: ChannelAssemblyProgram(name='Program', description='The information about the program.'),
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
}

model UpdateProgramResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateProgramResponseBody(name='body'),
}

/**
 * @summary Modifies a program in a MediaWeaver channel.
 *
 * @param request UpdateProgramRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateProgramResponse
 */
async function updateProgramWithOptions(request: UpdateProgramRequest, runtime: $RuntimeOptions): UpdateProgramResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.adBreaks)) {
    query['AdBreaks'] = request.adBreaks;
  }
  if (!$isNull(request.channelName)) {
    query['ChannelName'] = request.channelName;
  }
  if (!$isNull(request.clipRange)) {
    query['ClipRange'] = request.clipRange;
  }
  if (!$isNull(request.programName)) {
    query['ProgramName'] = request.programName;
  }
  if (!$isNull(request.sourceLocationName)) {
    query['SourceLocationName'] = request.sourceLocationName;
  }
  if (!$isNull(request.sourceName)) {
    query['SourceName'] = request.sourceName;
  }
  if (!$isNull(request.sourceType)) {
    query['SourceType'] = request.sourceType;
  }
  if (!$isNull(request.transition)) {
    query['Transition'] = request.transition;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateProgram',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies a program in a MediaWeaver channel.
 *
 * @param request UpdateProgramRequest
 * @return UpdateProgramResponse
 */
async function updateProgram(request: UpdateProgramRequest): UpdateProgramResponse {
  var runtime = new $RuntimeOptions{};
  return updateProgramWithOptions(request, runtime);
}

model UpdateRtcRobotInstanceRequest {
  config?: {
    enableVoiceInterrupt?: boolean(name='EnableVoiceInterrupt', example='false'),
    greeting?: string(name='Greeting'),
    voiceId?: string(name='VoiceId', example='zhixiaoxia'),
  }(name='Config'),
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='727dc0e296014bb58670940a3da95592'),
}

model UpdateRtcRobotInstanceShrinkRequest {
  configShrink?: string(name='Config'),
  instanceId?: string(name='InstanceId', description='This parameter is required.', example='727dc0e296014bb58670940a3da95592'),
}

model UpdateRtcRobotInstanceResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='7707F0A2-C6FD-5959-87EB-7C4D02384FD4'),
}

model UpdateRtcRobotInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateRtcRobotInstanceResponseBody(name='body'),
}

/**
 * @summary 修改实例的配置
 *
 * @param tmpReq UpdateRtcRobotInstanceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateRtcRobotInstanceResponse
 */
async function updateRtcRobotInstanceWithOptions(tmpReq: UpdateRtcRobotInstanceRequest, runtime: $RuntimeOptions): UpdateRtcRobotInstanceResponse {
  tmpReq.validate();
  var request = new UpdateRtcRobotInstanceShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!$isNull(tmpReq.config)) {
    request.configShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.config, 'Config', 'json');
  }
  var query = {};
  if (!$isNull(request.configShrink)) {
    query['Config'] = request.configShrink;
  }
  if (!$isNull(request.instanceId)) {
    query['InstanceId'] = request.instanceId;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateRtcRobotInstance',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary 修改实例的配置
 *
 * @param request UpdateRtcRobotInstanceRequest
 * @return UpdateRtcRobotInstanceResponse
 */
async function updateRtcRobotInstance(request: UpdateRtcRobotInstanceRequest): UpdateRtcRobotInstanceResponse {
  var runtime = new $RuntimeOptions{};
  return updateRtcRobotInstanceWithOptions(request, runtime);
}

model UpdateSourceRequest {
  httpPackageConfigurations?: string(name='HttpPackageConfigurations', description='The source configurations.

This parameter is required.', example='[{
	"sourceGroupName": "mySourceGroup-1",
	"relativePath": "group1/hls.m3u8",
	"packageType": "hls"
}]'),
  sourceLocationName?: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourcelocation'),
  sourceName?: string(name='SourceName', description='The name of the source.

This parameter is required.', example='MySource'),
  sourceType?: string(name='SourceType', description='The source type. Valid values: vodSource and liveSource.

This parameter is required.', example='vodSource'),
}

model UpdateSourceResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  source?: ChannelAssemblySource(name='Source', description='The source information.'),
}

model UpdateSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateSourceResponseBody(name='body'),
}

/**
 * @summary Modifies a source in MediaWeaver.
 *
 * @param request UpdateSourceRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateSourceResponse
 */
async function updateSourceWithOptions(request: UpdateSourceRequest, runtime: $RuntimeOptions): UpdateSourceResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.httpPackageConfigurations)) {
    query['HttpPackageConfigurations'] = request.httpPackageConfigurations;
  }
  if (!$isNull(request.sourceLocationName)) {
    query['SourceLocationName'] = request.sourceLocationName;
  }
  if (!$isNull(request.sourceName)) {
    query['SourceName'] = request.sourceName;
  }
  if (!$isNull(request.sourceType)) {
    query['SourceType'] = request.sourceType;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateSource',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies a source in MediaWeaver.
 *
 * @param request UpdateSourceRequest
 * @return UpdateSourceResponse
 */
async function updateSource(request: UpdateSourceRequest): UpdateSourceResponse {
  var runtime = new $RuntimeOptions{};
  return updateSourceWithOptions(request, runtime);
}

model UpdateSourceLocationRequest {
  baseUrl?: string(name='BaseUrl', description='The protocol and hostname of the source location.', example='http://xxx.com'),
  enableSegmentDelivery?: boolean(name='EnableSegmentDelivery', description='Specifies whether to use an independent domain name to access the segments.', example='true'),
  segmentDeliveryUrl?: string(name='SegmentDeliveryUrl', description='The domain name used to access the segments.', example='http://xxxx.com'),
  sourceLocationName?: string(name='SourceLocationName', description='The name of the source location.

This parameter is required.', example='MySourceLocation'),
}

model UpdateSourceLocationResponseBody = {
  requestId?: string(name='RequestId', description='**Request ID**', example='xxx-xxxx-xxxxx-xxxx'),
  sourceLocation?: ChannelAssemblySourceLocation(name='SourceLocation', description='The source location information.'),
}

model UpdateSourceLocationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateSourceLocationResponseBody(name='body'),
}

/**
 * @summary Modifies a source location.
 *
 * @param request UpdateSourceLocationRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateSourceLocationResponse
 */
async function updateSourceLocationWithOptions(request: UpdateSourceLocationRequest, runtime: $RuntimeOptions): UpdateSourceLocationResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.baseUrl)) {
    query['BaseUrl'] = request.baseUrl;
  }
  if (!$isNull(request.enableSegmentDelivery)) {
    query['EnableSegmentDelivery'] = request.enableSegmentDelivery;
  }
  if (!$isNull(request.segmentDeliveryUrl)) {
    query['SegmentDeliveryUrl'] = request.segmentDeliveryUrl;
  }
  if (!$isNull(request.sourceLocationName)) {
    query['SourceLocationName'] = request.sourceLocationName;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateSourceLocation',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies a source location.
 *
 * @param request UpdateSourceLocationRequest
 * @return UpdateSourceLocationResponse
 */
async function updateSourceLocation(request: UpdateSourceLocationRequest): UpdateSourceLocationResponse {
  var runtime = new $RuntimeOptions{};
  return updateSourceLocationWithOptions(request, runtime);
}

model UpdateTemplateRequest {
  config?: string(name='Config', example='参见模板Config文档'),
  coverUrl?: string(name='CoverUrl', description='The URL of the template thumbnail.', example='http://example-bucket.oss-cn-shanghai.aliyuncs.com/cover.jpg'),
  name?: string(name='Name', description='The name of the online editing template.', example='视频添加水印模板'),
  previewMedia?: string(name='PreviewMedia', description='The ID of the preview video.', example='****20b48fb04483915d4f2cd8ac****'),
  relatedMediaids?: string(name='RelatedMediaids', description='The IDs of the materials associated with the template for use by the regular template editor.', example='{"video":["******c04f1d4a06996144cc1a******","******cb7db64841b159b4f2ea******"],"audio":["******c04f1d4a06996144cc1a******"],"image":["******c04f1d4a06996144cc1a******"]}'),
  source?: string(name='Source', description='The source from which the template is modified. Default value: OpenAPI. Valid values:

*   AliyunConsole
*   OpenAPI
*   WebSDK', example='OpenAPI'),
  status?: string(name='Status', description='The template state. Valid values:

*   Available: The template is available.
*   Created: The template is created but not ready for use.
*   Uploading: The video is being uploaded.
*   Processing: The advanced template is being processed.
*   UploadFailed: Failed to upload the video.
*   ProcessFailed: Failed to process the advanced template.

>  After an advanced template is created, it enters the Processing state. In this case, the template is unavailable. The template can be used only when it is in the Available state. The time required for template processing varies based on the size of the template file. Generally, it ranges from 10 seconds to 5 minutes.', example='Available'),
  templateId?: string(name='TemplateId', description='The ID of the online editing template. You can obtain the template ID in the [Intelligent Media Services (IMS) console](https://ice.console.aliyun.com/production/template/list/common) or the response parameters of the [AddTemplate](https://help.aliyun.com/document_detail/441161.html) operation.', example='****20b48fb04483915d4f2cd8ac****'),
}

model UpdateTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='******11-DB8D-4A9A-875B-275798******'),
}

model UpdateTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateTemplateResponseBody(name='body'),
}

/**
 * @summary Modifies an online editing template. You can modify the template title and template configurations.
 *
 * @description *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request UpdateTemplateRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateTemplateResponse
 */
async function updateTemplateWithOptions(request: UpdateTemplateRequest, runtime: $RuntimeOptions): UpdateTemplateResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.coverUrl)) {
    query['CoverUrl'] = request.coverUrl;
  }
  if (!$isNull(request.name)) {
    query['Name'] = request.name;
  }
  if (!$isNull(request.previewMedia)) {
    query['PreviewMedia'] = request.previewMedia;
  }
  if (!$isNull(request.relatedMediaids)) {
    query['RelatedMediaids'] = request.relatedMediaids;
  }
  if (!$isNull(request.source)) {
    query['Source'] = request.source;
  }
  if (!$isNull(request.status)) {
    query['Status'] = request.status;
  }
  if (!$isNull(request.templateId)) {
    query['TemplateId'] = request.templateId;
  }
  var body : map[string]any = {};
  if (!$isNull(request.config)) {
    body['Config'] = request.config;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApiUtil.Params{
    action = 'UpdateTemplate',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Modifies an online editing template. You can modify the template title and template configurations.
 *
 * @description *   For more information about how to use a regular template, see [Create and use a regular template](https://help.aliyun.com/document_detail/445399.html).
 * *   For more information about how to use an advanced template, see [Create and use advanced templates](https://help.aliyun.com/document_detail/445389.html).
 *
 * @param request UpdateTemplateRequest
 * @return UpdateTemplateResponse
 */
async function updateTemplate(request: UpdateTemplateRequest): UpdateTemplateResponse {
  var runtime = new $RuntimeOptions{};
  return updateTemplateWithOptions(request, runtime);
}

model UploadMediaByURLRequest {
  appId?: string(name='AppId', description='The application ID.', example='app-1000000'),
  entityId?: string(name='EntityId', description='The entity ID. You can call the CreateEntity operation to create an entity and specify a dynamic metadata structure.', example='d67281da3c8743b8823ad12976187***'),
  mediaMetaData?: string(name='MediaMetaData', description='The metadata of the media file that you want to upload. The value must be a JSON string.

*   This parameter takes effect only if its value matches a URL that is specified in UploadURLs.
*   You must convert the JSON-formatted data, such as [UploadMetadata, UploadMetadata,…], into a JSON string.
*   For more information, see the "UploadMetadata" section of this topic.', example='[{"SourceURL":"https://example.aliyundoc.com/video01.mp4","Title":"urlUploadTest"}]'),
  postProcessConfig?: string(name='PostProcessConfig', description='The postprocessing configurations. You can specify this parameter if Type is set to video or audio.

Set ProcessType to Workflow.', example='{"ProcessType": "Workflow","ProcessID":"b72a06c6beeb4dcdb898feef067b1***"}'),
  uploadTargetConfig?: string(name='UploadTargetConfig', description='The destination storage address.

Set StorageType to oss.

Set StorageLocation to an address in ApsaraVideo VOD. You cannot set this field to an OSS URL.', example='{"StorageType":"oss","StorageLocation":"outin-***.oss-cn-shanghai.aliyuncs.com"}'),
  uploadURLs?: string(name='UploadURLs', description='The URL of the source file.

*   The URL must contain a file name extension, such as mp4 in `https://****.mp4`.

    *   If the URL does not contain a file name extension, you can specify one by setting `FileExtension` in `UploadMetadata`.
    *   If the URL contains a file name extension and `FileExtension` is also specified, the value of `FileExtension` prevails.

*   URL encoding is required. Separate multiple URLs with commas (,). You can specify a maximum of 20 URLs.

*   Special characters may cause upload failures. Therefore, you must encode URLs before you separate them with commas (,).', example='https://diffurl.mp4'),
  userData?: string(name='UserData', description='The user data. The value must be a JSON string. You can configure settings such as message callbacks.', example='{"MessageCallback":{"CallbackURL":"http://example.aliyundoc.com"},"Extend":{"localId":"xxx","test":"www"}}'),
}

model UploadMediaByURLResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='****83B7-7F87-4792-BFE9-63CD2137****'),
  uploadJobs?: [ 
    {
      jobId?: string(name='JobId', description='The ID of the upload job.', example='20ce1e05dba64576b96e9683879f0***'),
      mediaId?: string(name='MediaId', description='The ID of the media asset.', example='f476988629f54a7b8a4ba90d1a6c7***'),
      sourceURL?: string(name='SourceURL', description='The URL of the source file that is uploaded in the upload job.', example='http://example****.mp4'),
    }
  ](name='UploadJobs', description='The information about upload jobs.'),
}

model UploadMediaByURLResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UploadMediaByURLResponseBody(name='body'),
}

/**
 * @summary Uploads an audio or video file based on the URL of the source file. You can upload multiple media files at a time.
 *
 * @description *   If a callback is configured, you will receive an UploadByURLComplete event notification after the file is uploaded. You can query the upload status by calling the GetURLUploadInfos operation.
 * *   After a request is submitted, the upload job is queued as an asynchronous job in the cloud. You can query the status of the upload job based on information such as the URL and media asset ID that are returned in the event notification.
 * *   You can call this operation to upload media files that are not stored on a local server or device and must be uploaded by using URLs that are accessible over the Internet.
 * *   You can call this operation to upload media files only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media file to an OSS bucket, pull the file to a local directory, use [OSS SDK](https://help.aliyun.com/document_detail/32006.html) to upload the file to an OSS bucket, and then call the [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html) operation to register the file in the OSS bucket with the media asset library.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 * *   You can call this operation to upload only audio and video files.
 *
 * @param request UploadMediaByURLRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UploadMediaByURLResponse
 */
async function uploadMediaByURLWithOptions(request: UploadMediaByURLRequest, runtime: $RuntimeOptions): UploadMediaByURLResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.appId)) {
    query['AppId'] = request.appId;
  }
  if (!$isNull(request.entityId)) {
    query['EntityId'] = request.entityId;
  }
  if (!$isNull(request.mediaMetaData)) {
    query['MediaMetaData'] = request.mediaMetaData;
  }
  if (!$isNull(request.postProcessConfig)) {
    query['PostProcessConfig'] = request.postProcessConfig;
  }
  if (!$isNull(request.uploadTargetConfig)) {
    query['UploadTargetConfig'] = request.uploadTargetConfig;
  }
  if (!$isNull(request.uploadURLs)) {
    query['UploadURLs'] = request.uploadURLs;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UploadMediaByURL',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Uploads an audio or video file based on the URL of the source file. You can upload multiple media files at a time.
 *
 * @description *   If a callback is configured, you will receive an UploadByURLComplete event notification after the file is uploaded. You can query the upload status by calling the GetURLUploadInfos operation.
 * *   After a request is submitted, the upload job is queued as an asynchronous job in the cloud. You can query the status of the upload job based on information such as the URL and media asset ID that are returned in the event notification.
 * *   You can call this operation to upload media files that are not stored on a local server or device and must be uploaded by using URLs that are accessible over the Internet.
 * *   You can call this operation to upload media files only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media file to an OSS bucket, pull the file to a local directory, use [OSS SDK](https://help.aliyun.com/document_detail/32006.html) to upload the file to an OSS bucket, and then call the [RegisterMediaInfo](https://help.aliyun.com/document_detail/441152.html) operation to register the file in the OSS bucket with the media asset library.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 * *   You can call this operation to upload only audio and video files.
 *
 * @param request UploadMediaByURLRequest
 * @return UploadMediaByURLResponse
 */
async function uploadMediaByURL(request: UploadMediaByURLRequest): UploadMediaByURLResponse {
  var runtime = new $RuntimeOptions{};
  return uploadMediaByURLWithOptions(request, runtime);
}

model UploadStreamByURLRequest {
  definition?: string(name='Definition', description='The quality of the media stream. Valid values:

*   FD: low definition.
*   LD: standard definition.
*   SD: high definition.
*   HD: ultra-high definition.
*   OD: original quality.
*   2K: 2K resolution.
*   4K: 4K resolution.
*   SQ: standard sound quality.
*   HQ: high sound quality.', example='HD'),
  fileExtension?: string(name='FileExtension', description='The file name extension of the media stream.', example='mp4'),
  HDRType?: string(name='HDRType', description='The high dynamic range (HDR) format of the transcoded stream. Valid values:

*   HDR
*   HDR10
*   HLG
*   DolbyVision
*   HDRVivid
*   SDR+

> 

*   The value is not case-sensitive,

*   You can leave this parameter empty for non-HDR streams.', example='HDR10'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***'),
  streamURL?: string(name='StreamURL', description='The URL of the transcoded stream file.

If the URL of the transcoded stream requires authentication, you must specify the authentication parameters in the stream URL and make sure that the URL can be accessed over the Internet.', example='https://example.com/sample-stream.mp4'),
  userData?: string(name='UserData', description='The user data.', example='{"MessageCallback":{"CallbackURL":"http://test.test.com"}, "Extend":{"localId":"xxx","test":"www"}}'),
}

model UploadStreamByURLResponseBody = {
  fileURL?: string(name='FileURL', description='The OSS URL of the file.', example='http://outin-***.oss-cn-shanghai.aliyuncs.com/stream/48555e8b-181dd5a8c07/48555e8b-181dd5a8c07.mp4'),
  jobId?: string(name='JobId', description='The ID of the upload job.', example='****cdb3e74639973036bc84****'),
  mediaId?: string(name='MediaId', description='The ID of the media asset.', example='411bed50018971edb60b0764a0ec6***'),
  requestId?: string(name='RequestId', description='The request ID.', example='******89-C21D-4B78-AE24-3788B8******'),
  sourceURL?: string(name='SourceURL', description='The URL of the source file that is uploaded in the upload job.', example='https://example.com/sample-stream.mp4'),
}

model UploadStreamByURLResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UploadStreamByURLResponseBody(name='body'),
}

/**
 * @summary Uploads a media stream file based on the URL of the source file.
 *
 * @description *   You can call this operation to pull a media stream file based on a URL and upload the file. After the media stream file is uploaded, the media stream is associated with the specified media asset ID.
 * *   You can call this operation to upload media stream files only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media stream file to an OSS bucket, pull the file to a local directory, use [OSS SDK](https://help.aliyun.com/document_detail/32006.html) to upload the file to an OSS bucket, and then call the [RegisterMediaStream](https://help.aliyun.com/document_detail/440765.html) operation to associate the media stream with the specified media asset ID.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 *
 * @param request UploadStreamByURLRequest
 * @param runtime runtime options for this request RuntimeOptions
 * @return UploadStreamByURLResponse
 */
async function uploadStreamByURLWithOptions(request: UploadStreamByURLRequest, runtime: $RuntimeOptions): UploadStreamByURLResponse {
  request.validate();
  var query = {};
  if (!$isNull(request.definition)) {
    query['Definition'] = request.definition;
  }
  if (!$isNull(request.fileExtension)) {
    query['FileExtension'] = request.fileExtension;
  }
  if (!$isNull(request.HDRType)) {
    query['HDRType'] = request.HDRType;
  }
  if (!$isNull(request.mediaId)) {
    query['MediaId'] = request.mediaId;
  }
  if (!$isNull(request.streamURL)) {
    query['StreamURL'] = request.streamURL;
  }
  if (!$isNull(request.userData)) {
    query['UserData'] = request.userData;
  }
  var req = new OpenApiUtil.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApiUtil.Params{
    action = 'UploadStreamByURL',
    version = '2020-11-09',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  if ($isNull(@signatureVersion) || @signatureVersion != 'v4') {
    return callApi(params, req, runtime);
  } else {
    return execute(params, req, runtime);
  }
}

/**
 * @summary Uploads a media stream file based on the URL of the source file.
 *
 * @description *   You can call this operation to pull a media stream file based on a URL and upload the file. After the media stream file is uploaded, the media stream is associated with the specified media asset ID.
 * *   You can call this operation to upload media stream files only to ApsaraVideo VOD, but not to your own Object Storage Service (OSS) buckets. To upload a media stream file to an OSS bucket, pull the file to a local directory, use [OSS SDK](https://help.aliyun.com/document_detail/32006.html) to upload the file to an OSS bucket, and then call the [RegisterMediaStream](https://help.aliyun.com/document_detail/440765.html) operation to associate the media stream with the specified media asset ID.
 * *   This operation is available only in the China (Shanghai), China (Beijing), and China (Shenzhen) regions.
 *
 * @param request UploadStreamByURLRequest
 * @return UploadStreamByURLResponse
 */
async function uploadStreamByURL(request: UploadStreamByURLRequest): UploadStreamByURLResponse {
  var runtime = new $RuntimeOptions{};
  return uploadStreamByURLWithOptions(request, runtime);
}

