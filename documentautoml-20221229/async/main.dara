/**
 *
 */
import BaseClientBuilder;
import TeaAsyncHandler;
import TeaRequest;
import AsyncRequestBody;
import RequestBody;
import AsyncResponseHandler;
import ClientConfiguration;
import ClientExecutionParams;
extends BaseClientBuilder;
type @product = string
type @version = string
type @endpointRule = string
type @endpointMap = map[string]string
type @REQUEST = TeaRequest
type @handler = TeaAsyncHandler

init(configuration: ClientConfiguration){
  @handler = new TeaAsyncHandler(configuration);
  @product = 'documentAutoml';
  @version = '2022-12-29';
  @endpointRule = '';
  @endpointMap = {
  };
}

function close(): void {
  @handler.close();
}

model CreateModelAsyncPredictRequest {
  binaryToText?: boolean(name='BinaryToText', position='Query'),
  content?: string(name='Content', example='https://doc-automl-public.oss-cn-hangzhou.aliyuncs.com/3/1559855998794593/stage/upload/20230206/oss-hlfCRJ1SorSWs10MkqxK6YcL4OVAFSv4.png?Expires=1675665563&OSSAccessKeyId=XXXX&Signature=WLKghBc3zKzWJ3Td69%2B4C21jrbE%3D', position='Query'),
  modelId?: long(name='ModelId', example='123', minimum=1, maximum=9999999999999, position='Query'),
  modelVersion?: string(name='ModelVersion', example='V1', position='Query'),
  serviceName?: string(name='ServiceName', example='pre_train_service', position='Query'),
  serviceVersion?: string(name='ServiceVersion', example='V1', position='Query'),
  body?: string(name='body', position='Body'),
}

model CreateModelAsyncPredictResponseBody = {
  code?: int32(name='Code', example='200'),
  data?: string(name='Data', example='{
  "RequestId": "292D1584-134C-1221-B9BB-1B847C623D41",
  "Message": "",
  "Data": 1,
  "Code": 200
}'),
  message?: string(name='Message', example='success'),
  requestId?: string(name='RequestId', description='Id of the request', example='3EAC98E6-8DD6-511F-8764-DEE8B6EB6BB4'),
}

model CreateModelAsyncPredictResponse = {
  headers: map[string]string(name='headers'),
  body: CreateModelAsyncPredictResponseBody(name='body'),
}

async function createModelAsyncPredict(request: CreateModelAsyncPredictRequest): CreateModelAsyncPredictResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateModelAsyncPredict', 'POST', '/', 'json', false, 'json', request);
}

model GetModelAsyncPredictRequest {
  asyncPredictId: long(name='AsyncPredictId', example='1', minimum=1, maximum=99999999999999, position='Query'),
}

model GetModelAsyncPredictResponseBody = {
  code?: int32(name='Code', example='200'),
  data?: string(name='Data', example='{
  "RequestId": "A9796F06-F1C4-1E89-8AFD-596583FF4B16",
  "Message": "",
  "Data": {
    "result": "https://doc-automl-public.oss-cn-hangzhou.aliyuncs.com/3/stage/data/XXXX/asyncPredict/713908/oss-933bbdf4-fa10-4c56-b6ab-9c85f32bbd0e.json?Expires=1991115127&OSSAccessKeyId=XXXX&Signature=5zYLY9yR%2B9Ok1WuRgHYdqtXHK10%3D",
    "asyncPredictId": 713908,
    "errorCode": 200,
    "errorMsg": "",
    "status": 2
  },
  "Code": 200
}'),
  message?: string(name='Message', example='success'),
  requestId?: string(name='RequestId', description='Id of the request', example='3EAC98E6-8DD6-511F-8764-DEE8B6EB6BB4'),
}

model GetModelAsyncPredictResponse = {
  headers: map[string]string(name='headers'),
  body: GetModelAsyncPredictResponseBody(name='body'),
}

async function getModelAsyncPredict(request: GetModelAsyncPredictRequest): GetModelAsyncPredictResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetModelAsyncPredict', 'POST', '/', 'json', false, 'json', request);
}

model PredictClassifierModelRequest {
  autoPrediction?: boolean(name='AutoPrediction', example='true', position='Query'),
  classifierId?: long(name='ClassifierId', example='c0d420955af6bc0761f9207480333cca', minimum=1, maximum=99999999999999, position='Query'),
  content?: string(name='Content', example='https://doc-automl-public.oss-cn-hangzhou.aliyuncs.com/3/xxx/stage/upload/20230207/oss-fCeg7ri12SCN5eECeuQdKEDVG9P06tJc.png?Expires=1675744411&OSSAccessKeyId=xxx&Signature=Kchn7sHa1W8mI8JC1D3uPBW2vds%3D', position='Query'),
  body?: string(name='body', position='Body'),
}

model PredictClassifierModelResponseBody = {
  code?: int32(name='Code', example='200'),
  data?: map[string]any(name='Data'),
  message?: string(name='Message', example='success'),
  requestId?: string(name='RequestId', description='Id of the request', example='232B91A8-9938-5C10-B522-127D1E342A57'),
}

model PredictClassifierModelResponse = {
  headers: map[string]string(name='headers'),
  body: PredictClassifierModelResponseBody(name='body'),
}

async function predictClassifierModel(request: PredictClassifierModelRequest): PredictClassifierModelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'PredictClassifierModel', 'POST', '/', 'json', false, 'json', request);
}

model PredictModelRequest {
  binaryToText?: boolean(name='BinaryToText', example='false', position='Query'),
  content?: string(name='Content', example='https://doc-automl-public.oss-cn-hangzhou.aliyuncs.com/3/1559855998794593/stage/upload/20230206/oss-hlfCRJ1SorSWs10MkqxK6YcL4OVAFSv4.png?Expires=1675665563&OSSAccessKeyId=XXXX&Signature=WLKghBc3zKzWJ3Td69%2B4C21jrbE%3D', position='Query'),
  modelId: long(name='ModelId', example='123', minimum=1, maximum=9999999999999, position='Query'),
  modelVersion?: string(name='ModelVersion', example='1', position='Query'),
  body?: string(name='body', position='Body'),
}

model PredictModelResponseBody = {
  code?: int32(name='Code', example='200'),
  data?: map[string]any(name='Data'),
  message?: string(name='Message', example='success'),
  requestId?: string(name='RequestId', description='Id of the request', example='3EAC98E6-8DD6-511F-8764-DEE8B6EB6BB4'),
}

model PredictModelResponse = {
  headers: map[string]string(name='headers'),
  body: PredictModelResponseBody(name='body'),
}

async function predictModel(request: PredictModelRequest): PredictModelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'PredictModel', 'POST', '/', 'json', false, 'json', request);
}

model PredictTemplateModelRequest {
  binaryToText?: boolean(name='BinaryToText', position='Query'),
  content?: string(name='Content', example='https://doc-automl-public.oss-cn-hangzhou.aliyuncs.com/3/xxx/stage/upload/20230207/oss-Y96lOVVWdjui6QVGsHJk0JfNf1luQkGT.png?Expires=1675750767&OSSAccessKeyId=xxx&Signature=lzq1ZUi6j4vkXnDDMhDD4DQty5Q%3D', position='Query'),
  taskId: long(name='TaskId', position='Query'),
  body?: string(name='body', position='Body'),
}

model PredictTemplateModelResponseBody = {
  code?: string(name='Code', example='200'),
  data?: map[string]any(name='Data'),
  message?: string(name='Message', example='successful'),
  requestId?: string(name='RequestId', description='Id of the request', example='F25FBAB4-665A-5D85-8AEF-39AE29F7D588'),
}

model PredictTemplateModelResponse = {
  headers: map[string]string(name='headers'),
  body: PredictTemplateModelResponseBody(name='body'),
}

async function predictTemplateModel(request: PredictTemplateModelRequest): PredictTemplateModelResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'PredictTemplateModel', 'POST', '/', 'json', false, 'json', request);
}

