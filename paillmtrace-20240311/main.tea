/**
 *
 */
import Util;
import OpenApi;
import OpenApiUtil;
import EndpointUtil;

extends OpenApi;


init(config: OpenApi.Config){
  super(config);
  @endpointRule = '';
  
  checkConfig(config);
  @endpoint = getEndpoint('paillmtrace', @regionId, @endpointRule, @network, @suffix, @endpointMap, @endpoint);
}

function getEndpoint(productId: string, regionId: string, endpointRule: string, network: string, suffix: string, endpointMap: map[string]string, endpoint: string) throws: string{
  if (!Util.empty(endpoint)) {
    return endpoint;
  }
  
  if (!Util.isUnset(endpointMap) && !Util.empty(endpointMap[regionId])) {
    return endpointMap[regionId];
  }
  return EndpointUtil.getEndpointRules(productId, regionId, endpointRule, network, suffix);
}

model EvaluationConfig {
  answer?: {
    jsonPathInSpan?: string(name='JsonPathInSpan'),
    jsonPathInSpanValue?: string(name='JsonPathInSpanValue'),
    spanName?: string(name='SpanName'),
  }(name='Answer'),
  context?: {
    jsonPathInSpan?: string(name='JsonPathInSpan'),
    jsonPathInSpanValue?: string(name='JsonPathInSpanValue'),
    spanName?: string(name='SpanName'),
  }(name='Context'),
  query?: {
    jsonPathInSpan?: string(name='JsonPathInSpan'),
    jsonPathInSpanValue?: string(name='JsonPathInSpanValue'),
    spanName?: string(name='SpanName'),
  }(name='Query'),
}

model ModelConfig {
  apiKey?: string(name='ApiKey'),
  endpoint?: string(name='Endpoint'),
  isSelfHost?: boolean(name='IsSelfHost'),
  name?: string(name='Name'),
  temperature?: float(name='Temperature'),
  topP?: float(name='TopP'),
  useFunctionCall?: boolean(name='UseFunctionCall'),
}

model QuestionAnswer {
  answer?: {
    contexts?: [ string ](name='Contexts'),
    text?: string(name='Text'),
  }(name='Answer'),
  groundTruth?: {
    contexts?: [ string ](name='Contexts'),
    text?: string(name='Text'),
  }(name='GroundTruth'),
  question?: string(name='Question'),
}

model CreateOnlineEvalTaskRequest {
  body?: {
    appName?: string(name='AppName', description='The name of the user application in the trace data.', example='my-best-llm-app'),
    description?: string(name='Description', description='The description of the task.', example='April to June data assessment'),
    endTime?: string(name='EndTime', description='The end time of the trace data, in UTC format.', example='2025-06-05 14:00:01
2025-06-05'),
    evaluationConfig?: EvaluationConfig(name='EvaluationConfig', description='This configuration structure defines the JSON paths needed to extract specific values from trace data in JSON format. EvaluationConfig defines these JSON paths.'),
    filters?: [ 
      {
        key?: string(name='Key', description='The key of the filter condition.

Valid values:

*   Status
*   SpanName
*   Input
*   TraceType
*   SpanType
*   ServiceName
*   Output
*   TraceName
*   ServiceId', example='ServiceId
ServiceName
Input
Output
Status
TraceType
SpanType
TraceName
SpanName'),
        operator?: string(name='Operator', description='The matching operator of the filter condition.

Valid values:

*   Contains
*   \\\\=
*   StartsWith', example='=
StartsWith
Contains'),
        value?: string(name='Value', description='The value of the filter condition.', example='foo'),
      }
    ](name='Filters', description='The evaluation task must search for a certain amount of trace data generated by the user application as input data for the evaluation. This list defines the search filter conditions.'),
    modelConfig?: ModelConfig(name='ModelConfig', description='The access configuration structure of the model used in the evaluation.'),
    samplingFrequencyMinutes?: int32(name='SamplingFrequencyMinutes', description='The evaluation task must search for a certain amount of trace data generated by the user application as input data for the evaluation. This is the width of the time window for each search of input data.', example='9'),
    samplingRatio?: int32(name='SamplingRatio', description='The percentage of data found in a time window that truly serves as evaluation input data. For example, 100 indicates that all data searched is used as evaluation input. 20 indicates that 20% of the found data is randomly selected as evaluation input.', example='50'),
    startTime?: string(name='StartTime', description='The start time of the trace data, in UTC format.', example='2025-04-05 14:00:01
2025-04-05'),
    taskName?: string(name='TaskName', description='The task name.', example='my-llm-app-eval-task-1'),
  }(name='body', description='The request data.'),
}

model CreateOnlineEvalTaskShrinkRequest {
  bodyShrink?: string(name='body', description='The request data.'),
}

model CreateOnlineEvalTaskResponseBody = {
  code?: string(name='Code', description='The internal error code. This parameter is returned only when an error occurs.', example='InvalidInputParams'),
  message?: string(name='Message', description='The error message. This parameter is returned only when an error occurs.', example='EvaluationConfig.Answer.SpanName is required.'),
  requestId?: string(name='RequestId', description='Id of the request', example='6A87228C-969A-1381-98CF-AE07AE630FA5'),
  taskId?: string(name='TaskId', description='The ID of the created trace evaluation task.', example='711ef9112343286810abbfce04e161ee'),
}

model CreateOnlineEvalTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateOnlineEvalTaskResponseBody(name='body'),
}

/**
 * @summary Creates a trace evaluation task. The system will sample some data from the user\\"s trace data based on the task\\"s configuration. Then, an LLM is used to evaluate the performance of these traces, and the evaluation results are recorded.
 *
 * @param tmpReq CreateOnlineEvalTaskRequest
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateOnlineEvalTaskResponse
 */
async function createOnlineEvalTaskWithOptions(tmpReq: CreateOnlineEvalTaskRequest, headers: map[string]string, runtime: Util.RuntimeOptions): CreateOnlineEvalTaskResponse {
  Util.validateModel(tmpReq);
  var request = new CreateOnlineEvalTaskShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.body)) {
    request.bodyShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.body, 'body', 'json');
  }
  var query : map[string]any = {};
  if (!Util.isUnset(request.bodyShrink)) {
    query['body'] = request.bodyShrink;
  }

  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateOnlineEvalTask',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/onlineevaltasks`,
    method = 'POST',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Creates a trace evaluation task. The system will sample some data from the user\\"s trace data based on the task\\"s configuration. Then, an LLM is used to evaluate the performance of these traces, and the evaluation results are recorded.
 *
 * @param request CreateOnlineEvalTaskRequest
 * @return CreateOnlineEvalTaskResponse
 */
async function createOnlineEvalTask(request: CreateOnlineEvalTaskRequest): CreateOnlineEvalTaskResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return createOnlineEvalTaskWithOptions(request, headers, runtime);
}

model CreateServiceIdentityRoleResponseBody = {
  code?: string(name='Code', description='The error code returned if the request fails.', example='InvalidInputParams'),
  message?: string(name='Message', description='The error message returned if the request fails.', example='User don\\\\"t have permission to create SLR.'),
  requestId?: string(name='RequestId', description='Id of the request', example='6A87228C-969A-1381-98CF-AE07AE630FA5'),
  roleDetails?: string(name='RoleDetails', description='The role details.', example='AliyunServiceRoleForPaiLLMTrace'),
  roleName?: string(name='RoleName', description='The name of the service-linked role. Default value: AliyunServiceRoleForPaiLLMTrace.', example='AliyunServiceRoleForPaiLLMTrace'),
}

model CreateServiceIdentityRoleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateServiceIdentityRoleResponseBody(name='body'),
}

/**
 * @summary Creates a service-linked role required for the PaiLLMTrace service.
 *
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return CreateServiceIdentityRoleResponse
 */
async function createServiceIdentityRoleWithOptions(headers: map[string]string, runtime: Util.RuntimeOptions): CreateServiceIdentityRoleResponse {
  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
  };
  var params = new OpenApi.Params{
    action = 'CreateServiceIdentityRole',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/ServiceIdentityRole`,
    method = 'POST',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Creates a service-linked role required for the PaiLLMTrace service.
 *
 * @return CreateServiceIdentityRoleResponse
 */
async function createServiceIdentityRole(): CreateServiceIdentityRoleResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return createServiceIdentityRoleWithOptions(headers, runtime);
}

model DeleteOnlineEvalTaskResponseBody = {
  code?: string(name='Code', description='Internal error code. Set only when the response is in error.', example='InvalidInputParams'),
  message?: string(name='Message', description='Response error message. Set only when the response is in error.', example='task id is empty'),
  requestId?: string(name='RequestId', description='ID of the request', example='6A87228C-969A-1381-98CF-AE07AE630FA5'),
}

model DeleteOnlineEvalTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteOnlineEvalTaskResponseBody(name='body'),
}

/**
 * @summary Delete an online evaluation task
 *
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return DeleteOnlineEvalTaskResponse
 */
async function deleteOnlineEvalTaskWithOptions(TaskId: string, headers: map[string]string, runtime: Util.RuntimeOptions): DeleteOnlineEvalTaskResponse {
  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
  };
  var params = new OpenApi.Params{
    action = 'DeleteOnlineEvalTask',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/onlineevaltasks/${OpenApiUtil.getEncodeParam(TaskId)}`,
    method = 'DELETE',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Delete an online evaluation task
 *
 * @return DeleteOnlineEvalTaskResponse
 */
async function deleteOnlineEvalTask(TaskId: string): DeleteOnlineEvalTaskResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return deleteOnlineEvalTaskWithOptions(TaskId, headers, runtime);
}

model EvaluateTraceRequest {
  appName?: string(name='AppName', description='The name of the application to which the trace belongs.', example='my-llm-app'),
  evaluationConfig?: EvaluationConfig(name='EvaluationConfig', description='If the value retrieved at the JSON path is itself a JSON string, further JSON path definitions within this JSON are necessary to get the actual value.

This parameter is required.'),
  evaluationId?: string(name='EvaluationId', description='The ID of the evaluation task. If not specified, the system randomly generates and returns an ID. You can use this ID to quickly search for evaluation results.', example='44aea0ee00000000be5be24b2abb8f98'),
  maxTime?: string(name='MaxTime', description='The end time of the search time range, in UTC format.', example='2025-04-05 13:24:25
2025-04-05'),
  minTime?: string(name='MinTime', description='The start time of the search time range, in UTC format.', example='2025-04-05 13:24:25
2025-04-05'),
  modelConfig?: ModelConfig(name='ModelConfig', description='The configuration structure to access the model used internally by the evaluation trace.'),
}

model EvaluateTraceResponseBody = {
  code?: string(name='Code', description='The internal error code. This parameter is returned if an exception occurred.', example='InvalidInputParams'),
  evaluationId?: string(name='EvaluationId', description='the task ID of the evaluation task to which the trace belongs.', example='6000043e103011f0922edec44617e03c'),
  message?: string(name='Message', description='The error message. This parameter is returned if an exception occurred.', example='eval_request missing dataset id or times'),
  requestId?: string(name='RequestId', description='Id of the request', example='F1AB295E-0D1F-5ECE-9FFA-98ABB4CB5DF5'),
}

model EvaluateTraceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: EvaluateTraceResponseBody(name='body'),
}

/**
 * @summary Evaluates a specified piece of trace data.
 *
 * @param request EvaluateTraceRequest
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return EvaluateTraceResponse
 */
async function evaluateTraceWithOptions(TraceId: string, request: EvaluateTraceRequest, headers: map[string]string, runtime: Util.RuntimeOptions): EvaluateTraceResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.appName)) {
    body['AppName'] = request.appName;
  }
  if (!Util.isUnset(request.evaluationConfig)) {
    body['EvaluationConfig'] = request.evaluationConfig;
  }
  if (!Util.isUnset(request.evaluationId)) {
    body['EvaluationId'] = request.evaluationId;
  }
  if (!Util.isUnset(request.maxTime)) {
    body['MaxTime'] = request.maxTime;
  }
  if (!Util.isUnset(request.minTime)) {
    body['MinTime'] = request.minTime;
  }
  if (!Util.isUnset(request.modelConfig)) {
    body['ModelConfig'] = request.modelConfig;
  }

  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'EvaluateTrace',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/eval/trace/${OpenApiUtil.getEncodeParam(TraceId)}`,
    method = 'PUT',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Evaluates a specified piece of trace data.
 *
 * @param request EvaluateTraceRequest
 * @return EvaluateTraceResponse
 */
async function evaluateTrace(TraceId: string, request: EvaluateTraceRequest): EvaluateTraceResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return evaluateTraceWithOptions(TraceId, request, headers, runtime);
}

model GetEvaluationTemplatesResponseBody = {
  code?: string(name='Code', description='Internal error code. Set only when the response has an error.', example='ExecutionFailure'),
  evaluationTemplates?: [ any ](name='EvaluationTemplates', description='A series of templates used internally by the evaluation system to construct LLM interaction information.'),
  message?: string(name='Message', description='Response error message. Set only when the response has an error.', example='cannot get data back.'),
  requestId?: string(name='RequestId', description='ID of the request', example='6A87228C-969A-1381-98CF-AE07AE630FA5'),
}

model GetEvaluationTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEvaluationTemplatesResponseBody(name='body'),
}

/**
 * @summary Get the content of prompt templates used for evaluation
 *
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetEvaluationTemplatesResponse
 */
async function getEvaluationTemplatesWithOptions(headers: map[string]string, runtime: Util.RuntimeOptions): GetEvaluationTemplatesResponse {
  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
  };
  var params = new OpenApi.Params{
    action = 'GetEvaluationTemplates',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/eval/templates`,
    method = 'GET',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Get the content of prompt templates used for evaluation
 *
 * @return GetEvaluationTemplatesResponse
 */
async function getEvaluationTemplates(): GetEvaluationTemplatesResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return getEvaluationTemplatesWithOptions(headers, runtime);
}

model GetOnlineEvalTaskResponseBody = {
  code?: string(name='Code', description='Internal error code. Set only when the response is in error.', example='InvalidInputParams'),
  message?: string(name='Message', description='Response error message. Set only when the response is in error.', example='task id is empty'),
  requestId?: string(name='RequestId', description='POP request ID', example='6F352A02-9C0D-54A7-B57C-663CF71D5714'),
  task?: {
    aliyunUid?: string(name='AliyunUid', description='The Alibaba Cloud account (primary account) of the task creator.', example='1195531608511111'),
    appName?: string(name='AppName', description='The name of the user application targeted by this task.', example='my-llm-app'),
    description?: string(name='Description', description='Task description information', example='这个任务做了这些事。'),
    evalResults?: string(name='EvalResults', description='Deprecated. Will be removed.', example='Deprecated. Will be removed.'),
    evaluationConfig?: EvaluationConfig(name='EvaluationConfig', description='Extract specific path values from JSON-formatted trace data as input for the evaluation operation. These JSON paths are defined within this EvaluationConfig structure.'),
    filters?: [ 
      {
        key?: string(name='Key', description='Key of the filter condition.', example='ServiceId
ServiceName
Input
Output
Status
TraceType
SpanType
TraceName
SpanName'),
        operator?: string(name='Operator', description='Filter condition match operator.', example='=
StartsWith
Contains'),
        value?: string(name='Value', description='Value of the filter condition.', example='foo'),
      }
    ](name='Filters', description='The evaluation task needs to search for a certain amount of trace data generated by the user application as input data for the evaluation operation. This is a list that defines the search filter conditions.'),
    gmtCreateTime?: string(name='GmtCreateTime', description='UTC creation time of the task.', example='2024-07-31 08:30:00'),
    gmtEndTime?: string(name='GmtEndTime', description='UTC end time of the trace data.', example='2024-08-10 13:20:00'),
    gmtLastSamplingWindowEndTime?: string(name='GmtLastSamplingWindowEndTime', description='UTC upper bound of the last sampling window', example='2024-08-10 13:14:00'),
    gmtLastSamplingWindowStartTime?: string(name='GmtLastSamplingWindowStartTime', description='UTC lower bound of the last sampling window.', example='2024-08-10 13:11:00'),
    gmtStartTime?: string(name='GmtStartTime', description='UTC start time of the trace data.', example='2024-08-02'),
    id?: string(name='Id', description='Task ID', example='0839a02d-aa24-4174-90bb-7a773885934d'),
    modelConfig?: ModelConfig(name='ModelConfig', description='Access configuration structure for the large model used internally by the evaluation task.'),
    name?: string(name='Name', description='Task name.', example='my-eval-task-1'),
    recordCount?: int32(name='RecordCount', description='Number of evaluation records', example='999'),
    samplingFrequencyMinutes?: int32(name='SamplingFrequencyMinutes', description='The evaluation task needs to search for a certain amount of trace data generated by the user application as input data for the evaluation operation. This defines the width of the time window for each search of input data.', example='3'),
    samplingRatio?: int32(name='SamplingRatio', description='The percentage of the data found within a time window that is actually used as input for the evaluation task. For example, 100 means all the found data is used as input, 20 means 20% of the found data is randomly selected as input.', example='70'),
    status?: string(name='Status', description='Task status', example='CREATED
RUNNING
FINISHED
USER_CANCELED'),
    userId?: string(name='UserId', description='The Alibaba Cloud sub-account of the task creator.', example='222222222222222222'),
  }(name='Task', description='Task information'),
}

model GetOnlineEvalTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetOnlineEvalTaskResponseBody(name='body'),
}

/**
 * @summary Get the details of an online evaluation task
 *
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetOnlineEvalTaskResponse
 */
async function getOnlineEvalTaskWithOptions(TaskId: string, headers: map[string]string, runtime: Util.RuntimeOptions): GetOnlineEvalTaskResponse {
  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
  };
  var params = new OpenApi.Params{
    action = 'GetOnlineEvalTask',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/onlineevaltasks/${OpenApiUtil.getEncodeParam(TaskId)}`,
    method = 'GET',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Get the details of an online evaluation task
 *
 * @return GetOnlineEvalTaskResponse
 */
async function getOnlineEvalTask(TaskId: string): GetOnlineEvalTaskResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return getOnlineEvalTaskWithOptions(TaskId, headers, runtime);
}

model GetServiceIdentityRoleResponseBody = {
  code?: string(name='Code', description='The internal error code. This parameter is returned only when an error occurs.', example='EntityNotExist'),
  message?: string(name='Message', description='The error message. This parameter is returned only when an error occurs.', example='Serivce role does not exit.'),
  requestId?: string(name='RequestId', description='Id of the request', example='6A87228C-969A-1381-98CF-AE07AE630FA5'),
  roleDetail?: string(name='RoleDetail', description='The role details.', example='AliyunServiceRoleForPaiLLMTrace'),
  roleName?: string(name='RoleName', description='The name of the service-linked role. Default value: AliyunServiceRoleForPaiLLMTrace.', example='AliyunServiceRoleForPaiLLMTrace'),
}

model GetServiceIdentityRoleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetServiceIdentityRoleResponseBody(name='body'),
}

/**
 * @summary Obtains the information related to the service-linked role.
 *
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetServiceIdentityRoleResponse
 */
async function getServiceIdentityRoleWithOptions(headers: map[string]string, runtime: Util.RuntimeOptions): GetServiceIdentityRoleResponse {
  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
  };
  var params = new OpenApi.Params{
    action = 'GetServiceIdentityRole',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/ServiceIdentityRole`,
    method = 'GET',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Obtains the information related to the service-linked role.
 *
 * @return GetServiceIdentityRoleResponse
 */
async function getServiceIdentityRole(): GetServiceIdentityRoleResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return getServiceIdentityRoleWithOptions(headers, runtime);
}

model GetXtraceTokenResponseBody = {
  code?: string(name='Code', description='The internal error code. This parameter is returned only when an error occurs.', example='InvalidInputParams'),
  grpcEndpoint?: string(name='GrpcEndpoint', description='The gRPC endpoint used for uploading ARM traces.', example='http://tracing-analysis-dc-hz.aliyuncs.com:8090'),
  grpcInternalEndpoint?: string(name='GrpcInternalEndpoint', description='The internal gRPC endpoint used for uploading ARMS traces used by Alibaba Cloud.', example='http://tracing-analysis-dc-hz-internal.aliyuncs.com:8090'),
  httpEndpoint?: string(name='HttpEndpoint', description='The endpoint used for uploading ARMS traces.', example='http://tracing-analysis-dc-hz.aliyuncs.com/aaa@bbb@ccc/api/otlp/traces'),
  httpInternalEndpoint?: string(name='HttpInternalEndpoint', description='The internal endpoint used for uploading ARMS traces used by Alibaba Cloud.', example='http://tracing-analysis-dc-hz-internal.aliyuncs.com/aaa@bbb@ccc/api/otlp/traces'),
  message?: string(name='Message', description='The error message. This parameter is returned only when an error occurs.', example='get_xtrace_token: failed, ERROR: NoPermission'),
  requestId?: string(name='RequestId', description='Id of the request', example='6A87228C-969A-1381-98CF-AE07AE630FA5'),
  token?: string(name='Token', description='The token used for uploading ARMS traces.', example='h1abcw7@5abcb_h1abcw7@5abc01'),
}

model GetXtraceTokenResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetXtraceTokenResponseBody(name='body'),
}

/**
 * @summary Obtains the token used in the Xtrace service and the endpoint required for uploading trace data.
 *
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return GetXtraceTokenResponse
 */
async function getXtraceTokenWithOptions(headers: map[string]string, runtime: Util.RuntimeOptions): GetXtraceTokenResponse {
  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
  };
  var params = new OpenApi.Params{
    action = 'GetXtraceToken',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/XtraceToken`,
    method = 'GET',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Obtains the token used in the Xtrace service and the endpoint required for uploading trace data.
 *
 * @return GetXtraceTokenResponse
 */
async function getXtraceToken(): GetXtraceTokenResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return getXtraceTokenWithOptions(headers, runtime);
}

model ListEvalResultsRequest {
  evaluationId?: string(name='EvaluationId', description='The task ID of the evaluation task to which the trace belongs.', example='0bb05ae2a2dc11ef9757faaa2a1ec0c6'),
  keyword?: string(name='Keyword', description='The keyword to query from the evaluation inputs.', example='foo'),
  pageNumber?: int32(name='PageNumber', description='The page number. Page starts from page 1. Default value: 1', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries to return on each page. Maximum value: 50. Default value: 10.', example='10'),
  recordIds?: [ string ](name='RecordIds', description='The trace data IDs.'),
}

model ListEvalResultsShrinkRequest {
  evaluationId?: string(name='EvaluationId', description='The task ID of the evaluation task to which the trace belongs.', example='0bb05ae2a2dc11ef9757faaa2a1ec0c6'),
  keyword?: string(name='Keyword', description='The keyword to query from the evaluation inputs.', example='foo'),
  pageNumber?: int32(name='PageNumber', description='The page number. Page starts from page 1. Default value: 1', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries to return on each page. Maximum value: 50. Default value: 10.', example='10'),
  recordIdsShrink?: string(name='RecordIds', description='The trace data IDs.'),
}

model ListEvalResultsResponseBody = {
  code?: string(name='Code', description='The internal error code. This parameter is returned only when an error occurs.', example='ExecutionFailure'),
  evaluationResults?: [ string ](name='EvaluationResults', description='The evaluation results.'),
  message?: string(name='Message', description='The error message. This parameter is returned only when an error occurs.', example='cannot get data back.'),
  requestId?: string(name='RequestId', description='The ID of the POP request.', example='6A87228C-969A-1381-98CF-AE07AE630FA5'),
  totalCount?: int32(name='TotalCount', description='The total number of results that meet the condition.', example='22'),
}

model ListEvalResultsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListEvalResultsResponseBody(name='body'),
}

/**
 * @summary Obtains the list of results for trace evaluation. This API is used together with EvaluateTrace. EvaluateTrace starts the evaluation. ListEvalResults obtains the results.
 *
 * @param tmpReq ListEvalResultsRequest
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListEvalResultsResponse
 */
async function listEvalResultsWithOptions(tmpReq: ListEvalResultsRequest, headers: map[string]string, runtime: Util.RuntimeOptions): ListEvalResultsResponse {
  Util.validateModel(tmpReq);
  var request = new ListEvalResultsShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.recordIds)) {
    request.recordIdsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.recordIds, 'RecordIds', 'simple');
  }
  var query : map[string]any = {};
  if (!Util.isUnset(request.evaluationId)) {
    query['EvaluationId'] = request.evaluationId;
  }
  if (!Util.isUnset(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.recordIdsShrink)) {
    query['RecordIds'] = request.recordIdsShrink;
  }

  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListEvalResults',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/eval/results`,
    method = 'GET',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Obtains the list of results for trace evaluation. This API is used together with EvaluateTrace. EvaluateTrace starts the evaluation. ListEvalResults obtains the results.
 *
 * @param request ListEvalResultsRequest
 * @return ListEvalResultsResponse
 */
async function listEvalResults(request: ListEvalResultsRequest): ListEvalResultsResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return listEvalResultsWithOptions(request, headers, runtime);
}

model ListOnlineEvalTaskResultsRequest {
  evaluationId?: string(name='EvaluationId', description='The ID of the evaluation task. At least one of the trace ID or task ID must be set.', example='0bb05ae8888c11ef9757faaa2a1ec0c6'),
  mostRecentResultsOnly?: boolean(name='MostRecentResultsOnly', description='The same trace data may have been evaluated by different tasks. If no task ID is specified and there are multiple evaluation results for the same trace ID, this parameter specifies whether to return only the most recent evaluation result.', example='True'),
  pageNumber?: int32(name='PageNumber', description='The current page number. Value range: integers greater than 0. Default value: 1.', example='2'),
  pageSize?: int32(name='PageSize', description='Page size, default is 10.', example='50'),
  traceIds?: [ string ](name='TraceIds', description='Specify a set of trace IDs, and only return the evaluation results for these traces. At least one of the trace ID or task ID must be set.'),
}

model ListOnlineEvalTaskResultsShrinkRequest {
  evaluationId?: string(name='EvaluationId', description='The ID of the evaluation task. At least one of the trace ID or task ID must be set.', example='0bb05ae8888c11ef9757faaa2a1ec0c6'),
  mostRecentResultsOnly?: boolean(name='MostRecentResultsOnly', description='The same trace data may have been evaluated by different tasks. If no task ID is specified and there are multiple evaluation results for the same trace ID, this parameter specifies whether to return only the most recent evaluation result.', example='True'),
  pageNumber?: int32(name='PageNumber', description='The current page number. Value range: integers greater than 0. Default value: 1.', example='2'),
  pageSize?: int32(name='PageSize', description='Page size, default is 10.', example='50'),
  traceIdsShrink?: string(name='TraceIds', description='Specify a set of trace IDs, and only return the evaluation results for these traces. At least one of the trace ID or task ID must be set.'),
}

model ListOnlineEvalTaskResultsResponseBody = {
  code?: string(name='Code', description='Internal error code. Set only when the response has an error.', example='InvalidInputParams'),
  evaluationResults?: [ string ](name='EvaluationResults', description='List of evaluation results.'),
  message?: string(name='Message', description='Response error message. Set only when the response has an error.', example='must provide trace_id(s) or eval_id'),
  requestId?: string(name='RequestId', description='ID of the request', example='22BA9A5A-E3D8-5B4C-90FC-F33F6E5853F8'),
  totalCount?: int32(name='TotalCount', description='Total number of evaluation results that meet the criteria.', example='123'),
}

model ListOnlineEvalTaskResultsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListOnlineEvalTaskResultsResponseBody(name='body'),
}

/**
 * @summary List the results of online evaluation tasks that meet the criteria
 *
 * @param tmpReq ListOnlineEvalTaskResultsRequest
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListOnlineEvalTaskResultsResponse
 */
async function listOnlineEvalTaskResultsWithOptions(tmpReq: ListOnlineEvalTaskResultsRequest, headers: map[string]string, runtime: Util.RuntimeOptions): ListOnlineEvalTaskResultsResponse {
  Util.validateModel(tmpReq);
  var request = new ListOnlineEvalTaskResultsShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.traceIds)) {
    request.traceIdsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.traceIds, 'TraceIds', 'simple');
  }
  var query : map[string]any = {};
  if (!Util.isUnset(request.evaluationId)) {
    query['EvaluationId'] = request.evaluationId;
  }
  if (!Util.isUnset(request.mostRecentResultsOnly)) {
    query['MostRecentResultsOnly'] = request.mostRecentResultsOnly;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.traceIdsShrink)) {
    query['TraceIds'] = request.traceIdsShrink;
  }

  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListOnlineEvalTaskResults',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/onlineevaltaskresults`,
    method = 'GET',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary List the results of online evaluation tasks that meet the criteria
 *
 * @param request ListOnlineEvalTaskResultsRequest
 * @return ListOnlineEvalTaskResultsResponse
 */
async function listOnlineEvalTaskResults(request: ListOnlineEvalTaskResultsRequest): ListOnlineEvalTaskResultsResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return listOnlineEvalTaskResultsWithOptions(request, headers, runtime);
}

model ListOnlineEvalTasksRequest {
  appName?: string(name='AppName'),
  keyword?: string(name='Keyword', description='Search keyword. It will match on fields such as task name, application name (appName), task description, and evaluation metric name.', example='foo'),
  maxTime?: string(name='MaxTime', description='The UTC end time of the search time range', example='2025-04-07 13:24:25
2025-04-07'),
  minTime?: string(name='MinTime', description='The UTC start time of the search time range', example='2025-04-05 13:24:25
2025-04-05'),
  pageNumber?: int32(name='PageNumber', description='The current page number. Value range: integers greater than 0. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='Page size, default is 10.', example='50'),
  sortBy?: string(name='SortBy'),
  sortOrder?: string(name='SortOrder'),
  status?: string(name='Status'),
}

model ListOnlineEvalTasksResponseBody = {
  code?: string(name='Code', description='Internal error code. Set only when the response has an error.', example='InvalidInputParams'),
  message?: string(name='Message', description='Response error message. Set only when the response has an error.', example='page number should be greater than 0'),
  requestId?: string(name='RequestId', description='ID of the request', example='6F352A02-9C0D-54A7-B57C-663CF71D5714'),
  tasks?: [ 
    {
      aliyunUid?: string(name='AliyunUid', description='The Alibaba Cloud account (primary account) of the task creator.', example='1512522691911111'),
      appName?: string(name='AppName', description='The name of the user application targeted by this task.', example='my-llm-app'),
      description?: string(name='Description', description='Task description information', example='this task is for application evaluation'),
      evalResults?: string(name='EvalResults'),
      evaluationConfig?: EvaluationConfig(name='EvaluationConfig', description='Extract specific path values from JSON-formatted trace data as input for the evaluation operation. These JSON paths are defined in this EvaluationConfig structure.'),
      filters?: [ 
        {
          key?: string(name='Key', description='The key of the filter condition.', example='ServiceId
ServiceName
Input
Output
Status
TraceType
SpanType
TraceName
SpanName'),
          operator?: string(name='Operator', description='The matching operator of the filter condition.', example='=
StartsWith
Contains'),
          value?: string(name='Value', description='The value of the filter condition.', example='foo'),
        }
      ](name='Filters', description='The list define the search filter conditions for the evaluation task to search a certain amount of trace data generated by the user application, which serves as input data for the evaluation operation.'),
      gmtCreateTime?: string(name='GmtCreateTime', description='The UTC creation time of the task.', example='2025-04-07 13:24:35'),
      gmtEndTime?: string(name='GmtEndTime', description='Task UTC end time.', example='2025-04-09 13:24:35'),
      gmtStartTime?: string(name='GmtStartTime', description='The UTC start time of the task.', example='2025-04-08 13:24:35'),
      id?: string(name='Id', description='Task ID.', example='9f50cd72efcf36535152ee811a911115'),
      modelConfig?: ModelConfig(name='ModelConfig', description='Access configuration structure for the large model used internally by the evaluation task.'),
      name?: string(name='Name', description='Task name.', example='my-foo-evaluation-task'),
      recordCount?: int32(name='RecordCount'),
      samplingFrequencyMinutes?: int32(name='SamplingFrequencyMinutes', description='The evaluation task needs to search for a certain amount of trace data generated by the user\\\\"s application as input data for the evaluation operation. This defines the time window for each data search.', example='12'),
      samplingRatio?: int32(name='SamplingRatio', description='The percentage of the data searched within a time window that is used as input data for the evaluation. For example, 100 means all the searched data is used as input, 20 means 20% of the searched data is randomly selected as input.', example='50'),
      status?: string(name='Status', description='Task status', example='CREATED
RUNNING
FINISHED
USER_CANCELED'),
      userId?: string(name='UserId', description='The Alibaba Cloud sub-account of the task creator.', example='2222222222'),
    }
  ](name='Tasks', description='List of tasks.'),
  totalCount?: int32(name='TotalCount', description='Total number of tasks that meet the criteria.', example='22'),
}

model ListOnlineEvalTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListOnlineEvalTasksResponseBody(name='body'),
}

/**
 * @summary View online evaluation tasks that meet the criteria
 *
 * @param request ListOnlineEvalTasksRequest
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListOnlineEvalTasksResponse
 */
async function listOnlineEvalTasksWithOptions(request: ListOnlineEvalTasksRequest, headers: map[string]string, runtime: Util.RuntimeOptions): ListOnlineEvalTasksResponse {
  Util.validateModel(request);
  var query : map[string]any = {};
  if (!Util.isUnset(request.appName)) {
    query['AppName'] = request.appName;
  }
  if (!Util.isUnset(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!Util.isUnset(request.maxTime)) {
    query['MaxTime'] = request.maxTime;
  }
  if (!Util.isUnset(request.minTime)) {
    query['MinTime'] = request.minTime;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!Util.isUnset(request.sortOrder)) {
    query['SortOrder'] = request.sortOrder;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }

  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListOnlineEvalTasks',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/onlineevaltasks`,
    method = 'GET',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary View online evaluation tasks that meet the criteria
 *
 * @param request ListOnlineEvalTasksRequest
 * @return ListOnlineEvalTasksResponse
 */
async function listOnlineEvalTasks(request: ListOnlineEvalTasksRequest): ListOnlineEvalTasksResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return listOnlineEvalTasksWithOptions(request, headers, runtime);
}

model ListTracesDatasRequest {
  endUserId?: string(name='EndUserId', description='The value of the attributes.service.app.user_id field in the trace record. It can contain upper and lower case letters, digits, dot (.), hyphen (-), and underscore (_). It is empty by default.', example='end-user.12345'),
  filters?: [ 
    {
      key?: string(name='Key', description='The name of the filter parameter, case-insensitive. Supported parameters: \\\\"serviceid\\\\", \\\\"servicename\\\\", \\\\"input\\\\", \\\\"output\\\\", \\\\"status\\\\", \\\\"tracetype\\\\", and \\\\"tracename\\\\".

The otel span attributes corresponding to the parameters:

serviceid: resources.service.id

servicename: resources.service.name

input: attributes.input.value

output: attributes.output.value

status: statusCode

tracetype: the attributes.gen_ai.span.kind of span whose parentSpanId is 0

tracename: the spanName of span whose parentSpanId is 0

Valid values:

*   Status
*   SpanName
*   Input
*   TraceType
*   SpanType
*   ServiceName
*   Output
*   TraceName
*   ServiceId', example='output'),
      operator?: string(name='Operator', description='The parameter operator. Case-insensitive. Supported operators: \\\\"=\\\\", \\\\"contains\\\\", and \\\\"startswith\\\\".

Valid values:

*   contains
*   \\\\=
*   startsWith', example='contains'),
      value?: string(name='Value', description='The value of the filter parameter. For the contains operation, it is case-sensitive. For other operations, it is case-insensitive.', example='cretain filter string'),
    }
  ](name='Filters', description='Other filter parameters'),
  hasEvents?: boolean(name='HasEvents', description='Whether to return only trace records containing spans with a non-empty events. Example: Suppose a trace has 3 spans. If this parameter is True, this trace meets the condition when any one of the 3 spans has a non-empty events. The default value is False. The events is not used for filtering.', example='False'),
  hasStatusMessage?: boolean(name='HasStatusMessage', description='Whether to return only trace records containing spans with a non-empty statusMessage. Example: Suppose a trace has 3 spans. If this parameter is True, this trace meets the condition when any one of the 3 spans has a non-empty statusMessage. The default value is False. The statusMessage is not used for filtering.', example='False'),
  llmAppName?: string(name='LlmAppName', description='The value of the resources.service.app.name field in the trace record. It can contain upper and lower case letters, digits, dot (.), hyphen (-), and underscore (_). Must be an exact match. It is empty by default.', example='My.super_LLM-app2'),
  maxDuration?: float(name='MaxDuration'),
  maxTime?: string(name='MaxTime', description='The upper limit of the search time range, in UTC format (YYYY-mm-dd or YYYY-MM-DD HH:mm:ss). By default, the value is (current time +10 minutes)', example='2024-01-31
2024-12-31 23:59:59'),
  minDuration?: float(name='MinDuration'),
  minTime?: string(name='MinTime', description='The lower limit of the search time range, in UTC format (YYYY-mm-dd or YYYY-MM-DD HH:mm:ss). By default, the value is (current time - 2 days).

This parameter is required.', example='2024-01-31
2024-12-31 23:59:59'),
  opentelemetryCompatible?: boolean(name='OpentelemetryCompatible', description='Whether the returned JSON data can be directly converted to OpenTelemetry TracesData protobuf object. Default value: False. JSON data that is compatible with OpenTelemetry is more complex. Such data is generally not required unless you want to generate a protobuf object of OpenTelemetry.', example='False'),
  ownerId?: string(name='OwnerId'),
  ownerSubId?: string(name='OwnerSubId', description='The value of the resources.service.owner.sub_id field in the trace record. It can contain upper and lower case letters, digits, dot (.), hyphen (-), and underscore (_). It is empty by default.', example='123456789'),
  pageNumber?: int32(name='PageNumber', description='The page number. Page starts from page 1. Default value: 1', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Maximum value: 100.', example='10'),
  sortBy?: string(name='SortBy', description='The field used to sort the returned results. Valid values: StartTime and Duration.', example='StartTime
Duration'),
  sortOrder?: string(name='SortOrder', description='The sorting order. Valid values:

*   **ASC**
*   **DESC** (default)', example='DESC
ASC'),
  spanIds?: [ string ](name='SpanIds', description='The list of span IDs. Each trace record contains one or more spans.'),
  spanName?: string(name='SpanName'),
  traceIds?: [ string ](name='TraceIds', description='The list of trace IDs.'),
  traceReduceMethod?: string(name='TraceReduceMethod', description='The content simplification method for returned trace data to reduce the data volume.

REMOVE_EMBEDDING: Removes all embedding array contents.

ROOT_ONLY: Returns only the root span for each trace, with the root span content also having the REMOVE_EMBEDDING applied.

Blank: Maintains the original data without simplification.', example='REMOVE_EMBEDDING
ROOT_ONLY'),
}

model ListTracesDatasShrinkRequest {
  endUserId?: string(name='EndUserId', description='The value of the attributes.service.app.user_id field in the trace record. It can contain upper and lower case letters, digits, dot (.), hyphen (-), and underscore (_). It is empty by default.', example='end-user.12345'),
  filtersShrink?: string(name='Filters', description='Other filter parameters'),
  hasEvents?: boolean(name='HasEvents', description='Whether to return only trace records containing spans with a non-empty events. Example: Suppose a trace has 3 spans. If this parameter is True, this trace meets the condition when any one of the 3 spans has a non-empty events. The default value is False. The events is not used for filtering.', example='False'),
  hasStatusMessage?: boolean(name='HasStatusMessage', description='Whether to return only trace records containing spans with a non-empty statusMessage. Example: Suppose a trace has 3 spans. If this parameter is True, this trace meets the condition when any one of the 3 spans has a non-empty statusMessage. The default value is False. The statusMessage is not used for filtering.', example='False'),
  llmAppName?: string(name='LlmAppName', description='The value of the resources.service.app.name field in the trace record. It can contain upper and lower case letters, digits, dot (.), hyphen (-), and underscore (_). Must be an exact match. It is empty by default.', example='My.super_LLM-app2'),
  maxDuration?: float(name='MaxDuration'),
  maxTime?: string(name='MaxTime', description='The upper limit of the search time range, in UTC format (YYYY-mm-dd or YYYY-MM-DD HH:mm:ss). By default, the value is (current time +10 minutes)', example='2024-01-31
2024-12-31 23:59:59'),
  minDuration?: float(name='MinDuration'),
  minTime?: string(name='MinTime', description='The lower limit of the search time range, in UTC format (YYYY-mm-dd or YYYY-MM-DD HH:mm:ss). By default, the value is (current time - 2 days).

This parameter is required.', example='2024-01-31
2024-12-31 23:59:59'),
  opentelemetryCompatible?: boolean(name='OpentelemetryCompatible', description='Whether the returned JSON data can be directly converted to OpenTelemetry TracesData protobuf object. Default value: False. JSON data that is compatible with OpenTelemetry is more complex. Such data is generally not required unless you want to generate a protobuf object of OpenTelemetry.', example='False'),
  ownerId?: string(name='OwnerId'),
  ownerSubId?: string(name='OwnerSubId', description='The value of the resources.service.owner.sub_id field in the trace record. It can contain upper and lower case letters, digits, dot (.), hyphen (-), and underscore (_). It is empty by default.', example='123456789'),
  pageNumber?: int32(name='PageNumber', description='The page number. Page starts from page 1. Default value: 1', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 20. Maximum value: 100.', example='10'),
  sortBy?: string(name='SortBy', description='The field used to sort the returned results. Valid values: StartTime and Duration.', example='StartTime
Duration'),
  sortOrder?: string(name='SortOrder', description='The sorting order. Valid values:

*   **ASC**
*   **DESC** (default)', example='DESC
ASC'),
  spanIdsShrink?: string(name='SpanIds', description='The list of span IDs. Each trace record contains one or more spans.'),
  spanName?: string(name='SpanName'),
  traceIdsShrink?: string(name='TraceIds', description='The list of trace IDs.'),
  traceReduceMethod?: string(name='TraceReduceMethod', description='The content simplification method for returned trace data to reduce the data volume.

REMOVE_EMBEDDING: Removes all embedding array contents.

ROOT_ONLY: Returns only the root span for each trace, with the root span content also having the REMOVE_EMBEDDING applied.

Blank: Maintains the original data without simplification.', example='REMOVE_EMBEDDING
ROOT_ONLY'),
}

model ListTracesDatasResponseBody = {
  code?: string(name='Code', description='The internal error code. This parameter is returned only when an error occurs.', example='ExecutionFailure'),
  message?: string(name='Message', description='The error message. This parameter is returned only when an error occurs.', example='failed to get trace data'),
  requestId?: string(name='RequestId', description='POP request id', example='6A87228C-969A-1381-98CF-AE07AE630FA5'),
  totalCount?: int32(name='TotalCount', description='The total number of traces that meet the condition.', example='22'),
  traces?: [ any ](name='Traces', description='The JSON array with each element being a trace\\\\"s JSON string. Length of the array is equal to or less than the page size parameter value.'),
}

model ListTracesDatasResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTracesDatasResponseBody(name='body'),
}

/**
 * @summary Obtains a list of trace data based on specified criteria.
 *
 * @param tmpReq ListTracesDatasRequest
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return ListTracesDatasResponse
 */
async function listTracesDatasWithOptions(tmpReq: ListTracesDatasRequest, headers: map[string]string, runtime: Util.RuntimeOptions): ListTracesDatasResponse {
  Util.validateModel(tmpReq);
  var request = new ListTracesDatasShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.filters)) {
    request.filtersShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.filters, 'Filters', 'json');
  }
  if (!Util.isUnset(tmpReq.spanIds)) {
    request.spanIdsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.spanIds, 'SpanIds', 'simple');
  }
  if (!Util.isUnset(tmpReq.traceIds)) {
    request.traceIdsShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.traceIds, 'TraceIds', 'simple');
  }
  var query : map[string]any = {};
  if (!Util.isUnset(request.endUserId)) {
    query['EndUserId'] = request.endUserId;
  }
  if (!Util.isUnset(request.filtersShrink)) {
    query['Filters'] = request.filtersShrink;
  }
  if (!Util.isUnset(request.hasEvents)) {
    query['HasEvents'] = request.hasEvents;
  }
  if (!Util.isUnset(request.hasStatusMessage)) {
    query['HasStatusMessage'] = request.hasStatusMessage;
  }
  if (!Util.isUnset(request.llmAppName)) {
    query['LlmAppName'] = request.llmAppName;
  }
  if (!Util.isUnset(request.maxDuration)) {
    query['MaxDuration'] = request.maxDuration;
  }
  if (!Util.isUnset(request.maxTime)) {
    query['MaxTime'] = request.maxTime;
  }
  if (!Util.isUnset(request.minDuration)) {
    query['MinDuration'] = request.minDuration;
  }
  if (!Util.isUnset(request.minTime)) {
    query['MinTime'] = request.minTime;
  }
  if (!Util.isUnset(request.opentelemetryCompatible)) {
    query['OpentelemetryCompatible'] = request.opentelemetryCompatible;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.ownerSubId)) {
    query['OwnerSubId'] = request.ownerSubId;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.sortBy)) {
    query['SortBy'] = request.sortBy;
  }
  if (!Util.isUnset(request.sortOrder)) {
    query['SortOrder'] = request.sortOrder;
  }
  if (!Util.isUnset(request.spanIdsShrink)) {
    query['SpanIds'] = request.spanIdsShrink;
  }
  if (!Util.isUnset(request.spanName)) {
    query['SpanName'] = request.spanName;
  }
  if (!Util.isUnset(request.traceIdsShrink)) {
    query['TraceIds'] = request.traceIdsShrink;
  }
  if (!Util.isUnset(request.traceReduceMethod)) {
    query['TraceReduceMethod'] = request.traceReduceMethod;
  }

  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListTracesDatas',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/TracesDatas`,
    method = 'GET',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Obtains a list of trace data based on specified criteria.
 *
 * @param request ListTracesDatasRequest
 * @return ListTracesDatasResponse
 */
async function listTracesDatas(request: ListTracesDatasRequest): ListTracesDatasResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return listTracesDatasWithOptions(request, headers, runtime);
}

model StopOnlineEvalTaskResponseBody = {
  code?: string(name='Code', description='Internal error code. Set only when the response is in error.', example='InvalidInputParams'),
  message?: string(name='Message', description='Response error message. Set only when the response is in error.', example='task id is empty'),
  requestId?: string(name='RequestId', description='ID of the POP request', example='31E5FBC2-792D-5B5C-A5EB-3019984ABFC8'),
}

model StopOnlineEvalTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopOnlineEvalTaskResponseBody(name='body'),
}

/**
 * @summary Stop the execution of an online evaluation task
 *
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return StopOnlineEvalTaskResponse
 */
async function stopOnlineEvalTaskWithOptions(TaskId: string, headers: map[string]string, runtime: Util.RuntimeOptions): StopOnlineEvalTaskResponse {
  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
  };
  var params = new OpenApi.Params{
    action = 'StopOnlineEvalTask',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/onlineevaltasks/${OpenApiUtil.getEncodeParam(TaskId)}/stop`,
    method = 'PUT',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Stop the execution of an online evaluation task
 *
 * @return StopOnlineEvalTaskResponse
 */
async function stopOnlineEvalTask(TaskId: string): StopOnlineEvalTaskResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return stopOnlineEvalTaskWithOptions(TaskId, headers, runtime);
}

model UpdateOnlineEvalTaskRequest {
  appName?: string(name='AppName', description='The user-defined name of the LLM application.', example='my-llm-one'),
  description?: string(name='Description', description='The description of the task.', example='The purpose of the task is xxx.'),
  endTime?: string(name='EndTime', description='The end time of the trace data, in UTC format.', example='2024-09-02 22:24:00'),
  evaluationConfig?: EvaluationConfig(name='EvaluationConfig', description='This configuration structure defines the JSON paths needed to extract specific values from trace data in JSON format. EvaluationConfig defines these JSON paths.'),
  filters?: [ 
    {
      key?: string(name='Key', description='The key of the filter condition.

Valid values:

*   Status
*   SpanName
*   Input
*   TraceType
*   SpanType
*   ServiceName
*   Output
*   TraceName
*   ServiceId', example='ServiceId
ServiceName
Input
Output
Status
TraceType
SpanType
TraceName
SpanName'),
      operator?: string(name='Operator', description='The matching operator of the filter condition.

Valid values:

*   Contains
*   \\\\=
*   StartsWith', example='=
StartsWith
Contains'),
      value?: string(name='Value', description='The value of the filter condition.', example='foo'),
    }
  ](name='Filters', description='The evaluation task must search for a certain amount of trace data generated by the user application as input data for the evaluation. This list defines the search filter conditions.'),
  modelConfig?: ModelConfig(name='ModelConfig', description='The access configuration structure of the model used in the evaluation.'),
  samplingFrequencyMinutes?: int32(name='SamplingFrequencyMinutes', description='The evaluation task must search for a certain amount of trace data generated by the user application as input data for the evaluation. This is the width of the time window for each search of input data.', example='10'),
  samplingRatio?: int32(name='SamplingRatio', description='The percentage of data found in a time window that truly serves as evaluation input data. For example, 100 indicates that all data searched is used as evaluation input. 20 indicates that 20% of the found data is randomly selected as evaluation input.', example='50'),
  startTime?: string(name='StartTime', description='The start time of the trace data, in UTC format.', example='2024-07-31 08:30:00'),
  taskName?: string(name='TaskName', description='The task name.', example='foo model application performance evaluation'),
}

model UpdateOnlineEvalTaskResponseBody = {
  code?: string(name='Code', description='The internal error code. This parameter is returned only when an error occurs.', example='InvalidInputParams'),
  message?: string(name='Message', description='The error message. This parameter is returned only when an error occurs.', example='cannot modify a stopped task'),
  requestId?: string(name='RequestId', description='Id of the POP request', example='6A87228C-969A-1381-98CF-AE07AE630FA5'),
}

model UpdateOnlineEvalTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateOnlineEvalTaskResponseBody(name='body'),
}

/**
 * @summary Changes the configuration of a trace evaluation task.
 *
 * @param request UpdateOnlineEvalTaskRequest
 * @param headers map
 * @param runtime runtime options for this request RuntimeOptions
 * @return UpdateOnlineEvalTaskResponse
 */
async function updateOnlineEvalTaskWithOptions(TaskId: string, request: UpdateOnlineEvalTaskRequest, headers: map[string]string, runtime: Util.RuntimeOptions): UpdateOnlineEvalTaskResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.appName)) {
    body['AppName'] = request.appName;
  }
  if (!Util.isUnset(request.description)) {
    body['Description'] = request.description;
  }
  if (!Util.isUnset(request.endTime)) {
    body['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.evaluationConfig)) {
    body['EvaluationConfig'] = request.evaluationConfig;
  }
  if (!Util.isUnset(request.filters)) {
    body['Filters'] = request.filters;
  }
  if (!Util.isUnset(request.modelConfig)) {
    body['ModelConfig'] = request.modelConfig;
  }
  if (!Util.isUnset(request.samplingFrequencyMinutes)) {
    body['SamplingFrequencyMinutes'] = request.samplingFrequencyMinutes;
  }
  if (!Util.isUnset(request.samplingRatio)) {
    body['SamplingRatio'] = request.samplingRatio;
  }
  if (!Util.isUnset(request.startTime)) {
    body['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.taskName)) {
    body['TaskName'] = request.taskName;
  }

  var req = new OpenApi.OpenApiRequest{ 
    headers = headers,
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'UpdateOnlineEvalTask',
    version = '2024-03-11',
    protocol = 'HTTPS',
    pathname = `/api/v1/PAILLMTrace/onlineevaltasks/${OpenApiUtil.getEncodeParam(TaskId)}`,
    method = 'PUT',
    authType = 'AK',
    style = 'ROA',
    reqBodyType = 'json',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
 * @summary Changes the configuration of a trace evaluation task.
 *
 * @param request UpdateOnlineEvalTaskRequest
 * @return UpdateOnlineEvalTaskResponse
 */
async function updateOnlineEvalTask(TaskId: string, request: UpdateOnlineEvalTaskRequest): UpdateOnlineEvalTaskResponse {
  var runtime = new Util.RuntimeOptions{};
  var headers : map[string]string = {};
  return updateOnlineEvalTaskWithOptions(TaskId, request, headers, runtime);
}

