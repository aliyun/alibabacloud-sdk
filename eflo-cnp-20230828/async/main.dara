/**
  *
  */
import BaseClientBuilder;
import TeaAsyncHandler;
import TeaRequest;
import AsyncRequestBody;
import RequestBody;
import AsyncResponseHandler;
import ClientConfiguration;
import ClientExecutionParams;
extends BaseClientBuilder;
type @product = string
type @version = string
type @endpointRule = string
type @endpointMap = map[string]string
type @REQUEST = TeaRequest
type @handler = TeaAsyncHandler

init(configuration: ClientConfiguration){
  @handler = new TeaAsyncHandler(configuration);
  @product = 'eflo-cnp';
  @version = '2023-08-28';
  @endpointRule = '';
  @endpointMap = {
  };
}

function close(): void {
  @handler.close();
}

model ChangeResourceGroupRequest {
  regionId?: string(name='RegionId', description='Region Id', example='cn-shanghai', position='Query'),
  resourceGroupId: string(name='ResourceGroupId', description='The resource group id.

This parameter is required.', example='rg-aek25k3b4pbhc4a', position='Query'),
  resourceId: string(name='ResourceId', description='The resource id.

This parameter is required.', example='123', position='Query'),
  resourceType?: string(name='ResourceType', description='The resource type.', example='ExperimentPlan', position='Query'),
}

model ChangeResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='Request Id', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
}

model ChangeResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ChangeResourceGroupResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ChangeResourceGroup  ChangeResourceGroupRequest
  * @return ChangeResourceGroupResponse
 */
async function changeResourceGroup(request: ChangeResourceGroupRequest): ChangeResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ChangeResourceGroup', 'POST', '/', 'json', false, 'json', request);
}

model CheckServiceLinkedRoleEfloCnpForDeletingRequest {
  regionId?: string(name='RegionId', position='Host'),
  accountId?: string(name='AccountId', description='The ID of the cloud account.', example='345678901234', position='Query'),
  deletionTaskId?: string(name='DeletionTaskId', description='The ID of the deletion task.', example='task-003', position='Query'),
  roleArn?: string(name='RoleArn', description='The Alibaba Cloud Resource Name (ARN) of the RAM role.

The trusted entity of the RAM role is an Alibaba Cloud account. For more information, see [Create a RAM role for a trusted Alibaba Cloud account](https://help.aliyun.com/document_detail/93691.html) or [CreateRole](https://help.aliyun.com/document_detail/28710.html).

Format: `acs:ram::<account_id>:role/<role_name>`.

You can view the ARN in the RAM console or by calling operations. The following items describe the validity periods of storage addresses:

*   For more information about how to view the ARN in the RAM console, see [How do I find the ARN of the RAM role?](https://help.aliyun.com/document_detail/39744.html)
*   For more information about how to view the ARN by calling operations, see [ListRoles](https://help.aliyun.com/document_detail/28713.html) or [GetRole](https://help.aliyun.com/document_detail/28711.html).', example='arn:aws:iam::345678901234:role/eflo-cnp-role', position='Query'),
  SPIRegionId?: string(name='SPIRegionId', description='The ID of the region.', example='cn-hangzhou', position='Query'),
  serviceName?: string(name='ServiceName', description='The Service Name.', example='eflo-cnp', position='Query'),
}

model CheckServiceLinkedRoleEfloCnpForDeletingResponseBody = {
  deletable?: boolean(name='Deletable', description='Indicates whether the SLR can be deleted. Valid values:

*   `true`: The SLR can be deleted.
*   `false`: The SLR cannot be deleted.', example='True'),
  requestId?: string(name='RequestId', description='Request ID', example='6C212C4A-2CB3-56E6-BA2F-1CE2B03C5C94'),
  resources?: [ 
    {
      region?: string(name='Region', description='The region.', example='cn-beijing'),
      resources?: [ string ](name='Resources', description='The resources.'),
    }
  ](name='Resources', description='The resources.'),
}

model CheckServiceLinkedRoleEfloCnpForDeletingResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CheckServiceLinkedRoleEfloCnpForDeletingResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CheckServiceLinkedRoleEfloCnpForDeleting  CheckServiceLinkedRoleEfloCnpForDeletingRequest
  * @return CheckServiceLinkedRoleEfloCnpForDeletingResponse
 */
async function checkServiceLinkedRoleEfloCnpForDeleting(request: CheckServiceLinkedRoleEfloCnpForDeletingRequest): CheckServiceLinkedRoleEfloCnpForDeletingResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CheckServiceLinkedRoleEfloCnpForDeleting', 'POST', '/', 'json', false, 'json', request);
}

model CreateExperimentPlanRequest {
  regionId?: string(name='RegionId', position='Host'),
  externalParams?: map[string]any(name='ExternalParams', description='Additional parameters', example='{}', shrink='json', position='Query'),
  planTemplateName?: string(name='PlanTemplateName', description='Plan Template Name', example='test', position='Query'),
  resourceGroupId?: string(name='ResourceGroupId', description='Resource group ID', example='rg-aekzij65sf2rr5i', position='Query'),
  resourceId: long(name='ResourceId', description='Resource ID

This parameter is required.', example='189', position='Query'),
  tag?: [ 
    {
      key?: string(name='Key', description='Key', example='owner'),
      value?: string(name='Value', description='Value', example='test'),
    }
  ](name='Tag', description='Resource tags', position='Query'),
  templateId: long(name='TemplateId', description='Template ID

This parameter is required.', example='349623', position='Query'),
}

model CreateExperimentPlanResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: long(name='Data', description='Data', example='[]'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='Total count', example='0'),
}

model CreateExperimentPlanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateExperimentPlanResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateExperimentPlan  CreateExperimentPlanRequest
  * @return CreateExperimentPlanResponse
 */
async function createExperimentPlan(request: CreateExperimentPlanRequest): CreateExperimentPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateExperimentPlan', 'POST', '/', 'json', false, 'json', request);
}

model CreateExperimentPlanTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  privacyLevel: string(name='PrivacyLevel', description='Privacy Level

This parameter is required.', example='private', position='Query'),
  templateDescription?: string(name='TemplateDescription', description='Template Description', example='The template installs jdk and tomcat on a new ECS instance.', position='Query'),
  templateId?: long(name='TemplateId', description='Template ID', example='4724', position='Query'),
  templateName: string(name='TemplateName', description='Template Name

This parameter is required.', example='test', position='Query'),
  templatePipeline: [ 
    {
      envParams: {
        cpuPerWorker: int32(name='CpuPerWorker', description='CPU allocation count

This parameter is required.', example='90'),
        cudaVersion?: string(name='CudaVersion', description='CUDA Version', example='1.0.0'),
        gpuDriverVersion?: string(name='GpuDriverVersion', description='GPU Driver Version', example='1.0.0'),
        gpuPerWorker: int32(name='GpuPerWorker', description='GPU allocation count

This parameter is required.', example='8'),
        memoryPerWorker: int32(name='MemoryPerWorker', description='Memory (GB) allocation count

This parameter is required.', example='500'),
        NCCLVersion?: string(name='NCCLVersion', description='NCCL Version', example='1.0.0'),
        pyTorchVersion?: string(name='PyTorchVersion', description='PyTorch Version', example='1.0.0'),
        shareMemory: int32(name='ShareMemory', description='Shared Memory (GB) allocation count

This parameter is required.', example='500'),
        workerNum: int32(name='WorkerNum', description='Number of nodes

This parameter is required.', example='1'),
      }(name='EnvParams', description='Configured Environment Parameters

This parameter is required.'),
      pipelineOrder: int32(name='PipelineOrder', description='Node Order Number

This parameter is required.', example='1'),
      scene: string(name='Scene', description='Usage Scenario, e.g., "baseline"

This parameter is required.', example='baseline'),
      settingParams?: map[string]string(name='SettingParams', description='Configured Workload Parameters'),
      workloadId: long(name='WorkloadId', description='Workload ID

This parameter is required.', example='14'),
      workloadName: string(name='WorkloadName', description='Workload Name

This parameter is required.', example='test'),
    }
  ](name='TemplatePipeline', description='Template Pipeline

This parameter is required.', shrink='json', position='Body'),
}

model CreateExperimentPlanTemplateResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access Denied Detail', example='{}'),
  data?: {
    createTime?: string(name='CreateTime', description='Creation Time', example='2024-11-19T02:01:05Z'),
    creatorUid?: long(name='CreatorUid', description='Primary Account UID', example='12312312312312'),
    isDelete?: int32(name='IsDelete', description='Is Deleted', example='0'),
    privacyLevel?: string(name='PrivacyLevel', description='Privacy Level', example='private'),
    templateCode?: long(name='TemplateCode', description='Template Code', example='1'),
    templateDescription?: string(name='TemplateDescription', description='Template Description', example='test'),
    templateId?: long(name='TemplateId', description='Template ID', example='17615126'),
    templateName?: string(name='TemplateName', description='Template Name', example='test'),
    templatePipelineParam?: [ 
      {
        envParams?: {
          cpuPerWorker?: int32(name='CpuPerWorker', description='CPU Allocation', example='90'),
          cudaVersion?: string(name='CudaVersion', description='cudaVersion', example='1.0.0'),
          gpuDriverVersion?: string(name='GpuDriverVersion', description='GPU Driver Version', example='1.0.0'),
          gpuPerWorker?: int32(name='GpuPerWorker', description='GPU Allocation', example='8'),
          memoryPerWorker?: int32(name='MemoryPerWorker', description='Memory (GB) Allocation', example='500'),
          NCCLVersion?: string(name='NCCLVersion', description='NCCL Version', example='1.0.0'),
          pyTorchVersion?: string(name='PyTorchVersion', description='PyTorch Version', example='1.0.0'),
          shareMemory?: int32(name='ShareMemory', description='Shared Memory (GB) Allocation', example='500'),
          workerNum?: int32(name='WorkerNum', description='Number of Nodes', example='1'),
        }(name='EnvParams', description='Configured Environment Parameters'),
        pipelineOrder?: int32(name='PipelineOrder', description='Pipeline Order', example='1'),
        scene?: string(name='Scene', description='Usage Scenario, e.g., "baseline"', example='baseline'),
        settingParams?: map[string]string(name='SettingParams', description='Configured Workload Parameters'),
        workloadId?: long(name='WorkloadId', description='Workload ID', example='13'),
        workloadName?: string(name='WorkloadName', description='Workload Name', example='test'),
      }
    ](name='TemplatePipelineParam', description='Template Pipeline'),
    updateTime?: string(name='UpdateTime', description='Update Time', example='2023-10-16T01:58Z'),
    versionId?: long(name='VersionId', description='Version ID', example='1'),
  }(name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='total', example='0'),
}

model CreateExperimentPlanTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateExperimentPlanTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateExperimentPlanTemplate  CreateExperimentPlanTemplateRequest
  * @return CreateExperimentPlanTemplateResponse
 */
async function createExperimentPlanTemplate(request: CreateExperimentPlanTemplateRequest): CreateExperimentPlanTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateExperimentPlanTemplate', 'POST', '/', 'json', true, 'form', request);
}

model CreateResourceRequest {
  regionId?: string(name='RegionId', position='Host'),
  clusterDesc?: string(name='ClusterDesc', description='Cluster Description', example='ppu集群', position='Query'),
  clusterId: string(name='ClusterId', description='Cluster ID

This parameter is required.', example='ehpc-sh-fj71c0ycfw', position='Query'),
  clusterName: string(name='ClusterName', description='Cluster Name

This parameter is required.', example='tre-1-ppu', position='Query'),
  machineTypes: {
    bondNum?: int32(name='BondNum', description='Number of Network Bonds', example='5'),
    cpuInfo: string(name='CpuInfo', description='CPU Information

This parameter is required.', example='2x Intel Saphhire Rapid 8469C 48C CPU'),
    diskInfo?: string(name='DiskInfo', description='Disk Information', example='2x 480GB SATA SSD \\n 4x 3.84TB NVMe SSD'),
    gpuInfo: string(name='GpuInfo', description='GPU Information

This parameter is required.', example='8x NVIDIA SXM4 80GB A100 GPU'),
    memoryInfo?: string(name='MemoryInfo', description='Memory Information', example='32x 64GB DDR4 4800 Memory'),
    name?: string(name='Name', description='Specification Name', example='efg1.nvga1n'),
    networkInfo?: string(name='NetworkInfo', description='Network Information', example='1x 200Gbps Dual Port BF3 DPU for VPC\\\\n4x 200Gbps Dual Port EIC'),
    networkMode?: string(name='NetworkMode', description='Network Mode', example='2'),
    nodeCount?: int32(name='NodeCount', description='Number of Nodes', example='1'),
    type?: string(name='Type', description='Type', example='Private'),
  }(name='MachineTypes', description='Machine Types

This parameter is required.', shrink='json', position='Body'),
  userAccessParam: {
    accessId: string(name='AccessId', description='User ID

This parameter is required.', example='dev'),
    accessKey: string(name='AccessKey', description='User Key

This parameter is required.', example='test'),
    endpoint: string(name='Endpoint', description='Endpoint

This parameter is required.', example='test'),
    workspaceId: string(name='WorkspaceId', description='Workspace ID

This parameter is required.', example='1245688643'),
  }(name='UserAccessParam', description='User Access Parameters

This parameter is required.', shrink='json', position='Body'),
}

model CreateResourceResponseBody = {
  data?: long(name='Data', description='Data', example='[]'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='Total Count', example='0'),
}

model CreateResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateResource  CreateResourceRequest
  * @return CreateResourceResponse
 */
async function createResource(request: CreateResourceRequest): CreateResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateResource', 'POST', '/', 'json', true, 'form', request);
}

model DeleteExperimentRequest {
  regionId?: string(name='RegionId', position='Host'),
  experimentId: long(name='ExperimentId', description='Plan ID

This parameter is required.', example='234', position='Query'),
  resourceGroupId?: string(name='ResourceGroupId', description='Resource Group Id', example='rg-sdkfjgnvd24', position='Query'),
}

model DeleteExperimentResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: boolean(name='Data', description='Data', example='[]'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='Total count of queries', example='0'),
}

model DeleteExperimentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteExperimentResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteExperiment  DeleteExperimentRequest
  * @return DeleteExperimentResponse
 */
async function deleteExperiment(request: DeleteExperimentRequest): DeleteExperimentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteExperiment', 'POST', '/', 'json', false, 'json', request);
}

model DeleteExperimentPlanRequest {
  regionId?: string(name='RegionId', position='Host'),
  planId: long(name='PlanId', description='Plan ID

This parameter is required.', example='189', position='Query'),
}

model DeleteExperimentPlanResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: boolean(name='Data', description='Data', example='true'),
  requestId?: string(name='RequestId', description='Request ID', example='E67E2E4C-2B47-5C55-AA17-1D771E070AEF'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model DeleteExperimentPlanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteExperimentPlanResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteExperimentPlan  DeleteExperimentPlanRequest
  * @return DeleteExperimentPlanResponse
 */
async function deleteExperimentPlan(request: DeleteExperimentPlanRequest): DeleteExperimentPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteExperimentPlan', 'POST', '/', 'json', false, 'json', request);
}

model DeleteExperimentPlanTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  templateId: long(name='TemplateId', description='Template ID

This parameter is required.', example='346527', position='Query'),
}

model DeleteExperimentPlanTemplateResponseBody = {
  data?: boolean(name='Data', description='Data', example='[]'),
  requestId?: string(name='RequestId', description='Request ID', example='4D3FD55F-3BCD-5914-9B74-A1F4961327E7'),
  totalCount?: long(name='TotalCount', description='Total Count', example='0'),
}

model DeleteExperimentPlanTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteExperimentPlanTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteExperimentPlanTemplate  DeleteExperimentPlanTemplateRequest
  * @return DeleteExperimentPlanTemplateResponse
 */
async function deleteExperimentPlanTemplate(request: DeleteExperimentPlanTemplateRequest): DeleteExperimentPlanTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteExperimentPlanTemplate', 'POST', '/', 'json', false, 'json', request);
}

model GetExperimentRequest {
  regionId?: string(name='RegionId', position='Host'),
  experimentId: long(name='ExperimentId', description='Experiment ID

This parameter is required.', example='234', position='Query'),
  resourceGroupId?: string(name='ResourceGroupId', description='Resource Group Id', example='rg-sdsmfg23', position='Query'),
}

model GetExperimentResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied detail', example='{}'),
  data?: {
    createTime?: long(name='CreateTime', description='Creation time', example='2024-11-29 02:16:35'),
    endTime?: string(name='EndTime', description='Task end time', example='2024-11-29 02:26:35'),
    envParams?: {
      cpuPerWorker?: int32(name='CpuPerWorker', description='CPU allocation number', example='90'),
      cudaVersion?: string(name='CudaVersion', description='cudaVersion', example='1.0.0'),
      extendParam?: map[string]string(name='ExtendParam', description='Additional parameters'),
      gpuDriverVersion?: string(name='GpuDriverVersion', description='GPU driver version', example='1.0.0'),
      gpuPerWorker?: int32(name='GpuPerWorker', description='GPU allocation number', example='8'),
      memoryPerWorker?: int32(name='MemoryPerWorker', description='Memory Per Worker', example='500'),
      NCCLVersion?: string(name='NCCLVersion', description='NCCL version', example='1.0.0'),
      pyTorchVersion?: string(name='PyTorchVersion', description='PyTorch version', example='1.0.0'),
      resourceNodes?: [ 
        {
          nodeName?: string(name='NodeName', description='Node name', example='p-jt-waf-app1'),
          requestCPU?: int32(name='RequestCPU', description='Requested CPU', example='90'),
          requestGPU?: int32(name='RequestGPU', description='Requested GPU', example='8'),
          requestMemory?: int32(name='RequestMemory', description='Requested memory', example='500'),
          totalCPU?: int32(name='TotalCPU', description='Total CPU', example='90'),
          totalGPU?: int32(name='TotalGPU', description='Total GPU', example='8'),
          totalMemory?: long(name='TotalMemory', description='Total memory', example='500'),
        }
      ](name='ResourceNodes', description='Specified nodes'),
      shareMemory?: int32(name='ShareMemory', description='Share Memory', example='500'),
      workerNum?: int32(name='WorkerNum', description='Worker number', example='1'),
    }(name='EnvParams', description='Running environment parameters'),
    experimentId?: long(name='ExperimentId', description='Experiment ID', example='1726882991828688898'),
    experimentName?: string(name='ExperimentName', description='Experiment name', example='test'),
    experimentType?: string(name='ExperimentType', description='Experiment type', example='AI'),
    getParams?: map[string]string(name='GetParams', description='Parsed workload parameters'),
    resource?: {
      cpuCoreLimit?: int32(name='CpuCoreLimit', description='Used CPU', example='90'),
      gpuLimit?: int32(name='GpuLimit', description='Used GPU', example='8'),
      machineType?: {
        bondNum?: int32(name='BondNum', description='Number of network bonds', example='5'),
        cpuInfo?: string(name='CpuInfo', description='CPU information', example='2x Intel Icelake 8369B 32C CPU'),
        diskInfo?: string(name='DiskInfo', description='Disk information', example='2x 480GB SATA SSD \\n 4x 3.84TB NVMe SSD'),
        gpuInfo?: string(name='GpuInfo', description='GPU information', example='8x NVIDIA SXM4 80GB A100 GPU'),
        memoryInfo?: string(name='MemoryInfo', description='Memory information', example='32x 64GB DDR4 3200 Memory'),
        name?: string(name='Name', description='Specification name', example='efg1.nvga1n'),
        networkInfo?: string(name='NetworkInfo', description='Network information', example='1x 100Gbps DP NIC for VPC \\n 4x 100Gbps DP RoCE NIC'),
        networkMode?: string(name='NetworkMode', description='Network mode', example='2'),
        nodeCount?: int32(name='NodeCount', description='Number of nodes', example='1'),
        type?: string(name='Type', description='Type', example='Public'),
      }(name='MachineType', description='Instance type'),
      maxCpuCore?: int32(name='MaxCpuCore', description='Used memory', example='90'),
      maxGpu?: int32(name='MaxGpu', description='Used memory', example='8'),
      maxMemory?: long(name='MaxMemory', description='Used memory', example='500'),
      memoryLimit?: long(name='MemoryLimit', description='Used memory', example='500'),
      resourceId?: long(name='ResourceId', description='Cluster ID', example='189'),
      resourceName?: string(name='ResourceName', description='Cluster name', example='ecs.r8y.4xlarge'),
      resourceNodes?: [ 
        {
          nodeName?: string(name='NodeName', description='Node name', example='InputCheck'),
        }
      ](name='ResourceNodes', description='Resource node list'),
      userAccessParam?: {
        accessId?: string(name='AccessId', description='User ID', example='dev'),
        accessKey?: string(name='AccessKey', description='User key', example='test'),
        endpoint?: string(name='Endpoint', description='Endpoint', example='test'),
        workspaceId?: string(name='WorkspaceId', description='Workspace ID', example='123434542498'),
      }(name='UserAccessParam', description='User authorization parameters'),
    }(name='Resource', description='cluster info'),
    resourceName?: string(name='ResourceName', description='Resource name', example='cifnews-guoyuan'),
    results?: {
      duration?: double(name='Duration', description='Duration', example='764'),
      errorWorker?: [ 
        {
          errorFlag?: boolean(name='ErrorFlag', description='error flag', example='true'),
          errorMsg?: string(name='ErrorMsg', description='error message', example='Connection reset'),
          experimentId?: long(name='ExperimentId', description='Experiment ID', example='97'),
          gpuName?: string(name='GpuName', description='GPU name', example='8x OAM 810 GPU'),
          gpuNum?: int32(name='GpuNum', description='Number of GPUs', example='8'),
          hostname?: string(name='Hostname', description='Service address', example='60.188.98.209'),
          podName?: string(name='PodName', description='Pod name.', example='hzs-forge-sdxl-online-7ff4d86444-pc95h'),
          samplesPerSecond?: double(name='SamplesPerSecond', description='Samples Per Second', example='23'),
          tflops?: double(name='Tflops', description='TFLOPS', example='12'),
          warningFlag?: boolean(name='WarningFlag', description='Whether there is a warning', example='false'),
          warningMsg?: string(name='WarningMsg', description='Warning message', example='warning message'),
        }
      ](name='ErrorWorker', description='Error node'),
      experimentId?: long(name='ExperimentId', description='Parameter name', example='1748274952976261121'),
      mfu?: double(name='Mfu', description='MFU', example='54.2'),
      samplesPerSecond?: double(name='SamplesPerSecond', description='Samples Per Second', example='10'),
      secondsPerIteration?: double(name='SecondsPerIteration', description='Seconds per iteration', example='1000'),
      taskIndividualResultList?: [ 
        {
          errorFlag?: boolean(name='ErrorFlag', description='Whether there is an error', example='false'),
          errorMsg?: string(name='ErrorMsg', description='Error message', example='error message'),
          experimentId?: long(name='ExperimentId', description='实验ID。', example='48'),
          gpuName?: string(name='GpuName', description='GPU name', example='8x OAM 810 GPU'),
          gpuNum?: int32(name='GpuNum', description='Number of GPUs', example='8'),
          hostname?: string(name='Hostname', description='节点主机名称。', example='p-jt-waf-app1'),
          podName?: string(name='PodName', description='Pod名称。', example='fluxserv-6fc89b45cf-w8wq6'),
          samplesPerSecond?: double(name='SamplesPerSecond', description='Throughput', example='28'),
          tflops?: double(name='Tflops', description='TFLOPS value', example='16'),
          warningFlag?: boolean(name='WarningFlag', description='Whether there is a warning', example='false'),
          warningMsg?: string(name='WarningMsg', description='Warning message', example='warning message'),
        }
      ](name='TaskIndividualResultList', description='Task individual result list'),
      taskIndividualResultMap?: map[string][ DataResultsTaskIndividualResultMapValue       ](name='TaskIndividualResultMap', description='Invalid task results'),
      warningBoundList?: [ 
        {
          iteration?: int32(name='Iteration', description='Iteration', example='10'),
          lower?: double(name='Lower', description='LOWER', example='14'),
          upper?: double(name='Upper', description='UPPER', example='56'),
        }
      ](name='WarningBoundList', description='Warning bound list'),
      warningWorker?: [ 
        {
          errorFlag?: boolean(name='ErrorFlag', description='Whether there is an error', example='true'),
          errorMsg?: string(name='ErrorMsg', description='Error message', example='error message'),
          experimentId?: long(name='ExperimentId', description='Experiment ID', example='9'),
          gpuName?: string(name='GpuName', description='GPU name', example='8x OAM 810 GPU'),
          gpuNum?: int32(name='GpuNum', description='Number of GPUs', example='8'),
          hostname?: string(name='Hostname', description='Service address', example='whza008403'),
          podName?: string(name='PodName', description='Pod name.', example='fluxserv-6fc89b45cf-w8wq6'),
          samplesPerSecond?: double(name='SamplesPerSecond', description='Throughput', example='15'),
          tflops?: double(name='Tflops', description='TFLOPS value', example='14'),
          warningFlag?: boolean(name='WarningFlag', description='Whether there is an alarm', example='true'),
          warningMsg?: string(name='WarningMsg', description='Alarm message', example='warging message'),
        }
      ](name='WarningWorker', description='Warning worker'),
    }(name='Results', description='Task results'),
    setParams?: map[string]string(name='SetParams', description='Running workload parameters'),
    startTime?: string(name='StartTime', description='Task start time', example='2024-11-29 02:16:35'),
    status?: string(name='Status', description='Status', example='RUNNING'),
    task?: {
      createTime?: long(name='CreateTime', description='Creation time', example='2024-03-05 18:24:08'),
      endTime?: long(name='EndTime', description='End time', example='2024-03-05 18:34:08'),
      params?: map[string]string(name='Params', description='Experiment parameters'),
      scene?: string(name='Scene', description='Scene', example='baseline'),
      startTime?: long(name='StartTime', description='Start time', example='2024-03-05 18:24:08'),
      status?: string(name='Status', description='Status', example='success'),
      taskId?: long(name='TaskId', description='Task ID', example='167420'),
      updateTime?: long(name='UpdateTime', description='Update time', example='2024-03-05 18:24:08'),
    }(name='Task', description='Experiment task'),
    updateTime?: long(name='UpdateTime', description='Update time', example='2024-11-29 02:16:35'),
    workload?: {
      defaultCpuPerWorker?: int32(name='DefaultCpuPerWorker', description='Default CPU allocation', example='90'),
      defaultGpuPerWorker?: int32(name='DefaultGpuPerWorker', description='Default GPU allocation', example='8'),
      defaultMemoryPerWorker?: int32(name='DefaultMemoryPerWorker', description='Default memory (GB) allocation', example='500'),
      defaultShareMemory?: int32(name='DefaultShareMemory', description='Default shared memory (GB) allocation', example='500'),
      family?: string(name='Family', description='Workload cluster, AI, GPU', example='AI'),
      jobKind?: string(name='JobKind', description='JobKind', example='PyTorchJob'),
      paramSettings?: [ 
        {
          defaultValue?: string(name='DefaultValue', description='Default parameter value', example='100'),
          paramDesc?: string(name='ParamDesc', description='Parameter description', example='number'),
          paramName?: string(name='ParamName', description='Parameter name', example='ITERATION'),
          paramRegex?: string(name='ParamRegex', description='Parameter regular expression', example='[0-9]+'),
          paramType?: string(name='ParamType', description='Parameter type', example='number'),
          paramValue?: string(name='ParamValue', description='Parameter value', example='100'),
        }
      ](name='ParamSettings', description='Parameter settings'),
      scene?: string(name='Scene', description='Workload usage scenario', example='NLP-LLM'),
      scope?: string(name='Scope', description='Scope', example='common'),
      staticConfig?: {
        frameWork?: string(name='FrameWork', description='Framework', example='pyTorch'),
        os?: string(name='Os', description='Operating system', example='linux'),
        parameters?: string(name='Parameters', description='Number of parameters', example='7B'),
        softwareStack?: string(name='SoftwareStack', description='Software stack', example='python'),
      }(name='StaticConfig', description='Static configuration'),
      versionId?: long(name='VersionId', description='Version ID', example='1'),
      workloadDescription?: string(name='WorkloadDescription', description='Workload description', example='test'),
      workloadId?: long(name='WorkloadId', description='Workload ID', example='13'),
      workloadName?: string(name='WorkloadName', description='Workload name', example='test'),
      workloadType?: string(name='WorkloadType', description='Workload name', example='AI'),
    }(name='Workload', description='Workload information'),
    workloadName?: string(name='WorkloadName', description='Workload name', example='test'),
  }(name='Data', description='Data'),
  requestId?: string(name='RequestId', description='RequestId', example='E67E2E4C-2B47-5C55-AA17-1D771E070AEF'),
  totalCount?: long(name='TotalCount', description='total', example='0'),
}

model GetExperimentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetExperimentResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetExperiment  GetExperimentRequest
  * @return GetExperimentResponse
 */
async function getExperiment(request: GetExperimentRequest): GetExperimentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetExperiment', 'POST', '/', 'json', false, 'json', request);
}

model GetExperimentPlanRequest {
  regionId?: string(name='RegionId', position='Host'),
  planId: long(name='PlanId', description='Plan ID

This parameter is required.', example='189', position='Query'),
}

model GetExperimentPlanResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: {
    createTime?: string(name='CreateTime', description='Creation time', example='2024-07-07 02:08:54'),
    planId?: long(name='PlanId', description='Plan ID', example='189'),
    planPipeline?: [ 
      {
        envParams?: {
          cpuPerWorker?: int32(name='CpuPerWorker', description='CPU allocation', example='90'),
          cudaVersion?: string(name='CudaVersion', description='CUDA version', example='1.0.0'),
          extendParam?: map[string]string(name='ExtendParam', description='Additional parameters'),
          gpuDriverVersion?: string(name='GpuDriverVersion', description='GPU driver version', example='1.0.0'),
          gpuPerWorker?: int32(name='GpuPerWorker', description='Number of GPUs allocated', example='8'),
          memoryPerWorker?: int32(name='MemoryPerWorker', description='Memory GB allocation', example='500'),
          NCCLVersion?: string(name='NCCLVersion', description='NCCL version', example='1.0.0'),
          pyTorchVersion?: string(name='PyTorchVersion', description='PyTorch version', example='1.0.0'),
          resourceNodes?: [ 
            {
              nodeName?: string(name='NodeName', description='Node name', example='ods_galaxy_gateway_tickets'),
              requestCPU?: int32(name='RequestCPU', description='Requested CPU', example='90'),
              requestGPU?: int32(name='RequestGPU', description='Requested GPU', example='8'),
              requestMemory?: int32(name='RequestMemory', description='Memory of the current request', example='500'),
              totalCPU?: int32(name='TotalCPU', description='Total CPU', example='90'),
              totalGPU?: int32(name='TotalGPU', description='Total GPU', example='8'),
              totalMemory?: long(name='TotalMemory', description='Total memory', example='500'),
            }
          ](name='ResourceNodes', description='Specified nodes'),
          shareMemory?: int32(name='ShareMemory', description='Shared memory GB allocation', example='500'),
          workerNum?: int32(name='WorkerNum', description='Number of nodes', example='1'),
        }(name='EnvParams', description='Configured environment parameters'),
        pipelineOrder?: int32(name='PipelineOrder', description='Node order number', example='1'),
        resourceId?: long(name='ResourceId', description='Resource ID', example='36'),
        resourceName?: string(name='ResourceName', description='Resource name', example='PPU'),
        scene?: string(name='Scene', description='Usage scenario, e.g., "baseline"', example='baseline'),
        settingParams?: map[string]string(name='SettingParams', description='Configured workload parameters'),
        workloadId?: long(name='WorkloadId', description='Workload ID', example='14'),
        workloadName?: string(name='WorkloadName', description='Workload name', example='test'),
      }
    ](name='PlanPipeline', description='Test plan pipeline'),
    resourceGroupId?: string(name='ResourceGroupId', description='Resource group ID', example='rg-acfmvmpzi7lmxhq'),
    resourceId?: long(name='ResourceId', description='Associated resource ID', example='260860230684'),
    tags?: [ 
      {
        tagKey?: string(name='TagKey', description='The tag key.', example='acs:testLXP:test-quota40-19'),
        tagValue?: string(name='TagValue', description='The tag value.', example='000088aabb0019e4'),
      }
    ](name='Tags', description='The tag.'),
    templateId?: long(name='TemplateId', description='Associated test plan template ID', example='2162'),
    templateName?: string(name='TemplateName', description='Associated test plan template name', example='MM'),
    updateTime?: string(name='UpdateTime', description='Update time', example='2024-07-07 02:08:54'),
  }(name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='6DBAC169-93D1-5DCD-8109-30FB623B3197'),
  totalCount?: long(name='TotalCount', description='Total count of the query', example='0'),
}

model GetExperimentPlanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetExperimentPlanResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetExperimentPlan  GetExperimentPlanRequest
  * @return GetExperimentPlanResponse
 */
async function getExperimentPlan(request: GetExperimentPlanRequest): GetExperimentPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetExperimentPlan', 'POST', '/', 'json', false, 'json', request);
}

model GetExperimentPlanTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  templateId: long(name='TemplateId', description='Template ID

This parameter is required.', example='315797', position='Query'),
}

model GetExperimentPlanTemplateResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: {
    createTime?: string(name='CreateTime', description='Creation Time', example='2024-11-29 02:16:35'),
    creatorUid?: long(name='CreatorUid', description='Primary account UID', example='12312312312312'),
    isDelete?: int32(name='IsDelete', description='Whether deleted', example='0'),
    privacyLevel?: string(name='PrivacyLevel', description='Privacy Level', example='private'),
    templateCode?: long(name='TemplateCode', description='Template Code', example='464086216'),
    templateDescription?: string(name='TemplateDescription', description='Template Description', example='test'),
    templateId?: long(name='TemplateId', description='Template ID', example='17615126'),
    templateName?: string(name='TemplateName', description='Template Name', example='Test'),
    templatePipelineParam?: [ 
      {
        envParams?: {
          cpuPerWorker?: int32(name='CpuPerWorker', description='CPU allocation', example='90'),
          cudaVersion?: string(name='CudaVersion', description='CUDA version', example='1.0.0'),
          extendParam?: map[string]string(name='ExtendParam', description='Additional parameters'),
          gpuDriverVersion?: string(name='GpuDriverVersion', description='GPU driver version', example='1.0.0'),
          gpuPerWorker?: int32(name='GpuPerWorker', description='GPU allocation', example='8'),
          memoryPerWorker?: int32(name='MemoryPerWorker', description='Allocated memory in GB', example='500'),
          NCCLVersion?: string(name='NCCLVersion', description='NCCL version', example='1.0.0'),
          pyTorchVersion?: string(name='PyTorchVersion', description='PyTorch version', example='1.0.0'),
          resourceNodes?: [ 
            {
              nodeName?: string(name='NodeName', description='Node name', example='exclusive_coud'),
              requestCPU?: int32(name='RequestCPU', description='当前请求的cpu', example='10'),
              requestGPU?: int32(name='RequestGPU', description='Requested GPU', example='10'),
              requestMemory?: int32(name='RequestMemory', description='Requested memory', example='1024'),
              totalCPU?: int32(name='TotalCPU', description='Total CPU', example='100'),
              totalGPU?: int32(name='TotalGPU', description='Total GPU', example='100'),
              totalMemory?: long(name='TotalMemory', description='Total memory', example='2048'),
            }
          ](name='ResourceNodes', description='Specified nodes'),
          shareMemory?: int32(name='ShareMemory', description='Shared memory in GB', example='500'),
          workerNum?: int32(name='WorkerNum', description='Number of nodes', example='1'),
        }(name='EnvParams', description='Configured environment parameters'),
        pipelineOrder?: int32(name='PipelineOrder', description='Node sequence number', example='1'),
        scene?: string(name='Scene', description='Usage scenario, e.g., "baseline"', example='baseline'),
        settingParams?: map[string]string(name='SettingParams', description='Configured workload parameters'),
        workloadId?: long(name='WorkloadId', description='Workload ID', example='13'),
        workloadName?: string(name='WorkloadName', description='Workload Name', example='test'),
      }
    ](name='TemplatePipelineParam', description='Template Pipeline'),
    updateTime?: string(name='UpdateTime', description='Update Time', example='2024-10-22 10:18:10'),
    versionId?: long(name='VersionId', description='Version ID', example='1'),
  }(name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model GetExperimentPlanTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetExperimentPlanTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetExperimentPlanTemplate  GetExperimentPlanTemplateRequest
  * @return GetExperimentPlanTemplateResponse
 */
async function getExperimentPlanTemplate(request: GetExperimentPlanTemplateRequest): GetExperimentPlanTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetExperimentPlanTemplate', 'POST', '/', 'json', false, 'json', request);
}

model GetExperimentResultDataRequest {
  regionId?: string(name='RegionId', position='Host'),
  experimentId: long(name='ExperimentId', description='Experiment ID

This parameter is required.', example='234', position='Query'),
  hostname?: string(name='Hostname', description='Hostname', example='iZj6ccwd7zwfms7hzaz2riZ', position='Query'),
  resourceGroupId?: string(name='ResourceGroupId', description='Resource Group Id', example='rg-sfjgskdfj3k4', position='Query'),
  workloadType?: string(name='WorkloadType', description='Workload Type', example='AI', position='Query'),
}

model GetExperimentResultDataResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access Denied Details', example='{}'),
  data?: [ 
    {
      gpuNum?: string(name='GpuNum', description='Number of GPUs', example='8'),
      hostname?: string(name='Hostname', description='Host IP', example='p-jt-waf-app1'),
      metricsInfos?: [ 
        {
          gpuNum?: string(name='Gpu_num', description='GPU', example='8'),
          iteration?: long(name='Iteration', description='Iteration', example='100'),
          tflops?: double(name='Tflops', description='TFLOPS', example='43'),
          timestamp?: long(name='Timestamp', description='Operation Timestamp', example='1715393860'),
          value?: double(name='Value', description='Metric Value', example='126'),
        }
      ](name='MetricsInfos', description='List of Metrics Information'),
      podName?: string(name='PodName', description='Pod Name', example='hzs-forge-sdxl-online-7ff4d86444-pc95h'),
    }
  ](name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='C1D34EC2-AB13-56F4-8322-F15AE563EA04'),
  totalCount?: long(name='TotalCount', description='Total Count of Queries', example='0'),
}

model GetExperimentResultDataResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetExperimentResultDataResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetExperimentResultData  GetExperimentResultDataRequest
  * @return GetExperimentResultDataResponse
 */
async function getExperimentResultData(request: GetExperimentResultDataRequest): GetExperimentResultDataResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetExperimentResultData', 'POST', '/', 'json', false, 'json', request);
}

model GetResourceRequest {
  regionId?: string(name='RegionId', position='Host'),
  clusterId: string(name='ClusterId', description='The cluster ID of Lingjun

This parameter is required.', example='ehpc-bj-uo8f26cpmo', position='Query'),
}

model GetResourceResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: {
    clusterDesc?: string(name='ClusterDesc', description='Cluster description', example='test'),
    clusterId?: string(name='ClusterId', description='Cluster ID', example='3123121223'),
    clusterName?: string(name='ClusterName', description='Cluster name', example='main_cluster'),
    cpuCoreLimit?: int32(name='CpuCoreLimit', description='Used CPU', example='90'),
    gpuLimit?: int32(name='GpuLimit', description='Used GPU', example='8'),
    machineType?: {
      bondNum?: int32(name='BondNum', description='Number of network bonds', example='5'),
      cpuInfo?: string(name='CpuInfo', description='CPU information', example='2x Intel Saphhire Rapid 8469C 48C CPU'),
      diskInfo?: string(name='DiskInfo', description='Disk information', example='2x 480GB SATA SSD\\n4x 3.84TB NVMe SSD'),
      gpuInfo?: string(name='GpuInfo', description='GPU information', example='8x OAM 810 GPU'),
      memoryInfo?: string(name='MemoryInfo', description='Memory information', example='32x 64GB DDR4 4800 Memory'),
      name?: string(name='Name', description='Specification name', example='efg2.p8en'),
      networkInfo?: string(name='NetworkInfo', description='Network information', example='1x 200Gbps Dual Port BF3 DPU for VPC\\n4x 200Gbps Dual Port EIC'),
      networkMode?: string(name='NetworkMode', description='Network mode', example='2'),
      nodeCount?: int32(name='NodeCount', description='Number of nodes', example='1'),
      type?: string(name='Type', description='Type', example='Private'),
    }(name='MachineType', description='Machine type'),
    maxCpuCore?: int32(name='MaxCpuCore', description='Used memory', example='90'),
    maxGpu?: int32(name='MaxGpu', description='Used memory', example='8'),
    maxMemory?: long(name='MaxMemory', description='Used memory', example='500'),
    memoryLimit?: long(name='MemoryLimit', description='Used memory', example='500'),
    resourceId?: long(name='ResourceId', description='Cluster ID', example='189'),
    resourceNodes?: [ 
      {
        nodeName?: string(name='NodeName', description='Node name', example='lingj19q90jp66nq-mg2pa0p2l2bipnsi-17'),
      }
    ](name='ResourceNodes', description='List of resource nodes'),
    userAccessParam?: {
      accessId?: string(name='AccessId', description='User ID', example='dev'),
      accessKey?: string(name='AccessKey', description='User key', example='test'),
      endpoint?: string(name='Endpoint', description='Endpoint', example='test'),
      workspaceId?: string(name='WorkspaceId', description='Workspace ID', example='test'),
    }(name='UserAccessParam', description='User authorization parameters'),
  }(name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='25859897-35C8-5015-8365-7A3CE52F4854'),
  totalCount?: long(name='TotalCount', description='Total count of the query', example='0'),
}

model GetResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetResource  GetResourceRequest
  * @return GetResourceResponse
 */
async function getResource(request: GetResourceRequest): GetResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetResource', 'POST', '/', 'json', false, 'json', request);
}

model GetResourcePredictResultRequest {
  regionId?: string(name='RegionId', position='Host'),
  resourceId?: long(name='ResourceId', description='Resource ID', example='36', position='Query'),
  templateId: long(name='TemplateId', description='Template ID

This parameter is required.', example='315797', position='Query'),
}

model GetResourcePredictResultResponseBody = {
  data?: long(name='Data', description='Data', example='2'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='total', example='1'),
}

model GetResourcePredictResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetResourcePredictResultResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetResourcePredictResult  GetResourcePredictResultRequest
  * @return GetResourcePredictResultResponse
 */
async function getResourcePredictResult(request: GetResourcePredictResultRequest): GetResourcePredictResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetResourcePredictResult', 'POST', '/', 'json', false, 'json', request);
}

model GetWorkloadRequest {
  regionId?: string(name='RegionId', position='Host'),
  workloadId: long(name='WorkloadId', description='Workload ID

This parameter is required.', example='13', position='Query'),
}

model GetWorkloadResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access Denied Information', example='{}'),
  data?: {
    defaultCpuPerWorker?: int32(name='DefaultCpuPerWorker', description='Default CPU Allocation per Worker', example='90'),
    defaultGpuPerWorker?: int32(name='DefaultGpuPerWorker', description='Default GPU Allocation per Worker', example='8'),
    defaultMemoryPerWorker?: int32(name='DefaultMemoryPerWorker', description='Default Memory (GB) Allocation per Worker', example='500'),
    defaultShareMemory?: int32(name='DefaultShareMemory', description='Default Shared Memory (GB) Allocation', example='500'),
    family?: string(name='Family', description='Workload Cluster, e.g., AI, GPU', example='AI'),
    jobKind?: string(name='JobKind', description='Training Job Type', example='PyTorchJob'),
    paramSettings?: [ 
      {
        defaultValue?: string(name='DefaultValue', description='Default Parameter Value', example='100'),
        paramDesc?: string(name='ParamDesc', description='Parameter Description', example='number'),
        paramName?: string(name='ParamName', description='Parameter Name', example='ITERATION'),
        paramRegex?: string(name='ParamRegex', description='Parameter Regular Expression', example='[0-9]+'),
        paramType?: string(name='ParamType', description='Parameter type', example='number'),
        paramValue?: string(name='ParamValue', description='Parameter Value', example='100'),
      }
    ](name='ParamSettings', description='Parameter Settings'),
    scene?: string(name='Scene', description='Workload Usage Scenario', example='NLP-LLM'),
    scope?: string(name='Scope', description='Scope Identifier for Workload Usage', example='common'),
    staticConfig?: {
      frameWork?: string(name='FrameWork', description='Framework', example='PyTorch'),
      os?: string(name='Os', description='Operating System', example='linux'),
      parameters?: string(name='Parameters', description='Parameter Volume', example='7B'),
      softwareStack?: string(name='SoftwareStack', description='Software Stack', example='python'),
    }(name='StaticConfig', description='Static Configuration'),
    versionId?: long(name='VersionId', description='Version ID', example='1'),
    workloadDescription?: string(name='WorkloadDescription', description='Workload Description', example='test'),
    workloadId?: long(name='WorkloadId', description='Workload ID', example='13'),
    workloadName?: string(name='WorkloadName', description='Workload Name', example='test'),
    workloadType?: string(name='WorkloadType', description='Workload Type', example='AI'),
  }(name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='E67E2E4C-2B47-5C55-AA17-1D771E070AEF'),
  totalCount?: long(name='TotalCount', description='total', example='0'),
}

model GetWorkloadResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkloadResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetWorkload  GetWorkloadRequest
  * @return GetWorkloadResponse
 */
async function getWorkload(request: GetWorkloadRequest): GetWorkloadResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetWorkload', 'POST', '/', 'json', false, 'json', request);
}

model ListExperimentPlanTemplatesRequest {
  regionId?: string(name='RegionId', position='Host'),
  privacyLevel?: string(name='PrivacyLevel', description='The sharing level of the template, default is private, options are public and private.', example='private', position='Query'),
}

model ListExperimentPlanTemplatesResponseBody = {
  data?: [ 
    {
      createTime?: string(name='CreateTime', description='Creation time', example='2024-11-29 02:16:35'),
      creatorUid?: long(name='CreatorUid', description='Primary account UID', example='178154411231232'),
      isDelete?: int32(name='IsDelete', description='Whether it is deleted', example='0'),
      privacyLevel?: string(name='PrivacyLevel', description='Privacy level', example='private'),
      templateCode?: long(name='TemplateCode', description='The template code.', example='475315534'),
      templateDescription?: string(name='TemplateDescription', description='Template description', example='test'),
      templateId?: long(name='TemplateId', description='Template ID', example='17815441'),
      templateName?: string(name='TemplateName', description='Template name', example='test'),
      templatePipelineParam?: [ 
        {
          envParams?: {
            cpuPerWorker?: int32(name='CpuPerWorker', description='CPU allocation', example='90'),
            cudaVersion?: string(name='CudaVersion', description='Cuda Version', example='1.0.0'),
            gpuDriverVersion?: string(name='GpuDriverVersion', description='The version of the GPU driver.', example='1.0.0'),
            gpuPerWorker?: int32(name='GpuPerWorker', description='GPU allocation', example='8'),
            memoryPerWorker?: int32(name='MemoryPerWorker', description='Allocated memory in GB', example='500'),
            NCCLVersion?: string(name='NCCLVersion', description='NCCL Version', example='1.0.0'),
            pyTorchVersion?: string(name='PyTorchVersion', description='PyTorch Version', example='1.0.0'),
            shareMemory?: int32(name='ShareMemory', description='Allocated shared memory in GB', example='500'),
            workerNum?: int32(name='WorkerNum', description='Number of nodes', example='1'),
          }(name='EnvParams', description='Configured environment parameters'),
          pipelineOrder?: int32(name='PipelineOrder', description='Node sequence number', example='1'),
          scene?: string(name='Scene', description='Usage scenario, e.g., "baseline"', example='baseline'),
          settingParams?: map[string]string(name='SettingParams', description='Configured workload parameters'),
          workloadId?: long(name='WorkloadId', description='Workload ID', example='13'),
          workloadName?: string(name='WorkloadName', description='Workload name', example='test'),
        }
      ](name='TemplatePipelineParam', description='Template pipeline'),
      updateTime?: string(name='UpdateTime', description='Update time', example='2024-11-29 02:16:35'),
      versionId?: long(name='VersionId', description='Version ID', example='1'),
    }
  ](name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='AAE4AFED-7AE6-52FA-80B6-448E63760552'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model ListExperimentPlanTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListExperimentPlanTemplatesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListExperimentPlanTemplates  ListExperimentPlanTemplatesRequest
  * @return ListExperimentPlanTemplatesResponse
 */
async function listExperimentPlanTemplates(request: ListExperimentPlanTemplatesRequest): ListExperimentPlanTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListExperimentPlanTemplates', 'POST', '/', 'json', false, 'json', request);
}

model ListExperimentPlansRequest {
  regionId?: string(name='RegionId', position='Host'),
  creatTimeOrder?: string(name='CreatTimeOrder', description='Creation Time Sorting Rule', example='desc', position='Query'),
  endTimeOrder?: string(name='EndTimeOrder', description='End Time Sorting Rule', example='desc', position='Query'),
  page?: int32(name='Page', description='Page Number', example='1', position='Query'),
  planTaskStatus?: [ string ](name='PlanTaskStatus', description='Execution Status', shrink='json', position='Body'),
  resourceGroupId?: string(name='ResourceGroupId', description='Resource Group ID', example='rg-aekzij65sf2rr5i', position='Query'),
  resourceId?: long(name='ResourceId', description='Resource ID', example='189', position='Query'),
  resourceName?: [ string ](name='ResourceName', description='Resource', shrink='json', position='Body'),
  size?: int32(name='Size', description='Number of Items', example='100', position='Query'),
  startTimeOrder?: string(name='StartTimeOrder', description='Start Time Sorting Rule', example='desc', position='Query'),
  tag?: [ 
    {
      key?: string(name='Key', description='The tag key.', example='owner'),
      value?: string(name='Value', description='Tag value', example='test'),
    }
  ](name='Tag', description='The tags.', shrink='json', position='Query'),
  templateId?: long(name='TemplateId', description='Template Id', example='96', position='Query'),
}

model ListExperimentPlansResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access Denied Detail', example='{}'),
  data?: [ 
    {
      createTime?: string(name='CreateTime', description='Creation Time', example='2024-07-08 10:12:42'),
      endTime?: string(name='EndTime', description='End Time', example='2024-07-08 10:22:42'),
      planId?: long(name='PlanId', description='Plan ID', example='189'),
      planTaskStatus?: map[string]int32(name='PlanTaskStatus', description='Test Plan Execution Status'),
      resourceGroupId?: string(name='ResourceGroupId', description='Resource Group ID', example='rg-aek5behqmwbfhuy'),
      resourceId?: long(name='ResourceId', description='The resource ID.', example='189'),
      resourceName?: string(name='ResourceName', description='Associated Resource Name', example='q_ecs_xpec_postpay_c'),
      startTime?: string(name='StartTime', description='Start Time', example='2024-07-08 10:12:42'),
      tags?: [ 
        {
          tagKey?: string(name='TagKey', description='The tag key.', example='owner'),
          tagValue?: string(name='TagValue', description='The tag value.', example='test'),
        }
      ](name='Tags', description='The tag.'),
      templateId?: long(name='TemplateId', description='Associated Test Plan Template ID', example='6'),
      templateName?: string(name='TemplateName', description='Associated Test Plan Template Name', example='test'),
      updateTime?: string(name='UpdateTime', description='Update Time', example='2024-07-08 10:12:42'),
    }
  ](name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='FA9F1DE7-103B-5C18-AE9E-EB2BFF11C685'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model ListExperimentPlansResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListExperimentPlansResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListExperimentPlans  ListExperimentPlansRequest
  * @return ListExperimentPlansResponse
 */
async function listExperimentPlans(request: ListExperimentPlansRequest): ListExperimentPlansResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListExperimentPlans', 'POST', '/', 'json', true, 'form', request);
}

model ListExperimentsRequest {
  regionId?: string(name='RegionId', position='Host'),
  order?: int32(name='Order', description='Order', example='1', position='Query'),
  planId?: long(name='PlanId', description='Plan ID', example='189', position='Query'),
  resourceGroupId?: string(name='ResourceGroupId', description='资源组id', example='rg-uo8f26cpmo', position='Query'),
}

model ListExperimentsResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: [ 
    {
      createTime?: long(name='CreateTime', description='Creation time', example='2024-10-22 10:18:10'),
      endTime?: string(name='EndTime', description='Task end time', example='2024-10-22 10:28:10'),
      envParams?: {
        cpuPerWorker?: int32(name='CpuPerWorker', description='Number of CPUs allocated', example='90'),
        cudaVersion?: string(name='CudaVersion', description='CUDA version', example='1.0.0'),
        extendParam?: map[string]string(name='ExtendParam', description='Additional parameters'),
        gpuDriverVersion?: string(name='GpuDriverVersion', description='GPU driver version', example='1.0.0'),
        gpuPerWorker?: int32(name='GpuPerWorker', description='Number of GPUs allocated', example='8'),
        memoryPerWorker?: int32(name='MemoryPerWorker', description='Amount of memory (GB) allocated', example='500'),
        NCCLVersion?: string(name='NCCLVersion', description='NCCL version', example='1.0.0'),
        pyTorchVersion?: string(name='PyTorchVersion', description='PyTorch version', example='1.0.0'),
        resourceNodes?: [ 
          {
            nodeName?: string(name='NodeName', description='Node name', example='lingj1xxnjt1k4nv-mg18v52pydyuumae-0'),
            requestCPU?: int32(name='RequestCPU', description='Requested CPU', example='90'),
            requestGPU?: int32(name='RequestGPU', description='Requested GPU', example='8'),
            requestMemory?: int32(name='RequestMemory', description='Requested memory', example='500'),
            totalCPU?: int32(name='TotalCPU', description='Total CPU', example='90'),
            totalGPU?: int32(name='TotalGPU', description='Total GPU', example='8'),
            totalMemory?: long(name='TotalMemory', description='Total memory', example='500'),
          }
        ](name='ResourceNodes', description='Specified nodes'),
        shareMemory?: int32(name='ShareMemory', description='Amount of shared memory (GB) allocated', example='500'),
        workerNum?: int32(name='WorkerNum', description='Number of nodes', example='1'),
      }(name='EnvParams', description='Environment parameters in operation'),
      experimentId?: long(name='ExperimentId', description='Experiment ID', example='1684537476910997506'),
      experimentName?: string(name='ExperimentName', description='Experiment name', example='test'),
      experimentType?: string(name='ExperimentType', description='Experiment type', example='AI'),
      getParams?: map[string]string(name='GetParams', description='Parsed load parameters'),
      resourceName?: string(name='ResourceName', description='Resource name', example='ecs.r8y.4xlarge'),
      results?: {
        duration?: double(name='Duration', description='Duration', example='20'),
        errorWorker?: [ 
          {
            errorFlag?: boolean(name='ErrorFlag', description='Whether there is an error', example='false'),
            errorMsg?: string(name='ErrorMsg', description='Error information', example='error msg'),
            experimentId?: long(name='ExperimentId', description='Experiment ID', example='176'),
            gpuName?: string(name='GpuName', description='GPU name', example='8x OAM 810 GPU'),
            gpuNum?: int32(name='GpuNum', description='Number of GPUs', example='8'),
            hostname?: string(name='Hostname', description='Host IP', example='etcd_cluster_c0n2'),
            podName?: string(name='PodName', description='Pod name', example='fluxserv-6fc89b45cf-w8wq6'),
            samplesPerSecond?: double(name='SamplesPerSecond', description='Throughput', example='65'),
            tflops?: double(name='Tflops', description='TFLOPS value', example='42'),
            warningFlag?: boolean(name='WarningFlag', description='Whether there is an alarm', example='false'),
            warningMsg?: string(name='WarningMsg', description='Alarm information', example='warning msg'),
          }
        ](name='ErrorWorker', description='Error nodes'),
        experimentId?: long(name='ExperimentId', description='Parameter name', example='440'),
        mfu?: double(name='Mfu', description='MFU', example='34'),
        samplesPerSecond?: double(name='SamplesPerSecond', description='Samples per second', example='10'),
        secondsPerIteration?: double(name='SecondsPerIteration', description='Seconds per iteration', example='89'),
        warningWorker?: [ 
          {
            errorFlag?: boolean(name='ErrorFlag', description='Whether there is an error', example='false'),
            errorMsg?: string(name='ErrorMsg', description='Error message', example='error msg'),
            experimentId?: long(name='ExperimentId', description='Experiment ID', example='113'),
            gpuName?: string(name='GpuName', description='GPU name', example='8x OAM 810 GPU'),
            gpuNum?: int32(name='GpuNum', description='Number of GPUs', example='90'),
            hostname?: string(name='Hostname', description='Host IP', example='101.66.165.102'),
            podName?: string(name='PodName', description='Pod name', example='hzs-forge-sdxl-online-7ff4d86444-pc95h'),
            samplesPerSecond?: double(name='SamplesPerSecond', description='Throughput', example='53'),
            tflops?: double(name='Tflops', description='TFLOPS value', example='43'),
            warningFlag?: boolean(name='WarningFlag', description='Whether there is an alarm', example='false'),
            warningMsg?: string(name='WarningMsg', description='Alarm message', example='warning msg'),
          }
        ](name='WarningWorker', description='Warning worker'),
      }(name='Results', description='Task results'),
      setParams?: map[string]string(name='SetParams', description='Load parameters in operation'),
      startTime?: string(name='StartTime', description='Task start time', example='2024-10-22 10:18:10'),
      status?: string(name='Status', description='Status', example='RUNNING'),
      updateTime?: long(name='UpdateTime', description='Update time', example='2024-10-22 10:18:10'),
      workloadName?: string(name='WorkloadName', description='Workload name', example='test'),
    }
  ](name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model ListExperimentsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListExperimentsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListExperiments  ListExperimentsRequest
  * @return ListExperimentsResponse
 */
async function listExperiments(request: ListExperimentsRequest): ListExperimentsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListExperiments', 'POST', '/', 'json', false, 'json', request);
}

model ListTagResourcesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  nextToken?: string(name='NextToken', description='Next token for the next query', example='F0lqbr2JpLDppro1RahGKViWtqXr3L28cePimcRn', position='Query'),
  resourceId?: [ string ](name='ResourceId', description='ResourceId', position='Query'),
  resourceType: string(name='ResourceType', description='Resource type

This parameter is required.', example='ExperimentPlan', position='Query'),
  tag?: [ 
    {
      key?: string(name='Key', description='Tag key, with n in the range [1, 20].', example='owner'),
      value?: string(name='Value', description='Tag value', example='syg'),
    }
  ](name='Tag', description='The list of tags to be queried. The value range for N is 1~20.', position='Query'),
}

model ListTagResourcesResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  nextToken?: string(name='NextToken', description='Next token for the next query. An empty NextToken indicates there are no more results.', example='uPZbmbpgxp2/6vNWNPoase3Eqy+gL9pdDBH7KGZXMuZ9GxmBbMJcTP/dlrNqRaWF'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  tagResources?: [ 
    {
      resourceId?: string(name='ResourceId', description='ResourceId', example='189'),
      resourceType?: string(name='ResourceType', description='Resource type', example='ExperimentPlan'),
      tagKey?: string(name='TagKey', description='Tag key', example='owner'),
      tagValue?: string(name='TagValue', description='Tag value', example='syg'),
    }
  ](name='TagResources', description='List of resources'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model ListTagResourcesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTagResourcesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListTagResources  ListTagResourcesRequest
  * @return ListTagResourcesResponse
 */
async function listTagResources(request: ListTagResourcesRequest): ListTagResourcesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTagResources', 'POST', '/', 'json', false, 'json', request);
}

model ListWorkloadsRequest {
  regionId?: string(name='RegionId', position='Host'),
  scope?: string(name='Scope', description='Scope', example='common', position='Query'),
}

model ListWorkloadsResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access Denied Information', example='{}'),
  data?: [ 
    {
      defaultCpuPerWorker?: int32(name='DefaultCpuPerWorker', description='Default CPU Allocation', example='90'),
      defaultGpuPerWorker?: int32(name='DefaultGpuPerWorker', description='Default GPU Allocation', example='8'),
      defaultMemoryPerWorker?: int32(name='DefaultMemoryPerWorker', description='Default Memory (GB) Allocation', example='500'),
      defaultShareMemory?: int32(name='DefaultShareMemory', description='Default Shared Memory (GB) Allocation', example='500'),
      family?: string(name='Family', description='Workload Cluster, AI, GPU', example='AI'),
      jobKind?: string(name='JobKind', description='Training Job Type', example='PyTorchJob'),
      paramSettings?: [ 
        {
          defaultValue?: string(name='DefaultValue', description='Default Parameter Value', example='100'),
          paramDesc?: string(name='ParamDesc', description='Parameter Description', example='number'),
          paramName?: string(name='ParamName', description='Parameter Name', example='ITERATION'),
          paramRegex?: string(name='ParamRegex', description='Parameter Regular Expression', example='[0-9]+'),
          paramType?: string(name='ParamType', description='Parameter type', example='number'),
          paramValue?: string(name='ParamValue', description='Parameter Value', example='100'),
        }
      ](name='ParamSettings', description='Parameter Settings'),
      scene?: string(name='Scene', description='Workload Usage Scenario', example='NLP-LLM'),
      scope?: string(name='Scope', description='Scope Identifier for Workload Usage', example='common'),
      staticConfig?: {
        frameWork?: string(name='FrameWork', description='Framework', example='PyTorch'),
        os?: string(name='Os', description='Operating System', example='linux'),
        parameters?: string(name='Parameters', description='Number of Parameters', example='7B'),
        softwareStack?: string(name='SoftwareStack', description='Software Stack', example='python'),
      }(name='StaticConfig', description='Static Configuration'),
      versionId?: long(name='VersionId', description='Version ID', example='1'),
      workloadDescription?: string(name='WorkloadDescription', description='Workload Description', example='test'),
      workloadId?: long(name='WorkloadId', description='Workload ID', example='13'),
      workloadName?: string(name='WorkloadName', description='Workload Name', example='test'),
      workloadType?: string(name='WorkloadType', description='Workload Type', example='AI'),
    }
  ](name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='4AC08332-436C-57A3-9FBA-26772B1A9901'),
  totalCount?: long(name='TotalCount', description='total', example='1'),
}

model ListWorkloadsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListWorkloadsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListWorkloads  ListWorkloadsRequest
  * @return ListWorkloadsResponse
 */
async function listWorkloads(request: ListWorkloadsRequest): ListWorkloadsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListWorkloads', 'POST', '/', 'json', false, 'json', request);
}

model StopExperimentRequest {
  regionId?: string(name='RegionId', position='Host'),
  experimentId: long(name='ExperimentId', description='Plan ID

This parameter is required.', example='234', position='Query'),
  resourceGroupId?: string(name='ResourceGroupId', description='Resource Group Id', example='rg-kdsflsdfj23m', position='Query'),
}

model StopExperimentResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: boolean(name='Data', description='Data', example='true'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='Total number of queries', example='0'),
}

model StopExperimentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopExperimentResponseBody(name='body'),
}

/**
  * @param request  the request parameters of StopExperiment  StopExperimentRequest
  * @return StopExperimentResponse
 */
async function stopExperiment(request: StopExperimentRequest): StopExperimentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopExperiment', 'POST', '/', 'json', false, 'json', request);
}

model TagResourcesRequest {
  regionId?: string(name='RegionId', position='Host'),
  resourceId: [ string ](name='ResourceId', description='ResourceId

This parameter is required.', position='Query'),
  resourceType: string(name='ResourceType', description='Resource type

This parameter is required.', example='ExperimentPlan', position='Query'),
  tag: [ 
    {
      key?: string(name='Key', description='Tag key.', example='owner', maxLength=128),
      value?: string(name='Value', description='Tag value', example='syg', maxLength=256),
    }
  ](name='Tag', description='List of tags, up to 20.

This parameter is required.', position='Query'),
}

model TagResourcesResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied details', example='{}'),
  data?: string(name='Data', description='Data', example='[]'),
  requestId?: string(name='RequestId', description='Request ID', example='E67E2E4C-2B47-5C55-AA17-1D771E070AEF'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model TagResourcesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: TagResourcesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of TagResources  TagResourcesRequest
  * @return TagResourcesResponse
 */
async function tagResources(request: TagResourcesRequest): TagResourcesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'TagResources', 'POST', '/', 'json', false, 'json', request);
}

model UntagResourcesRequest {
  regionId?: string(name='RegionId', position='Host'),
  all?: boolean(name='All', description='Whether to delete all, only effective when TagKey.N is empty. Allowed values: true, false, True, False. Default is false.', example='true', position='Query'),
  resourceId: [ string ](name='ResourceId', description='Resource ID

This parameter is required.', position='Query'),
  resourceType: string(name='ResourceType', description='Resource type

This parameter is required.', example='ExperimentPlan', position='Query'),
  tagKey: [ string ](name='TagKey', description='Tag key group, up to 20 items

This parameter is required.', position='Query'),
}

model UntagResourcesResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: string(name='Data', description='Data', example='[]'),
  requestId?: string(name='RequestId', description='Request ID', example='25859897-35C8-5015-8365-7A3CE52F4854'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model UntagResourcesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UntagResourcesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UntagResources  UntagResourcesRequest
  * @return UntagResourcesResponse
 */
async function untagResources(request: UntagResourcesRequest): UntagResourcesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UntagResources', 'POST', '/', 'json', false, 'json', request);
}

model UpdateExperimentPlanRequest {
  regionId?: string(name='RegionId', position='Host'),
  planId: long(name='PlanId', description='Experiment plan ID

This parameter is required.', example='189', position='Query'),
  planTemplateName: string(name='PlanTemplateName', description='Experiment plan name

This parameter is required.', example='test', position='Query'),
}

model UpdateExperimentPlanResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: boolean(name='Data', description='Data', example='true'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model UpdateExperimentPlanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateExperimentPlanResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateExperimentPlan  UpdateExperimentPlanRequest
  * @return UpdateExperimentPlanResponse
 */
async function updateExperimentPlan(request: UpdateExperimentPlanRequest): UpdateExperimentPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateExperimentPlan', 'POST', '/', 'json', false, 'json', request);
}

model UpdateExperimentPlanTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  templateId: long(name='TemplateId', description='Template code

This parameter is required.', example='349623', position='Query'),
  templatePipeline: [ 
    {
      envParams: {
        cpuPerWorker: int32(name='CpuPerWorker', description='CPU allocation count

This parameter is required.', example='90'),
        cudaVersion?: string(name='CudaVersion', description='CUDA version', example='1.0.0'),
        gpuDriverVersion?: string(name='GpuDriverVersion', description='GPU driver version', example='1.0.0'),
        gpuPerWorker: int32(name='GpuPerWorker', description='GPU allocation count

This parameter is required.', example='8'),
        memoryPerWorker: int32(name='MemoryPerWorker', description='Memory GB allocation count

This parameter is required.', example='500'),
        NCCLVersion?: string(name='NCCLVersion', description='NCCL version', example='1.0.0'),
        pyTorchVersion?: string(name='PyTorchVersion', description='PyTorch version', example='1.0.0'),
        shareMemory: int32(name='ShareMemory', description='Shared memory GB allocation count

This parameter is required.', example='500'),
        workerNum: int32(name='WorkerNum', description='Number of nodes

This parameter is required.', example='1'),
      }(name='EnvParams', description='Configured environment parameters

This parameter is required.'),
      pipelineOrder: int32(name='PipelineOrder', description='Node order number

This parameter is required.', example='1'),
      scene: string(name='Scene', description='Usage scenario, e.g., "baseline"

This parameter is required.', example='baseline'),
      settingParams?: map[string]string(name='SettingParams', description='Configured workload parameters'),
      workloadId: long(name='WorkloadId', description='Workload ID

This parameter is required.', example='14'),
      workloadName: string(name='WorkloadName', description='Workload name

This parameter is required.', example='test'),
    }
  ](name='TemplatePipeline', description='Template pipeline

This parameter is required.', shrink='json', position='Body'),
}

model UpdateExperimentPlanTemplateResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: {
    createTime?: string(name='CreateTime', description='Create Time', example='2024-10-22 10:18:10'),
    creatorUid?: long(name='CreatorUid', description='Primary account UID', example='12312312312312'),
    isDelete?: int32(name='IsDelete', description='Whether it is deleted', example='0'),
    privacyLevel?: string(name='PrivacyLevel', description='Privacy Level', example='private'),
    templateCode?: long(name='TemplateCode', description='Template code', example='472840184'),
    templateDescription?: string(name='TemplateDescription', description='Template Description', example='test'),
    templateId?: long(name='TemplateId', description='Template ID', example='17815441'),
    templateName?: string(name='TemplateName', description='Template Name', example='test'),
    templatePipelineParam?: [ 
      {
        envParams?: {
          cpuPerWorker?: int32(name='CpuPerWorker', description='CPU Allocation', example='90'),
          cudaVersion?: string(name='CudaVersion', description='CUDA Version', example='1.0.0'),
          extendParam?: map[string]string(name='ExtendParam', description='Extend Param'),
          gpuDriverVersion?: string(name='GpuDriverVersion', description='GPU Driver Version', example='1.0.0'),
          gpuPerWorker?: int32(name='GpuPerWorker', description='GPU Allocation', example='8'),
          memoryPerWorker?: int32(name='MemoryPerWorker', description='Memory (GB) Allocation', example='500'),
          NCCLVersion?: string(name='NCCLVersion', description='NCCL Version', example='1.0.0'),
          pyTorchVersion?: string(name='PyTorchVersion', description='PyTorch Version', example='1.0.0'),
          resourceNodes?: [ 
            {
              nodeName?: string(name='NodeName', description='Node Name', example='honeypot'),
              requestCPU?: int32(name='RequestCPU', description='Requested CPU', example='10'),
              requestGPU?: int32(name='RequestGPU', description='Requested GPU', example='10'),
              requestMemory?: int32(name='RequestMemory', description='Requested Memory', example='10'),
              totalCPU?: int32(name='TotalCPU', description='Total CPU', example='100'),
              totalGPU?: int32(name='TotalGPU', description='Total GPU', example='100'),
              totalMemory?: long(name='TotalMemory', description='Total Memory', example='100'),
            }
          ](name='ResourceNodes', description='Specified Nodes'),
          shareMemory?: int32(name='ShareMemory', description='Shared Memory (GB) Allocation', example='500'),
          workerNum?: int32(name='WorkerNum', description='Number of Nodes', example='1'),
        }(name='EnvParams', description='Configured Environment Parameters'),
        pipelineOrder?: int32(name='PipelineOrder', description='Node sequence number', example='1'),
        scene?: string(name='Scene', description='Usage Scenario, e.g., "baseline"', example='baseline'),
        settingParams?: map[string]string(name='SettingParams', description='Configured Workload Parameters'),
        workloadId?: long(name='WorkloadId', description='Workload ID', example='13'),
        workloadName?: string(name='WorkloadName', description='Workload Name', example='test'),
      }
    ](name='TemplatePipelineParam', description='Template Pipeline'),
    updateTime?: string(name='UpdateTime', description='Update Time', example='2024-07-07 02:08:54'),
    versionId?: long(name='VersionId', description='Version ID', example='1'),
  }(name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model UpdateExperimentPlanTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateExperimentPlanTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateExperimentPlanTemplate  UpdateExperimentPlanTemplateRequest
  * @return UpdateExperimentPlanTemplateResponse
 */
async function updateExperimentPlanTemplate(request: UpdateExperimentPlanTemplateRequest): UpdateExperimentPlanTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateExperimentPlanTemplate', 'POST', '/', 'json', true, 'form', request);
}

model ValidateResourceRequest {
  regionId?: string(name='RegionId', position='Host'),
  clusterId: string(name='ClusterId', description='Resource ID

This parameter is required.', example='ehpc-sh-ouypm5aucy', position='Query'),
  userAccessParam?: {
    accessId?: string(name='AccessId', description='User ID', example='dev'),
    accessKey?: string(name='AccessKey', description='User Key', example='test'),
    endpoint?: string(name='Endpoint', description='Endpoint', example='test'),
    workspaceId?: string(name='WorkspaceId', description='Workspace ID', example='test'),
  }(name='UserAccessParam', description='User Authorization Parameters', shrink='json', position='Body'),
}

model ValidateResourceResponseBody = {
  data?: boolean(name='Data', description='Data', example='true'),
  requestId?: string(name='RequestId', description='Request Id', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model ValidateResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ValidateResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ValidateResource  ValidateResourceRequest
  * @return ValidateResourceResponse
 */
async function validateResource(request: ValidateResourceRequest): ValidateResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ValidateResource', 'POST', '/', 'json', true, 'form', request);
}

model DataResultsTaskIndividualResultMapValue = {
  experimentId?: long(name='ExperimentId', description='Experiment ID', example='54'),
  hostname?: string(name='Hostname', description='Host IP', example='p-jt-waf-app1'),
  podName?: string(name='PodName', description='Pod name', example='fluxserv-6fc89b45cf-w8wq6'),
  gpuNum?: int32(name='GpuNum', description='GPU数量', example='8'),
  gpuName?: string(name='GpuName', description='GPU名称', example='8x OAM 810 GPU'),
  warningFlag?: boolean(name='WarningFlag', description='Whether there is a warning', example='false'),
  warningMsg?: string(name='WarningMsg', description='Warning message', example='warning message'),
  errorFlag?: boolean(name='ErrorFlag', description='Whether there is an error', example='false'),
  errorMsg?: string(name='ErrorMsg', description='Error message', example='error message'),
  tflops?: double(name='Tflops', description='TFLOPS value', example='45'),
  samplesPerSecond?: double(name='SamplesPerSecond', description='Throughput', example='23'),
}

