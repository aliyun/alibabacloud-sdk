/**
  *
  */
import BaseClientBuilder;
import TeaAsyncHandler;
import TeaRequest;
import AsyncRequestBody;
import RequestBody;
import AsyncResponseHandler;
import ClientConfiguration;
import ClientExecutionParams;
extends BaseClientBuilder;
type @product = string
type @version = string
type @endpointRule = string
type @endpointMap = map[string]string
type @REQUEST = TeaRequest
type @handler = TeaAsyncHandler

init(configuration: ClientConfiguration){
  @handler = new TeaAsyncHandler(configuration);
  @product = 'eflo-cnp';
  @version = '2023-08-28';
  @endpointRule = '';
  @endpointMap = {
  };
}

function close(): void {
  @handler.close();
}

model ChangeResourceGroupRequest {
  resourceGroupId: string(name='ResourceGroupId', description='The resource group id.

This parameter is required.', example='rg-aek25k3b4pbhc4a', position='Query'),
  resourceId: string(name='ResourceId', description='The resource id.

This parameter is required.', example='123', position='Query'),
  resourceType?: string(name='ResourceType', description='The resource type.', example='ExperimentPlan', position='Query'),
}

model ChangeResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='Request Id', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
}

model ChangeResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ChangeResourceGroupResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ChangeResourceGroup  ChangeResourceGroupRequest
  * @return ChangeResourceGroupResponse
 */
async function changeResourceGroup(request: ChangeResourceGroupRequest): ChangeResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ChangeResourceGroup', 'POST', '/', 'json', false, 'json', request);
}

model CreateExperimentPlanRequest {
  regionId?: string(name='RegionId', position='Host'),
  externalParams?: map[string]any(name='ExternalParams', description='Additional parameters', example='{}', shrink='json', position='Query'),
  resourceGroupId?: string(name='ResourceGroupId', description='Resource group ID', example='rg-aekzij65sf2rr5i', position='Query'),
  resourceId?: long(name='ResourceId', description='Resource ID', example='189', position='Query'),
  templateId?: long(name='TemplateId', description='Template ID', example='349623', position='Query'),
}

model CreateExperimentPlanResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: long(name='Data', description='Data', example='[]'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='Total count of the query', example='0'),
}

model CreateExperimentPlanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateExperimentPlanResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateExperimentPlan  CreateExperimentPlanRequest
  * @return CreateExperimentPlanResponse
 */
async function createExperimentPlan(request: CreateExperimentPlanRequest): CreateExperimentPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateExperimentPlan', 'POST', '/', 'json', false, 'json', request);
}

model CreateExperimentPlanTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  privacyLevel?: string(name='PrivacyLevel', example='private', position='Query'),
  templateDescription?: string(name='TemplateDescription', example='The template installs jdk and tomcat on a new ECS instance.', position='Query'),
  templateId?: long(name='TemplateId', example='4724', position='Query'),
  templateName?: string(name='TemplateName', position='Query'),
  templatePipeline?: [ 
    {
      envParams?: {
        cpuPerWorker?: int32(name='CpuPerWorker', example='90'),
        cudaVersion?: string(name='CudaVersion', description='cudaVersion', example='1.0.0'),
        gpuDriverVersion?: string(name='GpuDriverVersion', description='GpuDriverVersion', example='1.0.0'),
        gpuPerWorker?: int32(name='GpuPerWorker', example='8'),
        memoryPerWorker?: int32(name='MemoryPerWorker', example='500'),
        NCCLVersion?: string(name='NCCLVersion', description='NCCLVersion', example='1.0.0'),
        pyTorchVersion?: string(name='PyTorchVersion', description='PyTorchVersion', example='1.0.0'),
        shareMemory?: int32(name='ShareMemory', example='500'),
        workerNum?: int32(name='WorkerNum', example='1'),
      }(name='EnvParams'),
      pipelineOrder?: int32(name='PipelineOrder', example='1'),
      scene?: string(name='Scene', example='baseline'),
      settingParams?: map[string]string(name='SettingParams'),
      workloadId?: long(name='WorkloadId', example='14'),
      workloadName?: string(name='WorkloadName', example='test'),
    }
  ](name='TemplatePipeline', shrink='json', position='Body'),
}

model CreateExperimentPlanTemplateResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', example='{}'),
  data?: {
    createTime?: string(name='CreateTime', example='2024-11-19T02:01:05Z'),
    creatorUid?: long(name='CreatorUid', example='12312312312312'),
    isDelete?: int32(name='IsDelete', example='0'),
    privacyLevel?: string(name='PrivacyLevel', example='private'),
    templateDescription?: string(name='TemplateDescription'),
    templateId?: long(name='TemplateId', example='17615126'),
    templateName?: string(name='TemplateName'),
    templatePipelineParam?: [ 
      {
        envParams?: {
          cpuPerWorker?: int32(name='CpuPerWorker', example='90'),
          cudaVersion?: string(name='CudaVersion', description='cudaVersion', example='1.0.0'),
          gpuDriverVersion?: string(name='GpuDriverVersion', description='GpuDriverVersion', example='1.0.0'),
          gpuPerWorker?: int32(name='GpuPerWorker', example='8'),
          memoryPerWorker?: int32(name='MemoryPerWorker', example='500'),
          NCCLVersion?: string(name='NCCLVersion', description='NCCLVersion', example='1.0.0'),
          pyTorchVersion?: string(name='PyTorchVersion', description='PyTorchVersion', example='1.0.0'),
          shareMemory?: int32(name='ShareMemory', example='500'),
          workerNum?: int32(name='WorkerNum', example='1'),
        }(name='EnvParams'),
        pipelineOrder?: int32(name='PipelineOrder', example='1'),
        scene?: string(name='Scene', example='baseline'),
        settingParams?: map[string]string(name='SettingParams'),
        workloadId?: long(name='WorkloadId', example='13'),
        workloadName?: string(name='WorkloadName', example='test'),
      }
    ](name='TemplatePipelineParam'),
    updateTime?: string(name='UpdateTime', example='2023-10-16T01:58Z'),
    versionId?: long(name='VersionId', example='1'),
  }(name='Data'),
  requestId?: string(name='RequestId', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', example='0'),
}

model CreateExperimentPlanTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateExperimentPlanTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateExperimentPlanTemplate  CreateExperimentPlanTemplateRequest
  * @return CreateExperimentPlanTemplateResponse
 */
async function createExperimentPlanTemplate(request: CreateExperimentPlanTemplateRequest): CreateExperimentPlanTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateExperimentPlanTemplate', 'POST', '/', 'json', true, 'form', request);
}

model CreateResourceRequest {
  regionId?: string(name='RegionId', position='Host'),
  clusterDesc?: string(name='ClusterDesc', description='Cluster Description', example='ppu集群', position='Query'),
  clusterId?: string(name='ClusterId', description='Cluster ID', example='ehpc-sh-fj71c0ycfw', position='Query'),
  clusterName?: string(name='ClusterName', description='Cluster Name', example='tre-1-ppu', position='Query'),
  clusterType?: string(name='ClusterType', description='Cluster Type', example='ACK', position='Query'),
  machineTypes?: {
    bondNum?: int32(name='BondNum', description='Number of Network Bonds', example='5'),
    cpuInfo?: string(name='CpuInfo', description='CPU Information', example='2x Intel Saphhire Rapid 8469C 48C CPU'),
    diskInfo?: string(name='DiskInfo', description='Disk Information', example='2x 480GB SATA SSD \\n 4x 3.84TB NVMe SSD'),
    gpuInfo?: string(name='GpuInfo', description='GPU Information', example='8x NVIDIA SXM4 80GB A100 GPU'),
    memoryInfo?: string(name='MemoryInfo', description='Memory Information', example='32x 64GB DDR4 4800 Memory'),
    name?: string(name='Name', description='Specification Name', example='efg1.nvga1n'),
    networkInfo?: string(name='NetworkInfo', description='Network Information', example='1x 200Gbps Dual Port BF3 DPU for VPC\\\\n4x 200Gbps Dual Port EIC'),
    networkMode?: string(name='NetworkMode', description='Network Mode', example='2'),
    nodeCount?: int32(name='NodeCount', description='Number of Nodes', example='1'),
    type?: string(name='Type', description='Type', example='Private'),
  }(name='MachineTypes', description='Machine Types', shrink='json', position='Body'),
  resourceType?: string(name='ResourceType', description='Resource Type', example='ACK', position='Query'),
  userAccessParam?: {
    accessId?: string(name='AccessId', description='User ID', example='dev'),
    accessKey?: string(name='AccessKey', description='User Key', example='test'),
    endpoint?: string(name='Endpoint', description='Endpoint', example='test'),
    workspaceId?: string(name='WorkspaceId', description='Workspace ID', example='1245688643'),
  }(name='UserAccessParam', description='User Access Parameters', shrink='json', position='Body'),
}

model CreateResourceResponseBody = {
  data?: long(name='Data', description='Data', example='[]'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='Total Count', example='0'),
}

model CreateResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateResource  CreateResourceRequest
  * @return CreateResourceResponse
 */
async function createResource(request: CreateResourceRequest): CreateResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateResource', 'POST', '/', 'json', true, 'form', request);
}

model DeleteExperimentRequest {
  regionId?: string(name='RegionId', position='Host'),
  experimentId?: long(name='ExperimentId', example='234', position='Query'),
}

model DeleteExperimentResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', example='{}'),
  data?: boolean(name='Data', example='[]'),
  requestId?: string(name='RequestId', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', example='0'),
}

model DeleteExperimentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteExperimentResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteExperiment  DeleteExperimentRequest
  * @return DeleteExperimentResponse
 */
async function deleteExperiment(request: DeleteExperimentRequest): DeleteExperimentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteExperiment', 'POST', '/', 'json', false, 'json', request);
}

model DeleteExperimentPlanTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  templateId?: long(name='TemplateId', example='346527', position='Query'),
}

model DeleteExperimentPlanTemplateResponseBody = {
  data?: boolean(name='Data', example='[]'),
  requestId?: string(name='RequestId', example='4D3FD55F-3BCD-5914-9B74-A1F4961327E7'),
  totalCount?: long(name='TotalCount', example='0'),
}

model DeleteExperimentPlanTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteExperimentPlanTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteExperimentPlanTemplate  DeleteExperimentPlanTemplateRequest
  * @return DeleteExperimentPlanTemplateResponse
 */
async function deleteExperimentPlanTemplate(request: DeleteExperimentPlanTemplateRequest): DeleteExperimentPlanTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteExperimentPlanTemplate', 'POST', '/', 'json', false, 'json', request);
}

model GetExperimentRequest {
  regionId?: string(name='RegionId', position='Host'),
  experimentId?: long(name='ExperimentId', example='234', position='Query'),
}

model GetExperimentResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', example='{}'),
  data?: {
    createTime?: long(name='CreateTime', example='2024-11-29 02:16:35'),
    endTime?: string(name='EndTime', example='2024-11-29 02:26:35'),
    envParams?: {
      cpuPerWorker?: int32(name='CpuPerWorker', example='90'),
      cudaVersion?: string(name='CudaVersion', description='cudaVersion', example='1.0.0'),
      extendParam?: map[string]string(name='ExtendParam'),
      gpuDriverVersion?: string(name='GpuDriverVersion', description='GpuDriverVersion', example='1.0.0'),
      gpuPerWorker?: int32(name='GpuPerWorker', example='8'),
      memoryPerWorker?: int32(name='MemoryPerWorker', example='500'),
      NCCLVersion?: string(name='NCCLVersion', description='NCCLVersion', example='1.0.0'),
      pyTorchVersion?: string(name='PyTorchVersion', description='PyTorchVersion', example='1.0.0'),
      resourceNodes?: [ 
        {
          nodeName?: string(name='NodeName', example='p-jt-waf-app1'),
          requestCPU?: int32(name='RequestCPU', example='90'),
          requestGPU?: int32(name='RequestGPU', example='8'),
          requestMemory?: int32(name='RequestMemory', example='500'),
          totalCPU?: int32(name='TotalCPU', example='90'),
          totalGPU?: int32(name='TotalGPU', example='8'),
          totalMemory?: long(name='TotalMemory', example='500'),
        }
      ](name='ResourceNodes'),
      shareMemory?: int32(name='ShareMemory', example='500'),
      workerNum?: int32(name='WorkerNum', example='1'),
    }(name='EnvParams'),
    experimentId?: long(name='ExperimentId', example='1726882991828688898'),
    experimentName?: string(name='ExperimentName', example='test'),
    experimentType?: string(name='ExperimentType', example='AI'),
    getParams?: map[string]string(name='GetParams'),
    resource?: {
      cpuCoreLimit?: int32(name='CpuCoreLimit', example='90'),
      gpuLimit?: int32(name='GpuLimit', example='8'),
      machineType?: {
        bondNum?: int32(name='BondNum', example='5'),
        cpuInfo?: string(name='CpuInfo', example='2x Intel Icelake 8369B 32C CPU'),
        diskInfo?: string(name='DiskInfo', example='2x 480GB SATA SSD \\n 4x 3.84TB NVMe SSD'),
        gpuInfo?: string(name='GpuInfo', example='8x NVIDIA SXM4 80GB A100 GPU'),
        memoryInfo?: string(name='MemoryInfo', example='32x 64GB DDR4 3200 Memory'),
        name?: string(name='Name', example='efg1.nvga1n'),
        networkInfo?: string(name='NetworkInfo', example='1x 100Gbps DP NIC for VPC \\n 4x 100Gbps DP RoCE NIC'),
        networkMode?: string(name='NetworkMode', example='2'),
        nodeCount?: int32(name='NodeCount', example='1'),
        type?: string(name='Type', example='Public'),
      }(name='MachineType'),
      maxCpuCore?: int32(name='MaxCpuCore', example='90'),
      maxGpu?: int32(name='MaxGpu', example='8'),
      maxMemory?: long(name='MaxMemory', example='500'),
      memoryLimit?: long(name='MemoryLimit', example='500'),
      resourceId?: long(name='ResourceId', example='189'),
      resourceName?: string(name='ResourceName', example='ecs.r8y.4xlarge'),
      resourceNodes?: [ 
        {
          nodeName?: string(name='NodeName', example='InputCheck'),
        }
      ](name='ResourceNodes'),
      userAccessParam?: {
        accessId?: string(name='AccessId', example='dev'),
        accessKey?: string(name='AccessKey', example='test'),
        endpoint?: string(name='Endpoint', description='endpoint', example='test'),
        workspaceId?: string(name='WorkspaceId', example='123434542498'),
      }(name='UserAccessParam'),
    }(name='Resource'),
    resourceName?: string(name='ResourceName', example='cifnews-guoyuan'),
    results?: {
      duration?: double(name='Duration', example='764'),
      errorWorker?: [ 
        {
          errorFlag?: boolean(name='ErrorFlag', example='true'),
          errorMsg?: string(name='ErrorMsg', example='Connection reset'),
          experimentId?: long(name='ExperimentId', example='97'),
          gpuName?: string(name='GpuName', example='8x OAM 810 GPU'),
          gpuNum?: int32(name='GpuNum', example='8'),
          hostname?: string(name='Hostname', example='60.188.98.209'),
          podName?: string(name='PodName', example='hzs-forge-sdxl-online-7ff4d86444-pc95h'),
          samplesPerSecond?: double(name='SamplesPerSecond', example='23'),
          tflops?: double(name='Tflops', example='12'),
          warningFlag?: boolean(name='WarningFlag', example='false'),
          warningMsg?: string(name='WarningMsg'),
        }
      ](name='ErrorWorker'),
      experimentId?: long(name='ExperimentId', example='1748274952976261121'),
      mfu?: double(name='Mfu', description='MFU', example='54.2'),
      samplesPerSecond?: double(name='SamplesPerSecond', example='10'),
      secondsPerIteration?: double(name='SecondsPerIteration', example='1000'),
      taskIndividualResultList?: [ 
        {
          errorFlag?: boolean(name='ErrorFlag', example='false'),
          errorMsg?: string(name='ErrorMsg'),
          experimentId?: long(name='ExperimentId', example='48'),
          gpuName?: string(name='GpuName', example='8x OAM 810 GPU'),
          gpuNum?: int32(name='GpuNum', example='8'),
          hostname?: string(name='Hostname', example='p-jt-waf-app1'),
          podName?: string(name='PodName', example='fluxserv-6fc89b45cf-w8wq6'),
          samplesPerSecond?: double(name='SamplesPerSecond', example='28'),
          tflops?: double(name='Tflops', example='16'),
          warningFlag?: boolean(name='WarningFlag', example='false'),
          warningMsg?: string(name='WarningMsg'),
        }
      ](name='TaskIndividualResultList'),
      taskIndividualResultMap?: map[string][ DataResultsTaskIndividualResultMapValue       ](name='TaskIndividualResultMap'),
      warningBoundList?: [ 
        {
          iteration?: int32(name='Iteration', example='10'),
          lower?: double(name='Lower', description='LOWER', example='14'),
          upper?: double(name='Upper', description='UPPER', example='56'),
        }
      ](name='WarningBoundList'),
      warningWorker?: [ 
        {
          errorFlag?: boolean(name='ErrorFlag', example='true'),
          errorMsg?: string(name='ErrorMsg'),
          experimentId?: long(name='ExperimentId', example='9'),
          gpuName?: string(name='GpuName', example='8x OAM 810 GPU'),
          gpuNum?: int32(name='GpuNum', example='8'),
          hostname?: string(name='Hostname', example='whza008403'),
          podName?: string(name='PodName', example='fluxserv-6fc89b45cf-w8wq6'),
          samplesPerSecond?: double(name='SamplesPerSecond', example='15'),
          tflops?: double(name='Tflops', example='14'),
          warningFlag?: boolean(name='WarningFlag', example='true'),
          warningMsg?: string(name='WarningMsg'),
        }
      ](name='WarningWorker'),
    }(name='Results'),
    setParams?: map[string]string(name='SetParams'),
    startTime?: string(name='StartTime', example='2024-11-29 02:16:35'),
    status?: string(name='Status', example='RUNNING'),
    task?: {
      createTime?: long(name='CreateTime', example='2024-03-05 18:24:08'),
      endTime?: long(name='EndTime', example='2024-03-05 18:34:08'),
      params?: map[string]string(name='Params'),
      scene?: string(name='Scene', example='baseline'),
      startTime?: long(name='StartTime', example='2024-03-05 18:24:08'),
      status?: string(name='Status', example='success'),
      taskId?: long(name='TaskId', example='167420'),
      updateTime?: long(name='UpdateTime', example='2024-03-05 18:24:08'),
    }(name='Task'),
    updateTime?: long(name='UpdateTime', example='2024-11-29 02:16:35'),
    workload?: {
      defaultCpuPerWorker?: int32(name='DefaultCpuPerWorker', example='90'),
      defaultGpuPerWorker?: int32(name='DefaultGpuPerWorker', example='8'),
      defaultMemoryPerWorker?: int32(name='DefaultMemoryPerWorker', example='500'),
      defaultShareMemory?: int32(name='DefaultShareMemory', example='500'),
      family?: string(name='Family', example='AI'),
      jobKind?: string(name='JobKind', example='PyTorchJob'),
      paramSettings?: [ 
        {
          defaultValue?: string(name='DefaultValue', example='100'),
          paramDesc?: string(name='ParamDesc'),
          paramName?: string(name='ParamName', example='ITERATION'),
          paramRegex?: string(name='ParamRegex', example='[0-9]+'),
          paramType?: string(name='ParamType', example='number'),
          paramValue?: string(name='ParamValue', example='100'),
        }
      ](name='ParamSettings'),
      scene?: string(name='Scene', example='NLP-LLM'),
      scope?: string(name='Scope', example='common'),
      staticConfig?: {
        frameWork?: string(name='FrameWork', example='pyTorch'),
        os?: string(name='Os', example='linux'),
        parameters?: string(name='Parameters', example='7B'),
        softwareStack?: string(name='SoftwareStack', example='python'),
      }(name='StaticConfig'),
      versionId?: long(name='VersionId', example='1'),
      workloadDescription?: string(name='WorkloadDescription', example='test'),
      workloadId?: long(name='WorkloadId', example='13'),
      workloadName?: string(name='WorkloadName', example='test'),
      workloadType?: string(name='WorkloadType', example='AI'),
    }(name='Workload'),
    workloadName?: string(name='WorkloadName', example='test'),
  }(name='Data'),
  requestId?: string(name='RequestId', example='E67E2E4C-2B47-5C55-AA17-1D771E070AEF'),
  totalCount?: long(name='TotalCount', example='0'),
}

model GetExperimentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetExperimentResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetExperiment  GetExperimentRequest
  * @return GetExperimentResponse
 */
async function getExperiment(request: GetExperimentRequest): GetExperimentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetExperiment', 'POST', '/', 'json', false, 'json', request);
}

model GetExperimentPlanRequest {
  regionId?: string(name='RegionId', position='Host'),
  planId?: long(name='PlanId', description='Plan ID', example='189', position='Query'),
}

model GetExperimentPlanResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: {
    createTime?: string(name='CreateTime', description='Creation time', example='2024-07-07 02:08:54'),
    planId?: long(name='PlanId', description='Plan ID', example='189'),
    planPipeline?: [ 
      {
        envParams?: {
          cpuPerWorker?: int32(name='CpuPerWorker', description='CPU allocation', example='90'),
          cudaVersion?: string(name='CudaVersion', description='CUDA version', example='1.0.0'),
          extendParam?: map[string]string(name='ExtendParam', description='Additional parameters'),
          gpuDriverVersion?: string(name='GpuDriverVersion', description='GPU driver version', example='1.0.0'),
          gpuPerWorker?: int32(name='GpuPerWorker', description='Number of GPUs allocated', example='8'),
          memoryPerWorker?: int32(name='MemoryPerWorker', description='Memory GB allocation', example='500'),
          NCCLVersion?: string(name='NCCLVersion', description='NCCL version', example='1.0.0'),
          pyTorchVersion?: string(name='PyTorchVersion', description='PyTorch version', example='1.0.0'),
          resourceNodes?: [ 
            {
              nodeName?: string(name='NodeName', description='Node name', example='ods_galaxy_gateway_tickets'),
              requestCPU?: int32(name='RequestCPU', description='Requested CPU', example='90'),
              requestGPU?: int32(name='RequestGPU', description='Requested GPU', example='8'),
              requestMemory?: int32(name='RequestMemory', description='Memory of the current request', example='500'),
              totalCPU?: int32(name='TotalCPU', description='Total CPU', example='90'),
              totalGPU?: int32(name='TotalGPU', description='Total GPU', example='8'),
              totalMemory?: long(name='TotalMemory', description='Total memory', example='500'),
            }
          ](name='ResourceNodes', description='Specified nodes'),
          shareMemory?: int32(name='ShareMemory', description='Shared memory GB allocation', example='500'),
          workerNum?: int32(name='WorkerNum', description='Number of nodes', example='1'),
        }(name='EnvParams', description='Configured environment parameters'),
        pipelineOrder?: int32(name='PipelineOrder', description='Node order number', example='1'),
        resourceId?: long(name='ResourceId', description='Resource ID', example='36'),
        resourceName?: string(name='ResourceName', description='Resource name', example='PPU'),
        scene?: string(name='Scene', description='Usage scenario, e.g., "baseline"', example='baseline'),
        settingParams?: map[string]string(name='SettingParams', description='Configured workload parameters'),
        workloadId?: long(name='WorkloadId', description='Workload ID', example='14'),
        workloadName?: string(name='WorkloadName', description='Workload name', example='test'),
      }
    ](name='PlanPipeline', description='Test plan pipeline'),
    resourceGroupId?: string(name='ResourceGroupId', description='Resource group ID', example='rg-acfmvmpzi7lmxhq'),
    resourceId?: long(name='ResourceId', description='Associated resource ID', example='260860230684'),
    templateId?: long(name='TemplateId', description='Associated test plan template ID', example='2162'),
    templateName?: string(name='TemplateName', description='Associated test plan template name', example='MM'),
    updateTime?: string(name='UpdateTime', description='Update time', example='2024-07-07 02:08:54'),
  }(name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='6DBAC169-93D1-5DCD-8109-30FB623B3197'),
  totalCount?: long(name='TotalCount', description='Total count of the query', example='0'),
}

model GetExperimentPlanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetExperimentPlanResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetExperimentPlan  GetExperimentPlanRequest
  * @return GetExperimentPlanResponse
 */
async function getExperimentPlan(request: GetExperimentPlanRequest): GetExperimentPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetExperimentPlan', 'POST', '/', 'json', false, 'json', request);
}

model GetExperimentResultDataRequest {
  regionId?: string(name='RegionId', position='Host'),
  experimentId?: long(name='ExperimentId', example='234', position='Query'),
  hostname?: string(name='Hostname', example='iZj6ccwd7zwfms7hzaz2riZ', position='Query'),
  workloadType?: string(name='WorkloadType', example='AI', position='Query'),
}

model GetExperimentResultDataResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', example='{}'),
  data?: [ 
    {
      gpuNum?: string(name='GpuNum', example='8'),
      hostname?: string(name='Hostname', example='p-jt-waf-app1'),
      metricsInfos?: [ 
        {
          gpuNum?: string(name='Gpu_num', description='gpu', example='8'),
          iteration?: long(name='Iteration', description='iteration', example='100'),
          tflops?: double(name='Tflops', description='TFLOPS', example='43'),
          timestamp?: long(name='Timestamp', example='1715393860'),
          value?: double(name='Value', example='126'),
        }
      ](name='MetricsInfos'),
      podName?: string(name='PodName', example='hzs-forge-sdxl-online-7ff4d86444-pc95h'),
    }
  ](name='Data'),
  requestId?: string(name='RequestId', example='C1D34EC2-AB13-56F4-8322-F15AE563EA04'),
  totalCount?: long(name='TotalCount', example='0'),
}

model GetExperimentResultDataResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetExperimentResultDataResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetExperimentResultData  GetExperimentResultDataRequest
  * @return GetExperimentResultDataResponse
 */
async function getExperimentResultData(request: GetExperimentResultDataRequest): GetExperimentResultDataResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetExperimentResultData', 'POST', '/', 'json', false, 'json', request);
}

model GetResourceRequest {
  regionId?: string(name='RegionId', position='Host'),
  clusterId?: string(name='ClusterId', description='The cluster ID of Lingjun', example='ehpc-bj-uo8f26cpmo', position='Query'),
}

model GetResourceResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: {
    clusterDesc?: string(name='ClusterDesc', description='Cluster description', example='test'),
    clusterId?: string(name='ClusterId', description='Cluster ID', example='3123121223'),
    clusterName?: string(name='ClusterName', description='Cluster name', example='main_cluster'),
    cpuCoreLimit?: int32(name='CpuCoreLimit', description='Used CPU', example='90'),
    gpuLimit?: int32(name='GpuLimit', description='Used GPU', example='8'),
    machineType?: {
      bondNum?: int32(name='BondNum', description='Number of network bonds', example='5'),
      cpuInfo?: string(name='CpuInfo', description='CPU information', example='2x Intel Saphhire Rapid 8469C 48C CPU'),
      diskInfo?: string(name='DiskInfo', description='Disk information', example='2x 480GB SATA SSD\\n4x 3.84TB NVMe SSD'),
      gpuInfo?: string(name='GpuInfo', description='GPU information', example='8x OAM 810 GPU'),
      memoryInfo?: string(name='MemoryInfo', description='Memory information', example='32x 64GB DDR4 4800 Memory'),
      name?: string(name='Name', description='Specification name', example='efg2.p8en'),
      networkInfo?: string(name='NetworkInfo', description='Network information', example='1x 200Gbps Dual Port BF3 DPU for VPC\\n4x 200Gbps Dual Port EIC'),
      networkMode?: string(name='NetworkMode', description='Network mode', example='2'),
      nodeCount?: int32(name='NodeCount', description='Number of nodes', example='1'),
      type?: string(name='Type', description='Type', example='Private'),
    }(name='MachineType', description='Machine type'),
    maxCpuCore?: int32(name='MaxCpuCore', description='Used memory', example='90'),
    maxGpu?: int32(name='MaxGpu', description='Used memory', example='8'),
    maxMemory?: long(name='MaxMemory', description='Used memory', example='500'),
    memoryLimit?: long(name='MemoryLimit', description='Used memory', example='500'),
    resourceId?: long(name='ResourceId', description='Cluster ID', example='189'),
    resourceName?: string(name='ResourceName', description='Cluster name', example='ecs.g6.4xlarge'),
    resourceNodes?: [ 
      {
        nodeName?: string(name='NodeName', description='Node name', example='lingj19q90jp66nq-mg2pa0p2l2bipnsi-17'),
      }
    ](name='ResourceNodes', description='List of resource nodes'),
    userAccessParam?: {
      accessId?: string(name='AccessId', description='User ID', example='dev'),
      accessKey?: string(name='AccessKey', description='User key', example='test'),
      endpoint?: string(name='Endpoint', description='Endpoint', example='test'),
      workspaceId?: string(name='WorkspaceId', description='Workspace ID', example='test'),
    }(name='UserAccessParam', description='User authorization parameters'),
  }(name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='25859897-35C8-5015-8365-7A3CE52F4854'),
  totalCount?: long(name='TotalCount', description='Total count of the query', example='0'),
}

model GetResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetResource  GetResourceRequest
  * @return GetResourceResponse
 */
async function getResource(request: GetResourceRequest): GetResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetResource', 'POST', '/', 'json', false, 'json', request);
}

model GetResourcePredictResultRequest {
  regionId?: string(name='RegionId', position='Host'),
  resourceId?: long(name='ResourceId', example='36', position='Query'),
  templateId?: long(name='TemplateId', example='315797', position='Query'),
}

model GetResourcePredictResultResponseBody = {
  data?: long(name='Data', example='2'),
  requestId?: string(name='RequestId', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', example='1'),
}

model GetResourcePredictResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetResourcePredictResultResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetResourcePredictResult  GetResourcePredictResultRequest
  * @return GetResourcePredictResultResponse
 */
async function getResourcePredictResult(request: GetResourcePredictResultRequest): GetResourcePredictResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetResourcePredictResult', 'POST', '/', 'json', false, 'json', request);
}

model GetWorkloadRequest {
  regionId?: string(name='RegionId', position='Host'),
  workloadId: long(name='WorkloadId', description='This parameter is required.', example='13', position='Query'),
}

model GetWorkloadResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', example='{}'),
  data?: {
    defaultCpuPerWorker?: int32(name='DefaultCpuPerWorker', example='90'),
    defaultGpuPerWorker?: int32(name='DefaultGpuPerWorker', example='8'),
    defaultMemoryPerWorker?: int32(name='DefaultMemoryPerWorker', example='500'),
    defaultShareMemory?: int32(name='DefaultShareMemory', example='500'),
    family?: string(name='Family', example='AI'),
    jobKind?: string(name='JobKind', example='PyTorchJob'),
    paramSettings?: [ 
      {
        defaultValue?: string(name='DefaultValue', example='100'),
        paramDesc?: string(name='ParamDesc'),
        paramName?: string(name='ParamName', example='ITERATION'),
        paramRegex?: string(name='ParamRegex', example='[0-9]+'),
        paramType?: string(name='ParamType', example='number'),
        paramValue?: string(name='ParamValue', example='100'),
      }
    ](name='ParamSettings'),
    scene?: string(name='Scene', example='NLP-LLM'),
    scope?: string(name='Scope', example='common'),
    staticConfig?: {
      frameWork?: string(name='FrameWork', example='PyTorch'),
      os?: string(name='Os', example='linux'),
      parameters?: string(name='Parameters', example='7B'),
      softwareStack?: string(name='SoftwareStack', example='python'),
    }(name='StaticConfig'),
    versionId?: long(name='VersionId', example='1'),
    workloadDescription?: string(name='WorkloadDescription', example='test'),
    workloadId?: long(name='WorkloadId', example='13'),
    workloadName?: string(name='WorkloadName', example='test'),
    workloadType?: string(name='WorkloadType', example='AI'),
  }(name='Data'),
  requestId?: string(name='RequestId', example='E67E2E4C-2B47-5C55-AA17-1D771E070AEF'),
  totalCount?: long(name='TotalCount', example='0'),
}

model GetWorkloadResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkloadResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetWorkload  GetWorkloadRequest
  * @return GetWorkloadResponse
 */
async function getWorkload(request: GetWorkloadRequest): GetWorkloadResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetWorkload', 'POST', '/', 'json', false, 'json', request);
}

model ListExperimentPlanTemplatesRequest {
  regionId?: string(name='RegionId', position='Host'),
  privacyLevel?: string(name='PrivacyLevel', description='The sharing level of the template, default is private, options are public and private.', example='private', position='Query'),
}

model ListExperimentPlanTemplatesResponseBody = {
  data?: [ 
    {
      createTime?: string(name='CreateTime', description='Creation time', example='2024-11-29 02:16:35'),
      creatorUid?: long(name='CreatorUid', description='Primary account UID', example='178154411231232'),
      isDelete?: int32(name='IsDelete', description='Whether it is deleted', example='0'),
      privacyLevel?: string(name='PrivacyLevel', description='Privacy level', example='private'),
      templateDescription?: string(name='TemplateDescription', description='Template description', example='test'),
      templateId?: long(name='TemplateId', description='Template ID', example='17815441'),
      templateName?: string(name='TemplateName', description='Template name', example='test'),
      templatePipelineParam?: [ 
        {
          envParams?: {
            cpuPerWorker?: int32(name='CpuPerWorker', description='CPU allocation', example='90'),
            gpuPerWorker?: int32(name='GpuPerWorker', description='GPU allocation', example='8'),
            memoryPerWorker?: int32(name='MemoryPerWorker', description='Allocated memory in GB', example='500'),
            shareMemory?: int32(name='ShareMemory', description='Allocated shared memory in GB', example='500'),
            workerNum?: int32(name='WorkerNum', description='Number of nodes', example='1'),
          }(name='EnvParams', description='Configured environment parameters'),
          pipelineOrder?: int32(name='PipelineOrder', description='Node sequence number', example='1'),
          scene?: string(name='Scene', description='Usage scenario, e.g., "baseline"', example='baseline'),
          settingParams?: map[string]string(name='SettingParams', description='Configured workload parameters'),
          workloadId?: long(name='WorkloadId', description='Workload ID', example='13'),
          workloadName?: string(name='WorkloadName', description='Workload name', example='test'),
        }
      ](name='TemplatePipelineParam', description='Template pipeline'),
      updateTime?: string(name='UpdateTime', description='Update time', example='2024-11-29 02:16:35'),
      versionId?: long(name='VersionId', description='Version ID', example='1'),
    }
  ](name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='AAE4AFED-7AE6-52FA-80B6-448E63760552'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model ListExperimentPlanTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListExperimentPlanTemplatesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListExperimentPlanTemplates  ListExperimentPlanTemplatesRequest
  * @return ListExperimentPlanTemplatesResponse
 */
async function listExperimentPlanTemplates(request: ListExperimentPlanTemplatesRequest): ListExperimentPlanTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListExperimentPlanTemplates', 'POST', '/', 'json', false, 'json', request);
}

model ListExperimentPlansRequest {
  regionId?: string(name='RegionId', position='Host'),
  creatTimeOrder?: string(name='CreatTimeOrder', description='Creation Time Sorting Rule', example='desc', position='Query'),
  endTimeOrder?: string(name='EndTimeOrder', description='End Time Sorting Rule', example='desc', position='Query'),
  page?: int32(name='Page', description='Page Number', example='1', position='Query'),
  planTaskStatus?: [ string ](name='PlanTaskStatus', description='Execution Status', shrink='json', position='Body'),
  resourceGroupId?: string(name='ResourceGroupId', description='Resource Group ID', example='rg-aekzij65sf2rr5i', position='Query'),
  resourceName?: [ string ](name='ResourceName', description='Resource', shrink='json', position='Body'),
  size?: int32(name='Size', description='Number of Items', example='100', position='Query'),
  startTimeOrder?: string(name='StartTimeOrder', description='Start Time Sorting Rule', example='desc', position='Query'),
}

model ListExperimentPlansResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access Denied Detail', example='{}'),
  data?: [ 
    {
      createTime?: string(name='CreateTime', description='Creation Time', example='2024-07-08 10:12:42'),
      endTime?: string(name='EndTime', description='End Time', example='2024-07-08 10:22:42'),
      planId?: long(name='PlanId', description='Plan ID', example='189'),
      planTaskStatus?: map[string]int32(name='PlanTaskStatus', description='Test Plan Execution Status'),
      resourceGroupId?: string(name='ResourceGroupId', description='Resource Group ID', example='rg-aek5behqmwbfhuy'),
      resourceName?: string(name='ResourceName', description='Associated Resource Name', example='q_ecs_xpec_postpay_c'),
      startTime?: string(name='StartTime', description='Start Time', example='2024-07-08 10:12:42'),
      templateId?: long(name='TemplateId', description='Associated Test Plan Template ID', example='6'),
      templateName?: string(name='TemplateName', description='Associated Test Plan Template Name', example='test'),
      updateTime?: string(name='UpdateTime', description='Update Time', example='2024-07-08 10:12:42'),
    }
  ](name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='FA9F1DE7-103B-5C18-AE9E-EB2BFF11C685'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model ListExperimentPlansResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListExperimentPlansResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListExperimentPlans  ListExperimentPlansRequest
  * @return ListExperimentPlansResponse
 */
async function listExperimentPlans(request: ListExperimentPlansRequest): ListExperimentPlansResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListExperimentPlans', 'POST', '/', 'json', true, 'form', request);
}

model ListExperimentsRequest {
  regionId?: string(name='RegionId', position='Host'),
  order?: int32(name='Order', description='Order', example='1', position='Query'),
  planId?: long(name='PlanId', description='Plan ID', example='189', position='Query'),
}

model ListExperimentsResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='Access denied information', example='{}'),
  data?: [ 
    {
      createTime?: long(name='CreateTime', description='Creation time', example='2024-10-22 10:18:10'),
      endTime?: string(name='EndTime', description='Task end time', example='2024-10-22 10:28:10'),
      envParams?: {
        cpuPerWorker?: int32(name='CpuPerWorker', description='Number of CPUs allocated', example='90'),
        cudaVersion?: string(name='CudaVersion', description='CUDA version', example='1.0.0'),
        extendParam?: map[string]string(name='ExtendParam', description='Additional parameters'),
        gpuDriverVersion?: string(name='GpuDriverVersion', description='GPU driver version', example='1.0.0'),
        gpuPerWorker?: int32(name='GpuPerWorker', description='Number of GPUs allocated', example='8'),
        memoryPerWorker?: int32(name='MemoryPerWorker', description='Amount of memory (GB) allocated', example='500'),
        NCCLVersion?: string(name='NCCLVersion', description='NCCL version', example='1.0.0'),
        pyTorchVersion?: string(name='PyTorchVersion', description='PyTorch version', example='1.0.0'),
        resourceNodes?: [ 
          {
            nodeName?: string(name='NodeName', description='Node name', example='lingj1xxnjt1k4nv-mg18v52pydyuumae-0'),
            requestCPU?: int32(name='RequestCPU', description='Requested CPU', example='90'),
            requestGPU?: int32(name='RequestGPU', description='Requested GPU', example='8'),
            requestMemory?: int32(name='RequestMemory', description='Requested memory', example='500'),
            totalCPU?: int32(name='TotalCPU', description='Total CPU', example='90'),
            totalGPU?: int32(name='TotalGPU', description='Total GPU', example='8'),
            totalMemory?: long(name='TotalMemory', description='Total memory', example='500'),
          }
        ](name='ResourceNodes', description='Specified nodes'),
        shareMemory?: int32(name='ShareMemory', description='Amount of shared memory (GB) allocated', example='500'),
        workerNum?: int32(name='WorkerNum', description='Number of nodes', example='1'),
      }(name='EnvParams', description='Environment parameters in operation'),
      experimentId?: long(name='ExperimentId', description='Experiment ID', example='1684537476910997506'),
      experimentName?: string(name='ExperimentName', description='Experiment name', example='test'),
      experimentType?: string(name='ExperimentType', description='Experiment type', example='AI'),
      getParams?: map[string]string(name='GetParams', description='Parsed load parameters'),
      resourceName?: string(name='ResourceName', description='Resource name', example='ecs.r8y.4xlarge'),
      results?: {
        duration?: double(name='Duration', description='Duration', example='20'),
        errorWorker?: [ 
          {
            errorFlag?: boolean(name='ErrorFlag', description='Whether there is an error', example='false'),
            errorMsg?: string(name='ErrorMsg', description='Error information', example='error msg'),
            experimentId?: long(name='ExperimentId', description='Experiment ID', example='176'),
            gpuName?: string(name='GpuName', description='GPU name', example='8x OAM 810 GPU'),
            gpuNum?: int32(name='GpuNum', description='Number of GPUs', example='8'),
            hostname?: string(name='Hostname', description='Host IP', example='etcd_cluster_c0n2'),
            podName?: string(name='PodName', description='Pod name', example='fluxserv-6fc89b45cf-w8wq6'),
            samplesPerSecond?: double(name='SamplesPerSecond', description='Throughput', example='65'),
            tflops?: double(name='Tflops', description='TFLOPS value', example='42'),
            warningFlag?: boolean(name='WarningFlag', description='Whether there is an alarm', example='false'),
            warningMsg?: string(name='WarningMsg', description='Alarm information', example='warning msg'),
          }
        ](name='ErrorWorker', description='Error nodes'),
        experimentId?: long(name='ExperimentId', description='Parameter name', example='440'),
        mfu?: double(name='Mfu', description='MFU', example='34'),
        samplesPerSecond?: double(name='SamplesPerSecond', description='Samples per second', example='10'),
        secondsPerIteration?: double(name='SecondsPerIteration', description='Seconds per iteration', example='89'),
        warningWorker?: [ 
          {
            errorFlag?: boolean(name='ErrorFlag', description='Whether there is an error', example='false'),
            errorMsg?: string(name='ErrorMsg', description='Error message', example='error msg'),
            experimentId?: long(name='ExperimentId', description='Experiment ID', example='113'),
            gpuName?: string(name='GpuName', description='GPU name', example='8x OAM 810 GPU'),
            gpuNum?: int32(name='GpuNum', description='Number of GPUs', example='90'),
            hostname?: string(name='Hostname', description='Host IP', example='101.66.165.102'),
            podName?: string(name='PodName', description='Pod name', example='hzs-forge-sdxl-online-7ff4d86444-pc95h'),
            samplesPerSecond?: double(name='SamplesPerSecond', description='Throughput', example='53'),
            tflops?: double(name='Tflops', description='TFLOPS value', example='43'),
            warningFlag?: boolean(name='WarningFlag', description='Whether there is an alarm', example='false'),
            warningMsg?: string(name='WarningMsg', description='Alarm message', example='warning msg'),
          }
        ](name='WarningWorker', description='Warning worker'),
      }(name='Results', description='Task results'),
      setParams?: map[string]string(name='SetParams', description='Load parameters in operation'),
      startTime?: string(name='StartTime', description='Task start time', example='2024-10-22 10:18:10'),
      status?: string(name='Status', description='Status', example='RUNNING'),
      updateTime?: long(name='UpdateTime', description='Update time', example='2024-10-22 10:18:10'),
      workloadName?: string(name='WorkloadName', description='Workload name', example='test'),
    }
  ](name='Data', description='Data'),
  requestId?: string(name='RequestId', description='Request ID', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model ListExperimentsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListExperimentsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListExperiments  ListExperimentsRequest
  * @return ListExperimentsResponse
 */
async function listExperiments(request: ListExperimentsRequest): ListExperimentsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListExperiments', 'POST', '/', 'json', false, 'json', request);
}

model ListWorkloadsRequest {
  regionId?: string(name='RegionId', position='Host'),
  scope?: string(name='Scope', example='common', position='Query'),
}

model ListWorkloadsResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', example='{}'),
  data?: [ 
    {
      defaultCpuPerWorker?: int32(name='DefaultCpuPerWorker', example='90'),
      defaultGpuPerWorker?: int32(name='DefaultGpuPerWorker', example='8'),
      defaultMemoryPerWorker?: int32(name='DefaultMemoryPerWorker', example='500'),
      defaultShareMemory?: int32(name='DefaultShareMemory', example='500'),
      family?: string(name='Family', example='AI'),
      jobKind?: string(name='JobKind', example='PyTorchJob'),
      paramSettings?: [ 
        {
          defaultValue?: string(name='DefaultValue', example='100'),
          paramDesc?: string(name='ParamDesc'),
          paramName?: string(name='ParamName', example='ITERATION'),
          paramRegex?: string(name='ParamRegex', example='[0-9]+'),
          paramType?: string(name='ParamType', example='number'),
          paramValue?: string(name='ParamValue', example='100'),
        }
      ](name='ParamSettings'),
      scene?: string(name='Scene', example='NLP-LLM'),
      scope?: string(name='Scope', example='common'),
      staticConfig?: {
        frameWork?: string(name='FrameWork', example='PyTorch'),
        os?: string(name='Os', example='linux'),
        parameters?: string(name='Parameters', example='7B'),
        softwareStack?: string(name='SoftwareStack', example='python'),
      }(name='StaticConfig'),
      versionId?: long(name='VersionId', example='1'),
      workloadDescription?: string(name='WorkloadDescription', example='test'),
      workloadId?: long(name='WorkloadId', example='13'),
      workloadName?: string(name='WorkloadName', example='test'),
      workloadType?: string(name='WorkloadType', example='AI'),
    }
  ](name='Data'),
  requestId?: string(name='RequestId', example='4AC08332-436C-57A3-9FBA-26772B1A9901'),
  totalCount?: long(name='TotalCount', example='1'),
}

model ListWorkloadsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListWorkloadsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListWorkloads  ListWorkloadsRequest
  * @return ListWorkloadsResponse
 */
async function listWorkloads(request: ListWorkloadsRequest): ListWorkloadsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListWorkloads', 'POST', '/', 'json', false, 'json', request);
}

model StopExperimentRequest {
  regionId?: string(name='RegionId', position='Host'),
  experimentId?: long(name='ExperimentId', example='234', position='Query'),
}

model StopExperimentResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', example='{}'),
  data?: boolean(name='Data', example='true'),
  requestId?: string(name='RequestId', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', example='0'),
}

model StopExperimentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopExperimentResponseBody(name='body'),
}

/**
  * @param request  the request parameters of StopExperiment  StopExperimentRequest
  * @return StopExperimentResponse
 */
async function stopExperiment(request: StopExperimentRequest): StopExperimentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopExperiment', 'POST', '/', 'json', false, 'json', request);
}

model ValidateResourceRequest {
  regionId?: string(name='RegionId', position='Host'),
  clusterId?: string(name='ClusterId', description='Resource ID', example='ehpc-sh-ouypm5aucy', position='Query'),
  userAccessParam?: {
    accessId?: string(name='AccessId', description='User ID', example='dev'),
    accessKey?: string(name='AccessKey', description='User Key', example='test'),
    endpoint?: string(name='Endpoint', description='Endpoint', example='test'),
    workspaceId?: string(name='WorkspaceId', description='Workspace ID', example='test'),
  }(name='UserAccessParam', description='User Authorization Parameters', shrink='json', position='Body'),
}

model ValidateResourceResponseBody = {
  data?: boolean(name='Data', description='Data', example='true'),
  requestId?: string(name='RequestId', description='Request Id', example='5514CB39-B7C0-5B89-8534-2DE1E0F2B7AB'),
  totalCount?: long(name='TotalCount', description='Total', example='0'),
}

model ValidateResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ValidateResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ValidateResource  ValidateResourceRequest
  * @return ValidateResourceResponse
 */
async function validateResource(request: ValidateResourceRequest): ValidateResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ValidateResource', 'POST', '/', 'json', true, 'form', request);
}

model DataResultsTaskIndividualResultMapValue = {
  experimentId?: long(name='ExperimentId', example='54'),
  hostname?: string(name='Hostname', example='p-jt-waf-app1'),
  podName?: string(name='PodName', example='fluxserv-6fc89b45cf-w8wq6'),
  gpuNum?: int32(name='GpuNum', example='8'),
  gpuName?: string(name='GpuName', example='8x OAM 810 GPU'),
  warningFlag?: boolean(name='WarningFlag', example='false'),
  warningMsg?: string(name='WarningMsg'),
  errorFlag?: boolean(name='ErrorFlag', example='false'),
  errorMsg?: string(name='ErrorMsg'),
  tflops?: double(name='Tflops', description='TFLOPS', example='45'),
  samplesPerSecond?: double(name='SamplesPerSecond', example='23'),
}

