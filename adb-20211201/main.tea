/**
 *
 */
import Util;
import OpenApi;
import OpenApiUtil;
import EndpointUtil;

extends OpenApi;


init(config: OpenApi.Config){
  super(config);
  @endpointRule = 'regional';
  @endpointMap = {
    cn-qingdao = 'adb.aliyuncs.com',
    cn-beijing = 'adb.aliyuncs.com',
    cn-hangzhou = 'adb.aliyuncs.com',
    cn-shanghai = 'adb.aliyuncs.com',
    cn-shenzhen = 'adb.aliyuncs.com',
    cn-hongkong = 'adb.aliyuncs.com',
    ap-southeast-1 = 'adb.aliyuncs.com',
    us-west-1 = 'adb.aliyuncs.com',
    us-east-1 = 'adb.aliyuncs.com',
    cn-hangzhou-finance = 'adb.aliyuncs.com',
    cn-north-2-gov-1 = 'adb.aliyuncs.com',
    ap-northeast-2-pop = 'adb.ap-northeast-1.aliyuncs.com',
    cn-beijing-finance-1 = 'adb.aliyuncs.com',
    cn-beijing-finance-pop = 'adb.aliyuncs.com',
    cn-beijing-gov-1 = 'adb.aliyuncs.com',
    cn-beijing-nu16-b01 = 'adb.aliyuncs.com',
    cn-edge-1 = 'adb.aliyuncs.com',
    cn-fujian = 'adb.aliyuncs.com',
    cn-haidian-cm12-c01 = 'adb.aliyuncs.com',
    cn-hangzhou-bj-b01 = 'adb.aliyuncs.com',
    cn-hangzhou-internal-prod-1 = 'adb.aliyuncs.com',
    cn-hangzhou-internal-test-1 = 'adb.aliyuncs.com',
    cn-hangzhou-internal-test-2 = 'adb.aliyuncs.com',
    cn-hangzhou-internal-test-3 = 'adb.aliyuncs.com',
    cn-hangzhou-test-306 = 'adb.aliyuncs.com',
    cn-hongkong-finance-pop = 'adb.aliyuncs.com',
    cn-qingdao-nebula = 'adb.aliyuncs.com',
    cn-shanghai-et15-b01 = 'adb.aliyuncs.com',
    cn-shanghai-et2-b01 = 'adb.aliyuncs.com',
    cn-shanghai-finance-1 = 'adb.aliyuncs.com',
    cn-shanghai-inner = 'adb.aliyuncs.com',
    cn-shanghai-internal-test-1 = 'adb.aliyuncs.com',
    cn-shenzhen-finance-1 = 'adb.aliyuncs.com',
    cn-shenzhen-inner = 'adb.aliyuncs.com',
    cn-shenzhen-st4-d01 = 'adb.aliyuncs.com',
    cn-shenzhen-su18-b01 = 'adb.aliyuncs.com',
    cn-wuhan = 'adb.aliyuncs.com',
    cn-yushanfang = 'adb.aliyuncs.com',
    cn-zhangbei-na61-b01 = 'adb.aliyuncs.com',
    cn-zhangjiakou-na62-a01 = 'adb.aliyuncs.com',
    cn-zhengzhou-nebula-1 = 'adb.aliyuncs.com',
    eu-west-1-oxs = 'adb.ap-northeast-1.aliyuncs.com',
    me-east-1 = 'adb.ap-northeast-1.aliyuncs.com',
    rus-west-1-pop = 'adb.ap-northeast-1.aliyuncs.com',
  };

  checkConfig(config);
  @endpoint = getEndpoint('adb', @regionId, @endpointRule, @network, @suffix, @endpointMap, @endpoint);
}

function getEndpoint(productId: string, regionId: string, endpointRule: string, network: string, suffix: string, endpointMap: map[string]string, endpoint: string) throws: string{
  if (!Util.empty(endpoint)) {
    return endpoint;
  }
  
  if (!Util.isUnset(endpointMap) && !Util.empty(endpointMap[regionId])) {
    return endpointMap[regionId];
  }
  return EndpointUtil.getEndpointRules(productId, regionId, endpointRule, network, suffix);
}

model Adb4MysqlSparkDiagnosisInfo {
  diagnosisCode?: string(name='DiagnosisCode'),
  diagnosisCodeLabel?: string(name='DiagnosisCodeLabel'),
  diagnosisMsg?: string(name='DiagnosisMsg'),
  diagnosisType?: string(name='DiagnosisType', example='APPLICATION'),
}

model ColDetailModel {
  columnName?: string(name='ColumnName'),
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  distributeKey?: boolean(name='DistributeKey'),
  nullable?: boolean(name='Nullable'),
  partitionKey?: boolean(name='PartitionKey'),
  primaryKey?: boolean(name='PrimaryKey'),
  schemaName?: string(name='SchemaName'),
  tableName?: string(name='TableName'),
  type?: string(name='Type'),
  updateTime?: string(name='UpdateTime'),
}

model CstoreIndexModel {
  columnOrds?: [ string ](name='ColumnOrds'),
  createTime?: string(name='CreateTime'),
  databaseName?: string(name='DatabaseName'),
  indexColumns?: [
    FieldSchemaModel
  ](name='IndexColumns'),
  indexName?: string(name='IndexName'),
  indexType?: string(name='IndexType'),
  options?: map[string]string(name='Options'),
  physicalTableName?: string(name='PhysicalTableName'),
  updateTime?: string(name='UpdateTime'),
}

model DatabaseSummaryModel {
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  owner?: string(name='Owner'),
  schemaName?: string(name='SchemaName'),
  updateTime?: string(name='UpdateTime'),
}

model Detail {
  appType?: string(name='AppType', example='BATCH'),
  DBClusterId?: string(name='DBClusterId', example='amv-bp11q28kv****'),
  data?: string(name='Data', example='{     "name": "SparkPi",     "file": "local:///tmp/spark-examples.jar",     "className": "org.apache.spark.examples.SparkPi",     "args": [         "1000000"     ],     "conf": {         "spark.driver.resourceSpec": "small",         "spark.executor.instances": 1,         "spark.executor.resourceSpec": "small"     } }'),
  durationInMillis?: long(name='DurationInMillis', example='100'),
  estimateExecutionCpuTimeInSeconds?: long(name='EstimateExecutionCpuTimeInSeconds', example='100'),
  lastAttemptId?: string(name='LastAttemptId', example='s202204291426hzpre60cfa*****-0003'),
  lastUpdatedTimeInMillis?: long(name='LastUpdatedTimeInMillis', example='1651213645200'),
  logRootPath?: string(name='LogRootPath', example='oss://<bucket-name>/logs/driver'),
  resourceGroupName?: string(name='ResourceGroupName', example='spark-rg'),
  startedTimeInMillis?: long(name='StartedTimeInMillis', example='1651213645010'),
  submittedTimeInMillis?: long(name='SubmittedTimeInMillis', example='1651213645000'),
  terminatedTimeInMillis?: long(name='TerminatedTimeInMillis', example='1651213645300'),
  webUiAddress?: string(name='WebUiAddress', example='https://sparkui.aliyuncs.com/token=xxx'),
}

model FieldSchemaModel {
  autoIncrement?: boolean(name='AutoIncrement'),
  columnRawName?: string(name='ColumnRawName'),
  comment?: string(name='Comment'),
  compressFloatUseShort?: boolean(name='CompressFloatUseShort'),
  compression?: string(name='Compression'),
  createTime?: string(name='CreateTime'),
  dataType?: string(name='DataType'),
  databaseName?: string(name='DatabaseName'),
  defaultValue?: string(name='DefaultValue'),
  delimiter?: string(name='Delimiter'),
  encode?: string(name='Encode'),
  isPartitionKey?: boolean(name='IsPartitionKey'),
  mappedName?: string(name='MappedName'),
  name?: string(name='Name'),
  nullable?: boolean(name='Nullable'),
  onUpdate?: string(name='OnUpdate'),
  ordinalPosition?: long(name='OrdinalPosition'),
  physicalColumnName?: string(name='PhysicalColumnName'),
  pkPosition?: long(name='PkPosition'),
  precision?: long(name='Precision'),
  primarykey?: boolean(name='Primarykey'),
  scale?: long(name='Scale'),
  tableName?: string(name='TableName'),
  tokenizer?: string(name='Tokenizer'),
  type?: string(name='Type'),
  updateTime?: string(name='UpdateTime'),
  valueType?: string(name='ValueType'),
}

model Filters {
  appIdRegex?: string(name='AppIdRegex'),
  appNameRegex?: string(name='AppNameRegex'),
  appState?: string(name='AppState'),
  appType?: string(name='AppType'),
  executionTimeRange?: {
    maxTimeInSeconds?: long(name='MaxTimeInSeconds'),
    minTimeInSeconds?: long(name='MinTimeInSeconds'),
  }(name='ExecutionTimeRange'),
  submitTimeRange?: {
    maxTimeInMills?: long(name='MaxTimeInMills'),
    minTimeInMills?: long(name='MinTimeInMills'),
  }(name='SubmitTimeRange'),
  termiatedTimeRange?: {
    maxTimeInMills?: long(name='MaxTimeInMills'),
    minTimeInMills?: long(name='MinTimeInMills'),
  }(name='TermiatedTimeRange'),
}

model LogAnalyzeResult {
  appErrorAdvice?: string(name='AppErrorAdvice'),
  appErrorCode?: string(name='AppErrorCode', example='EXCEEDED_QUOTA'),
  appErrorLog?: string(name='AppErrorLog', example='exception: xxxx'),
}

model OperatorNode {
  children?: [
    OperatorNode
  ](name='children'),
  id?: int32(name='id'),
  levelWidth?: int32(name='levelWidth'),
  nodeDepth?: int32(name='nodeDepth'),
  nodeName?: string(name='nodeName'),
  nodeWidth?: int32(name='nodeWidth'),
  parentId?: int32(name='parentId'),
  stats?: {
    bytes?: long(name='bytes'),
    outputRows?: long(name='outputRows'),
    parameters?: string(name='parameters'),
    peakMemory?: long(name='peakMemory'),
    timeCost?: long(name='timeCost'),
  }(name='stats'),
}

model SerDeInfoModel {
  name?: string(name='Name'),
  parameters?: map[string]string(name='Parameters'),
  serDeId?: long(name='SerDeId'),
  serializationLib?: string(name='SerializationLib'),
}

model SparkAnalyzeLogTask {
  DBClusterId?: string(name='DBClusterId', example='amv-adbxxxxx'),
  result?: LogAnalyzeResult(name='Result'),
  ruleMatched?: boolean(name='RuleMatched', example='true'),
  startedTimeInMillis?: long(name='StartedTimeInMillis', example='1672123543000'),
  submittedTimeInMillis?: long(name='SubmittedTimeInMillis', example='1672123543000'),
  taskErrMsg?: string(name='TaskErrMsg', example='Driver log not found'),
  taskId?: long(name='TaskId', example='10'),
  taskState?: string(name='TaskState', example='WAITING'),
  terminatedTimeInMillis?: long(name='TerminatedTimeInMillis', example='1672123543000'),
  userId?: long(name='UserId', example='13719918xxx'),
}

model SparkAppInfo {
  appId?: string(name='AppId', example='s202207151211hz0cb4*****'),
  appName?: string(name='AppName', example='Spark Test'),
  DBClusterId?: string(name='DBClusterId', example='amv-23xxxx'),
  detail?: Detail(name='Detail'),
  message?: string(name='Message', example='WARN: Disk is full'),
  priority?: string(name='Priority', example='NORMAL'),
  state?: string(name='State', example='FAILED'),
}

model SparkAttemptInfo {
  attemptId?: string(name='AttemptId', example='s202207151211hz0cb4200*****-0001'),
  detail?: Detail(name='Detail'),
  message?: string(name='Message', example='WARN: Disk is full'),
  priority?: string(name='Priority', example='NORMAL'),
  state?: string(name='State', example='RUNNING'),
}

model SparkOperatorInfo {
  metricValue?: long(name='MetricValue'),
  operatorName?: bytes(name='OperatorName'),
}

model SparkSession {
  active?: string(name='Active', example='true'),
  aliyunUid?: long(name='AliyunUid', example='11123123'),
  sessionId?: long(name='SessionId', example='15'),
  state?: string(name='State', example='idle'),
}

model Statement {
  aliyunUid?: long(name='AliyunUid', example='1111111'),
  code?: string(name='Code', example='SELECT * FROM table'),
  codeState?: string(name='CodeState', example='Waiting'),
  codeType?: string(name='CodeType', example='SQL'),
  endTime?: long(name='EndTime', example='1658987911000'),
  error?: string(name='Error', example='Disk is full'),
  haveRows?: boolean(name='HaveRows', example='true'),
  output?: string(name='Output', example='Spark is running, the ouput is...'),
  resourceGroup?: string(name='ResourceGroup', example='rg1'),
  sessionId?: long(name='SessionId', example='10'),
  startTime?: long(name='StartTime', example='1658977911000'),
  statementId?: long(name='StatementId', example='100'),
  totalCount?: long(name='TotalCount', example='1000'),
}

model StatementInfo {
  code?: string(name='Code'),
  completedTimeInMills?: long(name='CompletedTimeInMills'),
  output?: string(name='Output'),
  process?: float(name='Process'),
  startedTimeInMills?: long(name='StartedTimeInMills'),
  state?: string(name='State'),
  statementId?: string(name='StatementId'),
}

model StorageDescriptorModel {
  compressed?: boolean(name='Compressed'),
  inputFormat?: string(name='InputFormat'),
  location?: string(name='Location'),
  numBuckets?: long(name='NumBuckets'),
  outputFormat?: string(name='OutputFormat'),
  parameters?: map[string]string(name='Parameters'),
  sdId?: long(name='SdId'),
  serDeInfo?: SerDeInfoModel(name='SerDeInfo'),
  storedAsSubDirectories?: boolean(name='StoredAsSubDirectories'),
}

model TableDetailModel {
  catalog?: string(name='Catalog'),
  columns?: [
    ColDetailModel
  ](name='Columns'),
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  owner?: string(name='Owner'),
  schemaName?: string(name='SchemaName'),
  tableName?: string(name='TableName'),
  tableType?: string(name='TableType'),
  updateTime?: string(name='UpdateTime'),
}

model TableModel {
  archiveType?: string(name='ArchiveType'),
  blockSize?: long(name='BlockSize'),
  bucket?: long(name='Bucket'),
  bucketCount?: long(name='BucketCount'),
  cols?: [
    FieldSchemaModel
  ](name='Cols'),
  comment?: string(name='Comment'),
  compression?: string(name='Compression'),
  createTime?: string(name='CreateTime'),
  currentVersion?: long(name='CurrentVersion'),
  dbName?: string(name='DbName'),
  dictEncode?: boolean(name='DictEncode'),
  distributeColumns?: [
    FieldSchemaModel
  ](name='DistributeColumns'),
  distributeType?: string(name='DistributeType'),
  enableDfs?: boolean(name='EnableDfs'),
  hotPartitionCount?: long(name='HotPartitionCount'),
  indexes?: [
    CstoreIndexModel
  ](name='Indexes'),
  isAllIndex?: boolean(name='IsAllIndex'),
  isFulltextDict?: boolean(name='IsFulltextDict'),
  maxColumnId?: long(name='MaxColumnId'),
  parameters?: map[string]string(name='Parameters'),
  partitionColumn?: string(name='PartitionColumn'),
  partitionCount?: long(name='PartitionCount'),
  partitionKeys?: [
    FieldSchemaModel
  ](name='PartitionKeys'),
  partitionType?: string(name='PartitionType'),
  physicalDatabaseName?: string(name='PhysicalDatabaseName'),
  physicalTableName?: string(name='PhysicalTableName'),
  previousVersion?: long(name='PreviousVersion'),
  rawTableName?: string(name='RawTableName'),
  routeColumns?: [
    FieldSchemaModel
  ](name='RouteColumns'),
  routeEffectiveColumn?: FieldSchemaModel(name='RouteEffectiveColumn'),
  routeType?: string(name='RouteType'),
  rtEngineType?: string(name='RtEngineType'),
  rtIndexAll?: boolean(name='RtIndexAll'),
  rtModeType?: string(name='RtModeType'),
  sd?: StorageDescriptorModel(name='Sd'),
  storagePolicy?: string(name='StoragePolicy'),
  subpartitionColumn?: string(name='SubpartitionColumn'),
  subpartitionCount?: long(name='SubpartitionCount'),
  subpartitionType?: string(name='SubpartitionType'),
  tableEngineName?: string(name='TableEngineName'),
  tableName?: string(name='TableName'),
  tableType?: string(name='TableType'),
  tblId?: long(name='TblId'),
  temporary?: boolean(name='Temporary'),
  updateTime?: string(name='UpdateTime'),
  viewExpandedText?: string(name='ViewExpandedText'),
  viewOriginalText?: string(name='ViewOriginalText'),
  viewSecurityMode?: string(name='ViewSecurityMode'),
}

model TableSummaryModel {
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  owner?: string(name='Owner'),
  SQL?: string(name='SQL'),
  schemaName?: string(name='SchemaName'),
  tableName?: string(name='TableName'),
  tableSize?: long(name='TableSize'),
  tableType?: string(name='TableType'),
  updateTime?: string(name='UpdateTime'),
}

model AllocateClusterPublicConnectionRequest {
  connectionStringPrefix?: string(name='ConnectionStringPrefix', description='The prefix of the public endpoint.

*   The prefix can contain lowercase letters, digits, and hyphens (-). It must start with a lowercase letter.
*   The prefix can be up to 30 characters in length.', example='test12'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1z5d2q71is2****'),
}

model AllocateClusterPublicConnectionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='868EF07F-D0B2-5043-B092-0C14CD00B65A'),
}

model AllocateClusterPublicConnectionResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: AllocateClusterPublicConnectionResponseBody(name='body'),
}

async function allocateClusterPublicConnectionWithOptions(request: AllocateClusterPublicConnectionRequest, runtime: Util.RuntimeOptions): AllocateClusterPublicConnectionResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.connectionStringPrefix)) {
    query['ConnectionStringPrefix'] = request.connectionStringPrefix;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'AllocateClusterPublicConnection',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function allocateClusterPublicConnection(request: AllocateClusterPublicConnectionRequest): AllocateClusterPublicConnectionResponse {
  var runtime = new Util.RuntimeOptions{};
  return allocateClusterPublicConnectionWithOptions(request, runtime);
}

model AttachUserENIRequest {
  DBClusterId?: string(name='DBClusterId', example='am-bp11q28kvl688****'),
}

model AttachUserENIResponseBody = {
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model AttachUserENIResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: AttachUserENIResponseBody(name='body'),
}

async function attachUserENIWithOptions(request: AttachUserENIRequest, runtime: Util.RuntimeOptions): AttachUserENIResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'AttachUserENI',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function attachUserENI(request: AttachUserENIRequest): AttachUserENIResponse {
  var runtime = new Util.RuntimeOptions{};
  return attachUserENIWithOptions(request, runtime);
}

model BindAccountRequest {
  accountName?: string(name='AccountName', description='The standard account of the cluster.', example='test_accout'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz99d9nh532****'),
  ramUser?: string(name='RamUser', description='The ID of the RAM user.', example='1444832459****'),
}

model BindAccountResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='DFF27323-3868-5F8A-917D-5D1D06B6BC0D'),
}

model BindAccountResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: BindAccountResponseBody(name='body'),
}

async function bindAccountWithOptions(request: BindAccountRequest, runtime: Util.RuntimeOptions): BindAccountResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.accountName)) {
    query['AccountName'] = request.accountName;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.ramUser)) {
    query['RamUser'] = request.ramUser;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'BindAccount',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function bindAccount(request: BindAccountRequest): BindAccountResponse {
  var runtime = new Util.RuntimeOptions{};
  return bindAccountWithOptions(request, runtime);
}

model BindDBResourceGroupWithUserRequest {
  DBClusterId?: string(name='DBClusterId', example='am-bp1ub9grke1****'),
  groupName?: string(name='GroupName', example='test'),
  groupUser?: string(name='GroupUser', example='accout'),
}

model BindDBResourceGroupWithUserResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model BindDBResourceGroupWithUserResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: BindDBResourceGroupWithUserResponseBody(name='body'),
}

async function bindDBResourceGroupWithUserWithOptions(request: BindDBResourceGroupWithUserRequest, runtime: Util.RuntimeOptions): BindDBResourceGroupWithUserResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  if (!Util.isUnset(request.groupUser)) {
    query['GroupUser'] = request.groupUser;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'BindDBResourceGroupWithUser',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function bindDBResourceGroupWithUser(request: BindDBResourceGroupWithUserRequest): BindDBResourceGroupWithUserResponse {
  var runtime = new Util.RuntimeOptions{};
  return bindDBResourceGroupWithUserWithOptions(request, runtime);
}

model CheckBindRamUserRequest {
  DBClusterId?: string(name='DBClusterId', example='amv-wz9842849v6****'),
  regionId?: string(name='RegionId', example='cn-hangzhou'),
}

model CheckBindRamUserResponseBody = {
  requestId?: string(name='RequestId', example='2FB9DCA3-DA56-5B43-A9A0-68E3D0E6AA84'),
  result?: boolean(name='Result', example='true'),
}

model CheckBindRamUserResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CheckBindRamUserResponseBody(name='body'),
}

async function checkBindRamUserWithOptions(request: CheckBindRamUserRequest, runtime: Util.RuntimeOptions): CheckBindRamUserResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CheckBindRamUser',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function checkBindRamUser(request: CheckBindRamUserRequest): CheckBindRamUserResponse {
  var runtime = new Util.RuntimeOptions{};
  return checkBindRamUserWithOptions(request, runtime);
}

model CheckSampleDataSetRequest {
  DBClusterId?: string(name='DBClusterId', example='amv-wz9r8f67h4cqz41u'),
}

model CheckSampleDataSetResponseBody = {
  requestId?: string(name='RequestId', example='0CE655C3-C211-513D-A42F-D4AE2D1A867C'),
  status?: string(name='Status', example='UNINITIALIZED'),
}

model CheckSampleDataSetResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CheckSampleDataSetResponseBody(name='body'),
}

async function checkSampleDataSetWithOptions(request: CheckSampleDataSetRequest, runtime: Util.RuntimeOptions): CheckSampleDataSetResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CheckSampleDataSet',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function checkSampleDataSet(request: CheckSampleDataSetRequest): CheckSampleDataSetResponse {
  var runtime = new Util.RuntimeOptions{};
  return checkSampleDataSetWithOptions(request, runtime);
}

model CreateAccountRequest {
  accountDescription?: string(name='AccountDescription', description='The description of the database account.

*   The description cannot start with `http://` or `https://`.
*   The description can be up to 256 characters in length.'),
  accountName?: string(name='AccountName', description='The name of the database account.

*   The name must start with a lowercase letter and end with a lowercase letter or a digit.
*   The name can contain lowercase letters, digits, and underscores (\\_).
*   The name must be 2 to 16 characters in length.
*   Reserved account names such as root, admin, and opsadmin cannot be used.', example='test_accout'),
  accountPassword?: string(name='AccountPassword', description='The password of the database account.

*   The password must contain at least three of the following character types: uppercase letters, lowercase letters, digits, and special characters.
*   Special characters include `! @ # $ % ^ & * ( ) _ + - =`
*   The password must be 8 to 32 characters in length.', example='Test_accout1'),
  accountType?: string(name='AccountType', description='The type of the database account. Valid values:

*   **Normal**: standard account.
*   **Super**: privileged account.', example='Normal'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
}

model CreateAccountResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='2FED790E-FB61-4721-8C1C-07C627FA5A19'),
}

model CreateAccountResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CreateAccountResponseBody(name='body'),
}

async function createAccountWithOptions(request: CreateAccountRequest, runtime: Util.RuntimeOptions): CreateAccountResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.accountDescription)) {
    query['AccountDescription'] = request.accountDescription;
  }
  if (!Util.isUnset(request.accountName)) {
    query['AccountName'] = request.accountName;
  }
  if (!Util.isUnset(request.accountPassword)) {
    query['AccountPassword'] = request.accountPassword;
  }
  if (!Util.isUnset(request.accountType)) {
    query['AccountType'] = request.accountType;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateAccount',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function createAccount(request: CreateAccountRequest): CreateAccountResponse {
  var runtime = new Util.RuntimeOptions{};
  return createAccountWithOptions(request, runtime);
}

model CreateDBClusterRequest {
  backupSetId?: string(name='BackupSetId', description='The ID of the backup set that you want to use to restore data.

>  You can call the [DescribeBackups](~~612318~~) operation to query the backup sets of the cluster.', example='1880808684'),
  computeResource?: string(name='ComputeResource', description='The amount of reserved computing resources. Unit: ACUs. Valid values: 0 to 4096. The value must be in increments of 16 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.

>  This parameter must be specified with a unit.', example='16ACU'),
  DBClusterDescription?: string(name='DBClusterDescription', description='The description of the cluster.

*   The description cannot start with `http://` or `https://`.
*   The description must be 2 to 256 characters in length', example='test'),
  DBClusterNetworkType?: string(name='DBClusterNetworkType', description='The network type of the cluster. Only **VPC** is supported.', example='VPC'),
  DBClusterVersion?: string(name='DBClusterVersion', description='The version of the cluster. Set the value to **5.0**.', example='5.0'),
  enableDefaultResourcePool?: boolean(name='EnableDefaultResourcePool', description='Specifies whether to allocate all reserved computing resources to the user_default resource group. Valid values:

*   **true** (default)
*   **false**', example='true'),
  payType?: string(name='PayType', description='The billing method of the cluster. Valid values:

*   **Postpaid**: pay-as-you-go.
*   **Prepaid**: subscription.', example='Prepaid'),
  period?: string(name='Period', description='The subscription type of the subscription cluster. Valid values:

*   **Year**: subscription on a yearly basis.
*   **Month**: subscription on a monthly basis.

>  This parameter must be specified when PayType is set to Prepaid.', example='Month'),
  regionId?: string(name='RegionId', description='The region ID.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou'),
  resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='rg-4690g37929****'),
  restoreToTime?: string(name='RestoreToTime', description='The point in time to which you want to restore data from the backup set.', example='2023-09-20T03:13:56Z'),
  restoreType?: string(name='RestoreType', description='The method that you want to use to restore data. Valid values:

*   **backup**: restores data from a backup set. You must also specify the **BackupSetId** and **SourceDBClusterId** parameters.
*   **timepoint**: restores data to a point in time. You must also specify the **RestoreToTime** and **SourceDBClusterId** parameters.', example='backup'),
  sourceDbClusterId?: string(name='SourceDbClusterId', description='The ID of the source AnalyticDB for MySQL Data Warehouse Edition cluster. If you want to restore a Data Lakehouse Edition cluster from a Data Warehouse Edition cluster, you must specify this parameter.', example='amv-bp1r053byu48p****'),
  storageResource?: string(name='StorageResource', description='The amount of reserved storage resources. Unit: AnalyticDB compute units (ACUs). Valid values: 0 to 2064. The value must be in increments of 24 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.

>  This parameter must be specified with a unit.', example='24ACU'),
  tag?: [ 
    {
      key?: string(name='Key', description='The key of tag N to add to the cluster. You can use tags to filter clusters. Valid values of N: 1 to 20. The values that you specify for N must be unique and consecutive integers that start from 1. Each value of `Tag.N.Key` is paired with a value of `Tag.N.Value`.

>  The tag key can be up to 64 characters in length and cannot start with `aliyun`, `acs:`, `http://`, or `https://`.', example='testkey1'),
      value?: string(name='Value', description='The value of tag N to add to the cluster. You can use tags to filter clusters. Valid values of N: 1 to 20. The values that you specify for N must be unique and consecutive integers that start from 1. Each value of `Tag.N.Key` is paired with a value of `Tag.N.Value`.

>  The tag value can be up to 64 characters in length and cannot start with `aliyun`, `acs:`, `http://`, or `https://`.', example='test1'),
    }
  ](name='Tag', description='The tags to add to the cluster.'),
  usedTime?: string(name='UsedTime', description='The subscription duration of the subscription cluster.

*   Valid values when **Period** is set to Year: 1 to 3 (integer).
*   Valid values when **Period** is set to Month: 1 to 9 (integer).

>  This parameter must be specified when PayType is set to **Prepaid**.', example='3'),
  VPCId?: string(name='VPCId', description='The virtual private cloud (VPC) ID of the cluster.', example='vpc-bp1at5ze0t5u3xtqn****'),
  vSwitchId?: string(name='VSwitchId', description='The vSwitch ID of the cluster.', example='vsw-bp1aadw9k19x6cis9****'),
  zoneId?: string(name='ZoneId', description='The zone ID.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent zone list.', example='cn-hangzhou-h'),
}

model CreateDBClusterResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  orderId?: string(name='OrderId', description='The order ID.', example='202353278****'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  resourceGroupId?: string(name='ResourceGroupId', description='The default resource group ID.', example='rg-4690g37929****'),
}

model CreateDBClusterResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CreateDBClusterResponseBody(name='body'),
}

async function createDBClusterWithOptions(request: CreateDBClusterRequest, runtime: Util.RuntimeOptions): CreateDBClusterResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.backupSetId)) {
    query['BackupSetId'] = request.backupSetId;
  }
  if (!Util.isUnset(request.computeResource)) {
    query['ComputeResource'] = request.computeResource;
  }
  if (!Util.isUnset(request.DBClusterDescription)) {
    query['DBClusterDescription'] = request.DBClusterDescription;
  }
  if (!Util.isUnset(request.DBClusterNetworkType)) {
    query['DBClusterNetworkType'] = request.DBClusterNetworkType;
  }
  if (!Util.isUnset(request.DBClusterVersion)) {
    query['DBClusterVersion'] = request.DBClusterVersion;
  }
  if (!Util.isUnset(request.enableDefaultResourcePool)) {
    query['EnableDefaultResourcePool'] = request.enableDefaultResourcePool;
  }
  if (!Util.isUnset(request.payType)) {
    query['PayType'] = request.payType;
  }
  if (!Util.isUnset(request.period)) {
    query['Period'] = request.period;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.resourceGroupId)) {
    query['ResourceGroupId'] = request.resourceGroupId;
  }
  if (!Util.isUnset(request.restoreToTime)) {
    query['RestoreToTime'] = request.restoreToTime;
  }
  if (!Util.isUnset(request.restoreType)) {
    query['RestoreType'] = request.restoreType;
  }
  if (!Util.isUnset(request.sourceDbClusterId)) {
    query['SourceDbClusterId'] = request.sourceDbClusterId;
  }
  if (!Util.isUnset(request.storageResource)) {
    query['StorageResource'] = request.storageResource;
  }
  if (!Util.isUnset(request.tag)) {
    query['Tag'] = request.tag;
  }
  if (!Util.isUnset(request.usedTime)) {
    query['UsedTime'] = request.usedTime;
  }
  if (!Util.isUnset(request.VPCId)) {
    query['VPCId'] = request.VPCId;
  }
  if (!Util.isUnset(request.vSwitchId)) {
    query['VSwitchId'] = request.vSwitchId;
  }
  if (!Util.isUnset(request.zoneId)) {
    query['ZoneId'] = request.zoneId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateDBCluster',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function createDBCluster(request: CreateDBClusterRequest): CreateDBClusterResponse {
  var runtime = new Util.RuntimeOptions{};
  return createDBClusterWithOptions(request, runtime);
}

model CreateDBResourceGroupRequest {
  clusterMode?: string(name='ClusterMode', description='A reserved parameter.', example='N/A'),
  clusterSizeResource?: string(name='ClusterSizeResource', description='A reserved parameter.', example='N/A'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  groupName?: string(name='GroupName', description='The name of the resource group.

*   The name can be up to 255 characters in length.
*   The name must start with a letter or a digit.
*   The name can contain letters, digits, hyphens (\\_), and underscores (\\_).', example='test_group'),
  groupType?: string(name='GroupType', description='The type of the resource group. Valid values:

*   **Interactive**
*   **Job**

> For information about resource groups of Data Lakehouse Edition, see [Resource groups](~~428610~~).', example='Job'),
  maxClusterCount?: int32(name='MaxClusterCount', description='A reserved parameter.', example='N/A'),
  maxComputeResource?: string(name='MaxComputeResource', description='The maximum reserved computing resources. Unit: ACU.

*   If GroupType is set to Interactive, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 16 ACUs.
*   If GroupType is set to Job, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 8 ACUs.', example='48'),
  minClusterCount?: int32(name='MinClusterCount', description='A reserved parameter.', example='N/A'),
  minComputeResource?: string(name='MinComputeResource', description='The minimum reserved computing resources. Unit: AnalyticDB Compute Units (ACUs).

*   When GroupType is set to Interactive, set this parameter to 16 ACUs.
*   When GroupType is set to Job, set this parameter to 0 ACUs.', example='0'),
}

model CreateDBResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A94B6C02-7BD4-5D67-9776-3AC8317E8DD5'),
}

model CreateDBResourceGroupResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CreateDBResourceGroupResponseBody(name='body'),
}

async function createDBResourceGroupWithOptions(request: CreateDBResourceGroupRequest, runtime: Util.RuntimeOptions): CreateDBResourceGroupResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.clusterMode)) {
    query['ClusterMode'] = request.clusterMode;
  }
  if (!Util.isUnset(request.clusterSizeResource)) {
    query['ClusterSizeResource'] = request.clusterSizeResource;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  if (!Util.isUnset(request.groupType)) {
    query['GroupType'] = request.groupType;
  }
  if (!Util.isUnset(request.maxClusterCount)) {
    query['MaxClusterCount'] = request.maxClusterCount;
  }
  if (!Util.isUnset(request.maxComputeResource)) {
    query['MaxComputeResource'] = request.maxComputeResource;
  }
  if (!Util.isUnset(request.minClusterCount)) {
    query['MinClusterCount'] = request.minClusterCount;
  }
  if (!Util.isUnset(request.minComputeResource)) {
    query['MinComputeResource'] = request.minComputeResource;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateDBResourceGroup',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function createDBResourceGroup(request: CreateDBResourceGroupRequest): CreateDBResourceGroupResponse {
  var runtime = new Util.RuntimeOptions{};
  return createDBResourceGroupWithOptions(request, runtime);
}

model CreateElasticPlanRequest {
  autoScale?: boolean(name='AutoScale', description='Specifies whether to enable **Proportional Default Scaling for EIUs**.

Valid values:

*   true: enables Proportional Default Scaling for EIUs. If you enable Proportional Default Scaling, storage resources are scaled along with computing resources, and the TargetSize and CronExpression parameters are not supported.

*   false: does not enable Proportional Default Scaling for EIUs.

> *   This parameter is required if the Type parameter is set to WORKER. This parameter is not required if the Type parameter is set to EXECUTOR.
> *   You can enable Proportional Default Scaling for EIUs for only a single scaling plan of a cluster.', example='false'),
  cronExpression?: string(name='CronExpression', description='A CORN expression that specifies the scaling cycle and time for the scaling plan.', example='0 20 14 * * ?'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the ID of an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****'),
  elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.

>  The name must be 2 to 30 characters in length, and can contain letters, digits, and underscores (\\_). It must start with a letter.', example='test'),
  enabled?: boolean(name='Enabled', description='Specifies whether to immediately enable the scaling plan after the scaling plan is created.

Valid values:

*   true: immediately enables the scaling plan.
*   false: does not immediately enable the scaling plan.', example='true'),
  endTime?: string(name='EndTime', description='The time to end the scaling plan.

>  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2025-01-01T12:01:00Z'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> *   This parameter is required if you want to create a scaling plan that uses interactive resource groups. This parameter is not required if you want to create a scaling plan that uses elastic I/O units (EIUs).
> *   You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group within a specific cluster.', example='test'),
  startTime?: string(name='StartTime', description='The time to start the scaling plan.

>  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-01-01T12:01:00Z'),
  targetSize?: string(name='TargetSize', description='The amount of elastic resources after scaling.

> *   This parameter is not required only if the resource group uses **EIUs** and **Proportional Default Scaling for EIUs** is enabled.
> *   You can call the [DescribeElasticPlanSpecifications](~~601278~~) operation to query the specifications that are supported for scaling plans.', example='32ACU'),
  type?: string(name='Type', description='The type of the scaling plan.

Valid values:

*   EXECUTOR: interactive resource groups, which fall into the computing resource category.
*   WORKER: EIUs.', example='EXECUTOR'),
}

model CreateElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model CreateElasticPlanResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CreateElasticPlanResponseBody(name='body'),
}

async function createElasticPlanWithOptions(request: CreateElasticPlanRequest, runtime: Util.RuntimeOptions): CreateElasticPlanResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.autoScale)) {
    query['AutoScale'] = request.autoScale;
  }
  if (!Util.isUnset(request.cronExpression)) {
    query['CronExpression'] = request.cronExpression;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.elasticPlanName)) {
    query['ElasticPlanName'] = request.elasticPlanName;
  }
  if (!Util.isUnset(request.enabled)) {
    query['Enabled'] = request.enabled;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.resourceGroupName)) {
    query['ResourceGroupName'] = request.resourceGroupName;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.targetSize)) {
    query['TargetSize'] = request.targetSize;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'CreateElasticPlan',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function createElasticPlan(request: CreateElasticPlanRequest): CreateElasticPlanResponse {
  var runtime = new Util.RuntimeOptions{};
  return createElasticPlanWithOptions(request, runtime);
}

model CreateOssSubDirectoryRequest {
  DBClusterId?: string(name='DBClusterId'),
  path?: string(name='Path'),
}

model CreateOssSubDirectoryResponseBody = {
  data?: {
    clientCRC?: long(name='ClientCRC'),
    ETag?: string(name='ETag'),
    requestId?: string(name='RequestId'),
    serverCRC?: long(name='ServerCRC'),
  }(name='Data'),
  httpStatusCode?: long(name='HttpStatusCode'),
  message?: string(name='Message'),
  requestId?: string(name='RequestId'),
  success?: boolean(name='Success'),
}

model CreateOssSubDirectoryResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CreateOssSubDirectoryResponseBody(name='body'),
}

async function createOssSubDirectoryWithOptions(request: CreateOssSubDirectoryRequest, runtime: Util.RuntimeOptions): CreateOssSubDirectoryResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.path)) {
    body['Path'] = request.path;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'CreateOssSubDirectory',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function createOssSubDirectory(request: CreateOssSubDirectoryRequest): CreateOssSubDirectoryResponse {
  var runtime = new Util.RuntimeOptions{};
  return createOssSubDirectoryWithOptions(request, runtime);
}

model CreateSparkTemplateRequest {
  appType?: string(name='AppType', description='The type of the application. Valid values:

*   **SQL**: SQL application
*   **STREAMING**: streaming application
*   **BATCH**: batch application

>  This parameter is not required if the application template is of the folder type.', example='SQL'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  name?: string(name='Name', description='The name of the application template. The name can be up to 64 characters in length.', example='batchfile'),
  parentId?: long(name='ParentId', description='The ID of the directory to which the application template belongs.', example='10'),
  type?: string(name='Type', description='The type of the application template. Valid values:

*   **folder**: directory
*   **file**: application', example='file'),
}

model CreateSparkTemplateResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the application template is created. Valid values:

*   **true**: The application template is created.
*   **false**: The application fails to be created.', example='True'),
  }(name='Data', description='The creation result.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model CreateSparkTemplateResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CreateSparkTemplateResponseBody(name='body'),
}

async function createSparkTemplateWithOptions(request: CreateSparkTemplateRequest, runtime: Util.RuntimeOptions): CreateSparkTemplateResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.appType)) {
    body['AppType'] = request.appType;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.name)) {
    body['Name'] = request.name;
  }
  if (!Util.isUnset(request.parentId)) {
    body['ParentId'] = request.parentId;
  }
  if (!Util.isUnset(request.type)) {
    body['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'CreateSparkTemplate',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function createSparkTemplate(request: CreateSparkTemplateRequest): CreateSparkTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return createSparkTemplateWithOptions(request, runtime);
}

model DeleteAccountRequest {
  accountName?: string(name='AccountName', description='The name of the database account.

> You can call the [DescribeAccounts](~~612430~~) operation to query the information about database accounts in a cluster, including the database account name.', example='test_accout'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
}

model DeleteAccountResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='2FED790E-FB61-4721-8C1C-07C627FA5A19'),
}

model DeleteAccountResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteAccountResponseBody(name='body'),
}

async function deleteAccountWithOptions(request: DeleteAccountRequest, runtime: Util.RuntimeOptions): DeleteAccountResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.accountName)) {
    query['AccountName'] = request.accountName;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteAccount',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function deleteAccount(request: DeleteAccountRequest): DeleteAccountResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteAccountWithOptions(request, runtime);
}

model DeleteDBClusterRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1r053byu48p****'),
}

model DeleteDBClusterResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DeleteDBClusterResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteDBClusterResponseBody(name='body'),
}

/**
  * ###
  * You can call this operation to delete only subscription clusters.
  *
  * @param request DeleteDBClusterRequest
  * @param runtime runtime options for this request RuntimeOptions
  * @return DeleteDBClusterResponse
 */
async function deleteDBClusterWithOptions(request: DeleteDBClusterRequest, runtime: Util.RuntimeOptions): DeleteDBClusterResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteDBCluster',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
  * ###
  * You can call this operation to delete only subscription clusters.
  *
  * @param request DeleteDBClusterRequest
  * @return DeleteDBClusterResponse
 */
async function deleteDBCluster(request: DeleteDBClusterRequest): DeleteDBClusterResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteDBClusterWithOptions(request, runtime);
}

model DeleteDBResourceGroupRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  groupName?: string(name='GroupName', description='The name of the resource group.

> You can call the [DescribeDBResourceGroup](~~612410~~) operation to query the resource group information of a cluster, including the resource group name.', example='test_group'),
}

model DeleteDBResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A94B6C02-7BD4-5D67-9776-3AC8317E8DD3'),
}

model DeleteDBResourceGroupResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteDBResourceGroupResponseBody(name='body'),
}

async function deleteDBResourceGroupWithOptions(request: DeleteDBResourceGroupRequest, runtime: Util.RuntimeOptions): DeleteDBResourceGroupResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteDBResourceGroup',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function deleteDBResourceGroup(request: DeleteDBResourceGroupRequest): DeleteDBResourceGroupResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteDBResourceGroupWithOptions(request, runtime);
}

model DeleteElasticPlanRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the cluster IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a specific region.', example='amv-wz9509beptiz****'),
  elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the name of a scaling plan for a specific cluster.', example='test'),
}

model DeleteElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model DeleteElasticPlanResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteElasticPlanResponseBody(name='body'),
}

async function deleteElasticPlanWithOptions(request: DeleteElasticPlanRequest, runtime: Util.RuntimeOptions): DeleteElasticPlanResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.elasticPlanName)) {
    query['ElasticPlanName'] = request.elasticPlanName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteElasticPlan',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function deleteElasticPlan(request: DeleteElasticPlanRequest): DeleteElasticPlanResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteElasticPlanWithOptions(request, runtime);
}

model DeleteProcessInstanceRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='am-wz9rq819u71ig****'),
  processInstanceId?: long(name='ProcessInstanceId', description='The ID of the workflow instance.', example='4017'),
  projectCode?: long(name='ProjectCode', description='The project ID, which is the unique identifier of the project.', example='9839028042592'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
}

model DeleteProcessInstanceResponseBody = {
  data?: boolean(name='Data', description='Indicates whether the workflow instance is deleted. Valid values:

*   **true**
*   **false**', example='true'),
  message?: string(name='Message', description='The returned message. Valid values:

*   If the request was successful, **Success** is returned.
*   If the request failed, an error message is returned.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='115F9CCA-EF2E-5F91-AB60-4961D52FEAB4'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DeleteProcessInstanceResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteProcessInstanceResponseBody(name='body'),
}

async function deleteProcessInstanceWithOptions(request: DeleteProcessInstanceRequest, runtime: Util.RuntimeOptions): DeleteProcessInstanceResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.processInstanceId)) {
    query['ProcessInstanceId'] = request.processInstanceId;
  }
  if (!Util.isUnset(request.projectCode)) {
    query['ProjectCode'] = request.projectCode;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DeleteProcessInstance',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function deleteProcessInstance(request: DeleteProcessInstanceRequest): DeleteProcessInstanceResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteProcessInstanceWithOptions(request, runtime);
}

model DeleteSparkTemplateRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  id?: long(name='Id', description='The ID of the directory or application to which the template belongs.

> *   You can call the [GetSparkTemplateFullTree](~~456205~~) operation to query the directory ID or application ID.
> *   If you specify a directory ID, the entire directory is deleted.', example='725204'),
}

model DeleteSparkTemplateResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the template is deleted. Valid values:

*   **true**: The template is deleted.
*   **false**: The template fails to be deleted.', example='True'),
  }(name='Data', description='The result returned.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DeleteSparkTemplateResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteSparkTemplateResponseBody(name='body'),
}

async function deleteSparkTemplateWithOptions(request: DeleteSparkTemplateRequest, runtime: Util.RuntimeOptions): DeleteSparkTemplateResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.id)) {
    body['Id'] = request.id;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'DeleteSparkTemplate',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function deleteSparkTemplate(request: DeleteSparkTemplateRequest): DeleteSparkTemplateResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteSparkTemplateWithOptions(request, runtime);
}

model DeleteSparkTemplateFileRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1y769u11748****'),
  id?: long(name='Id', description='The ID of the template file to be deleted.

>  You can call the [GetSparkTemplateFullTree](~~456205#doc-api-adb-GetSparkTemplateFullTree~~) operation to query the IDs of all existing template files.', example='284'),
}

model DeleteSparkTemplateFileResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the template file is deleted. Valid values:

*   **true**: The template file is deleted.
*   **false**: The template file fails to be deleted.', example='true'),
  }(name='Data', description='The deletion result.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='C3A9594F-1D40-4472-A96C-8FB8AA20D38C'),
}

model DeleteSparkTemplateFileResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteSparkTemplateFileResponseBody(name='body'),
}

async function deleteSparkTemplateFileWithOptions(request: DeleteSparkTemplateFileRequest, runtime: Util.RuntimeOptions): DeleteSparkTemplateFileResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.id)) {
    body['Id'] = request.id;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'DeleteSparkTemplateFile',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function deleteSparkTemplateFile(request: DeleteSparkTemplateFileRequest): DeleteSparkTemplateFileResponse {
  var runtime = new Util.RuntimeOptions{};
  return deleteSparkTemplateFileWithOptions(request, runtime);
}

model DescribeAccountAllPrivilegesRequest {
  accountName?: string(name='AccountName', description='The name of the database account.', example='account1'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp14t95lun0w****'),
  marker?: string(name='Marker', description='Specifies the start position marker from which to return results. If you receive a response indicating that the results are truncated, set this parameter to the value of the `Marker` parameter in the response that you received.', example='EXAMPLE'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
}

model DescribeAccountAllPrivilegesResponseBody = {
  data?: {
    marker?: string(name='Marker', description='Indicates the position where the results are truncated. When a value of `true` is returned for the `Truncated` parameter, this parameter is present and contains the value to use for the Marker parameter in a subsequent call.', example='0573e74fd1ccb01739993a691e876074db6e1b6ad79f54115f0e98528432ba6a523cfec5780ade5189299cc3396f6ff7'),
    result?: [ 
      {
        privilegeObject?: {
          column?: string(name='Column', description='The name of the column.', example='id'),
          database?: string(name='Database', description='The name of the database.', example='tdb1'),
          description?: string(name='Description', description='The description of the permission object.', example='id of table'),
          table?: string(name='Table', description='The name of the table.', example='table1'),
        }(name='PrivilegeObject', description='The objects on which the permission takes effect, including databases, tables, and columns. If Global is returned for the PrivilegeType parameter, an empty string is returned for this parameter.'),
        privilegeType?: string(name='PrivilegeType', description='The permission level of the database account. You can call the `DescribeEnabledPrivileges` operation to query the permission level of the database account.', example='Global'),
        privileges?: [ string ](name='Privileges', description='The name of the permission, which is the same as the permission name returned by the `DescribeEnabledPrivileges` operation.'),
      }
    ](name='Result', description='The permissions.'),
    truncated?: boolean(name='Truncated', description='Indicates whether the results are truncated. If the results are truncated, a value of `true` is returned. In this case, you must call this operation again to obtain all the results until a value of `false` is returned for this parameter.', example='true'),
  }(name='Data', description='Details of the permissions.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='3BB185E9-BB54-1727-B876-13243E4C0EB5'),
}

model DescribeAccountAllPrivilegesResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAccountAllPrivilegesResponseBody(name='body'),
}

async function describeAccountAllPrivilegesWithOptions(request: DescribeAccountAllPrivilegesRequest, runtime: Util.RuntimeOptions): DescribeAccountAllPrivilegesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.accountName)) {
    query['AccountName'] = request.accountName;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.marker)) {
    query['Marker'] = request.marker;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeAccountAllPrivileges',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeAccountAllPrivileges(request: DescribeAccountAllPrivilegesRequest): DescribeAccountAllPrivilegesResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeAccountAllPrivilegesWithOptions(request, runtime);
}

model DescribeAccountPrivilegeObjectsRequest {
  accountName?: string(name='AccountName', description='The name of the database account.', example='test'),
  columnPrivilegeObject?: string(name='ColumnPrivilegeObject', description='The column name that is used to filter columns.', example='col1'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1k3wdmt139****'),
  databasePrivilegeObject?: string(name='DatabasePrivilegeObject', description='The database name that is used to filter databases.', example='database1'),
  pageNumber?: string(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries per page. Default value: 20.', example='20'),
  privilegeType?: string(name='PrivilegeType', description='The permission level. Valid values: Database, Table, and Column. Global is not supported.', example='Column'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='ch-hangzhou'),
  tablePrivilegeObject?: string(name='TablePrivilegeObject', description='The table name that is used to filter tables.', example='table1'),
}

model DescribeAccountPrivilegeObjectsResponseBody = {
  data?: [ 
    {
      column?: string(name='Column', description='The name of the column. This parameter is returned when PrivilegeType is set to Column.', example='column1'),
      database?: string(name='Database', description='The name of the database. This parameter is returned when PrivilegeType is set to Database, Table, or Column.', example='tdb1'),
      description?: string(name='Description', description='The description that is specified when you create a table or column. This parameter is returned only when PrivilegeType is set to Database or Table, indicating the database description or table description.', example='a test db'),
      table?: string(name='Table', description='The name of the table. This parameter is returned when PrivilegeType is set to Table or Column.', example='table1'),
    }
  ](name='Data', description='The permissions.'),
  pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='20'),
  requestId?: string(name='RequestId', description='The request ID.', example='34B2AD29-682F-1C14-B3AA-9EF1A96084B8'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='23'),
}

model DescribeAccountPrivilegeObjectsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAccountPrivilegeObjectsResponseBody(name='body'),
}

async function describeAccountPrivilegeObjectsWithOptions(request: DescribeAccountPrivilegeObjectsRequest, runtime: Util.RuntimeOptions): DescribeAccountPrivilegeObjectsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.accountName)) {
    query['AccountName'] = request.accountName;
  }
  if (!Util.isUnset(request.columnPrivilegeObject)) {
    query['ColumnPrivilegeObject'] = request.columnPrivilegeObject;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.databasePrivilegeObject)) {
    query['DatabasePrivilegeObject'] = request.databasePrivilegeObject;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.privilegeType)) {
    query['PrivilegeType'] = request.privilegeType;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.tablePrivilegeObject)) {
    query['TablePrivilegeObject'] = request.tablePrivilegeObject;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeAccountPrivilegeObjects',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeAccountPrivilegeObjects(request: DescribeAccountPrivilegeObjectsRequest): DescribeAccountPrivilegeObjectsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeAccountPrivilegeObjectsWithOptions(request, runtime);
}

model DescribeAccountPrivilegesRequest {
  accountName?: string(name='AccountName', description='The name of the database account.', example='account1'),
  columnPrivilegeObject?: string(name='ColumnPrivilegeObject', description='The columns that you want to query. You can use this parameter to query the permissions of the database account on specific columns. This parameter is available only if the PrivilegeType parameter is set to Column.', example='col1'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1k5p066e1a****'),
  databasePrivilegeObject?: string(name='DatabasePrivilegeObject', description='The databases that you want to query. You can use this parameter to query the permissions of the database account on specific databases. This parameter is available only if the PrivilegeType parameter is set to Database, Table, or Column.', example='db1'),
  pageNumber?: string(name='PageNumber', description='The number of the page to return. Pages start from page 1. Default value: 1.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries to return on each page. Default value: 20.', example='10'),
  privilegeType?: string(name='PrivilegeType', description='The permission level that you want to query. You can call the `DescribeEnabledPrivileges` operation to query the permission level of the database account.', example='Global'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
  tablePrivilegeObject?: string(name='TablePrivilegeObject', description='The tables that you want to query. You can use this parameter to query the permissions of the database account on specific tables. This parameter can be used together with the DatabasePrivilegeObject parameter. This parameter is available only if the PrivilegeType parameter is set to Table or Column.', example='table1'),
}

model DescribeAccountPrivilegesResponseBody = {
  data?: [ 
    {
      privilegeObject?: {
        column?: string(name='Column', description='The name of the column.', example='column1'),
        database?: string(name='Database', description='The name of the database.', example='db1'),
        description?: string(name='Description', description='The description of the permission object.', example='a test column'),
        table?: string(name='Table', description='The name of the table.', example='tabl1'),
      }(name='PrivilegeObject', description='The objects on which the permission takes effect, including databases, tables, columns, and additional descriptions.'),
      privilegeType?: string(name='PrivilegeType', description='The permission level of the permission. Valid values: `Global`, `Database`, `Table`, and `Column`. You can call the `DescribeEnabledPrivileges` parameter to query the permission level of a specific permission.', example='Column'),
      privileges?: [ string ](name='Privileges', description='The name of the permission. You can call the `DescribeEnabledPrivileges` operation to query the name of the permission.'),
    }
  ](name='Data', description='Details of the permissions.'),
  pageNumber?: long(name='PageNumber', description='The page number of the returned page.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries returned per page.', example='20'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='DA32480A-E3E5-1BE7-BA98-724551DC04C8'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model DescribeAccountPrivilegesResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAccountPrivilegesResponseBody(name='body'),
}

async function describeAccountPrivilegesWithOptions(request: DescribeAccountPrivilegesRequest, runtime: Util.RuntimeOptions): DescribeAccountPrivilegesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.accountName)) {
    query['AccountName'] = request.accountName;
  }
  if (!Util.isUnset(request.columnPrivilegeObject)) {
    query['ColumnPrivilegeObject'] = request.columnPrivilegeObject;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.databasePrivilegeObject)) {
    query['DatabasePrivilegeObject'] = request.databasePrivilegeObject;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.privilegeType)) {
    query['PrivilegeType'] = request.privilegeType;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.tablePrivilegeObject)) {
    query['TablePrivilegeObject'] = request.tablePrivilegeObject;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeAccountPrivileges',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeAccountPrivileges(request: DescribeAccountPrivilegesRequest): DescribeAccountPrivilegesResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeAccountPrivilegesWithOptions(request, runtime);
}

model DescribeAccountsRequest {
  accountName?: string(name='AccountName', description='The name of the database account.

> If you do not specify this parameter, the information about all database accounts in the cluster is returned.', example='test_accout'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  ownerId?: string(name='OwnerId'),
}

model DescribeAccountsResponseBody = {
  accountList?: {
    DBAccount?: [ 
    {
      accountDescription?: string(name='AccountDescription', description='The description of the database account.', example='test_accout_des'),
      accountName?: string(name='AccountName', description='The name of the database account.', example='test_accout'),
      accountStatus?: string(name='AccountStatus', description='The state of the database account. Valid values:

*   **Creating**
*   **Available**
*   **Deleting**', example='Available'),
      accountType?: string(name='AccountType', description='The type of the database account. Valid values:

*   **Normal**: standard account.
*   **Super**: privileged account.', example='Normal'),
      ramUsers?: string(name='RamUsers', description='The ID of the RAM user.', example='1958134230****'),
    }
  ](name='DBAccount')
  }(name='AccountList', description='The queried database accounts.'),
  requestId?: string(name='RequestId', description='The request ID.', example='9CCFAAB4-97B7-5800-B9F2-685EB596E3EF'),
}

model DescribeAccountsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAccountsResponseBody(name='body'),
}

async function describeAccountsWithOptions(request: DescribeAccountsRequest, runtime: Util.RuntimeOptions): DescribeAccountsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.accountName)) {
    query['AccountName'] = request.accountName;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeAccounts',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeAccounts(request: DescribeAccountsRequest): DescribeAccountsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeAccountsWithOptions(request, runtime);
}

model DescribeAdbMySqlColumnsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a specific region.', example='amv-bp1r053byu48p****'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou'),
  schema?: string(name='Schema', description='The name of the database.', example='adb_demo'),
  tableName?: string(name='TableName', description='The name of the table.', example='test'),
}

model DescribeAdbMySqlColumnsResponseBody = {
  columnCount?: int32(name='ColumnCount', description='The total number of columns.', example='1'),
  columns?: [ 
    {
      comment?: string(name='Comment', description='The comments of the column.', example='test'),
      name?: string(name='Name', description='The name of the column.', example='id'),
      type?: string(name='Type', description='The data type of the column.', example='bigint'),
    }
  ](name='Columns', description='Details of the columns.'),
  message?: string(name='Message', description='The message returned for the operation. Valid values:

*   **Success** is returned if the operation is successful.
*   An error message is returned if the operation fails.', example='Success'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='A9F013CD-0222-595E-8157-445969B97F03'),
  schema?: string(name='Schema', description='The name of the database.', example='adb_demo'),
  success?: boolean(name='Success', description='Indicates whether the operation is successful. Valid values:

*   **true**: The operation is successful.
*   **false**: The operation fails.', example='true'),
  tableName?: string(name='TableName', description='The name of the table.', example='test'),
}

model DescribeAdbMySqlColumnsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAdbMySqlColumnsResponseBody(name='body'),
}

async function describeAdbMySqlColumnsWithOptions(request: DescribeAdbMySqlColumnsRequest, runtime: Util.RuntimeOptions): DescribeAdbMySqlColumnsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.schema)) {
    query['Schema'] = request.schema;
  }
  if (!Util.isUnset(request.tableName)) {
    query['TableName'] = request.tableName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeAdbMySqlColumns',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeAdbMySqlColumns(request: DescribeAdbMySqlColumnsRequest): DescribeAdbMySqlColumnsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeAdbMySqlColumnsWithOptions(request, runtime);
}

model DescribeAdbMySqlSchemasRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou'),
}

model DescribeAdbMySqlSchemasResponseBody = {
  message?: string(name='Message', description='The message returned for the operation. Valid values:

*   **Success** is returned if the operation is successful.
*   An error message is returned if the operation fails.', example='Success'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  schemas?: [ string ](name='Schemas', description='The names of databases.'),
  success?: boolean(name='Success', description='Indicates whether the operation is successful. Valid values:

*   **true**: The operation is successful.
*   **false**: The operation fails.', example='true'),
}

model DescribeAdbMySqlSchemasResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAdbMySqlSchemasResponseBody(name='body'),
}

async function describeAdbMySqlSchemasWithOptions(request: DescribeAdbMySqlSchemasRequest, runtime: Util.RuntimeOptions): DescribeAdbMySqlSchemasResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeAdbMySqlSchemas',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeAdbMySqlSchemas(request: DescribeAdbMySqlSchemasRequest): DescribeAdbMySqlSchemasResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeAdbMySqlSchemasWithOptions(request, runtime);
}

model DescribeAdbMySqlTablesRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou'),
  schema?: string(name='Schema', description='The name of the database.', example='adb_demo'),
}

model DescribeAdbMySqlTablesResponseBody = {
  message?: string(name='Message', description='The message returned for the operation. Valid values:

*   **Success** is returned if the operation is successful.
*   An error message is returned if the operation fails.', example='Success'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='7A7D49E3-5585-5DF8-B62C-75C46B4991DC'),
  schema?: string(name='Schema', description='The name of the database.', example='adb_demo'),
  success?: boolean(name='Success', description='Indicates whether the operation is successful. Valid values:

*   **true**: The operation is successful.
*   **false**: The operation fails.', example='true'),
  tables?: [ string ](name='Tables', description='The names of tables.'),
}

model DescribeAdbMySqlTablesResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAdbMySqlTablesResponseBody(name='body'),
}

async function describeAdbMySqlTablesWithOptions(request: DescribeAdbMySqlTablesRequest, runtime: Util.RuntimeOptions): DescribeAdbMySqlTablesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.schema)) {
    query['Schema'] = request.schema;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeAdbMySqlTables',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeAdbMySqlTables(request: DescribeAdbMySqlTablesRequest): DescribeAdbMySqlTablesResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeAdbMySqlTablesWithOptions(request, runtime);
}

model DescribeAllDataSourceRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1pke2pcfavw****'),
  regionId?: string(name='RegionId', description='The region ID.', example='cn-hangzhou'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
  tableName?: string(name='TableName', description='The name of the table.', example='test'),
}

model DescribeAllDataSourceResponseBody = {
  columns?: {
    column?: [ 
    {
      autoIncrementColumn?: boolean(name='AutoIncrementColumn', description='Indicates whether the column is an auto-increment column. Valid values:

*   **true**
*   **false**', example='true'),
      columnName?: string(name='ColumnName', description='The name of the column.', example='id'),
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1pke2pcfavw****'),
      primaryKey?: boolean(name='PrimaryKey', description='Indicates whether the column is the primary key of the table. Valid values:

*   **true**
*   **false**', example='false'),
      schemaName?: string(name='SchemaName', description='The logical name of the database.', example='adb_demo'),
      tableName?: string(name='TableName', description='The logical name of the table.', example='test'),
      type?: string(name='Type', description='The data type of the column.', example='bigint'),
    }
  ](name='Column')
  }(name='Columns', description='The queried columns.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C7EDB8E4-9769-4233-88C7-DCA4C9******'),
  schemas?: {
    schema?: [ 
    {
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1pke2pcfavw****'),
      schemaName?: string(name='SchemaName', description='The logical name of the database.', example='adb_demo'),
    }
  ](name='Schema')
  }(name='Schemas', description='The queried databases.'),
  tables?: {
    table?: [ 
    {
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1pke2pcfavw****'),
      schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
      tableName?: string(name='TableName', description='The logical name of the table.', example='test'),
    }
  ](name='Table')
  }(name='Tables', description='The queried tables.'),
}

model DescribeAllDataSourceResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAllDataSourceResponseBody(name='body'),
}

async function describeAllDataSourceWithOptions(request: DescribeAllDataSourceRequest, runtime: Util.RuntimeOptions): DescribeAllDataSourceResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.schemaName)) {
    query['SchemaName'] = request.schemaName;
  }
  if (!Util.isUnset(request.tableName)) {
    query['TableName'] = request.tableName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeAllDataSource',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeAllDataSource(request: DescribeAllDataSourceRequest): DescribeAllDataSourceResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeAllDataSourceWithOptions(request, runtime);
}

model DescribeApsActionLogsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the ID of the cluster.', example='amv-bp1r053byu48p****'),
  endTime?: string(name='EndTime', description='The end time of the logs to be queried. Specify the time in the ISO 8601 standard in the **yyyy-MM-ddTHH:mmZ** format. The time must be in UTC.

>  The end time must be later than the start time. Their interval cannot be longer than 30 days.', example='2023-02-11T09:30:00Z'),
  keyword?: string(name='Keyword', description='The keyword that you want to use for fuzzy match in the query.', example='table_test'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  pageNumber?: int32(name='PageNumber', description='The number of the page to return. The value must be an integer that is greater than 0. Default value: 1.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries to return on each page. Default value: 30. Valid values:

*   **30**
*   **50**
*   **100**', example='30'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
  stage?: string(name='Stage', description='The task phase during which the logs to be queried are generated. Valid values:

*   **StructureMigrate**: schema migration.
*   **FullDataSync**: full data synchronization.
*   **IncrementalSync**: incremental data synchronization.

>  If you do not specify this parameter, logs of all the task phases are queried.', example='FullDataSync'),
  startTime?: string(name='StartTime', description='The start time of the logs to be queried. Specify the time in the ISO 8601 standard in the **yyyy-MM-ddTHH:mm:ssZ** format. The time must be in UTC.', example='2023-02-11T08:30:00Z'),
  state?: string(name='State', description='The type of the log. Separate multiple log types with commas (,). Valid values:

*   **INFO**
*   **WARN**
*   **ERROR**

>  If you do not specify this parameter, logs of all types are queried.', example='INFO,WARN,ERROR'),
  workloadId?: string(name='WorkloadId', description='The ID of the real-time data ingestion task.', example='aps-hz109vpvt4fg8528d****'),
}

model DescribeApsActionLogsResponseBody = {
  actionLogs?: [ 
    {
      context?: string(name='Context', description='The content of the log.', example='DDL migration job finished'),
      stage?: string(name='Stage', description='The task phase during which the logs are generated. Valid values:

*   **StructureMigrate**: schema migration.
*   **FullDataSync**: full data synchronization.
*   **IncrementalSync**: incremental data synchronization.', example='FullDataSync'),
      state?: string(name='State', description='The type of the log. Multiple log types are separated by commas (,). Valid values:

*   **INFO**
*   **WARN**
*   **ERROR**', example='INFO,WARN,ERROR'),
      time?: string(name='Time', description='The time when the log is generated. The time follows the ISO 8601 standard in the **yyyy-MM-ddTHH:mm:ssZ** format. The time is displayed in UTC.', example='2023-02-01T05:46:30Z'),
    }
  ](name='ActionLogs', description='Details of the logs.'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  pageNumber?: string(name='PageNumber', description='The page number of the returned page.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries returned on each page.', example='30'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5EDBA27-AF3E-5966-9503-FD1557E19167'),
  totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='3'),
  workloadId?: string(name='WorkloadId', description='The ID of the real-time data ingestion task.', example='aps-hz109vpvt4fg8528d****'),
}

model DescribeApsActionLogsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeApsActionLogsResponseBody(name='body'),
}

async function describeApsActionLogsWithOptions(request: DescribeApsActionLogsRequest, runtime: Util.RuntimeOptions): DescribeApsActionLogsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  if (!Util.isUnset(request.stage)) {
    query['Stage'] = request.stage;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.state)) {
    query['State'] = request.state;
  }
  if (!Util.isUnset(request.workloadId)) {
    query['WorkloadId'] = request.workloadId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeApsActionLogs',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeApsActionLogs(request: DescribeApsActionLogsRequest): DescribeApsActionLogsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeApsActionLogsWithOptions(request, runtime);
}

model DescribeApsResourceGroupsRequest {
  DBClusterId?: string(name='DBClusterId'),
}

model DescribeApsResourceGroupsResponseBody = {
  data?: {
    resourceGroups?: [ 
      {
        available?: boolean(name='Available'),
        cuOptions?: [ long ](name='CuOptions'),
        groupName?: string(name='GroupName'),
        groupType?: string(name='GroupType'),
        leftComputeResource?: int32(name='LeftComputeResource'),
        maxComputeResource?: int32(name='MaxComputeResource'),
        minComputeResource?: int32(name='MinComputeResource'),
      }
    ](name='ResourceGroups'),
    step?: long(name='Step'),
  }(name='Data'),
  httpStatusCode?: long(name='HttpStatusCode'),
  message?: string(name='Message'),
  requestId?: string(name='RequestId'),
  success?: boolean(name='Success'),
}

model DescribeApsResourceGroupsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeApsResourceGroupsResponseBody(name='body'),
}

async function describeApsResourceGroupsWithOptions(request: DescribeApsResourceGroupsRequest, runtime: Util.RuntimeOptions): DescribeApsResourceGroupsResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'DescribeApsResourceGroups',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeApsResourceGroups(request: DescribeApsResourceGroupsRequest): DescribeApsResourceGroupsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeApsResourceGroupsWithOptions(request, runtime);
}

model DescribeAuditLogRecordsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-t4nj8619bz2w3****'),
  DBName?: string(name='DBName', description='The name of the database on which the SQL statement was executed.', example='adb_demo'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.

> 

*   The end time must be later than the start time.

*   The maximum time range that can be specified is 24 hours.', example='2022-08-12T17:08Z'),
  hostAddress?: string(name='HostAddress', description='The IP address and port number of the client that is used to execute the SQL statement.', example='100.104.XX.XX:43908'),
  order?: string(name='Order', description='The order in which to sort the retrieved entries by field. Specify this parameter in the JSON format. The value is an ordered array that uses the order of the input array and contains `Field` and `Type`. Example: `[{"Field":"ExecutionStartTime","Type":"Desc"},{"Field":"ScanRows","Type":"Asc"}]`. Fields:

*   `Field`: the field that is used to sort the retrieved entries. Valid values:

    *   **HostAddress**: the IP address of the client that is used to connect to the database.
    *   **UserName**: the username.
    *   **ExecutionStartTime**: the start time of the query execution.
    *   **QueryTime**: the amount of time consumed to execute the SQL statement.
    *   **PeakMemoryUsage**: the maximum memory usage when the SQL statement is executed.
    *   **ScanRows**: the number of rows to be scanned from a data source in the task.
    *   **ScanSize**: the amount of data to be scanned.
    *   **ScanTime**: the total amount of time consumed to scan data.
    *   **PlanningTime**: the amount of time consumed to generate execution plans.
    *   **WallTime**: the accumulated CPU Time values of all operators in the query on each node.
    *   **ProcessID**: the process ID.

*   `Type`: the sorting type of the retrieved entries. Valid values:

    *   **Desc**: descending order.
    *   **Asc**: ascending order.', example='[{"Field":"ExecuteTime","Type":"Desc"},{"Field":"HostAddress","Type":"Asc"}]'),
  orderType?: string(name='OrderType', description='The sorting order of the retrieved entries. Valid values:

*   **asc**: sorts the retrieved entries by time in ascending order.
*   **desc**: sorts the retrieved entries by time in descending order.', example='asc'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **10** (default)
*   **30**
*   **50**
*   **100**', example='10'),
  proxyUser?: string(name='ProxyUser', description='A reserved parameter.', example='none'),
  queryKeyword?: string(name='QueryKeyword', description='The keyword based on which audit logs are queried. You can set this parameter to a value of the STRING type.', example='adb'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.

> You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
  sqlType?: string(name='SqlType', description='The type of the SQL statement. Valid values:

*   **DELETE**
*   **SELECT**
*   **UPDATE**
*   **INSERT INTO SELECT**
*   **ALTER**
*   **DROP**
*   **INSERT**

> You can query only a single type of SQL statements at a time. If you leave this parameter empty, the **SELECT** SQL statements are queried.', example='SELECT'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.

> SQL audit logs can be queried only when SQL audit is enabled. Only SQL audit logs within the last 30 days can be queried. If SQL audit was disabled and re-enabled, only SQL audit logs from the time when SQL audit was re-enabled can be queried.', example='2022-08-12T04:17Z'),
  succeed?: string(name='Succeed', description='Specifies whether the execution of the SQL statement succeeds. Valid values:

*   **true**
*   **false**', example='true'),
  user?: string(name='User', description='The username that is used to execute the SQL statement.', example='test'),
}

model DescribeAuditLogRecordsResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-t4nj8619bz2w3****'),
  items?: [ 
    {
      connId?: string(name='ConnId', description='The connection ID.', example='14356****'),
      DBName?: string(name='DBName', description='The name of the database on which the SQL statement was executed.', example='adb_demo'),
      executeTime?: string(name='ExecuteTime', description='The start time of the execution of the SQL statement. The time is displayed in the ISO 8601 standard in the yyyy-MM-dd HH:mm:ss format. The time must be in UTC.', example='2022-08-12 10:10:00'),
      hostAddress?: string(name='HostAddress', description='The IP address and port number of the client that is used to execute the SQL statement.', example='100.104.XX.XX:43908'),
      processID?: string(name='ProcessID', description='The task ID.', example='202106081752021720161662490345362390'),
      SQLText?: string(name='SQLText', description='The SQL statement.', example='SELECT * FROM adb_hdfs_import_source'),
      SQLType?: string(name='SQLType', description='The type of the SQL statement.', example='SELECT'),
      succeed?: string(name='Succeed', description='Indicates whether the SQL statement was successfully executed. Valid values:

*   **true**
*   **false**', example='true'),
      totalTime?: string(name='TotalTime', description='The amount of time that is consumed to execute the SQL statement. Unit: milliseconds.', example='216'),
      user?: string(name='User', description='The username that is used to execute the SQL statement.', example='test'),
    }
  ](name='Items', description='The queried SQL audit logs.'),
  pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='8A564B7F-8C00-43C0-8EC5-919FBB70573'),
  totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='6974'),
}

model DescribeAuditLogRecordsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAuditLogRecordsResponseBody(name='body'),
}

async function describeAuditLogRecordsWithOptions(request: DescribeAuditLogRecordsRequest, runtime: Util.RuntimeOptions): DescribeAuditLogRecordsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.DBName)) {
    query['DBName'] = request.DBName;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.hostAddress)) {
    query['HostAddress'] = request.hostAddress;
  }
  if (!Util.isUnset(request.order)) {
    query['Order'] = request.order;
  }
  if (!Util.isUnset(request.orderType)) {
    query['OrderType'] = request.orderType;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.proxyUser)) {
    query['ProxyUser'] = request.proxyUser;
  }
  if (!Util.isUnset(request.queryKeyword)) {
    query['QueryKeyword'] = request.queryKeyword;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  if (!Util.isUnset(request.sqlType)) {
    query['SqlType'] = request.sqlType;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.succeed)) {
    query['Succeed'] = request.succeed;
  }
  if (!Util.isUnset(request.user)) {
    query['User'] = request.user;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeAuditLogRecords',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeAuditLogRecords(request: DescribeAuditLogRecordsRequest): DescribeAuditLogRecordsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeAuditLogRecordsWithOptions(request, runtime);
}

model DescribeBackupPolicyRequest {
  DBClusterId?: string(name='DBClusterId', example='am-uf6s7oa710rbu0x3b'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model DescribeBackupPolicyResponseBody = {
  backupRetentionPeriod?: int32(name='BackupRetentionPeriod', example='7'),
  enableBackupLog?: string(name='EnableBackupLog', example='true'),
  logBackupRetentionPeriod?: int32(name='LogBackupRetentionPeriod', example='7'),
  preferredBackupPeriod?: string(name='PreferredBackupPeriod', example='Wednesday,Saturday'),
  preferredBackupTime?: string(name='PreferredBackupTime', example='15:00Z-16:00Z'),
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DescribeBackupPolicyResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeBackupPolicyResponseBody(name='body'),
}

async function describeBackupPolicyWithOptions(request: DescribeBackupPolicyRequest, runtime: Util.RuntimeOptions): DescribeBackupPolicyResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeBackupPolicy',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeBackupPolicy(request: DescribeBackupPolicyRequest): DescribeBackupPolicyResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeBackupPolicyWithOptions(request, runtime);
}

model DescribeBackupsRequest {
  backupId?: string(name='BackupId', example='1679758862'),
  DBClusterId?: string(name='DBClusterId', example='am-bp18934i73vb5****'),
  endTime?: string(name='EndTime', example='2023-02-20T02:30Z'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  pageNumber?: int32(name='PageNumber', example='1'),
  pageSize?: int32(name='PageSize', example='30'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
  startTime?: string(name='StartTime', example='2011-06-01T16:00Z'),
}

model DescribeBackupsResponseBody = {
  items?: {
    backup?: [ 
    {
      backupEndTime?: string(name='BackupEndTime', example='2022-06-02T16:00Z'),
      backupId?: string(name='BackupId', example='32732****'),
      backupMethod?: string(name='BackupMethod', example='Snapshot'),
      backupSize?: int32(name='BackupSize', example='2167808'),
      backupStartTime?: string(name='BackupStartTime', example='2022-06-01T16:00Z'),
      backupType?: string(name='BackupType', example='FullBackup'),
      DBClusterId?: string(name='DBClusterId', example='am-bp11q28kvl688****'),
    }
  ](name='Backup')
  }(name='Items'),
  pageNumber?: string(name='PageNumber', example='1'),
  pageSize?: string(name='PageSize', example='30'),
  requestId?: string(name='RequestId', example='CE17270B-F8F8-5A31-9DB4-DADDFDAD7940'),
  totalCount?: string(name='TotalCount', example='300'),
}

model DescribeBackupsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeBackupsResponseBody(name='body'),
}

async function describeBackupsWithOptions(request: DescribeBackupsRequest, runtime: Util.RuntimeOptions): DescribeBackupsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.backupId)) {
    query['BackupId'] = request.backupId;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeBackups',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeBackups(request: DescribeBackupsRequest): DescribeBackupsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeBackupsWithOptions(request, runtime);
}

model DescribeClusterAccessWhiteListRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
}

model DescribeClusterAccessWhiteListResponseBody = {
  items?: {
    IPArray?: [ 
    {
      DBClusterIPArrayAttribute?: string(name='DBClusterIPArrayAttribute', description='The attribute of the whitelist.

> Whitelists with the **hidden** attribute are not displayed in the console. Those whitelists are used to access Data Transmission Service (DTS) and PolarDB.', example='hidden'),
      DBClusterIPArrayName?: string(name='DBClusterIPArrayName', description='The name of the IP address whitelist.

Each cluster supports up to 50 IP address whitelists.', example='test'),
      securityIPList?: string(name='SecurityIPList', description='The IP addresses in the IP address whitelist. Up to 500 IP addresses can be returned. Multiple IP addresses are separated by commas (,).', example='127.0.xx.xx'),
    }
  ](name='IPArray')
  }(name='Items', description='The queried IP address whitelists.'),
  requestId?: string(name='RequestId', description='The request ID.', example='370D09FD-442A-5225-AAD3-7362CAE39177'),
}

model DescribeClusterAccessWhiteListResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeClusterAccessWhiteListResponseBody(name='body'),
}

async function describeClusterAccessWhiteListWithOptions(request: DescribeClusterAccessWhiteListRequest, runtime: Util.RuntimeOptions): DescribeClusterAccessWhiteListResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeClusterAccessWhiteList',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeClusterAccessWhiteList(request: DescribeClusterAccessWhiteListRequest): DescribeClusterAccessWhiteListResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeClusterAccessWhiteListWithOptions(request, runtime);
}

model DescribeClusterNetInfoRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~129857~~) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region, including cluster IDs.', example='amv-wz9dqvn0o7****'),
}

model DescribeClusterNetInfoResponseBody = {
  clusterNetworkType?: string(name='ClusterNetworkType', description='The network type of the cluster. Only the Virtual Private Cloud (VPC) network type is supported. **VPC** is returned.', example='VPC'),
  items?: {
    address?: [ 
    {
      connectionString?: string(name='ConnectionString', description='The endpoint of the cluster.

*   If the network type of the cluster is VPC, the VPC endpoint of the cluster is returned.
*   If the network type of the cluster is Public, the public endpoint of the cluster is returned.', example='amv-wz9dqvn0o7****.ads.aliyuncs.com'),
      connectionStringPrefix?: string(name='ConnectionStringPrefix', description='The prefix of the endpoint.

*   If the network type of the cluster is VPC, the prefix of the private endpoint is returned.
*   If the network type of the cluster is Public, the prefix of the public endpoint is returned.', example='amv-wz9dqvn0o7****'),
      IPAddress?: string(name='IPAddress', description='The IP address of the endpoint.

*   If the network type of the cluster is VPC, the IP address of the private endpoint is returned.
*   If the network type of the cluster is Public, the IP address of the public endpoint is returned.', example='192.168.xx.xx'),
      netType?: string(name='NetType', description='The network type of the cluster. Valid values:

*   **Public**: Internet.
*   **VPC**: VPC.', example='VPC'),
      port?: string(name='Port', description='The port number that is used to connect to the cluster. **3306** is returned.', example='3306'),
      VPCId?: string(name='VPCId', description='The VPC ID.

> If NetType is set to Public, an empty string is returned for this parameter.', example='vpc-8vbhucmd5b****'),
      vSwitchId?: string(name='VSwitchId', description='The vSwitch ID of the cluster.

> If NetType is set to Public, an empty string is returned for this parameter.', example='vsw-bp1syh8vvw8yec****'),
    }
  ](name='Address')
  }(name='Items', description='The network information about the cluster.'),
  requestId?: string(name='RequestId', description='The request ID.', example='69A29B65-CD0C-52B1-BE42-8B454569747F'),
}

model DescribeClusterNetInfoResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeClusterNetInfoResponseBody(name='body'),
}

async function describeClusterNetInfoWithOptions(request: DescribeClusterNetInfoRequest, runtime: Util.RuntimeOptions): DescribeClusterNetInfoResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeClusterNetInfo',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeClusterNetInfo(request: DescribeClusterNetInfoRequest): DescribeClusterNetInfoResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeClusterNetInfoWithOptions(request, runtime);
}

model DescribeClusterResourceDetailRequest {
  DBClusterId?: string(name='DBClusterId', example='am-bp1jj9xqft1po****'),
}

model DescribeClusterResourceDetailResponseBody = {
  code?: int32(name='Code', example='200'),
  data?: {
    computeResource?: string(name='ComputeResource', example='16ACU'),
    DBClusterId?: string(name='DBClusterId', example='amv-adbxxxxx'),
    freeComputeResource?: string(name='FreeComputeResource', example='0ACU'),
    resourceGroupList?: [ 
      {
        clusterMode?: string(name='ClusterMode', example='0'),
        clusterSizeResource?: string(name='ClusterSizeResource', example='0'),
        maxClusterCount?: int32(name='MaxClusterCount', example='0'),
        maxComputeResource?: string(name='MaxComputeResource', example='128ACU'),
        minClusterCount?: int32(name='MinClusterCount', example='0'),
        minComputeResource?: string(name='MinComputeResource', example='16ACU'),
        poolId?: long(name='PoolId', example='17'),
        poolName?: string(name='PoolName', example='testadb'),
        poolType?: string(name='PoolType', example='interactive'),
        poolUsers?: string(name='PoolUsers', example='user1'),
        runningClusterCount?: int32(name='RunningClusterCount', example='0'),
        status?: string(name='Status', example='running'),
      }
    ](name='ResourceGroupList'),
    storageResource?: string(name='StorageResource', example='24ACU'),
  }(name='Data'),
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DescribeClusterResourceDetailResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeClusterResourceDetailResponseBody(name='body'),
}

async function describeClusterResourceDetailWithOptions(request: DescribeClusterResourceDetailRequest, runtime: Util.RuntimeOptions): DescribeClusterResourceDetailResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeClusterResourceDetail',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeClusterResourceDetail(request: DescribeClusterResourceDetailRequest): DescribeClusterResourceDetailResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeClusterResourceDetailWithOptions(request, runtime);
}

model DescribeClusterResourceUsageRequest {
  DBClusterId?: string(name='DBClusterId', example='amv-bp11q28kvl688****'),
  endTime?: string(name='EndTime', example='2022-08-22T01:06:00Z'),
  startTime?: string(name='StartTime', example='2022-11-29T10:20Z'),
}

model DescribeClusterResourceUsageResponseBody = {
  code?: int32(name='Code', example='200'),
  data?: {
    acuInfo?: [ 
      {
        name?: string(name='Name', example='TotalAcuNumber'),
        values?: [ string ](name='Values'),
      }
    ](name='AcuInfo'),
    DBClusterId?: string(name='DBClusterId', example='amv-uf6dj23rt5zo9s9d'),
    endTime?: string(name='EndTime', example='2023-03-23T02:31Z'),
    startTime?: string(name='StartTime', example='2023-03-14T03:42:15Z'),
  }(name='Data'),
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEAW'),
}

model DescribeClusterResourceUsageResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeClusterResourceUsageResponseBody(name='body'),
}

async function describeClusterResourceUsageWithOptions(request: DescribeClusterResourceUsageRequest, runtime: Util.RuntimeOptions): DescribeClusterResourceUsageResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeClusterResourceUsage',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeClusterResourceUsage(request: DescribeClusterResourceUsageRequest): DescribeClusterResourceUsageResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeClusterResourceUsageWithOptions(request, runtime);
}

model DescribeColumnsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1xxxxxxxx47'),
  regionId?: string(name='RegionId', description='The region ID.', example='cn-hangzhou'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
  tableName?: string(name='TableName', description='The name of the table.', example='test'),
}

model DescribeColumnsResponseBody = {
  items?: {
    column?: [ 
    {
      autoIncrementColumn?: boolean(name='AutoIncrementColumn', description='Indicates whether the column is an auto-increment column. Valid values:

*   **true**
*   **false**', example='true'),
      columnName?: string(name='ColumnName', description='The name of the column.', example='id'),
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp111m2cfrdl1****'),
      primaryKey?: boolean(name='PrimaryKey', description='Indicates whether the column is the primary key of the table. Valid values:

*   **true**
*   **false**', example='false'),
      schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
      tableName?: string(name='TableName', description='The name of the table.', example='test'),
      type?: string(name='Type', description='The data type of the column.', example='bigint'),
    }
  ](name='Column')
  }(name='Items', description='The queried columns.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-XXX442913CEF'),
}

model DescribeColumnsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeColumnsResponseBody(name='body'),
}

async function describeColumnsWithOptions(request: DescribeColumnsRequest, runtime: Util.RuntimeOptions): DescribeColumnsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.schemaName)) {
    query['SchemaName'] = request.schemaName;
  }
  if (!Util.isUnset(request.tableName)) {
    query['TableName'] = request.tableName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeColumns',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeColumns(request: DescribeColumnsRequest): DescribeColumnsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeColumnsWithOptions(request, runtime);
}

model DescribeComputeResourceUsageRequest {
  DBClusterId?: string(name='DBClusterId', example='am-bp1xxxxxxxx47'),
  endTime?: string(name='EndTime', example='2023-02-05T03:45:00Z'),
  resourceGroupName?: string(name='ResourceGroupName', example='test'),
  startTime?: string(name='StartTime', example='2023-02-04T03:45:00Z'),
}

model DescribeComputeResourceUsageResponseBody = {
  code?: int32(name='Code', example='200'),
  data?: {
    acuInfo?: [ 
      {
        name?: string(name='Name', example='TotalAcuNumber'),
        values?: [ string ](name='Values'),
      }
    ](name='AcuInfo'),
    DBClusterId?: string(name='DBClusterId', example='amv-clusterxxx'),
    endTime?: string(name='EndTime', example='2023-06-07T02:37:00Z'),
    resourceGroupName?: string(name='ResourceGroupName', example='test'),
    resourceGroupType?: string(name='ResourceGroupType', example='interative'),
    startTime?: string(name='StartTime', example='2023-04-24T07:00:00Z'),
  }(name='Data'),
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEAW'),
}

model DescribeComputeResourceUsageResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeComputeResourceUsageResponseBody(name='body'),
}

async function describeComputeResourceUsageWithOptions(request: DescribeComputeResourceUsageRequest, runtime: Util.RuntimeOptions): DescribeComputeResourceUsageResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.resourceGroupName)) {
    query['ResourceGroupName'] = request.resourceGroupName;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeComputeResourceUsage',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeComputeResourceUsage(request: DescribeComputeResourceUsageRequest): DescribeComputeResourceUsageResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeComputeResourceUsageWithOptions(request, runtime);
}

model DescribeDBClusterAttributeRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Warehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****'),
}

model DescribeDBClusterAttributeResponseBody = {
  items?: {
    DBCluster?: [ 
    {
      commodityCode?: string(name='CommodityCode', description='The billing method of the cluster. Valid values:

*   **ads**: pay-as-you-go.
*   **ads_pre**: subscription.', example='ads_pre'),
      computeResource?: string(name='ComputeResource', description='The specifications of reserved computing resources. Each ACU is equivalent to 1 core and 4 GB memory. Computing resources serve compute operations. The amount of computing resources is proportional to the query speed of the cluster. You can scale computing resources based on your needs.', example='16ACU'),
      computeResourceTotal?: string(name='ComputeResourceTotal', description='The total amount of computing resources in the cluster. Each ACU is equivalent to 1 core and 4 GB memory.', example='48ACU'),
      connectionString?: string(name='ConnectionString', description='The public endpoint that is used to connect to the cluster.', example='amv-wz9509beptiz****.ads.aliyuncs.com'),
      creationTime?: string(name='CreationTime', description='The time when the cluster was created. The time follows the ISO 8601 standard in the `yyyy-MM-ddThh:mm:ssZ` format. The time is displayed in UTC.', example='2022-07-01T09:50:18Z'),
      DBClusterDescription?: string(name='DBClusterDescription', description='The description of the cluster.', example='adb_test'),
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****'),
      DBClusterNetworkType?: string(name='DBClusterNetworkType', description='The network type of the cluster. **VPC** is returned.', example='VPC'),
      DBClusterStatus?: string(name='DBClusterStatus', description='The state of the cluster. Valid values:

*   **Preparing**: The cluster is being prepared.
*   **Creating**: The cluster is being created.
*   **Running**: The cluster is running.
*   **Deleting**: The cluster is being deleted.
*   **Restoring**: The cluster is being restored from a backup.
*   **ClassChanging**: The cluster specifications are being changed.
*   **NetAddressCreating**: A network connection is being created.
*   **NetAddressDeleting**: A network connection is being deleted.
*   **NetAddressModifying**: A network connection is being modified.', example='Running'),
      DBClusterType?: string(name='DBClusterType', description='The type of the cluster. By default, **Common** is returned, which indicates a common cluster.', example='Common'),
      DBVersion?: string(name='DBVersion', description='The engine version of the AnalyticDB for MySQL Data Lakehouse Edition cluster. **5.0** is returned.', example='5.0'),
      engine?: string(name='Engine', description='The engine of the cluster. **AnalyticDB** is returned.', example='AnalyticDB'),
      engineVersion?: string(name='EngineVersion', description='The minor version of the cluster.', example='3.1.16'),
      expireTime?: string(name='ExpireTime', description='The time when the cluster expires.

*   The expiration time is returned for a subscription cluster.
*   An empty string is returned for a pay-as-you-go cluster.', example='2022-10-01T09:50:18Z'),
      expired?: string(name='Expired', description='Indicates whether the subscription cluster has expired. Valid values:

*   **true**
*   **false**

> 

*   If the cluster has expired, the system locks or releases the cluster within a period of time. We recommend that you renew the expired cluster. For more information, see [Renewal policy](~~135248~~).

*   This parameter is not returned for pay-as-you-go clusters.', example='false'),
      lockMode?: string(name='LockMode', description='The lock mode of the cluster. Valid values:

*   **Unlock**: The cluster is not locked.
*   **ManualLock**: The cluster is manually locked.
*   **LockByExpiration**: The cluster is automatically locked after the cluster expires.', example='ManualLock'),
      lockReason?: string(name='LockReason', description='The reason why the cluster is locked.

> This parameter is returned only when the cluster was locked. The value is **instance_expire**.', example='instance_expire'),
      maintainTime?: string(name='MaintainTime', description='The maintenance window of the cluster. The time is displayed in the `HH:mmZ-HH:mmZ` format in UTC.

> For more information about maintenance windows, see [Configure a maintenance window](~~122569~~).', example='04:00Z-05:00Z'),
      mode?: string(name='Mode', description='The mode of the cluster. By default, **flexible** is returned, which indicates that the cluster is in elastic mode.', example='flexible'),
      payType?: string(name='PayType', description='The billing method of the cluster. Valid values:

*   **Postpaid**: pay-as-you-go.
*   **Prepaid**: subscription.', example='Prepaid'),
      port?: int32(name='Port', description='The port number that is used to connect to the cluster.', example='3306'),
      regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
      reservedACU?: string(name='ReservedACU', description='The amount of remaining reserved computing resources that are available in the cluster. Each ACU is equivalent to 1 core and 4 GB memory.', example='24ACU'),
      resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group.', example='rg-acfmyiu4ekp****'),
      storageResource?: string(name='StorageResource', description='The specifications of reserved storage resources. Each AnalyticDB compute unit (ACU) is equivalent to 1 core and 4 GB memory. Storage resources serve read and write requests. The amount of storage resources is proportional to the read and write performance of the cluster.', example='24ACU'),
      storageResourceTotal?: string(name='StorageResourceTotal', description='The total amount of storage resources in the cluster. Each ACU is equivalent to 1 core and 4 GB memory.', example='24ACU'),
      supportedFeatures?: map[string]string(name='SupportedFeatures'),
      tags?: {
        tag?: [ 
        {
          key?: string(name='Key'),
          value?: string(name='Value'),
        }
      ](name='Tag')
      }(name='Tags'),
      userENIStatus?: boolean(name='UserENIStatus', description='Indicates whether Elastic Network Interface (ENI) is enabled. Valid values:

*   **true**
*   **false**', example='false'),
      VPCId?: string(name='VPCId', description='The virtual private cloud (VPC) ID of the cluster.', example='vpc-bp13h7uzhulpu****'),
      vSwitchId?: string(name='VSwitchId', description='The vSwitch ID of the cluster.', example='vsw-uf629gydd54ld****'),
      zoneId?: string(name='ZoneId', description='The zone ID of the cluster.', example='cn-hangzhou-h'),
    }
  ](name='DBCluster')
  }(name='Items', description='The queried AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.'),
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model DescribeDBClusterAttributeResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDBClusterAttributeResponseBody(name='body'),
}

async function describeDBClusterAttributeWithOptions(request: DescribeDBClusterAttributeRequest, runtime: Util.RuntimeOptions): DescribeDBClusterAttributeResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeDBClusterAttribute',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeDBClusterAttribute(request: DescribeDBClusterAttributeRequest): DescribeDBClusterAttributeResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeDBClusterAttributeWithOptions(request, runtime);
}

model DescribeDBClusterHealthStatusRequest {
  DBClusterId?: string(name='DBClusterId', example='amv-uf6o6m8p6x7v****'),
  regionId?: string(name='RegionId', example='cn-hangzhou'),
}

model DescribeDBClusterHealthStatusResponseBody = {
  CS?: {
    activeCount?: long(name='ActiveCount', example='2'),
    expectedCount?: long(name='ExpectedCount', example='2'),
    riskCount?: long(name='RiskCount', example='0'),
    status?: string(name='Status', example='NORMAL'),
    unavailableCount?: long(name='UnavailableCount', example='0'),
  }(name='CS'),
  executor?: {
    activeCount?: long(name='ActiveCount', example='2'),
    expectedCount?: long(name='ExpectedCount', example='2'),
    riskCount?: long(name='RiskCount', example='0'),
    status?: string(name='Status', example='NORMAL'),
    unavailableCount?: long(name='UnavailableCount', example='0'),
  }(name='Executor'),
  instanceStatus?: string(name='InstanceStatus', example='NORMAL'),
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEA'),
  worker?: {
    activeCount?: long(name='ActiveCount', example='2'),
    expectedCount?: long(name='ExpectedCount', example='2'),
    riskCount?: long(name='RiskCount', example='0'),
    status?: string(name='Status', example='NORMAL'),
    unavailableCount?: long(name='UnavailableCount', example='0'),
  }(name='Worker'),
}

model DescribeDBClusterHealthStatusResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDBClusterHealthStatusResponseBody(name='body'),
}

async function describeDBClusterHealthStatusWithOptions(request: DescribeDBClusterHealthStatusRequest, runtime: Util.RuntimeOptions): DescribeDBClusterHealthStatusResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeDBClusterHealthStatus',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeDBClusterHealthStatus(request: DescribeDBClusterHealthStatusRequest): DescribeDBClusterHealthStatusResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeDBClusterHealthStatusWithOptions(request, runtime);
}

model DescribeDBClusterPerformanceRequest {
  DBClusterId?: string(name='DBClusterId', example='amv-bp1hx5n1o8f61****'),
  endTime?: string(name='EndTime', example='2022-03-11T15:01Z'),
  key?: string(name='Key', example='AnalyticDB_CPU_Usage_Percentage'),
  regionId?: string(name='RegionId', example='cn-hangzhou'),
  resourcePools?: string(name='ResourcePools', example='user_default'),
  startTime?: string(name='StartTime', example='2022-03-10T23:56Z'),
}

model DescribeDBClusterPerformanceResponseBody = {
  DBClusterId?: string(name='DBClusterId', example='amv-bp1hx5n1o8f61****'),
  endTime?: string(name='EndTime', example='2022-03-11T15:01Z'),
  performances?: [ 
    {
      key?: string(name='Key', example='AnalyticDB_CPU_Usage_Percentage'),
      series?: [ 
        {
          name?: string(name='Name', example='AnalyticDB_Storage_CPU_Avg_Usage_Percentage'),
          tags?: string(name='Tags', example='{instance_name: "am-***"}'),
          values?: [ string ](name='Values'),
        }
      ](name='Series'),
      unit?: string(name='Unit', example='%'),
    }
  ](name='Performances'),
  requestId?: string(name='RequestId', example='BD8C3096-8BC6-51DF-A4AB-BACD9DC10435'),
  startTime?: string(name='StartTime', example='2022-03-10T23:56Z'),
}

model DescribeDBClusterPerformanceResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDBClusterPerformanceResponseBody(name='body'),
}

async function describeDBClusterPerformanceWithOptions(request: DescribeDBClusterPerformanceRequest, runtime: Util.RuntimeOptions): DescribeDBClusterPerformanceResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.key)) {
    query['Key'] = request.key;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.resourcePools)) {
    query['ResourcePools'] = request.resourcePools;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeDBClusterPerformance',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeDBClusterPerformance(request: DescribeDBClusterPerformanceRequest): DescribeDBClusterPerformanceResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeDBClusterPerformanceWithOptions(request, runtime);
}

model DescribeDBClusterStatusRequest {
  regionId?: string(name='RegionId', example='cn-hangzhou'),
}

model DescribeDBClusterStatusResponseBody = {
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEAU'),
  status?: [ string ](name='Status'),
}

model DescribeDBClusterStatusResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDBClusterStatusResponseBody(name='body'),
}

async function describeDBClusterStatusWithOptions(request: DescribeDBClusterStatusRequest, runtime: Util.RuntimeOptions): DescribeDBClusterStatusResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeDBClusterStatus',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeDBClusterStatus(request: DescribeDBClusterStatusRequest): DescribeDBClusterStatusResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeDBClusterStatusWithOptions(request, runtime);
}

model DescribeDBClustersRequest {
  DBClusterDescription?: string(name='DBClusterDescription', description='The description of the cluster.

*   The description cannot start with `http://` or `https://`.
*   The description must be 2 to 256 characters in length.', example='test'),
  DBClusterIds?: string(name='DBClusterIds', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

If you do not specify this parameter, the information of all clusters that reside in the specified region is returned.', example='amv-bp1r053byu48p****'),
  DBClusterStatus?: string(name='DBClusterStatus', description='The state of the cluster. Valid values:

*   **Preparing**: The cluster is being prepared.
*   **Creating**: The cluster is being created.
*   **Running**: The cluster is running.
*   **Deleting**: The cluster is being deleted.
*   **Restoring**: The cluster is being restored from a backup.
*   **ClassChanging**: The cluster specifications are being changed.
*   **NetAddressCreating**: A network connection is being created.
*   **NetAddressDeleting**: A network connection is being deleted.
*   **NetAddressModifying**: A network connection is being modified.', example='Running'),
  pageNumber?: int32(name='PageNumber', description='The number of the page to return. The value must be an integer that is greater than 0. Default value: **1**.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries to return on each page. Default value: 30. Valid values:

*   **30**
*   **50**
*   **100**', example='30'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou'),
  resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group.

If you do not specify this parameter, the information of all resource groups in the cluster is returned.', example='rg-4690g37929****'),
  tag?: [ 
    {
      key?: string(name='Key'),
      value?: string(name='Value'),
    }
  ](name='Tag'),
}

model DescribeDBClustersResponseBody = {
  items?: {
    DBCluster?: [ 
    {
      commodityCode?: string(name='CommodityCode', description='The billing method of the cluster. Valid values:

*   **ads**: pay-as-you-go
*   **ads_pre**: subscription', example='ads_pre'),
      computeResource?: string(name='ComputeResource', description='The specifications of the reserved computing resources. Each ACU is equivalent to 1 core and 4 GB memory. Computing resources serve compute operations. The amount of computing resources is proportional to the query speed of the cluster. You can scale computing resources based on your needs.', example='16ACU'),
      connectionString?: string(name='ConnectionString', description='The public endpoint of the cluster.', example='amv-bp163885f8q21****.ads.aliyuncs.com'),
      createTime?: string(name='CreateTime', description='The time when the cluster was created. The time follows the ISO 8601 standard in the *yyyy-mm-ddThh:mm:ssZ* format. The time is displayed in UTC.', example='2022-04-01T09:50:18Z'),
      DBClusterDescription?: string(name='DBClusterDescription', description='The description of the cluster.', example='adb_test'),
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp163885f8q21****'),
      DBClusterNetworkType?: string(name='DBClusterNetworkType', description='The network type of the cluster. **VPC** is returned.', example='VPC'),
      DBClusterStatus?: string(name='DBClusterStatus', description='The state of the cluster. Valid values:

*   **Preparing**: The cluster is being prepared.
*   **Creating**: The cluster is being created.
*   **Running**: The cluster is running.
*   **Deleting**: The cluster is being deleted.
*   **Restoring**: The cluster is being restored from a backup.
*   **ClassChanging**: The cluster specifications are being changed.
*   **NetAddressCreating**: A network connection is being created.
*   **NetAddressDeleting**: A network connection is being deleted.
*   **NetAddressModifying**: A network connection is being modified.', example='Running'),
      DBClusterType?: string(name='DBClusterType', description='The type of the cluster. By default, **Common** is returned, which indicates a common cluster.', example='Common'),
      DBVersion?: string(name='DBVersion', description='The version of the AnalyticDB for MySQL Data Lakehouse Edition cluster. Only the version **5.0** is supported.', example='5.0'),
      engine?: string(name='Engine', description='The engine of the cluster. **AnalyticDB** is returned.', example='AnalyticDB'),
      expireTime?: string(name='ExpireTime', description='The time when the cluster expired. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.

> *   The expiration time is returned for a subscription cluster.
> *   An empty string is returned for a pay-as-you-go cluster.', example='2022-07-01T09:50:18Z'),
      expired?: string(name='Expired', description='Indicates whether the subscription cluster has expired. Valid values:

*   **true**: The cluster has expired.
*   **false**: The cluster has not expired.

> *   If the cluster has expired, the system locks or releases the cluster within a specific time period. We recommend that you renew expired clusters. For more information, see [Renewal policy](~~135246~~).
> *  This parameter is not returned for pay-as-you-go clusters.', example='false'),
      lockMode?: string(name='LockMode', description='The lock state of the instance. Valid values:

*   **Unlock**: The cluster is not locked.
*   **ManualLock**: The cluster is manually locked.
*   **LockByExpiration**: The cluster is automatically locked due to cluster expiration.', example='Unlock'),
      lockReason?: string(name='LockReason', description='The reason why the cluster is locked.

>  This parameter is returned only when the cluster is locked. The value is **instance_expire**.', example='instance_expired'),
      mode?: string(name='Mode', description='The mode of the cluster. By default, **flexible** is returned, which indicates that the cluster is in elastic mode.', example='flexible'),
      payType?: string(name='PayType', description='The billing method of the cluster. Valid values:

*   **Postpaid**: pay-as-you-go
*   **Prepaid**: subscription', example='Prepaid'),
      port?: string(name='Port', description='The port number that is used to connect to the cluster.', example='3306'),
      regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
      reservedACU?: string(name='ReservedACU', description='The remaining reserved computing resources that are available in the cluster. Each ACU is equivalent to 1 core and 4 GB memory.', example='32ACU'),
      resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group.', example='rg-acfmyiu4ekp****'),
      storageResource?: string(name='StorageResource', description='The specifications of the reserved storage resources. Each AnalyticDB compute unit (ACU) is equivalent to 1 core and 4 GB memory. Storage resources serve read and write requests. The amount of storage resources is proportional to the read and write performance of the cluster.', example='24ACU'),
      tags?: {
        tag?: [ 
        {
          key?: string(name='Key'),
          value?: string(name='Value'),
        }
      ](name='Tag')
      }(name='Tags'),
      VPCId?: string(name='VPCId', description='The ID of the virtual private cloud (VPC).', example='vpc-bp13h7uzhulpuxvnp****'),
      vSwitchId?: string(name='VSwitchId', description='The vSwitch ID of the cluster.', example='vsw-bp1syh8vvw8yech7n****'),
      zoneId?: string(name='ZoneId', description='The zone ID of the cluster.', example='cn-hangzhou-h'),
    }
  ](name='DBCluster')
  }(name='Items', description='Details of the clusters.'),
  pageNumber?: int32(name='PageNumber', description='The page number of the returned page.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries returned on each page.', example='30'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5EDBA27-AF3E-5966-9503-FD1557E19167'),
  totalCount?: int32(name='TotalCount', description='The total number of entries.', example='1'),
}

model DescribeDBClustersResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDBClustersResponseBody(name='body'),
}

async function describeDBClustersWithOptions(request: DescribeDBClustersRequest, runtime: Util.RuntimeOptions): DescribeDBClustersResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterDescription)) {
    query['DBClusterDescription'] = request.DBClusterDescription;
  }
  if (!Util.isUnset(request.DBClusterIds)) {
    query['DBClusterIds'] = request.DBClusterIds;
  }
  if (!Util.isUnset(request.DBClusterStatus)) {
    query['DBClusterStatus'] = request.DBClusterStatus;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.resourceGroupId)) {
    query['ResourceGroupId'] = request.resourceGroupId;
  }
  if (!Util.isUnset(request.tag)) {
    query['Tag'] = request.tag;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeDBClusters',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeDBClusters(request: DescribeDBClustersRequest): DescribeDBClustersResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeDBClustersWithOptions(request, runtime);
}

model DescribeDBResourceGroupRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  groupName?: string(name='GroupName', description='The name of the resource group.

> If you do not specify this parameter, the information about all resource groups in the cluster is returned.', example='test_group'),
  groupType?: string(name='GroupType', description='The type of the resource group. Valid values:

*   **Interactive**
*   **Job**

> For information about resource groups of Data Lakehouse Edition, see [Resource groups](~~428610~~).', example='Job'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
}

model DescribeDBResourceGroupResponseBody = {
  groupsInfo?: [ 
    {
      clusterMode?: string(name='ClusterMode'),
      clusterSizeResource?: string(name='ClusterSizeResource'),
      createTime?: string(name='CreateTime', description='The time when the resource group was created. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.', example='2022-08-29T03:34:30Z'),
      elasticMinComputeResource?: string(name='ElasticMinComputeResource', description='The amount of minimum elastic computing resources. Unit: ACU.', example='16ACU'),
      groupName?: string(name='GroupName', description='The name of the resource group.', example='test1'),
      groupType?: string(name='GroupType', description='The type of the resource group. Valid values:

*   **Interactive**
*   **Job**

> For information about resource groups of Data Lakehouse Edition, see [Resource groups](~~428610~~).', example='Job'),
      groupUsers?: string(name='GroupUsers', description='The Resource Access Management (RAM) user with which the resource group is associated.', example='testb,testc'),
      maxClusterCount?: int32(name='MaxClusterCount'),
      maxComputeResource?: string(name='MaxComputeResource', description='The maximum amount of reserved computing resources. Unit: ACU.', example='512ACU'),
      minClusterCount?: int32(name='MinClusterCount'),
      minComputeResource?: string(name='MinComputeResource', description='The minimum amount of reserved computing resources. Unit: AnalyticDB compute unit (ACU).', example='0ACU'),
      runningClusterCount?: int32(name='RunningClusterCount'),
      status?: string(name='Status', description='The state of the resource group. Valid values:

*   **creating**
*   **ok**
*   **pendingdelete**', example='ok'),
      updateTime?: string(name='UpdateTime', description='The time when the resource group was updated. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.', example='2022-08-31T03:34:30Z'),
    }
  ](name='GroupsInfo', description='The queried resource groups.'),
  requestId?: string(name='RequestId', description='The request ID.', example='A94B6C02-7BD4-5D67-9776-3AC8317E8DD3'),
}

model DescribeDBResourceGroupResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDBResourceGroupResponseBody(name='body'),
}

async function describeDBResourceGroupWithOptions(request: DescribeDBResourceGroupRequest, runtime: Util.RuntimeOptions): DescribeDBResourceGroupResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  if (!Util.isUnset(request.groupType)) {
    query['GroupType'] = request.groupType;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeDBResourceGroup',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeDBResourceGroup(request: DescribeDBResourceGroupRequest): DescribeDBResourceGroupResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeDBResourceGroupWithOptions(request, runtime);
}

model DescribeDiagnosisDimensionsRequest {
  DBClusterId?: string(name='DBClusterId', example='amv-bt6u59zcmd945****'),
  endTime?: string(name='EndTime', example='1625220213000'),
  lang?: string(name='Lang', example='zh-CN'),
  queryCondition?: string(name='QueryCondition', example='{"Type":"maxCost","Value":"100"}'),
  regionId?: string(name='RegionId', example='cn-hangzhou'),
  startTime?: string(name='StartTime', example='1625220210000'),
}

model DescribeDiagnosisDimensionsResponseBody = {
  clientIps?: [ string ](name='ClientIps'),
  databases?: [ string ](name='Databases'),
  requestId?: string(name='RequestId', example='DEA97C6B-D7A4-5E69-9EFC-D7F88737CED5'),
  resourceGroups?: [ string ](name='ResourceGroups'),
  userNames?: [ string ](name='UserNames'),
}

model DescribeDiagnosisDimensionsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDiagnosisDimensionsResponseBody(name='body'),
}

async function describeDiagnosisDimensionsWithOptions(request: DescribeDiagnosisDimensionsRequest, runtime: Util.RuntimeOptions): DescribeDiagnosisDimensionsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.lang)) {
    query['Lang'] = request.lang;
  }
  if (!Util.isUnset(request.queryCondition)) {
    query['QueryCondition'] = request.queryCondition;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeDiagnosisDimensions',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeDiagnosisDimensions(request: DescribeDiagnosisDimensionsRequest): DescribeDiagnosisDimensionsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeDiagnosisDimensionsWithOptions(request, runtime);
}

model DescribeDiagnosisRecordsRequest {
  clientIp?: string(name='ClientIp', example='59.82.XX.XX'),
  DBClusterId?: string(name='DBClusterId', example='amv-bp1scs48yc125****'),
  database?: string(name='Database', example='adb_demo'),
  endTime?: string(name='EndTime', example='1633017540000'),
  keyword?: string(name='Keyword', example='select'),
  lang?: string(name='Lang', example='zh'),
  maxPeakMemory?: long(name='MaxPeakMemory', example='89000000'),
  maxScanSize?: long(name='MaxScanSize', example='1024000000'),
  minPeakMemory?: long(name='MinPeakMemory', example='0'),
  minScanSize?: long(name='MinScanSize', example='0'),
  order?: string(name='Order', example='[{"Field":"StartTime", "Type": "desc" }]'),
  pageNumber?: int32(name='PageNumber', example='1'),
  pageSize?: int32(name='PageSize', example='30'),
  patternId?: string(name='PatternId', example='5575924945138******'),
  queryCondition?: string(name='QueryCondition', example='{"Type":"status","Value":"finished"}'),
  regionId?: string(name='RegionId', example='cn-hangzhou'),
  resourceGroup?: string(name='ResourceGroup', example='user_default'),
  startTime?: string(name='StartTime', example='1632931200000'),
  userName?: string(name='UserName', example='test_user'),
}

model DescribeDiagnosisRecordsResponseBody = {
  pageNumber?: int32(name='PageNumber', example='1'),
  pageSize?: int32(name='PageSize', example='30'),
  querys?: [ 
    {
      clientIp?: string(name='ClientIp', example='59.82.XX.XX'),
      cost?: long(name='Cost', example='10'),
      database?: string(name='Database', example='adb_demo'),
      etlWriteRows?: long(name='EtlWriteRows', example='0'),
      executionTime?: long(name='ExecutionTime', example='6'),
      outputDataSize?: long(name='OutputDataSize', example='9'),
      outputRows?: long(name='OutputRows', example='1'),
      peakMemory?: long(name='PeakMemory', example='16648'),
      processId?: string(name='ProcessId', example='2021093000414401000000023503151******'),
      queueTime?: long(name='QueueTime', example='6'),
      rcHost?: string(name='RcHost', example='10.0.XX.XX:3004'),
      resourceCostRank?: int32(name='ResourceCostRank', example='1'),
      resourceGroup?: string(name='ResourceGroup', example='user_default'),
      SQL?: string(name='SQL', example='SELECT count(*)\\nFROM nation'),
      SQLTruncated?: boolean(name='SQLTruncated', example='false'),
      SQLTruncatedThreshold?: long(name='SQLTruncatedThreshold', example='5120'),
      scanRows?: long(name='ScanRows', example='1'),
      scanSize?: long(name='ScanSize', example='9'),
      startTime?: long(name='StartTime', example='1632933704000'),
      status?: string(name='Status', example='finished'),
      totalPlanningTime?: long(name='TotalPlanningTime', example='4'),
      totalStages?: int32(name='TotalStages', example='2'),
      userName?: string(name='UserName', example='test_user'),
    }
  ](name='Querys'),
  requestId?: string(name='RequestId', example='7F88BEFA-CF0B-5C95-8BB1-92EC9F09E40D'),
  totalCount?: int32(name='TotalCount', example='1'),
}

model DescribeDiagnosisRecordsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDiagnosisRecordsResponseBody(name='body'),
}

async function describeDiagnosisRecordsWithOptions(request: DescribeDiagnosisRecordsRequest, runtime: Util.RuntimeOptions): DescribeDiagnosisRecordsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.clientIp)) {
    query['ClientIp'] = request.clientIp;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.database)) {
    query['Database'] = request.database;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!Util.isUnset(request.lang)) {
    query['Lang'] = request.lang;
  }
  if (!Util.isUnset(request.maxPeakMemory)) {
    query['MaxPeakMemory'] = request.maxPeakMemory;
  }
  if (!Util.isUnset(request.maxScanSize)) {
    query['MaxScanSize'] = request.maxScanSize;
  }
  if (!Util.isUnset(request.minPeakMemory)) {
    query['MinPeakMemory'] = request.minPeakMemory;
  }
  if (!Util.isUnset(request.minScanSize)) {
    query['MinScanSize'] = request.minScanSize;
  }
  if (!Util.isUnset(request.order)) {
    query['Order'] = request.order;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.patternId)) {
    query['PatternId'] = request.patternId;
  }
  if (!Util.isUnset(request.queryCondition)) {
    query['QueryCondition'] = request.queryCondition;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.resourceGroup)) {
    query['ResourceGroup'] = request.resourceGroup;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.userName)) {
    query['UserName'] = request.userName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeDiagnosisRecords',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeDiagnosisRecords(request: DescribeDiagnosisRecordsRequest): DescribeDiagnosisRecordsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeDiagnosisRecordsWithOptions(request, runtime);
}

model DescribeDiagnosisSQLInfoRequest {
  DBClusterId?: string(name='DBClusterId', example='amv-bp1r053byu48p'),
  lang?: string(name='Lang', example='zh'),
  processId?: string(name='ProcessId', example='2021070216432217201616806503453'),
  processRcHost?: string(name='ProcessRcHost', example='192.45.***.***:3145'),
  processStartTime?: long(name='ProcessStartTime', example='1625215402000'),
  processState?: string(name='ProcessState', example='running'),
  regionId?: string(name='RegionId', example='cn-hangzhou'),
}

model DescribeDiagnosisSQLInfoResponseBody = {
  diagnosisSQLInfo?: string(name='DiagnosisSQLInfo', example='{     "DiagnosisSQLInfo": {         "hasSharedStage": false,         "resourceGroup": "user_default",         "cost": 274,         "queuedTime": 0,         "outputDataSize": 9,         "scheduled": true,         "query": "/*+display=tpch_q14*/SELECT 100.00 * SUM(CASE WHEN p_type LIKE \\"PROMO%\\" THEN l_extendedprice * (1 - l_discount) ELSE 0 END) / SUM(l_extendedprice * (1 - l_discount)) AS promo_revenue FROM lineitem l, part p WHERE l_partkey = p_partkey AND l_shipdate &gt;= DATE \\"1995-09-01\\" AND l_shipdate &lt; DATE \\"1995-09-01\\" + INTERVAL \\"1\\" MONTH",         "outputRows": 1,         "userName": "test_user",         "parentId": 0,         "maxOutputRows": 200000,         "scanSize": 8247470,         "peakMemory": 13188295,         "startTime": 1626330527632,         "state": "FINISHED",         "endTime": 1626330527905,         "writeTableRows": 0,         "scanRows": 351966     } }'),
  requestId?: string(name='RequestId', example='1'),
  stageInfos?: [ 
    {
      inputDataSize?: long(name='InputDataSize', example='2341'),
      inputRows?: long(name='InputRows', example='2341'),
      operatorCost?: long(name='OperatorCost', example='2341'),
      outputDataSize?: long(name='OutputDataSize', example='2341'),
      outputRows?: long(name='OutputRows', example='2341'),
      peakMemory?: long(name='PeakMemory', example='2341'),
      progress?: double(name='Progress', example='0.3'),
      stageId?: string(name='StageId', description='StageID', example='Stage[26]'),
      state?: string(name='State', example='RUNNING'),
    }
  ](name='StageInfos'),
}

model DescribeDiagnosisSQLInfoResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDiagnosisSQLInfoResponseBody(name='body'),
}

async function describeDiagnosisSQLInfoWithOptions(request: DescribeDiagnosisSQLInfoRequest, runtime: Util.RuntimeOptions): DescribeDiagnosisSQLInfoResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeDiagnosisSQLInfo',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeDiagnosisSQLInfo(request: DescribeDiagnosisSQLInfoRequest): DescribeDiagnosisSQLInfoResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeDiagnosisSQLInfoWithOptions(request, runtime);
}

model DescribeDownloadRecordsRequest {
  DBClusterId?: string(name='DBClusterId', example='amv-8vb6ha79k6e****'),
  lang?: string(name='Lang', example='zh'),
  regionId?: string(name='RegionId', example='cn-hangzhou'),
}

model DescribeDownloadRecordsResponseBody = {
  records?: [ 
    {
      downloadId?: long(name='DownloadId', example='636890'),
      exceptionMsg?: string(name='ExceptionMsg', example='The query result is empty.'),
      fileName?: string(name='FileName', example='20210806094635-20210806095135'),
      status?: string(name='Status', example='finished'),
      url?: string(name='Url', example='https://perth-download-task.oss-cn-beijing.aliyuncs.com/adbmysql/query-sql-logs/amv-*********/20210805104301-20210805164302.xlsx?Expires=1943514161&OSSAccessKeyId=*********&Signature=******"'),
    }
  ](name='Records'),
  requestId?: string(name='RequestId', example='D761DA51-12F8-5457-AAA9-F52B9F436D2D'),
}

model DescribeDownloadRecordsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDownloadRecordsResponseBody(name='body'),
}

async function describeDownloadRecordsWithOptions(request: DescribeDownloadRecordsRequest, runtime: Util.RuntimeOptions): DescribeDownloadRecordsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.lang)) {
    query['Lang'] = request.lang;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeDownloadRecords',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeDownloadRecords(request: DescribeDownloadRecordsRequest): DescribeDownloadRecordsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeDownloadRecordsWithOptions(request, runtime);
}

model DescribeElasticPlanAttributeRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the ID of an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****'),
  elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the name of a scaling plan.', example='test'),
}

model DescribeElasticPlanAttributeResponseBody = {
  elasticPlan?: {
    autoScale?: boolean(name='AutoScale', description='Indicates whether **Proportional Default Scaling for EIUs** is enabled.

Valid values:

true: Proportional Default Scaling for EIUs is enabled. If you set this parameter to true, the amount of storage resources scales along with the computing resources.

false: Proportional Default Scaling for EIUs is not enabled.

>  You can enable Proportional Default Scaling for EIUs for only a single scaling plan of a cluster.', example='false'),
    cronExpression?: string(name='CronExpression', description='A CORN expression that indicates the scaling cycle and time for the scaling plan.', example='0 20 14 * * ?'),
    elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.', example='test'),
    enabled?: boolean(name='Enabled', description='Indicates whether the scaling plan was enabled.', example='true'),
    endTime?: string(name='EndTime', description='The end time of the scaling plan.

>  The time follows the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time is displayed in UTC.', example='2025-01-01T12:01:00Z'),
    resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.', example='test'),
    startTime?: string(name='StartTime', description='The start time of the scaling plan.

>  The time follows the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time is displayed in UTC.', example='2022-01-01T12:01:00Z'),
    targetSize?: string(name='TargetSize', description='The amount of elastic resources after scaling.', example='32ACU'),
    type?: string(name='Type', description='The type of the scaling plan.', example='EXECUTOR'),
  }(name='ElasticPlan', description='Details of the scaling plan.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model DescribeElasticPlanAttributeResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeElasticPlanAttributeResponseBody(name='body'),
}

async function describeElasticPlanAttributeWithOptions(request: DescribeElasticPlanAttributeRequest, runtime: Util.RuntimeOptions): DescribeElasticPlanAttributeResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.elasticPlanName)) {
    query['ElasticPlanName'] = request.elasticPlanName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeElasticPlanAttribute',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeElasticPlanAttribute(request: DescribeElasticPlanAttributeRequest): DescribeElasticPlanAttributeResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeElasticPlanAttributeWithOptions(request, runtime);
}

model DescribeElasticPlanJobsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the ID of an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****'),
  elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.

> *   If you do not specify this parameter, all scaling plans of the cluster are queried.
> *   You can call the [DescribeElasticPlans](~~601334~~) operation to query the name of a scaling plan.', example='test'),
  pageNumber?: int32(name='PageNumber', description='The number of the page to return.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of scaling plan jobs to return per page.', example='10'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> *   If you do not specify this parameter, the scaling plans of all resource groups are queried, including interactive resource groups and elastic I/O units (EIUs).
> *   You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group within a specific cluster.', example='test'),
  startTime?: string(name='StartTime', description='The time to enable the scaling plan job.

Specify the time in the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time must be in UTC.', example='2022-01-01T12:01:00Z'),
  status?: string(name='Status', description='The state of the scaling plan job.

Valid values:

*   RUNNING: The job is running.

*   SUCCESSFUL: The job is successfully run.

*   FAILED: The job fails.

> If you do not specify this parameter, scaling plan jobs in all states are queried.', example='SUCCESSFUL'),
}

model DescribeElasticPlanJobsResponseBody = {
  jobs?: [ 
    {
      elasticAcu?: string(name='ElasticAcu', description='The amount of elastic resources.

> *   If the Type parameter is set to EXECUTOR, ElasticAcu indicates the amount of elastic resources in the current resource group.
> *   If the Type parameter is set to WORKER, ElasticAcu indicates the total amount of elastic storage resources in the current cluster.', example='16ACU'),
      elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.', example='test'),
      endTime?: string(name='EndTime', description='The time when the scaling plan job was complete.

>  The time follows the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time is displayed in UTC.', example='2022-01-01T12:01:00Z'),
      instanceSize?: int32(name='InstanceSize', description='The number of instances.

> *   If the Type parameter is set to EXECUTOR, InstanceSize indicates the number of compute nodes.
> *   If the Type parameter is set to EXECUTOR, InstanceSize indicates the number of replica sets at the storage layer in the cluster.', example='1'),
      reserveAcu?: string(name='ReserveAcu', description='The amount of reserved resources.

> *   If the Type parameter is set to EXECUTOR, ReserveAcu indicates the amount of reserved resources in the current resource group.
> *   If the Type parameter is set to WORKER, ReserveAcu indicates the total amount of reserved storage resources in the current cluster.', example='16ACU'),
      resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.', example='test'),
      startTime?: string(name='StartTime', description='The time when the scaling plan job was enabled.

>  The time follows the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time is displayed in UTC.', example='2022-01-01T11:01:00Z'),
      status?: string(name='Status', description='The state of the scaling plan job.

Valid values:

*   RUNNING: The job is running.
*   SUCCESSFUL: The job is successfully run.
*   FAILED: The job fails.', example='SUCCESSFUL'),
      targetSize?: string(name='TargetSize', description='The amount of elastic resources after scaling.', example='32ACU'),
      totalAcu?: string(name='TotalAcu', description='The total amount of resources.

> *   If the Type parameter is set to EXECUTOR, TotalAcu indicates the total amount of computing resources in the current resource group.
> *   If the Type parameter is set to WORKER, TotalAcu indicates the total amount of storage resources in the cluster.', example='32ACU'),
      type?: string(name='Type', description='The type of the scaling plan job.

Valid values:

*   EXECUTOR: interactive resource groups, which fall into the computing resource category.
*   WORKER: EIUs.', example='EXECUTOR'),
    }
  ](name='Jobs', description='Details of the scaling plan jobs.'),
  pageNumber?: int32(name='PageNumber', description='The page number of the returned page.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of scaling plan jobs returned per page.', example='10'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
  totalCount?: int32(name='TotalCount', description='The total number of scaling plan jobs.', example='15'),
}

model DescribeElasticPlanJobsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeElasticPlanJobsResponseBody(name='body'),
}

async function describeElasticPlanJobsWithOptions(request: DescribeElasticPlanJobsRequest, runtime: Util.RuntimeOptions): DescribeElasticPlanJobsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.elasticPlanName)) {
    query['ElasticPlanName'] = request.elasticPlanName;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.resourceGroupName)) {
    query['ResourceGroupName'] = request.resourceGroupName;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.status)) {
    query['Status'] = request.status;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeElasticPlanJobs',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeElasticPlanJobs(request: DescribeElasticPlanJobsRequest): DescribeElasticPlanJobsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeElasticPlanJobsWithOptions(request, runtime);
}

model DescribeElasticPlanSpecificationsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the ID of an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> *   This parameter is required only when you query the resource specifications that can be scaled for an interactive resource group.
> *   You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group within a specific cluster.', example='test'),
  type?: string(name='Type', description='The type of the scaling plan. Valid values:

*   EXECUTOR: interactive resource groups, which fall into the computing resource category.
*   WORKER: EIUs.', example='EXECUTOR'),
}

model DescribeElasticPlanSpecificationsResponseBody = {
  pageNumber?: int32(name='PageNumber', description='The page number of the returned page.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of resource specifications returned per page.', example='5'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
  specifications?: [ string ](name='Specifications', description='The resource specifications that can be scaled.'),
  totalCount?: int32(name='TotalCount', description='The number of resource specifications that can be scaled.', example='10'),
}

model DescribeElasticPlanSpecificationsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeElasticPlanSpecificationsResponseBody(name='body'),
}

async function describeElasticPlanSpecificationsWithOptions(request: DescribeElasticPlanSpecificationsRequest, runtime: Util.RuntimeOptions): DescribeElasticPlanSpecificationsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.resourceGroupName)) {
    query['ResourceGroupName'] = request.resourceGroupName;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeElasticPlanSpecifications',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeElasticPlanSpecifications(request: DescribeElasticPlanSpecificationsRequest): DescribeElasticPlanSpecificationsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeElasticPlanSpecificationsWithOptions(request, runtime);
}

model DescribeElasticPlansRequest {
  DBClusterId?: string(name='DBClusterId', description='The cluster ID.

> You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****'),
  elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.

> If you do not specify this parameter, all scaling plans are queried.', example='test'),
  enabled?: boolean(name='Enabled', description='Indicates whether the scaling plan was immediately enabled after the plan is created. Valid values:

*   true
*   false', example='true'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> *   If you do not specify this parameter, the scaling plans of all resource groups are queried, covering the interactive resource group type and the elastic I/O unit (EIU) type.
>*   You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group within a cluster.', example='test'),
  type?: string(name='Type', description='The type of the scaling plan. Valid values:

*   EXECUTOR: interactive resource groups, which fall into the computing resource category.
*   WORKER: EIUs.', example='EXECUTOR'),
}

model DescribeElasticPlansResponseBody = {
  elasticPlans?: [ 
    {
      autoScale?: boolean(name='AutoScale', description='Indicates whether **Proportional Default Scaling for EIUs** is enabled. Valid values:

*   true
*   false', example='false'),
      elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.', example='test'),
      enabled?: boolean(name='Enabled', description='Indicates whether the scaling plan was immediately enabled after the plan is created. Valid values:

*   true
*   false', example='true'),
      nextScheduleTime?: string(name='NextScheduleTime', description='The time when the next scheduling is performed.

> The time is in the yyyy-MM-ddTHH:mm:ssZ format.', example='2022-01-01T12:01:00Z'),
      resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group within a cluster.', example='test'),
      targetSize?: string(name='TargetSize', description='The amount of elastic resources after scaling.', example='32ACU'),
      type?: string(name='Type', description='The type of the scaling plan. Valid values:

*   EXECUTOR: interactive resource group.
*   WORKER: EIU.', example='EXECUTOR'),
    }
  ](name='ElasticPlans', description='The scaling plans.'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='15'),
}

model DescribeElasticPlansResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeElasticPlansResponseBody(name='body'),
}

async function describeElasticPlansWithOptions(request: DescribeElasticPlansRequest, runtime: Util.RuntimeOptions): DescribeElasticPlansResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.elasticPlanName)) {
    query['ElasticPlanName'] = request.elasticPlanName;
  }
  if (!Util.isUnset(request.enabled)) {
    query['Enabled'] = request.enabled;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.resourceGroupName)) {
    query['ResourceGroupName'] = request.resourceGroupName;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeElasticPlans',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeElasticPlans(request: DescribeElasticPlansRequest): DescribeElasticPlansResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeElasticPlansWithOptions(request, runtime);
}

model DescribeEnabledPrivilegesRequest {
  accountName?: string(name='AccountName'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp14t95lun0w****'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
}

model DescribeEnabledPrivilegesResponseBody = {
  data?: [ 
    {
      description?: string(name='Description', description='The description of the permission level.'),
      privileges?: [ 
        {
          description?: string(name='Description', description='The description of the permission.'),
          key?: string(name='Key', description='The name of the permission.', example='select'),
        }
      ](name='Privileges', description='Details of the permissions.'),
      scope?: string(name='Scope', description='The permission level.', example='Global'),
    }
  ](name='Data', description='The permission levels and specific permissions.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='246F42E0-A475-15FF-96D2-8DC47FC2F289'),
}

model DescribeEnabledPrivilegesResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeEnabledPrivilegesResponseBody(name='body'),
}

async function describeEnabledPrivilegesWithOptions(request: DescribeEnabledPrivilegesRequest, runtime: Util.RuntimeOptions): DescribeEnabledPrivilegesResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeEnabledPrivileges',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeEnabledPrivileges(request: DescribeEnabledPrivilegesRequest): DescribeEnabledPrivilegesResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeEnabledPrivilegesWithOptions(request, runtime);
}

model DescribeJobResourceUsageRequest {
  DBClusterId?: string(name='DBClusterId', example='am-uf6g8w25jacm7****'),
  endTime?: string(name='EndTime', example='2023-03-17T16:00:00Z'),
  startTime?: string(name='StartTime', example='2023-02-04T03:45:00Z'),
}

model DescribeJobResourceUsageResponseBody = {
  code?: int32(name='Code', example='200'),
  data?: {
    DBClusterId?: string(name='DBClusterId', example='amv-clusterxxx'),
    endTime?: string(name='EndTime', example='2023-05-23T16:00:00Z'),
    jobAcuUsage?: [ 
      {
        acuUsageDetail?: {
          elasticAcuNumber?: float(name='ElasticAcuNumber', example='16ACU'),
          reservedAcuNumber?: float(name='ReservedAcuNumber', example='16ACU'),
          totalAcuNumber?: float(name='TotalAcuNumber', example='32ACU'),
        }(name='AcuUsageDetail'),
        jobEndTime?: string(name='JobEndTime', example='2023-05-23T16:00:00Z'),
        jobId?: string(name='JobId', example='1592'),
        jobStartTime?: string(name='JobStartTime', example='2023-05-22T16:00:00Z'),
        resourceGroupName?: string(name='ResourceGroupName', example='job_default'),
      }
    ](name='JobAcuUsage'),
    startTime?: string(name='StartTime', example='2023-05-22T16:00:00Z'),
  }(name='Data'),
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DescribeJobResourceUsageResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeJobResourceUsageResponseBody(name='body'),
}

async function describeJobResourceUsageWithOptions(request: DescribeJobResourceUsageRequest, runtime: Util.RuntimeOptions): DescribeJobResourceUsageResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeJobResourceUsage',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeJobResourceUsage(request: DescribeJobResourceUsageRequest): DescribeJobResourceUsageResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeJobResourceUsageWithOptions(request, runtime);
}

model DescribePatternPerformanceRequest {
  DBClusterId?: string(name='DBClusterId', description='The cluster ID.

> You can call the [DescribeDBClusters](~~129857~~) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region, including cluster IDs.', example='amv-uf6li1r3do8m****'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.

> The end time must be later than the start time.', example='2022-08-22T01:06:00Z'),
  patternId?: string(name='PatternId', description='The ID of the SQL pattern.

> You can call the [DescribeSQLPatterns](~~321868~~) operation to query the information about all SQL patterns in an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster within a period of time, including SQL pattern IDs.', example='3847585356974******'),
  regionId?: string(name='RegionId', description='The region ID.', example='cn-hangzhou'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.

> 

*   If the current date is August 22, 2022 (UTC+8), you can query the data of August 9, 2022 (2022-08-08T16:00:00Z) to the earliest extent. If you want to query the data that is earlier than August 9, 2022 (2022-08-08T16:00:00Z), null is returned.

*   The maximum time range that can be specified is 24 hours.', example='2022-08-21T02:15:00Z'),
}

model DescribePatternPerformanceResponseBody = {
  endTime?: string(name='EndTime', description='The end time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time is displayed in UTC.', example='2022-08-22T01:06:00Z'),
  performances?: [ 
    {
      key?: string(name='Key', example='AnalyticDB_PatternExecutionTime'),
      series?: [ 
        {
          name?: string(name='Name', example='max_query_time'),
          values?: [ string ](name='Values'),
        }
      ](name='Series'),
      unit?: string(name='Unit', example='ms'),
    }
  ](name='Performances', description='The name of the performance metric value. Valid values:

*   When the `Key` parameter is set to `AnalyticDB_PatternQueryCount`, `pattern_query_count` is returned, which indicates the number of executions of the SQL statements in association with the SQL pattern.

*   When the `Key` value is `AnalyticDB_PatternQueryTime`, the following values are returned:

    *   `average_query_time`, which indicates the average total amount of time consumed by the SQL statements in association with the SQL pattern.
    *   `max_query_time`, which indicates the maximum total amount of time consumed by the SQL statements in association with the SQL pattern.

*   When the `Key` value is `AnalyticDB_PatternExecutionTime`, the following values are returned:

    *   `average_execution_time`, which indicates the average execution duration of the SQL statements in association with the SQL pattern.
    *   `max_execution_time`, which indicates the maximum execution duration of the SQL statements in association with the SQL pattern.

*   When the `Key` value is `AnalyticDB_PatternPeakMemory`, the following values are returned:

    *   `average_peak_memory`, which indicates the average peak memory usage of the SQL statements in association with the SQL pattern.
    *   `max_peak_memory`, which indicates the maximum peak memory usage of the SQL statements in association with the SQL pattern.

*   When the `Key` value is `AnalyticDB_PatternScanSize`, the following values are returned:

    *   `average_scan_size`, which indicates the average amount of data scanned by the SQL statements in association with the SQL pattern.
    *   `max_scan_size`, which indicates the maximum amount of data scanned by the SQL statements in association with the SQL pattern.'),
  requestId?: string(name='RequestId', description='The request ID.', example='F21AF487-B8C9-57E0-8E3A-A92BC3611FB6'),
  startTime?: string(name='StartTime', description='The start time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time is displayed in UTC.', example='2022-08-21T02:15:00Z'),
}

model DescribePatternPerformanceResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribePatternPerformanceResponseBody(name='body'),
}

async function describePatternPerformanceWithOptions(request: DescribePatternPerformanceRequest, runtime: Util.RuntimeOptions): DescribePatternPerformanceResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.patternId)) {
    query['PatternId'] = request.patternId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribePatternPerformance',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describePatternPerformance(request: DescribePatternPerformanceRequest): DescribePatternPerformanceResponse {
  var runtime = new Util.RuntimeOptions{};
  return describePatternPerformanceWithOptions(request, runtime);
}

model DescribeRegionsRequest {
  acceptLanguage?: string(name='AcceptLanguage', description='The language used for the region and zone names specified by the LocalName parameter. Default value: zh-CN. Valid values:

*   **zh-CN**: simplified Chinese
*   **en-US**: English
*   **ja**: Japanese', example='en-US'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model DescribeRegionsResponseBody = {
  regions?: {
    region?: [ 
    {
      localName?: string(name='LocalName', description='The name of the region.', example='China (Hangzhou)'),
      regionEndpoint?: string(name='RegionEndpoint', description='The endpoint of the region.', example='adb.aliyuncs.com'),
      regionId?: string(name='RegionId', description='The ID of the region.', example='cn-hangzhou'),
      zones?: {
        zone?: [ 
        {
          localName?: string(name='LocalName', description='The name of the zone.', example='Hangzhou Zone H'),
          vpcEnabled?: boolean(name='VpcEnabled', description='Indicates whether Virtual Private Cloud (VPC) is supported in the zone. Valid values:

*   **true**: VPC is supported.
*   **false**: VPC is not supported.', example='true'),
          zoneId?: string(name='ZoneId', description='The ID of the zone.', example='cn-hangzhou-h'),
        }
      ](name='Zone')
      }(name='Zones', description='Details of the zones.'),
    }
  ](name='Region')
  }(name='Regions', description='Details of the regions.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='421794A3-72A5-5D27-9E8B-A75A4C503E17'),
}

model DescribeRegionsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeRegionsResponseBody(name='body'),
}

async function describeRegionsWithOptions(request: DescribeRegionsRequest, runtime: Util.RuntimeOptions): DescribeRegionsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.acceptLanguage)) {
    query['AcceptLanguage'] = request.acceptLanguage;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeRegions',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeRegions(request: DescribeRegionsRequest): DescribeRegionsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeRegionsWithOptions(request, runtime);
}

model DescribeSQLPatternsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~129857~~) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region, including cluster IDs.', example='amv-8vb8de93v9b****'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.

> The end time must be later than the start time.', example='2022-09-07T03:06:00Z'),
  keyword?: string(name='Keyword', description='The keyword that is used for the query.', example='SELECT'),
  lang?: string(name='Lang', description='The language. Valid values:

*   **zh** (default): simplified Chinese.
*   **en**: English.
*   **ja**: Japanese.
*   **zh-tw**: traditional Chinese.', example='zh'),
  order?: string(name='Order', description='The order by which to sort query results. Specify the parameter value in the JSON string format. Example: `[{"Field":"AverageQueryTime","Type":"Asc"}]`. Parameters:

*   `Field` specifies the field by which to sort the query results. Valid values:

    *   `PatternCreationTime`: the earliest commit time of the SQL pattern within the time range to query.
    *   `AverageQueryTime`: the average total amount of time consumed by the SQL pattern within the time range to query.
    *   `MaxQueryTime`: the maximum total amount of time consumed by the SQL pattern within the time range to query.
    *   `AverageExecutionTime`: the average execution duration of the SQL pattern within the time range to query.
    *   `MaxExecutionTime`: the maximum execution duration of the SQL pattern within the time range to query.
    *   `AveragePeakMemory`: the average peak memory usage of the SQL pattern within the time range to query.
    *   `MaxPeakMemory`: the maximum peak memory usage of the SQL pattern within the time range to query.
    *   `AverageScanSize`: the average amount of data scanned based on the SQL pattern within the time range to query.
    *   `MaxScanSize`: the maximum amount of data scanned based on the SQL pattern within the time range to query.
    *   `QueryCount`: the number of queries performed in association with the SQL pattern within the time range to query.
    *   `FailedCount`: the number of failed queries performed in association with the SQL pattern within the time range to query.

*   `Type` specifies the sorting order. Valid values (case-insensitive):

    *   `Asc`: ascending order.
    *   `Desc`: descending order.', example='[{"Field":"AverageQueryTime","Type":"Asc"}]'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='2'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **10** (default)
*   **30**
*   **50**
*   **100**', example='10'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.

> 

*   Only data within the last 14 days can be queried.

*   The maximum time range that can be specified is 24 hours.', example='2022-09-06T03:06:00Z'),
}

model DescribeSQLPatternsResponseBody = {
  pageNumber?: int32(name='PageNumber', description='The page number.', example='2'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  patternDetails?: [ 
    {
      accessIp?: string(name='AccessIp', example='192.168.xx.xx'),
      averageExecutionTime?: double(name='AverageExecutionTime', example='234.78'),
      averagePeakMemory?: double(name='AveragePeakMemory', example='234.22'),
      averageQueryTime?: double(name='AverageQueryTime', example='4'),
      averageScanSize?: double(name='AverageScanSize', example='234149.23'),
      blockable?: boolean(name='Blockable', example='true'),
      failedCount?: long(name='FailedCount', example='18'),
      maxExecutionTime?: long(name='MaxExecutionTime', example='2142'),
      maxPeakMemory?: long(name='MaxPeakMemory', example='234149'),
      maxQueryTime?: long(name='MaxQueryTime', example='2341'),
      maxScanSize?: long(name='MaxScanSize', example='32212254'),
      patternCreationTime?: string(name='PatternCreationTime', example='2022-09-06 05:06:00'),
      patternId?: string(name='PatternId', example='5575924945138******'),
      queryCount?: long(name='QueryCount', example='345'),
      SQLPattern?: string(name='SQLPattern', example='SELECT * FROM KEPLER_META_NODE_STATIC_INFO WHERE elastic_node = ? OR (elastic_node = ? AND enable = ?)'),
      tables?: string(name='Tables', example='tpch.orders'),
      user?: string(name='User', example='test'),
    }
  ](name='PatternDetails', description='Indicates whether the execution of the SQL pattern can be blocked. Valid values:

*   **true**
*   **false**

> Only SELECT and INSERT statements can be blocked.'),
  requestId?: string(name='RequestId', description='The request ID.', example='F3174013-5B7A-5A47-9FE0-6B5D397BD86B'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='20'),
}

model DescribeSQLPatternsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeSQLPatternsResponseBody(name='body'),
}

async function describeSQLPatternsWithOptions(request: DescribeSQLPatternsRequest, runtime: Util.RuntimeOptions): DescribeSQLPatternsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!Util.isUnset(request.lang)) {
    query['Lang'] = request.lang;
  }
  if (!Util.isUnset(request.order)) {
    query['Order'] = request.order;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeSQLPatterns',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeSQLPatterns(request: DescribeSQLPatternsRequest): DescribeSQLPatternsResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeSQLPatternsWithOptions(request, runtime);
}

model DescribeSchemasRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1xxxxxxxx47'),
  regionId?: string(name='RegionId', description='The region ID.', example='cn-hangzhou'),
}

model DescribeSchemasResponseBody = {
  items?: {
    schema?: [ 
    {
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
      schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
    }
  ](name='Schema')
  }(name='Items', description='The queried databases.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25B56BC7-4978-40B3-9E48-4B7067******'),
}

model DescribeSchemasResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeSchemasResponseBody(name='body'),
}

async function describeSchemasWithOptions(request: DescribeSchemasRequest, runtime: Util.RuntimeOptions): DescribeSchemasResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeSchemas',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeSchemas(request: DescribeSchemasRequest): DescribeSchemasResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeSchemasWithOptions(request, runtime);
}

model DescribeSparkCodeLogRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-uf6o6m8p6x7v****'),
  jobId?: long(name='JobId', description='The ID of the Spark job.', example='1248'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
}

model DescribeSparkCodeLogResponseBody = {
  log?: string(name='Log', description='The content of the log.', example='>>>>>>>> stdout:n++++++++++++++++++executing sql: MSCK REPAIR TABLE  `footprint_ethereum`.`dwd_eth_eth_txr_v2_di` n++n'),
  message?: string(name='Message', description='The returned message.

*   If the request was successful, **Success** is returned.
*   If the request failed, an error message is returned.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='1CD65640-9963-5D60-929C-118F2C84070E'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeSparkCodeLogResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeSparkCodeLogResponseBody(name='body'),
}

async function describeSparkCodeLogWithOptions(request: DescribeSparkCodeLogRequest, runtime: Util.RuntimeOptions): DescribeSparkCodeLogResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeSparkCodeLog',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeSparkCodeLog(request: DescribeSparkCodeLogRequest): DescribeSparkCodeLogResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeSparkCodeLogWithOptions(request, runtime);
}

model DescribeSparkCodeOutputRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-uf6210mmev07****'),
  jobId?: long(name='JobId', description='The ID of the Spark job.', example='620'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
}

model DescribeSparkCodeOutputResponseBody = {
  message?: string(name='Message', description='The returned message.

*   If the request was successful, **Success** is returned.
*   If the request failed, an error message is returned.', example='Success'),
  output?: string(name='Output', description='The execution result, which is in the format of JSON objects.', example='"{\\"schema\\":[\\"id\\",\\"name\\",\\"age\\"],\\"data\\":[\\"{\\\\\\"id\\\\\\":10,\\\\\\"name\\\\\\":\\\\\\"z\\\\\\",\\\\\\"age\\\\\\":123}\\",\\"{\\\\\\"id\\\\\\":2,\\\\\\"name\\\\\\":\\\\\\"b\\\\\\",\\\\\\"age\\\\\\":17}\\",\\"{\\\\\\"id\\\\\\":1,\\\\\\"name\\\\\\":\\\\\\"a\\\\\\",\\\\\\"age\\\\\\":15}\\",\\"{\\\\\\"id\\\\\\":3,\\\\\\"name\\\\\\":\\\\\\"c\\\\\\",\\\\\\"age\\\\\\":222}\\",\\"{\\\\\\"id\\\\\\":10,\\\\\\"name\\\\\\":\\\\\\"z\\\\\\",\\\\\\"age\\\\\\":123}\\"],\\"haveRows\\":true,\\"rowNumber\\":6}"'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeSparkCodeOutputResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeSparkCodeOutputResponseBody(name='body'),
}

async function describeSparkCodeOutputWithOptions(request: DescribeSparkCodeOutputRequest, runtime: Util.RuntimeOptions): DescribeSparkCodeOutputResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeSparkCodeOutput',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeSparkCodeOutput(request: DescribeSparkCodeOutputRequest): DescribeSparkCodeOutputResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeSparkCodeOutputWithOptions(request, runtime);
}

model DescribeSparkCodeWebUiRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1v6usq6m65****'),
  jobId?: long(name='JobId', description='The ID of the Spark job.', example='1248'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
}

model DescribeSparkCodeWebUiResponseBody = {
  message?: string(name='Message', description='The returned message.

*   If the request was successful, **SUCCESS** is returned.
*   If the request failed, an error message is returned.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='774DDC37-1908-58F6-B9CA-99E3E45965A6'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
  url?: string(name='Url', description='The URL of the web UI for the Spark application.', example='https://adb-subuser-cn-hangzhou-1358535755648527-100000648.oss-cn-hangzhou.aliyuncs.com/%3Facl?Expires=1681295967&OSSAccessKeyId=LTAI5tB7NAkm25oiGASu****&Signature=hKAZ1vgvhJ%2FD8hNHTuX%2FOOBWht****'),
}

model DescribeSparkCodeWebUiResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeSparkCodeWebUiResponseBody(name='body'),
}

async function describeSparkCodeWebUiWithOptions(request: DescribeSparkCodeWebUiRequest, runtime: Util.RuntimeOptions): DescribeSparkCodeWebUiResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.jobId)) {
    query['JobId'] = request.jobId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeSparkCodeWebUi',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeSparkCodeWebUi(request: DescribeSparkCodeWebUiRequest): DescribeSparkCodeWebUiResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeSparkCodeWebUiWithOptions(request, runtime);
}

model DescribeSqlPatternRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1ej1nq9n6****'),
  order?: string(name='Order', description='The order by which to sort query results. Specify the parameter value in the JSON string format. Example: `[{"Field":"Pattern","Type":"Asc"}]`. Parameters:

*   `Field` specifies the field by which to sort the query results. Valid values:

    *   `Pattern`: the SQL pattern.
    *   `AccessIP`: the IP address of the client.
    *   `User`: the username.
    *   `QueryCount`: the number of queries performed in association with the SQL pattern within the time range to query.
    *   `AvgPeakMemory`: the average peak memory usage of the SQL pattern within the time range to query. Unit: KB.
    *   `MaxPeakMemory`: the maximum peak memory usage of the SQL pattern within the time range to query. Unit: KB.
    *   `AvgCpuTime`: the average execution duration of the SQL pattern within the time range to query. Unit: milliseconds.
    *   `MaxCpuTime`: the maximum execution duration of the SQL pattern within the time range to query. Unit: milliseconds.
    *   `AvgStageCount`: the average number of stages.
    *   `MaxStageCount`: the maximum number of stages.
    *   `AvgTaskCount`: the average number of tasks.
    *   `MaxTaskCount`: the maximum number of tasks.
    *   `AvgScanSize`: the average amount of data scanned based on the SQL pattern within the time range to query. Unit: KB.
    *   `MaxScanSize`: the maximum amount of data scanned based on the SQL pattern within the time range to query. Unit: KB.

*   `Type` specifies the sorting order. Valid values:

    *   `Asc`: ascending order.
    *   `Desc`: descending order.

> 

*   If you do not specify this parameter, query results are sorted in ascending order of `Pattern`.

*   If you want to sort query results by `AccessIP`, you must set the `Type` parameter to `accessip`. If you want to sort query results by `User`, you must leave the `Type` parameter empty or set it to `user`.', example='[{"Field":"Pattern","Type":"Asc"}]'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='2'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **10** (default)
*   **30**
*   **50**
*   **100**', example='30'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
  sqlPattern?: string(name='SqlPattern', description='The keyword that is used for the query.

> If you do not specify this parameter, all SQL patterns of the AnalyticDB for MySQL cluster within the time period specified by `StartTime` are returned.', example='SELECT'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-dd format. The time must be in UTC.

> Only data within the last 30 days can be queried.', example='2022-08-30T12:10:00Z'),
  type?: string(name='Type', description='The dimension by which to aggregate the SQL patterns. Valid values:

*   `user`: aggregates the SQL patterns by user.
*   `accessip`: aggregates the SQL patterns by client IP address.

> If you do not specify this parameter, the SQL patterns are aggregated by `user`.', example='user'),
}

model DescribeSqlPatternResponseBody = {
  items?: [ 
    {
      accessIP?: string(name='AccessIP', description='The IP address of the client.

>  This parameter is returned only when **Type** is set to **accessip**.', example='100.104.xx.xx'),
      avgCpuTime?: string(name='AvgCpuTime', description='The average execution duration of the SQL pattern within the query time range. Unit: milliseconds.', example='1.0625'),
      avgPeakMemory?: string(name='AvgPeakMemory', description='The average peak memory usage of the SQL pattern within the query time range. Unit: KB.', example='240048'),
      avgScanSize?: string(name='AvgScanSize', description='The average amount of data scanned based on the SQL pattern within the query time range. Unit: KB.', example='244'),
      avgStageCount?: string(name='AvgStageCount', description='The average number of scanned rows.', example='2'),
      avgTaskCount?: string(name='AvgTaskCount', description='The average number of tasks.', example='2'),
      instanceName?: string(name='InstanceName', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1ej1nq9n6****'),
      maxCpuTime?: string(name='MaxCpuTime', description='The maximum execution duration of the SQL pattern within the query time range. Unit: milliseconds.', example='17'),
      maxPeakMemory?: string(name='MaxPeakMemory', description='The maximum peak memory usage of the SQL pattern within the query time range. Unit: KB.', example='480096'),
      maxScanSize?: string(name='MaxScanSize', description='The maximum amount of data scanned based on the SQL pattern within the query time range. Unit: KB.', example='1024'),
      maxStageCount?: string(name='MaxStageCount', description='The maximum number of stages.', example='2'),
      maxTaskCount?: string(name='MaxTaskCount', description='The maximum number of tasks.', example='2'),
      pattern?: string(name='Pattern', description='The SQL pattern.', example='SELECT table_name, table_schema AS schema_name, create_time, create_time AS last_ddl_time, table_comment AS description , ceil((data_length + index_length) / ? / ?) AS store_capacity , data_length AS data_bytes, index_length AS index_bytes, table_collation AS collation, auto_increment, table_rows AS num_rows , engine FROM information_schema.tables WHERE table_type != ? AND table_schema = ? AND table_name IN (?) ORDER BY 1'),
      queryCount?: string(name='QueryCount', description='The number of queries performed in association with the SQL pattern within the query time range.', example='16'),
      reportDate?: string(name='ReportDate', description='The start date of the query.', example='2022-08-30'),
      user?: string(name='User', description='The username.

>  This parameter is returned only when **Type** is left empty or set to **user**.', example='test_acc'),
    }
  ](name='Items', description='The queried SQL pattern.'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='2'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='DB1F6C23-CBCA-5260-9366-BA7BB5EBF6F1'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='50'),
}

model DescribeSqlPatternResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeSqlPatternResponseBody(name='body'),
}

async function describeSqlPatternWithOptions(request: DescribeSqlPatternRequest, runtime: Util.RuntimeOptions): DescribeSqlPatternResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.order)) {
    query['Order'] = request.order;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.sqlPattern)) {
    query['SqlPattern'] = request.sqlPattern;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.type)) {
    query['Type'] = request.type;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeSqlPattern',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeSqlPattern(request: DescribeSqlPatternRequest): DescribeSqlPatternResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeSqlPatternWithOptions(request, runtime);
}

model DescribeStorageResourceUsageRequest {
  DBClusterId?: string(name='DBClusterId', example='amv-bp10yt0gva71ei7d'),
  endTime?: string(name='EndTime', example='2022-08-23T01:06:00Z'),
  startTime?: string(name='StartTime', example='2022-08-22T01:06:00Z'),
}

model DescribeStorageResourceUsageResponseBody = {
  code?: int32(name='Code', example='200'),
  data?: {
    acuInfo?: [ 
      {
        name?: string(name='Name', example='TotalAcuNumber'),
        values?: [ string ](name='Values'),
      }
    ](name='AcuInfo'),
    DBClusterId?: string(name='DBClusterId', example='amv-bp1bg858bo8c****'),
    endTime?: string(name='EndTime', example='2022-08-23T01:06:00Z'),
    startTime?: string(name='StartTime', example='2022-08-22T01:06:00Z'),
  }(name='Data'),
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEAW'),
}

model DescribeStorageResourceUsageResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeStorageResourceUsageResponseBody(name='body'),
}

async function describeStorageResourceUsageWithOptions(request: DescribeStorageResourceUsageRequest, runtime: Util.RuntimeOptions): DescribeStorageResourceUsageResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeStorageResourceUsage',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeStorageResourceUsage(request: DescribeStorageResourceUsageRequest): DescribeStorageResourceUsageResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeStorageResourceUsageWithOptions(request, runtime);
}

model DescribeTableAccessCountRequest {
  DBClusterId?: string(name='DBClusterId', example='amv-2ze627uzpkh8a8****'),
  order?: string(name='Order', example='[{"Field":"TableSchema","Type":"Asc"}]'),
  pageNumber?: int32(name='PageNumber', example='1'),
  pageSize?: int32(name='PageSize', example='30'),
  regionId?: string(name='RegionId', example='cn-hangzhou'),
  startTime?: string(name='StartTime', example='2022-09-25T12:10:00Z'),
  tableName?: string(name='TableName', example='CUSTOMER'),
}

model DescribeTableAccessCountResponseBody = {
  items?: [ 
    {
      accessCount?: string(name='AccessCount', example='6'),
      instanceName?: string(name='InstanceName', example='amv-2ze627uzpkh8a8****'),
      reportDate?: string(name='ReportDate', example='2022-09-26'),
      tableName?: string(name='TableName', example='CUSTOMER'),
      tableSchema?: string(name='TableSchema', example='tpch'),
    }
  ](name='Items'),
  pageNumber?: int32(name='PageNumber', example='1'),
  pageSize?: int32(name='PageSize', example='30'),
  requestId?: string(name='RequestId', example='6B7D627B-DA23-572D-AD71-256F64698B7D'),
  totalCount?: int32(name='TotalCount', example='1'),
}

model DescribeTableAccessCountResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeTableAccessCountResponseBody(name='body'),
}

async function describeTableAccessCountWithOptions(request: DescribeTableAccessCountRequest, runtime: Util.RuntimeOptions): DescribeTableAccessCountResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.order)) {
    query['Order'] = request.order;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.tableName)) {
    query['TableName'] = request.tableName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeTableAccessCount',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeTableAccessCount(request: DescribeTableAccessCountRequest): DescribeTableAccessCountResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeTableAccessCountWithOptions(request, runtime);
}

model DescribeTablesRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1xxxxxxxx47'),
  regionId?: string(name='RegionId', description='The region ID.', example='cn-hangzhou'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
}

model DescribeTablesResponseBody = {
  items?: {
    table?: [ 
    {
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1xxxxxxxx47'),
      schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
      tableName?: string(name='TableName', description='The name of the table.', example='test'),
    }
  ](name='Table')
  }(name='Items', description='The queried tables.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DescribeTablesResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeTablesResponseBody(name='body'),
}

async function describeTablesWithOptions(request: DescribeTablesRequest, runtime: Util.RuntimeOptions): DescribeTablesResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.schemaName)) {
    query['SchemaName'] = request.schemaName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeTables',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeTables(request: DescribeTablesRequest): DescribeTablesResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeTablesWithOptions(request, runtime);
}

model DescribeUserQuotaRequest {
  DBClusterId?: string(name='DBClusterId', example='amv-bp1qjt3o18d86987'),
  regionId?: string(name='RegionId'),
}

model DescribeUserQuotaResponseBody = {
  elasticACU?: string(name='ElasticACU', example='512ACU'),
  requestId?: string(name='RequestId', example='0322C7FB-4584-5D2A-BF7F-F9036E940C35'),
  reserverdCompteACU?: string(name='ReserverdCompteACU', example='48ACU'),
  reserverdStorageACU?: string(name='ReserverdStorageACU', example='24ACU'),
  resourceGroupCount?: string(name='ResourceGroupCount', example='10'),
}

model DescribeUserQuotaResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeUserQuotaResponseBody(name='body'),
}

async function describeUserQuotaWithOptions(request: DescribeUserQuotaRequest, runtime: Util.RuntimeOptions): DescribeUserQuotaResponse {
  Util.validateModel(request);
  var query = OpenApiUtil.query(Util.toMap(request));
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DescribeUserQuota',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'GET',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function describeUserQuota(request: DescribeUserQuotaRequest): DescribeUserQuotaResponse {
  var runtime = new Util.RuntimeOptions{};
  return describeUserQuotaWithOptions(request, runtime);
}

model DetachUserENIRequest {
  DBClusterId?: string(name='DBClusterId', example='am-bp11q28kvl688****'),
}

model DetachUserENIResponseBody = {
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DetachUserENIResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DetachUserENIResponseBody(name='body'),
}

async function detachUserENIWithOptions(request: DetachUserENIRequest, runtime: Util.RuntimeOptions): DetachUserENIResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DetachUserENI',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function detachUserENI(request: DetachUserENIRequest): DetachUserENIResponse {
  var runtime = new Util.RuntimeOptions{};
  return detachUserENIWithOptions(request, runtime);
}

model DisableElasticPlanRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the ID of an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****'),
  elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the name of a scaling plan for a specific cluster.', example='test'),
}

model DisableElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model DisableElasticPlanResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DisableElasticPlanResponseBody(name='body'),
}

async function disableElasticPlanWithOptions(request: DisableElasticPlanRequest, runtime: Util.RuntimeOptions): DisableElasticPlanResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.elasticPlanName)) {
    query['ElasticPlanName'] = request.elasticPlanName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DisableElasticPlan',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function disableElasticPlan(request: DisableElasticPlanRequest): DisableElasticPlanResponse {
  var runtime = new Util.RuntimeOptions{};
  return disableElasticPlanWithOptions(request, runtime);
}

model DownloadDiagnosisRecordsRequest {
  clientIp?: string(name='ClientIp', example='106.11.XX.XX'),
  DBClusterId?: string(name='DBClusterId', example='amv-bp1q8bu9a****'),
  database?: string(name='Database', example='adb_demo'),
  endTime?: string(name='EndTime', example='1662450730000'),
  keyword?: string(name='Keyword', example='select'),
  lang?: string(name='Lang', example='zh'),
  maxPeakMemory?: long(name='MaxPeakMemory', example='88000000'),
  maxScanSize?: long(name='MaxScanSize', example='64424509440'),
  minPeakMemory?: long(name='MinPeakMemory', example='88000000'),
  minScanSize?: long(name='MinScanSize', example='1073741824'),
  queryCondition?: string(name='QueryCondition', example='{"Type":"status","Value":"finished"}'),
  regionId?: string(name='RegionId', example='cn-hangzhou'),
  resourceGroup?: string(name='ResourceGroup', example='user_default'),
  startTime?: string(name='StartTime', example='1662364330000'),
  userName?: string(name='UserName', example='test_user'),
}

model DownloadDiagnosisRecordsResponseBody = {
  downloadId?: int32(name='DownloadId', example='25494'),
  requestId?: string(name='RequestId', example='845774AC-5D43-53A2-AAB8-C73828E68508'),
}

model DownloadDiagnosisRecordsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DownloadDiagnosisRecordsResponseBody(name='body'),
}

async function downloadDiagnosisRecordsWithOptions(request: DownloadDiagnosisRecordsRequest, runtime: Util.RuntimeOptions): DownloadDiagnosisRecordsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.clientIp)) {
    query['ClientIp'] = request.clientIp;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.database)) {
    query['Database'] = request.database;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.keyword)) {
    query['Keyword'] = request.keyword;
  }
  if (!Util.isUnset(request.lang)) {
    query['Lang'] = request.lang;
  }
  if (!Util.isUnset(request.maxPeakMemory)) {
    query['MaxPeakMemory'] = request.maxPeakMemory;
  }
  if (!Util.isUnset(request.maxScanSize)) {
    query['MaxScanSize'] = request.maxScanSize;
  }
  if (!Util.isUnset(request.minPeakMemory)) {
    query['MinPeakMemory'] = request.minPeakMemory;
  }
  if (!Util.isUnset(request.minScanSize)) {
    query['MinScanSize'] = request.minScanSize;
  }
  if (!Util.isUnset(request.queryCondition)) {
    query['QueryCondition'] = request.queryCondition;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.resourceGroup)) {
    query['ResourceGroup'] = request.resourceGroup;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.userName)) {
    query['UserName'] = request.userName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'DownloadDiagnosisRecords',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function downloadDiagnosisRecords(request: DownloadDiagnosisRecordsRequest): DownloadDiagnosisRecordsResponse {
  var runtime = new Util.RuntimeOptions{};
  return downloadDiagnosisRecordsWithOptions(request, runtime);
}

model EnableElasticPlanRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the ID of an AnalyticDB for MySQL Data Warehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****'),
  elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the name of a scaling plan for a specific cluster.', example='test'),
}

model EnableElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model EnableElasticPlanResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: EnableElasticPlanResponseBody(name='body'),
}

async function enableElasticPlanWithOptions(request: EnableElasticPlanRequest, runtime: Util.RuntimeOptions): EnableElasticPlanResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.elasticPlanName)) {
    query['ElasticPlanName'] = request.elasticPlanName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'EnableElasticPlan',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function enableElasticPlan(request: EnableElasticPlanRequest): EnableElasticPlanResponse {
  var runtime = new Util.RuntimeOptions{};
  return enableElasticPlanWithOptions(request, runtime);
}

model ExistRunningSQLEngineRequest {
  DBClusterId?: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.', example='amv-bp1cit7z8j****'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

>  You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of the resource group for a cluster.', example='spark_test'),
}

model ExistRunningSQLEngineResponseBody = {
  data?: boolean(name='Data', description='Indicates whether a running SQL engine exists in the resource group.

Valid values:

*   **True**
*   **False**', example='True'),
  requestId?: string(name='RequestId', description='The request ID.', example='FA675D68-14A4-5D9C-8820-92537D9F447E'),
}

model ExistRunningSQLEngineResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ExistRunningSQLEngineResponseBody(name='body'),
}

async function existRunningSQLEngineWithOptions(request: ExistRunningSQLEngineRequest, runtime: Util.RuntimeOptions): ExistRunningSQLEngineResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.resourceGroupName)) {
    body['ResourceGroupName'] = request.resourceGroupName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'ExistRunningSQLEngine',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function existRunningSQLEngine(request: ExistRunningSQLEngineRequest): ExistRunningSQLEngineResponse {
  var runtime = new Util.RuntimeOptions{};
  return existRunningSQLEngineWithOptions(request, runtime);
}

model GetDatabaseObjectsRequest {
  DBClusterId?: string(name='DBClusterId', description='The cluster ID.', example='am-bp1565u55p32****'),
  filterOwner?: string(name='FilterOwner', description='The owner of the database.', example='admin'),
  filterSchemaName?: string(name='FilterSchemaName', description='The name of the database.', example='test_db'),
  orderBy?: string(name='OrderBy', description='The order in which you want to sort the query results. Valid values:

*   Asc
*   Desc

Valid values for Field: DatabaseName, CreateTime, and UpdateTime. -CreateTime; -UpdateTime;

Default value: {"Type": "Desc","Field": "DatabaseName"}.', example='{"Type": "Desc","Field": "DbName"}'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   30
*   50
*   100

Default value: 30.', example='30'),
  regionId?: string(name='RegionId', description='The region ID of the database.', example='cn-hangzhou'),
}

model GetDatabaseObjectsResponseBody = {
  data?: {
    databaseSummaryModels?: [
      DatabaseSummaryModel
    ](name='DatabaseSummaryModels', description='The queried database.'),
    pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   30
*   50
*   100

Default value: 30.', example='30'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The queried databases.'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='863D51B7-5321-41D8-A0B6-A088B0******'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model GetDatabaseObjectsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetDatabaseObjectsResponseBody(name='body'),
}

async function getDatabaseObjectsWithOptions(request: GetDatabaseObjectsRequest, runtime: Util.RuntimeOptions): GetDatabaseObjectsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.filterOwner)) {
    query['FilterOwner'] = request.filterOwner;
  }
  if (!Util.isUnset(request.filterSchemaName)) {
    query['FilterSchemaName'] = request.filterSchemaName;
  }
  if (!Util.isUnset(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetDatabaseObjects',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getDatabaseObjects(request: GetDatabaseObjectsRequest): GetDatabaseObjectsResponse {
  var runtime = new Util.RuntimeOptions{};
  return getDatabaseObjectsWithOptions(request, runtime);
}

model GetSparkAppAttemptLogRequest {
  attemptId?: string(name='AttemptId', description='The ID of the log.

> You can call the [ListSparkAppAttempts](~~455887~~) operation to query the information about the retry attempts of a Spark application, including the retry log IDs.', example='s202207151211hz****-0001'),
  logLength?: long(name='LogLength', description='The number of log entries to return. Valid values: 1 to 500. Default value: 300.', example='20'),
}

model GetSparkAppAttemptLogResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The application ID.', example='s202204132018hzprec1ac61a000****'),
    DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-clusterxxx'),
    logContent?: string(name='LogContent', description='The content of the log.', example='22/04/22 15:30:49 INFO Utils: Start the dump task because s202207151211hz****-0001 app end, the interval is 238141ms;22/04/22 15:30:49 INFO AbstractConnector: Stopped Spark@5e774d9d{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}'),
    message?: string(name='Message', description='The alert message returned for the request, such as task execution failure or insufficient resources. If no alert occurs, null is returned.', example='WARNING: log file maybe deleted, please check oss path: oss://TestBucketName/applog/'),
  }(name='Data', description='The queried log.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C3A9594F-1D40-4472-A96C-8FB8AA20D38C'),
}

model GetSparkAppAttemptLogResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkAppAttemptLogResponseBody(name='body'),
}

async function getSparkAppAttemptLogWithOptions(request: GetSparkAppAttemptLogRequest, runtime: Util.RuntimeOptions): GetSparkAppAttemptLogResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.attemptId)) {
    body['AttemptId'] = request.attemptId;
  }
  if (!Util.isUnset(request.logLength)) {
    body['LogLength'] = request.logLength;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'GetSparkAppAttemptLog',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getSparkAppAttemptLog(request: GetSparkAppAttemptLogRequest): GetSparkAppAttemptLogResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSparkAppAttemptLogWithOptions(request, runtime);
}

model GetSparkAppInfoRequest {
  appId?: string(name='AppId', description='The application ID.

>  You can call the [ListSparkApps](~~455888~~) operation to query the Spark application IDs.', example='s202205201533hz1209892000****'),
  DBClusterId?: string(name='DBClusterId', example='am-bp11q28kvl688****'),
}

model GetSparkAppInfoResponseBody = {
  data?: SparkAppInfo(name='Data', description='The queried Spark application. Fields in the response parameter:

*   **Data**: the data of the Spark application template.
*   **EstimateExecutionCpuTimeInSeconds**: the amount of time that is required to consume CPU resources for running the Spark application. Unit: milliseconds.
*   **LogRootPath**: the storage path of log files.
*   **LastAttemptId**: the most recent attempt ID.
*   **WebUiAddress**: the web UI URL.
*   **SubmittedTimeInMillis**: the time when the Spark application was submitted. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
*   **StartedTimeInMillis**: the time when the Spark application was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
*   **LastUpdatedTimeInMillis**: the time when the Spark application was last updated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
*   **TerminatedTimeInMillis**: the time when the Spark application was terminated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
*   **DBClusterId**: the ID of the cluster on which the Spark application runs.
*   **ResourceGroupName**: the name of the job resource group.
*   **DurationInMillis**: the amount of time that is required to run the Spark application. Unit: milliseconds.', example='{     \\"name\\": \\"SparkPi\\",     \\"file\\": \\"local:///tmp/spark-examples.jar\\",     \\"className\\": \\"org.apache.spark.examples.SparkPi\\",     \\"args\\": [         \\"1000000\\"     ],     \\"conf\\": {         \\"spark.driver.resourceSpec\\": \\"small\\",         \\"spark.executor.instances\\": 1,         \\"spark.executor.resourceSpec\\": \\"small\\"     } }",
      "EstimateExecutionCpuTimeInSeconds" : 100,
      "LogRootPath" : "oss://test/logs/driver",
      "LastAttemptId" : "s202204291426hzpre60cfabb0000004-0003",
      "WebUiAddress" : "https://sparkui.aliyuncs.com/token=xxx",
      "SubmittedTimeInMillis" : 1651213645000,
      "StartedTimeInMillis" : 1651213645010,
      "LastUpdatedTimeInMillis" : 1651213645200,
      "TerminatedTimeInMillis" : 1651213645300,
      "DBClusterId" : "am-dbclusterid",
      "ResourceGroupName" : "spark-rg",
      "DurationInMillis" : 100
    }'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkAppInfoResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkAppInfoResponseBody(name='body'),
}

async function getSparkAppInfoWithOptions(request: GetSparkAppInfoRequest, runtime: Util.RuntimeOptions): GetSparkAppInfoResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.appId)) {
    body['AppId'] = request.appId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'GetSparkAppInfo',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getSparkAppInfo(request: GetSparkAppInfoRequest): GetSparkAppInfoResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSparkAppInfoWithOptions(request, runtime);
}

model GetSparkAppLogRequest {
  appId?: string(name='AppId', description='The Spark application ID.

> You can call the [ListSparkApps](~~612475~~) operation to query the Spark application ID.', example='s202206061441hz22a35ab000****'),
  DBClusterId?: string(name='DBClusterId'),
  logLength?: long(name='LogLength', description='The number of log entries to return. Valid values: 1 to 500. Default value: 300.', example='20'),
}

model GetSparkAppLogResponseBody = {
  data?: {
    DBClusterId?: string(name='DBClusterId', description='The ID of the Data Lakehouse Edition (V3.0) cluster.', example='amv-clusterxxx'),
    logContent?: string(name='LogContent', description='The content of the log.', example='22/04/22 15:30:49 INFO Utils: Start the dump task because s202206061441hz22a35ab000****-0001 app end, the interval is 238141ms;22/04/22 15:30:49 INFO AbstractConnector: Stopped Spark@5e774d9d{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}'),
    message?: string(name='Message', description='The alert message returned for the request, such as task execution failure or insufficient resources. If no alert occurs, null is returned.', example='WARNING:  log file maybe deleted, please check oss path: oss://TestBucketName/applog/'),
  }(name='Data', description='The queried log.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C3A9594F-1D40-4472-A96C-8FB8AA20D38C'),
}

model GetSparkAppLogResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkAppLogResponseBody(name='body'),
}

async function getSparkAppLogWithOptions(request: GetSparkAppLogRequest, runtime: Util.RuntimeOptions): GetSparkAppLogResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.appId)) {
    body['AppId'] = request.appId;
  }
  if (!Util.isUnset(request.logLength)) {
    body['LogLength'] = request.logLength;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'GetSparkAppLog',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getSparkAppLog(request: GetSparkAppLogRequest): GetSparkAppLogResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSparkAppLogWithOptions(request, runtime);
}

model GetSparkAppMetricsRequest {
  appId?: string(name='AppId', description='The ID of the Spark application.', example='s202204221525hzca7d8140000003'),
  DBClusterId?: string(name='DBClusterId'),
}

model GetSparkAppMetricsResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark application.', example='s202302051515shfa865f80003691'),
    attemptId?: string(name='AttemptId', description='The attempt ID of the Spark application.', example='s202301061000hz57d797b0000201-0001'),
    eventLogPath?: string(name='EventLogPath', description='The path of the event log.', example='oss://path/to/eventLog'),
    finished?: boolean(name='Finished', description='Indicates whether parsing is complete. Valid values:

*   true
*   false', example='True'),
    scanMetrics?: {
      outputRowsCount?: long(name='OutputRowsCount', description='The number of scanned rows.', example='1000'),
      totalReadFileSizeInByte?: long(name='TotalReadFileSizeInByte', description='The number of scanned bytes.', example='10000'),
    }(name='ScanMetrics', description='The metrics.'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model GetSparkAppMetricsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkAppMetricsResponseBody(name='body'),
}

async function getSparkAppMetricsWithOptions(request: GetSparkAppMetricsRequest, runtime: Util.RuntimeOptions): GetSparkAppMetricsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.appId)) {
    body['AppId'] = request.appId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'GetSparkAppMetrics',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getSparkAppMetrics(request: GetSparkAppMetricsRequest): GetSparkAppMetricsResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSparkAppMetricsWithOptions(request, runtime);
}

model GetSparkAppStateRequest {
  appId?: string(name='AppId', description='The ID of the application.', example='s202204191546hzpread6a896000****'),
  DBClusterId?: string(name='DBClusterId'),
}

model GetSparkAppStateResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the application.', example='s202204191546hzpread6a896000****'),
    appName?: string(name='AppName', description='The name of the application.', example='test'),
    DBClusterId?: string(name='DBClusterId', description='The ID of the Database.', example='amv-clusterxxx'),
    message?: string(name='Message', description='The alert message returned for the operation, such as task execution failure or insufficient resources. Null is returned if no alert occurs.', example='Insufficient resources.'),
    state?: string(name='State', description='The execution state of the application. Valid values:

*   **SUBMITTED**: The application is submitted.
*   **STARTING**: The application task is starting.
*   **RUNNING**: The application task is being executed.
*   **FAILING**: The application task failed, and the environment is being cleared.
*   **FAILED**: The application task failed.
*   **KILLING**: The application task is terminated, and the environment is being cleared.
*   **KILLED**: The application task is terminated.
*   **SUCCEEDING**: The application task is completed, and the environment is being cleared.
*   **COMPLETED**: The application task is completed.
*   **FATAL**: An unexpected failure occurred.
*   **UNKNOWN**: An unknown error occurred.', example='COMPLETED'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkAppStateResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkAppStateResponseBody(name='body'),
}

async function getSparkAppStateWithOptions(request: GetSparkAppStateRequest, runtime: Util.RuntimeOptions): GetSparkAppStateResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.appId)) {
    body['AppId'] = request.appId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'GetSparkAppState',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getSparkAppState(request: GetSparkAppStateRequest): GetSparkAppStateResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSparkAppStateWithOptions(request, runtime);
}

model GetSparkAppWebUiAddressRequest {
  appId?: string(name='AppId', description='The ID of the Spark application.', example='s202205201533hz1209892000****'),
  DBClusterId?: string(name='DBClusterId'),
}

model GetSparkAppWebUiAddressResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark application.', example='s202205201533hz1209892000****'),
    DBClusterId?: string(name='DBClusterId', description='The ID of the Database.', example='amv-clusterxxx'),
    expirationTimeInMillis?: long(name='ExpirationTimeInMillis', description='The expiration time. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since the epoch time January 1, 1970, 00:00:00 UTC.', example='1655801973000'),
    webUiAddress?: string(name='WebUiAddress', description='The URL of the web UI for the Spark application.', example='https://adbsparkui-cn-hangzhou.aliyuncs.com/?token=****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkAppWebUiAddressResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkAppWebUiAddressResponseBody(name='body'),
}

async function getSparkAppWebUiAddressWithOptions(request: GetSparkAppWebUiAddressRequest, runtime: Util.RuntimeOptions): GetSparkAppWebUiAddressResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.appId)) {
    body['AppId'] = request.appId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'GetSparkAppWebUiAddress',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getSparkAppWebUiAddress(request: GetSparkAppWebUiAddressRequest): GetSparkAppWebUiAddressResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSparkAppWebUiAddressWithOptions(request, runtime);
}

model GetSparkConfigLogPathRequest {
  DBClusterId?: string(name='DBClusterId', description='The database ID.', example='am-adsdxxxx'),
}

model GetSparkConfigLogPathResponseBody = {
  data?: {
    defaultLogPath?: string(name='DefaultLogPath', description='The recommended default log path.', example='oss://aliyun-oa-adb-spark-1111-oss-cn-hanghzou/spark-logs'),
    isLogPathExists?: boolean(name='IsLogPathExists', description='Indicates whether a log path exists.', example='true'),
    modifiedTimestamp?: string(name='ModifiedTimestamp', description='The time when the configuration was last modified.', example='1675654361000'),
    modifiedUid?: string(name='ModifiedUid', description='The modifier ID.', example='10130223128xxx'),
    recordedLogPath?: string(name='RecordedLogPath', description='The log path.', example='oss://test/spark-logs/'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1919-xxx-ssdfsdff'),
}

model GetSparkConfigLogPathResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkConfigLogPathResponseBody(name='body'),
}

async function getSparkConfigLogPathWithOptions(request: GetSparkConfigLogPathRequest, runtime: Util.RuntimeOptions): GetSparkConfigLogPathResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'GetSparkConfigLogPath',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getSparkConfigLogPath(request: GetSparkConfigLogPathRequest): GetSparkConfigLogPathResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSparkConfigLogPathWithOptions(request, runtime);
}

model GetSparkDefinitionsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.', example='amv-clusterxxx'),
}

model GetSparkDefinitionsResponseBody = {
  data?: string(name='Data', description='The common definitions of Spark applications.', example='{"SQLTemplateExample": "-- Here is just an example of SparkSQL. Modify the content and run your spark program.
conf spark.driver.resourceSpec=medium;
conf spark.executor.instances=2;
conf spark.executor.resourceSpec=medium;
conf spark.app.name=Spark SQL Test;
conf spark.adb.connectors=oss;

-- Here are your sql statements
show databases;",
                 "BatchTemplateExample": "{
    "comments": [
        "-- Here is just an example of SparkPi. Modify the content and run your spark program."
    ],
    "args": ["1000"],
  "file":"local:///tmp/spark-examples.jar",
    "name": "SparkPi",
    "className": "org.apache.spark.examples.SparkPi",
    "conf": {      "spark.driver.resourceSpec": "medium",
        "spark.executor.instances": 2,
        "spark.executor.resourceSpec": "medium"
    }
}"'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkDefinitionsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkDefinitionsResponseBody(name='body'),
}

async function getSparkDefinitionsWithOptions(request: GetSparkDefinitionsRequest, runtime: Util.RuntimeOptions): GetSparkDefinitionsResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'GetSparkDefinitions',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getSparkDefinitions(request: GetSparkDefinitionsRequest): GetSparkDefinitionsResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSparkDefinitionsWithOptions(request, runtime);
}

model GetSparkLogAnalyzeTaskRequest {
  taskId?: long(name='TaskId', description='The ID of the Spark log analysis task. You can call the ListSparkLogAnalyzeTasks operation to query the IDs of all Spark log analysis tasks that are submitted in the current cluster.', example='12'),
}

model GetSparkLogAnalyzeTaskResponseBody = {
  data?: SparkAnalyzeLogTask(name='Data', description='The information about the Spark log analysis task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1DF5AF5B-C803-1861-A0FF-63666A557709'),
}

model GetSparkLogAnalyzeTaskResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkLogAnalyzeTaskResponseBody(name='body'),
}

async function getSparkLogAnalyzeTaskWithOptions(request: GetSparkLogAnalyzeTaskRequest, runtime: Util.RuntimeOptions): GetSparkLogAnalyzeTaskResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.taskId)) {
    body['TaskId'] = request.taskId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'GetSparkLogAnalyzeTask',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getSparkLogAnalyzeTask(request: GetSparkLogAnalyzeTaskRequest): GetSparkLogAnalyzeTaskResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSparkLogAnalyzeTaskWithOptions(request, runtime);
}

model GetSparkSQLEngineStateRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the job resource group.', example='test_instance'),
}

model GetSparkSQLEngineStateResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark application.', example='s202207151211hz0c****'),
    config?: string(name='Config', description='The configuration of the Spark application.', example='{"key1": "value1", "key2": "value2"}'),
    jars?: string(name='Jars', description='The third-party JAR package.', example='oss://test-bucket/test.jar'),
    maxExecutor?: string(name='MaxExecutor', description='The maximum number of started Spark executors.', example='3'),
    minExecutor?: string(name='MinExecutor', description='The minimum number of started Spark executors.', example='1'),
    slotNum?: string(name='SlotNum', description='The slot number of the Spark application.', example='2'),
    state?: string(name='State', description='The execution state of the application. Valid values:

*   SUBMITTED
*   STARTING
*   RUNNING
*   FAILING
*   FAILED
*   KILLING
*   KILLED
*   SUCCEEDING
*   COMPLETED
*   FATAL
*   UNKNOWN', example='COMPLETED'),
    submittedTimeInMillis?: string(name='SubmittedTimeInMillis', description='The timestamp when the Spark SQL application was submitted. Unit: milliseconds.', example='1651213645000'),
  }(name='Data', description='The state information about the Spark SQL engine.'),
  requestId?: string(name='RequestId', description='The request ID.', example='xxxx-xxx-xx'),
}

model GetSparkSQLEngineStateResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkSQLEngineStateResponseBody(name='body'),
}

async function getSparkSQLEngineStateWithOptions(request: GetSparkSQLEngineStateRequest, runtime: Util.RuntimeOptions): GetSparkSQLEngineStateResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.resourceGroupName)) {
    body['ResourceGroupName'] = request.resourceGroupName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'GetSparkSQLEngineState',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getSparkSQLEngineState(request: GetSparkSQLEngineStateRequest): GetSparkSQLEngineStateResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSparkSQLEngineStateWithOptions(request, runtime);
}

model GetSparkTemplateFileContentRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-8vbn8pq537k8w****'),
  id?: long(name='Id', description='The ID of the application template.

>  You can call the [GetSparkTemplateFullTree](~~456205~~) operation to query the template ID.', example='725204'),
}

model GetSparkTemplateFileContentResponseBody = {
  data?: {
    appType?: string(name='AppType', description='The type of the application. Valid values:

*   **SQL**: SQL application
*   **STREAMING**: streaming application
*   **BATCH**: batch application', example='SQL'),
    content?: string(name='Content', description='The content of the template.', example='set spark.driver.resourceSpec=medium;set spark.executor.instances=2;set spark.executor.resourceSpec=medium;set spark.app.name=Spark SQL Test;'),
    id?: long(name='Id', description='The ID of the application template.', example='725204'),
    resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.', example='test'),
    type?: string(name='Type', description='The type of the file. Valid values:

*   **folder**
*   **file**', example='file'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkTemplateFileContentResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkTemplateFileContentResponseBody(name='body'),
}

async function getSparkTemplateFileContentWithOptions(request: GetSparkTemplateFileContentRequest, runtime: Util.RuntimeOptions): GetSparkTemplateFileContentResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.id)) {
    body['Id'] = request.id;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'GetSparkTemplateFileContent',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getSparkTemplateFileContent(request: GetSparkTemplateFileContentRequest): GetSparkTemplateFileContentResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSparkTemplateFileContentWithOptions(request, runtime);
}

model GetSparkTemplateFolderTreeRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
}

model GetSparkTemplateFolderTreeResponseBody = {
  data?: string(name='Data', description='The directory structure of Spark applications, which is in the tree format. Fields in the response parameter:

*   **Uid**: the UID of the Alibaba Cloud account.

*   **Type**: the type of the application template. Valid values: **FOLDER**: directory.

*   **Parent**: indicates whether a child directory exists. Valid values:

    *   **0**: No child directory exists.
    *   **-1**: A child directory exists.

*   **Children**: the child directory.

*   **LastModified**: the time when applications in the directory are last modified. The time is displayed in the UNIX timestamp format. Unit: seconds.

*   **Name**: the name of the directory.

*   **Id**: the ID of the directory.', example='{           "Uid":195813423****,           "Type":"FOLDER",          "Parent":-1,           "Children":[              {                     "LastModified":1647853173,               "Uid":195813423****,                     "Type":"FOLDER",                     "Parent":0,                     "Id":157,                     "Name":"t"         }       ],            "Id":725204,            "Name":"root"      }'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model GetSparkTemplateFolderTreeResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkTemplateFolderTreeResponseBody(name='body'),
}

/**
  * You can call this operation to query the directory structure but not application data in the directory. To query the directory structure that contains application data, call the [GetSparkTemplateFullTree](~~456205~~) operation.
  *
  * @param request GetSparkTemplateFolderTreeRequest
  * @param runtime runtime options for this request RuntimeOptions
  * @return GetSparkTemplateFolderTreeResponse
 */
async function getSparkTemplateFolderTreeWithOptions(request: GetSparkTemplateFolderTreeRequest, runtime: Util.RuntimeOptions): GetSparkTemplateFolderTreeResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'GetSparkTemplateFolderTree',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
  * You can call this operation to query the directory structure but not application data in the directory. To query the directory structure that contains application data, call the [GetSparkTemplateFullTree](~~456205~~) operation.
  *
  * @param request GetSparkTemplateFolderTreeRequest
  * @return GetSparkTemplateFolderTreeResponse
 */
async function getSparkTemplateFolderTree(request: GetSparkTemplateFolderTreeRequest): GetSparkTemplateFolderTreeResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSparkTemplateFolderTreeWithOptions(request, runtime);
}

model GetSparkTemplateFullTreeRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
}

model GetSparkTemplateFullTreeResponseBody = {
  data?: string(name='Data', description='The directory structure of the application template. Fields in the response parameter:

*   **Uid**: the UID of the Alibaba Cloud account.

*   **Type**: the type of the application template. Valid values:

    *   **FOLDER**: directory
    *   **FILE**: application

*   **Parent**: the parent directory. Valid values:

    *   **0**: No child directory exists.
    *   **-1**: A child directory exists.

*   **Children**: the child directory.

*   **LastModified**: the time when the application is last modified. The time is displayed in the UNIX timestamp format. Unit: seconds.

*   **AppType**: the application type. Valid values:

    *   **SQL**: SQL application
    *   **STREAMING**: streaming application
    *   **BATCH**: batch application

*   **Name**: the name of the directory or application.

*   **Id**: the ID of the directory or application.', example='{     "Uid": 10415777****,     "Type": "FOLDER",     "Parent": -1,     "Children": [       {         "LastModified": 1648544748,         "Uid": 104157779****,         "Type": "FILE",         "Parent": 0,         "Id": s202204132****,         "AppType": "SQL",         "Name": "f"       },       {         "LastModified": 1648544956,         "Uid": 1041577795****,         "Type": "FOLDER",         "Parent": 0,         "Id": 157,         "Name": "f3333"       }     ],     "Id": 725204,     "Name": "root"   }'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model GetSparkTemplateFullTreeResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkTemplateFullTreeResponseBody(name='body'),
}

async function getSparkTemplateFullTreeWithOptions(request: GetSparkTemplateFullTreeRequest, runtime: Util.RuntimeOptions): GetSparkTemplateFullTreeResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'GetSparkTemplateFullTree',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getSparkTemplateFullTree(request: GetSparkTemplateFullTreeRequest): GetSparkTemplateFullTreeResponse {
  var runtime = new Util.RuntimeOptions{};
  return getSparkTemplateFullTreeWithOptions(request, runtime);
}

model GetTableRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.', example='amv-*******'),
  dbName?: string(name='DbName', description='The name of the database.', example='dbName'),
  regionId?: string(name='RegionId', description='The ID of the region in which the cluster resides.', example='cn-hangzhou'),
  tableName?: string(name='TableName', description='The name of the table.', example='tableName'),
}

model GetTableResponseBody = {
  code?: long(name='Code', description='The error code returned.', example='0'),
  message?: string(name='Message', description='The error message returned.', example='""'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  success?: boolean(name='Success', description='Indicates whether the query succeeded.', example='true'),
  table?: TableModel(name='Table', description='Details of the table.'),
}

model GetTableResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetTableResponseBody(name='body'),
}

/**
  * @deprecated
  *
  * @param request GetTableRequest
  * @param runtime runtime options for this request RuntimeOptions
  * @return GetTableResponse
 */
// Deprecated
async function getTableWithOptions(request: GetTableRequest, runtime: Util.RuntimeOptions): GetTableResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.dbName)) {
    query['DbName'] = request.dbName;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.tableName)) {
    query['TableName'] = request.tableName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetTable',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
  * @deprecated
  *
  * @param request GetTableRequest
  * @return GetTableResponse
 */
// Deprecated
async function getTable(request: GetTableRequest): GetTableResponse {
  var runtime = new Util.RuntimeOptions{};
  return getTableWithOptions(request, runtime);
}

model GetTableColumnsRequest {
  columnName?: string(name='ColumnName', description='The name of the column.', example='assist_user_phone'),
  DBClusterId?: string(name='DBClusterId', description='The cluster ID.', example='amv-bp11q28kvl688****'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
  tableName?: string(name='TableName', description='The name of the table.', example='test'),
}

model GetTableColumnsResponseBody = {
  data?: {
    pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
    table?: TableDetailModel(name='Table', description='The information about the table.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='15'),
  }(name='Data', description='The queried data.'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='15'),
}

model GetTableColumnsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetTableColumnsResponseBody(name='body'),
}

async function getTableColumnsWithOptions(request: GetTableColumnsRequest, runtime: Util.RuntimeOptions): GetTableColumnsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.columnName)) {
    query['ColumnName'] = request.columnName;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.schemaName)) {
    query['SchemaName'] = request.schemaName;
  }
  if (!Util.isUnset(request.tableName)) {
    query['TableName'] = request.tableName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetTableColumns',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getTableColumns(request: GetTableColumnsRequest): GetTableColumnsResponse {
  var runtime = new Util.RuntimeOptions{};
  return getTableColumnsWithOptions(request, runtime);
}

model GetTableDDLRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.', example='am-bp1ub9grke1****'),
  regionId?: string(name='RegionId', description='The ID of the region in which the cluster resides.', example='cn-hangzhou'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
  tableName?: string(name='TableName', description='The name of the table.', example='test'),
}

model GetTableDDLResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='863D51B7-5321-41D8-A0B6-A088B0******'),
  SQL?: string(name='SQL', description='The SQL statement.', example='create table (
 id varchar(32)
);'),
}

model GetTableDDLResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetTableDDLResponseBody(name='body'),
}

async function getTableDDLWithOptions(request: GetTableDDLRequest, runtime: Util.RuntimeOptions): GetTableDDLResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.schemaName)) {
    query['SchemaName'] = request.schemaName;
  }
  if (!Util.isUnset(request.tableName)) {
    query['TableName'] = request.tableName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetTableDDL',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getTableDDL(request: GetTableDDLRequest): GetTableDDLResponse {
  var runtime = new Util.RuntimeOptions{};
  return getTableDDLWithOptions(request, runtime);
}

model GetTableObjectsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.', example='am-bp1565u55p32****'),
  filterDescription?: string(name='FilterDescription', description='The description of the table.', example='description'),
  filterOwner?: string(name='FilterOwner', description='The owner of the table.', example='admin'),
  filterTblName?: string(name='FilterTblName', description='The name of the table.', example='test_tbl'),
  filterTblType?: string(name='FilterTblType', description='The type of the table.

Valid values:

DIMENSION_TABLE

FACT_TABLE

EXTERNAL_TABLE

Default value: null.', example='FACT_TABLE'),
  orderBy?: string(name='OrderBy', description='The order in which the fields to be returned are sorted.

Valid values:

*   Asc
*   Desc

Values for fields:

TableName

TableSize

CreateTime

UpdateTime

Default value: {"Type": "Desc","Field": "TableName"};', example='{"Type": "Desc","Field": "TableName"}'),
  pageNumber?: long(name='PageNumber', description='The number of the page to return. The value is an integer that is greater than 0. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries to return on each page. Valid values:

*   30
*   50
*   100

Default value: 30.', example='30'),
  regionId?: string(name='RegionId', description='The ID of the region in which the cluster resides.', example='cn-hangzhou'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
}

model GetTableObjectsResponseBody = {
  data?: {
    pageNumber?: long(name='PageNumber', description='The number of the returned page. The value is an integer that is greater than 0. Default value: **1**.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries returned per page. Default value: 30. Valid values:

*   **30**
*   **50**
*   **100**', example='30'),
    tableSummaryModels?: [
      TableSummaryModel
    ](name='TableSummaryModels', description='Details of the tables.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The data returned.'),
  pageNumber?: long(name='PageNumber', description='The number of the returned page. The value is an integer that is greater than 0. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries returned per page. Default value: 30. Valid values:

*   **30**
*   **50**
*   **100**', example='30'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='863D51B7-5321-41D8-A0B6-A088B0******'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model GetTableObjectsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetTableObjectsResponseBody(name='body'),
}

async function getTableObjectsWithOptions(request: GetTableObjectsRequest, runtime: Util.RuntimeOptions): GetTableObjectsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.filterDescription)) {
    query['FilterDescription'] = request.filterDescription;
  }
  if (!Util.isUnset(request.filterOwner)) {
    query['FilterOwner'] = request.filterOwner;
  }
  if (!Util.isUnset(request.filterTblName)) {
    query['FilterTblName'] = request.filterTblName;
  }
  if (!Util.isUnset(request.filterTblType)) {
    query['FilterTblType'] = request.filterTblType;
  }
  if (!Util.isUnset(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.schemaName)) {
    query['SchemaName'] = request.schemaName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetTableObjects',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getTableObjects(request: GetTableObjectsRequest): GetTableObjectsResponse {
  var runtime = new Util.RuntimeOptions{};
  return getTableObjectsWithOptions(request, runtime);
}

model GetViewDDLRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.', example='am-bp1ub9grke1****'),
  regionId?: string(name='RegionId', description='The ID of the region in which the cluster resides.', example='cn-hangzhou'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
  viewName?: string(name='ViewName', description='The name of the view.', example='v_modbus'),
}

model GetViewDDLResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='421794A3-72A5-5D27-9E8B-A75A4C503E17'),
  SQL?: string(name='SQL', description='Details of the SQL statement.', example='CREATE VIEW `test`.`test_view` AS SELECT
  `id`
, `name`
FROM
  `test_tbl_adb`'),
}

model GetViewDDLResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetViewDDLResponseBody(name='body'),
}

async function getViewDDLWithOptions(request: GetViewDDLRequest, runtime: Util.RuntimeOptions): GetViewDDLResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.schemaName)) {
    query['SchemaName'] = request.schemaName;
  }
  if (!Util.isUnset(request.viewName)) {
    query['ViewName'] = request.viewName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetViewDDL',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getViewDDL(request: GetViewDDLRequest): GetViewDDLResponse {
  var runtime = new Util.RuntimeOptions{};
  return getViewDDLWithOptions(request, runtime);
}

model GetViewObjectsRequest {
  DBClusterId?: string(name='DBClusterId', description='The cluster ID.', example='am-bp1xxxxxxxx47'),
  filterOwner?: string(name='FilterOwner', description='The owner of the view.', example='admin'),
  filterViewName?: string(name='FilterViewName', description='The name of the view.', example='test_filter'),
  filterViewType?: string(name='FilterViewType', description='The type of the view.

Valid values:

\\-VIRTUAL_VIEW

\\-MATERIALIZED_VIEW

Default value: null.', example='VIRTUAL_VIEW'),
  orderBy?: string(name='OrderBy', description='The order in which you want to sort the query results. Valid values for Type:

*   Asc
*   Desc

Valid values for Field: -ViewName

\\-CreateTime

\\-UpdateTime

Default value: {"Type": "Desc","Field": "ViewName"}.', example='{"Type": "Desc","Field": "ViewName"}'),
  pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
}

model GetViewObjectsResponseBody = {
  data?: {
    pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
    tableSummaryModels?: [
      TableSummaryModel
    ](name='TableSummaryModels', description='The queried views.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The returned data.'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model GetViewObjectsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetViewObjectsResponseBody(name='body'),
}

async function getViewObjectsWithOptions(request: GetViewObjectsRequest, runtime: Util.RuntimeOptions): GetViewObjectsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.filterOwner)) {
    query['FilterOwner'] = request.filterOwner;
  }
  if (!Util.isUnset(request.filterViewName)) {
    query['FilterViewName'] = request.filterViewName;
  }
  if (!Util.isUnset(request.filterViewType)) {
    query['FilterViewType'] = request.filterViewType;
  }
  if (!Util.isUnset(request.orderBy)) {
    query['OrderBy'] = request.orderBy;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.schemaName)) {
    query['SchemaName'] = request.schemaName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'GetViewObjects',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function getViewObjects(request: GetViewObjectsRequest): GetViewObjectsResponse {
  var runtime = new Util.RuntimeOptions{};
  return getViewObjectsWithOptions(request, runtime);
}

model KillSparkAppRequest {
  appId?: string(name='AppId', description='The ID of the Spark application.', example='s202204132018hzprec1ac****'),
  DBClusterId?: string(name='DBClusterId'),
}

model KillSparkAppResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark application.', example='s202204132018hzprec1ac****'),
    appName?: string(name='AppName', description='The name of the Spark application.', example='LAKEHOUSE-1-1'),
    DBClusterId?: string(name='DBClusterId', description='The database ID.', example='amv-clusterxxx'),
    message?: string(name='Message', description='The error message returned if the request failed.', example='[Advisor] Advisor feature is not available for instance: am-2ze292w4fyglwxxxx'),
    state?: string(name='State', description='The state of the Spark application. Valid values:

*   **waiting**
*   **running**
*   **finished**
*   **failed**
*   **closed**', example='running'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='69D0810B-F9F5-5F4C-A57F-DF36133B63C9'),
}

model KillSparkAppResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: KillSparkAppResponseBody(name='body'),
}

async function killSparkAppWithOptions(request: KillSparkAppRequest, runtime: Util.RuntimeOptions): KillSparkAppResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.appId)) {
    body['AppId'] = request.appId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'KillSparkApp',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function killSparkApp(request: KillSparkAppRequest): KillSparkAppResponse {
  var runtime = new Util.RuntimeOptions{};
  return killSparkAppWithOptions(request, runtime);
}

model KillSparkLogAnalyzeTaskRequest {
  taskId?: long(name='TaskId', description='The ID of the Spark log analysis task. You can call the ListSparkLogAnalyzeTasks operation to query the IDs and states of all analysis tasks in the current cluster.', example='15'),
}

model KillSparkLogAnalyzeTaskResponseBody = {
  data?: SparkAnalyzeLogTask(name='Data', description='The information about the Spark log analysis task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1DF5AF5B-C803-1861-A0FF-63666A557709'),
}

model KillSparkLogAnalyzeTaskResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: KillSparkLogAnalyzeTaskResponseBody(name='body'),
}

async function killSparkLogAnalyzeTaskWithOptions(request: KillSparkLogAnalyzeTaskRequest, runtime: Util.RuntimeOptions): KillSparkLogAnalyzeTaskResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.taskId)) {
    body['TaskId'] = request.taskId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'KillSparkLogAnalyzeTask',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function killSparkLogAnalyzeTask(request: KillSparkLogAnalyzeTaskRequest): KillSparkLogAnalyzeTaskResponse {
  var runtime = new Util.RuntimeOptions{};
  return killSparkLogAnalyzeTaskWithOptions(request, runtime);
}

model KillSparkSQLEngineRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-8vbn8pq537k8w****'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.', example='spark_test'),
}

model KillSparkSQLEngineResponseBody = {
  data?: boolean(name='Data', description='Indicates whether the request was successful.', example='true'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model KillSparkSQLEngineResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: KillSparkSQLEngineResponseBody(name='body'),
}

async function killSparkSQLEngineWithOptions(request: KillSparkSQLEngineRequest, runtime: Util.RuntimeOptions): KillSparkSQLEngineResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.resourceGroupName)) {
    body['ResourceGroupName'] = request.resourceGroupName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'KillSparkSQLEngine',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function killSparkSQLEngine(request: KillSparkSQLEngineRequest): KillSparkSQLEngineResponse {
  var runtime = new Util.RuntimeOptions{};
  return killSparkSQLEngineWithOptions(request, runtime);
}

model ListSparkAppAttemptsRequest {
  appId?: string(name='AppId', description='The ID of the Spark application.

> You can call the [ListSparkApps](~~455888~~) operation to query all application IDs.', example='s202204132018hzprec1ac****'),
  DBClusterId?: string(name='DBClusterId'),
  pageNumber?: long(name='PageNumber', description='The page number. The value must be an integer that is greater than 0. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **10** (default)
*   **50**
*   **100**', example='10'),
}

model ListSparkAppAttemptsResponseBody = {
  data?: {
    attemptInfoList?: [
      SparkAttemptInfo
    ](name='AttemptInfoList', description='The information about the attempts. Fields in the response parameter:

*   **AttemptId**: the attempt ID.

*   **State**: the state of the Spark application. Valid values:

    *   **SUBMITTED**
    *   **STARTING**
    *   **RUNNING**
    *   **FAILING**
    *   **FAILED**
    *   **KILLING**
    *   **KILLED**
    *   **SUCCEEDING**
    *   **COMPLETED**
    *   **FATAL**
    *   **UNKNOWN**

*   **Message**: the alert message that is returned. If no alert is generated, null is returned.

*   **Data**: the data of the Spark application template.

*   **EstimateExecutionCpuTimeInSeconds**: the amount of time it takes to consume CPU resources for running the Spark application. Unit: milliseconds.

*   **LogRootPath**: the storage path of log files.

*   **LastAttemptId**: the ID of the last attempt.

*   **WebUiAddress**: the web UI address.

*   **SubmittedTimeInMillis**: the time when the Spark application was submitted. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **StartedTimeInMillis**: the time when the Spark application was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **LastUpdatedTimeInMillis**: the time when the Spark application was last updated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **TerminatedTimeInMillis**: the time when the Spark application task was terminated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **DBClusterId**: the ID of the cluster on which the Spark application runs.

*   **ResourceGroupName**: the name of the job resource group.

*   **DurationInMillis**: the amount of time it takes to run the Spark application. Unit: milliseconds.'),
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='3'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ListSparkAppAttemptsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ListSparkAppAttemptsResponseBody(name='body'),
}

async function listSparkAppAttemptsWithOptions(request: ListSparkAppAttemptsRequest, runtime: Util.RuntimeOptions): ListSparkAppAttemptsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.appId)) {
    query['AppId'] = request.appId;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListSparkAppAttempts',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function listSparkAppAttempts(request: ListSparkAppAttemptsRequest): ListSparkAppAttemptsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listSparkAppAttemptsWithOptions(request, runtime);
}

model ListSparkAppsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  pageNumber?: long(name='PageNumber', description='The number of the page to return. The value must be an integer that is greater than 0. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries to return on each page. Default value: 10. Valid values:

- **10**
- **50**
- **100**', example='30'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the job resource group.', example='test_instance'),
}

model ListSparkAppsResponseBody = {
  data?: {
    appInfoList?: [
      SparkAppInfo
    ](name='AppInfoList', description='Details of the applications. Fields in the response parameter:

- **Data**: the data of the Spark application template.
- **EstimateExecutionCpuTimeInSeconds**: the amount of time it takes to consume CPU resources for running the Spark application. Unit: milliseconds.
- **LogRootPath**: the storage path of log files.
- **LastAttemptId**: the most recent attempt ID.
- **WebUiAddress**: the web UI URL.
- **SubmittedTimeInMillis**: the time when the Spark application was submitted. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
- **StartedTimeInMillis**: the time when the Spark application was created. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
- **LastUpdatedTimeInMillis**: the time when the Spark application was last updated. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
- **TerminatedTimeInMillis**: the time when the Spark application task was terminated. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
- **DBClusterId**: the ID of the cluster on which the Spark application runs.
- **ResourceGroupName**: the name of the job resource group.
- **DurationInMillis**: the amount of time it takes to run the Spark application. Unit: milliseconds.'),
    pageNumber?: long(name='PageNumber', description='The page number of the returned page.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries returned per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The data returned.'),
  pageNumber?: long(name='PageNumber', description='The page number of the returned page.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries returned per page.', example='10'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model ListSparkAppsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ListSparkAppsResponseBody(name='body'),
}

async function listSparkAppsWithOptions(request: ListSparkAppsRequest, runtime: Util.RuntimeOptions): ListSparkAppsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.pageNumber)) {
    query['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    query['PageSize'] = request.pageSize;
  }
  if (!Util.isUnset(request.resourceGroupName)) {
    query['ResourceGroupName'] = request.resourceGroupName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ListSparkApps',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function listSparkApps(request: ListSparkAppsRequest): ListSparkAppsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listSparkAppsWithOptions(request, runtime);
}

model ListSparkLogAnalyzeTasksRequest {
  DBClusterId?: string(name='DBClusterId', description='The cluster ID.', example='amv-9scxs****'),
  pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='20'),
}

model ListSparkLogAnalyzeTasksResponseBody = {
  data?: {
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='20'),
    taskList?: [
      SparkAnalyzeLogTask
    ](name='TaskList', description='The queried Spark log analysis tasks.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1DF5AF5B-C803-1861-A0FF-63666A557709'),
}

model ListSparkLogAnalyzeTasksResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ListSparkLogAnalyzeTasksResponseBody(name='body'),
}

async function listSparkLogAnalyzeTasksWithOptions(request: ListSparkLogAnalyzeTasksRequest, runtime: Util.RuntimeOptions): ListSparkLogAnalyzeTasksResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.pageNumber)) {
    body['PageNumber'] = request.pageNumber;
  }
  if (!Util.isUnset(request.pageSize)) {
    body['PageSize'] = request.pageSize;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'ListSparkLogAnalyzeTasks',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function listSparkLogAnalyzeTasks(request: ListSparkLogAnalyzeTasksRequest): ListSparkLogAnalyzeTasksResponse {
  var runtime = new Util.RuntimeOptions{};
  return listSparkLogAnalyzeTasksWithOptions(request, runtime);
}

model ListSparkTemplateFileIdsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
}

model ListSparkTemplateFileIdsResponseBody = {
  data?: [ long ](name='Data', description='The IDs of Spark template files.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ListSparkTemplateFileIdsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ListSparkTemplateFileIdsResponseBody(name='body'),
}

async function listSparkTemplateFileIdsWithOptions(request: ListSparkTemplateFileIdsRequest, runtime: Util.RuntimeOptions): ListSparkTemplateFileIdsResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'ListSparkTemplateFileIds',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function listSparkTemplateFileIds(request: ListSparkTemplateFileIdsRequest): ListSparkTemplateFileIdsResponse {
  var runtime = new Util.RuntimeOptions{};
  return listSparkTemplateFileIdsWithOptions(request, runtime);
}

model LoadSampleDataSetRequest {
  DBClusterId?: string(name='DBClusterId', example='amv-2ze0z517o1mgp66a'),
}

model LoadSampleDataSetResponseBody = {
  DBClusterId?: string(name='DBClusterId', example='amv-2ze0z517o1mgp66a'),
  requestId?: string(name='RequestId', example='FA31BE84-ABE8-554A-A769-5F860C34EE10'),
}

model LoadSampleDataSetResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: LoadSampleDataSetResponseBody(name='body'),
}

async function loadSampleDataSetWithOptions(request: LoadSampleDataSetRequest, runtime: Util.RuntimeOptions): LoadSampleDataSetResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'LoadSampleDataSet',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function loadSampleDataSet(request: LoadSampleDataSetRequest): LoadSampleDataSetResponse {
  var runtime = new Util.RuntimeOptions{};
  return loadSampleDataSetWithOptions(request, runtime);
}

model ModifyAccountDescriptionRequest {
  accountDescription?: string(name='AccountDescription', description='The description of the database account.

*   The description cannot start with `http://` or `https://`.
*   The description must be 2 to 256 characters in length.', example='AccDesc'),
  accountName?: string(name='AccountName', description='The name of the database account.

> You can call the [DescribeAccounts](~~612430~~) operation to query the information about database accounts in a cluster, including the database account name.', example='testacc'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
}

model ModifyAccountDescriptionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ModifyAccountDescriptionResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyAccountDescriptionResponseBody(name='body'),
}

async function modifyAccountDescriptionWithOptions(request: ModifyAccountDescriptionRequest, runtime: Util.RuntimeOptions): ModifyAccountDescriptionResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.accountDescription)) {
    query['AccountDescription'] = request.accountDescription;
  }
  if (!Util.isUnset(request.accountName)) {
    query['AccountName'] = request.accountName;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ModifyAccountDescription',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function modifyAccountDescription(request: ModifyAccountDescriptionRequest): ModifyAccountDescriptionResponse {
  var runtime = new Util.RuntimeOptions{};
  return modifyAccountDescriptionWithOptions(request, runtime);
}

model ModifyAccountPrivilegesRequest {
  accountName?: string(name='AccountName', description='The name of the database account.', example='account1'),
  accountPrivileges?: [ 
    {
      privilegeObject?: {
        column?: string(name='Column', description='The columns on which the database account has permissions. This parameter is required if the PrivilegeType parameter is set to Column.', example='column1'),
        database?: string(name='Database', description='The databases on which the database account has permissions. This parameter is required if the PrivilegeType parameter is set to Database, Table, or Column.', example='tsdb1'),
        table?: string(name='Table', description='The tables on which the database account has permissions. This parameter is required if the PrivilegeType parameter is set to Table or Column.', example='table1'),
      }(name='PrivilegeObject', description='The objects on which the permission takes effect, including databases, tables, and columns.'),
      privilegeType?: string(name='PrivilegeType', description='The permission level of the database account. You can call the `DescribeEnabledPrivileges` operation to query the permission level of the database account.', example='Global'),
      privileges?: [ string ](name='Privileges', description='The permissions that you want to modify. You can call the `DescribeEnabledPrivileges` operation to query the permissions of the database account.'),
    }
  ](name='AccountPrivileges', description='The permissions of the database account.'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1k5p066e1a****'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
}

model ModifyAccountPrivilegesShrinkRequest {
  accountName?: string(name='AccountName', description='The name of the database account.', example='account1'),
  accountPrivilegesShrink?: string(name='AccountPrivileges', description='The permissions of the database account.'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1k5p066e1a****'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
}

model ModifyAccountPrivilegesResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='9DD88DE7-824F-1082-AA57-575AFC6517A8'),
}

model ModifyAccountPrivilegesResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyAccountPrivilegesResponseBody(name='body'),
}

async function modifyAccountPrivilegesWithOptions(tmpReq: ModifyAccountPrivilegesRequest, runtime: Util.RuntimeOptions): ModifyAccountPrivilegesResponse {
  Util.validateModel(tmpReq);
  var request = new ModifyAccountPrivilegesShrinkRequest{};
  OpenApiUtil.convert(tmpReq, request);
  if (!Util.isUnset(tmpReq.accountPrivileges)) {
    request.accountPrivilegesShrink = OpenApiUtil.arrayToStringWithSpecifiedStyle(tmpReq.accountPrivileges, 'AccountPrivileges', 'json');
  }
  var query = {};
  if (!Util.isUnset(request.accountName)) {
    query['AccountName'] = request.accountName;
  }
  if (!Util.isUnset(request.accountPrivilegesShrink)) {
    query['AccountPrivileges'] = request.accountPrivilegesShrink;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ModifyAccountPrivileges',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function modifyAccountPrivileges(request: ModifyAccountPrivilegesRequest): ModifyAccountPrivilegesResponse {
  var runtime = new Util.RuntimeOptions{};
  return modifyAccountPrivilegesWithOptions(request, runtime);
}

model ModifyAuditLogConfigRequest {
  auditLogStatus?: string(name='AuditLogStatus', description='Modifies the status of SQL audit. Valid values:

*   **on**: enables SQL audit.
*   **off**: disables SQL audit.

>  After you disable the SQL audit feature, all SQL audit logs are deleted. You must query and export SQL audit logs before you disable SQL audit. For more information, see Query and export SQL audit logs. When you re-enable SQL audit, audit logs that are generated from the last time when SQL audit was enabled are available for queries.', example='on'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-t4nj8619bz2w3****'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  regionId?: string(name='RegionId', description='The region ID.

> You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model ModifyAuditLogConfigResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='CDC59E56-BD07-56CA-A05F-B7907DE5C862'),
  updateSucceed?: boolean(name='UpdateSucceed', description='Indicates whether the status of SQL audit is updated. Valid values:

*   **true**
*   **false**', example='true'),
}

model ModifyAuditLogConfigResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyAuditLogConfigResponseBody(name='body'),
}

async function modifyAuditLogConfigWithOptions(request: ModifyAuditLogConfigRequest, runtime: Util.RuntimeOptions): ModifyAuditLogConfigResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.auditLogStatus)) {
    query['AuditLogStatus'] = request.auditLogStatus;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ModifyAuditLogConfig',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function modifyAuditLogConfig(request: ModifyAuditLogConfigRequest): ModifyAuditLogConfigResponse {
  var runtime = new Util.RuntimeOptions{};
  return modifyAuditLogConfigWithOptions(request, runtime);
}

model ModifyBackupPolicyRequest {
  backupRetentionPeriod?: string(name='BackupRetentionPeriod', example='7'),
  DBClusterId?: string(name='DBClusterId', example='am-bp1xxxxxxxx47'),
  enableBackupLog?: string(name='EnableBackupLog', example='Enable'),
  logBackupRetentionPeriod?: int32(name='LogBackupRetentionPeriod', example='7'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  preferredBackupPeriod?: string(name='PreferredBackupPeriod', example='Monday,Wednesday,Friday,Sunday'),
  preferredBackupTime?: string(name='PreferredBackupTime', example='18:00Z-19:00Z'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  resourceOwnerId?: long(name='ResourceOwnerId'),
}

model ModifyBackupPolicyResponseBody = {
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ModifyBackupPolicyResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyBackupPolicyResponseBody(name='body'),
}

async function modifyBackupPolicyWithOptions(request: ModifyBackupPolicyRequest, runtime: Util.RuntimeOptions): ModifyBackupPolicyResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.backupRetentionPeriod)) {
    query['BackupRetentionPeriod'] = request.backupRetentionPeriod;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.enableBackupLog)) {
    query['EnableBackupLog'] = request.enableBackupLog;
  }
  if (!Util.isUnset(request.logBackupRetentionPeriod)) {
    query['LogBackupRetentionPeriod'] = request.logBackupRetentionPeriod;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.preferredBackupPeriod)) {
    query['PreferredBackupPeriod'] = request.preferredBackupPeriod;
  }
  if (!Util.isUnset(request.preferredBackupTime)) {
    query['PreferredBackupTime'] = request.preferredBackupTime;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.resourceOwnerId)) {
    query['ResourceOwnerId'] = request.resourceOwnerId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ModifyBackupPolicy',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function modifyBackupPolicy(request: ModifyBackupPolicyRequest): ModifyBackupPolicyResponse {
  var runtime = new Util.RuntimeOptions{};
  return modifyBackupPolicyWithOptions(request, runtime);
}

model ModifyClusterAccessWhiteListRequest {
  DBClusterIPArrayAttribute?: string(name='DBClusterIPArrayAttribute', description='The attribute of the IP address whitelist. By default, this parameter is empty.

> Whitelists with the hidden attribute are not displayed in the console. Those whitelists are used to access Data Transmission Service (DTS) and PolarDB.', example='hidden'),
  DBClusterIPArrayName?: string(name='DBClusterIPArrayName', description='The name of the IP address whitelist. If you do not specify this parameter, the Default whitelist is modified.

*   The whitelist name must be 2 to 32 characters in length. The name can contain lowercase letters, digits, and underscores (\\_). The name must start with a lowercase letter and end with a lowercase letter or a digit.
*   Each cluster supports up to 50 IP address whitelists.', example='test'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  modifyMode?: string(name='ModifyMode', description='The method used to modify the IP address whitelist. Valid values:

*   **Cover** (default)
*   **Append**
*   **Delete**', example='Cover'),
  securityIps?: string(name='SecurityIps', description='The IP addresses in an IP address whitelist of a cluster. Separate multiple IP addresses with commas (,). You can add a maximum of 500 different IP addresses to a whitelist. The entries in the IP address whitelist must be in one of the following formats:

*   IP addresses, such as 10.23.XX.XX.
*   CIDR blocks, such as 10.23.xx.xx/24. In this example, 24 indicates that the prefix of each IP address in the IP whitelist is 24 bits in length. You can replace 24 with a value within the range of 1 to 32.', example='10.23.xx.xx'),
}

model ModifyClusterAccessWhiteListResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  requestId?: string(name='RequestId', description='The request ID.', example='370D09FD-442A-5225-AAD3-7362CAE39177'),
  taskId?: int32(name='TaskId', description='The task ID.', example='1564657730'),
}

model ModifyClusterAccessWhiteListResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyClusterAccessWhiteListResponseBody(name='body'),
}

async function modifyClusterAccessWhiteListWithOptions(request: ModifyClusterAccessWhiteListRequest, runtime: Util.RuntimeOptions): ModifyClusterAccessWhiteListResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterIPArrayAttribute)) {
    query['DBClusterIPArrayAttribute'] = request.DBClusterIPArrayAttribute;
  }
  if (!Util.isUnset(request.DBClusterIPArrayName)) {
    query['DBClusterIPArrayName'] = request.DBClusterIPArrayName;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.modifyMode)) {
    query['ModifyMode'] = request.modifyMode;
  }
  if (!Util.isUnset(request.securityIps)) {
    query['SecurityIps'] = request.securityIps;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ModifyClusterAccessWhiteList',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function modifyClusterAccessWhiteList(request: ModifyClusterAccessWhiteListRequest): ModifyClusterAccessWhiteListResponse {
  var runtime = new Util.RuntimeOptions{};
  return modifyClusterAccessWhiteListWithOptions(request, runtime);
}

model ModifyClusterConnectionStringRequest {
  connectionStringPrefix?: string(name='ConnectionStringPrefix', description='The prefix of the public endpoint.

*   The prefix can contain lowercase letters, digits, and hyphens (-). It must start with a lowercase letter.
*   The prefix can be up to 30 characters in length.', example='test-123'),
  currentConnectionString?: string(name='CurrentConnectionString', description='The current public endpoint of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****.ads.aliyuncs.com'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  port?: int32(name='Port', description='The port number that is used to connect to the cluster. Set the value to **3306**.', example='3306'),
}

model ModifyClusterConnectionStringResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='370D09FD-442A-5225-AAD3-7362CAE39177'),
}

model ModifyClusterConnectionStringResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyClusterConnectionStringResponseBody(name='body'),
}

async function modifyClusterConnectionStringWithOptions(request: ModifyClusterConnectionStringRequest, runtime: Util.RuntimeOptions): ModifyClusterConnectionStringResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.connectionStringPrefix)) {
    query['ConnectionStringPrefix'] = request.connectionStringPrefix;
  }
  if (!Util.isUnset(request.currentConnectionString)) {
    query['CurrentConnectionString'] = request.currentConnectionString;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.port)) {
    query['Port'] = request.port;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ModifyClusterConnectionString',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function modifyClusterConnectionString(request: ModifyClusterConnectionStringRequest): ModifyClusterConnectionStringResponse {
  var runtime = new Util.RuntimeOptions{};
  return modifyClusterConnectionStringWithOptions(request, runtime);
}

model ModifyDBClusterRequest {
  computeResource?: string(name='ComputeResource', description='The amount of reserved computing resources. Unit: ACUs. Valid values: 0 to 4096. The value must be in increments of 16 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.

>  This parameter must be specified with a unit.', example='16ACU'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1r053byu48p****'),
  enableDefaultResourcePool?: boolean(name='EnableDefaultResourcePool', description='Specifies whether to allocate all reserved computing resources to the user_default resource group. Valid values:

*   true (default)
*   false', example='true'),
  ownerAccount?: string(name='OwnerAccount'),
  ownerId?: long(name='OwnerId'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount'),
  storageResource?: string(name='StorageResource', description='The amount of reserved storage resources. Unit: ACUs. Valid values: 0 to 2064. The value must be in increments of 24 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.

>  This parameter must be specified with a unit.', example='24ACU'),
}

model ModifyDBClusterResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  orderId?: string(name='OrderId', description='The order ID.', example='2035629****'),
  requestId?: string(name='RequestId', description='The request ID.', example='0D6BF3E2-41D8-57F6-9A62-A13A70377952'),
}

model ModifyDBClusterResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyDBClusterResponseBody(name='body'),
}

/**
  * ### [](#)
  * *   During a scaling event, you are not allowed to execute the `SUBMIT JOB` statement to submit asynchronous jobs. If your business requires asynchronous jobs, perform scaling during appropriate periods.
  * *   When cluster specifications are scaled up or down, data in the cluster is migrated for redistribution. The amount of time that is required for data migration is proportional to the volume of data. During a scaling event, the services provided by the cluster are not interrupted. During a scale-down event, data migration can take up to dozens of hours to complete. Proceed with caution especially when your cluster contains a large amount of data.
  * *   If the cluster has a built-in dataset loaded, make sure that the cluster has reserved storage resources of at least 24 AnalyticDB compute units (ACUs). Otherwise, the built-in dataset cannot be used.
  * *   When the scaling process is about to end, your service may encounter transient connections. We recommend that you scale your cluster during off-peak hours or make sure that your application is configured to automatically reconnect to your cluster.
  * *   You can change an AnalyticDB for MySQL cluster from Data Warehouse Edition (V3.0) to Data Lakehouse Edition (V3.0), but not the other way around. For more information, see Change a cluster from Data Warehouse Edition to Data Lakehouse Edition.
  *
  * @param request ModifyDBClusterRequest
  * @param runtime runtime options for this request RuntimeOptions
  * @return ModifyDBClusterResponse
 */
async function modifyDBClusterWithOptions(request: ModifyDBClusterRequest, runtime: Util.RuntimeOptions): ModifyDBClusterResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.computeResource)) {
    query['ComputeResource'] = request.computeResource;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.enableDefaultResourcePool)) {
    query['EnableDefaultResourcePool'] = request.enableDefaultResourcePool;
  }
  if (!Util.isUnset(request.ownerAccount)) {
    query['OwnerAccount'] = request.ownerAccount;
  }
  if (!Util.isUnset(request.ownerId)) {
    query['OwnerId'] = request.ownerId;
  }
  if (!Util.isUnset(request.regionId)) {
    query['RegionId'] = request.regionId;
  }
  if (!Util.isUnset(request.resourceOwnerAccount)) {
    query['ResourceOwnerAccount'] = request.resourceOwnerAccount;
  }
  if (!Util.isUnset(request.storageResource)) {
    query['StorageResource'] = request.storageResource;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ModifyDBCluster',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

/**
  * ### [](#)
  * *   During a scaling event, you are not allowed to execute the `SUBMIT JOB` statement to submit asynchronous jobs. If your business requires asynchronous jobs, perform scaling during appropriate periods.
  * *   When cluster specifications are scaled up or down, data in the cluster is migrated for redistribution. The amount of time that is required for data migration is proportional to the volume of data. During a scaling event, the services provided by the cluster are not interrupted. During a scale-down event, data migration can take up to dozens of hours to complete. Proceed with caution especially when your cluster contains a large amount of data.
  * *   If the cluster has a built-in dataset loaded, make sure that the cluster has reserved storage resources of at least 24 AnalyticDB compute units (ACUs). Otherwise, the built-in dataset cannot be used.
  * *   When the scaling process is about to end, your service may encounter transient connections. We recommend that you scale your cluster during off-peak hours or make sure that your application is configured to automatically reconnect to your cluster.
  * *   You can change an AnalyticDB for MySQL cluster from Data Warehouse Edition (V3.0) to Data Lakehouse Edition (V3.0), but not the other way around. For more information, see Change a cluster from Data Warehouse Edition to Data Lakehouse Edition.
  *
  * @param request ModifyDBClusterRequest
  * @return ModifyDBClusterResponse
 */
async function modifyDBCluster(request: ModifyDBClusterRequest): ModifyDBClusterResponse {
  var runtime = new Util.RuntimeOptions{};
  return modifyDBClusterWithOptions(request, runtime);
}

model ModifyDBClusterDescriptionRequest {
  DBClusterDescription?: string(name='DBClusterDescription', description='The description of the cluster.

*   The description cannot start with `http://` or `https`.
*   The description must be 2 to 256 characters in length.', example='adb_test'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
}

model ModifyDBClusterDescriptionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='17F57FEE-EA4F-4337-8D2E-9C23CAA63D74'),
}

model ModifyDBClusterDescriptionResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyDBClusterDescriptionResponseBody(name='body'),
}

async function modifyDBClusterDescriptionWithOptions(request: ModifyDBClusterDescriptionRequest, runtime: Util.RuntimeOptions): ModifyDBClusterDescriptionResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterDescription)) {
    query['DBClusterDescription'] = request.DBClusterDescription;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ModifyDBClusterDescription',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function modifyDBClusterDescription(request: ModifyDBClusterDescriptionRequest): ModifyDBClusterDescriptionResponse {
  var runtime = new Util.RuntimeOptions{};
  return modifyDBClusterDescriptionWithOptions(request, runtime);
}

model ModifyDBClusterMaintainTimeRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  maintainTime?: string(name='MaintainTime', description='The maintenance window of the cluster. It must be in the hh:mmZ-hh:mmZ format.

> The interval must be 1 hour on the hour.', example='22:00Z-23:00Z'),
}

model ModifyDBClusterMaintainTimeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='65BDA532-28AF-4122-AA39-B382721EEE64'),
}

model ModifyDBClusterMaintainTimeResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyDBClusterMaintainTimeResponseBody(name='body'),
}

async function modifyDBClusterMaintainTimeWithOptions(request: ModifyDBClusterMaintainTimeRequest, runtime: Util.RuntimeOptions): ModifyDBClusterMaintainTimeResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.maintainTime)) {
    query['MaintainTime'] = request.maintainTime;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ModifyDBClusterMaintainTime',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function modifyDBClusterMaintainTime(request: ModifyDBClusterMaintainTimeRequest): ModifyDBClusterMaintainTimeResponse {
  var runtime = new Util.RuntimeOptions{};
  return modifyDBClusterMaintainTimeWithOptions(request, runtime);
}

model ModifyDBResourceGroupRequest {
  clusterMode?: string(name='ClusterMode'),
  clusterSizeResource?: string(name='ClusterSizeResource'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  groupName?: string(name='GroupName', description='The name of the resource group.

> You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group in a cluster.', example='test'),
  groupType?: string(name='GroupType', description='The type of the resource group. Valid values:

*   **Interactive**
*   **Job**

> For information about resource groups of Data Lakehouse Edition, see [Resource groups](~~428610~~).', example='Interactive'),
  maxClusterCount?: int32(name='MaxClusterCount'),
  maxComputeResource?: string(name='MaxComputeResource', description='The maximum amount of reserved computing resources. Unit: ACU.

*   If GroupType is set to Interactive, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 16 ACUs.
*   If GroupType is set to Job, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 8 ACUs.', example='48ACU'),
  minClusterCount?: int32(name='MinClusterCount'),
  minComputeResource?: string(name='MinComputeResource', description='The minimum amount of reserved computing resources. Unit: AnalyticDB compute unit (ACU).

*   If GroupType is set to Interactive, set the value to 16ACU.
*   If GroupType is set to Job, set the value to 0ACU.', example='0ACU'),
}

model ModifyDBResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='805F14E1-0186-520E-A6D5-30188D94E8DA'),
}

model ModifyDBResourceGroupResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyDBResourceGroupResponseBody(name='body'),
}

async function modifyDBResourceGroupWithOptions(request: ModifyDBResourceGroupRequest, runtime: Util.RuntimeOptions): ModifyDBResourceGroupResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.clusterMode)) {
    query['ClusterMode'] = request.clusterMode;
  }
  if (!Util.isUnset(request.clusterSizeResource)) {
    query['ClusterSizeResource'] = request.clusterSizeResource;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  if (!Util.isUnset(request.groupType)) {
    query['GroupType'] = request.groupType;
  }
  if (!Util.isUnset(request.maxClusterCount)) {
    query['MaxClusterCount'] = request.maxClusterCount;
  }
  if (!Util.isUnset(request.maxComputeResource)) {
    query['MaxComputeResource'] = request.maxComputeResource;
  }
  if (!Util.isUnset(request.minClusterCount)) {
    query['MinClusterCount'] = request.minClusterCount;
  }
  if (!Util.isUnset(request.minComputeResource)) {
    query['MinComputeResource'] = request.minComputeResource;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ModifyDBResourceGroup',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function modifyDBResourceGroup(request: ModifyDBResourceGroupRequest): ModifyDBResourceGroupResponse {
  var runtime = new Util.RuntimeOptions{};
  return modifyDBResourceGroupWithOptions(request, runtime);
}

model ModifyElasticPlanRequest {
  cronExpression?: string(name='CronExpression', description='A CORN expression that specifies the scaling cycle and time for the scaling plan.', example='0 20 14 * * ?'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the ID of an AnalyticDB for MySQL Data Warehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****'),
  elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the name of a scaling plan of a specific cluster.', example='test'),
  endTime?: string(name='EndTime', description='The time to end the scaling plan.

>  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2025-01-01T12:01:00Z'),
  startTime?: string(name='StartTime', description='The time to start the scaling plan.

>  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-01-01T12:01:00Z'),
  targetSize?: string(name='TargetSize', description='The amount of elastic resources after scaling.

> *   This parameter is not required only if the resource group uses **EIUs** and **Proportional Default Scaling for EIUs** is enabled.
> *   You can call the [DescribeElasticPlanSpecifications](~~601278~~) operation to query the specifications that are supported for scaling plans.', example='32ACU'),
}

model ModifyElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model ModifyElasticPlanResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyElasticPlanResponseBody(name='body'),
}

async function modifyElasticPlanWithOptions(request: ModifyElasticPlanRequest, runtime: Util.RuntimeOptions): ModifyElasticPlanResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.cronExpression)) {
    query['CronExpression'] = request.cronExpression;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.elasticPlanName)) {
    query['ElasticPlanName'] = request.elasticPlanName;
  }
  if (!Util.isUnset(request.endTime)) {
    query['EndTime'] = request.endTime;
  }
  if (!Util.isUnset(request.startTime)) {
    query['StartTime'] = request.startTime;
  }
  if (!Util.isUnset(request.targetSize)) {
    query['TargetSize'] = request.targetSize;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ModifyElasticPlan',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function modifyElasticPlan(request: ModifyElasticPlanRequest): ModifyElasticPlanResponse {
  var runtime = new Util.RuntimeOptions{};
  return modifyElasticPlanWithOptions(request, runtime);
}

model PreloadSparkAppMetricsRequest {
  appId?: string(name='AppId', description='The ID of the Spark application.', example='s202204221525hzca7d8140000003'),
  DBClusterId?: string(name='DBClusterId'),
}

model PreloadSparkAppMetricsResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark application.', example='s202212181815shaccb8be0000253'),
    attemptId?: string(name='AttemptId', description='The retry ID of the Spark application.', example='s202301061000hz57d797b0000201-0001'),
    eventLogPath?: string(name='EventLogPath', description='The path of the event log.', example='oss://path/to/eventLog'),
    finished?: boolean(name='Finished', description='Indicates whether parsing is complete. Valid values:

*   true
*   false', example='True'),
    scanMetrics?: {
      outputRowsCount?: long(name='OutputRowsCount', description='The number of scanned rows.', example='1000'),
      totalReadFileSizeInByte?: long(name='TotalReadFileSizeInByte', description='The number of scanned bytes.', example='10000'),
    }(name='ScanMetrics', description='The metrics.'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='84489769-3065-5A28-A4CB-977CD426F1C3'),
}

model PreloadSparkAppMetricsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: PreloadSparkAppMetricsResponseBody(name='body'),
}

async function preloadSparkAppMetricsWithOptions(request: PreloadSparkAppMetricsRequest, runtime: Util.RuntimeOptions): PreloadSparkAppMetricsResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var body : map[string]any = {};
  if (!Util.isUnset(request.appId)) {
    body['AppId'] = request.appId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'PreloadSparkAppMetrics',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function preloadSparkAppMetrics(request: PreloadSparkAppMetricsRequest): PreloadSparkAppMetricsResponse {
  var runtime = new Util.RuntimeOptions{};
  return preloadSparkAppMetricsWithOptions(request, runtime);
}

model ReleaseClusterPublicConnectionRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
}

model ReleaseClusterPublicConnectionResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='A94B6C02-7BD4-5D67-9776-3AC8317E8DD5'),
}

model ReleaseClusterPublicConnectionResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ReleaseClusterPublicConnectionResponseBody(name='body'),
}

async function releaseClusterPublicConnectionWithOptions(request: ReleaseClusterPublicConnectionRequest, runtime: Util.RuntimeOptions): ReleaseClusterPublicConnectionResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ReleaseClusterPublicConnection',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function releaseClusterPublicConnection(request: ReleaseClusterPublicConnectionRequest): ReleaseClusterPublicConnectionResponse {
  var runtime = new Util.RuntimeOptions{};
  return releaseClusterPublicConnectionWithOptions(request, runtime);
}

model RenameSparkTemplateFileRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-d*****'),
  id?: long(name='Id', description='The template file ID.', example='1'),
  name?: string(name='Name', description='The name of the template file that you want to rename.', example='new_template_name'),
}

model RenameSparkTemplateFileResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the request was successful. Valid values:

*   True
*   False', example='True'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='16D332C4-ACEB-526A-9B53-2B708FED594A'),
}

model RenameSparkTemplateFileResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: RenameSparkTemplateFileResponseBody(name='body'),
}

async function renameSparkTemplateFileWithOptions(request: RenameSparkTemplateFileRequest, runtime: Util.RuntimeOptions): RenameSparkTemplateFileResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.id)) {
    query['Id'] = request.id;
  }
  if (!Util.isUnset(request.name)) {
    query['Name'] = request.name;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'RenameSparkTemplateFile',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function renameSparkTemplateFile(request: RenameSparkTemplateFileRequest): RenameSparkTemplateFileResponse {
  var runtime = new Util.RuntimeOptions{};
  return renameSparkTemplateFileWithOptions(request, runtime);
}

model ResetAccountPasswordRequest {
  accountDescription?: string(name='AccountDescription', description='The description of the database account.

*   The description cannot start with `http://` or `https://`.
*   The description must be 2 to 256 characters in length.', example='AccDesc'),
  accountName?: string(name='AccountName', description='The name of the database account.

> You can call the [DescribeAccounts](~~612430~~) operation to query the information about database accounts in a cluster, including the database account name.', example='test_accout'),
  accountPassword?: string(name='AccountPassword', description='The password of the database account.

*   The password must contain at least three of the following character types: uppercase letters, lowercase letters, digits, and special characters.
*   Special characters include `! @ # $ % ^ & * ( ) _ + - =`
*   The password must be 8 to 32 characters in length.', example='Test_accout1'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
}

model ResetAccountPasswordResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ResetAccountPasswordResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ResetAccountPasswordResponseBody(name='body'),
}

async function resetAccountPasswordWithOptions(request: ResetAccountPasswordRequest, runtime: Util.RuntimeOptions): ResetAccountPasswordResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.accountDescription)) {
    query['AccountDescription'] = request.accountDescription;
  }
  if (!Util.isUnset(request.accountName)) {
    query['AccountName'] = request.accountName;
  }
  if (!Util.isUnset(request.accountPassword)) {
    query['AccountPassword'] = request.accountPassword;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'ResetAccountPassword',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function resetAccountPassword(request: ResetAccountPasswordRequest): ResetAccountPasswordResponse {
  var runtime = new Util.RuntimeOptions{};
  return resetAccountPasswordWithOptions(request, runtime);
}

model SetSparkAppLogRootPathRequest {
  DBClusterId?: string(name='DBClusterId', description='The database ID.', example='am-dbclusterid'),
  ossLogPath?: string(name='OssLogPath', description='The Object Storage Service (OSS) log path.', example='oss://path/to/log'),
  useDefaultOss?: boolean(name='UseDefaultOss', description='Specifies whether to use the default OSS log path.', example='true'),
}

model SetSparkAppLogRootPathResponseBody = {
  data?: {
    defaultLogPath?: string(name='DefaultLogPath', description='The recommended default OSS log path.', example='oss://path/to/log'),
    isLogPathExists?: boolean(name='IsLogPathExists', description='Indicates whether an OSS log path exists.', example='true'),
    modifiedTimestamp?: string(name='ModifiedTimestamp', description='The time when the modification was last modified.', example='1675236908'),
    modifiedUid?: string(name='ModifiedUid', description='The modifier ID.', example='1111111'),
    recordedLogPath?: string(name='RecordedLogPath', description='The OSS log path.', example='oss://path/to/log'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model SetSparkAppLogRootPathResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: SetSparkAppLogRootPathResponseBody(name='body'),
}

async function setSparkAppLogRootPathWithOptions(request: SetSparkAppLogRootPathRequest, runtime: Util.RuntimeOptions): SetSparkAppLogRootPathResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.ossLogPath)) {
    body['OssLogPath'] = request.ossLogPath;
  }
  if (!Util.isUnset(request.useDefaultOss)) {
    body['UseDefaultOss'] = request.useDefaultOss;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'SetSparkAppLogRootPath',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function setSparkAppLogRootPath(request: SetSparkAppLogRootPathRequest): SetSparkAppLogRootPathResponse {
  var runtime = new Util.RuntimeOptions{};
  return setSparkAppLogRootPathWithOptions(request, runtime);
}

model StartSparkSQLEngineRequest {
  config?: string(name='Config', description='The configuration that is required to start the Spark SQL engine. Specify this value in the JSON format. For more information, see [Conf configuration parameters](~~471203~~).', example='{ "spark.shuffle.timeout": ":0s" }'),
  DBClusterId?: string(name='DBClusterId', description='The cluster ID.', example='amv-abcd****'),
  jars?: string(name='Jars', description='The Object Storage Service (OSS) paths of third-party JAR packages that are required to start the Spark SQL engine. Separate multiple OSS paths with commas (,).', example='oss://testBuckname/test.jar,oss://testBuckname/test2.jar'),
  maxExecutor?: long(name='MaxExecutor', description='The maximum number of executors that are required to execute SQL statements. Valid values: 1 to 2000. If this value exceeds the total number of executes that are supported by the resource group, the Spark SQL engine fails to be started.', example='10'),
  minExecutor?: long(name='MinExecutor', description='The minimum number of executors that are required to execute SQL statements. Valid values: 0 to 2000. A value of 0 indicates that no executors are permanent if no SQL statements are executed. If this value exceeds the total number of executes that are supported by the resource group, the Spark SQL engine fails to be started. The value must be less than the value of MaxExecutor.', example='1'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.', example='spark-rg-name'),
  slotNum?: long(name='SlotNum', description='The maximum number of slots that are required to maintain Spark sessions for executing SQL statements. Valid values: 1 to 500.', example='100'),
}

model StartSparkSQLEngineResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark job.', example='s202301xxxx'),
    appName?: string(name='AppName', description='The name of the Spark application.', example='SQLEngine1'),
    state?: string(name='State', description='The state of the Spark SQL engine. Valid values:

*   SUBMITTED
*   STARTING
*   RUNNING
*   FAILED', example='SUBMITTED'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model StartSparkSQLEngineResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: StartSparkSQLEngineResponseBody(name='body'),
}

async function startSparkSQLEngineWithOptions(request: StartSparkSQLEngineRequest, runtime: Util.RuntimeOptions): StartSparkSQLEngineResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.config)) {
    body['Config'] = request.config;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.jars)) {
    body['Jars'] = request.jars;
  }
  if (!Util.isUnset(request.maxExecutor)) {
    body['MaxExecutor'] = request.maxExecutor;
  }
  if (!Util.isUnset(request.minExecutor)) {
    body['MinExecutor'] = request.minExecutor;
  }
  if (!Util.isUnset(request.resourceGroupName)) {
    body['ResourceGroupName'] = request.resourceGroupName;
  }
  if (!Util.isUnset(request.slotNum)) {
    body['SlotNum'] = request.slotNum;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'StartSparkSQLEngine',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function startSparkSQLEngine(request: StartSparkSQLEngineRequest): StartSparkSQLEngineResponse {
  var runtime = new Util.RuntimeOptions{};
  return startSparkSQLEngineWithOptions(request, runtime);
}

model SubmitSparkAppRequest {
  agentSource?: string(name='AgentSource', description='The type of the client. The value can be up to 64 characters in length.', example='CONSOLE'),
  agentVersion?: string(name='AgentVersion', description='The version of the client. The value can be up to 64 characters in length.', example='1.091'),
  appName?: string(name='AppName', description='The name of the application. The value can be up to 64 characters in length.', example='TestApp'),
  appType?: string(name='AppType', description='The type of the application. Valid values:

*   **SQL**
*   **STREAMING**
*   **BATCH** (default)', example='SQL'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query cluster IDs.', example='amv-bp11q28kvl688****'),
  data?: string(name='Data', description='The data of the application template.

> For information about the application template configuration, see [Spark application configuration guide](~~452402~~).', example='conf spark.driver.resourceSpec=small; conf spark.executor.instances=1; conf spark.executor.resourceSpec=small; conf spark.app.name=TestApp;'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the job resource group.

> You can call the [DescribeDBResourceGroup](~~612413~~) operation to query the resource group IDs of an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='adb'),
  templateFileId?: long(name='TemplateFileId', description='The ID of the application template.

> You can call the [GetSparkTemplateFullTree](~~456205~~) operation to query the application template ID.', example='15'),
}

model SubmitSparkAppResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The application ID.', example='s202204132018hzprec1ac61a000****'),
    appName?: string(name='AppName', description='The name of the application.', example='TestApp'),
    message?: string(name='Message', description='The alert message returned for the operation, such as task execution failure or insufficient resources. If no alert occurs, null is returned.', example='Insufficient resources.'),
    state?: string(name='State', description='The execution state of the application. Valid values:

*   **SUBMITTED**
*   **STARTING**
*   **RUNNING**
*   **FAILING**
*   **FAILED**
*   **KILLING**
*   **KILLED**
*   **SUCCEEDING**
*   **COMPLETED**
*   **FATAL**
*   **UNKNOWN**', example='SUBMITTED'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model SubmitSparkAppResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: SubmitSparkAppResponseBody(name='body'),
}

async function submitSparkAppWithOptions(request: SubmitSparkAppRequest, runtime: Util.RuntimeOptions): SubmitSparkAppResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.agentSource)) {
    body['AgentSource'] = request.agentSource;
  }
  if (!Util.isUnset(request.agentVersion)) {
    body['AgentVersion'] = request.agentVersion;
  }
  if (!Util.isUnset(request.appName)) {
    body['AppName'] = request.appName;
  }
  if (!Util.isUnset(request.appType)) {
    body['AppType'] = request.appType;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.data)) {
    body['Data'] = request.data;
  }
  if (!Util.isUnset(request.resourceGroupName)) {
    body['ResourceGroupName'] = request.resourceGroupName;
  }
  if (!Util.isUnset(request.templateFileId)) {
    body['TemplateFileId'] = request.templateFileId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'SubmitSparkApp',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function submitSparkApp(request: SubmitSparkAppRequest): SubmitSparkAppResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitSparkAppWithOptions(request, runtime);
}

model SubmitSparkLogAnalyzeTaskRequest {
  appId?: string(name='AppId', description='The ID of the Spark application.', example='s202301121553hzd9c6f7xxxx'),
}

model SubmitSparkLogAnalyzeTaskResponseBody = {
  data?: SparkAnalyzeLogTask(name='Data', description='The information about the Spark log analysis task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1DF5AF5B-C803-1861-A0FF-63666A557709'),
}

model SubmitSparkLogAnalyzeTaskResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: SubmitSparkLogAnalyzeTaskResponseBody(name='body'),
}

async function submitSparkLogAnalyzeTaskWithOptions(request: SubmitSparkLogAnalyzeTaskRequest, runtime: Util.RuntimeOptions): SubmitSparkLogAnalyzeTaskResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.appId)) {
    body['AppId'] = request.appId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'SubmitSparkLogAnalyzeTask',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function submitSparkLogAnalyzeTask(request: SubmitSparkLogAnalyzeTaskRequest): SubmitSparkLogAnalyzeTaskResponse {
  var runtime = new Util.RuntimeOptions{};
  return submitSparkLogAnalyzeTaskWithOptions(request, runtime);
}

model UnbindAccountRequest {
  accountName?: string(name='AccountName', description='The name of the database account.

> You can call the [DescribeAccounts](~~612430~~) operation to view the information about a database account in a cluster, including the name of the database account.', example='test_accout'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz99d9nh5****'),
}

model UnbindAccountResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='93E85E5C-C805-5837-8713-05B69A504EE5'),
}

model UnbindAccountResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: UnbindAccountResponseBody(name='body'),
}

async function unbindAccountWithOptions(request: UnbindAccountRequest, runtime: Util.RuntimeOptions): UnbindAccountResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.accountName)) {
    query['AccountName'] = request.accountName;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UnbindAccount',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function unbindAccount(request: UnbindAccountRequest): UnbindAccountResponse {
  var runtime = new Util.RuntimeOptions{};
  return unbindAccountWithOptions(request, runtime);
}

model UnbindDBResourceGroupWithUserRequest {
  DBClusterId?: string(name='DBClusterId', example='am-bp1ub9grke1****'),
  groupName?: string(name='GroupName', example='test'),
  groupUser?: string(name='GroupUser', example='user1'),
}

model UnbindDBResourceGroupWithUserResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model UnbindDBResourceGroupWithUserResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: UnbindDBResourceGroupWithUserResponseBody(name='body'),
}

async function unbindDBResourceGroupWithUserWithOptions(request: UnbindDBResourceGroupWithUserRequest, runtime: Util.RuntimeOptions): UnbindDBResourceGroupWithUserResponse {
  Util.validateModel(request);
  var query = {};
  if (!Util.isUnset(request.DBClusterId)) {
    query['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.groupName)) {
    query['GroupName'] = request.groupName;
  }
  if (!Util.isUnset(request.groupUser)) {
    query['GroupUser'] = request.groupUser;
  }
  var req = new OpenApi.OpenApiRequest{ 
    query = OpenApiUtil.query(query),
  };
  var params = new OpenApi.Params{
    action = 'UnbindDBResourceGroupWithUser',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function unbindDBResourceGroupWithUser(request: UnbindDBResourceGroupWithUserRequest): UnbindDBResourceGroupWithUserResponse {
  var runtime = new Util.RuntimeOptions{};
  return unbindDBResourceGroupWithUserWithOptions(request, runtime);
}

model UpdateSparkTemplateFileRequest {
  content?: string(name='Content', description='The template data to be updated.

>  If you do not specify this parameter, the application template is not updated. For more information about how to configure an application template, see [Configure a Spark application](~~452402~~).', example='set spark.driver.resourceSpec=medium;set spark.executor.instances=2;set spark.executor.resourceSpec=medium;set spark.app.name=Spark SQL Test;'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-pz5vp4585l466****'),
  id?: long(name='Id', description='The ID of the application template.

>  You can call the [GetSparkTemplateFullTree](~~456205~~) operation to query the template ID.', example='718056'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the job resource group.', example='adb'),
}

model UpdateSparkTemplateFileResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the application template is updated.

*   **true**: The application template is updated.
*   **false**: The application template fails to be updated.', example='True'),
  }(name='Data', description='The update result.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='C3A9594F-1D40-4472-A96C-8FB8AA20D38C'),
}

model UpdateSparkTemplateFileResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: UpdateSparkTemplateFileResponseBody(name='body'),
}

async function updateSparkTemplateFileWithOptions(request: UpdateSparkTemplateFileRequest, runtime: Util.RuntimeOptions): UpdateSparkTemplateFileResponse {
  Util.validateModel(request);
  var body : map[string]any = {};
  if (!Util.isUnset(request.content)) {
    body['Content'] = request.content;
  }
  if (!Util.isUnset(request.DBClusterId)) {
    body['DBClusterId'] = request.DBClusterId;
  }
  if (!Util.isUnset(request.id)) {
    body['Id'] = request.id;
  }
  if (!Util.isUnset(request.resourceGroupName)) {
    body['ResourceGroupName'] = request.resourceGroupName;
  }
  var req = new OpenApi.OpenApiRequest{ 
    body = OpenApiUtil.parseToMap(body),
  };
  var params = new OpenApi.Params{
    action = 'UpdateSparkTemplateFile',
    version = '2021-12-01',
    protocol = 'HTTPS',
    pathname = '/',
    method = 'POST',
    authType = 'AK',
    style = 'RPC',
    reqBodyType = 'formData',
    bodyType = 'json',
  };
  return callApi(params, req, runtime);
}

async function updateSparkTemplateFile(request: UpdateSparkTemplateFileRequest): UpdateSparkTemplateFileResponse {
  var runtime = new Util.RuntimeOptions{};
  return updateSparkTemplateFileWithOptions(request, runtime);
}

