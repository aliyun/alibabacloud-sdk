/**
 *
 */
import BaseClientBuilder;
import TeaAsyncHandler;
import TeaRequest;
import AsyncRequestBody;
import RequestBody;
import AsyncResponseHandler;
import ClientConfiguration;
import ClientExecutionParams;
extends BaseClientBuilder;
type @product = string
type @version = string
type @endpointRule = string
type @endpointMap = map[string]string
type @REQUEST = TeaRequest
type @handler = TeaAsyncHandler

init(configuration: ClientConfiguration){
  @handler = new TeaAsyncHandler(configuration);
  @product = 'adb';
  @version = '2021-12-01';
  @endpointRule = 'regional';
  @endpointMap = {
    cn-qingdao = 'adb.aliyuncs.com',
    cn-beijing = 'adb.aliyuncs.com',
    cn-hangzhou = 'adb.aliyuncs.com',
    cn-shanghai = 'adb.aliyuncs.com',
    cn-shenzhen = 'adb.aliyuncs.com',
    cn-hongkong = 'adb.aliyuncs.com',
    ap-southeast-1 = 'adb.aliyuncs.com',
    us-west-1 = 'adb.aliyuncs.com',
    us-east-1 = 'adb.aliyuncs.com',
    cn-hangzhou-finance = 'adb.aliyuncs.com',
    cn-north-2-gov-1 = 'adb.aliyuncs.com',
    ap-northeast-2-pop = 'adb.ap-northeast-1.aliyuncs.com',
    cn-beijing-finance-1 = 'adb.aliyuncs.com',
    cn-beijing-finance-pop = 'adb.aliyuncs.com',
    cn-beijing-gov-1 = 'adb.aliyuncs.com',
    cn-beijing-nu16-b01 = 'adb.aliyuncs.com',
    cn-edge-1 = 'adb.aliyuncs.com',
    cn-fujian = 'adb.aliyuncs.com',
    cn-haidian-cm12-c01 = 'adb.aliyuncs.com',
    cn-hangzhou-bj-b01 = 'adb.aliyuncs.com',
    cn-hangzhou-internal-prod-1 = 'adb.aliyuncs.com',
    cn-hangzhou-internal-test-1 = 'adb.aliyuncs.com',
    cn-hangzhou-internal-test-2 = 'adb.aliyuncs.com',
    cn-hangzhou-internal-test-3 = 'adb.aliyuncs.com',
    cn-hangzhou-test-306 = 'adb.aliyuncs.com',
    cn-hongkong-finance-pop = 'adb.aliyuncs.com',
    cn-qingdao-nebula = 'adb.aliyuncs.com',
    cn-shanghai-et15-b01 = 'adb.aliyuncs.com',
    cn-shanghai-et2-b01 = 'adb.aliyuncs.com',
    cn-shanghai-finance-1 = 'adb.aliyuncs.com',
    cn-shanghai-inner = 'adb.aliyuncs.com',
    cn-shanghai-internal-test-1 = 'adb.aliyuncs.com',
    cn-shenzhen-finance-1 = 'adb.aliyuncs.com',
    cn-shenzhen-inner = 'adb.aliyuncs.com',
    cn-shenzhen-st4-d01 = 'adb.aliyuncs.com',
    cn-shenzhen-su18-b01 = 'adb.aliyuncs.com',
    cn-wuhan = 'adb.aliyuncs.com',
    cn-yushanfang = 'adb.aliyuncs.com',
    cn-zhangbei-na61-b01 = 'adb.aliyuncs.com',
    cn-zhangjiakou-na62-a01 = 'adb.aliyuncs.com',
    cn-zhengzhou-nebula-1 = 'adb.aliyuncs.com',
    eu-west-1-oxs = 'adb.ap-northeast-1.aliyuncs.com',
    me-east-1 = 'adb.ap-northeast-1.aliyuncs.com',
    rus-west-1-pop = 'adb.ap-northeast-1.aliyuncs.com',
  };
}

function close(): void {
  @handler.close();
}

model Adb4MysqlSparkDiagnosisInfo {
  diagnosisCode?: string(name='DiagnosisCode'),
  diagnosisCodeLabel?: string(name='DiagnosisCodeLabel'),
  diagnosisMsg?: string(name='DiagnosisMsg'),
  diagnosisType?: string(name='DiagnosisType', example='APPLICATION'),
}

model ColDetailModel {
  columnName?: string(name='ColumnName'),
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  distributeKey?: boolean(name='DistributeKey'),
  nullable?: boolean(name='Nullable'),
  partitionKey?: boolean(name='PartitionKey'),
  primaryKey?: boolean(name='PrimaryKey'),
  schemaName?: string(name='SchemaName'),
  tableName?: string(name='TableName'),
  type?: string(name='Type'),
  updateTime?: string(name='UpdateTime'),
}

model CstoreIndexModel {
  columnOrds?: [ string ](name='ColumnOrds'),
  createTime?: string(name='CreateTime'),
  databaseName?: string(name='DatabaseName'),
  indexColumns?: [
    FieldSchemaModel
  ](name='IndexColumns'),
  indexName?: string(name='IndexName'),
  indexType?: string(name='IndexType'),
  options?: map[string]string(name='Options'),
  physicalTableName?: string(name='PhysicalTableName'),
  updateTime?: string(name='UpdateTime'),
}

model DatabaseSummaryModel {
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  owner?: string(name='Owner'),
  schemaName?: string(name='SchemaName'),
  updateTime?: string(name='UpdateTime'),
}

model Detail {
  appType?: string(name='AppType', example='BATCH'),
  DBClusterId?: string(name='DBClusterId', example='amv-bp11q28kv****'),
  data?: string(name='Data', example='{     "name": "SparkPi",     "file": "local:///tmp/spark-examples.jar",     "className": "org.apache.spark.examples.SparkPi",     "args": [         "1000000"     ],     "conf": {         "spark.driver.resourceSpec": "small",         "spark.executor.instances": 1,         "spark.executor.resourceSpec": "small"     } }'),
  durationInMillis?: long(name='DurationInMillis', example='100'),
  estimateExecutionCpuTimeInSeconds?: long(name='EstimateExecutionCpuTimeInSeconds', example='100'),
  lastAttemptId?: string(name='LastAttemptId', example='s202204291426hzpre60cfa*****-0003'),
  lastUpdatedTimeInMillis?: long(name='LastUpdatedTimeInMillis', example='1651213645200'),
  logRootPath?: string(name='LogRootPath', example='oss://<bucket-name>/logs/driver'),
  resourceGroupName?: string(name='ResourceGroupName', example='spark-rg'),
  startedTimeInMillis?: long(name='StartedTimeInMillis', example='1651213645010'),
  submittedTimeInMillis?: long(name='SubmittedTimeInMillis', example='1651213645000'),
  terminatedTimeInMillis?: long(name='TerminatedTimeInMillis', example='1651213645300'),
  webUiAddress?: string(name='WebUiAddress', example='https://sparkui.aliyuncs.com/token=xxx'),
}

model FieldSchemaModel {
  autoIncrement?: boolean(name='AutoIncrement'),
  columnRawName?: string(name='ColumnRawName'),
  comment?: string(name='Comment'),
  compressFloatUseShort?: boolean(name='CompressFloatUseShort'),
  compression?: string(name='Compression'),
  createTime?: string(name='CreateTime'),
  dataType?: string(name='DataType'),
  databaseName?: string(name='DatabaseName'),
  defaultValue?: string(name='DefaultValue'),
  delimiter?: string(name='Delimiter'),
  encode?: string(name='Encode'),
  isPartitionKey?: boolean(name='IsPartitionKey'),
  mappedName?: string(name='MappedName'),
  name?: string(name='Name'),
  nullable?: boolean(name='Nullable'),
  onUpdate?: string(name='OnUpdate'),
  ordinalPosition?: long(name='OrdinalPosition'),
  physicalColumnName?: string(name='PhysicalColumnName'),
  pkPosition?: long(name='PkPosition'),
  precision?: long(name='Precision'),
  primarykey?: boolean(name='Primarykey'),
  scale?: long(name='Scale'),
  tableName?: string(name='TableName'),
  tokenizer?: string(name='Tokenizer'),
  type?: string(name='Type'),
  updateTime?: string(name='UpdateTime'),
  valueType?: string(name='ValueType'),
}

model Filters {
  appIdRegex?: string(name='AppIdRegex'),
  appNameRegex?: string(name='AppNameRegex'),
  appState?: string(name='AppState'),
  appType?: string(name='AppType'),
  executionTimeRange?: {
    maxTimeInSeconds?: long(name='MaxTimeInSeconds', minimum=1),
    minTimeInSeconds?: long(name='MinTimeInSeconds', minimum=0),
  }(name='ExecutionTimeRange'),
  submitTimeRange?: {
    maxTimeInMills?: long(name='MaxTimeInMills', minimum=0),
    minTimeInMills?: long(name='MinTimeInMills', minimum=0),
  }(name='SubmitTimeRange'),
  termiatedTimeRange?: {
    maxTimeInMills?: long(name='MaxTimeInMills', minimum=0),
    minTimeInMills?: long(name='MinTimeInMills', minimum=0),
  }(name='TermiatedTimeRange'),
}

model LogAnalyzeResult {
  appErrorAdvice?: string(name='AppErrorAdvice'),
  appErrorCode?: string(name='AppErrorCode', example='EXCEEDED_QUOTA'),
  appErrorLog?: string(name='AppErrorLog', example='exception: xxxx'),
}

model SerDeInfoModel {
  name?: string(name='Name'),
  parameters?: map[string]string(name='Parameters'),
  serDeId?: long(name='SerDeId'),
  serializationLib?: string(name='SerializationLib'),
}

model SparkAnalyzeLogTask {
  DBClusterId?: string(name='DBClusterId', example='amv-adbxxxxx'),
  result?: LogAnalyzeResult(name='Result'),
  ruleMatched?: boolean(name='RuleMatched', example='true'),
  startedTimeInMillis?: long(name='StartedTimeInMillis', example='1672123543000'),
  submittedTimeInMillis?: long(name='SubmittedTimeInMillis', example='1672123543000'),
  taskErrMsg?: string(name='TaskErrMsg', example='Driver log not found'),
  taskId?: long(name='TaskId', example='10'),
  taskState?: string(name='TaskState', example='WAITING'),
  terminatedTimeInMillis?: long(name='TerminatedTimeInMillis', example='1672123543000'),
  userId?: long(name='UserId', example='13719918xxx'),
}

model SparkAppInfo {
  appId?: string(name='AppId', example='s202207151211hz0cb4*****'),
  appName?: string(name='AppName', example='Spark Test'),
  DBClusterId?: string(name='DBClusterId', example='amv-23xxxx'),
  detail?: Detail(name='Detail'),
  message?: string(name='Message', example='WARN: Disk is full'),
  priority?: string(name='Priority', example='NORMAL'),
  state?: string(name='State', example='FAILED'),
}

model SparkAttemptInfo {
  attemptId?: string(name='AttemptId', example='s202207151211hz0cb4200*****-0001'),
  detail?: Detail(name='Detail'),
  message?: string(name='Message', example='WARN: Disk is full'),
  priority?: string(name='Priority', example='NORMAL'),
  state?: string(name='State', example='RUNNING'),
}

model SparkSession {
  active?: string(name='Active', example='true'),
  aliyunUid?: long(name='AliyunUid', example='11123123'),
  sessionId?: long(name='SessionId', example='15'),
  state?: string(name='State', example='idle'),
}

model Statement {
  aliyunUid?: long(name='AliyunUid', example='1111111'),
  code?: string(name='Code', example='SELECT * FROM table'),
  codeState?: string(name='CodeState', example='Waiting'),
  codeType?: string(name='CodeType', example='SQL'),
  endTime?: long(name='EndTime', example='1658987911000'),
  error?: string(name='Error', example='Disk is full'),
  haveRows?: boolean(name='HaveRows', example='true'),
  output?: string(name='Output', example='Spark is running, the ouput is...'),
  resourceGroup?: string(name='ResourceGroup', example='rg1'),
  sessionId?: long(name='SessionId', example='10'),
  startTime?: long(name='StartTime', example='1658977911000'),
  statementId?: long(name='StatementId', example='100'),
  totalCount?: long(name='TotalCount', example='1000'),
}

model StatementInfo {
  code?: string(name='Code'),
  completedTimeInMills?: long(name='CompletedTimeInMills'),
  output?: string(name='Output'),
  process?: float(name='Process'),
  startedTimeInMills?: long(name='StartedTimeInMills'),
  state?: string(name='State'),
  statementId?: string(name='StatementId'),
}

model StorageDescriptorModel {
  compressed?: boolean(name='Compressed'),
  inputFormat?: string(name='InputFormat'),
  location?: string(name='Location'),
  numBuckets?: long(name='NumBuckets'),
  outputFormat?: string(name='OutputFormat'),
  parameters?: map[string]string(name='Parameters'),
  sdId?: long(name='SdId'),
  serDeInfo?: SerDeInfoModel(name='SerDeInfo'),
  storedAsSubDirectories?: boolean(name='StoredAsSubDirectories'),
}

model TableDetailModel {
  catalog?: string(name='Catalog'),
  columns?: [
    ColDetailModel
  ](name='Columns'),
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  owner?: string(name='Owner'),
  schemaName?: string(name='SchemaName'),
  tableName?: string(name='TableName'),
  tableType?: string(name='TableType'),
  updateTime?: string(name='UpdateTime'),
}

model TableModel {
  archiveType?: string(name='ArchiveType'),
  blockSize?: long(name='BlockSize'),
  bucket?: long(name='Bucket'),
  bucketCount?: long(name='BucketCount'),
  cols?: [
    FieldSchemaModel
  ](name='Cols'),
  comment?: string(name='Comment'),
  compression?: string(name='Compression'),
  createTime?: string(name='CreateTime'),
  currentVersion?: long(name='CurrentVersion'),
  dbName?: string(name='DbName'),
  dictEncode?: boolean(name='DictEncode'),
  distributeColumns?: [
    FieldSchemaModel
  ](name='DistributeColumns'),
  distributeType?: string(name='DistributeType'),
  enableDfs?: boolean(name='EnableDfs'),
  hotPartitionCount?: long(name='HotPartitionCount'),
  indexes?: [
    CstoreIndexModel
  ](name='Indexes'),
  isAllIndex?: boolean(name='IsAllIndex'),
  isFulltextDict?: boolean(name='IsFulltextDict'),
  maxColumnId?: long(name='MaxColumnId'),
  parameters?: map[string]string(name='Parameters'),
  partitionColumn?: string(name='PartitionColumn'),
  partitionCount?: long(name='PartitionCount'),
  partitionKeys?: [
    FieldSchemaModel
  ](name='PartitionKeys'),
  partitionType?: string(name='PartitionType'),
  physicalDatabaseName?: string(name='PhysicalDatabaseName'),
  physicalTableName?: string(name='PhysicalTableName'),
  previousVersion?: long(name='PreviousVersion'),
  rawTableName?: string(name='RawTableName'),
  routeColumns?: [
    FieldSchemaModel
  ](name='RouteColumns'),
  routeEffectiveColumn?: FieldSchemaModel(name='RouteEffectiveColumn'),
  routeType?: string(name='RouteType'),
  rtEngineType?: string(name='RtEngineType'),
  rtIndexAll?: boolean(name='RtIndexAll'),
  rtModeType?: string(name='RtModeType'),
  sd?: StorageDescriptorModel(name='Sd'),
  storagePolicy?: string(name='StoragePolicy'),
  subpartitionColumn?: string(name='SubpartitionColumn'),
  subpartitionCount?: long(name='SubpartitionCount'),
  subpartitionType?: string(name='SubpartitionType'),
  tableEngineName?: string(name='TableEngineName'),
  tableName?: string(name='TableName'),
  tableType?: string(name='TableType'),
  tblId?: long(name='TblId'),
  temporary?: boolean(name='Temporary'),
  updateTime?: string(name='UpdateTime'),
  viewExpandedText?: string(name='ViewExpandedText'),
  viewOriginalText?: string(name='ViewOriginalText'),
  viewSecurityMode?: string(name='ViewSecurityMode'),
}

model TableSummaryModel {
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  owner?: string(name='Owner'),
  SQL?: string(name='SQL'),
  schemaName?: string(name='SchemaName'),
  tableName?: string(name='TableName'),
  tableSize?: long(name='TableSize'),
  tableType?: string(name='TableType'),
  updateTime?: string(name='UpdateTime'),
}

model AllocateClusterPublicConnectionRequest {
  connectionStringPrefix?: string(name='ConnectionStringPrefix', description='The prefix of the public endpoint.

*   The prefix can contain lowercase letters, digits, and hyphens (-). It must start with a lowercase letter.
*   The prefix can be up to 30 characters in length.', example='test12', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1z5d2q71is2****', position='Query'),
}

model AllocateClusterPublicConnectionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='868EF07F-D0B2-5043-B092-0C14CD00B65A'),
}

model AllocateClusterPublicConnectionResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: AllocateClusterPublicConnectionResponseBody(name='body'),
}

async function allocateClusterPublicConnection(request: AllocateClusterPublicConnectionRequest): AllocateClusterPublicConnectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AllocateClusterPublicConnection', 'POST', '/', 'json', false, 'json', request);
}

model AttachUserENIRequest {
  DBClusterId: string(name='DBClusterId', example='am-bp11q28kvl688****', position='Query'),
}

model AttachUserENIResponseBody = {
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model AttachUserENIResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: AttachUserENIResponseBody(name='body'),
}

async function attachUserENI(request: AttachUserENIRequest): AttachUserENIResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AttachUserENI', 'POST', '/', 'json', false, 'json', request);
}

model BindAccountRequest {
  accountName: string(name='AccountName', description='The standard account of the cluster.', example='test_accout', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz99d9nh532****', position='Query'),
  ramUser: string(name='RamUser', description='The ID of the RAM user.', example='1444832459****', position='Query'),
}

model BindAccountResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='DFF27323-3868-5F8A-917D-5D1D06B6BC0D'),
}

model BindAccountResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: BindAccountResponseBody(name='body'),
}

async function bindAccount(request: BindAccountRequest): BindAccountResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'BindAccount', 'POST', '/', 'json', false, 'json', request);
}

model BindDBResourceGroupWithUserRequest {
  DBClusterId: string(name='DBClusterId', example='am-bp1ub9grke1****', position='Query'),
  groupName: string(name='GroupName', example='test', position='Query'),
  groupUser: string(name='GroupUser', example='accout', position='Query'),
}

model BindDBResourceGroupWithUserResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model BindDBResourceGroupWithUserResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: BindDBResourceGroupWithUserResponseBody(name='body'),
}

async function bindDBResourceGroupWithUser(request: BindDBResourceGroupWithUserRequest): BindDBResourceGroupWithUserResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'BindDBResourceGroupWithUser', 'POST', '/', 'json', false, 'json', request);
}

model CheckBindRamUserRequest {
  DBClusterId?: string(name='DBClusterId', example='amv-wz9842849v6****', position='Query'),
  regionId?: string(name='RegionId', example='cn-hangzhou', position='Query'),
}

model CheckBindRamUserResponseBody = {
  requestId?: string(name='RequestId', example='2FB9DCA3-DA56-5B43-A9A0-68E3D0E6AA84'),
  result?: boolean(name='Result', example='true'),
}

model CheckBindRamUserResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CheckBindRamUserResponseBody(name='body'),
}

async function checkBindRamUser(request: CheckBindRamUserRequest): CheckBindRamUserResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CheckBindRamUser', 'POST', '/', 'json', false, 'json', request);
}

model CheckSampleDataSetRequest {
  DBClusterId: string(name='DBClusterId', example='amv-wz9r8f67h4cqz41u', position='Query'),
}

model CheckSampleDataSetResponseBody = {
  requestId?: string(name='RequestId', example='0CE655C3-C211-513D-A42F-D4AE2D1A867C'),
  status?: string(name='Status', example='UNINITIALIZED'),
}

model CheckSampleDataSetResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CheckSampleDataSetResponseBody(name='body'),
}

async function checkSampleDataSet(request: CheckSampleDataSetRequest): CheckSampleDataSetResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CheckSampleDataSet', 'POST', '/', 'json', false, 'json', request);
}

model CreateAccountRequest {
  accountDescription?: string(name='AccountDescription', description='The description of the database account.

*   The description cannot start with `http://` or `https://`.
*   The description can be up to 256 characters in length.', position='Query'),
  accountName: string(name='AccountName', description='The name of the database account.

*   The name must start with a lowercase letter and end with a lowercase letter or a digit.
*   The name can contain lowercase letters, digits, and underscores (\\_).
*   The name must be 2 to 16 characters in length.
*   Reserved account names such as root, admin, and opsadmin cannot be used.', example='test_accout', position='Query'),
  accountPassword: string(name='AccountPassword', description='The password of the database account.

*   The password must contain at least three of the following character types: uppercase letters, lowercase letters, digits, and special characters.
*   Special characters include `! @ # $ % ^ & * ( ) _ + - =`
*   The password must be 8 to 32 characters in length.', example='Test_accout1', position='Query'),
  accountType: string(name='AccountType', description='The type of the database account. Valid values:

*   **Normal**: standard account.
*   **Super**: privileged account.', example='Normal', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
}

model CreateAccountResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='2FED790E-FB61-4721-8C1C-07C627FA5A19'),
}

model CreateAccountResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CreateAccountResponseBody(name='body'),
}

async function createAccount(request: CreateAccountRequest): CreateAccountResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateAccount', 'POST', '/', 'json', false, 'json', request);
}

model CreateDBClusterRequest {
  backupSetId?: string(name='BackupSetId', description='The ID of the backup set that you want to use to restore data.

>  You can call the [DescribeBackups](~~612318~~) operation to query the backup sets of the cluster.', example='1880808684', position='Query'),
  computeResource: string(name='ComputeResource', description='The amount of reserved computing resources. Unit: ACUs. Valid values: 0 to 4096. The value must be in increments of 16 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.

>  This parameter must be specified with a unit.', example='16ACU', position='Query'),
  DBClusterDescription?: string(name='DBClusterDescription', description='The description of the cluster.

*   The description cannot start with `http://` or `https://`.
*   The description must be 2 to 256 characters in length', example='test', position='Query'),
  DBClusterNetworkType?: string(name='DBClusterNetworkType', description='The network type of the cluster. Only **VPC** is supported.', example='VPC', position='Query'),
  DBClusterVersion: string(name='DBClusterVersion', description='The version of the cluster. Set the value to **5.0**.', example='5.0', position='Query'),
  enableDefaultResourcePool?: boolean(name='EnableDefaultResourcePool', description='Specifies whether to allocate all reserved computing resources to the user_default resource group. Valid values:

*   **true** (default)
*   **false**', example='true', position='Query'),
  payType: string(name='PayType', description='The billing method of the cluster. Valid values:

*   **Postpaid**: pay-as-you-go.
*   **Prepaid**: subscription.', example='Prepaid', position='Query'),
  period?: string(name='Period', description='The subscription type of the subscription cluster. Valid values:

*   **Year**: subscription on a yearly basis.
*   **Month**: subscription on a monthly basis.

>  This parameter must be specified when PayType is set to Prepaid.', example='Month', position='Query'),
  regionId: string(name='RegionId', description='The region ID.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='rg-4690g37929****', position='Query'),
  restoreToTime?: string(name='RestoreToTime', description='The point in time to which you want to restore data from the backup set.', example='2023-09-20T03:13:56Z', position='Query'),
  restoreType?: string(name='RestoreType', description='The method that you want to use to restore data. Valid values:

*   **backup**: restores data from a backup set. You must also specify the **BackupSetId** and **SourceDBClusterId** parameters.
*   **timepoint**: restores data to a point in time. You must also specify the **RestoreToTime** and **SourceDBClusterId** parameters.', example='backup', position='Query'),
  sourceDbClusterId?: string(name='SourceDbClusterId', description='The ID of the source AnalyticDB for MySQL Data Warehouse Edition cluster. If you want to restore a Data Lakehouse Edition cluster from a Data Warehouse Edition cluster, you must specify this parameter.', example='amv-bp1r053byu48p****', position='Query'),
  storageResource: string(name='StorageResource', description='The amount of reserved storage resources. Unit: AnalyticDB compute units (ACUs). Valid values: 0 to 2064. The value must be in increments of 24 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.

>  This parameter must be specified with a unit.', example='24ACU', position='Query'),
  tag?: [ 
    {
      key?: string(name='Key', description='The key of tag N to add to the cluster. You can use tags to filter clusters. Valid values of N: 1 to 20. The values that you specify for N must be unique and consecutive integers that start from 1. Each value of `Tag.N.Key` is paired with a value of `Tag.N.Value`.

>  The tag key can be up to 64 characters in length and cannot start with `aliyun`, `acs:`, `http://`, or `https://`.', example='testkey1'),
      value?: string(name='Value', description='The value of tag N to add to the cluster. You can use tags to filter clusters. Valid values of N: 1 to 20. The values that you specify for N must be unique and consecutive integers that start from 1. Each value of `Tag.N.Key` is paired with a value of `Tag.N.Value`.

>  The tag value can be up to 64 characters in length and cannot start with `aliyun`, `acs:`, `http://`, or `https://`.', example='test1'),
    }
  ](name='Tag', description='The tags to add to the cluster.', position='Query'),
  usedTime?: string(name='UsedTime', description='The subscription duration of the subscription cluster.

*   Valid values when **Period** is set to Year: 1 to 3 (integer).
*   Valid values when **Period** is set to Month: 1 to 9 (integer).

>  This parameter must be specified when PayType is set to **Prepaid**.', example='3', position='Query'),
  VPCId: string(name='VPCId', description='The virtual private cloud (VPC) ID of the cluster.', example='vpc-bp1at5ze0t5u3xtqn****', position='Query'),
  vSwitchId: string(name='VSwitchId', description='The vSwitch ID of the cluster.', example='vsw-bp1aadw9k19x6cis9****', position='Query'),
  zoneId: string(name='ZoneId', description='The zone ID.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent zone list.', example='cn-hangzhou-h', position='Query'),
}

model CreateDBClusterResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  orderId?: string(name='OrderId', description='The order ID.', example='202353278****'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  resourceGroupId?: string(name='ResourceGroupId', description='The default resource group ID.', example='rg-4690g37929****'),
}

model CreateDBClusterResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CreateDBClusterResponseBody(name='body'),
}

async function createDBCluster(request: CreateDBClusterRequest): CreateDBClusterResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDBCluster', 'POST', '/', 'json', false, 'json', request);
}

model CreateDBResourceGroupRequest {
  clusterMode?: string(name='ClusterMode', position='Query'),
  clusterSizeResource?: string(name='ClusterSizeResource', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  groupName: string(name='GroupName', description='The name of the resource group.

*   The name can be up to 255 characters in length.
*   The name must start with a letter or a digit.
*   The name can contain letters, digits, hyphens (\\_), and underscores (\\_).', example='test_group', position='Query'),
  groupType: string(name='GroupType', description='The type of the resource group. Valid values:

*   **Interactive**
*   **Job**

> For information about resource groups of Data Lakehouse Edition, see [Resource groups](~~428610~~).', example='Job', position='Query'),
  maxClusterCount?: int32(name='MaxClusterCount', position='Query'),
  maxComputeResource?: string(name='MaxComputeResource', description='The maximum reserved computing resources. Unit: ACU.

*   If GroupType is set to Interactive, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 16 ACUs.
*   If GroupType is set to Job, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 8 ACUs.', example='48', position='Query'),
  minClusterCount?: int32(name='MinClusterCount', position='Query'),
  minComputeResource?: string(name='MinComputeResource', description='The minimum reserved computing resources. Unit: AnalyticDB Compute Unit (ACU).

*   If GroupType is set to Interactive, set the value to 16ACU.
*   If GroupType is set to Job, set the value to 0ACU.', example='0', position='Query'),
}

model CreateDBResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A94B6C02-7BD4-5D67-9776-3AC8317E8DD5'),
}

model CreateDBResourceGroupResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CreateDBResourceGroupResponseBody(name='body'),
}

async function createDBResourceGroup(request: CreateDBResourceGroupRequest): CreateDBResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDBResourceGroup', 'POST', '/', 'json', false, 'json', request);
}

model CreateElasticPlanRequest {
  autoScale?: boolean(name='AutoScale', description='Specifies whether to enable **Proportional Default Scaling for EIUs**.

Valid values:

*   true: enables Proportional Default Scaling for EIUs. If you enable Proportional Default Scaling, storage resources are scaled along with computing resources, and the TargetSize and CronExpression parameters are not supported.

*   false: does not enable Proportional Default Scaling for EIUs.

> *   This parameter is required if the Type parameter is set to WORKER. This parameter is not required if the Type parameter is set to EXECUTOR.
> *   You can enable Proportional Default Scaling for EIUs for only a single scaling plan of a cluster.', example='false', position='Query'),
  cronExpression?: string(name='CronExpression', description='A CORN expression that specifies the scaling cycle and time for the scaling plan.', example='0 20 14 * * ?', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the ID of an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName: string(name='ElasticPlanName', description='The name of the scaling plan.

>  The name must be 2 to 30 characters in length, and can contain letters, digits, and underscores (\\_). It must start with a letter.', example='test', position='Query'),
  enabled: boolean(name='Enabled', description='Specifies whether to immediately enable the scaling plan after the scaling plan is created.

Valid values:

*   true: immediately enables the scaling plan.
*   false: does not immediately enable the scaling plan.', example='true', position='Query'),
  endTime?: string(name='EndTime', description='The time to end the scaling plan.

>  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2025-01-01T12:01:00Z', position='Query'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> *   This parameter is required if you want to create a scaling plan that uses interactive resource groups. This parameter is not required if you want to create a scaling plan that uses elastic I/O units (EIUs).
> *   You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group within a specific cluster.', example='test', position='Query'),
  startTime?: string(name='StartTime', description='The time to start the scaling plan.

>  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-01-01T12:01:00Z', position='Query'),
  targetSize?: string(name='TargetSize', description='The amount of elastic resources after scaling.

> *   This parameter is not required only if the resource group uses **EIUs** and **Proportional Default Scaling for EIUs** is enabled.
> *   You can call the [DescribeElasticPlanSpecifications](~~601278~~) operation to query the specifications that are supported for scaling plans.', example='32ACU', position='Query'),
  type: string(name='Type', description='The type of the scaling plan.

Valid values:

*   EXECUTOR: interactive resource groups, which fall into the computing resource category.
*   WORKER: EIUs.', example='EXECUTOR', position='Query'),
}

model CreateElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model CreateElasticPlanResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CreateElasticPlanResponseBody(name='body'),
}

async function createElasticPlan(request: CreateElasticPlanRequest): CreateElasticPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateElasticPlan', 'POST', '/', 'json', false, 'json', request);
}

model CreateOssSubDirectoryRequest {
  DBClusterId?: string(name='DBClusterId', position='Body'),
  path: string(name='Path', position='Body'),
}

model CreateOssSubDirectoryResponseBody = {
  data?: {
    clientCRC?: long(name='ClientCRC'),
    eTag?: string(name='ETag'),
    requestId?: string(name='RequestId'),
    serverCRC?: long(name='ServerCRC'),
  }(name='Data'),
  httpStatusCode?: long(name='HttpStatusCode'),
  message?: string(name='Message'),
  requestId?: string(name='RequestId'),
  success?: boolean(name='Success'),
}

model CreateOssSubDirectoryResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CreateOssSubDirectoryResponseBody(name='body'),
}

async function createOssSubDirectory(request: CreateOssSubDirectoryRequest): CreateOssSubDirectoryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateOssSubDirectory', 'POST', '/', 'json', true, 'form', request);
}

model CreateSparkTemplateRequest {
  appType?: string(name='AppType', description='The type of the application. Valid values:

*   **SQL**: SQL application
*   **STREAMING**: streaming application
*   **BATCH**: batch application

>  This parameter is not required if the application template is of the folder type.', example='SQL', position='Body'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', maxLength=64, position='Body'),
  name: string(name='Name', description='The name of the application template. The name can be up to 64 characters in length.', example='batchfile', maxLength=64, position='Body'),
  parentId: long(name='ParentId', description='The ID of the directory to which the application template belongs.', example='10', minimum=0, position='Body'),
  type: string(name='Type', description='The type of the application template. Valid values:

*   **folder**: directory
*   **file**: application', example='file', position='Body'),
}

model CreateSparkTemplateResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the application template is created. Valid values:

*   **true**: The application template is created.
*   **false**: The application fails to be created.', example='True'),
  }(name='Data', description='The creation result.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model CreateSparkTemplateResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: CreateSparkTemplateResponseBody(name='body'),
}

async function createSparkTemplate(request: CreateSparkTemplateRequest): CreateSparkTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateSparkTemplate', 'POST', '/', 'json', true, 'form', request);
}

model DeleteAccountRequest {
  accountName: string(name='AccountName', description='The name of the database account.

> You can call the [DescribeAccounts](~~612430~~) operation to query the information about database accounts in a cluster, including the database account name.', example='test_accout', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
}

model DeleteAccountResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='2FED790E-FB61-4721-8C1C-07C627FA5A19'),
}

model DeleteAccountResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteAccountResponseBody(name='body'),
}

async function deleteAccount(request: DeleteAccountRequest): DeleteAccountResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteAccount', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDBClusterRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1r053byu48p****', position='Query'),
}

model DeleteDBClusterResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DeleteDBClusterResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteDBClusterResponseBody(name='body'),
}

/**
  * ###
  * You can call this operation to delete only subscription clusters.
  *
 */
async function deleteDBCluster(request: DeleteDBClusterRequest): DeleteDBClusterResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDBCluster', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDBResourceGroupRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  groupName: string(name='GroupName', description='The name of the resource group.

> You can call the [DescribeDBResourceGroup](~~612410~~) operation to query the resource group information of a cluster, including the resource group name.', example='test_group', position='Query'),
}

model DeleteDBResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A94B6C02-7BD4-5D67-9776-3AC8317E8DD3'),
}

model DeleteDBResourceGroupResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteDBResourceGroupResponseBody(name='body'),
}

async function deleteDBResourceGroup(request: DeleteDBResourceGroupRequest): DeleteDBResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDBResourceGroup', 'POST', '/', 'json', false, 'json', request);
}

model DeleteElasticPlanRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the cluster IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a specific region.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the name of a scaling plan for a specific cluster.', example='test', position='Query'),
}

model DeleteElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model DeleteElasticPlanResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteElasticPlanResponseBody(name='body'),
}

async function deleteElasticPlan(request: DeleteElasticPlanRequest): DeleteElasticPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteElasticPlan', 'POST', '/', 'json', false, 'json', request);
}

model DeleteProcessInstanceRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='am-wz9rq819u71ig****', position='Query'),
  processInstanceId: long(name='ProcessInstanceId', description='The ID of the workflow instance.', example='4017', position='Query'),
  projectCode: long(name='ProjectCode', description='The project ID, which is the unique identifier of the project.', example='9839028042592', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model DeleteProcessInstanceResponseBody = {
  data?: boolean(name='Data', description='Indicates whether the workflow instance is deleted. Valid values:

*   **true**
*   **false**', example='true'),
  message?: string(name='Message', description='The returned message. Valid values:

*   If the request was successful, **Success** is returned.
*   If the request failed, an error message is returned.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='115F9CCA-EF2E-5F91-AB60-4961D52FEAB4'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DeleteProcessInstanceResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteProcessInstanceResponseBody(name='body'),
}

async function deleteProcessInstance(request: DeleteProcessInstanceRequest): DeleteProcessInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteProcessInstance', 'POST', '/', 'json', false, 'json', request);
}

model DeleteSparkTemplateRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', maxLength=64, position='Body'),
  id: long(name='Id', description='The ID of the directory or application to which the template belongs.

> *   You can call the [GetSparkTemplateFullTree](~~456205~~) operation to query the directory ID or application ID.
> *   If you specify a directory ID, the entire directory is deleted.', example='725204', minimum=0, position='Body'),
}

model DeleteSparkTemplateResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the template is deleted. Valid values:

*   **true**: The template is deleted.
*   **false**: The template fails to be deleted.', example='True'),
  }(name='Data', description='The result returned.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DeleteSparkTemplateResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteSparkTemplateResponseBody(name='body'),
}

async function deleteSparkTemplate(request: DeleteSparkTemplateRequest): DeleteSparkTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteSparkTemplate', 'POST', '/', 'json', true, 'form', request);
}

model DeleteSparkTemplateFileRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1y769u11748****', maxLength=64, position='Body'),
  id: long(name='Id', description='The ID of the template file to be deleted.

>  You can call the [GetSparkTemplateFullTree](~~456205#doc-api-adb-GetSparkTemplateFullTree~~) operation to query the IDs of all existing template files.', example='284', minimum=0, position='Body'),
}

model DeleteSparkTemplateFileResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the template file is deleted. Valid values:

*   **true**: The template file is deleted.
*   **false**: The template file fails to be deleted.', example='true'),
  }(name='Data', description='The deletion result.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='C3A9594F-1D40-4472-A96C-8FB8AA20D38C'),
}

model DeleteSparkTemplateFileResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DeleteSparkTemplateFileResponseBody(name='body'),
}

async function deleteSparkTemplateFile(request: DeleteSparkTemplateFileRequest): DeleteSparkTemplateFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteSparkTemplateFile', 'POST', '/', 'json', true, 'form', request);
}

model DescribeAccountAllPrivilegesRequest {
  accountName: string(name='AccountName', description='The name of the database account.', example='account1', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp14t95lun0w****', position='Query'),
  marker?: string(name='Marker', description='Specifies the start position marker from which to return results. If you receive a response indicating that the results are truncated, set this parameter to the value of the `Marker` parameter in the response that you received.', example='EXAMPLE', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model DescribeAccountAllPrivilegesResponseBody = {
  data?: {
    marker?: string(name='Marker', description='Indicates the position where the results are truncated. When a value of `true` is returned for the `Truncated` parameter, this parameter is present and contains the value to use for the Marker parameter in a subsequent call.', example='0573e74fd1ccb01739993a691e876074db6e1b6ad79f54115f0e98528432ba6a523cfec5780ade5189299cc3396f6ff7'),
    result?: [ 
      {
        privilegeObject?: {
          column?: string(name='Column', description='The name of the column.', example='id'),
          database?: string(name='Database', description='The name of the database.', example='tdb1'),
          description?: string(name='Description', description='The description of the permission object.', example='id of table'),
          table?: string(name='Table', description='The name of the table.', example='table1'),
        }(name='PrivilegeObject', description='The objects on which the permission takes effect, including databases, tables, and columns. If Global is returned for the PrivilegeType parameter, an empty string is returned for this parameter.'),
        privilegeType?: string(name='PrivilegeType', description='The permission level of the database account. You can call the `DescribeEnabledPrivileges` operation to query the permission level of the database account.', example='Global'),
        privileges?: [ string ](name='Privileges', description='The name of the permission, which is the same as the permission name returned by the `DescribeEnabledPrivileges` operation.'),
      }
    ](name='Result', description='The permissions.'),
    truncated?: boolean(name='Truncated', description='Indicates whether the results are truncated. If the results are truncated, a value of `true` is returned. In this case, you must call this operation again to obtain all the results until a value of `false` is returned for this parameter.', example='true'),
  }(name='Data', description='Details of the permissions.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='3BB185E9-BB54-1727-B876-13243E4C0EB5'),
}

model DescribeAccountAllPrivilegesResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAccountAllPrivilegesResponseBody(name='body'),
}

async function describeAccountAllPrivileges(request: DescribeAccountAllPrivilegesRequest): DescribeAccountAllPrivilegesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAccountAllPrivileges', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAccountPrivilegeObjectsRequest {
  accountName: string(name='AccountName', description='The name of the database account.', example='test', position='Query'),
  columnPrivilegeObject?: string(name='ColumnPrivilegeObject', description='The column name that is used to filter columns.', example='col1', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1k3wdmt139****', position='Query'),
  databasePrivilegeObject?: string(name='DatabasePrivilegeObject', description='The database name that is used to filter databases.', example='database1', position='Query'),
  pageNumber?: string(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries per page. Default value: 20.', example='20', position='Query'),
  privilegeType: string(name='PrivilegeType', description='The permission level. Valid values: Database, Table, and Column. Global is not supported.', example='Column', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='ch-hangzhou', position='Query'),
  tablePrivilegeObject?: string(name='TablePrivilegeObject', description='The table name that is used to filter tables.', example='table1', position='Query'),
}

model DescribeAccountPrivilegeObjectsResponseBody = {
  data?: [ 
    {
      column?: string(name='Column', description='The name of the column. This parameter is returned when PrivilegeType is set to Column.', example='column1'),
      database?: string(name='Database', description='The name of the database. This parameter is returned when PrivilegeType is set to Database, Table, or Column.', example='tdb1'),
      description?: string(name='Description', description='The description that is specified when you create a table or column. This parameter is returned only when PrivilegeType is set to Database or Table, indicating the database description or table description.', example='a test db'),
      table?: string(name='Table', description='The name of the table. This parameter is returned when PrivilegeType is set to Table or Column.', example='table1'),
    }
  ](name='Data', description='The permissions.'),
  pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='20'),
  requestId?: string(name='RequestId', description='The request ID.', example='34B2AD29-682F-1C14-B3AA-9EF1A96084B8'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='23'),
}

model DescribeAccountPrivilegeObjectsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAccountPrivilegeObjectsResponseBody(name='body'),
}

async function describeAccountPrivilegeObjects(request: DescribeAccountPrivilegeObjectsRequest): DescribeAccountPrivilegeObjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAccountPrivilegeObjects', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAccountPrivilegesRequest {
  accountName: string(name='AccountName', description='The name of the database account.', example='account1', position='Query'),
  columnPrivilegeObject?: string(name='ColumnPrivilegeObject', description='The columns that you want to query. You can use this parameter to query the permissions of the database account on specific columns. This parameter is available only if the PrivilegeType parameter is set to Column.', example='col1', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1k5p066e1a****', position='Query'),
  databasePrivilegeObject?: string(name='DatabasePrivilegeObject', description='The databases that you want to query. You can use this parameter to query the permissions of the database account on specific databases. This parameter is available only if the PrivilegeType parameter is set to Database, Table, or Column.', example='db1', position='Query'),
  pageNumber?: string(name='PageNumber', description='The number of the page to return. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries to return on each page. Default value: 20.', example='10', position='Query'),
  privilegeType: string(name='PrivilegeType', description='The permission level that you want to query. You can call the `DescribeEnabledPrivileges` operation to query the permission level of the database account.', example='Global', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
  tablePrivilegeObject?: string(name='TablePrivilegeObject', description='The tables that you want to query. You can use this parameter to query the permissions of the database account on specific tables. This parameter can be used together with the DatabasePrivilegeObject parameter. This parameter is available only if the PrivilegeType parameter is set to Table or Column.', example='table1', position='Query'),
}

model DescribeAccountPrivilegesResponseBody = {
  data?: [ 
    {
      privilegeObject?: {
        column?: string(name='Column', description='The name of the column.', example='column1'),
        database?: string(name='Database', description='The name of the database.', example='db1'),
        description?: string(name='Description', description='The description of the permission object.', example='a test column'),
        table?: string(name='Table', description='The name of the table.', example='tabl1'),
      }(name='PrivilegeObject', description='The objects on which the permission takes effect, including databases, tables, columns, and additional descriptions.'),
      privilegeType?: string(name='PrivilegeType', description='The permission level of the permission. Valid values: `Global`, `Database`, `Table`, and `Column`. You can call the `DescribeEnabledPrivileges` parameter to query the permission level of a specific permission.', example='Column'),
      privileges?: [ string ](name='Privileges', description='The name of the permission. You can call the `DescribeEnabledPrivileges` operation to query the name of the permission.'),
    }
  ](name='Data', description='Details of the permissions.'),
  pageNumber?: long(name='PageNumber', description='The page number of the returned page.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries returned per page.', example='20'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='DA32480A-E3E5-1BE7-BA98-724551DC04C8'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model DescribeAccountPrivilegesResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAccountPrivilegesResponseBody(name='body'),
}

async function describeAccountPrivileges(request: DescribeAccountPrivilegesRequest): DescribeAccountPrivilegesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAccountPrivileges', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAccountsRequest {
  accountName?: string(name='AccountName', description='The name of the database account.

> If you do not specify this parameter, the information about all database accounts in the cluster is returned.', example='test_accout', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  ownerId?: string(name='OwnerId', position='Query'),
}

model DescribeAccountsResponseBody = {
  accountList?: {
    DBAccount?: [ 
    {
      accountDescription?: string(name='AccountDescription', description='The description of the database account.'),
      accountName?: string(name='AccountName', description='The name of the database account.', example='test_accout'),
      accountStatus?: string(name='AccountStatus', description='The state of the database account. Valid values:

*   **Creating**
*   **Available**
*   **Deleting**', example='Available'),
      accountType?: string(name='AccountType', description='The type of the database account. Valid values:

*   **Normal**: standard account.
*   **Super**: privileged account.', example='Normal'),
      ramUsers?: string(name='RamUsers', description='The ID of the RAM user.', example='1958134230****'),
    }
  ](name='DBAccount')
  }(name='AccountList', description='The queried database accounts.'),
  requestId?: string(name='RequestId', description='The request ID.', example='9CCFAAB4-97B7-5800-B9F2-685EB596E3EF'),
}

model DescribeAccountsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAccountsResponseBody(name='body'),
}

async function describeAccounts(request: DescribeAccountsRequest): DescribeAccountsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAccounts', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAdbMySqlColumnsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a specific region.', example='amv-bp1r053byu48p****', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  schema?: string(name='Schema', description='The name of the database.', example='adb_demo', position='Query'),
  tableName?: string(name='TableName', description='The name of the table.', example='test', position='Query'),
}

model DescribeAdbMySqlColumnsResponseBody = {
  columnCount?: int32(name='ColumnCount', description='The total number of columns.', example='1'),
  columns?: [ 
    {
      comment?: string(name='Comment', description='The comments of the column.', example='test'),
      name?: string(name='Name', description='The name of the column.', example='id'),
      type?: string(name='Type', description='The data type of the column.', example='bigint'),
    }
  ](name='Columns', description='Details of the columns.'),
  message?: string(name='Message', description='The message returned for the operation. Valid values:

*   **Success** is returned if the operation is successful.
*   An error message is returned if the operation fails.', example='Success'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='A9F013CD-0222-595E-8157-445969B97F03'),
  schema?: string(name='Schema', description='The name of the database.', example='adb_demo'),
  success?: boolean(name='Success', description='Indicates whether the operation is successful. Valid values:

*   **true**: The operation is successful.
*   **false**: The operation fails.', example='true'),
  tableName?: string(name='TableName', description='The name of the table.', example='test'),
}

model DescribeAdbMySqlColumnsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAdbMySqlColumnsResponseBody(name='body'),
}

async function describeAdbMySqlColumns(request: DescribeAdbMySqlColumnsRequest): DescribeAdbMySqlColumnsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAdbMySqlColumns', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAdbMySqlSchemasRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
}

model DescribeAdbMySqlSchemasResponseBody = {
  message?: string(name='Message', description='The message returned for the operation. Valid values:

*   **Success** is returned if the operation is successful.
*   An error message is returned if the operation fails.', example='Success'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  schemas?: [ string ](name='Schemas', description='The names of databases.'),
  success?: boolean(name='Success', description='Indicates whether the operation is successful. Valid values:

*   **true**: The operation is successful.
*   **false**: The operation fails.', example='true'),
}

model DescribeAdbMySqlSchemasResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAdbMySqlSchemasResponseBody(name='body'),
}

async function describeAdbMySqlSchemas(request: DescribeAdbMySqlSchemasRequest): DescribeAdbMySqlSchemasResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAdbMySqlSchemas', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAdbMySqlTablesRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  schema?: string(name='Schema', description='The name of the database.', example='adb_demo', position='Query'),
}

model DescribeAdbMySqlTablesResponseBody = {
  message?: string(name='Message', description='The message returned for the operation. Valid values:

*   **Success** is returned if the operation is successful.
*   An error message is returned if the operation fails.', example='Success'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='7A7D49E3-5585-5DF8-B62C-75C46B4991DC'),
  schema?: string(name='Schema', description='The name of the database.', example='adb_demo'),
  success?: boolean(name='Success', description='Indicates whether the operation is successful. Valid values:

*   **true**: The operation is successful.
*   **false**: The operation fails.', example='true'),
  tables?: [ string ](name='Tables', description='The names of tables.'),
}

model DescribeAdbMySqlTablesResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAdbMySqlTablesResponseBody(name='body'),
}

async function describeAdbMySqlTables(request: DescribeAdbMySqlTablesRequest): DescribeAdbMySqlTablesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAdbMySqlTables', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAllDataSourceRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1pke2pcfavw****', position='Query'),
  regionId: string(name='RegionId', description='The region ID.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
  tableName?: string(name='TableName', description='The name of the table.', example='test', position='Query'),
}

model DescribeAllDataSourceResponseBody = {
  columns?: {
    column?: [ 
    {
      autoIncrementColumn?: boolean(name='AutoIncrementColumn', description='Indicates whether the column is an auto-increment column. Valid values:

*   **true**
*   **false**', example='true'),
      columnName?: string(name='ColumnName', description='The name of the column.', example='id'),
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1pke2pcfavw****'),
      primaryKey?: boolean(name='PrimaryKey', description='Indicates whether the column is the primary key of the table. Valid values:

*   **true**
*   **false**', example='false'),
      schemaName?: string(name='SchemaName', description='The logical name of the database.', example='adb_demo'),
      tableName?: string(name='TableName', description='The logical name of the table.', example='test'),
      type?: string(name='Type', description='The data type of the column.', example='bigint'),
    }
  ](name='Column')
  }(name='Columns', description='The queried columns.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C7EDB8E4-9769-4233-88C7-DCA4C9******'),
  schemas?: {
    schema?: [ 
    {
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1pke2pcfavw****'),
      schemaName?: string(name='SchemaName', description='The logical name of the database.', example='adb_demo'),
    }
  ](name='Schema')
  }(name='Schemas', description='The queried databases.'),
  tables?: {
    table?: [ 
    {
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1pke2pcfavw****'),
      schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
      tableName?: string(name='TableName', description='The logical name of the table.', example='test'),
    }
  ](name='Table')
  }(name='Tables', description='The queried tables.'),
}

model DescribeAllDataSourceResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAllDataSourceResponseBody(name='body'),
}

async function describeAllDataSource(request: DescribeAllDataSourceRequest): DescribeAllDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAllDataSource', 'POST', '/', 'json', false, 'json', request);
}

model DescribeApsActionLogsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the ID of the cluster.', example='amv-bp1r053byu48p****', position='Query'),
  endTime: string(name='EndTime', description='The end time of the logs to be queried. Specify the time in the ISO 8601 standard in the **yyyy-MM-ddTHH:mmZ** format. The time must be in UTC.

>  The end time must be later than the start time. Their interval cannot be longer than 30 days.', example='2023-02-11T09:30:00Z', position='Query'),
  keyword?: string(name='Keyword', description='The keyword that you want to use for fuzzy match in the query.', example='table_test', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The number of the page to return. The value must be an integer that is greater than 0. Default value: 1.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries to return on each page. Default value: 30. Valid values:

*   **30**
*   **50**
*   **100**', example='30', minimum=10, maximum=100, position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  stage?: string(name='Stage', description='The task phase during which the logs to be queried are generated. Valid values:

*   **StructureMigrate**: schema migration.
*   **FullDataSync**: full data synchronization.
*   **IncrementalSync**: incremental data synchronization.

>  If you do not specify this parameter, logs of all the task phases are queried.', example='FullDataSync', position='Query'),
  startTime: string(name='StartTime', description='The start time of the logs to be queried. Specify the time in the ISO 8601 standard in the **yyyy-MM-ddTHH:mm:ssZ** format. The time must be in UTC.', example='2023-02-11T08:30:00Z', position='Query'),
  state?: string(name='State', description='The type of the log. Separate multiple log types with commas (,). Valid values:

*   **INFO**
*   **WARN**
*   **ERROR**

>  If you do not specify this parameter, logs of all types are queried.', example='INFO,WARN,ERROR', position='Query'),
  workloadId: string(name='WorkloadId', description='The ID of the real-time data ingestion task.', example='aps-hz109vpvt4fg8528d****', position='Query'),
}

model DescribeApsActionLogsResponseBody = {
  actionLogs?: [ 
    {
      context?: string(name='Context', description='The content of the log.', example='DDL migration job finished'),
      stage?: string(name='Stage', description='The task phase during which the logs are generated. Valid values:

*   **StructureMigrate**: schema migration.
*   **FullDataSync**: full data synchronization.
*   **IncrementalSync**: incremental data synchronization.', example='FullDataSync'),
      state?: string(name='State', description='The type of the log. Multiple log types are separated by commas (,). Valid values:

*   **INFO**
*   **WARN**
*   **ERROR**', example='INFO,WARN,ERROR'),
      time?: string(name='Time', description='The time when the log is generated. The time follows the ISO 8601 standard in the **yyyy-MM-ddTHH:mm:ssZ** format. The time is displayed in UTC.', example='2023-02-01T05:46:30Z'),
    }
  ](name='ActionLogs', description='Details of the logs.'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  pageNumber?: string(name='PageNumber', description='The page number of the returned page.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries returned on each page.', example='30'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5EDBA27-AF3E-5966-9503-FD1557E19167'),
  totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='3'),
  workloadId?: string(name='WorkloadId', description='The ID of the real-time data ingestion task.', example='aps-hz109vpvt4fg8528d****'),
}

model DescribeApsActionLogsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeApsActionLogsResponseBody(name='body'),
}

async function describeApsActionLogs(request: DescribeApsActionLogsRequest): DescribeApsActionLogsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeApsActionLogs', 'POST', '/', 'json', false, 'json', request);
}

model DescribeApsResourceGroupsRequest {
  DBClusterId: string(name='DBClusterId', position='Body'),
}

model DescribeApsResourceGroupsResponseBody = {
  data?: {
    resourceGroups?: [ 
      {
        available?: boolean(name='Available'),
        cuOptions?: [ long ](name='CuOptions'),
        groupName?: string(name='GroupName'),
        groupType?: string(name='GroupType'),
        leftComputeResource?: int32(name='LeftComputeResource'),
        maxComputeResource?: int32(name='MaxComputeResource'),
        minComputeResource?: int32(name='MinComputeResource'),
      }
    ](name='ResourceGroups'),
    step?: long(name='Step'),
  }(name='Data'),
  httpStatusCode?: long(name='HttpStatusCode'),
  message?: string(name='Message'),
  requestId?: string(name='RequestId'),
  success?: boolean(name='Success'),
}

model DescribeApsResourceGroupsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeApsResourceGroupsResponseBody(name='body'),
}

async function describeApsResourceGroups(request: DescribeApsResourceGroupsRequest): DescribeApsResourceGroupsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeApsResourceGroups', 'POST', '/', 'json', true, 'form', request);
}

model DescribeAuditLogRecordsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-t4nj8619bz2w3****', position='Query'),
  DBName?: string(name='DBName', description='The name of the database on which the SQL statement was executed.', example='adb_demo', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.

> 

*   The end time must be later than the start time.

*   The maximum time range that can be specified is 24 hours.', example='2022-08-12T17:08Z', position='Query'),
  hostAddress?: string(name='HostAddress', description='The IP address and port number of the client that is used to execute the SQL statement.', example='100.104.XX.XX:43908', position='Query'),
  order?: string(name='Order', description='The order in which to sort the retrieved entries by field. Specify this parameter in the JSON format. The value is an ordered array that uses the order of the input array and contains `Field` and `Type`. Example: `[{"Field":"ExecutionStartTime","Type":"Desc"},{"Field":"ScanRows","Type":"Asc"}]`. Fields:

*   `Field`: the field that is used to sort the retrieved entries. Valid values:

    *   **HostAddress**: the IP address of the client that is used to connect to the database.
    *   **UserName**: the username.
    *   **ExecutionStartTime**: the start time of the query execution.
    *   **QueryTime**: the amount of time consumed to execute the SQL statement.
    *   **PeakMemoryUsage**: the maximum memory usage when the SQL statement is executed.
    *   **ScanRows**: the number of rows to be scanned from a data source in the task.
    *   **ScanSize**: the amount of data to be scanned.
    *   **ScanTime**: the total amount of time consumed to scan data.
    *   **PlanningTime**: the amount of time consumed to generate execution plans.
    *   **WallTime**: the accumulated CPU Time values of all operators in the query on each node.
    *   **ProcessID**: the process ID.

*   `Type`: the sorting type of the retrieved entries. Valid values:

    *   **Desc**: descending order.
    *   **Asc**: ascending order.', example='[{"Field":"ExecuteTime","Type":"Desc"},{"Field":"HostAddress","Type":"Asc"}]', position='Query'),
  orderType?: string(name='OrderType', description='The sorting order of the retrieved entries. Valid values:

*   **asc**: sorts the retrieved entries by time in ascending order.
*   **desc**: sorts the retrieved entries by time in descending order.', example='asc', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **10** (default)
*   **30**
*   **50**
*   **100**', example='10', minimum=10, maximum=100, position='Query'),
  proxyUser?: string(name='ProxyUser', description='A reserved parameter.', position='Query'),
  queryKeyword?: string(name='QueryKeyword', description='The keyword based on which audit logs are queried. You can set this parameter to a value of the STRING type.', example='adb', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

> You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  sqlType?: string(name='SqlType', description='The type of the SQL statement. Valid values:

*   **DELETE**
*   **SELECT**
*   **UPDATE**
*   **INSERT INTO SELECT**
*   **ALTER**
*   **DROP**
*   **INSERT**

> You can query only a single type of SQL statements at a time. If you leave this parameter empty, the **SELECT** SQL statements are queried.', example='SELECT', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.

> SQL audit logs can be queried only when SQL audit is enabled. Only SQL audit logs within the last 30 days can be queried. If SQL audit was disabled and re-enabled, only SQL audit logs from the time when SQL audit was re-enabled can be queried.', example='2022-08-12T04:17Z', position='Query'),
  succeed?: string(name='Succeed', description='Specifies whether the execution of the SQL statement succeeds. Valid values:

*   **true**
*   **false**', example='true', position='Query'),
  user?: string(name='User', description='The username that is used to execute the SQL statement.', example='test', position='Query'),
}

model DescribeAuditLogRecordsResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-t4nj8619bz2w3****'),
  items?: [ 
    {
      connId?: string(name='ConnId', description='The connection ID.', example='14356****'),
      DBName?: string(name='DBName', description='The name of the database on which the SQL statement was executed.', example='adb_demo'),
      executeTime?: string(name='ExecuteTime', description='The start time of the execution of the SQL statement. The time is displayed in the ISO 8601 standard in the yyyy-MM-dd HH:mm:ss format. The time must be in UTC.', example='2022-08-12 10:10:00'),
      hostAddress?: string(name='HostAddress', description='The IP address and port number of the client that is used to execute the SQL statement.', example='100.104.XX.XX:43908'),
      processID?: string(name='ProcessID', description='The task ID.', example='202106081752021720161662490345362390'),
      SQLText?: string(name='SQLText', description='The SQL statement.', example='SELECT * FROM adb_hdfs_import_source'),
      SQLType?: string(name='SQLType', description='The type of the SQL statement.', example='SELECT'),
      succeed?: string(name='Succeed', description='Indicates whether the SQL statement was successfully executed. Valid values:

*   **true**
*   **false**', example='true'),
      totalTime?: string(name='TotalTime', description='The amount of time that is consumed to execute the SQL statement. Unit: milliseconds.', example='216'),
      user?: string(name='User', description='The username that is used to execute the SQL statement.', example='test'),
    }
  ](name='Items', description='The queried SQL audit logs.'),
  pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='8A564B7F-8C00-43C0-8EC5-919FBB70573'),
  totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='6974'),
}

model DescribeAuditLogRecordsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeAuditLogRecordsResponseBody(name='body'),
}

async function describeAuditLogRecords(request: DescribeAuditLogRecordsRequest): DescribeAuditLogRecordsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAuditLogRecords', 'POST', '/', 'json', false, 'json', request);
}

model DescribeClusterAccessWhiteListRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
}

model DescribeClusterAccessWhiteListResponseBody = {
  items?: {
    IPArray?: [ 
    {
      DBClusterIPArrayAttribute?: string(name='DBClusterIPArrayAttribute', description='The attribute of the whitelist.

> Whitelists with the **hidden** attribute are not displayed in the console. Those whitelists are used to access Data Transmission Service (DTS) and PolarDB.', example='hidden'),
      DBClusterIPArrayName?: string(name='DBClusterIPArrayName', description='The name of the IP address whitelist.

Each cluster supports up to 50 IP address whitelists.', example='test'),
      securityIPList?: string(name='SecurityIPList', description='The IP addresses in the IP address whitelist. Up to 500 IP addresses can be returned. Multiple IP addresses are separated by commas (,).', example='127.0.xx.xx'),
    }
  ](name='IPArray')
  }(name='Items', description='The queried IP address whitelists.'),
  requestId?: string(name='RequestId', description='The request ID.', example='370D09FD-442A-5225-AAD3-7362CAE39177'),
}

model DescribeClusterAccessWhiteListResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeClusterAccessWhiteListResponseBody(name='body'),
}

async function describeClusterAccessWhiteList(request: DescribeClusterAccessWhiteListRequest): DescribeClusterAccessWhiteListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeClusterAccessWhiteList', 'POST', '/', 'json', false, 'json', request);
}

model DescribeClusterNetInfoRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~129857~~) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region, including cluster IDs.', example='amv-wz9dqvn0o7****', position='Query'),
}

model DescribeClusterNetInfoResponseBody = {
  clusterNetworkType?: string(name='ClusterNetworkType', description='The network type of the cluster. Only the Virtual Private Cloud (VPC) network type is supported. **VPC** is returned.', example='VPC'),
  items?: {
    address?: [ 
    {
      connectionString?: string(name='ConnectionString', description='The endpoint of the cluster.

*   If the network type of the cluster is VPC, the VPC endpoint of the cluster is returned.
*   If the network type of the cluster is Public, the public endpoint of the cluster is returned.', example='amv-wz9dqvn0o7****.ads.aliyuncs.com'),
      connectionStringPrefix?: string(name='ConnectionStringPrefix', description='The prefix of the endpoint.

*   If the network type of the cluster is VPC, the prefix of the private endpoint is returned.
*   If the network type of the cluster is Public, the prefix of the public endpoint is returned.', example='amv-wz9dqvn0o7****'),
      IPAddress?: string(name='IPAddress', description='The IP address of the endpoint.

*   If the network type of the cluster is VPC, the IP address of the private endpoint is returned.
*   If the network type of the cluster is Public, the IP address of the public endpoint is returned.', example='192.168.xx.xx'),
      netType?: string(name='NetType', description='The network type of the cluster. Valid values:

*   **Public**: Internet.
*   **VPC**: VPC.', example='VPC'),
      port?: string(name='Port', description='The port number that is used to connect to the cluster. **3306** is returned.', example='3306'),
      VPCId?: string(name='VPCId', description='The VPC ID.

> If NetType is set to Public, an empty string is returned for this parameter.', example='vpc-8vbhucmd5b****'),
      vSwitchId?: string(name='VSwitchId', description='The vSwitch ID of the cluster.

> If NetType is set to Public, an empty string is returned for this parameter.', example='vsw-bp1syh8vvw8yec****'),
    }
  ](name='Address')
  }(name='Items', description='The network information about the cluster.'),
  requestId?: string(name='RequestId', description='The request ID.', example='69A29B65-CD0C-52B1-BE42-8B454569747F'),
}

model DescribeClusterNetInfoResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeClusterNetInfoResponseBody(name='body'),
}

async function describeClusterNetInfo(request: DescribeClusterNetInfoRequest): DescribeClusterNetInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeClusterNetInfo', 'POST', '/', 'json', false, 'json', request);
}

model DescribeColumnsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1xxxxxxxx47', position='Query'),
  regionId: string(name='RegionId', description='The region ID.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
  tableName?: string(name='TableName', description='The name of the table.', example='test', position='Query'),
}

model DescribeColumnsResponseBody = {
  items?: {
    column?: [ 
    {
      autoIncrementColumn?: boolean(name='AutoIncrementColumn', description='Indicates whether the column is an auto-increment column. Valid values:

*   **true**
*   **false**', example='true'),
      columnName?: string(name='ColumnName', description='The name of the column.', example='id'),
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp111m2cfrdl1****'),
      primaryKey?: boolean(name='PrimaryKey', description='Indicates whether the column is the primary key of the table. Valid values:

*   **true**
*   **false**', example='false'),
      schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
      tableName?: string(name='TableName', description='The name of the table.', example='test'),
      type?: string(name='Type', description='The data type of the column.', example='bigint'),
    }
  ](name='Column')
  }(name='Items', description='The queried columns.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-XXX442913CEF'),
}

model DescribeColumnsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeColumnsResponseBody(name='body'),
}

async function describeColumns(request: DescribeColumnsRequest): DescribeColumnsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeColumns', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDBClusterAttributeRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Warehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****', position='Query'),
}

model DescribeDBClusterAttributeResponseBody = {
  items?: {
    DBCluster?: [ 
    {
      commodityCode?: string(name='CommodityCode', description='The billing method of the cluster. Valid values:

*   **ads**: pay-as-you-go.
*   **ads_pre**: subscription.', example='ads_pre'),
      computeResource?: string(name='ComputeResource', description='The specifications of reserved computing resources. Each ACU is equivalent to 1 core and 4 GB memory. Computing resources serve compute operations. The amount of computing resources is proportional to the query speed of the cluster. You can scale computing resources based on your needs.', example='16ACU'),
      computeResourceTotal?: string(name='ComputeResourceTotal', description='The total amount of computing resources in the cluster. Each ACU is equivalent to 1 core and 4 GB memory.', example='48ACU'),
      connectionString?: string(name='ConnectionString', description='The public endpoint that is used to connect to the cluster.', example='amv-wz9509beptiz****.ads.aliyuncs.com'),
      creationTime?: string(name='CreationTime', description='The time when the cluster was created. The time follows the ISO 8601 standard in the `yyyy-MM-ddThh:mm:ssZ` format. The time is displayed in UTC.', example='2022-07-01T09:50:18Z'),
      DBClusterDescription?: string(name='DBClusterDescription', description='The description of the cluster.', example='adb_test'),
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****'),
      DBClusterNetworkType?: string(name='DBClusterNetworkType', description='The network type of the cluster. **VPC** is returned.', example='VPC'),
      DBClusterStatus?: string(name='DBClusterStatus', description='The state of the cluster. Valid values:

*   **Preparing**: The cluster is being prepared.
*   **Creating**: The cluster is being created.
*   **Running**: The cluster is running.
*   **Deleting**: The cluster is being deleted.
*   **Restoring**: The cluster is being restored from a backup.
*   **ClassChanging**: The cluster specifications are being changed.
*   **NetAddressCreating**: A network connection is being created.
*   **NetAddressDeleting**: A network connection is being deleted.
*   **NetAddressModifying**: A network connection is being modified.', example='Running'),
      DBClusterType?: string(name='DBClusterType', description='The type of the cluster. By default, **Common** is returned, which indicates a common cluster.', example='Common'),
      DBVersion?: string(name='DBVersion', description='The engine version of the AnalyticDB for MySQL Data Lakehouse Edition cluster. **5.0** is returned.', example='5.0'),
      engine?: string(name='Engine', description='The engine of the cluster. **AnalyticDB** is returned.', example='AnalyticDB'),
      engineVersion?: string(name='EngineVersion', description='The minor version of the cluster.', example='3.1.16'),
      expireTime?: string(name='ExpireTime', description='The time when the cluster expires.

*   The expiration time is returned for a subscription cluster.
*   An empty string is returned for a pay-as-you-go cluster.', example='2022-10-01T09:50:18Z'),
      expired?: string(name='Expired', description='Indicates whether the subscription cluster has expired. Valid values:

*   **true**
*   **false**

> 

*   If the cluster has expired, the system locks or releases the cluster within a period of time. We recommend that you renew the expired cluster. For more information, see [Renewal policy](~~135248~~).

*   This parameter is not returned for pay-as-you-go clusters.', example='false'),
      lockMode?: string(name='LockMode', description='The lock mode of the cluster. Valid values:

*   **Unlock**: The cluster is not locked.
*   **ManualLock**: The cluster is manually locked.
*   **LockByExpiration**: The cluster is automatically locked after the cluster expires.', example='ManualLock'),
      lockReason?: string(name='LockReason', description='The reason why the cluster is locked.

> This parameter is returned only when the cluster was locked. The value is **instance_expire**.', example='instance_expire'),
      maintainTime?: string(name='MaintainTime', description='The maintenance window of the cluster. The time is displayed in the `HH:mmZ-HH:mmZ` format in UTC.

> For more information about maintenance windows, see [Configure a maintenance window](~~122569~~).', example='04:00Z-05:00Z'),
      mode?: string(name='Mode', description='The mode of the cluster. By default, **flexible** is returned, which indicates that the cluster is in elastic mode.', example='flexible'),
      payType?: string(name='PayType', description='The billing method of the cluster. Valid values:

*   **Postpaid**: pay-as-you-go.
*   **Prepaid**: subscription.', example='Prepaid'),
      port?: int32(name='Port', description='The port number that is used to connect to the cluster.', example='3306'),
      regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
      reservedACU?: string(name='ReservedACU', description='The amount of remaining reserved computing resources that are available in the cluster. Each ACU is equivalent to 1 core and 4 GB memory.', example='24ACU'),
      resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group.', example='rg-acfmyiu4ekp****'),
      storageResource?: string(name='StorageResource', description='The specifications of reserved storage resources. Each AnalyticDB compute unit (ACU) is equivalent to 1 core and 4 GB memory. Storage resources serve read and write requests. The amount of storage resources is proportional to the read and write performance of the cluster.', example='24ACU'),
      storageResourceTotal?: string(name='StorageResourceTotal', description='The total amount of storage resources in the cluster. Each ACU is equivalent to 1 core and 4 GB memory.', example='24ACU'),
      supportedFeatures?: map[string]string(name='SupportedFeatures'),
      tags?: {
        tag?: [ 
        {
          key?: string(name='Key'),
          value?: string(name='Value'),
        }
      ](name='Tag')
      }(name='Tags'),
      userENIStatus?: boolean(name='UserENIStatus', description='Indicates whether Elastic Network Interface (ENI) is enabled. Valid values:

*   **true**
*   **false**', example='false'),
      VPCId?: string(name='VPCId', description='The virtual private cloud (VPC) ID of the cluster.', example='vpc-bp13h7uzhulpu****'),
      vSwitchId?: string(name='VSwitchId', description='The vSwitch ID of the cluster.', example='vsw-uf629gydd54ld****'),
      zoneId?: string(name='ZoneId', description='The zone ID of the cluster.', example='cn-hangzhou-h'),
    }
  ](name='DBCluster')
  }(name='Items', description='The queried AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.'),
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model DescribeDBClusterAttributeResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDBClusterAttributeResponseBody(name='body'),
}

async function describeDBClusterAttribute(request: DescribeDBClusterAttributeRequest): DescribeDBClusterAttributeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDBClusterAttribute', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDBClusterHealthStatusRequest {
  DBClusterId: string(name='DBClusterId', example='amv-uf6o6m8p6x7v****', position='Query'),
  regionId: string(name='RegionId', example='cn-hangzhou', position='Query'),
}

model DescribeDBClusterHealthStatusResponseBody = {
  cs?: {
    activeCount?: long(name='ActiveCount', example='2'),
    expectedCount?: long(name='ExpectedCount', example='2'),
    riskCount?: long(name='RiskCount', example='0'),
    status?: string(name='Status', example='NORMAL'),
    unavailableCount?: long(name='UnavailableCount', example='0'),
  }(name='CS'),
  executor?: {
    activeCount?: long(name='ActiveCount', example='2'),
    expectedCount?: long(name='ExpectedCount', example='2'),
    riskCount?: long(name='RiskCount', example='0'),
    status?: string(name='Status', example='NORMAL'),
    unavailableCount?: long(name='UnavailableCount', example='0'),
  }(name='Executor'),
  instanceStatus?: string(name='InstanceStatus', example='NORMAL'),
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEA'),
  worker?: {
    activeCount?: long(name='ActiveCount', example='2'),
    expectedCount?: long(name='ExpectedCount', example='2'),
    riskCount?: long(name='RiskCount', example='0'),
    status?: string(name='Status', example='NORMAL'),
    unavailableCount?: long(name='UnavailableCount', example='0'),
  }(name='Worker'),
}

model DescribeDBClusterHealthStatusResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDBClusterHealthStatusResponseBody(name='body'),
}

async function describeDBClusterHealthStatus(request: DescribeDBClusterHealthStatusRequest): DescribeDBClusterHealthStatusResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDBClusterHealthStatus', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDBClusterPerformanceRequest {
  DBClusterId: string(name='DBClusterId', example='amv-bp1hx5n1o8f61****', position='Query'),
  endTime?: string(name='EndTime', example='2022-03-11T15:01Z', position='Query'),
  key?: string(name='Key', example='AnalyticDB_CPU_Usage_Percentage', position='Query'),
  regionId: string(name='RegionId', example='cn-hangzhou', position='Query'),
  resourcePools?: string(name='ResourcePools', example='user_default', position='Query'),
  startTime?: string(name='StartTime', example='2022-03-10T23:56Z', position='Query'),
}

model DescribeDBClusterPerformanceResponseBody = {
  DBClusterId?: string(name='DBClusterId', example='amv-bp1hx5n1o8f61****'),
  endTime?: string(name='EndTime', example='2022-03-11T15:01Z'),
  performances?: [ 
    {
      key?: string(name='Key', example='AnalyticDB_CPU_Usage_Percentage'),
      series?: [ 
        {
          name?: string(name='Name', example='AnalyticDB_Storage_CPU_Avg_Usage_Percentage'),
          tags?: string(name='Tags', example='{instance_name: "am-***"}'),
          values?: [ string ](name='Values'),
        }
      ](name='Series'),
      unit?: string(name='Unit', example='%'),
    }
  ](name='Performances'),
  requestId?: string(name='RequestId', example='BD8C3096-8BC6-51DF-A4AB-BACD9DC10435'),
  startTime?: string(name='StartTime', example='2022-03-10T23:56Z'),
}

model DescribeDBClusterPerformanceResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDBClusterPerformanceResponseBody(name='body'),
}

async function describeDBClusterPerformance(request: DescribeDBClusterPerformanceRequest): DescribeDBClusterPerformanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDBClusterPerformance', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDBClusterStatusRequest {
  regionId: string(name='RegionId', example='cn-hangzhou', position='Query'),
}

model DescribeDBClusterStatusResponseBody = {
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEAU'),
  status?: [ string ](name='Status'),
}

model DescribeDBClusterStatusResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDBClusterStatusResponseBody(name='body'),
}

async function describeDBClusterStatus(request: DescribeDBClusterStatusRequest): DescribeDBClusterStatusResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDBClusterStatus', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDBClustersRequest {
  DBClusterDescription?: string(name='DBClusterDescription', description='The description of the cluster.

*   The description cannot start with `http://` or `https://`.
*   The description must be 2 to 256 characters in length.', example='test', position='Query'),
  DBClusterIds?: string(name='DBClusterIds', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

If you do not specify this parameter, the information of all clusters that reside in the specified region is returned.', example='amv-bp1r053byu48p****', position='Query'),
  DBClusterStatus?: string(name='DBClusterStatus', description='The state of the cluster. Valid values:

*   **Preparing**: The cluster is being prepared.
*   **Creating**: The cluster is being created.
*   **Running**: The cluster is running.
*   **Deleting**: The cluster is being deleted.
*   **Restoring**: The cluster is being restored from a backup.
*   **ClassChanging**: The cluster specifications are being changed.
*   **NetAddressCreating**: A network connection is being created.
*   **NetAddressDeleting**: A network connection is being deleted.
*   **NetAddressModifying**: A network connection is being modified.', example='Running', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The number of the page to return. The value must be an integer that is greater than 0. Default value: **1**.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries to return on each page. Default value: 30. Valid values:

*   **30**
*   **50**
*   **100**', example='30', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group.

If you do not specify this parameter, the information of all resource groups in the cluster is returned.', example='rg-4690g37929****', position='Query'),
  tag?: [ 
    {
      key?: string(name='Key'),
      value?: string(name='Value'),
    }
  ](name='Tag', position='Query'),
}

model DescribeDBClustersResponseBody = {
  items?: {
    DBCluster?: [ 
    {
      commodityCode?: string(name='CommodityCode', description='The billing method of the cluster. Valid values:

*   **ads**: pay-as-you-go
*   **ads_pre**: subscription', example='ads_pre'),
      computeResource?: string(name='ComputeResource', description='The specifications of the reserved computing resources. Each ACU is equivalent to 1 core and 4 GB memory. Computing resources serve compute operations. The amount of computing resources is proportional to the query speed of the cluster. You can scale computing resources based on your needs.', example='16ACU'),
      connectionString?: string(name='ConnectionString', description='The public endpoint of the cluster.', example='amv-bp163885f8q21****.ads.aliyuncs.com'),
      createTime?: string(name='CreateTime', description='The time when the cluster was created. The time follows the ISO 8601 standard in the *yyyy-mm-ddThh:mm:ssZ* format. The time is displayed in UTC.', example='2022-04-01T09:50:18Z'),
      DBClusterDescription?: string(name='DBClusterDescription', description='The description of the cluster.', example='adb_test'),
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp163885f8q21****'),
      DBClusterNetworkType?: string(name='DBClusterNetworkType', description='The network type of the cluster. **VPC** is returned.', example='VPC'),
      DBClusterStatus?: string(name='DBClusterStatus', description='The state of the cluster. Valid values:

*   **Preparing**: The cluster is being prepared.
*   **Creating**: The cluster is being created.
*   **Running**: The cluster is running.
*   **Deleting**: The cluster is being deleted.
*   **Restoring**: The cluster is being restored from a backup.
*   **ClassChanging**: The cluster specifications are being changed.
*   **NetAddressCreating**: A network connection is being created.
*   **NetAddressDeleting**: A network connection is being deleted.
*   **NetAddressModifying**: A network connection is being modified.', example='Running'),
      DBClusterType?: string(name='DBClusterType', description='The type of the cluster. By default, **Common** is returned, which indicates a common cluster.', example='Common'),
      DBVersion?: string(name='DBVersion', description='The version of the AnalyticDB for MySQL Data Lakehouse Edition cluster. Only the version **5.0** is supported.', example='5.0'),
      engine?: string(name='Engine', description='The engine of the cluster. **AnalyticDB** is returned.', example='AnalyticDB'),
      expireTime?: string(name='ExpireTime', description='The time when the cluster expired. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.

> *   The expiration time is returned for a subscription cluster.
> *   An empty string is returned for a pay-as-you-go cluster.', example='2022-07-01T09:50:18Z'),
      expired?: string(name='Expired', description='Indicates whether the subscription cluster has expired. Valid values:

*   **true**: The cluster has expired.
*   **false**: The cluster has not expired.

> *   If the cluster has expired, the system locks or releases the cluster within a specific time period. We recommend that you renew expired clusters. For more information, see [Renewal policy](~~135246~~).
> *  This parameter is not returned for pay-as-you-go clusters.', example='false'),
      lockMode?: string(name='LockMode', description='The lock state of the instance. Valid values:

*   **Unlock**: The cluster is not locked.
*   **ManualLock**: The cluster is manually locked.
*   **LockByExpiration**: The cluster is automatically locked due to cluster expiration.', example='Unlock'),
      lockReason?: string(name='LockReason', description='The reason why the cluster is locked.

>  This parameter is returned only when the cluster is locked. The value is **instance_expire**.', example='instance_expired'),
      mode?: string(name='Mode', description='The mode of the cluster. By default, **flexible** is returned, which indicates that the cluster is in elastic mode.', example='flexible'),
      payType?: string(name='PayType', description='The billing method of the cluster. Valid values:

*   **Postpaid**: pay-as-you-go
*   **Prepaid**: subscription', example='Prepaid'),
      port?: string(name='Port', description='The port number that is used to connect to the cluster.', example='3306'),
      regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
      reservedACU?: string(name='ReservedACU', description='The remaining reserved computing resources that are available in the cluster. Each ACU is equivalent to 1 core and 4 GB memory.', example='32ACU'),
      resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group.', example='rg-acfmyiu4ekp****'),
      storageResource?: string(name='StorageResource', description='The specifications of the reserved storage resources. Each AnalyticDB compute unit (ACU) is equivalent to 1 core and 4 GB memory. Storage resources serve read and write requests. The amount of storage resources is proportional to the read and write performance of the cluster.', example='24ACU'),
      tags?: {
        tag?: [ 
        {
          key?: string(name='Key'),
          value?: string(name='Value'),
        }
      ](name='Tag')
      }(name='Tags'),
      VPCId?: string(name='VPCId', description='The ID of the virtual private cloud (VPC).', example='vpc-bp13h7uzhulpuxvnp****'),
      vSwitchId?: string(name='VSwitchId', description='The vSwitch ID of the cluster.', example='vsw-bp1syh8vvw8yech7n****'),
      zoneId?: string(name='ZoneId', description='The zone ID of the cluster.', example='cn-hangzhou-h'),
    }
  ](name='DBCluster')
  }(name='Items', description='Details of the clusters.'),
  pageNumber?: int32(name='PageNumber', description='The page number of the returned page.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries returned on each page.', example='30'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5EDBA27-AF3E-5966-9503-FD1557E19167'),
  totalCount?: int32(name='TotalCount', description='The total number of entries.', example='1'),
}

model DescribeDBClustersResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDBClustersResponseBody(name='body'),
}

async function describeDBClusters(request: DescribeDBClustersRequest): DescribeDBClustersResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDBClusters', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDBResourceGroupRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  groupName?: string(name='GroupName', description='The name of the resource group.

> If you do not specify this parameter, the information about all resource groups in the cluster is returned.', example='test_group', position='Query'),
  groupType?: string(name='GroupType', description='The type of the resource group. Valid values:

*   **Interactive**
*   **Job**

> For information about resource groups of Data Lakehouse Edition, see [Resource groups](~~428610~~).', example='Job', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
}

model DescribeDBResourceGroupResponseBody = {
  groupsInfo?: [ 
    {
      clusterMode?: string(name='ClusterMode'),
      clusterSizeResource?: string(name='ClusterSizeResource'),
      createTime?: string(name='CreateTime', description='The time when the resource group was created. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.', example='2022-08-29T03:34:30Z'),
      elasticMinComputeResource?: string(name='ElasticMinComputeResource', description='The amount of minimum elastic computing resources. Unit: ACU.', example='16ACU'),
      groupName?: string(name='GroupName', description='The name of the resource group.', example='test1'),
      groupType?: string(name='GroupType', description='The type of the resource group. Valid values:

*   **Interactive**
*   **Job**

> For information about resource groups of Data Lakehouse Edition, see [Resource groups](~~428610~~).', example='Job'),
      groupUsers?: string(name='GroupUsers', description='The Resource Access Management (RAM) user with which the resource group is associated.', example='testb,testc'),
      maxClusterCount?: int32(name='MaxClusterCount'),
      maxComputeResource?: string(name='MaxComputeResource', description='The maximum amount of reserved computing resources. Unit: ACU.', example='512ACU'),
      minClusterCount?: int32(name='MinClusterCount'),
      minComputeResource?: string(name='MinComputeResource', description='The minimum amount of reserved computing resources. Unit: AnalyticDB compute unit (ACU).', example='0ACU'),
      runningClusterCount?: int32(name='RunningClusterCount'),
      status?: string(name='Status', description='The state of the resource group. Valid values:

*   **creating**
*   **ok**
*   **pendingdelete**', example='ok'),
      updateTime?: string(name='UpdateTime', description='The time when the resource group was updated. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.', example='2022-08-31T03:34:30Z'),
    }
  ](name='GroupsInfo', description='The queried resource groups.'),
  requestId?: string(name='RequestId', description='The request ID.', example='A94B6C02-7BD4-5D67-9776-3AC8317E8DD3'),
}

model DescribeDBResourceGroupResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDBResourceGroupResponseBody(name='body'),
}

async function describeDBResourceGroup(request: DescribeDBResourceGroupRequest): DescribeDBResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDBResourceGroup', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDiagnosisDimensionsRequest {
  DBClusterId: string(name='DBClusterId', example='amv-bt6u59zcmd945****', position='Query'),
  endTime?: string(name='EndTime', example='1625220213000', position='Query'),
  lang?: string(name='Lang', example='zh-CN', position='Query'),
  queryCondition?: string(name='QueryCondition', example='{"Type":"maxCost","Value":"100"}', position='Query'),
  regionId: string(name='RegionId', example='cn-hangzhou', position='Query'),
  startTime?: string(name='StartTime', example='1625220210000', position='Query'),
}

model DescribeDiagnosisDimensionsResponseBody = {
  clientIps?: [ string ](name='ClientIps'),
  databases?: [ string ](name='Databases'),
  requestId?: string(name='RequestId', example='DEA97C6B-D7A4-5E69-9EFC-D7F88737CED5'),
  resourceGroups?: [ string ](name='ResourceGroups'),
  userNames?: [ string ](name='UserNames'),
}

model DescribeDiagnosisDimensionsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDiagnosisDimensionsResponseBody(name='body'),
}

async function describeDiagnosisDimensions(request: DescribeDiagnosisDimensionsRequest): DescribeDiagnosisDimensionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDiagnosisDimensions', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDiagnosisRecordsRequest {
  clientIp?: string(name='ClientIp', example='59.82.XX.XX', position='Query'),
  DBClusterId: string(name='DBClusterId', example='amv-bp1scs48yc125****', position='Query'),
  database?: string(name='Database', example='adb_demo', position='Query'),
  endTime?: string(name='EndTime', example='1633017540000', position='Query'),
  keyword?: string(name='Keyword', example='select', position='Query'),
  lang?: string(name='Lang', example='zh', position='Query'),
  maxPeakMemory?: long(name='MaxPeakMemory', example='89000000', position='Query'),
  maxScanSize?: long(name='MaxScanSize', example='1024000000', position='Query'),
  minPeakMemory?: long(name='MinPeakMemory', example='0', position='Query'),
  minScanSize?: long(name='MinScanSize', example='0', position='Query'),
  order?: string(name='Order', example='[{"Field":"StartTime", "Type": "desc" }]', position='Query'),
  pageNumber?: int32(name='PageNumber', example='1', position='Query'),
  pageSize?: int32(name='PageSize', example='30', position='Query'),
  patternId?: string(name='PatternId', example='5575924945138******', position='Query'),
  queryCondition?: string(name='QueryCondition', example='{"Type":"status","Value":"finished"}', position='Query'),
  regionId: string(name='RegionId', example='cn-hangzhou', position='Query'),
  resourceGroup?: string(name='ResourceGroup', example='user_default', position='Query'),
  startTime?: string(name='StartTime', example='1632931200000', position='Query'),
  userName?: string(name='UserName', example='test_user', position='Query'),
}

model DescribeDiagnosisRecordsResponseBody = {
  pageNumber?: int32(name='PageNumber', example='1'),
  pageSize?: int32(name='PageSize', example='30'),
  querys?: [ 
    {
      clientIp?: string(name='ClientIp', example='59.82.XX.XX'),
      cost?: long(name='Cost', example='10'),
      database?: string(name='Database', example='adb_demo'),
      etlWriteRows?: long(name='EtlWriteRows', example='0'),
      executionTime?: long(name='ExecutionTime', example='6'),
      outputDataSize?: long(name='OutputDataSize', example='9'),
      outputRows?: long(name='OutputRows', example='1'),
      peakMemory?: long(name='PeakMemory', example='16648'),
      processId?: string(name='ProcessId', example='2021093000414401000000023503151******'),
      queueTime?: long(name='QueueTime', example='6'),
      rcHost?: string(name='RcHost', example='10.0.XX.XX:3004'),
      resourceCostRank?: int32(name='ResourceCostRank', example='1'),
      resourceGroup?: string(name='ResourceGroup', example='user_default'),
      SQL?: string(name='SQL', example='SELECT count(*)\\nFROM nation'),
      SQLTruncated?: boolean(name='SQLTruncated', example='false'),
      SQLTruncatedThreshold?: long(name='SQLTruncatedThreshold', example='5120'),
      scanRows?: long(name='ScanRows', example='1'),
      scanSize?: long(name='ScanSize', example='9'),
      startTime?: long(name='StartTime', example='1632933704000'),
      status?: string(name='Status', example='finished'),
      totalPlanningTime?: long(name='TotalPlanningTime', example='4'),
      totalStages?: int32(name='TotalStages', example='2'),
      userName?: string(name='UserName', example='test_user'),
    }
  ](name='Querys'),
  requestId?: string(name='RequestId', example='7F88BEFA-CF0B-5C95-8BB1-92EC9F09E40D'),
  totalCount?: int32(name='TotalCount', example='1'),
}

model DescribeDiagnosisRecordsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDiagnosisRecordsResponseBody(name='body'),
}

async function describeDiagnosisRecords(request: DescribeDiagnosisRecordsRequest): DescribeDiagnosisRecordsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDiagnosisRecords', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDiagnosisSQLInfoRequest {
  DBClusterId: string(name='DBClusterId', example='amv-bp1r053byu48p', position='Query'),
  lang: string(name='Lang', example='zh', position='Query'),
  processId: string(name='ProcessId', example='2021070216432217201616806503453', position='Query'),
  processRcHost?: string(name='ProcessRcHost', example='192.45.***.***:3145', position='Query'),
  processStartTime?: long(name='ProcessStartTime', example='1625215402000', position='Query'),
  processState?: string(name='ProcessState', example='running', position='Query'),
  regionId: string(name='RegionId', example='cn-hangzhou', position='Query'),
}

model DescribeDiagnosisSQLInfoResponseBody = {
  diagnosisSQLInfo?: string(name='DiagnosisSQLInfo', example='{     "DiagnosisSQLInfo": {         "hasSharedStage": false,         "resourceGroup": "user_default",         "cost": 274,         "queuedTime": 0,         "outputDataSize": 9,         "scheduled": true,         "query": "/*+display=tpch_q14*/SELECT 100.00 * SUM(CASE WHEN p_type LIKE \\"PROMO%\\" THEN l_extendedprice * (1 - l_discount) ELSE 0 END) / SUM(l_extendedprice * (1 - l_discount)) AS promo_revenue FROM lineitem l, part p WHERE l_partkey = p_partkey AND l_shipdate &gt;= DATE \\"1995-09-01\\" AND l_shipdate &lt; DATE \\"1995-09-01\\" + INTERVAL \\"1\\" MONTH",         "outputRows": 1,         "userName": "test_user",         "parentId": 0,         "maxOutputRows": 200000,         "scanSize": 8247470,         "peakMemory": 13188295,         "startTime": 1626330527632,         "state": "FINISHED",         "endTime": 1626330527905,         "writeTableRows": 0,         "scanRows": 351966     } }'),
  requestId?: string(name='RequestId', example='1'),
  stageInfos?: [ 
    {
      inputDataSize?: long(name='InputDataSize', example='2341'),
      inputRows?: long(name='InputRows', example='2341'),
      operatorCost?: long(name='OperatorCost', example='2341'),
      outputDataSize?: long(name='OutputDataSize', example='2341'),
      outputRows?: long(name='OutputRows', example='2341'),
      peakMemory?: long(name='PeakMemory', example='2341'),
      progress?: double(name='Progress', example='0.3'),
      stageId?: string(name='StageId', description='StageID。', example='Stage[26]'),
      state?: string(name='State', example='RUNNING'),
    }
  ](name='StageInfos'),
}

model DescribeDiagnosisSQLInfoResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDiagnosisSQLInfoResponseBody(name='body'),
}

async function describeDiagnosisSQLInfo(request: DescribeDiagnosisSQLInfoRequest): DescribeDiagnosisSQLInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDiagnosisSQLInfo', 'GET', '/', 'json', false, 'json', request);
}

model DescribeDownloadRecordsRequest {
  DBClusterId: string(name='DBClusterId', example='amv-8vb6ha79k6e****', position='Query'),
  lang?: string(name='Lang', example='zh', position='Query'),
  regionId: string(name='RegionId', example='cn-hangzhou', position='Query'),
}

model DescribeDownloadRecordsResponseBody = {
  records?: [ 
    {
      downloadId?: long(name='DownloadId', example='636890'),
      exceptionMsg?: string(name='ExceptionMsg', example='The query result is empty.'),
      fileName?: string(name='FileName', example='20210806094635-20210806095135'),
      status?: string(name='Status', example='finished'),
      url?: string(name='Url', example='https://perth-download-task.oss-cn-beijing.aliyuncs.com/adbmysql/query-sql-logs/amv-*********/20210805104301-20210805164302.xlsx?Expires=1943514161&OSSAccessKeyId=*********&Signature=******"'),
    }
  ](name='Records'),
  requestId?: string(name='RequestId', example='D761DA51-12F8-5457-AAA9-F52B9F436D2D'),
}

model DescribeDownloadRecordsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeDownloadRecordsResponseBody(name='body'),
}

async function describeDownloadRecords(request: DescribeDownloadRecordsRequest): DescribeDownloadRecordsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDownloadRecords', 'POST', '/', 'json', false, 'json', request);
}

model DescribeElasticPlanAttributeRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the ID of an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the name of a scaling plan.', example='test', position='Query'),
}

model DescribeElasticPlanAttributeResponseBody = {
  elasticPlan?: {
    autoScale?: boolean(name='AutoScale', description='Indicates whether **Proportional Default Scaling for EIUs** is enabled.

Valid values:

true: Proportional Default Scaling for EIUs is enabled. If you set this parameter to true, the amount of storage resources scales along with the computing resources.

false: Proportional Default Scaling for EIUs is not enabled.

>  You can enable Proportional Default Scaling for EIUs for only a single scaling plan of a cluster.', example='false'),
    cronExpression?: string(name='CronExpression', description='A CORN expression that indicates the scaling cycle and time for the scaling plan.', example='0 20 14 * * ?'),
    elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.', example='test'),
    enabled?: boolean(name='Enabled', description='Indicates whether the scaling plan was enabled.', example='true'),
    endTime?: string(name='EndTime', description='The end time of the scaling plan.

>  The time follows the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time is displayed in UTC.', example='2025-01-01T12:01:00Z'),
    resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.', example='test'),
    startTime?: string(name='StartTime', description='The start time of the scaling plan.

>  The time follows the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time is displayed in UTC.', example='2022-01-01T12:01:00Z'),
    targetSize?: string(name='TargetSize', description='The amount of elastic resources after scaling.', example='32ACU'),
    type?: string(name='Type', description='The type of the scaling plan.', example='EXECUTOR'),
  }(name='ElasticPlan', description='Details of the scaling plan.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model DescribeElasticPlanAttributeResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeElasticPlanAttributeResponseBody(name='body'),
}

async function describeElasticPlanAttribute(request: DescribeElasticPlanAttributeRequest): DescribeElasticPlanAttributeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeElasticPlanAttribute', 'POST', '/', 'json', false, 'json', request);
}

model DescribeElasticPlanJobsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the ID of an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.

> *   If you do not specify this parameter, all scaling plans of the cluster are queried.
> *   You can call the [DescribeElasticPlans](~~601334~~) operation to query the name of a scaling plan.', example='test', position='Query'),
  pageNumber: int32(name='PageNumber', description='The number of the page to return.', example='1', position='Query'),
  pageSize: int32(name='PageSize', description='The number of scaling plan jobs to return per page.', example='10', position='Query'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> *   If you do not specify this parameter, the scaling plans of all resource groups are queried, including interactive resource groups and elastic I/O units (EIUs).
> *   You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group within a specific cluster.', example='test', position='Query'),
  startTime?: string(name='StartTime', description='The time to enable the scaling plan job.

Specify the time in the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time must be in UTC.', example='2022-01-01T12:01:00Z', position='Query'),
  status?: string(name='Status', description='The state of the scaling plan job.

Valid values:

*   RUNNING: The job is running.

*   SUCCESSFUL: The job is successfully run.

*   FAILED: The job fails.

> If you do not specify this parameter, scaling plan jobs in all states are queried.', example='SUCCESSFUL', position='Query'),
}

model DescribeElasticPlanJobsResponseBody = {
  jobs?: [ 
    {
      elasticAcu?: string(name='ElasticAcu', description='The amount of elastic resources.

> *   If the Type parameter is set to EXECUTOR, ElasticAcu indicates the amount of elastic resources in the current resource group.
> *   If the Type parameter is set to WORKER, ElasticAcu indicates the total amount of elastic storage resources in the current cluster.', example='16ACU'),
      elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.', example='test'),
      endTime?: string(name='EndTime', description='The time when the scaling plan job was complete.

>  The time follows the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time is displayed in UTC.', example='2022-01-01T12:01:00Z'),
      instanceSize?: int32(name='InstanceSize', description='The number of instances.

> *   If the Type parameter is set to EXECUTOR, InstanceSize indicates the number of compute nodes.
> *   If the Type parameter is set to EXECUTOR, InstanceSize indicates the number of replica sets at the storage layer in the cluster.', example='1'),
      reserveAcu?: string(name='ReserveAcu', description='The amount of reserved resources.

> *   If the Type parameter is set to EXECUTOR, ReserveAcu indicates the amount of reserved resources in the current resource group.
> *   If the Type parameter is set to WORKER, ReserveAcu indicates the total amount of reserved storage resources in the current cluster.', example='16ACU'),
      resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.', example='test'),
      startTime?: string(name='StartTime', description='The time when the scaling plan job was enabled.

>  The time follows the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time is displayed in UTC.', example='2022-01-01T11:01:00Z'),
      status?: string(name='Status', description='The state of the scaling plan job.

Valid values:

*   RUNNING: The job is running.
*   SUCCESSFUL: The job is successfully run.
*   FAILED: The job fails.', example='SUCCESSFUL'),
      targetSize?: string(name='TargetSize', description='The amount of elastic resources after scaling.', example='32ACU'),
      totalAcu?: string(name='TotalAcu', description='The total amount of resources.

> *   If the Type parameter is set to EXECUTOR, TotalAcu indicates the total amount of computing resources in the current resource group.
> *   If the Type parameter is set to WORKER, TotalAcu indicates the total amount of storage resources in the cluster.', example='32ACU'),
      type?: string(name='Type', description='The type of the scaling plan job.

Valid values:

*   EXECUTOR: interactive resource groups, which fall into the computing resource category.
*   WORKER: EIUs.', example='EXECUTOR'),
    }
  ](name='Jobs', description='Details of the scaling plan jobs.'),
  pageNumber?: int32(name='PageNumber', description='The page number of the returned page.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of scaling plan jobs returned per page.', example='10'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
  totalCount?: int32(name='TotalCount', description='The total number of scaling plan jobs.', example='15'),
}

model DescribeElasticPlanJobsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeElasticPlanJobsResponseBody(name='body'),
}

async function describeElasticPlanJobs(request: DescribeElasticPlanJobsRequest): DescribeElasticPlanJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeElasticPlanJobs', 'POST', '/', 'json', false, 'json', request);
}

model DescribeElasticPlanSpecificationsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the ID of an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****', position='Query'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> *   This parameter is required only when you query the resource specifications that can be scaled for an interactive resource group.
> *   You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group within a specific cluster.', example='test', position='Query'),
  type: string(name='Type', description='The type of the scaling plan. Valid values:

*   EXECUTOR: interactive resource groups, which fall into the computing resource category.
*   WORKER: EIUs.', example='EXECUTOR', position='Query'),
}

model DescribeElasticPlanSpecificationsResponseBody = {
  pageNumber?: int32(name='PageNumber', description='The page number of the returned page.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of resource specifications returned per page.', example='5'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
  specifications?: [ string ](name='Specifications', description='The resource specifications that can be scaled.'),
  totalCount?: int32(name='TotalCount', description='The number of resource specifications that can be scaled.', example='10'),
}

model DescribeElasticPlanSpecificationsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeElasticPlanSpecificationsResponseBody(name='body'),
}

async function describeElasticPlanSpecifications(request: DescribeElasticPlanSpecificationsRequest): DescribeElasticPlanSpecificationsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeElasticPlanSpecifications', 'POST', '/', 'json', false, 'json', request);
}

model DescribeElasticPlansRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

> You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.

> If you do not specify this parameter, all scaling plans are queried.', example='test', position='Query'),
  enabled?: boolean(name='Enabled', description='Indicates whether the scaling plan was immediately enabled after the plan is created. Valid values:

*   true
*   false', example='true', position='Query'),
  pageNumber: int32(name='PageNumber', description='The page number.', example='1', minimum=1, position='Query'),
  pageSize: int32(name='PageSize', description='The number of entries per page.', example='10', minimum=1, position='Query'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> *   If you do not specify this parameter, the scaling plans of all resource groups are queried, covering the interactive resource group type and the elastic I/O unit (EIU) type.
>*   You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group within a cluster.', example='test', position='Query'),
  type?: string(name='Type', description='The type of the scaling plan. Valid values:

*   EXECUTOR: interactive resource groups, which fall into the computing resource category.
*   WORKER: EIUs.', example='EXECUTOR', position='Query'),
}

model DescribeElasticPlansResponseBody = {
  elasticPlans?: [ 
    {
      autoScale?: boolean(name='AutoScale', description='Indicates whether **Proportional Default Scaling for EIUs** is enabled. Valid values:

*   true
*   false', example='false'),
      elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.', example='test'),
      enabled?: boolean(name='Enabled', description='Indicates whether the scaling plan was immediately enabled after the plan is created. Valid values:

*   true
*   false', example='true'),
      nextScheduleTime?: string(name='NextScheduleTime', description='The time when the next scheduling is performed.

> The time is in the yyyy-MM-ddTHH:mm:ssZ format.', example='2022-01-01T12:01:00Z'),
      resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group within a cluster.', example='test'),
      targetSize?: string(name='TargetSize', description='The amount of elastic resources after scaling.', example='32ACU'),
      type?: string(name='Type', description='The type of the scaling plan. Valid values:

*   EXECUTOR: interactive resource group.
*   WORKER: EIU.', example='EXECUTOR'),
    }
  ](name='ElasticPlans', description='The scaling plans.'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='15'),
}

model DescribeElasticPlansResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeElasticPlansResponseBody(name='body'),
}

async function describeElasticPlans(request: DescribeElasticPlansRequest): DescribeElasticPlansResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeElasticPlans', 'POST', '/', 'json', false, 'json', request);
}

model DescribeEnabledPrivilegesRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp14t95lun0w****', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model DescribeEnabledPrivilegesResponseBody = {
  data?: [ 
    {
      description: string(name='Description', description='The description of the permission level.'),
      privileges: [ 
        {
          description?: string(name='Description', description='The description of the permission.'),
          key?: string(name='Key', description='The name of the permission.', example='select'),
        }
      ](name='Privileges', description='Details of the permissions.'),
      scope: string(name='Scope', description='The permission level.', example='Global'),
    }
  ](name='Data', description='The permission levels and specific permissions.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='246F42E0-A475-15FF-96D2-8DC47FC2F289'),
}

model DescribeEnabledPrivilegesResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeEnabledPrivilegesResponseBody(name='body'),
}

async function describeEnabledPrivileges(request: DescribeEnabledPrivilegesRequest): DescribeEnabledPrivilegesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeEnabledPrivileges', 'GET', '/', 'json', false, 'json', request);
}

model DescribePatternPerformanceRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

> You can call the [DescribeDBClusters](~~129857~~) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region, including cluster IDs.', example='amv-uf6li1r3do8m****', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to query. Specify the time in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.

> The end time must be later than the start time.', example='2022-08-22T01:06:00Z', position='Query'),
  patternId: string(name='PatternId', description='The ID of the SQL pattern.

> You can call the [DescribeSQLPatterns](~~321868~~) operation to query the information about all SQL patterns in an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster within a period of time, including SQL pattern IDs.', example='3847585356974******', position='Query'),
  regionId: string(name='RegionId', description='The region ID.', example='cn-hangzhou', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.

> 

*   If the current date is August 22, 2022 (UTC+8), you can query the data of August 9, 2022 (2022-08-08T16:00:00Z) to the earliest extent. If you want to query the data that is earlier than August 9, 2022 (2022-08-08T16:00:00Z), null is returned.

*   The maximum time range that can be specified is 24 hours.', example='2022-08-21T02:15:00Z', position='Query'),
}

model DescribePatternPerformanceResponseBody = {
  endTime?: string(name='EndTime', description='The end time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time is displayed in UTC.', example='2022-08-22T01:06:00Z'),
  performances?: [ 
    {
      key?: string(name='Key', example='AnalyticDB_PatternExecutionTime'),
      series?: [ 
        {
          name?: string(name='Name', example='max_query_time'),
          values?: [ string ](name='Values'),
        }
      ](name='Series'),
      unit?: string(name='Unit', example='ms'),
    }
  ](name='Performances', description='The name of the performance metric value. Valid values:

*   When the `Key` parameter is set to `AnalyticDB_PatternQueryCount`, `pattern_query_count` is returned, which indicates the number of executions of the SQL statements in association with the SQL pattern.

*   When the `Key` value is `AnalyticDB_PatternQueryTime`, the following values are returned:

    *   `average_query_time`, which indicates the average total amount of time consumed by the SQL statements in association with the SQL pattern.
    *   `max_query_time`, which indicates the maximum total amount of time consumed by the SQL statements in association with the SQL pattern.

*   When the `Key` value is `AnalyticDB_PatternExecutionTime`, the following values are returned:

    *   `average_execution_time`, which indicates the average execution duration of the SQL statements in association with the SQL pattern.
    *   `max_execution_time`, which indicates the maximum execution duration of the SQL statements in association with the SQL pattern.

*   When the `Key` value is `AnalyticDB_PatternPeakMemory`, the following values are returned:

    *   `average_peak_memory`, which indicates the average peak memory usage of the SQL statements in association with the SQL pattern.
    *   `max_peak_memory`, which indicates the maximum peak memory usage of the SQL statements in association with the SQL pattern.

*   When the `Key` value is `AnalyticDB_PatternScanSize`, the following values are returned:

    *   `average_scan_size`, which indicates the average amount of data scanned by the SQL statements in association with the SQL pattern.
    *   `max_scan_size`, which indicates the maximum amount of data scanned by the SQL statements in association with the SQL pattern.'),
  requestId?: string(name='RequestId', description='The request ID.', example='F21AF487-B8C9-57E0-8E3A-A92BC3611FB6'),
  startTime?: string(name='StartTime', description='The start time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time is displayed in UTC.', example='2022-08-21T02:15:00Z'),
}

model DescribePatternPerformanceResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribePatternPerformanceResponseBody(name='body'),
}

async function describePatternPerformance(request: DescribePatternPerformanceRequest): DescribePatternPerformanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribePatternPerformance', 'POST', '/', 'json', false, 'json', request);
}

model DescribeRegionsRequest {
  acceptLanguage?: string(name='AcceptLanguage', description='The language used for the region and zone names specified by the LocalName parameter. Default value: zh-CN. Valid values:

*   **zh-CN**: simplified Chinese
*   **en-US**: English
*   **ja**: Japanese', example='en-US', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model DescribeRegionsResponseBody = {
  regions?: {
    region?: [ 
    {
      localName?: string(name='LocalName', description='The name of the region.', example='China (Hangzhou)'),
      regionEndpoint?: string(name='RegionEndpoint', description='The endpoint of the region.', example='adb.aliyuncs.com'),
      regionId?: string(name='RegionId', description='The ID of the region.', example='cn-hangzhou'),
      zones?: {
        zone?: [ 
        {
          localName?: string(name='LocalName', description='The name of the zone.', example='Hangzhou Zone H'),
          vpcEnabled?: boolean(name='VpcEnabled', description='Indicates whether Virtual Private Cloud (VPC) is supported in the zone. Valid values:

*   **true**: VPC is supported.
*   **false**: VPC is not supported.', example='true'),
          zoneId?: string(name='ZoneId', description='The ID of the zone.', example='cn-hangzhou-h'),
        }
      ](name='Zone')
      }(name='Zones', description='Details of the zones.'),
    }
  ](name='Region')
  }(name='Regions', description='Details of the regions.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='421794A3-72A5-5D27-9E8B-A75A4C503E17'),
}

model DescribeRegionsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeRegionsResponseBody(name='body'),
}

async function describeRegions(request: DescribeRegionsRequest): DescribeRegionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeRegions', 'POST', '/', 'json', false, 'json', request);
}

model DescribeSQLPatternsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~129857~~) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region, including cluster IDs.', example='amv-8vb8de93v9b****', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.

> The end time must be later than the start time.', example='2022-09-07T03:06:00Z', position='Query'),
  keyword?: string(name='Keyword', description='The keyword that is used for the query.', example='SELECT', position='Query'),
  lang?: string(name='Lang', description='The language. Valid values:

*   **zh** (default): simplified Chinese.
*   **en**: English.
*   **ja**: Japanese.
*   **zh-tw**: traditional Chinese.', example='zh', position='Query'),
  order: string(name='Order', description='The order by which to sort query results. Specify the parameter value in the JSON string format. Example: `[{"Field":"AverageQueryTime","Type":"Asc"}]`. Parameters:

*   `Field` specifies the field by which to sort the query results. Valid values:

    *   `PatternCreationTime`: the earliest commit time of the SQL pattern within the time range to query.
    *   `AverageQueryTime`: the average total amount of time consumed by the SQL pattern within the time range to query.
    *   `MaxQueryTime`: the maximum total amount of time consumed by the SQL pattern within the time range to query.
    *   `AverageExecutionTime`: the average execution duration of the SQL pattern within the time range to query.
    *   `MaxExecutionTime`: the maximum execution duration of the SQL pattern within the time range to query.
    *   `AveragePeakMemory`: the average peak memory usage of the SQL pattern within the time range to query.
    *   `MaxPeakMemory`: the maximum peak memory usage of the SQL pattern within the time range to query.
    *   `AverageScanSize`: the average amount of data scanned based on the SQL pattern within the time range to query.
    *   `MaxScanSize`: the maximum amount of data scanned based on the SQL pattern within the time range to query.
    *   `QueryCount`: the number of queries performed in association with the SQL pattern within the time range to query.
    *   `FailedCount`: the number of failed queries performed in association with the SQL pattern within the time range to query.

*   `Type` specifies the sorting order. Valid values (case-insensitive):

    *   `Asc`: ascending order.
    *   `Desc`: descending order.', example='[{"Field":"AverageQueryTime","Type":"Asc"}]', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='2', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **10** (default)
*   **30**
*   **50**
*   **100**', example='10', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.

> 

*   Only data within the last 14 days can be queried.

*   The maximum time range that can be specified is 24 hours.', example='2022-09-06T03:06:00Z', position='Query'),
}

model DescribeSQLPatternsResponseBody = {
  pageNumber?: int32(name='PageNumber', description='The page number.', example='2'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  patternDetails?: [ 
    {
      accessIp?: string(name='AccessIp', example='192.168.xx.xx'),
      averageExecutionTime?: double(name='AverageExecutionTime', example='234.78'),
      averagePeakMemory?: double(name='AveragePeakMemory', example='234.22'),
      averageQueryTime?: double(name='AverageQueryTime', example='4'),
      averageScanSize?: double(name='AverageScanSize', example='234149.23'),
      blockable?: boolean(name='Blockable', example='true'),
      failedCount?: long(name='FailedCount', example='18'),
      maxExecutionTime?: long(name='MaxExecutionTime', example='2142'),
      maxPeakMemory?: long(name='MaxPeakMemory', example='234149'),
      maxQueryTime?: long(name='MaxQueryTime', example='2341'),
      maxScanSize?: long(name='MaxScanSize', example='32212254'),
      patternCreationTime?: string(name='PatternCreationTime', example='2022-09-06 05:06:00'),
      patternId?: string(name='PatternId', example='5575924945138******'),
      queryCount?: long(name='QueryCount', example='345'),
      SQLPattern?: string(name='SQLPattern', example='SELECT * FROM KEPLER_META_NODE_STATIC_INFO WHERE elastic_node = ? OR (elastic_node = ? AND enable = ?)'),
      tables?: string(name='Tables', example='tpch.orders'),
      user?: string(name='User', example='test'),
    }
  ](name='PatternDetails', description='Indicates whether the execution of the SQL pattern can be blocked. Valid values:

*   **true**
*   **false**

> Only SELECT and INSERT statements can be blocked.'),
  requestId?: string(name='RequestId', description='The request ID.', example='F3174013-5B7A-5A47-9FE0-6B5D397BD86B'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='20'),
}

model DescribeSQLPatternsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeSQLPatternsResponseBody(name='body'),
}

async function describeSQLPatterns(request: DescribeSQLPatternsRequest): DescribeSQLPatternsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSQLPatterns', 'POST', '/', 'json', false, 'json', request);
}

model DescribeSchemasRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1xxxxxxxx47', position='Query'),
  regionId: string(name='RegionId', description='The region ID.', example='cn-hangzhou', position='Query'),
}

model DescribeSchemasResponseBody = {
  items?: {
    schema?: [ 
    {
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
      schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
    }
  ](name='Schema')
  }(name='Items', description='The queried databases.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25B56BC7-4978-40B3-9E48-4B7067******'),
}

model DescribeSchemasResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeSchemasResponseBody(name='body'),
}

async function describeSchemas(request: DescribeSchemasRequest): DescribeSchemasResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSchemas', 'POST', '/', 'json', false, 'json', request);
}

model DescribeSparkCodeLogRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-uf6o6m8p6x7v****', position='Query'),
  jobId: long(name='JobId', description='The ID of the Spark job.', example='1248', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model DescribeSparkCodeLogResponseBody = {
  log?: string(name='Log', description='The content of the log.', example='>>>>>>>> stdout:n++++++++++++++++++executing sql: MSCK REPAIR TABLE  `footprint_ethereum`.`dwd_eth_eth_txr_v2_di` n++n'),
  message?: string(name='Message', description='The returned message.

*   If the request was successful, **Success** is returned.
*   If the request failed, an error message is returned.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='1CD65640-9963-5D60-929C-118F2C84070E'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeSparkCodeLogResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeSparkCodeLogResponseBody(name='body'),
}

async function describeSparkCodeLog(request: DescribeSparkCodeLogRequest): DescribeSparkCodeLogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSparkCodeLog', 'POST', '/', 'json', false, 'json', request);
}

model DescribeSparkCodeOutputRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-uf6210mmev07****', position='Query'),
  jobId: long(name='JobId', description='The ID of the Spark job.', example='620', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model DescribeSparkCodeOutputResponseBody = {
  message?: string(name='Message', description='The returned message.

*   If the request was successful, **Success** is returned.
*   If the request failed, an error message is returned.', example='Success'),
  output?: string(name='Output', description='The execution result, which is in the format of JSON objects.', example='"{\\"schema\\":[\\"id\\",\\"name\\",\\"age\\"],\\"data\\":[\\"{\\\\\\"id\\\\\\":10,\\\\\\"name\\\\\\":\\\\\\"z\\\\\\",\\\\\\"age\\\\\\":123}\\",\\"{\\\\\\"id\\\\\\":2,\\\\\\"name\\\\\\":\\\\\\"b\\\\\\",\\\\\\"age\\\\\\":17}\\",\\"{\\\\\\"id\\\\\\":1,\\\\\\"name\\\\\\":\\\\\\"a\\\\\\",\\\\\\"age\\\\\\":15}\\",\\"{\\\\\\"id\\\\\\":3,\\\\\\"name\\\\\\":\\\\\\"c\\\\\\",\\\\\\"age\\\\\\":222}\\",\\"{\\\\\\"id\\\\\\":10,\\\\\\"name\\\\\\":\\\\\\"z\\\\\\",\\\\\\"age\\\\\\":123}\\"],\\"haveRows\\":true,\\"rowNumber\\":6}"'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeSparkCodeOutputResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeSparkCodeOutputResponseBody(name='body'),
}

async function describeSparkCodeOutput(request: DescribeSparkCodeOutputRequest): DescribeSparkCodeOutputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSparkCodeOutput', 'POST', '/', 'json', false, 'json', request);
}

model DescribeSparkCodeWebUiRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1v6usq6m65****', position='Query'),
  jobId: long(name='JobId', description='The ID of the Spark job.', example='1248', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model DescribeSparkCodeWebUiResponseBody = {
  message?: string(name='Message', description='The returned message.

*   If the request was successful, **SUCCESS** is returned.
*   If the request failed, an error message is returned.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='774DDC37-1908-58F6-B9CA-99E3E45965A6'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
  url?: string(name='Url', description='The URL of the web UI for the Spark application.', example='https://adb-subuser-cn-hangzhou-1358535755648527-100000648.oss-cn-hangzhou.aliyuncs.com/%3Facl?Expires=1681295967&OSSAccessKeyId=LTAI5tB7NAkm25oiGASu****&Signature=hKAZ1vgvhJ%2FD8hNHTuX%2FOOBWht****'),
}

model DescribeSparkCodeWebUiResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeSparkCodeWebUiResponseBody(name='body'),
}

async function describeSparkCodeWebUi(request: DescribeSparkCodeWebUiRequest): DescribeSparkCodeWebUiResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSparkCodeWebUi', 'POST', '/', 'json', false, 'json', request);
}

model DescribeSqlPatternRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1ej1nq9n6****', position='Query'),
  order?: string(name='Order', description='The order by which to sort query results. Specify the parameter value in the JSON string format. Example: `[{"Field":"Pattern","Type":"Asc"}]`. Parameters:

*   `Field` specifies the field by which to sort the query results. Valid values:

    *   `Pattern`: the SQL pattern.
    *   `AccessIP`: the IP address of the client.
    *   `User`: the username.
    *   `QueryCount`: the number of queries performed in association with the SQL pattern within the time range to query.
    *   `AvgPeakMemory`: the average peak memory usage of the SQL pattern within the time range to query. Unit: KB.
    *   `MaxPeakMemory`: the maximum peak memory usage of the SQL pattern within the time range to query. Unit: KB.
    *   `AvgCpuTime`: the average execution duration of the SQL pattern within the time range to query. Unit: milliseconds.
    *   `MaxCpuTime`: the maximum execution duration of the SQL pattern within the time range to query. Unit: milliseconds.
    *   `AvgStageCount`: the average number of stages.
    *   `MaxStageCount`: the maximum number of stages.
    *   `AvgTaskCount`: the average number of tasks.
    *   `MaxTaskCount`: the maximum number of tasks.
    *   `AvgScanSize`: the average amount of data scanned based on the SQL pattern within the time range to query. Unit: KB.
    *   `MaxScanSize`: the maximum amount of data scanned based on the SQL pattern within the time range to query. Unit: KB.

*   `Type` specifies the sorting order. Valid values:

    *   `Asc`: ascending order.
    *   `Desc`: descending order.

> 

*   If you do not specify this parameter, query results are sorted in ascending order of `Pattern`.

*   If you want to sort query results by `AccessIP`, you must set the `Type` parameter to `accessip`. If you want to sort query results by `User`, you must leave the `Type` parameter empty or set it to `user`.', example='[{"Field":"Pattern","Type":"Asc"}]', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='2', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **10** (default)
*   **30**
*   **50**
*   **100**', example='30', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
  sqlPattern?: string(name='SqlPattern', description='The keyword that is used for the query.

> If you do not specify this parameter, all SQL patterns of the AnalyticDB for MySQL cluster within the time period specified by `StartTime` are returned.', example='SELECT', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-dd format. The time must be in UTC.

> Only data within the last 30 days can be queried.', example='2022-08-30T12:10:00Z', position='Query'),
  type?: string(name='Type', description='The dimension by which to aggregate the SQL patterns. Valid values:

*   `user`: aggregates the SQL patterns by user.
*   `accessip`: aggregates the SQL patterns by client IP address.

> If you do not specify this parameter, the SQL patterns are aggregated by `user`.', example='user', position='Query'),
}

model DescribeSqlPatternResponseBody = {
  items?: [ 
    {
      accessIP?: string(name='AccessIP', example='100.104.xx.xx'),
      avgCpuTime?: string(name='AvgCpuTime', example='1.0625'),
      avgPeakMemory?: string(name='AvgPeakMemory', example='240048'),
      avgScanSize?: string(name='AvgScanSize', example='244'),
      avgStageCount?: string(name='AvgStageCount', example='2'),
      avgTaskCount?: string(name='AvgTaskCount', example='2'),
      instanceName?: string(name='InstanceName', example='amv-bp1ej1nq9n6****'),
      maxCpuTime?: string(name='MaxCpuTime', example='17'),
      maxPeakMemory?: string(name='MaxPeakMemory', example='480096'),
      maxScanSize?: string(name='MaxScanSize', example='1024'),
      maxStageCount?: string(name='MaxStageCount', example='2'),
      maxTaskCount?: string(name='MaxTaskCount', example='2'),
      pattern?: string(name='Pattern', description='SQL Pattern。', example='SELECT table_name, table_schema AS schema_name, create_time, create_time AS last_ddl_time, table_comment AS description , ceil((data_length + index_length) / ? / ?) AS store_capacity , data_length AS data_bytes, index_length AS index_bytes, table_collation AS collation, auto_increment, table_rows AS num_rows , engine FROM information_schema.tables WHERE table_type != ? AND table_schema = ? AND table_name IN (?) ORDER BY 1'),
      queryCount?: string(name='QueryCount', example='16'),
      reportDate?: string(name='ReportDate', example='2022-08-30'),
      user?: string(name='User', example='test_acc'),
    }
  ](name='Items', description='The average number of tasks.'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='2'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='DB1F6C23-CBCA-5260-9366-BA7BB5EBF6F1'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='50'),
}

model DescribeSqlPatternResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeSqlPatternResponseBody(name='body'),
}

async function describeSqlPattern(request: DescribeSqlPatternRequest): DescribeSqlPatternResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSqlPattern', 'POST', '/', 'json', false, 'json', request);
}

model DescribeTableAccessCountRequest {
  DBClusterId: string(name='DBClusterId', example='amv-2ze627uzpkh8a8****', position='Query'),
  order?: string(name='Order', example='[{"Field":"TableSchema","Type":"Asc"}]', position='Query'),
  pageNumber?: int32(name='PageNumber', example='1', position='Query'),
  pageSize?: int32(name='PageSize', example='30', position='Query'),
  regionId: string(name='RegionId', example='cn-hangzhou', position='Query'),
  startTime?: string(name='StartTime', example='2022-09-25T12:10:00Z', position='Query'),
  tableName?: string(name='TableName', example='CUSTOMER', position='Query'),
}

model DescribeTableAccessCountResponseBody = {
  items?: [ 
    {
      accessCount?: string(name='AccessCount', example='6'),
      instanceName?: string(name='InstanceName', example='amv-2ze627uzpkh8a8****'),
      reportDate?: string(name='ReportDate', example='2022-09-26'),
      tableName?: string(name='TableName', example='CUSTOMER'),
      tableSchema?: string(name='TableSchema', example='tpch'),
    }
  ](name='Items'),
  pageNumber?: int32(name='PageNumber', example='1'),
  pageSize?: int32(name='PageSize', example='30'),
  requestId?: string(name='RequestId', example='6B7D627B-DA23-572D-AD71-256F64698B7D'),
  totalCount?: int32(name='TotalCount', example='1'),
}

model DescribeTableAccessCountResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeTableAccessCountResponseBody(name='body'),
}

async function describeTableAccessCount(request: DescribeTableAccessCountRequest): DescribeTableAccessCountResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeTableAccessCount', 'POST', '/', 'json', false, 'json', request);
}

model DescribeTablesRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1xxxxxxxx47', position='Query'),
  regionId: string(name='RegionId', description='The region ID.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
}

model DescribeTablesResponseBody = {
  items?: {
    table?: [ 
    {
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1xxxxxxxx47'),
      schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
      tableName?: string(name='TableName', description='The name of the table.', example='test'),
    }
  ](name='Table')
  }(name='Items', description='The queried tables.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DescribeTablesResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeTablesResponseBody(name='body'),
}

async function describeTables(request: DescribeTablesRequest): DescribeTablesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeTables', 'POST', '/', 'json', false, 'json', request);
}

model DescribeUserQuotaRequest {
  DBClusterId: string(name='DBClusterId', example='amv-bp1qjt3o18d86987', position='Query'),
}

model DescribeUserQuotaResponseBody = {
  elasticACU?: string(name='ElasticACU', example='512ACU'),
  requestId?: string(name='RequestId', example='0322C7FB-4584-5D2A-BF7F-F9036E940C35'),
  reserverdCompteACU?: string(name='ReserverdCompteACU', example='48ACU'),
  reserverdStorageACU?: string(name='ReserverdStorageACU', example='24ACU'),
  resourceGroupCount?: string(name='ResourceGroupCount', example='10'),
}

model DescribeUserQuotaResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DescribeUserQuotaResponseBody(name='body'),
}

async function describeUserQuota(request: DescribeUserQuotaRequest): DescribeUserQuotaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeUserQuota', 'GET', '/', 'json', false, 'json', request);
}

model DetachUserENIRequest {
  DBClusterId: string(name='DBClusterId', example='am-bp11q28kvl688****', position='Query'),
}

model DetachUserENIResponseBody = {
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DetachUserENIResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DetachUserENIResponseBody(name='body'),
}

async function detachUserENI(request: DetachUserENIRequest): DetachUserENIResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DetachUserENI', 'POST', '/', 'json', false, 'json', request);
}

model DisableElasticPlanRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the ID of an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the name of a scaling plan for a specific cluster.', example='test', position='Query'),
}

model DisableElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model DisableElasticPlanResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DisableElasticPlanResponseBody(name='body'),
}

async function disableElasticPlan(request: DisableElasticPlanRequest): DisableElasticPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DisableElasticPlan', 'POST', '/', 'json', false, 'json', request);
}

model DownloadDiagnosisRecordsRequest {
  clientIp?: string(name='ClientIp', example='106.11.XX.XX', position='Query'),
  DBClusterId: string(name='DBClusterId', example='amv-bp1q8bu9a****', position='Query'),
  database?: string(name='Database', example='adb_demo', position='Query'),
  endTime?: string(name='EndTime', example='1662450730000', position='Query'),
  keyword?: string(name='Keyword', example='select', position='Query'),
  lang?: string(name='Lang', example='zh', position='Query'),
  maxPeakMemory?: long(name='MaxPeakMemory', example='88000000', position='Query'),
  maxScanSize?: long(name='MaxScanSize', example='64424509440', position='Query'),
  minPeakMemory?: long(name='MinPeakMemory', example='88000000', position='Query'),
  minScanSize?: long(name='MinScanSize', example='1073741824', position='Query'),
  queryCondition?: string(name='QueryCondition', example='{"Type":"status","Value":"finished"}', position='Query'),
  regionId: string(name='RegionId', example='cn-hangzhou', position='Query'),
  resourceGroup?: string(name='ResourceGroup', example='user_default', position='Query'),
  startTime?: string(name='StartTime', example='1662364330000', position='Query'),
  userName?: string(name='UserName', example='test_user', position='Query'),
}

model DownloadDiagnosisRecordsResponseBody = {
  downloadId?: int32(name='DownloadId', example='25494'),
  requestId?: string(name='RequestId', example='845774AC-5D43-53A2-AAB8-C73828E68508'),
}

model DownloadDiagnosisRecordsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: DownloadDiagnosisRecordsResponseBody(name='body'),
}

async function downloadDiagnosisRecords(request: DownloadDiagnosisRecordsRequest): DownloadDiagnosisRecordsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DownloadDiagnosisRecords', 'POST', '/', 'json', false, 'json', request);
}

model EnableElasticPlanRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the ID of an AnalyticDB for MySQL Data Warehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the name of a scaling plan for a specific cluster.', example='test', position='Query'),
}

model EnableElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model EnableElasticPlanResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: EnableElasticPlanResponseBody(name='body'),
}

async function enableElasticPlan(request: EnableElasticPlanRequest): EnableElasticPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'EnableElasticPlan', 'POST', '/', 'json', false, 'json', request);
}

model ExistRunningSQLEngineRequest {
  DBClusterId: string(name='DBClusterId', example='amv-bp1cit7z8j****', position='Body'),
  resourceGroupName: string(name='ResourceGroupName', example='spark_test', position='Body'),
}

model ExistRunningSQLEngineResponseBody = {
  data?: boolean(name='Data', example='True'),
  requestId?: string(name='RequestId', example='FA675D68-14A4-5D9C-8820-92537D9F447E'),
}

model ExistRunningSQLEngineResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ExistRunningSQLEngineResponseBody(name='body'),
}

async function existRunningSQLEngine(request: ExistRunningSQLEngineRequest): ExistRunningSQLEngineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ExistRunningSQLEngine', 'POST', '/', 'json', true, 'form', request);
}

model GetDatabaseObjectsRequest {
  DBClusterId?: string(name='DBClusterId', description='The cluster ID.', example='am-bp1565u55p32****', position='Query'),
  filterOwner?: string(name='FilterOwner', description='The owner of the database.', example='admin', position='Query'),
  filterSchemaName?: string(name='FilterSchemaName', description='The name of the database.', example='test_db', position='Query'),
  orderBy?: string(name='OrderBy', description='The order in which you want to sort the query results. Valid values:

*   Asc
*   Desc

Valid values for Field: DatabaseName, CreateTime, and UpdateTime. -CreateTime; -UpdateTime;

Default value: {"Type": "Desc","Field": "DatabaseName"}.', example='{"Type": "Desc","Field": "DbName"}', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   30
*   50
*   100

Default value: 30.', example='30', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the database.', example='cn-hangzhou', position='Query'),
}

model GetDatabaseObjectsResponseBody = {
  data?: {
    databaseSummaryModels?: [
      DatabaseSummaryModel
    ](name='DatabaseSummaryModels', description='The queried database.'),
    pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   30
*   50
*   100

Default value: 30.', example='30'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The queried databases.'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='863D51B7-5321-41D8-A0B6-A088B0******'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model GetDatabaseObjectsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetDatabaseObjectsResponseBody(name='body'),
}

async function getDatabaseObjects(request: GetDatabaseObjectsRequest): GetDatabaseObjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDatabaseObjects', 'POST', '/', 'json', false, 'json', request);
}

model GetSparkAppAttemptLogRequest {
  attemptId: string(name='AttemptId', description='The ID of the log.

> You can call the [ListSparkAppAttempts](~~455887~~) operation to query the information about the retry attempts of a Spark application, including the retry log IDs.', example='s202207151211hz****-0001', maxLength=72, position='Body'),
  logLength?: long(name='LogLength', description='The number of log entries to return. Valid values: 1 to 500. Default value: 300.', example='20', minimum=0, maximum=500, position='Body'),
}

model GetSparkAppAttemptLogResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The application ID.', example='s202204132018hzprec1ac61a000****'),
    DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-clusterxxx'),
    logContent?: string(name='LogContent', description='The content of the log.', example='22/04/22 15:30:49 INFO Utils: Start the dump task because s202207151211hz****-0001 app end, the interval is 238141ms;22/04/22 15:30:49 INFO AbstractConnector: Stopped Spark@5e774d9d{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}'),
    message?: string(name='Message', description='The alert message returned for the request, such as task execution failure or insufficient resources. If no alert occurs, null is returned.', example='WARNING: log file maybe deleted, please check oss path: oss://TestBucketName/applog/'),
  }(name='Data', description='The queried log.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C3A9594F-1D40-4472-A96C-8FB8AA20D38C'),
}

model GetSparkAppAttemptLogResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkAppAttemptLogResponseBody(name='body'),
}

async function getSparkAppAttemptLog(request: GetSparkAppAttemptLogRequest): GetSparkAppAttemptLogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkAppAttemptLog', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkAppInfoRequest {
  appId: string(name='AppId', description='The ID of the application. 

>  You can call the [ListSparkApps](~~612475~~) operation to query the Spark application ID.', example='s202205201533hz1209892000****', maxLength=64, position='Body'),
}

model GetSparkAppInfoResponseBody = {
  data?: SparkAppInfo(name='Data', description='Details of the Spark application. Fields in the response parameter:

- **Data**: the data of the Spark application template.
- **EstimateExecutionCpuTimeInSeconds**: the amount of time it takes to consume CPU resources for running the Spark application. Unit: milliseconds.
- **LogRootPath**: the storage path of log files.
- **LastAttemptId**: the most recent attempt ID.
- **WebUiAddress**: the web UI URL.
- **SubmittedTimeInMillis**: the time when the Spark application was submitted. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
- **StartedTimeInMillis**: the time when the Spark application was created. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
- **LastUpdatedTimeInMillis**: the time when the Spark application was last updated. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
- **TerminatedTimeInMillis**: the time when the Spark application task was terminated. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
- **DBClusterId**: the ID of the cluster on which the Spark application runs.
- **ResourceGroupName**: the name of the job resource group.
- **DurationInMillis**: the amount of time it takes to run the Spark application. Unit: milliseconds.', example='{     \\"name\\": \\"SparkPi\\",     \\"file\\": \\"local:///tmp/spark-examples.jar\\",     \\"className\\": \\"org.apache.spark.examples.SparkPi\\",     \\"args\\": [         \\"1000000\\"     ],     \\"conf\\": {         \\"spark.driver.resourceSpec\\": \\"small\\",         \\"spark.executor.instances\\": 1,         \\"spark.executor.resourceSpec\\": \\"small\\"     } }",
      "EstimateExecutionCpuTimeInSeconds" : 100,
      "LogRootPath" : "oss://test/logs/driver",
      "LastAttemptId" : "s202204291426hzpre60cfabb0000004-0003",
      "WebUiAddress" : "https://sparkui.aliyuncs.com/token=xxx",
      "SubmittedTimeInMillis" : 1651213645000,
      "StartedTimeInMillis" : 1651213645010,
      "LastUpdatedTimeInMillis" : 1651213645200,
      "TerminatedTimeInMillis" : 1651213645300,
      "DBClusterId" : "am-dbclusterid",
      "ResourceGroupName" : "spark-rg",
      "DurationInMillis" : 100
    }'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkAppInfoResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkAppInfoResponseBody(name='body'),
}

async function getSparkAppInfo(request: GetSparkAppInfoRequest): GetSparkAppInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkAppInfo', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkAppLogRequest {
  appId: string(name='AppId', description='The Spark application ID.

> You can call the [ListSparkApps](~~612475~~) operation to query the Spark application ID.', example='s202206061441hz22a35ab000****', position='Body'),
  logLength?: long(name='LogLength', description='The number of log entries to return. Valid values: 1 to 500. Default value: 300.', example='20', minimum=0, maximum=500, position='Body'),
}

model GetSparkAppLogResponseBody = {
  data?: {
    DBClusterId?: string(name='DBClusterId', description='The ID of the Data Lakehouse Edition (V3.0) cluster.', example='amv-clusterxxx'),
    logContent?: string(name='LogContent', description='The content of the log.', example='22/04/22 15:30:49 INFO Utils: Start the dump task because s202206061441hz22a35ab000****-0001 app end, the interval is 238141ms;22/04/22 15:30:49 INFO AbstractConnector: Stopped Spark@5e774d9d{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}'),
    message?: string(name='Message', description='The alert message returned for the request, such as task execution failure or insufficient resources. If no alert occurs, null is returned.', example='WARNING:  log file maybe deleted, please check oss path: oss://TestBucketName/applog/'),
  }(name='Data', description='The queried log.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C3A9594F-1D40-4472-A96C-8FB8AA20D38C'),
}

model GetSparkAppLogResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkAppLogResponseBody(name='body'),
}

async function getSparkAppLog(request: GetSparkAppLogRequest): GetSparkAppLogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkAppLog', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkAppMetricsRequest {
  appId: string(name='AppId', description='The ID of the Spark application.', example='s202204221525hzca7d8140000003', maxLength=64, position='Body'),
}

model GetSparkAppMetricsResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark application.', example='s202302051515shfa865f80003691'),
    attemptId?: string(name='AttemptId', description='The attempt ID of the Spark application.', example='s202301061000hz57d797b0000201-0001'),
    eventLogPath?: string(name='EventLogPath', description='The path of the event log.', example='oss://path/to/eventLog'),
    finished?: boolean(name='Finished', description='Indicates whether parsing is complete. Valid values:

*   true
*   false', example='True'),
    scanMetrics?: {
      outputRowsCount?: long(name='OutputRowsCount', description='The number of scanned rows.', example='1000'),
      totalReadFileSizeInByte?: long(name='TotalReadFileSizeInByte', description='The number of scanned bytes.', example='10000'),
    }(name='ScanMetrics', description='The metrics.'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model GetSparkAppMetricsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkAppMetricsResponseBody(name='body'),
}

async function getSparkAppMetrics(request: GetSparkAppMetricsRequest): GetSparkAppMetricsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkAppMetrics', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkAppStateRequest {
  appId: string(name='AppId', description='The ID of the application.', example='s202204191546hzpread6a896000****', maxLength=64, position='Body'),
}

model GetSparkAppStateResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the application.', example='s202204191546hzpread6a896000****'),
    appName?: string(name='AppName', description='The name of the application.', example='test'),
    DBClusterId?: string(name='DBClusterId', description='The ID of the Database.', example='amv-clusterxxx'),
    message?: string(name='Message', description='The alert message returned for the operation, such as task execution failure or insufficient resources. Null is returned if no alert occurs.', example='Insufficient resources.'),
    state?: string(name='State', description='The execution state of the application. Valid values:

*   **SUBMITTED**: The application is submitted.
*   **STARTING**: The application task is starting.
*   **RUNNING**: The application task is being executed.
*   **FAILING**: The application task failed, and the environment is being cleared.
*   **FAILED**: The application task failed.
*   **KILLING**: The application task is terminated, and the environment is being cleared.
*   **KILLED**: The application task is terminated.
*   **SUCCEEDING**: The application task is completed, and the environment is being cleared.
*   **COMPLETED**: The application task is completed.
*   **FATAL**: An unexpected failure occurred.
*   **UNKNOWN**: An unknown error occurred.', example='COMPLETED'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkAppStateResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkAppStateResponseBody(name='body'),
}

async function getSparkAppState(request: GetSparkAppStateRequest): GetSparkAppStateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkAppState', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkAppWebUiAddressRequest {
  appId: string(name='AppId', description='The ID of the Spark application.', example='s202205201533hz1209892000****', maxLength=64, position='Body'),
}

model GetSparkAppWebUiAddressResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark application.', example='s202205201533hz1209892000****'),
    DBClusterId?: string(name='DBClusterId', description='The ID of the Database.', example='amv-clusterxxx'),
    expirationTimeInMillis?: long(name='ExpirationTimeInMillis', description='The expiration time. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since the epoch time January 1, 1970, 00:00:00 UTC.', example='1655801973000'),
    webUiAddress?: string(name='WebUiAddress', description='The URL of the web UI for the Spark application.', example='https://adbsparkui-cn-hangzhou.aliyuncs.com/?token=****'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkAppWebUiAddressResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkAppWebUiAddressResponseBody(name='body'),
}

async function getSparkAppWebUiAddress(request: GetSparkAppWebUiAddressRequest): GetSparkAppWebUiAddressResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkAppWebUiAddress', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkConfigLogPathRequest {
  DBClusterId: string(name='DBClusterId', description='The database ID.', example='am-adsdxxxx', maxLength=64, position='Body'),
}

model GetSparkConfigLogPathResponseBody = {
  data?: {
    defaultLogPath?: string(name='DefaultLogPath', description='The recommended default log path.', example='oss://aliyun-oa-adb-spark-1111-oss-cn-hanghzou/spark-logs'),
    isLogPathExists?: boolean(name='IsLogPathExists', description='Indicates whether a log path exists.', example='true'),
    modifiedTimestamp?: string(name='ModifiedTimestamp', description='The time when the configuration was last modified.', example='1675654361000'),
    modifiedUid?: string(name='ModifiedUid', description='The modifier ID.', example='10130223128xxx'),
    recordedLogPath?: string(name='RecordedLogPath', description='The log path.', example='oss://test/spark-logs/'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1919-xxx-ssdfsdff'),
}

model GetSparkConfigLogPathResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkConfigLogPathResponseBody(name='body'),
}

async function getSparkConfigLogPath(request: GetSparkConfigLogPathRequest): GetSparkConfigLogPathResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkConfigLogPath', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkDefinitionsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the cluster.', example='amv-clusterxxx', position='Body'),
}

model GetSparkDefinitionsResponseBody = {
  data?: string(name='Data', description='The common definitions of Spark applications.', example='{"SQLTemplateExample": "-- Here is just an example of SparkSQL. Modify the content and run your spark program.
conf spark.driver.resourceSpec=medium;
conf spark.executor.instances=2;
conf spark.executor.resourceSpec=medium;
conf spark.app.name=Spark SQL Test;
conf spark.adb.connectors=oss;

-- Here are your sql statements
show databases;",
                 "BatchTemplateExample": "{
    "comments": [
        "-- Here is just an example of SparkPi. Modify the content and run your spark program."
    ],
    "args": ["1000"],
  "file":"local:///tmp/spark-examples.jar",
    "name": "SparkPi",
    "className": "org.apache.spark.examples.SparkPi",
    "conf": {      "spark.driver.resourceSpec": "medium",
        "spark.executor.instances": 2,
        "spark.executor.resourceSpec": "medium"
    }
}"'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkDefinitionsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkDefinitionsResponseBody(name='body'),
}

async function getSparkDefinitions(request: GetSparkDefinitionsRequest): GetSparkDefinitionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkDefinitions', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkLogAnalyzeTaskRequest {
  taskId: long(name='TaskId', description='The ID of the Spark log analysis task. You can call the ListSparkLogAnalyzeTasks operation to query the IDs of all Spark log analysis tasks that are submitted in the current cluster.', example='12', minimum=0, position='Body'),
}

model GetSparkLogAnalyzeTaskResponseBody = {
  data?: SparkAnalyzeLogTask(name='Data', description='The information about the Spark log analysis task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1DF5AF5B-C803-1861-A0FF-63666A557709'),
}

model GetSparkLogAnalyzeTaskResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkLogAnalyzeTaskResponseBody(name='body'),
}

async function getSparkLogAnalyzeTask(request: GetSparkLogAnalyzeTaskRequest): GetSparkLogAnalyzeTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkLogAnalyzeTask', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkSQLEngineStateRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Body'),
  resourceGroupName: string(name='ResourceGroupName', description='The name of the job resource group.', example='test_instance', position='Body'),
}

model GetSparkSQLEngineStateResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark application.', example='s202207151211hz0c****'),
    config?: string(name='Config', description='The configuration of the Spark application.', example='{"key1": "value1", "key2": "value2"}'),
    jars?: string(name='Jars', description='The third-party JAR package.', example='oss://test-bucket/test.jar'),
    maxExecutor?: string(name='MaxExecutor', description='The maximum number of started Spark executors.', example='3'),
    minExecutor?: string(name='MinExecutor', description='The minimum number of started Spark executors.', example='1'),
    slotNum?: string(name='SlotNum', description='The slot number of the Spark application.', example='2'),
    state?: string(name='State', description='The execution state of the application. Valid values:

*   SUBMITTED
*   STARTING
*   RUNNING
*   FAILING
*   FAILED
*   KILLING
*   KILLED
*   SUCCEEDING
*   COMPLETED
*   FATAL
*   UNKNOWN', example='COMPLETED'),
    submittedTimeInMillis?: string(name='SubmittedTimeInMillis', description='The timestamp when the Spark SQL application was submitted. Unit: milliseconds.', example='1651213645000'),
  }(name='Data', description='The state information about the Spark SQL engine.'),
  requestId?: string(name='RequestId', description='The request ID.', example='xxxx-xxx-xx'),
}

model GetSparkSQLEngineStateResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkSQLEngineStateResponseBody(name='body'),
}

async function getSparkSQLEngineState(request: GetSparkSQLEngineStateRequest): GetSparkSQLEngineStateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkSQLEngineState', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkTemplateFileContentRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-8vbn8pq537k8w****', maxLength=64, position='Body'),
  id: long(name='Id', description='The ID of the application template.

>  You can call the [GetSparkTemplateFullTree](~~456205~~) operation to query the template ID.', example='725204', minimum=0, position='Body'),
}

model GetSparkTemplateFileContentResponseBody = {
  data?: {
    appType?: string(name='AppType', description='The type of the application. Valid values:

*   **SQL**: SQL application
*   **STREAMING**: streaming application
*   **BATCH**: batch application', example='SQL'),
    content?: string(name='Content', description='The content of the template.', example='set spark.driver.resourceSpec=medium;set spark.executor.instances=2;set spark.executor.resourceSpec=medium;set spark.app.name=Spark SQL Test;'),
    id?: long(name='Id', description='The ID of the application template.', example='725204'),
    resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.', example='test'),
    type?: string(name='Type', description='The type of the file. Valid values:

*   **folder**
*   **file**', example='file'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkTemplateFileContentResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkTemplateFileContentResponseBody(name='body'),
}

async function getSparkTemplateFileContent(request: GetSparkTemplateFileContentRequest): GetSparkTemplateFileContentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkTemplateFileContent', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkTemplateFolderTreeRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', maxLength=64, position='Body'),
}

model GetSparkTemplateFolderTreeResponseBody = {
  data?: string(name='Data', description='The directory structure of Spark applications, which is in the tree format. Fields in the response parameter:

*   **Uid**: the UID of the Alibaba Cloud account.

*   **Type**: the type of the application template. Valid values: **FOLDER**: directory.

*   **Parent**: indicates whether a child directory exists. Valid values:

    *   **0**: No child directory exists.
    *   **-1**: A child directory exists.

*   **Children**: the child directory.

*   **LastModified**: the time when applications in the directory are last modified. The time is displayed in the UNIX timestamp format. Unit: seconds.

*   **Name**: the name of the directory.

*   **Id**: the ID of the directory.', example='{           "Uid":195813423****,           "Type":"FOLDER",          "Parent":-1,           "Children":[              {                     "LastModified":1647853173,               "Uid":195813423****,                     "Type":"FOLDER",                     "Parent":0,                     "Id":157,                     "Name":"t"         }       ],            "Id":725204,            "Name":"root"      }'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model GetSparkTemplateFolderTreeResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkTemplateFolderTreeResponseBody(name='body'),
}

/**
  * You can call this operation to query the directory structure but not application data in the directory. To query the directory structure that contains application data, call the [GetSparkTemplateFullTree](~~456205~~) operation.
  *
 */
async function getSparkTemplateFolderTree(request: GetSparkTemplateFolderTreeRequest): GetSparkTemplateFolderTreeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkTemplateFolderTree', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkTemplateFullTreeRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', maxLength=64, position='Body'),
}

model GetSparkTemplateFullTreeResponseBody = {
  data?: string(name='Data', description='The directory structure of the application template. Fields in the response parameter:

*   **Uid**: the UID of the Alibaba Cloud account.

*   **Type**: the type of the application template. Valid values:

    *   **FOLDER**: directory
    *   **FILE**: application

*   **Parent**: the parent directory. Valid values:

    *   **0**: No child directory exists.
    *   **-1**: A child directory exists.

*   **Children**: the child directory.

*   **LastModified**: the time when the application is last modified. The time is displayed in the UNIX timestamp format. Unit: seconds.

*   **AppType**: the application type. Valid values:

    *   **SQL**: SQL application
    *   **STREAMING**: streaming application
    *   **BATCH**: batch application

*   **Name**: the name of the directory or application.

*   **Id**: the ID of the directory or application.', example='{     "Uid": 10415777****,     "Type": "FOLDER",     "Parent": -1,     "Children": [       {         "LastModified": 1648544748,         "Uid": 104157779****,         "Type": "FILE",         "Parent": 0,         "Id": s202204132****,         "AppType": "SQL",         "Name": "f"       },       {         "LastModified": 1648544956,         "Uid": 1041577795****,         "Type": "FOLDER",         "Parent": 0,         "Id": 157,         "Name": "f3333"       }     ],     "Id": 725204,     "Name": "root"   }'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model GetSparkTemplateFullTreeResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetSparkTemplateFullTreeResponseBody(name='body'),
}

async function getSparkTemplateFullTree(request: GetSparkTemplateFullTreeRequest): GetSparkTemplateFullTreeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkTemplateFullTree', 'POST', '/', 'json', true, 'form', request);
}

model GetTableRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.', example='amv-*******', position='Query'),
  dbName: string(name='DbName', description='The name of the database.', example='dbName', position='Query'),
  regionId: string(name='RegionId', description='The ID of the region in which the cluster resides.', example='cn-hangzhou', position='Query'),
  tableName: string(name='TableName', description='The name of the table.', example='tableName', position='Query'),
}

model GetTableResponseBody = {
  code?: long(name='Code', description='The error code returned.', example='0'),
  message?: string(name='Message', description='The error message returned.', example='""'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  success?: boolean(name='Success', description='Indicates whether the query succeeded.', example='true'),
  table?: TableModel(name='Table', description='Details of the table.'),
}

model GetTableResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetTableResponseBody(name='body'),
}

/**
  * @deprecated
  *
 */
// Deprecated
async function getTable(request: GetTableRequest): GetTableResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTable', 'POST', '/', 'json', false, 'json', request);
}

model GetTableColumnsRequest {
  columnName?: string(name='ColumnName', description='The name of the column.', example='assist_user_phone', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.', example='amv-bp11q28kvl688****', position='Query'),
  pageNumber?: long(name='PageNumber', description='The number of the page to return. The value is an integer that is greater than 0. Default value: **1**.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries to return on each page. Default value: 30. Valid values:

*   **30**
*   **50**
*   **100**', example='30', position='Query'),
  regionId: string(name='RegionId', description='The ID of the region in which the cluster resides.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
  tableName?: string(name='TableName', description='The name of the table.', example='test', position='Query'),
}

model GetTableColumnsResponseBody = {
  data?: {
    pageNumber?: long(name='PageNumber', description='The page number of the returned page. The value is an integer that is greater than 0. Default value: 1.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries returned per page. Default value: 30. Valid values:

*   **30**
*   **50**
*   **100**', example='30'),
    table?: TableDetailModel(name='Table', description='Details of the table.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='15'),
  }(name='Data', description='The data returned.'),
  pageNumber?: long(name='PageNumber', description='The page number of the returned page. The value is an integer that is greater than 0. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries returned per page. Default value: 30. Valid values:

*   **30**
*   **50**
*   **100**', example='30'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='15'),
}

model GetTableColumnsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetTableColumnsResponseBody(name='body'),
}

async function getTableColumns(request: GetTableColumnsRequest): GetTableColumnsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTableColumns', 'POST', '/', 'json', false, 'json', request);
}

model GetTableDDLRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.', example='am-bp1ub9grke1****', position='Query'),
  regionId: string(name='RegionId', description='The ID of the region in which the cluster resides.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
  tableName?: string(name='TableName', description='The name of the table.', example='test', position='Query'),
}

model GetTableDDLResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='863D51B7-5321-41D8-A0B6-A088B0******'),
  SQL?: string(name='SQL', description='The SQL statement.', example='create table (
 id varchar(32)
);'),
}

model GetTableDDLResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetTableDDLResponseBody(name='body'),
}

async function getTableDDL(request: GetTableDDLRequest): GetTableDDLResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTableDDL', 'POST', '/', 'json', false, 'json', request);
}

model GetTableObjectsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.', example='am-bp1565u55p32****', position='Query'),
  filterDescription?: string(name='FilterDescription', description='The description of the table.', example='description', position='Query'),
  filterOwner?: string(name='FilterOwner', description='The owner of the table.', example='admin', position='Query'),
  filterTblName?: string(name='FilterTblName', description='The name of the table.', example='test_tbl', position='Query'),
  filterTblType?: string(name='FilterTblType', description='The type of the table.

Valid values:

DIMENSION_TABLE

FACT_TABLE

EXTERNAL_TABLE

Default value: null.', example='FACT_TABLE', position='Query'),
  orderBy?: string(name='OrderBy', description='The order in which the fields to be returned are sorted.

Valid values:

*   Asc
*   Desc

Values for fields:

TableName

TableSize

CreateTime

UpdateTime

Default value: {"Type": "Desc","Field": "TableName"};', example='{"Type": "Desc","Field": "TableName"}', position='Query'),
  pageNumber?: long(name='PageNumber', description='The number of the page to return. The value is an integer that is greater than 0. Default value: **1**.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries to return on each page. Valid values:

*   30
*   50
*   100

Default value: 30.', example='30', position='Query'),
  regionId: string(name='RegionId', description='The ID of the region in which the cluster resides.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
}

model GetTableObjectsResponseBody = {
  data?: {
    pageNumber?: long(name='PageNumber', description='The number of the returned page. The value is an integer that is greater than 0. Default value: **1**.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries returned per page. Default value: 30. Valid values:

*   **30**
*   **50**
*   **100**', example='30'),
    tableSummaryModels?: [
      TableSummaryModel
    ](name='TableSummaryModels', description='Details of the tables.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The data returned.'),
  pageNumber?: long(name='PageNumber', description='The number of the returned page. The value is an integer that is greater than 0. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries returned per page. Default value: 30. Valid values:

*   **30**
*   **50**
*   **100**', example='30'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='863D51B7-5321-41D8-A0B6-A088B0******'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model GetTableObjectsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetTableObjectsResponseBody(name='body'),
}

async function getTableObjects(request: GetTableObjectsRequest): GetTableObjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTableObjects', 'POST', '/', 'json', false, 'json', request);
}

model GetViewDDLRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.', example='am-bp1ub9grke1****', position='Query'),
  regionId: string(name='RegionId', description='The ID of the region in which the cluster resides.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
  viewName?: string(name='ViewName', description='The name of the view.', example='v_modbus', position='Query'),
}

model GetViewDDLResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='421794A3-72A5-5D27-9E8B-A75A4C503E17'),
  SQL?: string(name='SQL', description='Details of the SQL statement.', example='CREATE VIEW `test`.`test_view` AS SELECT
  `id`
, `name`
FROM
  `test_tbl_adb`'),
}

model GetViewDDLResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetViewDDLResponseBody(name='body'),
}

async function getViewDDL(request: GetViewDDLRequest): GetViewDDLResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetViewDDL', 'POST', '/', 'json', false, 'json', request);
}

model GetViewObjectsRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.', example='am-bp1xxxxxxxx47', position='Query'),
  filterOwner?: string(name='FilterOwner', description='The owner of the view.', example='admin', position='Query'),
  filterViewName?: string(name='FilterViewName', description='The name of the view.', example='test_filter', position='Query'),
  filterViewType?: string(name='FilterViewType', description='The type of the view.

Valid values:

\\-VIRTUAL_VIEW

\\-MATERIALIZED_VIEW

Default value: null.', example='VIRTUAL_VIEW', position='Query'),
  orderBy?: string(name='OrderBy', description='The order in which you want to sort the query results. Valid values for Type:

*   Asc
*   Desc

Valid values for Field: -ViewName

\\-CreateTime

\\-UpdateTime

Default value: {"Type": "Desc","Field": "ViewName"}.', example='{"Type": "Desc","Field": "ViewName"}', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
}

model GetViewObjectsResponseBody = {
  data?: {
    pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
    tableSummaryModels?: [
      TableSummaryModel
    ](name='TableSummaryModels', description='The queried views.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The returned data.'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model GetViewObjectsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: GetViewObjectsResponseBody(name='body'),
}

async function getViewObjects(request: GetViewObjectsRequest): GetViewObjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetViewObjects', 'POST', '/', 'json', false, 'json', request);
}

model KillSparkAppRequest {
  appId: string(name='AppId', description='The ID of the Spark application.', example='s202204132018hzprec1ac****', maxLength=64, position='Body'),
}

model KillSparkAppResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark application.', example='s202204132018hzprec1ac****'),
    appName?: string(name='AppName', description='The name of the Spark application.', example='LAKEHOUSE-1-1'),
    DBClusterId?: string(name='DBClusterId', description='The database ID.', example='amv-clusterxxx'),
    message?: string(name='Message', description='The error message returned if the request failed.', example='[Advisor] Advisor feature is not available for instance: am-2ze292w4fyglwxxxx'),
    state?: string(name='State', description='The state of the Spark application. Valid values:

*   **waiting**
*   **running**
*   **finished**
*   **failed**
*   **closed**', example='running'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='69D0810B-F9F5-5F4C-A57F-DF36133B63C9'),
}

model KillSparkAppResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: KillSparkAppResponseBody(name='body'),
}

async function killSparkApp(request: KillSparkAppRequest): KillSparkAppResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'KillSparkApp', 'POST', '/', 'json', true, 'form', request);
}

model KillSparkLogAnalyzeTaskRequest {
  taskId: long(name='TaskId', description='The ID of the Spark log analysis task. You can call the ListSparkLogAnalyzeTasks operation to query the IDs and states of all analysis tasks in the current cluster.', example='15', minimum=0, position='Body'),
}

model KillSparkLogAnalyzeTaskResponseBody = {
  data?: SparkAnalyzeLogTask(name='Data', description='The information about the Spark log analysis task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1DF5AF5B-C803-1861-A0FF-63666A557709'),
}

model KillSparkLogAnalyzeTaskResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: KillSparkLogAnalyzeTaskResponseBody(name='body'),
}

async function killSparkLogAnalyzeTask(request: KillSparkLogAnalyzeTaskRequest): KillSparkLogAnalyzeTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'KillSparkLogAnalyzeTask', 'POST', '/', 'json', true, 'form', request);
}

model KillSparkSQLEngineRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-8vbn8pq537k8w****', position='Body'),
  resourceGroupName: string(name='ResourceGroupName', description='The name of the resource group.', example='spark_test', position='Body'),
}

model KillSparkSQLEngineResponseBody = {
  data?: boolean(name='Data', description='Indicates whether the request was successful.', example='true'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model KillSparkSQLEngineResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: KillSparkSQLEngineResponseBody(name='body'),
}

async function killSparkSQLEngine(request: KillSparkSQLEngineRequest): KillSparkSQLEngineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'KillSparkSQLEngine', 'POST', '/', 'json', true, 'form', request);
}

model ListSparkAppAttemptsRequest {
  appId: string(name='AppId', description='The ID of the Spark application.

> You can call the [ListSparkApps](~~455888~~) operation to query all application IDs.', example='s202204132018hzprec1ac****', position='Query'),
  pageNumber: long(name='PageNumber', description='The page number. The value must be an integer that is greater than 0. Default value: **1**.', example='1', minimum=1, position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **10** (default)
*   **50**
*   **100**', example='10', minimum=1, maximum=100, position='Query'),
}

model ListSparkAppAttemptsResponseBody = {
  data?: {
    attemptInfoList?: [
      SparkAttemptInfo
    ](name='AttemptInfoList', description='The information about the attempts. Fields in the response parameter:

*   **AttemptId**: the attempt ID.

*   **State**: the state of the Spark application. Valid values:

    *   **SUBMITTED**
    *   **STARTING**
    *   **RUNNING**
    *   **FAILING**
    *   **FAILED**
    *   **KILLING**
    *   **KILLED**
    *   **SUCCEEDING**
    *   **COMPLETED**
    *   **FATAL**
    *   **UNKNOWN**

*   **Message**: the alert message that is returned. If no alert is generated, null is returned.

*   **Data**: the data of the Spark application template.

*   **EstimateExecutionCpuTimeInSeconds**: the amount of time it takes to consume CPU resources for running the Spark application. Unit: milliseconds.

*   **LogRootPath**: the storage path of log files.

*   **LastAttemptId**: the ID of the last attempt.

*   **WebUiAddress**: the web UI address.

*   **SubmittedTimeInMillis**: the time when the Spark application was submitted. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **StartedTimeInMillis**: the time when the Spark application was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **LastUpdatedTimeInMillis**: the time when the Spark application was last updated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **TerminatedTimeInMillis**: the time when the Spark application task was terminated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **DBClusterId**: the ID of the cluster on which the Spark application runs.

*   **ResourceGroupName**: the name of the job resource group.

*   **DurationInMillis**: the amount of time it takes to run the Spark application. Unit: milliseconds.'),
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='3'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ListSparkAppAttemptsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ListSparkAppAttemptsResponseBody(name='body'),
}

async function listSparkAppAttempts(request: ListSparkAppAttemptsRequest): ListSparkAppAttemptsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSparkAppAttempts', 'POST', '/', 'json', false, 'json', request);
}

model ListSparkAppsRequest {
  DBClusterId: string(name='DBClusterId', example='amv-bp11q28kvl688****', position='Query'),
  pageNumber: long(name='PageNumber', example='1', minimum=1, position='Query'),
  pageSize?: long(name='PageSize', example='30', minimum=1, maximum=100, position='Query'),
  resourceGroupName?: string(name='ResourceGroupName', example='test_instance', position='Query'),
}

model ListSparkAppsResponseBody = {
  data?: {
    appInfoList?: [
      SparkAppInfo
    ](name='AppInfoList'),
    pageNumber?: long(name='PageNumber', example='1'),
    pageSize?: long(name='PageSize', example='10'),
    totalCount?: long(name='TotalCount', example='1'),
  }(name='Data'),
  pageNumber?: long(name='PageNumber', example='1'),
  pageSize?: long(name='PageSize', example='10'),
  requestId?: string(name='RequestId', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
  totalCount?: long(name='TotalCount', example='1'),
}

model ListSparkAppsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ListSparkAppsResponseBody(name='body'),
}

async function listSparkApps(request: ListSparkAppsRequest): ListSparkAppsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSparkApps', 'POST', '/', 'json', false, 'json', request);
}

model ListSparkLogAnalyzeTasksRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.', example='amv-9scxs****', position='Body'),
  pageNumber: long(name='PageNumber', description='The page number.', example='1', minimum=1, position='Body'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='20', minimum=1, maximum=100, position='Body'),
}

model ListSparkLogAnalyzeTasksResponseBody = {
  data?: {
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='20'),
    taskList?: [
      SparkAnalyzeLogTask
    ](name='TaskList', description='The queried Spark log analysis tasks.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1DF5AF5B-C803-1861-A0FF-63666A557709'),
}

model ListSparkLogAnalyzeTasksResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ListSparkLogAnalyzeTasksResponseBody(name='body'),
}

async function listSparkLogAnalyzeTasks(request: ListSparkLogAnalyzeTasksRequest): ListSparkLogAnalyzeTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSparkLogAnalyzeTasks', 'POST', '/', 'json', true, 'form', request);
}

model ListSparkTemplateFileIdsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Body'),
}

model ListSparkTemplateFileIdsResponseBody = {
  data?: [ long ](name='Data', description='The IDs of Spark template files.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ListSparkTemplateFileIdsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ListSparkTemplateFileIdsResponseBody(name='body'),
}

async function listSparkTemplateFileIds(request: ListSparkTemplateFileIdsRequest): ListSparkTemplateFileIdsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSparkTemplateFileIds', 'POST', '/', 'json', true, 'form', request);
}

model ModifyAccountDescriptionRequest {
  accountDescription: string(name='AccountDescription', description='The description of the database account.

*   The description cannot start with `http://` or `https://`.
*   The description must be 2 to 256 characters in length.', example='AccDesc', position='Query'),
  accountName: string(name='AccountName', description='The name of the database account.

> You can call the [DescribeAccounts](~~612430~~) operation to query the information about database accounts in a cluster, including the database account name.', example='testacc', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
}

model ModifyAccountDescriptionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ModifyAccountDescriptionResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyAccountDescriptionResponseBody(name='body'),
}

async function modifyAccountDescription(request: ModifyAccountDescriptionRequest): ModifyAccountDescriptionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyAccountDescription', 'POST', '/', 'json', false, 'json', request);
}

model ModifyAccountPrivilegesRequest {
  accountName: string(name='AccountName', description='The name of the database account.', example='account1', position='Query'),
  accountPrivileges: [ 
    {
      privilegeObject?: {
        column?: string(name='Column', description='The columns on which the database account has permissions. This parameter is required if the PrivilegeType parameter is set to Column.', example='column1'),
        database?: string(name='Database', description='The databases on which the database account has permissions. This parameter is required if the PrivilegeType parameter is set to Database, Table, or Column.', example='tsdb1'),
        table?: string(name='Table', description='The tables on which the database account has permissions. This parameter is required if the PrivilegeType parameter is set to Table or Column.', example='table1'),
      }(name='PrivilegeObject', description='The objects on which the permission takes effect, including databases, tables, and columns.'),
      privilegeType?: string(name='PrivilegeType', description='The permission level of the database account. You can call the `DescribeEnabledPrivileges` operation to query the permission level of the database account.', example='Global'),
      privileges?: [ string ](name='Privileges', description='The permissions that you want to modify. You can call the `DescribeEnabledPrivileges` operation to query the permissions of the database account.'),
    }
  ](name='AccountPrivileges', description='The permissions of the database account.', shrink='json', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1k5p066e1a****', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model ModifyAccountPrivilegesResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='9DD88DE7-824F-1082-AA57-575AFC6517A8'),
}

model ModifyAccountPrivilegesResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyAccountPrivilegesResponseBody(name='body'),
}

async function modifyAccountPrivileges(request: ModifyAccountPrivilegesRequest): ModifyAccountPrivilegesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyAccountPrivileges', 'POST', '/', 'json', false, 'json', request);
}

model ModifyAuditLogConfigRequest {
  auditLogStatus: string(name='AuditLogStatus', description='Modifies the status of SQL audit. Valid values:

*   **on**: enables SQL audit.
*   **off**: disables SQL audit.

>  After you disable the SQL audit feature, all SQL audit logs are deleted. You must query and export SQL audit logs before you disable SQL audit. For more information, see Query and export SQL audit logs. When you re-enable SQL audit, audit logs that are generated from the last time when SQL audit was enabled are available for queries.', example='on', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-t4nj8619bz2w3****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  regionId: string(name='RegionId', description='The region ID.

> You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model ModifyAuditLogConfigResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='CDC59E56-BD07-56CA-A05F-B7907DE5C862'),
  updateSucceed?: boolean(name='UpdateSucceed', description='Indicates whether the status of SQL audit is updated. Valid values:

*   **true**
*   **false**', example='true'),
}

model ModifyAuditLogConfigResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyAuditLogConfigResponseBody(name='body'),
}

async function modifyAuditLogConfig(request: ModifyAuditLogConfigRequest): ModifyAuditLogConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyAuditLogConfig', 'POST', '/', 'json', false, 'json', request);
}

model ModifyClusterAccessWhiteListRequest {
  DBClusterIPArrayAttribute?: string(name='DBClusterIPArrayAttribute', description='The attribute of the IP address whitelist. By default, this parameter is empty.

> Whitelists with the hidden attribute are not displayed in the console. Those whitelists are used to access Data Transmission Service (DTS) and PolarDB.', example='hidden', position='Query'),
  DBClusterIPArrayName?: string(name='DBClusterIPArrayName', description='The name of the IP address whitelist. If you do not specify this parameter, the Default whitelist is modified.

*   The whitelist name must be 2 to 32 characters in length. The name can contain lowercase letters, digits, and underscores (\\_). The name must start with a lowercase letter and end with a lowercase letter or a digit.
*   Each cluster supports up to 50 IP address whitelists.', example='test', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  modifyMode?: string(name='ModifyMode', description='The method used to modify the IP address whitelist. Valid values:

*   **Cover** (default)
*   **Append**
*   **Delete**', example='Cover', position='Query'),
  securityIps: string(name='SecurityIps', description='The IP addresses in an IP address whitelist of a cluster. Separate multiple IP addresses with commas (,). You can add a maximum of 500 different IP addresses to a whitelist. The entries in the IP address whitelist must be in one of the following formats:

*   IP addresses, such as 10.23.XX.XX.
*   CIDR blocks, such as 10.23.xx.xx/24. In this example, 24 indicates that the prefix of each IP address in the IP whitelist is 24 bits in length. You can replace 24 with a value within the range of 1 to 32.', example='10.23.xx.xx', position='Query'),
}

model ModifyClusterAccessWhiteListResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  requestId?: string(name='RequestId', description='The request ID.', example='370D09FD-442A-5225-AAD3-7362CAE39177'),
  taskId?: int32(name='TaskId', description='The task ID.', example='1564657730'),
}

model ModifyClusterAccessWhiteListResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyClusterAccessWhiteListResponseBody(name='body'),
}

async function modifyClusterAccessWhiteList(request: ModifyClusterAccessWhiteListRequest): ModifyClusterAccessWhiteListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyClusterAccessWhiteList', 'POST', '/', 'json', false, 'json', request);
}

model ModifyClusterConnectionStringRequest {
  connectionStringPrefix: string(name='ConnectionStringPrefix', description='The prefix of the public endpoint.

*   The prefix can contain lowercase letters, digits, and hyphens (-). It must start with a lowercase letter.
*   The prefix can be up to 30 characters in length.', example='test-123', position='Query'),
  currentConnectionString: string(name='CurrentConnectionString', description='The current public endpoint of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****.ads.aliyuncs.com', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  port?: int32(name='Port', description='The port number that is used to connect to the cluster. Set the value to **3306**.', example='3306', position='Query'),
}

model ModifyClusterConnectionStringResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='370D09FD-442A-5225-AAD3-7362CAE39177'),
}

model ModifyClusterConnectionStringResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyClusterConnectionStringResponseBody(name='body'),
}

async function modifyClusterConnectionString(request: ModifyClusterConnectionStringRequest): ModifyClusterConnectionStringResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyClusterConnectionString', 'POST', '/', 'json', false, 'json', request);
}

model ModifyDBClusterRequest {
  computeResource: string(name='ComputeResource', description='The reserved computing resources. Unit: ACUs. Valid values: 0 to 4096. The value must be in increments of 16 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.

>  You must specify a value with the unit for this parameter.', example='16ACU', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****', position='Query'),
  enableDefaultResourcePool?: boolean(name='EnableDefaultResourcePool', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  storageResource: string(name='StorageResource', description='The reserved storage resources. Unit: AnalyticDB Compute Units (ACUs). Valid values: 0 to 2064. The value must be in increments of 24 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.

>  You must specify a value with the unit for this parameter.', example='24ACU', position='Query'),
}

model ModifyDBClusterResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  orderId?: string(name='OrderId', description='The ID of the order.', example='2035629****'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='0D6BF3E2-41D8-57F6-9A62-A13A70377952'),
}

model ModifyDBClusterResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyDBClusterResponseBody(name='body'),
}

/**
  * *   During a scaling event, you are not allowed to execute the `SUBMIT JOB` statement to submit asynchronous tasks. If your business requires asynchronous tasks, perform scaling during appropriate periods.
  * *   When cluster specifications are scaled up or down, data in the cluster is migrated for redistribution. The amount of time required for data migration is proportional to the volume of data. During a scale-up or scale-down event, the services provided by the cluster are not interrupted. During a scale-down event, data migration can take up to dozens of hours to complete. Proceed with caution especially when your cluster contains a large amount of data.
  * *   If the cluster has a built-in dataset loaded, make sure that the cluster has reserved storage resources of at least 24 AnalyticDB compute units (ACUs). Otherwise, the built-in dataset cannot be used.
  *
 */
async function modifyDBCluster(request: ModifyDBClusterRequest): ModifyDBClusterResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyDBCluster', 'POST', '/', 'json', false, 'json', request);
}

model ModifyDBClusterDescriptionRequest {
  DBClusterDescription: string(name='DBClusterDescription', description='The description of the cluster.

*   The description cannot start with `http://` or `https`.
*   The description must be 2 to 256 characters in length.', example='adb_test', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****', position='Query'),
}

model ModifyDBClusterDescriptionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='17F57FEE-EA4F-4337-8D2E-9C23CAA63D74'),
}

model ModifyDBClusterDescriptionResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyDBClusterDescriptionResponseBody(name='body'),
}

async function modifyDBClusterDescription(request: ModifyDBClusterDescriptionRequest): ModifyDBClusterDescriptionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyDBClusterDescription', 'POST', '/', 'json', false, 'json', request);
}

model ModifyDBClusterMaintainTimeRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****', position='Query'),
  maintainTime: string(name='MaintainTime', description='The maintenance window of the cluster. It must be in the hh:mmZ-hh:mmZ format.

> The interval must be 1 hour on the hour.', example='22:00Z-23:00Z', position='Query'),
}

model ModifyDBClusterMaintainTimeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='65BDA532-28AF-4122-AA39-B382721EEE64'),
}

model ModifyDBClusterMaintainTimeResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyDBClusterMaintainTimeResponseBody(name='body'),
}

async function modifyDBClusterMaintainTime(request: ModifyDBClusterMaintainTimeRequest): ModifyDBClusterMaintainTimeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyDBClusterMaintainTime', 'POST', '/', 'json', false, 'json', request);
}

model ModifyDBResourceGroupRequest {
  clusterMode?: string(name='ClusterMode', position='Query'),
  clusterSizeResource?: string(name='ClusterSizeResource', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****', position='Query'),
  groupName: string(name='GroupName', description='The name of the resource group.

> You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group in a cluster.', example='test', position='Query'),
  groupType: string(name='GroupType', description='The type of the resource group. Valid values:

*   **Interactive**
*   **Job**

> For information about resource groups of Data Lakehouse Edition, see [Resource groups](~~428610~~).', example='Interactive', position='Query'),
  maxClusterCount?: int32(name='MaxClusterCount', position='Query'),
  maxComputeResource?: string(name='MaxComputeResource', description='The maximum amount of reserved computing resources. Unit: ACU.

*   If GroupType is set to Interactive, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 16 ACUs.
*   If GroupType is set to Job, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 8 ACUs.', example='48ACU', position='Query'),
  minClusterCount?: int32(name='MinClusterCount', position='Query'),
  minComputeResource?: string(name='MinComputeResource', description='The minimum amount of reserved computing resources. Unit: AnalyticDB compute unit (ACU).

*   If GroupType is set to Interactive, set the value to 16ACU.
*   If GroupType is set to Job, set the value to 0ACU.', example='0ACU', position='Query'),
}

model ModifyDBResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='805F14E1-0186-520E-A6D5-30188D94E8DA'),
}

model ModifyDBResourceGroupResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyDBResourceGroupResponseBody(name='body'),
}

async function modifyDBResourceGroup(request: ModifyDBResourceGroupRequest): ModifyDBResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyDBResourceGroup', 'POST', '/', 'json', false, 'json', request);
}

model ModifyElasticPlanRequest {
  cronExpression?: string(name='CronExpression', description='A CORN expression that specifies the scaling cycle and time for the scaling plan.', example='0 20 14 * * ?', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the ID of an AnalyticDB for MySQL Data Warehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the name of a scaling plan of a specific cluster.', example='test', position='Query'),
  endTime?: string(name='EndTime', description='The time to end the scaling plan.

>  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2025-01-01T12:01:00Z', position='Query'),
  startTime?: string(name='StartTime', description='The time to start the scaling plan.

>  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-01-01T12:01:00Z', position='Query'),
  targetSize?: string(name='TargetSize', description='The amount of elastic resources after scaling.

> *   This parameter is not required only if the resource group uses **EIUs** and **Proportional Default Scaling for EIUs** is enabled.
> *   You can call the [DescribeElasticPlanSpecifications](~~601278~~) operation to query the specifications that are supported for scaling plans.', example='32ACU', position='Query'),
}

model ModifyElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model ModifyElasticPlanResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ModifyElasticPlanResponseBody(name='body'),
}

async function modifyElasticPlan(request: ModifyElasticPlanRequest): ModifyElasticPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyElasticPlan', 'POST', '/', 'json', false, 'json', request);
}

model PreloadSparkAppMetricsRequest {
  appId: string(name='AppId', description='The ID of the Spark application.', example='s202204221525hzca7d8140000003', maxLength=64, position='Body'),
}

model PreloadSparkAppMetricsResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark application.', example='s202212181815shaccb8be0000253'),
    attemptId?: string(name='AttemptId', description='The retry ID of the Spark application.', example='s202301061000hz57d797b0000201-0001'),
    eventLogPath?: string(name='EventLogPath', description='The path of the event log.', example='oss://path/to/eventLog'),
    finished?: boolean(name='Finished', description='Indicates whether parsing is complete. Valid values:

*   true
*   false', example='True'),
    scanMetrics?: {
      outputRowsCount?: long(name='OutputRowsCount', description='The number of scanned rows.', example='1000'),
      totalReadFileSizeInByte?: long(name='TotalReadFileSizeInByte', description='The number of scanned bytes.', example='10000'),
    }(name='ScanMetrics', description='The metrics.'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='84489769-3065-5A28-A4CB-977CD426F1C3'),
}

model PreloadSparkAppMetricsResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: PreloadSparkAppMetricsResponseBody(name='body'),
}

async function preloadSparkAppMetrics(request: PreloadSparkAppMetricsRequest): PreloadSparkAppMetricsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'PreloadSparkAppMetrics', 'POST', '/', 'json', true, 'form', request);
}

model ReleaseClusterPublicConnectionRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
}

model ReleaseClusterPublicConnectionResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request.', example='A94B6C02-7BD4-5D67-9776-3AC8317E8DD5'),
}

model ReleaseClusterPublicConnectionResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ReleaseClusterPublicConnectionResponseBody(name='body'),
}

async function releaseClusterPublicConnection(request: ReleaseClusterPublicConnectionRequest): ReleaseClusterPublicConnectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ReleaseClusterPublicConnection', 'POST', '/', 'json', false, 'json', request);
}

model RenameSparkTemplateFileRequest {
  DBClusterId: string(name='DBClusterId', example='amv-d*****', position='Query'),
  id: long(name='Id', example='1', minimum=0, position='Query'),
  name: string(name='Name', example='new_template_name', position='Query'),
}

model RenameSparkTemplateFileResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', example='True'),
  }(name='Data'),
  requestId?: string(name='RequestId', example='16D332C4-ACEB-526A-9B53-2B708FED594A'),
}

model RenameSparkTemplateFileResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: RenameSparkTemplateFileResponseBody(name='body'),
}

async function renameSparkTemplateFile(request: RenameSparkTemplateFileRequest): RenameSparkTemplateFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameSparkTemplateFile', 'POST', '/', 'json', false, 'json', request);
}

model ResetAccountPasswordRequest {
  accountDescription?: string(name='AccountDescription', description='The description of the database account.

*   The description cannot start with `http://` or `https://`.
*   The description must be 2 to 256 characters in length.', example='AccDesc', position='Query'),
  accountName: string(name='AccountName', description='The name of the database account.

> You can call the [DescribeAccounts](~~612430~~) operation to query the information about database accounts in a cluster, including the database account name.', example='test_accout', position='Query'),
  accountPassword: string(name='AccountPassword', description='The password of the database account.

*   The password must contain at least three of the following character types: uppercase letters, lowercase letters, digits, and special characters.
*   Special characters include `! @ # $ % ^ & * ( ) _ + - =`
*   The password must be 8 to 32 characters in length.', example='Test_accout1', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
}

model ResetAccountPasswordResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ResetAccountPasswordResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: ResetAccountPasswordResponseBody(name='body'),
}

async function resetAccountPassword(request: ResetAccountPasswordRequest): ResetAccountPasswordResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ResetAccountPassword', 'POST', '/', 'json', false, 'json', request);
}

model SetSparkAppLogRootPathRequest {
  DBClusterId: string(name='DBClusterId', description='The database ID.', example='am-dbclusterid', maxLength=64, position='Body'),
  ossLogPath?: string(name='OssLogPath', description='The Object Storage Service (OSS) log path.', example='oss://path/to/log', position='Body'),
  useDefaultOss?: boolean(name='UseDefaultOss', description='Specifies whether to use the default OSS log path.', example='true', position='Body'),
}

model SetSparkAppLogRootPathResponseBody = {
  data?: {
    defaultLogPath?: string(name='DefaultLogPath', description='The recommended default OSS log path.', example='oss://path/to/log'),
    isLogPathExists?: boolean(name='IsLogPathExists', description='Indicates whether an OSS log path exists.', example='true'),
    modifiedTimestamp?: string(name='ModifiedTimestamp', description='The time when the modification was last modified.', example='1675236908'),
    modifiedUid?: string(name='ModifiedUid', description='The modifier ID.', example='1111111'),
    recordedLogPath?: string(name='RecordedLogPath', description='The OSS log path.', example='oss://path/to/log'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model SetSparkAppLogRootPathResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: SetSparkAppLogRootPathResponseBody(name='body'),
}

async function setSparkAppLogRootPath(request: SetSparkAppLogRootPathRequest): SetSparkAppLogRootPathResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetSparkAppLogRootPath', 'POST', '/', 'json', true, 'form', request);
}

model StartSparkSQLEngineRequest {
  config?: string(name='Config', description='The configuration that is required to start the Spark SQL engine. Specify this value in the JSON format. For more information, see [Conf configuration parameters](~~471203~~).', example='{ "spark.shuffle.timeout": ":0s" }', position='Body'),
  DBClusterId: string(name='DBClusterId', description='The cluster ID.', example='amv-abcd****', position='Body'),
  jars?: string(name='Jars', description='The Object Storage Service (OSS) paths of third-party JAR packages that are required to start the Spark SQL engine. Separate multiple OSS paths with commas (,).', example='oss://testBuckname/test.jar,oss://testBuckname/test2.jar', position='Body'),
  maxExecutor?: long(name='MaxExecutor', description='The maximum number of executors that are required to execute SQL statements. Valid values: 1 to 2000. If this value exceeds the total number of executes that are supported by the resource group, the Spark SQL engine fails to be started.', example='10', position='Body'),
  minExecutor?: long(name='MinExecutor', description='The minimum number of executors that are required to execute SQL statements. Valid values: 0 to 2000. A value of 0 indicates that no executors are permanent if no SQL statements are executed. If this value exceeds the total number of executes that are supported by the resource group, the Spark SQL engine fails to be started. The value must be less than the value of MaxExecutor.', example='1', position='Body'),
  resourceGroupName: string(name='ResourceGroupName', description='The name of the resource group.', example='spark-rg-name', position='Body'),
  slotNum?: long(name='SlotNum', description='The maximum number of slots that are required to maintain Spark sessions for executing SQL statements. Valid values: 1 to 500.', example='100', position='Body'),
}

model StartSparkSQLEngineResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark job.', example='s202301xxxx'),
    appName?: string(name='AppName', description='The name of the Spark application.', example='SQLEngine1'),
    state?: string(name='State', description='The state of the Spark SQL engine. Valid values:

*   SUBMITTED
*   STARTING
*   RUNNING
*   FAILED', example='SUBMITTED'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model StartSparkSQLEngineResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: StartSparkSQLEngineResponseBody(name='body'),
}

async function startSparkSQLEngine(request: StartSparkSQLEngineRequest): StartSparkSQLEngineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartSparkSQLEngine', 'POST', '/', 'json', true, 'form', request);
}

model SubmitSparkAppRequest {
  agentSource?: string(name='AgentSource', description='The type of the client. The value can be up to 64 characters in length.', example='CONSOLE', position='Body'),
  agentVersion?: string(name='AgentVersion', description='The version of the client. The value can be up to 64 characters in length.', example='1.091', position='Body'),
  appName?: string(name='AppName', description='The name of the application. The value can be up to 64 characters in length.', example='TestApp', position='Body'),
  appType?: string(name='AppType', description='The type of the application. Valid values:

*   **SQL**
*   **STREAMING**
*   **BATCH** (default)', example='SQL', position='Body'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query cluster IDs.', example='amv-bp11q28kvl688****', maxLength=64, position='Body'),
  data: string(name='Data', description='The data of the application template.

> For information about the application template configuration, see [Spark application configuration guide](~~452402~~).', example='conf spark.driver.resourceSpec=small; conf spark.executor.instances=1; conf spark.executor.resourceSpec=small; conf spark.app.name=TestApp;', position='Body'),
  resourceGroupName: string(name='ResourceGroupName', description='The name of the job resource group.

> You can call the [DescribeDBResourceGroup](~~612413~~) operation to query the resource group IDs of an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='adb', maxLength=64, position='Body'),
  templateFileId?: long(name='TemplateFileId', description='The ID of the application template.

> You can call the [GetSparkTemplateFullTree](~~456205~~) operation to query the application template ID.', example='15', minimum=0, position='Body'),
}

model SubmitSparkAppResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The application ID.', example='s202204132018hzprec1ac61a000****'),
    appName?: string(name='AppName', description='The name of the application.', example='TestApp'),
    message?: string(name='Message', description='The alert message returned for the operation, such as task execution failure or insufficient resources. If no alert occurs, null is returned.', example='Insufficient resources.'),
    state?: string(name='State', description='The execution state of the application. Valid values:

*   **SUBMITTED**
*   **STARTING**
*   **RUNNING**
*   **FAILING**
*   **FAILED**
*   **KILLING**
*   **KILLED**
*   **SUCCEEDING**
*   **COMPLETED**
*   **FATAL**
*   **UNKNOWN**', example='SUBMITTED'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model SubmitSparkAppResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: SubmitSparkAppResponseBody(name='body'),
}

async function submitSparkApp(request: SubmitSparkAppRequest): SubmitSparkAppResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSparkApp', 'POST', '/', 'json', true, 'form', request);
}

model SubmitSparkLogAnalyzeTaskRequest {
  appId: string(name='AppId', description='The ID of the Spark application.', example='s202301121553hzd9c6f7xxxx', position='Body'),
}

model SubmitSparkLogAnalyzeTaskResponseBody = {
  data?: SparkAnalyzeLogTask(name='Data', description='The information about the Spark log analysis task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1DF5AF5B-C803-1861-A0FF-63666A557709'),
}

model SubmitSparkLogAnalyzeTaskResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: SubmitSparkLogAnalyzeTaskResponseBody(name='body'),
}

async function submitSparkLogAnalyzeTask(request: SubmitSparkLogAnalyzeTaskRequest): SubmitSparkLogAnalyzeTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSparkLogAnalyzeTask', 'POST', '/', 'json', true, 'form', request);
}

model UnbindAccountRequest {
  accountName: string(name='AccountName', description='The name of the database account.

> You can call the [DescribeAccounts](~~612430~~) operation to view the information about a database account in a cluster, including the name of the database account.', example='test_accout', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz99d9nh5****', position='Query'),
}

model UnbindAccountResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='93E85E5C-C805-5837-8713-05B69A504EE5'),
}

model UnbindAccountResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: UnbindAccountResponseBody(name='body'),
}

async function unbindAccount(request: UnbindAccountRequest): UnbindAccountResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UnbindAccount', 'POST', '/', 'json', false, 'json', request);
}

model UnbindDBResourceGroupWithUserRequest {
  DBClusterId: string(name='DBClusterId', example='am-bp1ub9grke1****', position='Query'),
  groupName?: string(name='GroupName', example='test', position='Query'),
  groupUser?: string(name='GroupUser', example='user1', position='Query'),
}

model UnbindDBResourceGroupWithUserResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model UnbindDBResourceGroupWithUserResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: UnbindDBResourceGroupWithUserResponseBody(name='body'),
}

async function unbindDBResourceGroupWithUser(request: UnbindDBResourceGroupWithUserRequest): UnbindDBResourceGroupWithUserResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UnbindDBResourceGroupWithUser', 'POST', '/', 'json', false, 'json', request);
}

model UpdateSparkTemplateFileRequest {
  content?: string(name='Content', description='The template data to be updated.

>  If you do not specify this parameter, the application template is not updated. For more information about how to configure an application template, see [Configure a Spark application](~~452402~~).', example='set spark.driver.resourceSpec=medium;set spark.executor.instances=2;set spark.executor.resourceSpec=medium;set spark.app.name=Spark SQL Test;', position='Body'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-pz5vp4585l466****', maxLength=64, position='Body'),
  id: long(name='Id', description='The ID of the application template.

>  You can call the [GetSparkTemplateFullTree](~~456205~~) operation to query the template ID.', example='718056', minimum=0, position='Body'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the job resource group.', example='adb', position='Body'),
}

model UpdateSparkTemplateFileResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the application template is updated.

*   **true**: The application template is updated.
*   **false**: The application template fails to be updated.', example='True'),
  }(name='Data', description='The update result.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='C3A9594F-1D40-4472-A96C-8FB8AA20D38C'),
}

model UpdateSparkTemplateFileResponse = {
  headers: map[string]string(name='headers'),
  statusCode: int32(name='statusCode'),
  body: UpdateSparkTemplateFileResponseBody(name='body'),
}

async function updateSparkTemplateFile(request: UpdateSparkTemplateFileRequest): UpdateSparkTemplateFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateSparkTemplateFile', 'POST', '/', 'json', true, 'form', request);
}

