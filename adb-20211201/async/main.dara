/**
 *
 */
import BaseClientBuilder;
import TeaAsyncHandler;
import TeaRequest;
import AsyncRequestBody;
import RequestBody;
import AsyncResponseHandler;
import ClientConfiguration;
import ClientExecutionParams;
extends BaseClientBuilder;
type @product = string
type @version = string
type @endpointRule = string
type @endpointMap = map[string]string
type @REQUEST = TeaRequest
type @handler = TeaAsyncHandler

init(configuration: ClientConfiguration){
  @handler = new TeaAsyncHandler(configuration);
  @product = 'adb';
  @version = '2021-12-01';
  @endpointRule = 'regional';
  @endpointMap = {
    'cn-qingdao' = 'adb.aliyuncs.com',
    'cn-beijing' = 'adb.aliyuncs.com',
    'cn-hangzhou' = 'adb.aliyuncs.com',
    'cn-shanghai' = 'adb.aliyuncs.com',
    'cn-shenzhen' = 'adb.aliyuncs.com',
    'cn-hongkong' = 'adb.aliyuncs.com',
    'ap-southeast-1' = 'adb.aliyuncs.com',
    'us-west-1' = 'adb.aliyuncs.com',
    'us-east-1' = 'adb.aliyuncs.com',
    'cn-hangzhou-finance' = 'adb.aliyuncs.com',
    'cn-north-2-gov-1' = 'adb.aliyuncs.com',
    'ap-northeast-2-pop' = 'adb.ap-northeast-1.aliyuncs.com',
    'cn-beijing-finance-1' = 'adb.aliyuncs.com',
    'cn-beijing-finance-pop' = 'adb.aliyuncs.com',
    'cn-beijing-gov-1' = 'adb.aliyuncs.com',
    'cn-beijing-nu16-b01' = 'adb.aliyuncs.com',
    'cn-edge-1' = 'adb.aliyuncs.com',
    'cn-fujian' = 'adb.aliyuncs.com',
    'cn-haidian-cm12-c01' = 'adb.aliyuncs.com',
    'cn-hangzhou-bj-b01' = 'adb.aliyuncs.com',
    'cn-hangzhou-internal-prod-1' = 'adb.aliyuncs.com',
    'cn-hangzhou-internal-test-1' = 'adb.aliyuncs.com',
    'cn-hangzhou-internal-test-2' = 'adb.aliyuncs.com',
    'cn-hangzhou-internal-test-3' = 'adb.aliyuncs.com',
    'cn-hangzhou-test-306' = 'adb.aliyuncs.com',
    'cn-hongkong-finance-pop' = 'adb.aliyuncs.com',
    'cn-qingdao-nebula' = 'adb.aliyuncs.com',
    'cn-shanghai-et15-b01' = 'adb.aliyuncs.com',
    'cn-shanghai-et2-b01' = 'adb.aliyuncs.com',
    'cn-shanghai-finance-1' = 'adb.aliyuncs.com',
    'cn-shanghai-inner' = 'adb.aliyuncs.com',
    'cn-shanghai-internal-test-1' = 'adb.aliyuncs.com',
    'cn-shenzhen-finance-1' = 'adb.aliyuncs.com',
    'cn-shenzhen-inner' = 'adb.aliyuncs.com',
    'cn-shenzhen-st4-d01' = 'adb.aliyuncs.com',
    'cn-shenzhen-su18-b01' = 'adb.aliyuncs.com',
    'cn-wuhan' = 'adb.aliyuncs.com',
    'cn-yushanfang' = 'adb.aliyuncs.com',
    'cn-zhangbei-na61-b01' = 'adb.aliyuncs.com',
    'cn-zhangjiakou-na62-a01' = 'adb.aliyuncs.com',
    'cn-zhengzhou-nebula-1' = 'adb.aliyuncs.com',
    'eu-west-1-oxs' = 'adb.ap-northeast-1.aliyuncs.com',
    'me-east-1' = 'adb.ap-northeast-1.aliyuncs.com',
    'rus-west-1-pop' = 'adb.ap-northeast-1.aliyuncs.com',
  };
}

function close(): void {
  @handler.close();
}

model Adb4MysqlSparkDiagnosisInfo {
  diagnosisCode?: string(name='DiagnosisCode'),
  diagnosisCodeLabel?: string(name='DiagnosisCodeLabel'),
  diagnosisMsg?: string(name='DiagnosisMsg'),
  diagnosisType?: string(name='DiagnosisType', example='APPLICATION'),
}

model ColDetailModel {
  columnName?: string(name='ColumnName'),
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  distributeKey?: boolean(name='DistributeKey'),
  nullable?: boolean(name='Nullable'),
  partitionKey?: boolean(name='PartitionKey'),
  primaryKey?: boolean(name='PrimaryKey'),
  schemaName?: string(name='SchemaName'),
  tableName?: string(name='TableName'),
  type?: string(name='Type'),
  updateTime?: string(name='UpdateTime'),
}

model CstoreIndexModel {
  columnOrds?: [ string ](name='ColumnOrds'),
  createTime?: string(name='CreateTime'),
  databaseName?: string(name='DatabaseName'),
  indexColumns?: [
    FieldSchemaModel
  ](name='IndexColumns'),
  indexName?: string(name='IndexName'),
  indexType?: string(name='IndexType'),
  options?: map[string]string(name='Options'),
  physicalTableName?: string(name='PhysicalTableName'),
  updateTime?: string(name='UpdateTime'),
}

model DatabaseSummaryModel {
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  owner?: string(name='Owner'),
  schemaName?: string(name='SchemaName'),
  updateTime?: string(name='UpdateTime'),
}

model Detail {
  appType?: string(name='AppType', example='BATCH'),
  DBClusterId?: string(name='DBClusterId', example='amv-bp11q28kv****'),
  data?: string(name='Data', example='{     "name": "SparkPi",     "file": "local:///tmp/spark-examples.jar",     "className": "org.apache.spark.examples.SparkPi",     "args": [         "1000000"     ],     "conf": {         "spark.driver.resourceSpec": "small",         "spark.executor.instances": 1,         "spark.executor.resourceSpec": "small"     } }'),
  durationInMillis?: long(name='DurationInMillis', example='100'),
  estimateExecutionCpuTimeInSeconds?: long(name='EstimateExecutionCpuTimeInSeconds', example='100'),
  lastAttemptId?: string(name='LastAttemptId', example='s202204291426hzpre60cfa*****-0003'),
  lastUpdatedTimeInMillis?: long(name='LastUpdatedTimeInMillis', example='1651213645200'),
  logRootPath?: string(name='LogRootPath', example='oss://<bucket-name>/logs/driver'),
  resourceGroupName?: string(name='ResourceGroupName', example='spark-rg'),
  startedTimeInMillis?: long(name='StartedTimeInMillis', example='1651213645010'),
  submittedTimeInMillis?: long(name='SubmittedTimeInMillis', example='1651213645000'),
  terminatedTimeInMillis?: long(name='TerminatedTimeInMillis', example='1651213645300'),
  webUiAddress?: string(name='WebUiAddress', example='https://sparkui.aliyuncs.com/token=xxx'),
}

model FieldSchemaModel {
  autoIncrement?: boolean(name='AutoIncrement'),
  columnRawName?: string(name='ColumnRawName'),
  comment?: string(name='Comment'),
  compressFloatUseShort?: boolean(name='CompressFloatUseShort'),
  compression?: string(name='Compression'),
  createTime?: string(name='CreateTime'),
  dataType?: string(name='DataType'),
  databaseName?: string(name='DatabaseName'),
  defaultValue?: string(name='DefaultValue'),
  delimiter?: string(name='Delimiter'),
  encode?: string(name='Encode'),
  isPartitionKey?: boolean(name='IsPartitionKey'),
  mappedName?: string(name='MappedName'),
  name?: string(name='Name'),
  nullable?: boolean(name='Nullable'),
  onUpdate?: string(name='OnUpdate'),
  ordinalPosition?: long(name='OrdinalPosition'),
  physicalColumnName?: string(name='PhysicalColumnName'),
  pkPosition?: long(name='PkPosition'),
  precision?: long(name='Precision'),
  primarykey?: boolean(name='Primarykey'),
  scale?: long(name='Scale'),
  tableName?: string(name='TableName'),
  tokenizer?: string(name='Tokenizer'),
  type?: string(name='Type'),
  updateTime?: string(name='UpdateTime'),
  valueType?: string(name='ValueType'),
}

model Filters {
  appIdRegex?: string(name='AppIdRegex'),
  appNameRegex?: string(name='AppNameRegex'),
  appState?: string(name='AppState'),
  appType?: string(name='AppType'),
  executionTimeRange?: {
    maxTimeInSeconds?: long(name='MaxTimeInSeconds', minimum=1),
    minTimeInSeconds?: long(name='MinTimeInSeconds', minimum=0),
  }(name='ExecutionTimeRange'),
  submitTimeRange?: {
    maxTimeInMills?: long(name='MaxTimeInMills', minimum=0),
    minTimeInMills?: long(name='MinTimeInMills', minimum=0),
  }(name='SubmitTimeRange'),
  termiatedTimeRange?: {
    maxTimeInMills?: long(name='MaxTimeInMills', minimum=0),
    minTimeInMills?: long(name='MinTimeInMills', minimum=0),
  }(name='TermiatedTimeRange'),
}

model LogAnalyzeResult {
  appErrorAdvice?: string(name='AppErrorAdvice'),
  appErrorCode?: string(name='AppErrorCode', example='EXCEEDED_QUOTA'),
  appErrorLog?: string(name='AppErrorLog', example='exception: xxxx'),
}

model OperatorNode {
  children?: [
    OperatorNode
  ](name='children'),
  id?: int32(name='id'),
  levelWidth?: int32(name='levelWidth'),
  nodeDepth?: int32(name='nodeDepth'),
  nodeName?: string(name='nodeName'),
  nodeWidth?: int32(name='nodeWidth'),
  parentId?: int32(name='parentId'),
  stats?: {
    bytes?: long(name='bytes'),
    outputRows?: long(name='outputRows'),
    parameters?: string(name='parameters'),
    peakMemory?: long(name='peakMemory'),
    timeCost?: long(name='timeCost'),
  }(name='stats'),
}

model SerDeInfoModel {
  name?: string(name='Name'),
  parameters?: map[string]string(name='Parameters'),
  serDeId?: long(name='SerDeId'),
  serializationLib?: string(name='SerializationLib'),
}

model SparkAnalyzeLogTask {
  DBClusterId?: string(name='DBClusterId', example='amv-adbxxxxx'),
  result?: LogAnalyzeResult(name='Result'),
  ruleMatched?: boolean(name='RuleMatched', example='true'),
  startedTimeInMillis?: long(name='StartedTimeInMillis', example='1672123543000'),
  submittedTimeInMillis?: long(name='SubmittedTimeInMillis', example='1672123543000'),
  taskErrMsg?: string(name='TaskErrMsg', example='Driver log not found'),
  taskId?: long(name='TaskId', example='10'),
  taskState?: string(name='TaskState', example='WAITING'),
  terminatedTimeInMillis?: long(name='TerminatedTimeInMillis', example='1672123543000'),
  userId?: long(name='UserId', example='13719918xxx'),
}

model SparkAppInfo {
  appId?: string(name='AppId', example='s202207151211hz0cb4*****'),
  appName?: string(name='AppName', example='Spark Test'),
  DBClusterId?: string(name='DBClusterId', example='amv-23xxxx'),
  detail?: Detail(name='Detail'),
  message?: string(name='Message', example='WARN: Disk is full'),
  priority?: string(name='Priority', example='NORMAL'),
  state?: string(name='State', example='FAILED'),
}

model SparkAttemptInfo {
  attemptId?: string(name='AttemptId', example='s202207151211hz0cb4200*****-0001'),
  detail?: Detail(name='Detail'),
  message?: string(name='Message', example='WARN: Disk is full'),
  priority?: string(name='Priority', example='NORMAL'),
  state?: string(name='State', example='RUNNING'),
}

model SparkOperatorInfo {
  metricValue?: long(name='MetricValue'),
  operatorName?: bytes(name='OperatorName'),
}

model SparkSession {
  active?: string(name='Active', example='true'),
  aliyunUid?: long(name='AliyunUid', example='11123123'),
  sessionId?: long(name='SessionId', example='15'),
  state?: string(name='State', example='idle'),
}

model Statement {
  aliyunUid?: long(name='AliyunUid', example='1111111'),
  code?: string(name='Code', example='SELECT * FROM table'),
  codeState?: string(name='CodeState', example='Waiting'),
  codeType?: string(name='CodeType', example='SQL'),
  endTime?: long(name='EndTime', example='1658987911000'),
  error?: string(name='Error', example='Disk is full'),
  haveRows?: boolean(name='HaveRows', example='true'),
  output?: string(name='Output', example='Spark is running, the ouput is...'),
  resourceGroup?: string(name='ResourceGroup', example='rg1'),
  sessionId?: long(name='SessionId', example='10'),
  startTime?: long(name='StartTime', example='1658977911000'),
  statementId?: long(name='StatementId', example='100'),
  totalCount?: long(name='TotalCount', example='1000'),
}

model StatementInfo {
  code?: string(name='Code'),
  completedTimeInMills?: long(name='CompletedTimeInMills'),
  output?: string(name='Output'),
  process?: float(name='Process'),
  startedTimeInMills?: long(name='StartedTimeInMills'),
  state?: string(name='State'),
  statementId?: string(name='StatementId'),
}

model StorageDescriptorModel {
  compressed?: boolean(name='Compressed'),
  inputFormat?: string(name='InputFormat'),
  location?: string(name='Location'),
  numBuckets?: long(name='NumBuckets'),
  outputFormat?: string(name='OutputFormat'),
  parameters?: map[string]string(name='Parameters'),
  sdId?: long(name='SdId'),
  serDeInfo?: SerDeInfoModel(name='SerDeInfo'),
  storedAsSubDirectories?: boolean(name='StoredAsSubDirectories'),
}

model TableDetailModel {
  catalog?: string(name='Catalog'),
  columns?: [
    ColDetailModel
  ](name='Columns'),
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  owner?: string(name='Owner'),
  schemaName?: string(name='SchemaName'),
  tableName?: string(name='TableName'),
  tableType?: string(name='TableType'),
  updateTime?: string(name='UpdateTime'),
}

model TableModel {
  archiveType?: string(name='ArchiveType'),
  blockSize?: long(name='BlockSize'),
  bucket?: long(name='Bucket'),
  bucketCount?: long(name='BucketCount'),
  cols?: [
    FieldSchemaModel
  ](name='Cols'),
  comment?: string(name='Comment'),
  compression?: string(name='Compression'),
  createTime?: string(name='CreateTime'),
  currentVersion?: long(name='CurrentVersion'),
  dbName?: string(name='DbName'),
  dictEncode?: boolean(name='DictEncode'),
  distributeColumns?: [
    FieldSchemaModel
  ](name='DistributeColumns'),
  distributeType?: string(name='DistributeType'),
  enableDfs?: boolean(name='EnableDfs'),
  hotPartitionCount?: long(name='HotPartitionCount'),
  indexes?: [
    CstoreIndexModel
  ](name='Indexes'),
  isAllIndex?: boolean(name='IsAllIndex'),
  isFulltextDict?: boolean(name='IsFulltextDict'),
  maxColumnId?: long(name='MaxColumnId'),
  parameters?: map[string]string(name='Parameters'),
  partitionColumn?: string(name='PartitionColumn'),
  partitionCount?: long(name='PartitionCount'),
  partitionKeys?: [
    FieldSchemaModel
  ](name='PartitionKeys'),
  partitionType?: string(name='PartitionType'),
  physicalDatabaseName?: string(name='PhysicalDatabaseName'),
  physicalTableName?: string(name='PhysicalTableName'),
  previousVersion?: long(name='PreviousVersion'),
  rawTableName?: string(name='RawTableName'),
  routeColumns?: [
    FieldSchemaModel
  ](name='RouteColumns'),
  routeEffectiveColumn?: FieldSchemaModel(name='RouteEffectiveColumn'),
  routeType?: string(name='RouteType'),
  rtEngineType?: string(name='RtEngineType'),
  rtIndexAll?: boolean(name='RtIndexAll'),
  rtModeType?: string(name='RtModeType'),
  sd?: StorageDescriptorModel(name='Sd'),
  storagePolicy?: string(name='StoragePolicy'),
  subpartitionColumn?: string(name='SubpartitionColumn'),
  subpartitionCount?: long(name='SubpartitionCount'),
  subpartitionType?: string(name='SubpartitionType'),
  tableEngineName?: string(name='TableEngineName'),
  tableName?: string(name='TableName'),
  tableType?: string(name='TableType'),
  tblId?: long(name='TblId'),
  temporary?: boolean(name='Temporary'),
  updateTime?: string(name='UpdateTime'),
  viewExpandedText?: string(name='ViewExpandedText'),
  viewOriginalText?: string(name='ViewOriginalText'),
  viewSecurityMode?: string(name='ViewSecurityMode'),
}

model TableSummaryModel {
  createTime?: string(name='CreateTime'),
  description?: string(name='Description'),
  owner?: string(name='Owner'),
  SQL?: string(name='SQL'),
  schemaName?: string(name='SchemaName'),
  tableName?: string(name='TableName'),
  tableSize?: long(name='TableSize'),
  tableType?: string(name='TableType'),
  updateTime?: string(name='UpdateTime'),
}

model AllocateClusterPublicConnectionRequest {
  connectionStringPrefix?: string(name='ConnectionStringPrefix', description='The prefix of the public endpoint.

*   The prefix can contain lowercase letters, digits, and hyphens (-). It must start with a lowercase letter.
*   The prefix can be up to 30 characters in length.', example='test12', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1z5d2q71is2****', position='Query'),
  engine?: string(name='Engine', description='The database engine of the cluster. Valid values:

*   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
*   **Clickhouse**: the wide table engine.', example='Clickhouse', position='Query'),
}

model AllocateClusterPublicConnectionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='868EF07F-D0B2-5043-B092-0C14CD00B65A'),
}

model AllocateClusterPublicConnectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AllocateClusterPublicConnectionResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function allocateClusterPublicConnection(request: AllocateClusterPublicConnectionRequest): AllocateClusterPublicConnectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AllocateClusterPublicConnection', 'POST', '/', 'json', false, 'json', request);
}

model AttachUserENIRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region, including cluster IDs.', example='am-bp11q28kvl688****', position='Query'),
}

model AttachUserENIResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model AttachUserENIResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AttachUserENIResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function attachUserENI(request: AttachUserENIRequest): AttachUserENIResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AttachUserENI', 'POST', '/', 'json', false, 'json', request);
}

model BindAccountRequest {
  accountName: string(name='AccountName', description='The standard account of the cluster.', example='test_accout', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz99d9nh532****', position='Query'),
  ramUser: string(name='RamUser', description='The ID of the RAM user.', example='1444832459****', position='Query'),
}

model BindAccountResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='DFF27323-3868-5F8A-917D-5D1D06B6BC0D'),
}

model BindAccountResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: BindAccountResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function bindAccount(request: BindAccountRequest): BindAccountResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'BindAccount', 'POST', '/', 'json', false, 'json', request);
}

model BindDBResourceGroupWithUserRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.', example='am-bp1ub9grke1****', position='Query'),
  groupName: string(name='GroupName', description='The name of the resource group.', example='test', position='Query'),
  groupUser: string(name='GroupUser', description='The name of the database account. It can be a standard account or a privileged account.', example='accout', position='Query'),
}

model BindDBResourceGroupWithUserResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model BindDBResourceGroupWithUserResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: BindDBResourceGroupWithUserResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function bindDBResourceGroupWithUser(request: BindDBResourceGroupWithUserRequest): BindDBResourceGroupWithUserResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'BindDBResourceGroupWithUser', 'POST', '/', 'json', false, 'json', request);
}

model CheckBindRamUserRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Warehouse Edition (V3.0) clusters within a region.', example='amv-wz9842849v6****', position='Query'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model CheckBindRamUserResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='2FB9DCA3-DA56-5B43-A9A0-68E3D0E6AA84'),
  result?: boolean(name='Result', description='The returned result of the request. Valid values:

*   **true**: the database account is associated with a RAM user.
*   **false**: the database account is not associated with a RAM user.', example='true'),
}

model CheckBindRamUserResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CheckBindRamUserResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function checkBindRamUser(request: CheckBindRamUserRequest): CheckBindRamUserResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CheckBindRamUser', 'POST', '/', 'json', false, 'json', request);
}

model CheckSampleDataSetRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.', example='amv-wz9r8f67h4cqz41u', position='Query'),
}

model CheckSampleDataSetResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0CE655C3-C211-513D-A42F-D4AE2D1A867C'),
  status?: string(name='Status', description='The state of the built-in dataset. Valid values:

*   **SUCCEED**: The dataset is loaded.
*   **INIT**: The dataset is being loaded.
*   **FAILED**: The dataset failed to be loaded.
*   **UNINITIALIZED**: The dataset is not loaded.', example='UNINITIALIZED'),
}

model CheckSampleDataSetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CheckSampleDataSetResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function checkSampleDataSet(request: CheckSampleDataSetRequest): CheckSampleDataSetResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CheckSampleDataSet', 'POST', '/', 'json', false, 'json', request);
}

model CreateAccountRequest {
  accountDescription?: string(name='AccountDescription', description='The description of the account.

*   The description cannot start with `http://` or `https://`.
*   The description can be up to 256 characters in length.', example='test', position='Query'),
  accountName: string(name='AccountName', description='The name of the database account.

*   The name must start with a lowercase letter and end with a lowercase letter or a digit.
*   The name can contain lowercase letters, digits, and underscores (\\_).
*   The name must be 2 to 16 characters in length.
*   Reserved account names such as root, admin, and opsadmin cannot be used.', example='test_accout', position='Query'),
  accountPassword: string(name='AccountPassword', description='The password of the database account.

*   The password must contain at least three of the following character types: uppercase letters, lowercase letters, digits, and special characters.
*   Special characters include `! @ # $ % ^ & * ( ) _ + - =`
*   The password must be 8 to 32 characters in length.', example='Test_accout1', position='Query'),
  accountType: string(name='AccountType', description='The type of the database account. Valid values:

*   **Normal**: standard account.
*   **Super**: privileged account.', example='Normal', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  engine?: string(name='Engine', description='The database engine of the cluster. Valid values:

*   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
*   **Clickhouse**: the wide table engine.', example='Clickhouse', position='Query'),
}

model CreateAccountResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='2FED790E-FB61-4721-8C1C-07C627FA5A19'),
}

model CreateAccountResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateAccountResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function createAccount(request: CreateAccountRequest): CreateAccountResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateAccount', 'POST', '/', 'json', false, 'json', request);
}

model CreateDBClusterRequest {
  backupSetId?: string(name='BackupSetId', description='The ID of the backup set that you want to use to restore data.

>  You can call the [DescribeBackups](~~612318~~) operation to query the backup sets of the cluster.', example='1880808684', position='Query'),
  computeResource?: string(name='ComputeResource', description='The amount of reserved computing resources. Unit: ACUs. Valid values: 0 to 4096. The value must be in increments of 16 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.

>  This parameter must be specified with a unit.', example='16ACU', position='Query'),
  DBClusterDescription?: string(name='DBClusterDescription', description='The description of the cluster.

*   The description cannot start with `http://` or `https://`.
*   The description must be 2 to 256 characters in length', example='test', position='Query'),
  DBClusterNetworkType?: string(name='DBClusterNetworkType', description='The network type of the cluster. Only **VPC** is supported.', example='VPC', position='Query'),
  DBClusterVersion: string(name='DBClusterVersion', description='The version of the cluster. Set the value to **5.0**.', example='5.0', position='Query'),
  diskEncryption?: boolean(name='DiskEncryption', position='Query'),
  enableDefaultResourcePool?: boolean(name='EnableDefaultResourcePool', description='Specifies whether to allocate all reserved computing resources to the user_default resource group. Valid values:

*   **true** (default)
*   **false**', example='true', position='Query'),
  kmsId?: string(name='KmsId', position='Query'),
  payType: string(name='PayType', description='The billing method of the cluster. Valid values:

*   **Postpaid**: pay-as-you-go.
*   **Prepaid**: subscription.', example='Prepaid', position='Query'),
  period?: string(name='Period', description='The subscription type of the subscription cluster. Valid values:

*   **Year**: subscription on a yearly basis.
*   **Month**: subscription on a monthly basis.

>  This parameter must be specified when PayType is set to Prepaid.', example='Month', position='Query'),
  productForm?: string(name='ProductForm', example='LegacyForm', position='Query'),
  regionId: string(name='RegionId', description='The region ID.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  reservedNodeCount?: int32(name='ReservedNodeCount', position='Query'),
  reservedNodeSize?: string(name='ReservedNodeSize', position='Query'),
  resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='rg-4690g37929****', position='Query'),
  restoreToTime?: string(name='RestoreToTime', description='The point in time to which you want to restore data from the backup set.', example='2023-09-20T03:13:56Z', position='Query'),
  restoreType?: string(name='RestoreType', description='The method that you want to use to restore data. Valid values:

*   **backup**: restores data from a backup set. You must also specify the **BackupSetId** and **SourceDBClusterId** parameters.
*   **timepoint**: restores data to a point in time. You must also specify the **RestoreToTime** and **SourceDBClusterId** parameters.', example='backup', position='Query'),
  sourceDbClusterId?: string(name='SourceDbClusterId', description='The ID of the source AnalyticDB for MySQL Data Warehouse Edition cluster. If you want to restore a Data Lakehouse Edition cluster from a Data Warehouse Edition cluster, you must specify this parameter.', example='amv-bp1r053byu48p****', position='Query'),
  storageResource?: string(name='StorageResource', description='The amount of reserved storage resources. Unit: AnalyticDB compute units (ACUs). Valid values: 0 to 2064. The value must be in increments of 24 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.

>  This parameter must be specified with a unit.', example='24ACU', position='Query'),
  tag?: [ 
    {
      key?: string(name='Key', description='The key of tag N to add to the cluster. You can use tags to filter clusters. Valid values of N: 1 to 20. The values that you specify for N must be unique and consecutive integers that start from 1. Each value of `Tag.N.Key` is paired with a value of `Tag.N.Value`.

>  The tag key can be up to 64 characters in length and cannot start with `aliyun`, `acs:`, `http://`, or `https://`.', example='testkey1'),
      value?: string(name='Value', description='The value of tag N to add to the cluster. You can use tags to filter clusters. Valid values of N: 1 to 20. The values that you specify for N must be unique and consecutive integers that start from 1. Each value of `Tag.N.Key` is paired with a value of `Tag.N.Value`.

>  The tag value can be up to 64 characters in length and cannot start with `aliyun`, `acs:`, `http://`, or `https://`.', example='test1'),
    }
  ](name='Tag', description='The tags to add to the cluster.', position='Query'),
  usedTime?: string(name='UsedTime', description='The subscription duration of the subscription cluster.

*   Valid values when **Period** is set to Year: 1 to 3 (integer).
*   Valid values when **Period** is set to Month: 1 to 9 (integer).

>  This parameter must be specified when PayType is set to **Prepaid**.', example='3', position='Query'),
  VPCId: string(name='VPCId', description='The virtual private cloud (VPC) ID of the cluster.', example='vpc-bp1at5ze0t5u3xtqn****', position='Query'),
  vSwitchId: string(name='VSwitchId', description='The vSwitch ID of the cluster.', example='vsw-bp1aadw9k19x6cis9****', position='Query'),
  zoneId: string(name='ZoneId', description='The zone ID.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent zone list.', example='cn-hangzhou-h', position='Query'),
}

model CreateDBClusterResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  orderId?: string(name='OrderId', description='The order ID.', example='202353278****'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  resourceGroupId?: string(name='ResourceGroupId', description='The default resource group ID.', example='rg-4690g37929****'),
}

model CreateDBClusterResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDBClusterResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function createDBCluster(request: CreateDBClusterRequest): CreateDBClusterResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDBCluster', 'POST', '/', 'json', false, 'json', request);
}

model CreateDBResourceGroupRequest {
  clusterMode?: string(name='ClusterMode', description='A reserved parameter.', example='N/A', position='Query'),
  clusterSizeResource?: string(name='ClusterSizeResource', description='A reserved parameter.', example='N/A', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  enableSpot?: boolean(name='EnableSpot', description='Specifies whether to enable the spot instance feature for the resource group. After you enable the spot instance feature, you are charged for resources at a lower unit price but the resources are probably released. You can enable the spot instance feature only for job resource groups. Valid values:

*   **True**
*   **False**', example='True', position='Query'),
  groupName: string(name='GroupName', description='The name of the resource group.

*   The name can be up to 255 characters in length.
*   The name must start with a letter or a digit.
*   The name can contain letters, digits, hyphens (\\_), and underscores (\\_).', example='test_group', position='Query'),
  groupType: string(name='GroupType', description='The type of the resource group. Valid values:

*   **Interactive**
*   **Job**

> For information about resource groups of Data Lakehouse Edition, see [Resource groups](~~428610~~).', example='Job', position='Query'),
  maxClusterCount?: int32(name='MaxClusterCount', description='A reserved parameter.', example='N/A', position='Query'),
  maxComputeResource?: string(name='MaxComputeResource', description='The maximum reserved computing resources. Unit: ACU.

*   If GroupType is set to Interactive, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 16 ACUs.
*   If GroupType is set to Job, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 8 ACUs.', example='48', position='Query'),
  minClusterCount?: int32(name='MinClusterCount', description='A reserved parameter.', example='N/A', position='Query'),
  minComputeResource?: string(name='MinComputeResource', description='The minimum reserved computing resources. Unit: AnalyticDB Compute Units (ACUs).

*   When GroupType is set to Interactive, set this parameter to 16 ACUs.
*   When GroupType is set to Job, set this parameter to 0 ACUs.', example='0', position='Query'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~612393~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  rules?: [ 
    {
      groupName?: string(name='GroupName', description='The name of the resource group.

*   The name can be up to 255 characters in length.
*   The name must start with a letter or digit.
*   The name can contain letters, digits, hyphens (-), and underscores (\\_).', example='test_group'),
      queryTime?: string(name='QueryTime', description='The execution duration of the query. Unit: milliseconds.', example='180000'),
      targetGroupName?: string(name='TargetGroupName', description='The name of the resource group to which you want to resubmit the query job.', example='job'),
    }
  ](name='Rules', description='The job resubmission rules.', shrink='json', position='Query'),
}

model CreateDBResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A94B6C02-7BD4-5D67-9776-3AC8317E8DD5'),
}

model CreateDBResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDBResourceGroupResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see Endpoints.
  *
 */
async function createDBResourceGroup(request: CreateDBResourceGroupRequest): CreateDBResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDBResourceGroup', 'POST', '/', 'json', false, 'json', request);
}

model CreateElasticPlanRequest {
  autoScale?: boolean(name='AutoScale', description='Specifies whether to enable **Default Proportional Scaling for EIUs**. Valid values:

*   true. In this case, storage resources are scaled along with computing resources, and the TargetSize and CronExpression parameters are not supported.
*   false

> 

*   This parameter must be specified when Type is set to WORKER. This parameter is not required when Type is set to EXECUTOR.

*   You can enable Default Proportional Scaling for EIUs for only a single scaling plan of a cluster.', example='false', position='Query'),
  cronExpression?: string(name='CronExpression', description='A CORN expression that specifies the scaling cycle and time for the scaling plan.', example='0 20 14 * * ?', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName: string(name='ElasticPlanName', description='The name of the scaling plan.

>  The name must be 2 to 30 characters in length and can contain letters, digits, and underscores (\\_). The name must start with a letter.', example='test', position='Query'),
  enabled: boolean(name='Enabled', description='Specifies whether to immediately enable the scaling plan after the plan is created. Valid values:

*   true
*   false', example='true', position='Query'),
  endTime?: string(name='EndTime', description='The end time of the scaling plan.

>  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2025-01-01T12:01:00Z', position='Query'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> 

*   If you want to create a scaling plan that uses interactive resource groups, you must specify this parameter. If you want to create a scaling plan that uses elastic I/O units (EIUs), you do not need to specify this parameter.

*   You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the resource group name for a cluster.', example='test', position='Query'),
  startTime?: string(name='StartTime', description='The start time of the scaling plan.

>  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-01-01T12:01:00Z', position='Query'),
  targetSize?: string(name='TargetSize', description='The desired specifications of elastic resources after scaling.

> 

*   If the scaling plan uses **EIUs** and **Default Proportional Scaling for EIUs** is enabled, you do not need to specify this parameter. In other cases, you must specify this parameter.

*   You can call the [DescribeElasticPlanSpecifications](~~601278~~) operation to query the specifications that are supported for scaling plans.', example='32ACU', position='Query'),
  type: string(name='Type', description='The type of the scaling plan. Valid values:

*   EXECUTOR: the interactive resource group type, which indicates the computing resource type.
*   WORKER: the EIU type.', example='EXECUTOR', position='Query'),
}

model CreateElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model CreateElasticPlanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateElasticPlanResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function createElasticPlan(request: CreateElasticPlanRequest): CreateElasticPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateElasticPlan', 'POST', '/', 'json', false, 'json', request);
}

model CreateOssSubDirectoryRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region, including cluster IDs.', example='amv-bp149vz49b36t****', position='Body'),
  path: string(name='Path', description='The OSS path where you want to create a subdirectory.', example='oss://testBucketName/das_lakehouse', position='Body'),
}

model CreateOssSubDirectoryResponseBody = {
  data?: {
    clientCRC?: long(name='ClientCRC', description='The cyclic redundancy check (CRC) value on the client.', example='1'),
    eTag?: string(name='ETag', description='The tag of the OSS path.', example='1'),
    requestId?: string(name='RequestId', description='The request ID.', example='3A0DE2E0-A37B-5EE4-9136-C4C473714802'),
    serverCRC?: long(name='ServerCRC', description='The CRC-64 value on the OSS bucket.', example='1'),
  }(name='Data', description='The returned data.'),
  httpStatusCode?: long(name='HttpStatusCode', description='The response code. The status code 200 indicates that the request was successful.', example='200'),
  message?: string(name='Message', description='The returned message.

*   If the request was successful, a **success** message is returned.
*   If the request failed, an error message is returned.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='3A0DE2E0-A37B-5EE4-9136-C4C473714802'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='True'),
}

model CreateOssSubDirectoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateOssSubDirectoryResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function createOssSubDirectory(request: CreateOssSubDirectoryRequest): CreateOssSubDirectoryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateOssSubDirectory', 'POST', '/', 'json', true, 'form', request);
}

model CreatePerformanceViewRequest {
  createFromViewType?: string(name='CreateFromViewType', example='Basic', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.', example='amv-bp1ub9grke1****', position='Query'),
  fillOriginViewKeys?: boolean(name='FillOriginViewKeys', description='Specifies whether to populate the names of the metrics in the original monitoring view when you view the monitoring view. Valid values:

*   **true**
*   **false**', example='true', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  regionId: string(name='RegionId', description='The region ID.

>  You can call the [DescribeRegions](~~143074~~) operation to query the most recent region list.', example='cn-beijing', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  viewDetail: {
    categories?: [ 
      {
        category?: string(name='Category', description='The name of the metric category. Valid values:

*   **Node**
*   **DiskData**
*   **WorkLoad**
*   **ResourceGroup**', example='Node'),
        keys?: [ 
          {
            keyName?: string(name='KeyName', description='The name of the metric.', example='AnalyticDB_CPU'),
            selected?: boolean(name='Selected', description='Specifies whether to select the metric. Valid values:

*   **true**
*   **false**', example='true'),
          }
        ](name='Keys', description='The metrics.'),
      }
    ](name='Categories', description='The metric categories.'),
    chartLinked?: boolean(name='ChartLinked', description='Specifies whether to enable the filter interaction feature. Valid values:

*   **true**
*   **false**', example='true'),
    chartsPerLine?: int32(name='ChartsPerLine', description='The number of charts to display in each row.', example='2'),
  }(name='ViewDetail', description='The information about the monitoring view.', shrink='json', position='Query'),
  viewName: string(name='ViewName', position='Query'),
}

model CreatePerformanceViewResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', example='{
    "PolicyType": "AccountLevelIdentityBasedPolicy",
    "AuthPrincipalOwnerId": "1*****************7",
    "EncodedDiagnosticMessage": "AQIBIAAAAOPdwKY2QLOvgMEc7SkkoJfj1kvZwsaRqNYMh10Tv0wTe0fCzaCdrvgazfNb0EnJKETgXyhR+3BIQjx9WAqZryejBsp1Bl4qI5En/D9dEhcXAtKCxCmE2kZCiEzpy8BoEUt+bs0DmlaGWO5xkEpttypLIB4rUhDvZd+zwPg4EXk4KSSWSWsurxtqDkKEMshKlQFBTKvJcKwyhk62IeYly4hQ+5IpXjkh1GQXuDRCQ==",
    "AuthPrincipalType": "SubUser",
    "AuthPrincipalDisplayName": "2***************9",
    "NoPermissionType": "ImplicitDeny",
    "AuthAction": "adb:DescribeExcessivePrimaryKeys"
}'),
  createStatus?: string(name='CreateStatus', description='The creation result. Valid values:

*   **SUCCESS**
*   **FAILED**', example='SUCCESS'),
  requestId?: string(name='RequestId', example='E031AABF-BD56-5966-A063-4283EF18DB45'),
}

model CreatePerformanceViewResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreatePerformanceViewResponseBody(name='body'),
}

async function createPerformanceView(request: CreatePerformanceViewRequest): CreatePerformanceViewResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreatePerformanceView', 'POST', '/', 'json', false, 'json', request);
}

model CreateSparkTemplateRequest {
  appType?: string(name='AppType', description='The application type. Valid values:

*   **SQL**
*   **STREAMING**
*   **BATCH**

>  You do not need to specify this parameter when Type is set to folder.', example='SQL', position='Body'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-bp11q28kvl688****', maxLength=64, position='Body'),
  name: string(name='Name', description='The name of the application template. The name can be up to 64 characters in length.', example='batchfile', maxLength=64, position='Body'),
  parentId: long(name='ParentId', description='The ID of the directory to which the application template belongs.

>  You can call the [GetSparkTemplateFolderTree](~~456218~~) operation to query the directory ID.', example='10', minimum=0, position='Body'),
  type: string(name='Type', description='The type of the application template. Valid values:

*   **folder**: directory.
*   **file**: application.', example='file', position='Body'),
}

model CreateSparkTemplateResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the application template is created. Valid values:

*   **True**
*   **False**', example='True'),
  }(name='Data', description='The creation result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model CreateSparkTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSparkTemplateResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function createSparkTemplate(request: CreateSparkTemplateRequest): CreateSparkTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateSparkTemplate', 'POST', '/', 'json', true, 'form', request);
}

model DeleteAccountRequest {
  accountName: string(name='AccountName', description='The name of the database account.

>  You can call the [DescribeAccounts](~~612430~~) operation to query the information about database accounts for a cluster, including the account name.', example='test_accout', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  engine?: string(name='Engine', description='The database engine of the cluster. Valid values:

*   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
*   **Clickhouse**: the wide table engine.', example='Clickhouse', position='Query'),
}

model DeleteAccountResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='2FED790E-FB61-4721-8C1C-07C627FA5A19'),
}

model DeleteAccountResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteAccountResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function deleteAccount(request: DeleteAccountRequest): DeleteAccountResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteAccount', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDBClusterRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1r053byu48p****', position='Query'),
}

model DeleteDBClusterResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DeleteDBClusterResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDBClusterResponseBody(name='body'),
}

/**
  * ### [](#)
  * *   You can call this operation to delete only subscription clusters.
  * *   For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function deleteDBCluster(request: DeleteDBClusterRequest): DeleteDBClusterResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDBCluster', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDBResourceGroupRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  groupName: string(name='GroupName', description='The name of the resource group.

>  You can call the [DescribeDBResourceGroup](~~612410~~) operation to query the information about resource groups of an AnalyticDB for MySQL cluster, including resource group names.', example='test_group', position='Query'),
}

model DeleteDBResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A94B6C02-7BD4-5D67-9776-3AC8317E8DD3'),
}

model DeleteDBResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDBResourceGroupResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function deleteDBResourceGroup(request: DeleteDBResourceGroupRequest): DeleteDBResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDBResourceGroup', 'POST', '/', 'json', false, 'json', request);
}

model DeleteElasticPlanRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the names of scaling plans.', example='test', position='Query'),
}

model DeleteElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model DeleteElasticPlanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteElasticPlanResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function deleteElasticPlan(request: DeleteElasticPlanRequest): DeleteElasticPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteElasticPlan', 'POST', '/', 'json', false, 'json', request);
}

model DeletePerformanceViewRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.', example='amv-uf6wjk5xxxxxxxxxx', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  regionId: string(name='RegionId', description='The region ID.

>  You can call the [DescribeRegions](~~143074~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  viewName: string(name='ViewName', position='Query'),
}

model DeletePerformanceViewResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='The details about the access denial.

>  This parameter is returned only if Resource Access Management (RAM) permission verification failed.', example='{
    "PolicyType": "AccountLevelIdentityBasedPolicy",
    "AuthPrincipalOwnerId": "1*****************7",
    "EncodedDiagnosticMessage": "AQIBIAAAAOPdwKY2QLOvgMEc7SkkoJfj1kvZwsaRqNYMh10Tv0wTe0fCzaCdrvgazfNb0EnJKETgXyhR+3BIQjx9WAqZryejBsp1Bl4qI5En/D9dEhcXAtKCxCmE2kZCiEzpy8BoEUt+bs0DmlaGWO5xkEpttypLIB4rUhDvZd+zwPg4EXk4KSSWSWsurxtqDkKEMshKlQFBTKvJcKwyhk62IeYly4hQ+5IpXjkh1GQXuDRCQ==",
    "AuthPrincipalType": "SubUser",
    "AuthPrincipalDisplayName": "2***************9",
    "NoPermissionType": "ImplicitDeny",
    "AuthAction": "adb:DescribeExcessivePrimaryKeys"
}'),
  deleteStatus?: boolean(name='DeleteStatus', example='SUCCESS'),
  requestId?: string(name='RequestId', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DeletePerformanceViewResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeletePerformanceViewResponseBody(name='body'),
}

async function deletePerformanceView(request: DeletePerformanceViewRequest): DeletePerformanceViewResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeletePerformanceView', 'POST', '/', 'json', false, 'json', request);
}

model DeleteProcessInstanceRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.', example='am-wz9rq819u71ig****', position='Query'),
  processInstanceId: long(name='ProcessInstanceId', description='The ID of the workflow instance.', example='4017', position='Query'),
  projectCode: long(name='ProjectCode', description='The project ID, which is the unique identifier of the project.', example='9839028042592', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model DeleteProcessInstanceResponseBody = {
  data?: boolean(name='Data', description='Indicates whether the workflow instance is deleted. Valid values:

*   **true**
*   **false**', example='true'),
  message?: string(name='Message', description='The returned message. Valid values:

*   If the request was successful, **Success** is returned.
*   If the request failed, an error message is returned.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='115F9CCA-EF2E-5F91-AB60-4961D52FEAB4'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DeleteProcessInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteProcessInstanceResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function deleteProcessInstance(request: DeleteProcessInstanceRequest): DeleteProcessInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteProcessInstance', 'POST', '/', 'json', false, 'json', request);
}

model DeleteSparkTemplateRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-bp11q28kvl688****', maxLength=64, position='Body'),
  id: long(name='Id', description='The directory ID of the template files that you want to delete.

> 

*   You can call the [GetSparkTemplateFullTree](~~456205~~) operation to query the directory ID of template files.

*   When you specify a directory ID, the directory and all template files that are included in the directory are deleted.', example='725204', minimum=0, position='Body'),
}

model DeleteSparkTemplateResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the request was successful. Valid values:

*   **True**
*   **False**', example='True'),
  }(name='Data', description='The returned result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DeleteSparkTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteSparkTemplateResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function deleteSparkTemplate(request: DeleteSparkTemplateRequest): DeleteSparkTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteSparkTemplate', 'POST', '/', 'json', true, 'form', request);
}

model DeleteSparkTemplateFileRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1y769u11748****', maxLength=64, position='Body'),
  id: long(name='Id', description='The ID of the template file to be deleted.

>  You can call the [GetSparkTemplateFullTree](~~456205~~) operation to query all template file IDs.', example='284', minimum=0, position='Body'),
}

model DeleteSparkTemplateFileResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the template file is deleted. Valid values:

*   **true**
*   **false**', example='true'),
  }(name='Data', description='The deletion result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C3A9594F-1D40-4472-A96C-8FB8AA20D38C'),
}

model DeleteSparkTemplateFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteSparkTemplateFileResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function deleteSparkTemplateFile(request: DeleteSparkTemplateFileRequest): DeleteSparkTemplateFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteSparkTemplateFile', 'POST', '/', 'json', true, 'form', request);
}

model DescribeAccountAllPrivilegesRequest {
  accountName: string(name='AccountName', description='The name of the database account.', example='account1', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp14t95lun0w****', position='Query'),
  marker?: string(name='Marker', description='Specifies the start position marker from which to return results. If you receive a response indicating that the results are truncated, set this parameter to the value of the `Marker` parameter in the response that you received.', example='EXAMPLE', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model DescribeAccountAllPrivilegesResponseBody = {
  data?: {
    marker?: string(name='Marker', description='Indicates the position where the results are truncated. When a value of `true` is returned for the `Truncated` parameter, this parameter is present and contains the value to use for the Marker parameter in a subsequent call.', example='0573e74fd1ccb01739993a691e876074db6e1b6ad79f54115f0e98528432ba6a523cfec5780ade5189299cc3396f6ff7'),
    result?: [ 
      {
        privilegeObject?: {
          column?: string(name='Column', description='The name of the column.', example='id'),
          database?: string(name='Database', description='The name of the database.', example='tdb1'),
          description?: string(name='Description', description='The description of the permission object.', example='id of table'),
          table?: string(name='Table', description='The name of the table.', example='table1'),
        }(name='PrivilegeObject', description='The objects on which the permission takes effect, including databases, tables, and columns. If Global is returned for the PrivilegeType parameter, an empty string is returned for this parameter.'),
        privilegeType?: string(name='PrivilegeType', description='The permission level of the database account. You can call the `DescribeEnabledPrivileges` operation to query the permission level of the database account.', example='Global'),
        privileges?: [ string ](name='Privileges', description='The name of the permission, which is the same as the permission name returned by the `DescribeEnabledPrivileges` operation.'),
      }
    ](name='Result', description='The permissions.'),
    truncated?: boolean(name='Truncated', description='Indicates whether the results are truncated. If the results are truncated, a value of `true` is returned. In this case, you must call this operation again to obtain all the results until a value of `false` is returned for this parameter.', example='true'),
  }(name='Data', description='Details of the permissions.'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='3BB185E9-BB54-1727-B876-13243E4C0EB5'),
}

model DescribeAccountAllPrivilegesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAccountAllPrivilegesResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeAccountAllPrivileges(request: DescribeAccountAllPrivilegesRequest): DescribeAccountAllPrivilegesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAccountAllPrivileges', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAccountPrivilegeObjectsRequest {
  accountName: string(name='AccountName', description='The name of the database account.', example='test', position='Query'),
  columnPrivilegeObject?: string(name='ColumnPrivilegeObject', description='The column name that is used to filter columns.', example='col1', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-bp1k3wdmt139****', position='Query'),
  databasePrivilegeObject?: string(name='DatabasePrivilegeObject', description='The database name that is used to filter databases.', example='database1', position='Query'),
  pageNumber?: string(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries per page. Default value: 20.', example='20', position='Query'),
  privilegeType?: string(name='PrivilegeType', description='The permission level. Valid values: Database, Table, and Column. Global is not supported.', example='Column', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='ch-hangzhou', position='Query'),
  tablePrivilegeObject?: string(name='TablePrivilegeObject', description='The table name that is used to filter tables.', example='table1', position='Query'),
}

model DescribeAccountPrivilegeObjectsResponseBody = {
  data?: [ 
    {
      column?: string(name='Column', description='The name of the column. This parameter is returned when PrivilegeType is set to Column.', example='column1'),
      database?: string(name='Database', description='The name of the database. This parameter is returned when PrivilegeType is set to Database, Table, or Column.', example='tdb1'),
      description?: string(name='Description', description='The description that is specified when you create a table or column. This parameter is returned only when PrivilegeType is set to Database or Table, indicating the database description or table description.', example='a test db'),
      table?: string(name='Table', description='The name of the table. This parameter is returned when PrivilegeType is set to Table or Column.', example='table1'),
    }
  ](name='Data', description='The permissions.'),
  pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='20'),
  requestId?: string(name='RequestId', description='The request ID.', example='34B2AD29-682F-1C14-B3AA-9EF1A96084B8'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='23'),
}

model DescribeAccountPrivilegeObjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAccountPrivilegeObjectsResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeAccountPrivilegeObjects(request: DescribeAccountPrivilegeObjectsRequest): DescribeAccountPrivilegeObjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAccountPrivilegeObjects', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAccountPrivilegesRequest {
  accountName: string(name='AccountName', description='The name of the database account.', example='account1', position='Query'),
  columnPrivilegeObject?: string(name='ColumnPrivilegeObject', description='The columns that you want to query. You can use this parameter to query the permissions of the database account on specific columns. This parameter is available only if the PrivilegeType parameter is set to Column.', example='col1', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1k5p066e1a****', position='Query'),
  databasePrivilegeObject?: string(name='DatabasePrivilegeObject', description='The databases that you want to query. You can use this parameter to query the permissions of the database account on specific databases. This parameter is available only if the PrivilegeType parameter is set to Database, Table, or Column.', example='db1', position='Query'),
  pageNumber?: string(name='PageNumber', description='The number of the page to return. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries to return on each page. Default value: 20.', example='10', position='Query'),
  privilegeType?: string(name='PrivilegeType', description='The permission level that you want to query. You can call the `DescribeEnabledPrivileges` operation to query the permission level of the database account.', example='Global', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
  tablePrivilegeObject?: string(name='TablePrivilegeObject', description='The tables that you want to query. You can use this parameter to query the permissions of the database account on specific tables. This parameter can be used together with the DatabasePrivilegeObject parameter. This parameter is available only if the PrivilegeType parameter is set to Table or Column.', example='table1', position='Query'),
}

model DescribeAccountPrivilegesResponseBody = {
  data?: [ 
    {
      privilegeObject?: {
        column?: string(name='Column', description='The name of the column.', example='column1'),
        database?: string(name='Database', description='The name of the database.', example='db1'),
        description?: string(name='Description', description='The description of the permission object.', example='a test column'),
        table?: string(name='Table', description='The name of the table.', example='tabl1'),
      }(name='PrivilegeObject', description='The objects on which the permission takes effect, including databases, tables, columns, and additional descriptions.'),
      privilegeType?: string(name='PrivilegeType', description='The permission level of the permission. Valid values: `Global`, `Database`, `Table`, and `Column`. You can call the `DescribeEnabledPrivileges` parameter to query the permission level of a specific permission.', example='Column'),
      privileges?: [ string ](name='Privileges', description='The name of the permission. You can call the `DescribeEnabledPrivileges` operation to query the name of the permission.'),
    }
  ](name='Data', description='Details of the permissions.'),
  pageNumber?: long(name='PageNumber', description='The page number of the returned page.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries returned per page.', example='20'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='DA32480A-E3E5-1BE7-BA98-724551DC04C8'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
}

model DescribeAccountPrivilegesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAccountPrivilegesResponseBody(name='body'),
}

async function describeAccountPrivileges(request: DescribeAccountPrivilegesRequest): DescribeAccountPrivilegesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAccountPrivileges', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAccountsRequest {
  accountName?: string(name='AccountName', description='The name of the database account.

> If you do not specify this parameter, the information about all database accounts in the cluster is returned.', example='test_accout', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  engine?: string(name='Engine', description='The database engine of the cluster. Valid values:

*   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
*   **Clickhouse**: the wide table engine.', example='Clickhouse', position='Query'),
  ownerId?: string(name='OwnerId', position='Query'),
}

model DescribeAccountsResponseBody = {
  accountList?: {
    DBAccount?: [ 
    {
      accountDescription?: string(name='AccountDescription', description='The description of the database account.', example='test_accout_des'),
      accountName?: string(name='AccountName', description='The name of the database account.', example='test_accout'),
      accountStatus?: string(name='AccountStatus', description='The status of the database account. Valid values:

*   **Creating**
*   **Available**
*   **Deleting**', example='Available'),
      accountType?: string(name='AccountType', description='The type of the database account. Valid values:

*   **Normal**: standard account.
*   **Super**: privileged account.', example='Normal'),
      engine?: string(name='Engine', description='The database engine of the cluster. Valid values:

*   **AnalyticDB**: the AnalyticDB for MySQL engine.
*   **Clickhouse**: the wide table engine.', example='Clickhouse'),
      ramUsers?: string(name='RamUsers', description='The ID of the Resource Access Management (RAM) user.', example='1958134230****'),
    }
  ](name='DBAccount')
  }(name='AccountList', description='The queried database accounts.'),
  requestId?: string(name='RequestId', description='The request ID.', example='9CCFAAB4-97B7-5800-B9F2-685EB596E3EF'),
}

model DescribeAccountsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAccountsResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeAccounts(request: DescribeAccountsRequest): DescribeAccountsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAccounts', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAdbMySqlColumnsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a specific region.', example='amv-bp1r053byu48p****', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  schema?: string(name='Schema', description='The name of the database.', example='adb_demo', position='Query'),
  tableName?: string(name='TableName', description='The name of the table.', example='test', position='Query'),
}

model DescribeAdbMySqlColumnsResponseBody = {
  columnCount?: int32(name='ColumnCount', description='The total number of columns.', example='1'),
  columns?: [ 
    {
      comment?: string(name='Comment', description='The comments of the column.', example='test'),
      name?: string(name='Name', description='The name of the column.', example='id'),
      type?: string(name='Type', description='The data type of the column.', example='bigint'),
    }
  ](name='Columns', description='Details of the columns.'),
  message?: string(name='Message', description='The message returned for the operation. Valid values:

*   **Success** is returned if the operation is successful.
*   An error message is returned if the operation fails.', example='Success'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='A9F013CD-0222-595E-8157-445969B97F03'),
  schema?: string(name='Schema', description='The name of the database.', example='adb_demo'),
  success?: boolean(name='Success', description='Indicates whether the operation is successful. Valid values:

*   **true**: The operation is successful.
*   **false**: The operation fails.', example='true'),
  tableName?: string(name='TableName', description='The name of the table.', example='test'),
}

model DescribeAdbMySqlColumnsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAdbMySqlColumnsResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describeAdbMySqlColumns(request: DescribeAdbMySqlColumnsRequest): DescribeAdbMySqlColumnsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAdbMySqlColumns', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAdbMySqlSchemasRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
}

model DescribeAdbMySqlSchemasResponseBody = {
  message?: string(name='Message', description='The returned message.

*   If the request was successful, a **success** message is returned.
*   If the request failed, an error message is returned.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  schemas?: [ string ](name='Schemas', description='The queried databases.'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeAdbMySqlSchemasResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAdbMySqlSchemasResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describeAdbMySqlSchemas(request: DescribeAdbMySqlSchemasRequest): DescribeAdbMySqlSchemasResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAdbMySqlSchemas', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAdbMySqlTablesRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  schema?: string(name='Schema', description='The name of the database.', example='adb_demo', position='Query'),
}

model DescribeAdbMySqlTablesResponseBody = {
  message?: string(name='Message', description='The message returned for the operation. Valid values:

*   **Success** is returned if the operation is successful.
*   An error message is returned if the operation fails.', example='Success'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='7A7D49E3-5585-5DF8-B62C-75C46B4991DC'),
  schema?: string(name='Schema', description='The name of the database.', example='adb_demo'),
  success?: boolean(name='Success', description='Indicates whether the operation is successful. Valid values:

*   **true**: The operation is successful.
*   **false**: The operation fails.', example='true'),
  tables?: [ string ](name='Tables', description='The names of tables.'),
}

model DescribeAdbMySqlTablesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAdbMySqlTablesResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describeAdbMySqlTables(request: DescribeAdbMySqlTablesRequest): DescribeAdbMySqlTablesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAdbMySqlTables', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAllDataSourceRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-bp1pke2pcfavw****', position='Query'),
  regionId: string(name='RegionId', description='The region ID.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
  tableName?: string(name='TableName', description='The name of the table.', example='test', position='Query'),
}

model DescribeAllDataSourceResponseBody = {
  columns?: {
    column?: [ 
    {
      autoIncrementColumn?: boolean(name='AutoIncrementColumn', description='Indicates whether the column is an auto-increment column. Valid values:

*   **true**
*   **false**', example='true'),
      columnName?: string(name='ColumnName', description='The name of the column.', example='id'),
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-bp1pke2pcfavw****'),
      primaryKey?: boolean(name='PrimaryKey', description='Indicates whether the column is the primary key of the table. Valid values:

*   **true**
*   **false**', example='false'),
      schemaName?: string(name='SchemaName', description='The logical name of the database.', example='adb_demo'),
      tableName?: string(name='TableName', description='The logical name of the table.', example='test'),
      type?: string(name='Type', description='The data type of the column.', example='bigint'),
    }
  ](name='Column')
  }(name='Columns', description='The queried columns.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C7EDB8E4-9769-4233-88C7-DCA4C9******'),
  schemas?: {
    schema?: [ 
    {
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-bp1pke2pcfavw****'),
      schemaName?: string(name='SchemaName', description='The logical name of the database.', example='adb_demo'),
    }
  ](name='Schema')
  }(name='Schemas', description='The queried databases.'),
  tables?: {
    table?: [ 
    {
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-bp1pke2pcfavw****'),
      schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
      tableName?: string(name='TableName', description='The logical name of the table.', example='test'),
    }
  ](name='Table')
  }(name='Tables', description='The queried tables.'),
}

model DescribeAllDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAllDataSourceResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describeAllDataSource(request: DescribeAllDataSourceRequest): DescribeAllDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAllDataSource', 'POST', '/', 'json', false, 'json', request);
}

model DescribeApsActionLogsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.', example='amv-bp1r053byu48p****', position='Query'),
  endTime: string(name='EndTime', description='The end time of the logs to be queried. Specify the time in the ISO 8601 standard in the **yyyy-MM-ddTHH:mm:ssZ** format. The time must be in UTC.

>  The end time must be later than the start time. The maximum time range that can be specified is 30 days.', example='2023-02-11T09:30:00Z', position='Query'),
  keyword?: string(name='Keyword', description='The keyword that you want to use for fuzzy match in the query.', example='table_test', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30', minimum=10, maximum=100, position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  stage?: string(name='Stage', description='The phase during which the logs to be queried were generated. Valid values:

*   **StructureMigrate**: schema migration.
*   **FullDataSync**: full data synchronization.
*   **IncrementalSync**: incremental data synchronization.

>  If you do not specify this parameter, logs of all the phases are queried.', example='FullDataSync', position='Query'),
  startTime: string(name='StartTime', description='The start time of the logs to be queried. Specify the time in the ISO 8601 standard in the **yyyy-MM-ddTHH:mm:ssZ** format. The time must be in UTC.', example='2023-02-11T08:30:00Z', position='Query'),
  state?: string(name='State', description='The types of the logs. Separate multiple log types with commas (,). Valid values:

*   **INFO**
*   **WARN**
*   **ERROR**

>  If you do not specify this parameter, logs of all types are queried.', example='INFO,WARN,ERROR', position='Query'),
  workloadId: string(name='WorkloadId', description='The ID of the real-time data ingestion job.', example='aps-hz109vpvt4fg8528d****', position='Query'),
}

model DescribeApsActionLogsResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='The information about the request denial.', example='{
  "AuthAction": "xxx",
  "AuthPrincipalDisplayName": "sampleName",
  "AuthPrincipalOwnerId": "111111111111111111",
  "AuthPrincipalType": "SubUser",
  "AuthResource": "xxx",
  "NoPermissionType": "xxx",
  "PolicyType": "xxx"
}'),
  actionLogs?: [ 
    {
      context?: string(name='Context', description='The content of the log.', example='DDL migration job finished'),
      stage?: string(name='Stage', description='The phase during which the log was generated. Valid values:

*   **StructureMigrate**: schema migration.
*   **FullDataSync**: full data synchronization.
*   **IncrementalSync**: incremental data synchronization.', example='FullDataSync'),
      state?: string(name='State', description='The type of the log. Multiple log types are separated by commas (,). Valid values:

*   **INFO**
*   **WARN**
*   **ERROR**', example='INFO,WARN,ERROR'),
      time?: string(name='Time', description='The time when the log was generated. The time follows the ISO 8601 standard in the **yyyy-MM-ddTHH:mm:ssZ** format. The time is displayed in UTC.', example='2023-02-01T05:46:30Z'),
    }
  ](name='ActionLogs', description='The queried logs.'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries per page.', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='A5EDBA27-AF3E-5966-9503-FD1557E19167'),
  totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='3'),
  workloadId?: string(name='WorkloadId', description='The ID of the real-time data ingestion job.', example='aps-hz109vpvt4fg8528d****'),
}

model DescribeApsActionLogsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeApsActionLogsResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describeApsActionLogs(request: DescribeApsActionLogsRequest): DescribeApsActionLogsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeApsActionLogs', 'POST', '/', 'json', false, 'json', request);
}

model DescribeApsResourceGroupsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1t6rym21****', position='Body'),
  regionId?: string(name='RegionId', description='The region ID.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Body'),
  workloadId?: string(name='WorkloadId', description='The ID of the data synchronization job.', example='aps-hz1686v37sx****', position='Body'),
}

model DescribeApsResourceGroupsResponseBody = {
  data?: {
    resourceGroups?: [ 
      {
        available?: boolean(name='Available', description='Indicates whether the resource group is available. Valid values:

*   **true**
*   **false**', example='True'),
        cuOptions?: [ long ](name='CuOptions'),
        groupName?: string(name='GroupName', description='The name of the resource group.', example='test'),
        groupType?: string(name='GroupType', description='The type of the resource group. Valid values:

*   **Interactive**
*   **Job**

>  For more information about resource groups, see [Resource groups](~~428610~~).', example='Job'),
        leftComputeResource?: int32(name='LeftComputeResource', description='The amount of remaining computing resources. Unit: ACUs.', example='512'),
        maxComputeResource?: int32(name='MaxComputeResource', description='The maximum amount of reserved computing resources. Unit: ACUs.

*   If the value of GroupType is **Interactive**, the amount of reserved computing resources that are not allocated in the cluster is returned in increments of 16 ACUs.
*   If the value of GroupType is **Job**, the amount of reserved computing resources that are not allocated in the cluster is returned in increments of 8 ACUs.', example='512'),
        minComputeResource?: int32(name='MinComputeResource', description='The minimum amount of reserved computing resources. Unit: ACUs.

*   If the value of GroupType is **Interactive**, 16 is returned.
*   If the value of GroupType is **Job**, 0 is returned.', example='0'),
      }
    ](name='ResourceGroups', description='The queried resource groups.'),
    step?: long(name='Step', description='The step size of resources. Unit: AnalyticDB compute units (ACUs).

*   If the value of GroupType is **Interactive**, 16 is returned.
*   If the value of GroupType is **Job**, 8 is returned.', example='8'),
  }(name='Data', description='The queried resource groups.'),
  httpStatusCode?: long(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  message?: string(name='Message', description='The returned message.

*   If the request was successful, a success message is returned.
*   If the request failed, an error message is returned.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='6FC370D7-1D4C-5A8E-805E-F73366382C66'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='True'),
}

model DescribeApsResourceGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeApsResourceGroupsResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describeApsResourceGroups(request: DescribeApsResourceGroupsRequest): DescribeApsResourceGroupsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeApsResourceGroups', 'POST', '/', 'json', true, 'form', request);
}

model DescribeAuditLogRecordsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-t4nj8619bz2w3****', position='Query'),
  DBName?: string(name='DBName', description='The name of the database on which the SQL statement was executed.', example='adb_demo', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.

> 

*   The end time must be later than the start time.

*   The maximum time range that can be specified is 24 hours.', example='2022-08-12T17:08Z', position='Query'),
  hostAddress?: string(name='HostAddress', description='The IP address and port number of the client that is used to execute the SQL statement.', example='100.104.XX.XX:43908', position='Query'),
  order?: string(name='Order', description='The order in which to sort the retrieved entries by field. Specify this parameter in the JSON format. The value is an ordered array that uses the order of the input array and contains `Field` and `Type`. Example: `[{"Field":"ExecutionStartTime","Type":"Desc"},{"Field":"ScanRows","Type":"Asc"}]`. Fields:

*   `Field`: the field that is used to sort the retrieved entries. Valid values:

    *   **HostAddress**: the IP address of the client that is used to connect to the database.
    *   **UserName**: the username.
    *   **ExecutionStartTime**: the start time of the query execution.
    *   **QueryTime**: the amount of time consumed to execute the SQL statement.
    *   **PeakMemoryUsage**: the maximum memory usage when the SQL statement is executed.
    *   **ScanRows**: the number of rows to be scanned from a data source in the task.
    *   **ScanSize**: the amount of data to be scanned.
    *   **ScanTime**: the total amount of time consumed to scan data.
    *   **PlanningTime**: the amount of time consumed to generate execution plans.
    *   **WallTime**: the accumulated CPU Time values of all operators in the query on each node.
    *   **ProcessID**: the process ID.

*   `Type`: the sorting type of the retrieved entries. Valid values:

    *   **Desc**: descending order.
    *   **Asc**: ascending order.', example='[{"Field":"ExecuteTime","Type":"Desc"},{"Field":"HostAddress","Type":"Asc"}]', position='Query'),
  orderType?: string(name='OrderType', description='The sorting order of the retrieved entries. Valid values:

*   **asc**: sorts the retrieved entries by time in ascending order.
*   **desc**: sorts the retrieved entries by time in descending order.', example='asc', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **10** (default)
*   **30**
*   **50**
*   **100**', example='10', minimum=10, maximum=100, position='Query'),
  proxyUser?: string(name='ProxyUser', description='A reserved parameter.', example='none', position='Query'),
  queryKeyword?: string(name='QueryKeyword', description='The keyword based on which audit logs are queried. You can set this parameter to a value of the STRING type.', example='adb', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

> You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  sqlType?: string(name='SqlType', description='The type of the SQL statement. Valid values:

*   **DELETE**
*   **SELECT**
*   **UPDATE**
*   **INSERT INTO SELECT**
*   **ALTER**
*   **DROP**
*   **CREATE**

>  You can query only a single type of SQL statements at a time. If you leave this parameter empty, the **SELECT** statements are queried.', example='SELECT', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.

> SQL audit logs can be queried only when SQL audit is enabled. Only SQL audit logs within the last 30 days can be queried. If SQL audit was disabled and re-enabled, only SQL audit logs from the time when SQL audit was re-enabled can be queried.', example='2022-08-12T04:17Z', position='Query'),
  succeed?: string(name='Succeed', description='Specifies whether the execution of the SQL statement succeeds. Valid values:

*   **true**
*   **false**', example='true', position='Query'),
  user?: string(name='User', description='The username that is used to execute the SQL statement.', example='test', position='Query'),
}

model DescribeAuditLogRecordsResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-t4nj8619bz2w3****'),
  items?: [ 
    {
      connId?: string(name='ConnId', description='The connection ID.', example='14356****'),
      DBName?: string(name='DBName', description='The name of the database on which the SQL statement was executed.', example='adb_demo'),
      executeTime?: string(name='ExecuteTime', description='The start time of the execution of the SQL statement. The time is displayed in the ISO 8601 standard in the yyyy-MM-dd HH:mm:ss format. The time must be in UTC.', example='2022-08-12 10:10:00'),
      hostAddress?: string(name='HostAddress', description='The IP address and port number of the client that is used to execute the SQL statement.', example='100.104.XX.XX:43908'),
      processID?: string(name='ProcessID', description='The task ID.', example='202106081752021720161662490345362390'),
      SQLText?: string(name='SQLText', description='The SQL statement.', example='SELECT * FROM adb_hdfs_import_source'),
      SQLType?: string(name='SQLType', description='The type of the SQL statement.', example='SELECT'),
      succeed?: string(name='Succeed', description='Indicates whether the SQL statement was successfully executed. Valid values:

*   **true**
*   **false**', example='true'),
      totalTime?: string(name='TotalTime', description='The amount of time that is consumed to execute the SQL statement. Unit: milliseconds.', example='216'),
      user?: string(name='User', description='The username that is used to execute the SQL statement.', example='test'),
    }
  ](name='Items', description='The queried SQL audit logs.'),
  pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='8A564B7F-8C00-43C0-8EC5-919FBB70573'),
  totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='6974'),
}

model DescribeAuditLogRecordsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAuditLogRecordsResponseBody(name='body'),
}

/**
  * *   SQL audit logs can be queried only when SQL audit is enabled. Only SQL audit logs within the last 30 days can be queried. If SQL audit was disabled and re-enabled, only SQL audit logs from the time when SQL audit was re-enabled can be queried. The following operations are not recorded in SQL audit logs: **INSERT INTO VALUES**, **REPLACE INTO VALUES**, and **UPSERT INTO VALUES**.
  * *   For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeAuditLogRecords(request: DescribeAuditLogRecordsRequest): DescribeAuditLogRecordsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAuditLogRecords', 'POST', '/', 'json', false, 'json', request);
}

model DescribeBackupPolicyRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.', example='am-uf6s7oa710rbu0x3b', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model DescribeBackupPolicyResponseBody = {
  backupRetentionPeriod?: int32(name='BackupRetentionPeriod', description='The number of days for which data backup files are retained.', example='7'),
  enableBackupLog?: string(name='EnableBackupLog', description='Indicates whether log backup is enabled. Valid values:

*   **Enable**
*   **Disable**', example='true'),
  logBackupRetentionPeriod?: int32(name='LogBackupRetentionPeriod', description='The number of days for which the log backup files are retained.', example='7'),
  preferredBackupPeriod?: string(name='PreferredBackupPeriod', description='The cycle based on which backups are performed. If more than one day of the week are specified, the days of the week are separated by commas (,). Valid value:

*   Monday
*   Tuesday
*   Wednesday
*   Thursday
*   Friday
*   Saturday
*   Sunday', example='Wednesday,Saturday'),
  preferredBackupTime?: string(name='PreferredBackupTime', description='The data backup time. The time is in the HH:mmZ-HH:mmZ format. The time is displayed in UTC.', example='15:00Z-16:00Z'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DescribeBackupPolicyResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeBackupPolicyResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeBackupPolicy(request: DescribeBackupPolicyRequest): DescribeBackupPolicyResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeBackupPolicy', 'POST', '/', 'json', false, 'json', request);
}

model DescribeBackupsRequest {
  backupId?: string(name='BackupId', description='The backup set ID.', example='1679758862', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.', example='am-bp18934i73vb5****', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC. The end time must be later than the start time.', example='2023-02-20T02:30Z', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   30
*   50
*   100

Default value: 30.', example='30', minimum=30, maximum=100, position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mmZ format. The time must be in UTC.', example='2011-06-01T16:00Z', position='Query'),
}

model DescribeBackupsResponseBody = {
  items?: {
    backup?: [ 
    {
      backupEndTime?: string(name='BackupEndTime', description='The end time of the backup.', example='2022-06-02T16:00Z'),
      backupId?: string(name='BackupId', description='The backup set ID.', example='32732****'),
      backupMethod?: string(name='BackupMethod', description='The backup method. Snapshot is returned.', example='Snapshot'),
      backupSize?: int32(name='BackupSize', description='The size of the backup set. Unit: bytes.', example='2167808'),
      backupStartTime?: string(name='BackupStartTime', description='The start time of the backup.', example='2022-06-01T16:00Z'),
      backupType?: string(name='BackupType', description='The backup type. Valid values:

*   **FullBackup**
*   **IncrementalBackup**', example='FullBackup'),
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='am-bp11q28kvl688****'),
    }
  ](name='Backup')
  }(name='Items', description='The queried backup sets.'),
  pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
  pageSize?: string(name='PageSize', description='The number of entries per page.', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='CE17270B-F8F8-5A31-9DB4-DADDFDAD7940'),
  totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='300'),
}

model DescribeBackupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeBackupsResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeBackups(request: DescribeBackupsRequest): DescribeBackupsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeBackups', 'POST', '/', 'json', false, 'json', request);
}

model DescribeClusterAccessWhiteListRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
}

model DescribeClusterAccessWhiteListResponseBody = {
  items?: {
    IPArray?: [ 
    {
      DBClusterIPArrayAttribute?: string(name='DBClusterIPArrayAttribute', description='The attribute of the whitelist.

> Whitelists with the **hidden** attribute are not displayed in the console. Those whitelists are used to access Data Transmission Service (DTS) and PolarDB.', example='hidden'),
      DBClusterIPArrayName?: string(name='DBClusterIPArrayName', description='The name of the IP address whitelist.

Each cluster supports up to 50 IP address whitelists.', example='test'),
      securityIPList?: string(name='SecurityIPList', description='The IP addresses in the IP address whitelist. Up to 500 IP addresses can be returned. Multiple IP addresses are separated by commas (,).', example='127.0.xx.xx'),
    }
  ](name='IPArray')
  }(name='Items', description='The queried IP address whitelists.'),
  requestId?: string(name='RequestId', description='The request ID.', example='370D09FD-442A-5225-AAD3-7362CAE39177'),
}

model DescribeClusterAccessWhiteListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeClusterAccessWhiteListResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeClusterAccessWhiteList(request: DescribeClusterAccessWhiteListRequest): DescribeClusterAccessWhiteListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeClusterAccessWhiteList', 'POST', '/', 'json', false, 'json', request);
}

model DescribeClusterNetInfoRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~129857~~) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region, including cluster IDs.', example='amv-wz9dqvn0o7****', position='Query'),
  engine?: string(name='Engine', description='The database engine of the cluster. Valid values:

*   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
*   **Clickhouse**: the wide table engine.', example='Clickhouse', position='Query'),
}

model DescribeClusterNetInfoResponseBody = {
  clusterNetworkType?: string(name='ClusterNetworkType', description='The network type of the cluster. Only the Virtual Private Cloud (VPC) network type is supported. **VPC** is returned.', example='VPC'),
  items?: {
    address?: [ 
    {
      connectionString?: string(name='ConnectionString', description='The endpoint of the cluster.

*   If NetType is set to VPC, the VPC endpoint of the cluster is returned.
*   If NetType is set to Public, the public endpoint of the cluster is returned.', example='amv-wz9dqvn0o7****.ads.aliyuncs.com'),
      connectionStringPrefix?: string(name='ConnectionStringPrefix', description='The prefix of the endpoint.

*   If NetType is set to VPC, the prefix of the VPC endpoint is returned.
*   If NetType is set to Public, the prefix of the public endpoint is returned.', example='amv-wz9dqvn0o7****'),
      IPAddress?: string(name='IPAddress', description='The IP address of the endpoint.

*   If NetType is set to VPC, the private IP address of the cluster is returned.
*   If NetType is set to Public, the public IP address of the cluster is returned.', example='192.168.xx.xx'),
      netType?: string(name='NetType', description='The network type of the cluster. Valid values:

*   **Public**: Internet.
*   **VPC**: VPC.', example='VPC'),
      port?: string(name='Port', description='The port number that is used to connect to the cluster. **3306** is returned.', example='3306'),
      ports?: {
        ports?: [ 
        {
          port?: string(name='Port', description='The port.', example='3306'),
          protocol?: string(name='Protocol', description='The type of the protocol. Valid values:

*   **tcp**
*   **http**
*   **https**
*   **mysql**', example='mysql'),
        }
      ](name='ports')
      }(name='Ports', description='The ports.'),
      VPCId?: string(name='VPCId', description='The VPC ID.

>  If NetType is set to Public, an empty string is returned.', example='vpc-8vbhucmd5b****'),
      vSwitchId?: string(name='VSwitchId', description='The vSwitch ID of the cluster.

>  If NetType is set to Public, an empty string is returned.', example='vsw-bp1syh8vvw8yec****'),
    }
  ](name='Address')
  }(name='Items', description='The queried network information about the cluster.'),
  requestId?: string(name='RequestId', description='The request ID.', example='69A29B65-CD0C-52B1-BE42-8B454569747F'),
}

model DescribeClusterNetInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeClusterNetInfoResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeClusterNetInfo(request: DescribeClusterNetInfoRequest): DescribeClusterNetInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeClusterNetInfo', 'POST', '/', 'json', false, 'json', request);
}

model DescribeClusterResourceDetailRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.', example='am-bp1jj9xqft1po****', position='Query'),
}

model DescribeClusterResourceDetailResponseBody = {
  code?: int32(name='Code', description='The HTTP status code.', example='200'),
  data?: {
    computeResource?: string(name='ComputeResource', description='The amount of reserved computing resources. Unit: AnalyticDB compute units (ACUs). Valid values: 0 to 4096. The value must be in increments of 16 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.', example='16ACU'),
    DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-adbxxxxx'),
    freeComputeResource?: string(name='FreeComputeResource', description='The amount of idle reserved computing resources. Unit: ACUs. Valid values: 0 to 4096. The value must be in increments of 16 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.', example='0ACU'),
    resourceGroupList?: [ 
      {
        clusterMode: string(name='ClusterMode', description='A reserved parameter.', example='0'),
        clusterSizeResource?: string(name='ClusterSizeResource', description='A reserved parameter.', example='0'),
        enableSpot?: boolean(name='EnableSpot', description='Indicates whether the preemptible instance feature is enabled for the resource group. After the preemptible instance feature is enabled, you are charged for resources at a lower unit price but the resources are probably released. Valid values:

*   **true**
*   **false**

The True value is returned only for job resource groups.', example='true'),
        maxClusterCount?: int32(name='MaxClusterCount', description='A reserved parameter.', example='0'),
        maxComputeResource?: string(name='MaxComputeResource', description='The maximum amount of reserved computing resources. Unit: ACUs.', example='128ACU'),
        minClusterCount?: int32(name='MinClusterCount', description='A reserved parameter.', example='0'),
        minComputeResource?: string(name='MinComputeResource', description='The minimum amount of reserved computing resources. Unit: ACUs.', example='16ACU'),
        poolId?: long(name='PoolId', description='The resource group ID.', example='17'),
        poolName?: string(name='PoolName', description='The name of the resource group.', example='testadb'),
        poolType?: string(name='PoolType', description='The type of the resource group.', example='interactive'),
        poolUsers?: string(name='PoolUsers', description='The user of the resource group.', example='user1'),
        runningClusterCount?: int32(name='RunningClusterCount', description='A reserved parameter.', example='0'),
        status?: string(name='Status', description='The status of the resource group. Valid values:

*   **running**
*   **deleting**
*   **scaling**', example='running'),
      }
    ](name='ResourceGroupList', description='The resource groups.'),
    storageResource?: string(name='StorageResource', description='The amount of reserved storage resources. Unit: ACUs. Valid values: 0 to 2064. The value must be in increments of 24 ACUs. Each ACU is equivalent to 1 core and 4 GB memory.', example='24ACU'),
  }(name='Data', description='The information about the cluster resource usage.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DescribeClusterResourceDetailResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeClusterResourceDetailResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see Endpoints.
  *
 */
async function describeClusterResourceDetail(request: DescribeClusterResourceDetailRequest): DescribeClusterResourceDetailResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeClusterResourceDetail', 'POST', '/', 'json', false, 'json', request);
}

model DescribeClusterResourceUsageRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp11q28kvl688****', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-08-22T01:06:00Z', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.', example='2022-11-29T10:20Z', position='Query'),
}

model DescribeClusterResourceUsageResponseBody = {
  code?: int32(name='Code', description='The HTTP status code.', example='200'),
  data?: {
    acuInfo?: [ 
      {
        name?: string(name='Name', description='The resource usage metric. Valid values:

*   `TotalAcuNumber`: the total number of ACUs.
*   `ReservedAcuNumber`: the number of ACUs for the reserved resources.
*   `ReservedAcuUsageNumber`: the number of ACUs for the reserved resources that are used.', example='TotalAcuNumber'),
        values?: [ string ](name='Values', description='The values of the metric at specific points in time.'),
      }
    ](name='AcuInfo', description='The AnalyticDB compute unit (ACU) usage of the cluster.'),
    DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-uf6dj23rt5zo9s9d'),
    endTime?: string(name='EndTime', description='The end time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.', example='2023-03-23T02:31Z'),
    startTime?: string(name='StartTime', description='The start time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.', example='2023-03-14T03:42:15Z'),
  }(name='Data', description='The queried resource usage.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEAW'),
}

model DescribeClusterResourceUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeClusterResourceUsageResponseBody(name='body'),
}

async function describeClusterResourceUsage(request: DescribeClusterResourceUsageRequest): DescribeClusterResourceUsageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeClusterResourceUsage', 'GET', '/', 'json', false, 'json', request);
}

model DescribeColumnsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-bp1xxxxxxxx47', position='Query'),
  regionId: string(name='RegionId', description='The region ID.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
  tableName?: string(name='TableName', description='The name of the table.', example='test', position='Query'),
}

model DescribeColumnsResponseBody = {
  items?: {
    column?: [ 
    {
      autoIncrementColumn?: boolean(name='AutoIncrementColumn', description='Indicates whether the column is an auto-increment column. Valid values:

*   **true**
*   **false**', example='true'),
      columnName?: string(name='ColumnName', description='The name of the column.', example='id'),
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-bp111m2cfrdl1****'),
      primaryKey?: boolean(name='PrimaryKey', description='Indicates whether the column is the primary key of the table. Valid values:

*   **true**
*   **false**', example='false'),
      schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
      tableName?: string(name='TableName', description='The name of the table.', example='test'),
      type?: string(name='Type', description='The data type of the column.', example='bigint'),
    }
  ](name='Column')
  }(name='Items', description='The queried columns.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-XXX442913CEF'),
}

model DescribeColumnsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeColumnsResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describeColumns(request: DescribeColumnsRequest): DescribeColumnsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeColumns', 'POST', '/', 'json', false, 'json', request);
}

model DescribeComputeResourceUsageRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.', example='am-bp1xxxxxxxx47', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.', example='2023-02-05T03:45:00Z', position='Query'),
  resourceGroupName: string(name='ResourceGroupName', description='The name of the resource group.', example='test', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2023-02-04T03:45:00Z', position='Query'),
}

model DescribeComputeResourceUsageResponseBody = {
  code?: int32(name='Code', description='The HTTP status code.', example='200'),
  data?: {
    acuInfo?: [ 
      {
        name?: string(name='Name', description='The resource usage metric. Valid values:

*   `TotalAcuNumber`: the total number of ACUs.
*   `ReservedAcuNumber`: the number of ACUs for the reserved resources.
*   `ReservedAcuUsageNumber`: the number of ACUs for the reserved resources that are used.', example='TotalAcuNumber'),
        values?: [ string ](name='Values', description='The values of the metric at specific points in time.'),
      }
    ](name='AcuInfo', description='The AnalyticDB compute unit (ACU) usage of the cluster.'),
    DBClusterId?: string(name='DBClusterId', description='The cluster ID.', example='amv-clusterxxx'),
    endTime?: string(name='EndTime', description='The end time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.', example='2023-06-07T02:37:00Z'),
    resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.', example='test'),
    resourceGroupType?: string(name='ResourceGroupType', description='The type of the resource group.', example='interative'),
    startTime?: string(name='StartTime', description='The start time of the query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-04-24T07:00:00Z'),
  }(name='Data', description='The queried resource usage.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEAW'),
}

model DescribeComputeResourceUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeComputeResourceUsageResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see Endpoints.
  *
 */
async function describeComputeResourceUsage(request: DescribeComputeResourceUsageRequest): DescribeComputeResourceUsageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeComputeResourceUsage', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDBClusterAttributeRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Warehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****', position='Query'),
}

model DescribeDBClusterAttributeResponseBody = {
  items?: {
    DBCluster?: [ 
    {
      clickhouseEngineCacheSize?: int32(name='ClickhouseEngineCacheSize', description='The cache size of the ClickHouse wide table engine. Unit: GB. If a value of -1 is returned, the ClickHouse wide table engine is disabled. If a value other than -1 is returned, this parameter indicates the disk cache size.', example='100'),
      clickhouseEngineEnabled?: boolean(name='ClickhouseEngineEnabled', description='Indicates whether the ClickHouse wide table engine is enabled. Valid values:

*   **true**
*   **false**', example='true'),
      commodityCode?: string(name='CommodityCode', description='The billing method of the cluster. Valid values:

*   **ads**: pay-as-you-go.
*   **ads_pre**: subscription.', example='ads_pre'),
      computeResource?: string(name='ComputeResource', description='The specifications of reserved computing resources. Each ACU is approximately equal to 1 core and 4 GB memory. Computing resources are used to compute data. The increase in the computing resources can accelerate queries. You can scale computing resources based on your business requirements.', example='16ACU'),
      computeResourceTotal?: string(name='ComputeResourceTotal', description='The total amount of computing resources in the cluster. Each ACU is approximately equal to 1 core and 4 GB memory.', example='48ACU'),
      connectionString?: string(name='ConnectionString', description='The public endpoint that is used to connect to the cluster.', example='amv-wz9509beptiz****.ads.aliyuncs.com'),
      creationTime?: string(name='CreationTime', description='The time when the cluster was created. The time follows the ISO 8601 standard in the `YYYY-MM-DDThh:mm:ssZ` format. The time is displayed in UTC.', example='2022-07-01T09:50:18Z'),
      DBClusterDescription?: string(name='DBClusterDescription', description='The description of the cluster.', example='adb_test'),
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz9509beptiz****'),
      DBClusterNetworkType?: string(name='DBClusterNetworkType', description='The network type of the cluster. **VPC** is returned.', example='VPC'),
      DBClusterStatus?: string(name='DBClusterStatus', description='The status of the cluster. Valid values:

*   **Preparing**
*   **Creating**
*   **Running**
*   **Deleting**
*   **Restoring**
*   **ClassChanging**
*   **NetAddressCreating**
*   **NetAddressDeleting**
*   **NetAddressModifying**', example='Running'),
      DBClusterType?: string(name='DBClusterType', description='The type of the cluster. By default, **Common** is returned, which indicates a common cluster.', example='Common'),
      DBVersion?: string(name='DBVersion', description='The engine version of the AnalyticDB for MySQL Data Lakehouse Edition cluster. **5.0** is returned.', example='5.0'),
      engine?: string(name='Engine', description='The engine of the cluster. **AnalyticDB** is returned.', example='AnalyticDB'),
      engineVersion?: string(name='EngineVersion', description='The minor version of the cluster.', example='3.1.16'),
      expireTime?: string(name='ExpireTime', description='The time when the cluster expires.

*   If the billing method of the cluster is subscription, the actual expiration time is returned.
*   If the billing method of the cluster is pay-as-you-go, null is returned.', example='2022-10-01T09:50:18Z'),
      expired?: string(name='Expired', description='Indicates whether the subscription cluster has expired. Valid values:

*   **true**
*   **false**

> 

*   If the cluster has expired, the system locks or releases the cluster within a period of time. We recommend that you renew the expired cluster. For more information, see [Renewal policy](~~135248~~).

*   This parameter is not returned for pay-as-you-go clusters.', example='false'),
      kmsId?: string(name='KmsId', description='The ID of the key that is used to encrypt disk data.

>  This parameter is returned only when disk encryption is enabled.', example='e1935511-cf88-1123-a0f8-1be8d251****'),
      lockMode?: string(name='LockMode', description='The lock mode of the cluster. Valid values:

*   **Unlock**: The cluster is not locked.
*   **ManualLock**: The cluster is manually locked.
*   **LockByExpiration**: The cluster is automatically locked due to cluster expiration.', example='ManualLock'),
      lockReason?: string(name='LockReason', description='The reason why the cluster is locked.

>  This parameter is returned only when the cluster was locked. **instance_expire** is returned.', example='instance_expire'),
      maintainTime?: string(name='MaintainTime', description='The maintenance window of the cluster. The time is displayed in the `HH:mmZ-HH:mmZ` format in UTC.

>  For more information about maintenance windows, see [Configure a maintenance window](~~122569~~).', example='04:00Z-05:00Z'),
      mode?: string(name='Mode', description='The mode of the cluster. By default, **flexible** is returned, which indicates that the cluster is in elastic mode.', example='flexible'),
      payType?: string(name='PayType', description='The billing method of the cluster. Valid values:

*   **Postpaid**: pay-as-you-go.
*   **Prepaid**: subscription.', example='Prepaid'),
      port?: int32(name='Port', description='The port number that is used to connect to the cluster.', example='3306'),
      productForm?: string(name='ProductForm', description='A reserved parameter.', example='N/A'),
      productVersion?: string(name='ProductVersion', description='The edition of the cluster. Valid values:

*   **BasicVersion**: Basic Edition.
*   **EnterpriseVersion**: Enterprise Edition.', example='BasicVersion'),
      regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
      reservedACU?: string(name='ReservedACU', description='The amount of remaining reserved computing resources that are available in the cluster. Each ACU is approximately equal to 1 core and 4 GB memory.', example='24ACU'),
      reservedNodeCount?: int32(name='ReservedNodeCount', description='A reserved parameter.', example='N/A'),
      reservedNodeSize?: string(name='ReservedNodeSize', description='A reserved parameter.', example='N/A'),
      resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='rg-acfmyiu4ekp****'),
      storageResource?: string(name='StorageResource', description='The specifications of reserved storage resources. Each AnalyticDB compute unit (ACU) is approximately equal to 1 core and 4 GB memory. Storage resources are used to read and write data. The increase in the storage resources can improve the read and write performance of the cluster.', example='24ACU'),
      storageResourceTotal?: string(name='StorageResourceTotal', description='The total amount of storage resources in the cluster. Each ACU is approximately equal to 1 core and 4 GB memory.', example='24ACU'),
      supportedFeatures?: map[string]string(name='SupportedFeatures', description='Reserved parameters.'),
      tags?: {
        tag?: [ 
        {
          key?: string(name='Key', description='The tag key.

>  You can call the [TagResources](~~179253~~) operation to add tags to a cluster.', example='tag1'),
          value?: string(name='Value', description='The tag value.', example='test1'),
        }
      ](name='Tag')
      }(name='Tags', description='The tags that are added to the cluster.'),
      userENIStatus?: boolean(name='UserENIStatus', description='Indicates whether Elastic Network Interface (ENI) is enabled. Valid values:

*   **true**
*   **false**', example='false'),
      VPCId?: string(name='VPCId', description='The virtual private cloud (VPC) ID of the cluster.', example='vpc-bp13h7uzhulpu****'),
      vSwitchId?: string(name='VSwitchId', description='The vSwitch ID of the cluster.', example='vsw-uf629gydd54ld****'),
      zoneId?: string(name='ZoneId', description='The zone ID of the cluster.', example='cn-hangzhou-h'),
    }
  ](name='DBCluster')
  }(name='Items', description='The queried information about the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.'),
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model DescribeDBClusterAttributeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeDBClusterAttributeResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeDBClusterAttribute(request: DescribeDBClusterAttributeRequest): DescribeDBClusterAttributeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDBClusterAttribute', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDBClusterHealthStatusRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.', example='amv-uf6o6m8p6x7v****', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~143074~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
}

model DescribeDBClusterHealthStatusResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail'),
  cs?: {
    activeCount?: long(name='ActiveCount', description='The number of healthy access nodes.', example='2'),
    expectedCount?: long(name='ExpectedCount', description='The total number of access nodes.', example='2'),
    riskCount?: long(name='RiskCount', description='The number of risky nodes.', example='0'),
    status?: string(name='Status', description='The health state of access nodes. Valid values:

*   **RISK**
*   **NORMAL**
*   **UNAVAILABLE**', example='NORMAL'),
    unavailableCount?: long(name='UnavailableCount', description='The number of unavailable access nodes.', example='0'),
  }(name='CS', description='The access nodes of the queried cluster.'),
  executor?: {
    activeCount?: long(name='ActiveCount', description='The number of healthy access nodes.', example='2'),
    expectedCount?: long(name='ExpectedCount', description='The total number of compute nodes.', example='2'),
    riskCount?: long(name='RiskCount', description='The number of risky nodes.', example='0'),
    status?: string(name='Status', description='The health state of compute node groups. Valid values:

*   **RISK**
*   **NORMAL**
*   **UNAVAILABLE**', example='NORMAL'),
    unavailableCount?: long(name='UnavailableCount', description='The number of unavailable access nodes.', example='0'),
  }(name='Executor', description='The compute node groups of the queried cluster.'),
  instanceStatus?: string(name='InstanceStatus', description='The health state of the cluster. Valid values:

*   **RISK**
*   **NORMAL**
*   **UNAVAILABLE**

>  When the states of the access nodes, compute node groups, and storage node groups of a cluster are all **NORMAL** and a connection to the cluster is established, the state of the cluster is **NORMAL**. When the state of the access nodes, compute node groups, or storage node groups of the cluster is **RISK**, the state of the cluster is **RISK**. When the state of the access nodes, compute node groups, or storage node groups of the cluster is **UNAVAILABLE**, the state of the cluster is **UNAVAILABLE**.', example='NORMAL'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEA'),
  worker?: {
    activeCount?: long(name='ActiveCount', description='The number of healthy storage node groups.', example='2'),
    expectedCount?: long(name='ExpectedCount', description='The total number of storage node groups.', example='2'),
    riskCount?: long(name='RiskCount', description='The number of risky storage node groups.', example='0'),
    status?: string(name='Status', description='The health state of storage node groups. Valid values:

*   **RISK**
*   **NORMAL**
*   **UNAVAILABLE**', example='NORMAL'),
    unavailableCount?: long(name='UnavailableCount', description='The number of unavailable storage node groups.', example='0'),
  }(name='Worker', description='The storage node groups of the queried cluster.'),
}

model DescribeDBClusterHealthStatusResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeDBClusterHealthStatusResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeDBClusterHealthStatus(request: DescribeDBClusterHealthStatusRequest): DescribeDBClusterHealthStatusResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDBClusterHealthStatus', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDBClusterPerformanceRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~~612397~~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.', example='amv-bp1hx5n1o8f61****', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.

> The end time must be later than the start time. The maximum time range that can be specified is two days.', example='2022-03-11T15:01Z', position='Query'),
  key?: string(name='Key', description='The performance metrics to be queried. Separate multiple values with commas (,). Valid values:

*   CPU

    *   **AnalyticDB_CPU_Usage_Percentage**: the average CPU utilization.

*   Connections

    *   **AnalyticDB_Instance_Connection_Count**: the number of database connections.

*   Writes

    *   **AnalyticDB_TPS**: the write transactions per second (TPS).
    *   **AnalyticDB_InsertRT**: the write response time.
    *   **AnalyticDB_InsertBytes**: the write throughput.

*   Queries

    *   **AnalyticDB_QPS**: the queries per second (QPS).
    *   **AnalyticDB_QueryRT**: the query response time.
    *   **AnalyticDB_QueryWaitTime**: the query wait time.

*   Disks

    *   **AnalyticDB_Disk_IO_Avg_Usage_Percentage**: the average I/O utilization.
    *   **AnalyticDB_Disk_IO_Avg_Waiting_Time**: the average I/O wait time.
    *   **AnalyticDB_IO_Throughput**: the disk throughput.
    *   **AnalyticDB_IOPS**: the disk IOPS.
    *   **AnalyticDB_Disk_Usage**: the disk space that is used.
    *   **AnalyticDB_Disk_Usage_Percentage**: the disk usage.
    *   **AnalyticDB_Hot_Data_Usage**: the disk space that is used by hot data.
    *   **AnalyticDB_Cold_Data_Usage**: the disk space that is used by code data.

>  This parameter must be specified.', example='AnalyticDB_CPU_Usage_Percentage', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

> You can call the [DescribeRegions](~~612393~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourcePools?: string(name='ResourcePools', description='The resource group ID.', example='user_default', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.', example='2022-03-10T23:56Z', position='Query'),
}

model DescribeDBClusterPerformanceResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1hx5n1o8f61****'),
  endTime?: string(name='EndTime', description='The end time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time is displayed in UTC.', example='2022-03-11T15:01Z'),
  performances?: [ 
    {
      key?: string(name='Key', description='The name of the performance metric.', example='AnalyticDB_CPU_Usage_Percentage'),
      series?: [ 
        {
          name?: string(name='Name', description='*   CPU

    *   **AnalyticDB_CPU_Usage_Percentage**: the CPU utilization.

        *   AnalyticDB_Storage_CPU_Avg_Usage_Percentage: the average CPU utilization across storage nodes.
        *   AnalyticDB_Storage_CPU_Max_Usage_Percentage: the maximum CPU utilization across storage nodes.
        *   AnalyticDB_Compute_CPU_Max_Usage_Percentage: the average CPU utilization across compute nodes.
        *   AnalyticDB_Compute_CPU_Max_Usage_Percentage: the maximum CPU utilization across compute nodes.
        *   AnalyticDB_CS_CPU_Avg_Usage_Percentage: the average CPU utilization across access nodes.
        *   AnalyticDB_CS_CPU_Max_Usage_Percentage: the maximum CPU utilization across access nodes.

*   Connections

    *   **AnalyticDB_Instance_Connection_Count**: the number of connections to the cluster.

        *   AnalyticDB_Instance_Connection_Count: the number of connections to the cluster.

*   Writes

    *   **AnalyticDB_TPS**: the write TPS.

        *   tps: the sum of the insert_tps, update_tps, delete_tps, and load_tps values.
        *   insert_tps: the number of successful INSERT INTO VALUES operations per second.
        *   update_tps: the number of successful UPDATE operations per second.
        *   delete_tps: the number of successful DELETE operations per second.
        *   load_tps: the number of successful INSERT OVERWRITE operations per second.

    *   **AnalyticDB_InsertRT**: the write response time.

        *   AnalyticDB_Avg_InsertRT: the average amount of time consumed by writes.
        *   AnalyticDB_Max_InsertRT: the maximum amount of time consumed by a single write.

    *   **AnalyticDB_InsertBytes**: the write throughput.

        *   AnalyticDB_InsertBytes: the amount of written data.

*   Updates

    *   **AnalyticDB_UpdateRT**: the update response time.

        *   updateinto_avg_rt: the average amount of time consumed by updates.
        *   updateinto_max_rt: the maximum amount of time consumed by a single update.

*   Deletes

    *   **AnalyticDB_DeleteRT**: the delete response time.

        *   delete_avg_rt: the average amount of time consumed by deletes.
        *   delete_max_rt: the maximum amount of time consumed by a single delete.

*   Queries

    *   **AnalyticDB_QPS**: the QPS.

        *   AnalyticDB_QPS: the number of SELECT operations completed per second.
        *   AnalyticDB_ETL_QPS: the number of INSERT OVERWRITE operations completed per second.

    *   **AnalyticDB_QueryRT**: the query response time.

        *   AnalyticDB_Avg_QueryRT: the average amount of time consumed by queries.
        *   AnalyticDB_Max_QueryRT: the maximum amount of time consumed by a single query.
        *   etl_avg_rt: the average amount of time consumed by extract, transform, load (ETL) operations.
        *   etl_max_rt: the maximum amount of time consumed by a single ETL operation.

    *   **AnalyticDB_QueryWaitTime**: the query wait time.

        *   AnalyticDB_Avg_QueryWaitTime: the average wait time for SELECT and ETL operations.
        *   AnalyticDB_Max_QueryWaitTime: the maximum wait time for SELECT and ETL operations.

    *   AnalyticDB_QueryFailedRatio: the query failure rate.

        *   query_failed_ratio: the failure rate of SELECT and ETL operations.

*   Disks

    *   **AnalyticDB_IO_Throughput**: the disk I/O throughput.

        *   AnalyticDB_Storage_Read_IO_Throughput: the average read throughput across storage nodes.
        *   AnalyticDB_Storage_Write_IO_Throughput: the average write throughput across storage nodes.
        *   AnalyticDB_Compute_Read_IO_Throughput: the average read throughput across compute nodes.
        *   AnalyticDB_Compute_Write_IO_Throughput: the average write throughput across compute nodes.

    *   **AnalyticDB_Disk_IO_Avg_Usage_Percentage**: the average I/O usage.

        *   AnalyticDB_Disk_IO_Avg_Usage_Percentage: the average I/O usage across storage nodes.

    *   **AnalyticDB_Disk_IO_Avg_Waiting_Time**: the average I/O wait time.

        *   AnalyticDB_Disk_IO_Avg_Waiting_Time: the average I/O wait time of storage nodes.

    *   **AnalyticDB_IOPS**: the disk IOPS.

        *   AnalyticDB_Storage_Read_IOPS: the average read IOPS of storage nodes.
        *   AnalyticDB_Storage_Write_IOPS: the average write IOPS of storage nodes.
        *   AnalyticDB_Compute_Read_IOPS: the average read IOPS of compute nodes.
        *   AnalyticDB_Compute_Write_IOPS: the average write IOPS of compute nodes.

    *   **AnalyticDB_DiskUsage**: the disk storage that is used.

        *   disk_used_ratio: the average disk usage across nodes.
        *   worker_max_node_disk_used_ratio: the maximum disk usage across nodes.

    *   **AnalyticDB_Hot_Data_Usage**: the disk storage that is used by hot data.

        *   AnalyticDB_Hot_Data_Usage: the disk storage that is used by hot data.

    *   **AnalyticDB_Cold_Data_Usage**: the disk storage that is used by cold data.

        *   AnalyticDB_Cold_Data_Usage: the disk storage that is used by cold data.

    *   AnalyticDB_DiskUsedRatio: the node disk usage.

        *   disk_used_ratio: the average disk usage across nodes.
        *   worker_max_node_disk_used_ratio: the maximum disk usage across nodes.

    *   AnalyticDB_DiskUsedSize: the total data size of the cluster.

        *   user_used_disk_max: the maximum hot data size across nodes.
        *   user_used_disk_avg: the average hot data size across nodes.
        *   hot_disk_used: the hot data size.
        *   cold_disk_used: the cold data size.

*   Other

    *   **AnalyticDB_BuildTaskCount**: the number of BUILD jobs.

        *   max_build_task_count: the maximum number of running BUILD jobs across nodes.
        *   avg_build_task_count: the average number of running BUILD jobs across nodes.

    *   **AnalyticDB_ComputeMemoryUsedRatio**: the compute memory usage.

        *   max_worker_compute_memory_used_ratio: the maximum compute memory usage across storage nodes.
        *   avg_worker_compute_memory_used_ratio: the average compute memory usage across storage nodes.
        *   max_executor_compute_memory_used_ratio: the maximum compute memory usage across compute nodes.
        *   avg_executor_compute_memory_used_ratio: the average compute memory usage across compute nodes.

    *   AnalyticDB_UnavailableNodeCount: the number of unavailable nodes.

        *   worker_unavailable_node_count: the number of unavailable storage nodes.
        *   executor_unavailable_node_count: the number of unavailable compute nodes.

*   WLM

    *   AnalyticDB_WLM_ResubmitQueries_Count: the number of resubmitted WLM queries.

        *   AnalyticDB_WLM_ResubmitQueries_Count: the number of resubmitted WLM queries.

    *   AnalyticDB_WLM_SQA_AvgRt_MS: the average amount of time consumed by accelerated short WLM queries.

        *   AnalyticDB_WLM_SQA_AvgRt_MS: the average amount of time consumed by accelerated short WLM queries.

    *   AnalyticDB_WLM_SQA_Queries_Count: the number of accelerated short WLM queries.

        *   AnalyticDB_WLM_SQA_Queries_Count: the number of accelerated short WLM queries.

    *   AnalyticDB_WLM_TotalQueries_Count: the total number of WLM queries.

        *   AnalyticDB_WLM_TotalQueries_Count: the total number of WLM queries.

*   AnalyticDB Pipeline Service (APS)

    *   AnalyticDB_APS_BPS: the bytes per second (BPS) of APS provided by the AnalyticDB for MySQL Data Lakehouse Edition cluster.

        *   APS_Read_BPS: the read BPS of APS.

    *   AnalyticDB_APS_CPU: the CPU utilization of APS provided by the AnalyticDB for MySQL Data Lakehouse Edition cluster.

        *   APS_CPU_Avg_Usage_Percentage: the average CPU utilization of APS.
        *   APS_CPU_Max_Usage_Percentage: the maximum CPU utilization of APS.

    *   AnalyticDB_APS_Memory: the memory usage of APS provided by the AnalyticDB for MySQL Data Lakehouse Edition cluster.

        *   APS_Memory_Avg_Usage_Percentage: the average memory usage of APS.
        *   APS_Memory_Max_Usage_Percentage: the maximum memory usage of APS.

    *   AnalyticDB_APS_RPS: the number of records per second of APS provided by the AnalyticDB for MySQL Data Lakehouse Edition cluster.

        *   APS_Read_RPS: the number of read records per second of APS.

    *   AnalyticDB_APS_RT: the response time of APS provided by the AnalyticDB for MySQL Data Lakehouse Edition cluster.

        *   APS_Read_Avg_RT: the average response time of APS.
        *   APS_Read_Max_RT: the maximum response time of APS.', example='AnalyticDB_Storage_CPU_Avg_Usage_Percentage'),
          tags?: string(name='Tags', description='The tags that are added to the cluster.', example='{instance_name: "am-***"}'),
          values?: [ string ](name='Values', description='The values of the performance metric at different points in time.'),
        }
      ](name='Series', description='The queried performance metric data.'),
      unit?: string(name='Unit', description='The unit of the performance metric.', example='%'),
    }
  ](name='Performances', description='The queried performance metrics.'),
  requestId?: string(name='RequestId', description='The request ID.', example='BD8C3096-8BC6-51DF-A4AB-BACD9DC10435'),
  startTime?: string(name='StartTime', description='The start time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time is displayed in UTC.', example='2022-03-10T23:56Z'),
}

model DescribeDBClusterPerformanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeDBClusterPerformanceResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeDBClusterPerformance(request: DescribeDBClusterPerformanceRequest): DescribeDBClusterPerformanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDBClusterPerformance', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDBClusterSpaceSummaryRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-wz9v5sa7mm79z4l2', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  regionId: string(name='RegionId', description='The region ID.

>  You can call the [DescribeRegions](~~143074~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model DescribeDBClusterSpaceSummaryResponseBody = {
  data?: {
    coldData?: {
      dataSize?: long(name='DataSize', description='The data size of table records. Unit: bytes.', example='1048576'),
      indexSize?: long(name='IndexSize', description='The data size of regular indexes. Unit: bytes.', example='1048576'),
      otherSize?: long(name='OtherSize', description='The data size of other data. Unit: bytes.', example='1048576'),
      primaryKeyIndexSize?: long(name='PrimaryKeyIndexSize', description='The data size of primary key indexes. Unit: bytes.', example='1048576'),
      totalSize?: long(name='TotalSize', description='The cold data size. Unit: bytes.

>  Formula: Cold data size = Data size of table records + Data size of regular indexes + Data size of primary key indexes + Data size of other data.', example='4194304'),
    }(name='ColdData', description='The cold data.'),
    dataGrowth?: {
      dayGrowth?: long(name='DayGrowth', description='The data growth within the last day. Unit: bytes.

>  Formula: Data growth within the last day = Current data size - Data size one day ago.', example='1048576'),
      weekGrowth?: long(name='WeekGrowth', description='The daily data growth within the last seven days. Unit: bytes.

>  Formula: Daily data growth within the last seven days = (Current data size - Data size seven days ago)/7.', example='1048576'),
    }(name='DataGrowth', description='The data growth.'),
    hotData?: {
      dataSize?: long(name='DataSize', description='The data size of table records. Unit: bytes.', example='1048576'),
      indexSize?: long(name='IndexSize', description='The data size of regular indexes. Unit: bytes.', example='1048576'),
      otherSize?: long(name='OtherSize', description='The data size of other data. Unit: bytes.', example='1048576'),
      primaryKeyIndexSize?: long(name='PrimaryKeyIndexSize', description='The data size of primary key indexes. Unit: bytes.', example='1048576'),
      totalSize?: long(name='TotalSize', description='The hot data size. Unit: bytes.

>  Formula: Hot data size = Data size of table records + Data size of regular indexes + Data size of primary key indexes + Data size of other data.', example='4194304'),
    }(name='HotData', description='The hot data.'),
    totalSize?: string(name='TotalSize', description='The total data size. Unit: bytes.

>  Formula: Total data size = Hot data size+ Cold data size.', example='8388608'),
  }(name='Data', description='The queried storage overview information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DescribeDBClusterSpaceSummaryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeDBClusterSpaceSummaryResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeDBClusterSpaceSummary(request: DescribeDBClusterSpaceSummaryRequest): DescribeDBClusterSpaceSummaryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDBClusterSpaceSummary', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDBClusterStatusRequest {
  regionId: string(name='RegionId', description='The region ID.

>  You can call the [DescribeRegions](~~143074~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
}

model DescribeDBClusterStatusResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEAU'),
  status?: [ string ](name='Status', description='The queried cluster states.'),
}

model DescribeDBClusterStatusResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeDBClusterStatusResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeDBClusterStatus(request: DescribeDBClusterStatusRequest): DescribeDBClusterStatusResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDBClusterStatus', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDBClustersRequest {
  DBClusterDescription?: string(name='DBClusterDescription', description='The description of the cluster.

*   The description cannot start with `http://` or `https://`.
*   The description must be 2 to 256 characters in length', example='test', position='Query'),
  DBClusterIds?: string(name='DBClusterIds', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

If you do not specify this parameter, the information about all clusters that reside in the region is returned.', example='amv-bp1r053byu48p****', position='Query'),
  DBClusterStatus?: string(name='DBClusterStatus', description='The state of the cluster. Valid values:

*   **Preparing**

<!---->

*   **Creating**
*   **Running**
*   **Deleting**

<!---->

*   **Restoring**

<!---->

*   **ClassChanging**
*   **NetAddressCreating**
*   **NetAddressDeleting**
*   **NetAddressModifying**', example='Running', position='Query'),
  DBClusterVersion?: string(name='DBClusterVersion', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30', position='Query'),
  productVersion?: string(name='ProductVersion', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID. If you do not specify this parameter, the information about all resource groups in the cluster is returned.', example='rg-4690g37929****', position='Query'),
  tag?: [ 
    {
      key?: string(name='Key', description='The tag key.', example='tag1'),
      value?: string(name='Value', description='The tag value.', example='test1'),
    }
  ](name='Tag', description='The tags that are added to the cluster.', position='Query'),
}

model DescribeDBClustersResponseBody = {
  items?: {
    DBCluster?: [ 
    {
      category?: string(name='Category'),
      commodityCode?: string(name='CommodityCode', description='The billing method of the cluster. Valid values:

*   **ads**: pay-as-you-go.
*   **ads_pre**: subscription.', example='ads_pre'),
      computeResource?: string(name='ComputeResource', description='The specifications of reserved computing resources. Each ACU is approximately equal to 1 core and 4 GB memory. Computing resources are used to compute data. The increase in the computing resources can accelerate queries. You can scale computing resources based on your business requirements.', example='16ACU'),
      connectionString?: string(name='ConnectionString', description='The public endpoint that is used to connect to the cluster.', example='amv-bp163885f8q21****.ads.aliyuncs.com'),
      createTime?: string(name='CreateTime', description='The time when the cluster was created. The time follows the ISO 8601 standard in the *yyyy-mm-ddThh:mm:ssZ* format. The time is displayed in UTC.', example='2022-04-01T09:50:18Z'),
      DBClusterDescription?: string(name='DBClusterDescription', description='The description of the cluster.', example='adb_test'),
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp163885f8q21****'),
      DBClusterNetworkType?: string(name='DBClusterNetworkType', description='The network type of the cluster. **VPC** is returned.', example='VPC'),
      DBClusterStatus?: string(name='DBClusterStatus', description='The status of the cluster. Valid values:

*   **Preparing**

<!---->

*   **Creating**
*   **Running**
*   **Deleting**

<!---->

*   **Restoring**

<!---->

*   **ClassChanging**
*   **NetAddressCreating**
*   **NetAddressDeleting**
*   **NetAddressModifying**', example='Running'),
      DBClusterType?: string(name='DBClusterType', description='The type of the cluster. By default, **Common** is returned, which indicates a common cluster.', example='Common'),
      DBNodeClass?: string(name='DBNodeClass'),
      DBNodeCount?: long(name='DBNodeCount'),
      DBNodeStorage?: long(name='DBNodeStorage'),
      DBVersion?: string(name='DBVersion', description='The engine version of the AnalyticDB for MySQL Data Lakehouse Edition cluster. **5.0** is returned.', example='5.0'),
      diskType?: string(name='DiskType'),
      dtsJobId?: string(name='DtsJobId'),
      elasticIOResource?: int32(name='ElasticIOResource'),
      engine?: string(name='Engine', description='The engine of the cluster. **AnalyticDB** is returned.', example='AnalyticDB'),
      executorCount?: string(name='ExecutorCount'),
      expireTime?: string(name='ExpireTime', description='The time when the cluster expires. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.

> 

*   If the billing method of the cluster is subscription, the actual expiration time is returned.

*   If the billing method of the cluster is pay-as-you-go, null is returned.', example='2022-07-01T09:50:18Z'),
      expired?: string(name='Expired', description='Indicates whether the subscription cluster has expired. Valid values:

*   **true**
*   **false**

> 

*   If the cluster has expired, the system locks or releases the cluster within a period of time. We recommend that you renew the expired cluster. For more information, see [Renewal policy](~~135246~~).

*   This parameter is not returned for pay-as-you-go clusters.', example='false'),
      innerIp?: string(name='InnerIp'),
      innerPort?: string(name='InnerPort'),
      lockMode?: string(name='LockMode', description='The lock status of the cluster. Valid values:

*   **Unlock**: The cluster is not locked.
*   **ManualLock**: The cluster is manually locked.
*   **LockByExpiration**: The cluster is automatically locked due to cluster expiration.', example='Unlock'),
      lockReason?: string(name='LockReason', description='The reason why the cluster is locked.

>  This parameter is returned only when the cluster was locked. **instance_expire** is returned.', example='instance_expire'),
      mode?: string(name='Mode', description='The mode of the cluster. By default, **flexible** is returned, which indicates that the cluster is in elastic mode.', example='flexible'),
      payType?: string(name='PayType', description='The billing method of the cluster. Valid values:

*   **Postpaid**: pay-as-you-go.
*   **Prepaid**: subscription.', example='Prepaid'),
      port?: string(name='Port', description='The port number that is used to connect to the cluster.', example='3306'),
      productForm?: string(name='ProductForm'),
      productVersion?: string(name='ProductVersion'),
      rdsInstanceId?: string(name='RdsInstanceId'),
      regionId?: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou'),
      reservedACU?: string(name='ReservedACU', description='The remaining reserved computing resources that are available in the cluster. Each ACU is approximately equal to 1 core and 4 GB memory.', example='32ACU'),
      reservedNodeCount?: int32(name='ReservedNodeCount'),
      reservedNodeSize?: string(name='ReservedNodeSize'),
      resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='rg-acfmyiu4ekp****'),
      storageResource?: string(name='StorageResource', description='The specifications of reserved storage resources. Each AnalyticDB compute unit (ACU) is approximately equal to 1 core and 4 GB memory. Storage resources are used to read and write data. The increase in the storage resources can improve the read and write performance of the cluster.', example='24ACU'),
      tags?: {
        tag?: [ 
        {
          key?: string(name='Key', description='The tag key.

>  You can call the [TagResources](~~179253~~) operation to add tags to a cluster.', example='tag1'),
          value?: string(name='Value', description='The tag value.', example='test1'),
        }
      ](name='Tag')
      }(name='Tags', description='The tags that are added to the cluster.'),
      taskInfo?: {
        name?: string(name='Name'),
        progress?: string(name='Progress'),
        status?: string(name='Status'),
        stepList?: {
          stepList?: [ 
          {
            endTime?: string(name='EndTime'),
            startTime?: string(name='StartTime'),
            stepDesc?: string(name='StepDesc'),
            stepName?: string(name='StepName'),
            stepProgress?: string(name='StepProgress'),
            stepStatus?: string(name='StepStatus'),
          }
        ](name='StepList')
        }(name='StepList'),
      }(name='TaskInfo'),
      VPCCloudInstanceId?: string(name='VPCCloudInstanceId'),
      VPCId?: string(name='VPCId', description='The virtual private cloud (VPC) ID of the cluster.', example='vpc-bp13h7uzhulpuxvnp****'),
      vSwitchId?: string(name='VSwitchId', description='The vSwitch ID of the cluster.', example='vsw-bp1syh8vvw8yech7n****'),
      zoneId?: string(name='ZoneId', description='The zone ID of the cluster.', example='cn-hangzhou-h'),
    }
  ](name='DBCluster')
  }(name='Items', description='The queried clusters.'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='A5EDBA27-AF3E-5966-9503-FD1557E19167'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model DescribeDBClustersResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeDBClustersResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeDBClusters(request: DescribeDBClustersRequest): DescribeDBClustersResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDBClusters', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDBResourceGroupRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  groupName?: string(name='GroupName', description='The name of the resource group.

> If you do not specify this parameter, the information about all resource groups in the cluster is returned.', example='test_group', position='Query'),
  groupType?: string(name='GroupType', description='The type of the resource group. Valid values:

*   **Interactive**
*   **Job**

> For information about resource groups of Data Lakehouse Edition, see [Resource groups](~~428610~~).', example='Job', position='Query'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~612393~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
}

model DescribeDBResourceGroupResponseBody = {
  groupsInfo?: [ 
    {
      clusterMode?: string(name='ClusterMode', description='A reserved parameter.', example='N/A'),
      clusterSizeResource?: string(name='ClusterSizeResource', description='A reserved parameter.', example='N/A'),
      createTime?: string(name='CreateTime', description='The time when the resource group was created. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.', example='2022-08-29T03:34:30Z'),
      elasticMinComputeResource?: string(name='ElasticMinComputeResource', description='The minimum amount of elastic computing resources. Unit: ACUs.', example='16ACU'),
      enableSpot?: string(name='EnableSpot', description='Indicates whether the preemptible instance feature is enabled for the resource group. After the preemptible instance feature is enabled, you are charged for resources at a lower unit price but the resources are probably released. Valid values:

*   **True**
*   **False**

The True value is returned only for job resource groups.', example='True'),
      groupName?: string(name='GroupName', description='The name of the resource group.', example='test1'),
      groupType?: string(name='GroupType', description='The type of the resource group. Valid values:

*   **Interactive**
*   **Job**

>  For more information about resource groups, see [Resource groups](~~428610~~).', example='Job'),
      groupUsers?: string(name='GroupUsers', description='The Resource Access Management (RAM) user that is associated with the resource group.', example='testb,testc'),
      maxClusterCount?: int32(name='MaxClusterCount', description='A reserved parameter.', example='N/A'),
      maxComputeResource?: string(name='MaxComputeResource', description='The maximum amount of reserved computing resources. Unit: ACUs.', example='512ACU'),
      minClusterCount?: int32(name='MinClusterCount', description='A reserved parameter.', example='N/A'),
      minComputeResource?: string(name='MinComputeResource', description='The minimum amount of reserved computing resources. Unit: AnalyticDB compute units (ACUs).', example='0ACU'),
      rules?: [ 
        {
          groupName?: string(name='GroupName', description='The name of the resource group.', example='user_default'),
          queryTime?: string(name='QueryTime', description='The execution duration of the query. Unit: milliseconds.', example='180000'),
          targetGroupName?: string(name='TargetGroupName', description='The name of the destination resource group.', example='job'),
        }
      ](name='Rules', description='The job resubmission rules.'),
      runningClusterCount?: int32(name='RunningClusterCount', description='A reserved parameter.', example='N/A'),
      status?: string(name='Status', description='The status of the resource group. Valid values:

*   **creating**: The resource group is being created.
*   **ok**: The resource group is created.
*   **pendingdelete**: The resource group is pending to be deleted.', example='ok'),
      updateTime?: string(name='UpdateTime', description='The time when the resource group was updated. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time is displayed in UTC.', example='2022-08-31T03:34:30Z'),
    }
  ](name='GroupsInfo', description='The queried resource group.'),
  requestId?: string(name='RequestId', description='The request ID.', example='A94B6C02-7BD4-5D67-9776-3AC8317E8DD3'),
}

model DescribeDBResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeDBResourceGroupResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeDBResourceGroup(request: DescribeDBResourceGroupRequest): DescribeDBResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDBResourceGroup', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDiagnosisDimensionsRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bt6u59zcmd945****', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

> 

*   The end time must be later than the start time.

*   The maximum time range that can be specified is 24 hours.', example='1625220213000', position='Query'),
  lang?: string(name='Lang', description='The language. Valid values:

*   **zh-CN** (default): simplified Chinese.
*   **en-US**: English.
*   **ja**: Japanese.', example='zh-CN', position='Query'),
  queryCondition?: string(name='QueryCondition', description='The query condition for SQL statements, which can contain the `Type`, `Value`, `Min`, and `Max` fields. Specify the condition in the JSON format. `Type` specifies the query dimension. Valid values for Type: `maxCost`, `status`, and `cost`. `Value`, `Min`, or `Max` specifies the query range for the dimension. Valid values:

*   `{"Type":"maxCost","Value":"100"}`: queries the top 100 most time-consuming SQL statements. Set `Value` to 100.
*   `{"Type":"status","Value":"finished"}`: queries the executed SQL statements. You can set `Value` to `running` to query the SQL statements that are being executed. You can also set Value to `failed` to query the SQL statements that failed to be executed.
*   `{"Type":"cost","Min":"10","Max":"200"}`: queries the SQL statements whose execution duration is in the range of 10 to 200 milliseconds. You can also specify custom values for the Min and Max fields.', example='{"Type":"maxCost","Value":"100"}', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  You can query data only within the last 14 days.', example='1625220210000', position='Query'),
}

model DescribeDiagnosisDimensionsResponseBody = {
  clientIps?: [ string ](name='ClientIps', description='The queried source IP addresses.'),
  databases?: [ string ](name='Databases', description='The queried database names.'),
  requestId?: string(name='RequestId', description='The request ID.', example='DEA97C6B-D7A4-5E69-9EFC-D7F88737CED5'),
  resourceGroups?: [ string ](name='ResourceGroups', description='The queried resource group names.'),
  userNames?: [ string ](name='UserNames', description='The queried usernames.'),
}

model DescribeDiagnosisDimensionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeDiagnosisDimensionsResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see Endpoints.
  *
 */
async function describeDiagnosisDimensions(request: DescribeDiagnosisDimensionsRequest): DescribeDiagnosisDimensionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDiagnosisDimensions', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDiagnosisRecordsRequest {
  clientIp?: string(name='ClientIp', description='The source IP address.

>  You can call the [DescribeDiagnosisDimensions](~~308210~~) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.', example='59.82.XX.XX', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1scs48yc125****', position='Query'),
  database?: string(name='Database', description='The name of the database on which the SQL statements are executed.

>  You can call the [DescribeDiagnosisDimensions](~~308210~~) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.', example='adb_demo', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

> 

*   The end time must be later than the start time.

*   The maximum time range that can be specified is 24 hours.', example='1633017540000', position='Query'),
  keyword?: string(name='Keyword', description='The query keyword of the SQL statements.', example='select', position='Query'),
  lang?: string(name='Lang', description='The language of file titles and error messages. Valid values:

*   **zh** (default): simplified Chinese.
*   **en**: English.
*   **ja**: Japanese.
*   **zh-tw**: traditional Chinese.', example='zh', position='Query'),
  maxPeakMemory?: long(name='MaxPeakMemory', description='The maximum peak memory of the SQL statements. Unit: bytes.', example='89000000', position='Query'),
  maxScanSize?: long(name='MaxScanSize', description='The maximum scan size of the SQL statements. Unit: bytes.', example='1024000000', position='Query'),
  minPeakMemory?: long(name='MinPeakMemory', description='The minimum peak memory of the SQL statements. Unit: bytes.', example='0', position='Query'),
  minScanSize?: long(name='MinScanSize', description='The minimum scan size of the SQL statements. Unit: bytes.', example='0', position='Query'),
  order?: string(name='Order', description='The order in which to sort the SQL statements by field, which contains the `Field` and `Type` fields. Specify the order in the JSON format. Example: `[{"Field":"StartTime", "Type": "desc"}]`. Fields:

*   `Field` specifies the field that is used to sort the SQL statements. Valid values:

    *   `StartTime`: the execution start time.
    *   `Status`: the execution status.
    *   `UserName`: the username.
    *   `Cost`: the execution duration.
    *   `PeakMemory`: the peak memory.
    *   `ScanSize`: the amount of data that is scanned.
    *   `Database`: the name of the database.
    *   `ClientIp`: the source IP address.
    *   `ResourceGroup`: the name of the resource group.
    *   `QueueTime`: the amount of time that is consumed for queuing.
    *   `OutputRows`: the number of output rows.
    *   `OutputDataSize`: the amount of output data.
    *   `ResourceCostRank`: the execution duration rank of operators that are used in the SQL statements. This value takes effect only when `QueryCondition` is set to `{"Type":"status","Value":"running"}`.

*   `Type` specifies the sorting order. Valid values (case-insensitive):

    *   `Desc`: descending order.
    *   `Asc`: ascending order.', example='[{"Field":"StartTime", "Type": "desc" }]', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30', position='Query'),
  patternId?: string(name='PatternId', description='The SQL pattern ID.', example='5575924945138******', position='Query'),
  queryCondition?: string(name='QueryCondition', description='The query condition for SQL statements, which can contain the `Type`, `Value`, `Min`, and `Max` fields. Specify the condition in the JSON format. `Type` specifies the query dimension. Valid values for Type: `maxCost`, `status`, and `cost`. `Value`, `Min`, or `Max` specifies the query range for the dimension. Valid values:

*   `{"Type":"maxCost","Value":"100"}`: queries the top 100 most time-consuming SQL statements. Set `Value` to 100.
*   `{"Type":"status","Value":"finished"}`: queries the executed SQL statements. You can set `Value` to `running` to query the SQL statements that are being executed. You can also set Value to `failed` to query the SQL statements that failed to be executed.
*   `{"Type":"cost","Min":"10","Max":"200"}`: queries the SQL statements whose execution duration is in the range of 10 to 200 milliseconds. You can also specify custom values for the Min and Max fields.', example='{"Type":"status","Value":"finished"}', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~143074~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceGroup?: string(name='ResourceGroup', description='The resource group to which the SQL statements belong.

>  You can call the [DescribeDiagnosisDimensions](~~308210~~) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.', example='user_default', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  You can query data only within the last 14 days.', example='1632931200000', position='Query'),
  userName?: string(name='UserName', description='The username that is used to execute the SQL statements. You can call the [DescribeDiagnosisDimensions](~~308210~~) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.', example='test_user', position='Query'),
}

model DescribeDiagnosisRecordsResponseBody = {
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
  querys?: [ 
    {
      clientIp?: string(name='ClientIp', description='The source IP address.', example='59.82.XX.XX'),
      cost?: long(name='Cost', description='The total execution duration. Unit: milliseconds.

>  This value is the cumulative value of the `QueuedTime`, `TotalPlanningTime`, and `ExecutionTime` parameters.', example='10'),
      database?: string(name='Database', description='The name of the database on which the SQL statement is executed.', example='adb_demo'),
      etlWriteRows?: long(name='EtlWriteRows', description='The number of rows written to the table by an extract-transform-load (ETL) job.', example='0'),
      executionTime?: long(name='ExecutionTime', description='The execution duration. Unit: milliseconds.', example='6'),
      outputDataSize?: long(name='OutputDataSize', description='The amount of returned data. Unit: bytes.', example='9'),
      outputRows?: long(name='OutputRows', description='The number of rows returned.', example='1'),
      peakMemory?: long(name='PeakMemory', description='The peak memory. Unit: bytes.', example='16648'),
      processId?: string(name='ProcessId', description='The query ID.', example='2021093000414401000000023503151******'),
      queueTime?: long(name='QueueTime', description='The amount of time that is consumed for queuing. Unit: milliseconds.', example='6'),
      rcHost?: string(name='RcHost', description='The IP address and port number of the AnalyticDB for MySQL frontend node on which the SQL statement is executed.', example='10.0.XX.XX:3004'),
      resourceCostRank?: int32(name='ResourceCostRank', description='The execution duration rank of operators that are used in the SQL statement.

>  This parameter is returned only for SQL statements whose `Status` parameter is `running`.', example='1'),
      resourceGroup?: string(name='ResourceGroup', description='The resource group to which the SQL statement belongs.', example='user_default'),
      SQL?: string(name='SQL', description='The queried SQL statement.

>  For performance considerations, an SQL statement cannot exceed 5,120 characters in length. Otherwise, the SQL statement is truncated. You can call the [DownloadDiagnosisRecords](~~308212~~) operation to download the information about SQL statements that meet a query condition for an AnalyticDB for MySQL cluster, including the complete SQL statements.', example='SELECT count(*)\\nFROM nation'),
      SQLTruncated?: boolean(name='SQLTruncated', description='Indicates whether the SQL statement is truncated. Valid values:

*   **true**
*   **false**', example='false'),
      SQLTruncatedThreshold?: long(name='SQLTruncatedThreshold', description='The maximum length of the SQL statement. 5120 is returned. Unit: characters. SQL statements that exceed this limit are truncated.', example='5120'),
      scanRows?: long(name='ScanRows', description='The number of rows scanned.', example='1'),
      scanSize?: long(name='ScanSize', description='The amount of scanned data. Unit: bytes.', example='9'),
      startTime?: long(name='StartTime', description='The execution start time of the SQL statement. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1632933704000'),
      status?: string(name='Status', description='The state of the SQL statement. Valid values:

*   **running**
*   **finished**
*   **failed**', example='finished'),
      totalPlanningTime?: long(name='TotalPlanningTime', description='The amount of time that is consumed to generate an execution plan. Unit: milliseconds.', example='4'),
      totalStages?: int32(name='TotalStages', description='The total number of stages generated.', example='2'),
      userName?: string(name='UserName', description='The username that is used to execute the SQL statements.', example='test_user'),
    }
  ](name='Querys', description='The queried SQL statements.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7F88BEFA-CF0B-5C95-8BB1-92EC9F09E40D'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model DescribeDiagnosisRecordsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeDiagnosisRecordsResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see Endpoints.
  *
 */
async function describeDiagnosisRecords(request: DescribeDiagnosisRecordsRequest): DescribeDiagnosisRecordsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDiagnosisRecords', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDiagnosisSQLInfoRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1r053byu48p', position='Query'),
  lang?: string(name='Lang', description='The language of file titles and error messages. Valid values:

*   **zh**: simplified Chinese.
*   **en**: English.
*   **ja**: Japanese.
*   **zh-tw**: traditional Chinese.', example='zh', position='Query'),
  processId?: string(name='ProcessId', description='The query ID.

>  You can call the [DescribeDiagnosisRecords](~~308207~~) operation to query the diagnostic information about SQL statements for an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster, including the query ID.', example='2021070216432217201616806503453', position='Query'),
  processRcHost?: string(name='ProcessRcHost', description='The IP address and port number of the AnalyticDB for MySQL frontend node on which the SQL statement is executed.

>  You can call the [DescribeDiagnosisRecords](~~308207~~) operation to query the diagnostic information about SQL statements for an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster, including the IP address and port number of the frontend node.', example='192.45.***.***:3145', position='Query'),
  processStartTime?: long(name='ProcessStartTime', description='The execution start time of the SQL statement. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  You can call the [DescribeDiagnosisRecords](~~308207~~) operation to query the diagnostic information about SQL statements for an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster, including the execution start time of the SQL statement.', example='1625215402000', position='Query'),
  processState?: string(name='ProcessState', description='The status of the SQL statement. Valid values:

*   **running**
*   **finished**
*   **failed**

>  You can call the [DescribeDiagnosisRecords](~~308207~~) operation to query the diagnostic information about SQL statements for an AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster, including the status of the SQL statement.', example='running', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~143074~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
}

model DescribeDiagnosisSQLInfoResponseBody = {
  diagnosisSQLInfo?: string(name='DiagnosisSQLInfo', description='The queried execution information, including the SQL statement, statistics, execution plan, and operator information.', example='{     "DiagnosisSQLInfo": {         "hasSharedStage": false,         "resourceGroup": "user_default",         "cost": 274,         "queuedTime": 0,         "outputDataSize": 9,         "scheduled": true,         "query": "/*+display=tpch_q14*/SELECT 100.00 * SUM(CASE WHEN p_type LIKE \\"PROMO%\\" THEN l_extendedprice * (1 - l_discount) ELSE 0 END) / SUM(l_extendedprice * (1 - l_discount)) AS promo_revenue FROM lineitem l, part p WHERE l_partkey = p_partkey AND l_shipdate &gt;= DATE \\"1995-09-01\\" AND l_shipdate &lt; DATE \\"1995-09-01\\" + INTERVAL \\"1\\" MONTH",         "outputRows": 1,         "userName": "test_user",         "parentId": 0,         "maxOutputRows": 200000,         "scanSize": 8247470,         "peakMemory": 13188295,         "startTime": 1626330527632,         "state": "FINISHED",         "endTime": 1626330527905,         "writeTableRows": 0,         "scanRows": 351966     } }'),
  requestId?: string(name='RequestId', description='The request ID.', example='1'),
  stageInfos?: [ 
    {
      inputDataSize?: long(name='InputDataSize', description='The total amount of input data in the stage. Unit: bytes.', example='2341'),
      inputRows?: long(name='InputRows', description='The total number of input rows in the stage.', example='2341'),
      operatorCost?: long(name='OperatorCost', description='The total amount of time consumed by all operators in the stage. Unit: milliseconds.', example='2341'),
      outputDataSize?: long(name='OutputDataSize', description='The total amount of output data in the stage. Unit: bytes.', example='2341'),
      outputRows?: long(name='OutputRows', description='The total number of output rows in the stage.', example='2341'),
      peakMemory?: long(name='PeakMemory', description='The total peak memory of the stage. Unit: bytes.', example='2341'),
      progress?: double(name='Progress', description='The execution progress of the stage.', example='0.3'),
      stageId?: string(name='StageId', description='The stage ID.', example='Stage[26]'),
      state?: string(name='State', description='The state of the stage.', example='RUNNING'),
    }
  ](name='StageInfos', description='The queried execution information by stage.'),
}

model DescribeDiagnosisSQLInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeDiagnosisSQLInfoResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see Endpoints.
  *
 */
async function describeDiagnosisSQLInfo(request: DescribeDiagnosisSQLInfoRequest): DescribeDiagnosisSQLInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDiagnosisSQLInfo', 'GET', '/', 'json', false, 'json', request);
}

model DescribeDownloadRecordsRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-8vb6ha79k6e****', position='Query'),
  lang?: string(name='Lang', description='The language of the returned data. Valid values:

*   **zh**: simplified Chinese.
*   **en**: English.
*   **ja**: Japanese.
*   **zh-tw**: traditional Chinese.', example='zh', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model DescribeDownloadRecordsResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail'),
  records?: [ 
    {
      downloadId?: long(name='DownloadId', description='The download job ID.', example='636890'),
      exceptionMsg?: string(name='ExceptionMsg', description='The error message returned if the download job failed.', example='The query result is empty.'),
      fileName?: string(name='FileName', description='The name of the downloaded file.', example='20210806094635-20210806095135'),
      status?: string(name='Status', description='The status of the download job. Valid values:

*   **running**
*   **finished**
*   **failed**', example='finished'),
      url?: string(name='Url', description='The download URL of the file.', example='https://perth-download-task.oss-cn-beijing.aliyuncs.com/adbmysql/query-sql-logs/amv-*********/20210805104301-20210805164302.xlsx?Expires=1943514161&OSSAccessKeyId=*********&Signature=******"'),
    }
  ](name='Records', description='The queried download tasks.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D761DA51-12F8-5457-AAA9-F52B9F436D2D'),
}

model DescribeDownloadRecordsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeDownloadRecordsResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see Endpoints.
  *
 */
async function describeDownloadRecords(request: DescribeDownloadRecordsRequest): DescribeDownloadRecordsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDownloadRecords', 'POST', '/', 'json', false, 'json', request);
}

model DescribeElasticPlanAttributeRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the names of scaling plans.', example='test', position='Query'),
}

model DescribeElasticPlanAttributeResponseBody = {
  elasticPlan?: {
    autoScale?: boolean(name='AutoScale', description='Indicates whether **Default Proportional Scaling for EIUs** is enabled. Valid values: true: Default Proportional Scaling for EIUs is enabled. If you set this parameter to true, storage resources are scaled along with computing resources. false: Default Proportional Scaling for EIUs is not enabled.

>  You can enable Default Proportional Scaling for EIUs for only a single scaling plan of a cluster. After you enable a scaling plan of the Default Proportional Scaling for EIUs type, you cannot enable scaling plans of other types.', example='false'),
    cronExpression?: string(name='CronExpression', description='A CORN expression that indicates the scaling cycle and time for the scaling plan.', example='0 20 14 * * ?'),
    elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.', example='test'),
    enabled?: boolean(name='Enabled', description='Indicates whether the scaling plan is enabled.', example='true'),
    endTime?: string(name='EndTime', description='The end time of the scaling plan.

>  The time follows the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time is displayed in UTC.', example='2025-01-01T12:01:00Z'),
    resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group used by the scaling plan.', example='test'),
    startTime?: string(name='StartTime', description='The start time of the scaling plan.

>  The time follows the ISO 8601 standard in the yyyy-MM-ddThh:mm:ssZ format. The time is displayed in UTC.', example='2022-01-01T12:01:00Z'),
    targetSize?: string(name='TargetSize', description='The amount of elastic resources after scaling.', example='32ACU'),
    type?: string(name='Type', description='The type of the scaling plan.', example='EXECUTOR'),
  }(name='ElasticPlan', description='The queried scaling plan.'),
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model DescribeElasticPlanAttributeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeElasticPlanAttributeResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeElasticPlanAttribute(request: DescribeElasticPlanAttributeRequest): DescribeElasticPlanAttributeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeElasticPlanAttribute', 'POST', '/', 'json', false, 'json', request);
}

model DescribeElasticPlanJobsRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.

> 

*   If you do not specify this parameter, all scaling plans of the cluster are queried.

*   You can call the [DescribeElasticPlans](~~601334~~) operation to query the names of scaling plans.', example='test', position='Query'),
  pageNumber: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize: int32(name='PageSize', description='The number of entries per page.', example='10', position='Query'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> 

*   If you do not specify this parameter, the scaling plans of all resource groups are queried, including the interactive resource group and elastic I/O unit (EIU) types.

*   You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the resource group name for a cluster.', example='test', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-01-01T12:01:00Z', position='Query'),
  status?: string(name='Status', description='The state of the scaling plan job. Valid values:

*   RUNNING
*   SUCCESSFUL
*   FAILED

>  If you do not specify this parameter, the scaling plans in all states are queried.', example='SUCCESSFUL', position='Query'),
}

model DescribeElasticPlanJobsResponseBody = {
  jobs?: [ 
    {
      elasticAcu?: string(name='ElasticAcu', description='The amount of elastic resources.

> 

*   If Type is set to EXECUTOR, ElasticAcu indicates the amount of elastic resources in the current resource group.
*   If Type is set to WORKER, ElasticAcu indicates the total amount of elastic storage resources in the current cluster.', example='16ACU'),
      elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.', example='test'),
      endTime?: string(name='EndTime', description='The end time of the scaling plan job.

>  The time follows the ISO 8601 standard in the YYYY-MM-DDThh:mm:ss format. The time is displayed in UTC.', example='2022-01-01T12:01:00Z'),
      instanceSize?: int32(name='InstanceSize', description='The number of compute nodes or storage replica sets.

> 

*   If Type is set to EXECUTOR, InstanceSize indicates the number of compute nodes in the cluster.
*   If Type is set to EXECUTOR, InstanceSize indicates the number of storage replica sets in the cluster.', example='1'),
      reserveAcu?: string(name='ReserveAcu', description='The amount of reserved resources.

> 

*   If Type is set to EXECUTOR, ReserveAcu indicates the amount of reserved resources in the current resource group.
*   If Type is set to WORKER, ReserveAcu indicates the total amount of reserved storage resources in the current cluster.', example='16ACU'),
      resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.', example='test'),
      startTime?: string(name='StartTime', description='The start time of the scaling plan job.

>  The time follows the ISO 8601 standard in the YYYY-MM-DDThh:mm:ss format. The time is displayed in UTC.', example='2022-01-01T11:01:00Z'),
      status?: string(name='Status', description='The state of the scaling plan job. Valid values:

*   RUNNING
*   SUCCESSFUL
*   FAILED', example='SUCCESSFUL'),
      targetSize?: string(name='TargetSize', description='The desired specifications of elastic resources after scaling.', example='32ACU'),
      totalAcu?: string(name='TotalAcu', description='The total amount of resources.

> 

*   If Type is set to EXECUTOR, TotalAcu indicates the total amount of computing resources in the current resource group.
*   If Type is set to WORKER, TotalAcu indicates the total amount of storage resources in the cluster.', example='32ACU'),
      type?: string(name='Type', description='The type of the scaling plan job. Valid values:

*   EXECUTOR: the interactive resource group type, which indicates the computing resource type.
*   WORKER: the EIU type.', example='EXECUTOR'),
    }
  ](name='Jobs', description='The queried scaling plan jobs.'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
  totalCount?: int32(name='TotalCount', description='The total number of scaling plan jobs.', example='15'),
}

model DescribeElasticPlanJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeElasticPlanJobsResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see Endpoints.
  *
 */
async function describeElasticPlanJobs(request: DescribeElasticPlanJobsRequest): DescribeElasticPlanJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeElasticPlanJobs', 'POST', '/', 'json', false, 'json', request);
}

model DescribeElasticPlanSpecificationsRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****', position='Query'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> 

*   This parameter must be specified only when you query the resource specifications that are supported by an interactive resource group.

*   You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group within a cluster.', example='test', position='Query'),
  type: string(name='Type', description='The type of the scaling plan. Valid values:

*   EXECUTOR: the interactive resource group type, which specifies the computing resource type.
*   WORKER: the elastic I/O unit (EIU) type.', example='EXECUTOR', position='Query'),
}

model DescribeElasticPlanSpecificationsResponseBody = {
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='5'),
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
  specifications?: [ string ](name='Specifications', description='The queried resource specifications.'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='10'),
}

model DescribeElasticPlanSpecificationsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeElasticPlanSpecificationsResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeElasticPlanSpecifications(request: DescribeElasticPlanSpecificationsRequest): DescribeElasticPlanSpecificationsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeElasticPlanSpecifications', 'POST', '/', 'json', false, 'json', request);
}

model DescribeElasticPlansRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.

> If you do not specify this parameter, all scaling plans are queried.', example='test', position='Query'),
  enabled?: boolean(name='Enabled', description='Specifies whether to query the scaling plans that are immediately enabled after the plans are created. Valid values:

*   true
*   false', example='true', position='Query'),
  pageNumber: int32(name='PageNumber', description='The page number.', example='1', minimum=1, position='Query'),
  pageSize: int32(name='PageSize', description='The number of entries per page.', example='10', minimum=1, position='Query'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> *   If you do not specify this parameter, the scaling plans of all resource groups are queried, covering the interactive resource group type and the elastic I/O unit (EIU) type.
>*   You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group within a cluster.', example='test', position='Query'),
  type?: string(name='Type', description='The type of the scaling plan. Valid values:

EXECUTOR: the interactive resource group type, which specifies the computing resource type. WORKER: the EIU type.', example='EXECUTOR', position='Query'),
}

model DescribeElasticPlansResponseBody = {
  elasticPlans?: [ 
    {
      autoScale?: boolean(name='AutoScale', description='Indicates whether **Proportional Default Scaling for EIUs** is enabled. Valid values:

*   true
*   false', example='false'),
      elasticPlanName?: string(name='ElasticPlanName', description='The name of the scaling plan.', example='test'),
      enabled?: boolean(name='Enabled', description='Indicates whether the scaling plan was immediately enabled after the plan is created. Valid values:

*   true
*   false', example='true'),
      nextScheduleTime?: string(name='NextScheduleTime', description='The time when the next scheduling is performed.

> The time is in the yyyy-MM-ddTHH:mm:ssZ format.', example='2022-01-01T12:01:00Z'),
      resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.

> You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group within a cluster.', example='test'),
      targetSize?: string(name='TargetSize', description='The amount of elastic resources after scaling.', example='32ACU'),
      type?: string(name='Type', description='The type of the scaling plan. Valid values:

*   EXECUTOR: interactive resource group.
*   WORKER: EIU.', example='EXECUTOR'),
    }
  ](name='ElasticPlans', description='The queried scaling plans.'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='15'),
}

model DescribeElasticPlansResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeElasticPlansResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see Endpoints.
  *
 */
async function describeElasticPlans(request: DescribeElasticPlansRequest): DescribeElasticPlansResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeElasticPlans', 'POST', '/', 'json', false, 'json', request);
}

model DescribeEnabledPrivilegesRequest {
  accountName?: string(name='AccountName', description='The name of the database account.

>  You can call the [DescribeAccounts](~~612430~~) operation to query the information about database accounts for a cluster, including the account name.', example='test_accout', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp14t95lun0w****', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model DescribeEnabledPrivilegesResponseBody = {
  data?: [ 
    {
      description: string(name='Description', description='The description of the permission level.'),
      privileges: [ 
        {
          description?: string(name='Description', description='The description of the permission.'),
          key?: string(name='Key', description='The name of the permission.', example='select'),
        }
      ](name='Privileges', description='The queried permissions.'),
      scope: string(name='Scope', description='The permission level.', example='Global'),
    }
  ](name='Data', description='The queried permission level and permissions.'),
  requestId?: string(name='RequestId', description='The request ID.', example='246F42E0-A475-15FF-96D2-8DC47FC2F289'),
}

model DescribeEnabledPrivilegesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeEnabledPrivilegesResponseBody(name='body'),
}

async function describeEnabledPrivileges(request: DescribeEnabledPrivilegesRequest): DescribeEnabledPrivilegesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeEnabledPrivileges', 'GET', '/', 'json', false, 'json', request);
}

model DescribeExcessivePrimaryKeysRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.', example='am-bp1xxxxxxxx47', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.', example='2019-06-01T16:00:00Z', position='Query'),
  lang?: string(name='Lang', description='The language of file titles and error messages. Valid values:

*   **zh (default)**: simplified Chinese.
*   **en**: English.
*   **ja**: Japanese.
*   **zh-tw**: traditional Chinese.', example='zh', position='Query'),
  order?: string(name='Order', description='The order in which table fields are sorted. Specify the value in the JSON format.

Example:

    [

        {

            "Field":"Name",

            "Type":"Asc"

        }

    ]

In the preceding code, Field specifies the field that is used to sort the table data. Set the value to Name. Type specifies the sorting order. Valid values: Desc and Asc.

Field and Type are case-insensitive.', example='[{"Field":"TableName", "Type": "Desc" }]', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30', minimum=10, maximum=100, position='Query'),
  regionId: string(name='RegionId', description='The region ID.

>  You can call the [DescribeRegions](~~143074~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.', example='2019-06-01T16:00:00Z', position='Query'),
}

model DescribeExcessivePrimaryKeysResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='The queried information about the request denial.', example='{
    "PolicyType": "AccountLevelIdentityBasedPolicy",
    "AuthPrincipalOwnerId": "1906102576997697",
    "EncodedDiagnosticMessage": "AQIBIAAAAOPdwKY2QLOvgMEc7SkkoJfj1kvZwsaRqNYMh10Tv0wTe0fCzaCdrvgazfNb0EnJKETgXyhR+3BIQjx9WAqZryejBsp1Bl4qI5En/D9dEhcXAtKCxCmE2kZCiEzpy8BoEUt+bs0DmlaGWO5xkEpttypLIB4rUhDvZd+zwPg4EXk4KSSWSWsurxtqDkKEMshKlQFBTKvJcNqPqHV6lwR4INiAGjIvK1ngXxN1O+6ORRB6A8YvztEOGywOk81ZmuNk0YrNy+qk7+UVDTHeXKsy8h9e/ePY/LMidj0RCmDpo/YpCumd0UGe0qEPe2U+UJAm/+UHlnEFLVg6BP3yIB5D++MCy7mgWm8Kwyhk62IeYly4hQ+5IpXjkh1GQXuDgLVVPVpxEek9n30vnCUL4KsaMgfa7dgojb+3TM8xGsD2zVK5STJNrsXclscIJEqyNXd7CBYiRJVZi1HPO6drN9WW0chLpCSTgjO8n0bNanZaxXKumW9PSwV58UoSFASeMWfZK3TLngX+oq8nGmnTwcJosVjfF4RGzAnS1IXt0Q9N2WHDnpwyLBU/nOz7Hsy8IZ+h+OVjsBTXSM9688/vOF707a5mNzpETvQeGRcua3A5livcKAM2cML0yeUs/Zyj/+BGqtVa+wektspDHC/CECh6R5lxQjRmUdPawY8VDs2onmdLuEH8DdmYt+Yv/jBFBUMWOyAluzkPYcX5nuQKouCIUJUFTSbsJsuH5CTIh7Ls5rbmkj+T1qTVz8gnDR8LxwaqoMSna+elXgVyOOxXtMkenVntsmoC3p/4G7yTPL1hu8JyWGIIvZHZGGLXGEH7FeSuMV8buKxPGFWG3arG8e9LGvDdz5dgTien4y6G5AQ0o1iQdXDos5VWdH3u7k5PrsvdEOpvMi6uSd8a42na80FsYlgGlwM5upydcWUC5Un2HCkJpT1xgk2L6shdVTrK6bidRrqE784FhW9bBQePzGaxSupPENZya0VUctRt+7uq3QwIn4y5jzjgX0E0jgmqPrgiVDjBesMQZYfGPCGysWYWYzfoh+G6V7N2VVGtNnGUwNWzM0WJBPONAgxPv+AmixFRCQ==",
    "AuthPrincipalType": "SubUser",
    "AuthPrincipalDisplayName": "202515810214480629",
    "NoPermissionType": "ImplicitDeny",
    "AuthAction": "adb:DescribeExcessivePrimaryKeys"
  }'),
  DBClusterId?: string(name='DBClusterId', description='The cluster ID.', example='am-bp1ub9grke1****'),
  detectionItems?: [ 
    {
      message?: string(name='Message', description='The detection result.'),
      name?: string(name='Name', description='The name of the detection item.'),
      status?: string(name='Status', description='The severity level of the detection result.', example='NORMAL
WARNNING
CRITICAL'),
    }
  ](name='DetectionItems', description='The queried detection items and detection results.'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', minimum=1, maximum=2147483647),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30', minimum=10, maximum=100),
  requestId?: string(name='RequestId', description='The request ID.', example='863D51B7-5321-41D8-A0B6-A088B0******'),
  tables?: [ 
    {
      columnCount?: int32(name='ColumnCount', description='The total number of columns.', example='21'),
      primaryKeyColumns?: string(name='PrimaryKeyColumns', description='The queried primary key fields.', example='2'),
      primaryKeyCount?: int32(name='PrimaryKeyCount', description='The number of primary key fields.', example='3'),
      primaryKeyIndexSize?: long(name='PrimaryKeyIndexSize', description='The data size of primary key indexes. Unit: bytes.', example='222'),
      schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
      spaceRatio?: double(name='SpaceRatio', description='The percentage of the table size. Unit: %.

>  Formula: Table storage percentage = Total data size of a table/Total data size of the cluster × 100%.', example='23'),
      tableName?: string(name='TableName', description='The name of the table', example='test'),
      totalSize?: long(name='TotalSize', description='The cold data size. Unit: bytes.

>  Formula: Cold data size = Data size of table records + Data size of regular indexes + Data size of primary key indexes + Data size of other data.', example='4'),
    }
  ](name='Tables', description='The queried tables that have excessive primary key fields.'),
  totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='300'),
}

model DescribeExcessivePrimaryKeysResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeExcessivePrimaryKeysResponseBody(name='body'),
}

async function describeExcessivePrimaryKeys(request: DescribeExcessivePrimaryKeysRequest): DescribeExcessivePrimaryKeysResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeExcessivePrimaryKeys', 'POST', '/', 'json', false, 'json', request);
}

model DescribeJobResourceUsageRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='am-uf6g8w25jacm7****', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC. The end time must be later than the start time.', example='2023-03-17T16:00:00Z', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.', example='2023-02-04T03:45:00Z', position='Query'),
}

model DescribeJobResourceUsageResponseBody = {
  code?: int32(name='Code', description='The HTTP status code.', example='200'),
  data?: {
    DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-clusterxxx'),
    endTime?: string(name='EndTime', description='The end time of the query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-05-23T16:00:00Z'),
    jobAcuUsage?: [ 
      {
        acuUsageDetail?: {
          elasticAcuNumber?: float(name='ElasticAcuNumber', description='The number of ACUs for the elastic resources.', example='16ACU'),
          reservedAcuNumber?: float(name='ReservedAcuNumber', description='The number of ACUs for the reserved resources.', example='16ACU'),
          spotAcuNumber?: float(name='SpotAcuNumber', example='16ACU'),
          spotAcuPercentage?: float(name='SpotAcuPercentage', example='0.9'),
          totalAcuNumber?: float(name='TotalAcuNumber', description='The total number of ACUs.', example='32ACU'),
        }(name='AcuUsageDetail', description='The ACU usage.'),
        jobEndTime?: string(name='JobEndTime', description='The end time of the job. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-05-23T16:00:00Z'),
        jobId?: string(name='JobId', description='The job ID.', example='1592'),
        jobStartTime?: string(name='JobStartTime', description='The start time of the job. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-05-22T16:00:00Z'),
        resourceGroupName?: string(name='ResourceGroupName', description='The name of the job resource group.', example='job_default'),
      }
    ](name='JobAcuUsage', description='The AnalyticDB compute unit (ACU) usage of the job resource group.'),
    startTime?: string(name='StartTime', description='The start time of the query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-05-22T16:00:00Z'),
  }(name='Data', description='The queried resource usage.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DescribeJobResourceUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeJobResourceUsageResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeJobResourceUsage(request: DescribeJobResourceUsageRequest): DescribeJobResourceUsageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeJobResourceUsage', 'POST', '/', 'json', false, 'json', request);
}

model DescribePatternPerformanceRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.', example='amv-uf6li1r3do8m****', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the *yyyy-MM-ddTHH:mmZ* format. The time must be in UTC.

> The end time must be later than the start time.', example='2022-08-22T01:06:00Z', position='Query'),
  patternId?: string(name='PatternId', description='The SQL pattern ID.

>  You can call the [DescribeSQLPatterns](~~321868~~) operation to query the information about all SQL patterns in an AnalyticDB for MySQL cluster within a period of time, including SQL pattern IDs.', example='3847585356974******', position='Query'),
  regionId: string(name='RegionId', description='The region ID.', example='cn-hangzhou', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.

> 

*   If the current date is August 22, 2022 (UTC+8), you can query the data of August 9, 2022 (2022-08-08T16:00:00Z) to the earliest extent. If you want to query the data that is earlier than August 9, 2022 (2022-08-08T16:00:00Z), null is returned.

*   The maximum time range that can be specified is 24 hours.', example='2022-08-21T02:15:00Z', position='Query'),
}

model DescribePatternPerformanceResponseBody = {
  endTime?: string(name='EndTime', description='The end time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time is displayed in UTC.', example='2022-08-22T01:06:00Z'),
  performances?: [ 
    {
      key?: string(name='Key', description='The queried performance metric. Valid values:

*   **AnalyticDB_PatternQueryCount**: the total number of queries executed in association with the SQL pattern.
*   **AnalyticDB_PatternQueryTime**: the total amount of time consumed by the queries executed in association with the SQL pattern.
*   **AnalyticDB_PatternExecutionTime**: the execution duration of the queries executed in association with the SQL pattern.
*   **AnalyticDB_PatternPeakMemory**: the peak memory usage of the queries executed in association with the SQL pattern.
*   **AnalyticDB_PatternScanSize**: the amount of data scanned in the queries executed in association with the SQL pattern.', example='AnalyticDB_PatternExecutionTime'),
      series?: [ 
        {
          name?: string(name='Name', description='The name of the performance metric value. Valid values:

*   If the value of `Key` is `AnalyticDB_PatternQueryCount`, `pattern_query_count` is returned, which indicates the number of executions of the SQL statements in association with the SQL pattern.

*   If the value of `Key` is `AnalyticDB_PatternQueryTime`, the following values are returned:

    *   `average_query_time`, which indicates the average total amount of time consumed by the SQL statements in association with the SQL pattern.
    *   `max_query_time`, which indicates the maximum total amount of time consumed by the SQL statements in association with the SQL pattern.

*   If the value of `Key` is `AnalyticDB_PatternExecutionTime`, the following values are returned:

    *   `average_execution_time`, which indicates the average execution duration of the SQL statements in association with the SQL pattern.
    *   `max_execution_time`, which indicates the maximum execution duration of the SQL statements in association with the SQL pattern.

*   If the value of `Key` is `AnalyticDB_PatternPeakMemory`, the following values are returned:

    *   `average_peak_memory`, which indicates the average peak memory usage of the SQL statements in association with the SQL pattern.
    *   `max_peak_memory`, which indicates the maximum peak memory usage of the SQL statements in association with the SQL pattern.

*   If the value of `Key` is `AnalyticDB_PatternScanSize`, the following values are returned:

    *   `average_scan_size`, which indicates the average amount of data scanned by the SQL statements in association with the SQL pattern.
    *   `max_scan_size`, which indicates the maximum amount of data scanned by the SQL statements in association with the SQL pattern.', example='max_query_time'),
          values?: [ string ](name='Values', description='The values of the performance metric.'),
        }
      ](name='Series', description='The values of the performance metrics.'),
      unit?: string(name='Unit', description='The unit of the performance metric. Valid values:

*   If the performance metric is related to the query time (the value of `Key` is `AnalyticDB_PatternQueryTime` or `AnalyticDB_PatternExecutionTime`), **ms** is returned.
*   If the performance metric is related to the peak memory usage (the value of `Key` is `AnalyticDB_PatternPeakMemory`), **MB** is returned.
*   If the performance metric is related to the amount of data scanned (the value of `Key` is `AnalyticDB_PatternScanSize`), **MB** is returned.
*   If the performance metric is related to the number of queries (the value of `Key` is `AnalyticDB_PatternQueryCount`), null is returned.', example='ms'),
    }
  ](name='Performances', description='The queried performance metrics.'),
  requestId?: string(name='RequestId', description='The request ID.', example='F21AF487-B8C9-57E0-8E3A-A92BC3611FB6'),
  startTime?: string(name='StartTime', description='The start time of the query. The time follows the ISO 8601 standard in the *yyyy-MM-ddTHH:mmZ* format. The time is displayed in UTC.', example='2022-08-21T02:15:00Z'),
}

model DescribePatternPerformanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribePatternPerformanceResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describePatternPerformance(request: DescribePatternPerformanceRequest): DescribePatternPerformanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribePatternPerformance', 'POST', '/', 'json', false, 'json', request);
}

model DescribePerformanceViewAttributeRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.', example='amv-bp11q28kvl688****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  regionId: string(name='RegionId', description='The region ID.

>  You can call the [DescribeRegions](~~143074~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  viewName: string(name='ViewName', position='Query'),
}

model DescribePerformanceViewAttributeResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', example='{
    "PolicyType": "AccountLevelIdentityBasedPolicy",
    "AuthPrincipalOwnerId": "1*****************7",
    "EncodedDiagnosticMessage": "AQIBIAAAAOPdwKY2QLOvgMEc7SkkoJfj1kvZwsaRqNYMh10Tv0wTe0fCzaCdrvgazfNb0EnJKETgXyhR+3BIQjx9WAqZryejBsp1Bl4qI5En/D9dEhcXAtKCxCmE2kZCiEzpy8BoEUt+bs0DmlaGWO5xkEpttypLIB4rUhDvZd+zwPg4EXk4KSSWSWsurxtqDkKEMshKlQFBTKvJcKwyhk62IeYly4hQ+5IpXjkh1GQXuDRCQ==",
    "AuthPrincipalType": "SubUser",
    "AuthPrincipalDisplayName": "2***************9",
    "NoPermissionType": "ImplicitDeny",
    "AuthAction": "adb:DescribeExcessivePrimaryKeys"
}'),
  createFromViewType?: string(name='CreateFromViewType', example='Basic'),
  DBClusterId?: string(name='DBClusterId', example='amv-bp198m028ih55xxxx'),
  fillOriginViewKeys?: boolean(name='FillOriginViewKeys', example='true'),
  requestId?: string(name='RequestId', example='E031AABF-BD56-5966-A063-4283EF18DB45'),
  viewDetail?: {
    categories?: [ 
      {
        category?: string(name='Category', example='Node'),
        keys?: [ 
          {
            keyName?: string(name='KeyName', example='AnalyticDB_CPU'),
            selected?: boolean(name='Selected', example='true'),
          }
        ](name='Keys'),
      }
    ](name='Categories'),
    chartLinked?: boolean(name='ChartLinked', example='true'),
    chartsPerLine?: int32(name='ChartsPerLine', example='2'),
  }(name='ViewDetail'),
  viewName?: string(name='ViewName'),
}

model DescribePerformanceViewAttributeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribePerformanceViewAttributeResponseBody(name='body'),
}

async function describePerformanceViewAttribute(request: DescribePerformanceViewAttributeRequest): DescribePerformanceViewAttributeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribePerformanceViewAttribute', 'POST', '/', 'json', false, 'json', request);
}

model DescribePerformanceViewsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.', example='amv-bp1ub9grke1****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  regionId: string(name='RegionId', description='The region ID.

>  You can call the [DescribeRegions](~~143074~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model DescribePerformanceViewsResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', example='{
    "PolicyType": "AccountLevelIdentityBasedPolicy",
    "AuthPrincipalOwnerId": "1*****************7",
    "EncodedDiagnosticMessage": "AQIBIAAAAOPdwKY2QLOvgMEc7SkkoJfj1kvZwsaRqNYMh10Tv0wTe0fCzaCdrvgazfNb0EnJKETgXyhR+3BIQjx9WAqZryejBsp1Bl4qI5En/D9dEhcXAtKCxCmE2kZCiEzpy8BoEUt+bs0DmlaGWO5xkEpttypLIB4rUhDvZd+zwPg4EXk4KSSWSWsurxtqDkKEMshKlQFBTKvJcKwyhk62IeYly4hQ+5IpXjkh1GQXuDRCQ==",
    "AuthPrincipalType": "SubUser",
    "AuthPrincipalDisplayName": "2***************9",
    "NoPermissionType": "ImplicitDeny",
    "AuthAction": "adb:DescribeExcessivePrimaryKeys"
}'),
  requestId?: string(name='RequestId', example='3A8F6106-6AFD-5A34-9C80-8DE2C42D06E8'),
  views?: [ 
    {
      createTime?: string(name='CreateTime', example='2024-06-18T07:06:53.000+00:00'),
      updateTime?: string(name='UpdateTime', example='2024-06-18T07:07:32.000+00:00'),
      viewName?: string(name='ViewName'),
    }
  ](name='Views'),
}

model DescribePerformanceViewsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribePerformanceViewsResponseBody(name='body'),
}

async function describePerformanceViews(request: DescribePerformanceViewsRequest): DescribePerformanceViewsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribePerformanceViews', 'POST', '/', 'json', false, 'json', request);
}

model DescribeRegionsRequest {
  acceptLanguage?: string(name='AcceptLanguage', description='The language that is used for the region and zone names indicated by the LocalName parameter in the response parameters. Valid values:

*   **zh-CN** (default): simplified Chinese.
*   **en-US**: English.
*   **ja**: Japanese.', example='en-US', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  regionId?: string(name='RegionId', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model DescribeRegionsResponseBody = {
  regions?: {
    region?: [ 
    {
      localName?: string(name='LocalName', description='The name of the region.', example='China (Hangzhou)'),
      regionEndpoint?: string(name='RegionEndpoint', description='The endpoint of the region.', example='adb.aliyuncs.com'),
      regionId?: string(name='RegionId', description='The region ID.', example='cn-hangzhou'),
      zones?: {
        zone?: [ 
        {
          localName?: string(name='LocalName', description='The name of the zone.', example='Hangzhou Zone H'),
          vpcEnabled?: boolean(name='VpcEnabled', description='Indicates whether Virtual Private Cloud (VPC) is supported in the zone. Valid values:

*   **true**
*   **false**', example='true'),
          zoneId?: string(name='ZoneId', description='The zone ID.', example='cn-hangzhou-h'),
        }
      ](name='Zone')
      }(name='Zones', description='The queried zones.'),
    }
  ](name='Region')
  }(name='Regions', description='The queried regions.'),
  requestId?: string(name='RequestId', description='The request ID.', example='421794A3-72A5-5D27-9E8B-A75A4C503E17'),
}

model DescribeRegionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeRegionsResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeRegions(request: DescribeRegionsRequest): DescribeRegionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeRegions', 'POST', '/', 'json', false, 'json', request);
}

model DescribeSQLPatternsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~129857~~) operation to query the information about all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region, including cluster IDs.', example='amv-8vb8de93v9b****', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.

> The end time must be later than the start time.', example='2022-09-07T03:06:00Z', position='Query'),
  keyword?: string(name='Keyword', description='The keyword that is used for the query.', example='SELECT', position='Query'),
  lang?: string(name='Lang', description='The language. Valid values:

*   **zh** (default): simplified Chinese.
*   **en**: English.
*   **ja**: Japanese.
*   **zh-tw**: traditional Chinese.', example='zh', position='Query'),
  order?: string(name='Order', description='The order by which to sort query results. Specify the parameter value in the JSON format. Example: `[{"Field":"AverageQueryTime","Type":"Asc"}]`.

*   `Field` specifies the field by which to sort the query results. Valid values:

    *   `PatternCreationTime`: the earliest commit time of the SQL pattern within the time range to query.
    *   `AverageQueryTime`: the average total amount of time consumed by the SQL pattern within the time range to query.
    *   `MaxQueryTime`: the maximum total amount of time consumed by the SQL pattern within the time range to query.
    *   `AverageExecutionTime`: the average execution duration of the SQL pattern within the time range to query.
    *   `MaxExecutionTime`: the maximum execution duration of the SQL pattern within the time range to query.
    *   `AveragePeakMemory`: the average peak memory usage of the SQL pattern within the time range to query.
    *   `MaxPeakMemory`: the maximum peak memory usage of the SQL pattern within the time range to query.
    *   `AverageScanSize`: the average amount of data scanned based on the SQL pattern within the time range to query.
    *   `MaxScanSize`: the maximum amount of data scanned based on the SQL pattern within the time range to query.
    *   `QueryCount`: the number of queries performed in association with the SQL pattern within the time range to query.
    *   `FailedCount`: the number of failed queries performed in association with the SQL pattern within the time range to query.

*   `Type` specifies the sorting order. Valid values (case-insensitive):

    *   `Asc`: ascending order.
    *   `Desc`: descending order.', example='[{"Field":"AverageQueryTime","Type":"Asc"}]', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='2', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **10** (default)
*   **30**
*   **50**
*   **100**', example='10', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the *yyyy-MM-ddTHH:mm:ssZ* format. The time must be in UTC.

> *   Only data within the last 14 days can be queried.
> * The maximum time range that can be specified is 24 hours.', example='2022-09-06T03:06:00Z', position='Query'),
}

model DescribeSQLPatternsResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='2'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
  patternDetails?: [ 
    {
      accessIp?: string(name='AccessIp', description='The IP address of the SQL client that commits the SQL pattern.', example='192.168.xx.xx'),
      averageExecutionTime?: double(name='AverageExecutionTime', description='The average execution duration of the SQL pattern within the query time range. Unit: milliseconds.', example='234.78'),
      averageOperatorCost?: double(name='AverageOperatorCost'),
      averagePeakMemory?: double(name='AveragePeakMemory', description='The average peak memory usage of the SQL pattern within the query time range. Unit: bytes.', example='234.22'),
      averageQueryTime?: double(name='AverageQueryTime', description='The average total amount of time consumed by the SQL pattern within the query time range. Unit: milliseconds.', example='4'),
      averageScanCost?: double(name='AverageScanCost'),
      averageScanSize?: double(name='AverageScanSize', description='The average amount of data scanned based on the SQL pattern within the query time range. Unit: bytes.', example='234149.23'),
      blockable?: boolean(name='Blockable', description='Indicates whether the execution of the SQL pattern can be intercepted. Valid values:

*   **true**
*   **false**

>  Only SELECT and INSERT statements can be intercepted.', example='true'),
      failedCount?: long(name='FailedCount', description='The number of failed queries executed in association with the SQL pattern within the query time range.', example='18'),
      maxExecutionTime?: long(name='MaxExecutionTime', description='The maximum execution duration of the SQL pattern within the query time range. Unit: milliseconds.', example='2142'),
      maxOperatorCost?: double(name='MaxOperatorCost'),
      maxPeakMemory?: long(name='MaxPeakMemory', description='The maximum peak memory usage of the SQL pattern within the query time range. Unit: bytes.', example='234149'),
      maxQueryTime?: long(name='MaxQueryTime', description='The maximum total amount of time consumed by the SQL pattern within the query time range. Unit: milliseconds.', example='2341'),
      maxScanCost?: double(name='MaxScanCost'),
      maxScanSize?: long(name='MaxScanSize', description='The maximum amount of data scanned based on the SQL pattern within the query time range. Unit: bytes.', example='32212254'),
      operatorCostPercentage?: double(name='OperatorCostPercentage'),
      operatorCostSum?: double(name='OperatorCostSum'),
      patternCreationTime?: string(name='PatternCreationTime', description='The earliest commit time of the SQL pattern within the query time range.', example='2022-09-06 05:06:00'),
      patternId?: string(name='PatternId', description='The ID of the SQL pattern.', example='5575924945138******'),
      peakMemoryPercentage?: double(name='PeakMemoryPercentage'),
      peakMemorySum?: double(name='PeakMemorySum'),
      queryCount?: long(name='QueryCount', description='The number of queries executed in association with the SQL pattern within the query time range.', example='345'),
      queryTimePercentage?: double(name='QueryTimePercentage'),
      queryTimeSum?: double(name='QueryTimeSum'),
      SQLPattern?: string(name='SQLPattern', description='The statement of the SQL pattern.', example='SELECT * FROM KEPLER_META_NODE_STATIC_INFO WHERE elastic_node = ? OR (elastic_node = ? AND enable = ?)'),
      scanCostPercentage?: double(name='ScanCostPercentage'),
      scanCostSum?: double(name='ScanCostSum'),
      scanSizePercentage?: double(name='ScanSizePercentage'),
      scanSizeSum?: double(name='ScanSizeSum'),
      tables?: string(name='Tables', description='The tables scanned based on the SQL pattern.', example='tpch.orders'),
      user?: string(name='User', description='The name of the database account that is used to commit the SQL pattern.', example='test'),
    }
  ](name='PatternDetails', description='The queried SQL pattern.'),
  requestId?: string(name='RequestId', description='The request ID.', example='F3174013-5B7A-5A47-9FE0-6B5D397BD86B'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='20'),
}

model DescribeSQLPatternsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeSQLPatternsResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describeSQLPatterns(request: DescribeSQLPatternsRequest): DescribeSQLPatternsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSQLPatterns', 'POST', '/', 'json', false, 'json', request);
}

model DescribeSchemasRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1xxxxxxxx47', position='Query'),
  regionId: string(name='RegionId', description='The region ID.', example='cn-hangzhou', position='Query'),
}

model DescribeSchemasResponseBody = {
  items?: {
    schema?: [ 
    {
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
      schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
    }
  ](name='Schema')
  }(name='Items', description='The queried databases.'),
  requestId?: string(name='RequestId', description='The request ID.', example='25B56BC7-4978-40B3-9E48-4B7067******'),
}

model DescribeSchemasResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeSchemasResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describeSchemas(request: DescribeSchemasRequest): DescribeSchemasResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSchemas', 'POST', '/', 'json', false, 'json', request);
}

model DescribeSparkCodeLogRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-uf6o6m8p6x7v****', position='Query'),
  jobId: long(name='JobId', description='The ID of the Spark job.', example='1248', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model DescribeSparkCodeLogResponseBody = {
  log?: string(name='Log', description='The content of the log.', example='>>>>>>>> stdout:n++++++++++++++++++executing sql: MSCK REPAIR TABLE  `footprint_ethereum`.`dwd_eth_eth_txr_v2_di` n++n'),
  message?: string(name='Message', description='The returned message.

*   If the request was successful, **Success** is returned.
*   If the request failed, an error message is returned.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='1CD65640-9963-5D60-929C-118F2C84070E'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeSparkCodeLogResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeSparkCodeLogResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describeSparkCodeLog(request: DescribeSparkCodeLogRequest): DescribeSparkCodeLogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSparkCodeLog', 'POST', '/', 'json', false, 'json', request);
}

model DescribeSparkCodeOutputRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.', example='amv-uf6210mmev07****', position='Query'),
  jobId: long(name='JobId', description='The ID of the Spark job.', example='620', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model DescribeSparkCodeOutputResponseBody = {
  message?: string(name='Message', description='The returned message.

*   If the request was successful, **Success** is returned.
*   If the request failed, an error message is returned.', example='Success'),
  output?: string(name='Output', description='The execution result, which is in the format of JSON objects.', example='"{\\"schema\\":[\\"id\\",\\"name\\",\\"age\\"],\\"data\\":[\\"{\\\\\\"id\\\\\\":10,\\\\\\"name\\\\\\":\\\\\\"z\\\\\\",\\\\\\"age\\\\\\":123}\\",\\"{\\\\\\"id\\\\\\":2,\\\\\\"name\\\\\\":\\\\\\"b\\\\\\",\\\\\\"age\\\\\\":17}\\",\\"{\\\\\\"id\\\\\\":1,\\\\\\"name\\\\\\":\\\\\\"a\\\\\\",\\\\\\"age\\\\\\":15}\\",\\"{\\\\\\"id\\\\\\":3,\\\\\\"name\\\\\\":\\\\\\"c\\\\\\",\\\\\\"age\\\\\\":222}\\",\\"{\\\\\\"id\\\\\\":10,\\\\\\"name\\\\\\":\\\\\\"z\\\\\\",\\\\\\"age\\\\\\":123}\\"],\\"haveRows\\":true,\\"rowNumber\\":6}"'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeSparkCodeOutputResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeSparkCodeOutputResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describeSparkCodeOutput(request: DescribeSparkCodeOutputRequest): DescribeSparkCodeOutputResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSparkCodeOutput', 'POST', '/', 'json', false, 'json', request);
}

model DescribeSparkCodeWebUiRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.', example='amv-bp1v6usq6m65****', position='Query'),
  jobId: long(name='JobId', description='The ID of the Spark job.', example='1248', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
}

model DescribeSparkCodeWebUiResponseBody = {
  message?: string(name='Message', description='The returned message.

*   If the request was successful, **SUCCESS** is returned.
*   If the request failed, an error message is returned.', example='Success'),
  requestId?: string(name='RequestId', description='The request ID.', example='774DDC37-1908-58F6-B9CA-99E3E45965A6'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
  url?: string(name='Url', description='The URL of the web UI for the Spark application.', example='https://adb-subuser-cn-hangzhou-1358535755648527-100000648.oss-cn-hangzhou.aliyuncs.com/%3Facl?Expires=1681295967&OSSAccessKeyId=LTAI5tB7NAkm25oiGASu****&Signature=hKAZ1vgvhJ%2FD8hNHTuX%2FOOBWht****'),
}

model DescribeSparkCodeWebUiResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeSparkCodeWebUiResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describeSparkCodeWebUi(request: DescribeSparkCodeWebUiRequest): DescribeSparkCodeWebUiResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSparkCodeWebUi', 'POST', '/', 'json', false, 'json', request);
}

model DescribeSqlPatternRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1ej1nq9n6****', position='Query'),
  order?: string(name='Order', description='The order by which to sort query results. Specify the parameter value in the JSON string format. Example: `[{"Field":"Pattern","Type":"Asc"}]`. Parameters:

*   `Field` specifies the field by which to sort the query results. Valid values:

    *   `Pattern`: the SQL pattern.
    *   `AccessIP`: the IP address of the client.
    *   `User`: the username.
    *   `QueryCount`: the number of queries performed in association with the SQL pattern within the time range to query.
    *   `AvgPeakMemory`: the average peak memory usage of the SQL pattern within the time range to query. Unit: KB.
    *   `MaxPeakMemory`: the maximum peak memory usage of the SQL pattern within the time range to query. Unit: KB.
    *   `AvgCpuTime`: the average execution duration of the SQL pattern within the time range to query. Unit: milliseconds.
    *   `MaxCpuTime`: the maximum execution duration of the SQL pattern within the time range to query. Unit: milliseconds.
    *   `AvgStageCount`: the average number of stages.
    *   `MaxStageCount`: the maximum number of stages.
    *   `AvgTaskCount`: the average number of tasks.
    *   `MaxTaskCount`: the maximum number of tasks.
    *   `AvgScanSize`: the average amount of data scanned based on the SQL pattern within the time range to query. Unit: KB.
    *   `MaxScanSize`: the maximum amount of data scanned based on the SQL pattern within the time range to query. Unit: KB.

*   `Type` specifies the sorting order. Valid values:

    *   `Asc`: ascending order.
    *   `Desc`: descending order.

> 

*   If you do not specify this parameter, query results are sorted in ascending order of `Pattern`.

*   If you want to sort query results by `AccessIP`, you must set the `Type` parameter to `accessip`. If you want to sort query results by `User`, you must leave the `Type` parameter empty or set it to `user`.', example='[{"Field":"Pattern","Type":"Asc"}]', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='2', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **10** (default)
*   **30**
*   **50**
*   **100**', example='30', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
  sqlPattern?: string(name='SqlPattern', description='The keyword that is used for the query.

> If you do not specify this parameter, all SQL patterns of the AnalyticDB for MySQL cluster within the time period specified by `StartTime` are returned.', example='SELECT', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-dd format. The time must be in UTC.

> Only data within the last 30 days can be queried.', example='2022-08-30T12:10:00Z', position='Query'),
  type?: string(name='Type', description='The dimension by which to aggregate the SQL patterns. Valid values:

*   `user`: aggregates the SQL patterns by user.
*   `accessip`: aggregates the SQL patterns by client IP address.

> If you do not specify this parameter, the SQL patterns are aggregated by `user`.', example='user', position='Query'),
}

model DescribeSqlPatternResponseBody = {
  items?: [ 
    {
      accessIP?: string(name='AccessIP', description='The IP address of the client.

>  This parameter is returned only when **Type** is set to **accessip**.', example='100.104.xx.xx'),
      avgCpuTime?: string(name='AvgCpuTime', description='The average execution duration of the SQL pattern within the query time range. Unit: milliseconds.', example='1.0625'),
      avgPeakMemory?: string(name='AvgPeakMemory', description='The average peak memory usage of the SQL pattern within the query time range. Unit: KB.', example='240048'),
      avgScanSize?: string(name='AvgScanSize', description='The average amount of data scanned based on the SQL pattern within the query time range. Unit: KB.', example='244'),
      avgStageCount?: string(name='AvgStageCount', description='The average number of scanned rows.', example='2'),
      avgTaskCount?: string(name='AvgTaskCount', description='The average number of tasks.', example='2'),
      instanceName?: string(name='InstanceName', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1ej1nq9n6****'),
      maxCpuTime?: string(name='MaxCpuTime', description='The maximum execution duration of the SQL pattern within the query time range. Unit: milliseconds.', example='17'),
      maxPeakMemory?: string(name='MaxPeakMemory', description='The maximum peak memory usage of the SQL pattern within the query time range. Unit: KB.', example='480096'),
      maxScanSize?: string(name='MaxScanSize', description='The maximum amount of data scanned based on the SQL pattern within the query time range. Unit: KB.', example='1024'),
      maxStageCount?: string(name='MaxStageCount', description='The maximum number of stages.', example='2'),
      maxTaskCount?: string(name='MaxTaskCount', description='The maximum number of tasks.', example='2'),
      pattern?: string(name='Pattern', description='The SQL pattern.', example='SELECT table_name, table_schema AS schema_name, create_time, create_time AS last_ddl_time, table_comment AS description , ceil((data_length + index_length) / ? / ?) AS store_capacity , data_length AS data_bytes, index_length AS index_bytes, table_collation AS collation, auto_increment, table_rows AS num_rows , engine FROM information_schema.tables WHERE table_type != ? AND table_schema = ? AND table_name IN (?) ORDER BY 1'),
      queryCount?: string(name='QueryCount', description='The number of queries performed in association with the SQL pattern within the query time range.', example='16'),
      reportDate?: string(name='ReportDate', description='The start date of the query.', example='2022-08-30'),
      user?: string(name='User', description='The username.

>  This parameter is returned only when **Type** is left empty or set to **user**.', example='test_acc'),
    }
  ](name='Items', description='The queried SQL pattern.'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='2'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='DB1F6C23-CBCA-5260-9366-BA7BB5EBF6F1'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='50'),
}

model DescribeSqlPatternResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeSqlPatternResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeSqlPattern(request: DescribeSqlPatternRequest): DescribeSqlPatternResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSqlPattern', 'POST', '/', 'json', false, 'json', request);
}

model DescribeStorageResourceUsageRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp10yt0gva71ei7d', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-08-23T01:06:00Z', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-08-22T01:06:00Z', position='Query'),
}

model DescribeStorageResourceUsageResponseBody = {
  code?: int32(name='Code', description='The HTTP status code.', example='200'),
  data?: {
    acuInfo?: [ 
      {
        name?: string(name='Name', description='The resource usage metric. Valid values:

*   `TotalAcuNumber`: the total number of ACUs.
*   `ReservedAcuNumber`: the number of ACUs for the reserved resources.', example='TotalAcuNumber'),
        values?: [ string ](name='Values', description='The values of the metric at specific points in time.'),
      }
    ](name='AcuInfo', description='The AnalyticDB compute unit (ACU) usage of the cluster.'),
    DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1bg858bo8c****'),
    endTime?: string(name='EndTime', description='The end time of the query. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2022-08-23T01:06:00Z'),
    startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-08-22T01:06:00Z'),
  }(name='Data', description='The queried resource usage.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEAW'),
}

model DescribeStorageResourceUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeStorageResourceUsageResponseBody(name='body'),
}

async function describeStorageResourceUsage(request: DescribeStorageResourceUsageRequest): DescribeStorageResourceUsageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeStorageResourceUsage', 'POST', '/', 'json', false, 'json', request);
}

model DescribeTableAccessCountRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.', example='amv-2ze627uzpkh8a8****', position='Query'),
  order?: string(name='Order', description='The order by which to sort query results. Specify the parameter value in the JSON string format. Example: `[{"Field":"TableSchema","Type":"Asc"}]`. Fields in the request parameter:

*   `Field` specifies the field by which to sort the query results. Valid values:

    *   `TableSchema`: the name of the database to which the table belongs.
    *   `TableName`: the name of the table.
    *   `AccessCount`: the number of accesses to the table.

*   `Type` specifies the sorting order. Valid values:

    *   `Asc`: ascending order.
    *   `Desc`: descending order.

>  If you do not specify this parameter, query results are sorted in ascending order based on the database and the table.', example='[{"Field":"TableSchema","Type":"Asc"}]', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from 1. Default value: **1**.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values:

*   **10** (default)
*   **30**
*   **50**
*   **100**', example='30', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.

>  Only data within the last 30 days can be queried.', example='2022-09-25T12:10:00Z', position='Query'),
  tableName?: string(name='TableName', description='The name of the table.

>  If you leave this parameter empty, the number of accesses to all tables in the cluster on a date is returned.', example='CUSTOMER', position='Query'),
}

model DescribeTableAccessCountResponseBody = {
  items?: [ 
    {
      accessCount?: string(name='AccessCount', description='The number of accesses to the table.', example='6'),
      instanceName?: string(name='InstanceName', description='The ID of the cluster to which the table belongs.', example='amv-2ze627uzpkh8a8****'),
      reportDate?: string(name='ReportDate', description='The date when the table was accessed.', example='2022-09-26'),
      tableName?: string(name='TableName', description='The name of the table.', example='CUSTOMER'),
      tableSchema?: string(name='TableSchema', description='The database to which the table belongs.', example='tpch'),
    }
  ](name='Items', description='The queried tables.'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='6B7D627B-DA23-572D-AD71-256F64698B7D'),
  totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model DescribeTableAccessCountResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeTableAccessCountResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see Endpoints.
  *
 */
async function describeTableAccessCount(request: DescribeTableAccessCountRequest): DescribeTableAccessCountResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeTableAccessCount', 'POST', '/', 'json', false, 'json', request);
}

model DescribeTablesRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1xxxxxxxx47', position='Query'),
  regionId: string(name='RegionId', description='The region ID.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
}

model DescribeTablesResponseBody = {
  items?: {
    table?: [ 
    {
      DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1xxxxxxxx47'),
      schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo'),
      tableName?: string(name='TableName', description='The name of the table.', example='test'),
    }
  ](name='Table')
  }(name='Items', description='The queried tables.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DescribeTablesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeTablesResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function describeTables(request: DescribeTablesRequest): DescribeTablesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeTables', 'POST', '/', 'json', false, 'json', request);
}

model DescribeUserQuotaRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.', example='amv-bp1qjt3o18d86987', position='Query'),
  regionId?: string(name='RegionId', description='The region ID.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
}

model DescribeUserQuotaResponseBody = {
  elasticACU?: string(name='ElasticACU', description='The available elastic AnalyticDB compute units (ACUs).', example='512ACU'),
  requestId?: string(name='RequestId', description='The request ID.', example='0322C7FB-4584-5D2A-BF7F-F9036E940C35'),
  reserverdCompteACU?: string(name='ReserverdCompteACU', description='The available reserved computing resources.', example='48ACU'),
  reserverdStorageACU?: string(name='ReserverdStorageACU', description='The available reserved storage resources.', example='24ACU'),
  resourceGroupCount?: string(name='ResourceGroupCount', description='The number of available resource groups.', example='10'),
}

model DescribeUserQuotaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeUserQuotaResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function describeUserQuota(request: DescribeUserQuotaRequest): DescribeUserQuotaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeUserQuota', 'GET', '/', 'json', false, 'json', request);
}

model DetachUserENIRequest {
  DBClusterId: string(name='DBClusterId', description='The instance ID.', example='am-bp11q28kvl688****', position='Query'),
}

model DetachUserENIResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model DetachUserENIResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DetachUserENIResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function detachUserENI(request: DetachUserENIRequest): DetachUserENIResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DetachUserENI', 'POST', '/', 'json', false, 'json', request);
}

model DisableElasticPlanRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the names of scaling plans.', example='test', position='Query'),
}

model DisableElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model DisableElasticPlanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DisableElasticPlanResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function disableElasticPlan(request: DisableElasticPlanRequest): DisableElasticPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DisableElasticPlan', 'POST', '/', 'json', false, 'json', request);
}

model DownloadDiagnosisRecordsRequest {
  clientIp?: string(name='ClientIp', description='The source IP address.

>  You can call the [DescribeDiagnosisDimensions](~~308210~~) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.', example='106.11.XX.XX', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1q8bu9a****', position='Query'),
  database?: string(name='Database', description='The name of the database on which the SQL statements are executed.

>  You can call the [DescribeDiagnosisDimensions](~~308210~~) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.', example='adb_demo', position='Query'),
  endTime?: string(name='EndTime', description='The end of the time range to query. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

> 

*   The end time must be later than the start time.

*   The maximum time range that can be specified is 24 hours.', example='1662450730000', position='Query'),
  keyword?: string(name='Keyword', description='The query keyword of the SQL statements.', example='select', position='Query'),
  lang?: string(name='Lang', description='The language. Valid values:

*   **zh**: simplified Chinese.
*   **en**: English.
*   **ja**: Japanese.
*   **zh-tw**: traditional Chinese.', example='zh', position='Query'),
  maxPeakMemory?: long(name='MaxPeakMemory', description='The maximum peak memory of the SQL statements. Unit: bytes.', example='88000000', position='Query'),
  maxScanSize?: long(name='MaxScanSize', description='The maximum scan size of the SQL statements. Unit: bytes.', example='64424509440', position='Query'),
  minPeakMemory?: long(name='MinPeakMemory', description='The minimum peak memory of the SQL statements. Unit: bytes.', example='88000000', position='Query'),
  minScanSize?: long(name='MinScanSize', description='The minimum scan size of the SQL statements. Unit: bytes.', example='1073741824', position='Query'),
  queryCondition?: string(name='QueryCondition', description='The query condition for SQL statements, which can contain the `Type`, `Value`, `Min`, and `Max` fields. Specify the condition in the JSON format. `Type` specifies the query dimension. Valid values for Type: `maxCost`, `status`, and `cost`. `Value`, `Min`, or `Max` specifies the query range for the dimension. Valid values:

*   `{"Type":"maxCost","Value":"100"}`: queries the top 100 most time-consuming SQL statements. Set `Value` to 100.
*   `{"Type":"status","Value":"finished"}`: queries the executed SQL statements. You can set `Value` to `running` to query the SQL statements that are being executed. You can also set Value to `failed` to query the SQL statements that failed to be executed.
*   `{"Type":"cost","Min":"10","Max":"200"}`: queries the SQL statements whose execution duration is in the range of 10 to 200 milliseconds. You can also specify custom values for the Min and Max fields.', example='{"Type":"status","Value":"finished"}', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
  resourceGroup?: string(name='ResourceGroup', description='The resource group to which the SQL statements belong.

>  You can call the [DescribeDiagnosisDimensions](~~308210~~) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.', example='user_default', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Set the time to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  You can query data only within the last 14 days.', example='1662364330000', position='Query'),
  userName?: string(name='UserName', description='The username that is used to execute the SQL statements.

>  You can call the [DescribeDiagnosisDimensions](~~~~) operation to query the resource groups, database names, usernames, and source IP addresses of the SQL statements that meet a query condition.', example='test_user', position='Query'),
}

model DownloadDiagnosisRecordsResponseBody = {
  downloadId?: int32(name='DownloadId', description='The download ID.', example='25494'),
  requestId?: string(name='RequestId', description='The request ID.', example='845774AC-5D43-53A2-AAB8-C73828E68508'),
}

model DownloadDiagnosisRecordsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DownloadDiagnosisRecordsResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see Endpoints.
  *
 */
async function downloadDiagnosisRecords(request: DownloadDiagnosisRecordsRequest): DownloadDiagnosisRecordsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DownloadDiagnosisRecords', 'POST', '/', 'json', false, 'json', request);
}

model EnableElasticPlanRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the names of scaling plans.', example='test', position='Query'),
}

model EnableElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model EnableElasticPlanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: EnableElasticPlanResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function enableElasticPlan(request: EnableElasticPlanRequest): EnableElasticPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'EnableElasticPlan', 'POST', '/', 'json', false, 'json', request);
}

model ExistRunningSQLEngineRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the information about all AnalyticDB for MySQL clusters within a region, including cluster IDs.', example='amv-bp1cit7z8j****', position='Body'),
  resourceGroupName: string(name='ResourceGroupName', description='The name of the resource group.

>  You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of the resource group for a cluster.', example='spark_test', position='Body'),
}

model ExistRunningSQLEngineResponseBody = {
  data?: boolean(name='Data', description='Indicates whether a running SQL engine exists in the resource group.

Valid values:

*   **True**
*   **False**', example='True'),
  requestId?: string(name='RequestId', description='The request ID.', example='FA675D68-14A4-5D9C-8820-92537D9F447E'),
}

model ExistRunningSQLEngineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ExistRunningSQLEngineResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function existRunningSQLEngine(request: ExistRunningSQLEngineRequest): ExistRunningSQLEngineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ExistRunningSQLEngine', 'POST', '/', 'json', true, 'form', request);
}

model GetDatabaseObjectsRequest {
  DBClusterId?: string(name='DBClusterId', description='The cluster ID.', example='am-bp1565u55p32****', position='Query'),
  filterOwner?: string(name='FilterOwner', description='The owner of the database.', example='admin', position='Query'),
  filterSchemaName?: string(name='FilterSchemaName', description='The name of the database.', example='test_db', position='Query'),
  orderBy?: string(name='OrderBy', description='The order in which you want to sort the query results. Valid values:

*   Asc
*   Desc

Valid values for Field: DatabaseName, CreateTime, and UpdateTime. -CreateTime; -UpdateTime;

Default value: {"Type": "Desc","Field": "DatabaseName"}.', example='{"Type": "Desc","Field": "DbName"}', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   30
*   50
*   100

Default value: 30.', example='30', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the database.', example='cn-hangzhou', position='Query'),
}

model GetDatabaseObjectsResponseBody = {
  data?: {
    databaseSummaryModels?: [
      DatabaseSummaryModel
    ](name='DatabaseSummaryModels', description='The queried database.'),
    pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   30
*   50
*   100

Default value: 30.', example='30'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The queried databases.'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='863D51B7-5321-41D8-A0B6-A088B0******'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model GetDatabaseObjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDatabaseObjectsResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function getDatabaseObjects(request: GetDatabaseObjectsRequest): GetDatabaseObjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDatabaseObjects', 'POST', '/', 'json', false, 'json', request);
}

model GetSparkAppAttemptLogRequest {
  attemptId: string(name='AttemptId', description='The ID of the log.

> You can call the [ListSparkAppAttempts](~~455887~~) operation to query the information about the retry attempts of a Spark application, including the retry log IDs.', example='s202207151211hz****-0001', maxLength=72, position='Body'),
  logLength?: long(name='LogLength', description='The number of log entries to return. Valid values: 1 to 500. Default value: 300.', example='20', minimum=0, maximum=500, position='Body'),
  pageNumber?: int32(name='PageNumber', description='The log offset.', example='1', minimum=0, position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries per page.', example='500', position='Query'),
}

model GetSparkAppAttemptLogResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The application ID.', example='s202204132018hzprec1ac61a000****'),
    DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-clusterxxx'),
    logContent?: string(name='LogContent', description='The content of the log.', example='22/04/22 15:30:49 INFO Utils: Start the dump task because s202207151211hz****-0001 app end, the interval is 238141ms;22/04/22 15:30:49 INFO AbstractConnector: Stopped Spark@5e774d9d{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}'),
    logSize?: int32(name='LogSize', description='The number of log entries. A value of 0 indicates that no valid logs are returned.', example='775946240'),
    message?: string(name='Message', description='The alert message returned for the request, such as task execution failure or insufficient resources. If no alert occurs, null is returned.', example='WARNING: log file maybe deleted, please check oss path: oss://TestBucketName/applog/'),
  }(name='Data', description='The queried log.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C3A9594F-1D40-4472-A96C-8FB8AA20D38C'),
}

model GetSparkAppAttemptLogResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSparkAppAttemptLogResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function getSparkAppAttemptLog(request: GetSparkAppAttemptLogRequest): GetSparkAppAttemptLogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkAppAttemptLog', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkAppInfoRequest {
  appId: string(name='AppId', description='The application ID.

>  You can call the [ListSparkApps](~~455888~~) operation to query the Spark application IDs.', example='s202205201533hz1209892000****', maxLength=64, position='Body'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='am-bp11q28kvl688****', position='Query'),
}

model GetSparkAppInfoResponseBody = {
  data?: SparkAppInfo(name='Data', description='The queried Spark application. Fields in the response parameter:

*   **Data**: the data of the Spark application template.
*   **EstimateExecutionCpuTimeInSeconds**: the amount of time that is required to consume CPU resources for running the Spark application. Unit: milliseconds.
*   **LogRootPath**: the storage path of log files.
*   **LastAttemptId**: the most recent attempt ID.
*   **WebUiAddress**: the web UI URL.
*   **SubmittedTimeInMillis**: the time when the Spark application was submitted. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
*   **StartedTimeInMillis**: the time when the Spark application was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
*   **LastUpdatedTimeInMillis**: the time when the Spark application was last updated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
*   **TerminatedTimeInMillis**: the time when the Spark application was terminated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.
*   **DBClusterId**: the ID of the cluster on which the Spark application runs.
*   **ResourceGroupName**: the name of the job resource group.
*   **DurationInMillis**: the amount of time that is required to run the Spark application. Unit: milliseconds.', example='{     \\"name\\": \\"SparkPi\\",     \\"file\\": \\"local:///tmp/spark-examples.jar\\",     \\"className\\": \\"org.apache.spark.examples.SparkPi\\",     \\"args\\": [         \\"1000000\\"     ],     \\"conf\\": {         \\"spark.driver.resourceSpec\\": \\"small\\",         \\"spark.executor.instances\\": 1,         \\"spark.executor.resourceSpec\\": \\"small\\"     } }",
      "EstimateExecutionCpuTimeInSeconds" : 100,
      "LogRootPath" : "oss://test/logs/driver",
      "LastAttemptId" : "s202204291426hzpre60cfabb0000004-0003",
      "WebUiAddress" : "https://sparkui.aliyuncs.com/token=xxx",
      "SubmittedTimeInMillis" : 1651213645000,
      "StartedTimeInMillis" : 1651213645010,
      "LastUpdatedTimeInMillis" : 1651213645200,
      "TerminatedTimeInMillis" : 1651213645300,
      "DBClusterId" : "am-dbclusterid",
      "ResourceGroupName" : "spark-rg",
      "DurationInMillis" : 100
    }'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkAppInfoResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSparkAppInfoResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function getSparkAppInfo(request: GetSparkAppInfoRequest): GetSparkAppInfoResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkAppInfo', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkAppLogRequest {
  appId: string(name='AppId', description='The Spark application ID.

> You can call the [ListSparkApps](~~612475~~) operation to query the Spark application ID.', example='s202206061441hz22a35ab000****', position='Body'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.', example='amv-2ze6fl8ud7t***', position='Query'),
  logLength?: long(name='LogLength', description='The number of log entries to return. Valid values: 1 to 500. Default value: 300.', example='20', minimum=0, maximum=500, position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', minimum=0, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='500', position='Query'),
}

model GetSparkAppLogResponseBody = {
  data?: {
    DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-clusterxxx'),
    logContent?: string(name='LogContent', description='The content of the log.', example='22/04/22 15:30:49 INFO Utils: Start the dump task because s202206061441hz22a35ab000****-0001 app end, the interval is 238141ms;22/04/22 15:30:49 INFO AbstractConnector: Stopped Spark@5e774d9d{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}'),
    logSize?: int32(name='LogSize', description='The number of log entries. A value of 0 indicates that no valid logs are returned.', example='3517972480'),
    message?: string(name='Message', description='The alert message returned for the request, such as task execution failure or insufficient resources. If no alert occurs, null is returned.', example='WARNING:  log file maybe deleted, please check oss path: oss://TestBucketName/applog/'),
  }(name='Data', description='The queried log.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C3A9594F-1D40-4472-A96C-8FB8AA20D38C'),
}

model GetSparkAppLogResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSparkAppLogResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function getSparkAppLog(request: GetSparkAppLogRequest): GetSparkAppLogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkAppLog', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkAppMetricsRequest {
  appId: string(name='AppId', description='The ID of the Spark application.', example='s202204221525hzca7d8140000003', maxLength=64, position='Body'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.', example='amv-bp1ggnu61d77****', position='Query'),
}

model GetSparkAppMetricsResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark application.', example='s202302051515shfa865f80003691'),
    attemptId?: string(name='AttemptId', description='The attempt ID of the Spark application.', example='s202301061000hz57d797b0000201-0001'),
    eventLogPath?: string(name='EventLogPath', description='The path of the event log.', example='oss://path/to/eventLog'),
    finished?: boolean(name='Finished', description='Indicates whether parsing is complete. Valid values:

*   true
*   false', example='True'),
    scanMetrics?: {
      outputRowsCount?: long(name='OutputRowsCount', description='The number of scanned rows.', example='1000'),
      totalReadFileSizeInByte?: long(name='TotalReadFileSizeInByte', description='The number of scanned bytes.', example='10000'),
    }(name='ScanMetrics', description='The metrics.'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model GetSparkAppMetricsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSparkAppMetricsResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function getSparkAppMetrics(request: GetSparkAppMetricsRequest): GetSparkAppMetricsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkAppMetrics', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkAppStateRequest {
  appId: string(name='AppId', description='The Spark application ID.

>  You can call the [ListSparkApps](~~455888~~) operation to query Spark application IDs.', example='s202204191546hzpread6a896000****', maxLength=64, position='Body'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.', example='amv-bp1h405854m****', position='Query'),
}

model GetSparkAppStateResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The Spark application ID.', example='s202204191546hzpread6a896000****'),
    appName?: string(name='AppName', description='The name of the application.', example='test'),
    DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-clusterxxx'),
    message?: string(name='Message', description='The alert message returned for the operation, such as task execution failure or insufficient resources. If no alert occurs, null is returned.', example='Insufficient resources.'),
    state?: string(name='State', description='The execution state of the application. Valid values:

*   **SUBMITTED**
*   **STARTING**
*   **RUNNING**
*   **FAILING**
*   **FAILED**
*   **KILLING**
*   **KILLED**
*   **SUCCEEDING**
*   **COMPLETED**
*   **FATAL**
*   **UNKNOWN**', example='COMPLETED'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkAppStateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSparkAppStateResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function getSparkAppState(request: GetSparkAppStateRequest): GetSparkAppStateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkAppState', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkAppWebUiAddressRequest {
  appId: string(name='AppId', description='The Spark application ID.

>  You can call the [ListSparkApps](~~455888~~) operation to query Spark application IDs.', example='s202205201533hz1209892000****', maxLength=64, position='Body'),
  DBClusterId?: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-uf6g8w25jacm7****', position='Query'),
}

model GetSparkAppWebUiAddressResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The Spark application ID.', example='s202205201533hz1209892000****'),
    DBClusterId?: string(name='DBClusterId', description='The database ID.', example='amv-clusterxxx'),
    expirationTimeInMillis?: long(name='ExpirationTimeInMillis', description='The expiration time. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1655801973000'),
    webUiAddress?: string(name='WebUiAddress', description='The URL of the web UI for the Spark application.', example='https://adbsparkui-cn-hangzhou.aliyuncs.com/?token=****'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkAppWebUiAddressResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSparkAppWebUiAddressResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function getSparkAppWebUiAddress(request: GetSparkAppWebUiAddressRequest): GetSparkAppWebUiAddressResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkAppWebUiAddress', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkConfigLogPathRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='am-adsdxxxx', maxLength=64, position='Body'),
}

model GetSparkConfigLogPathResponseBody = {
  data?: {
    defaultLogPath?: string(name='DefaultLogPath', description='The default log path.', example='oss://aliyun-oa-adb-spark-1111-oss-cn-hanghzou/spark-logs'),
    isLogPathExists?: boolean(name='IsLogPathExists', description='Indicates whether a log path exists.', example='true'),
    modifiedTimestamp?: string(name='ModifiedTimestamp', description='The last modification time.', example='1675654361000'),
    modifiedUid?: string(name='ModifiedUid', description='The account ID of the modifier.', example='10130223128xxx'),
    recordedLogPath?: string(name='RecordedLogPath', description='The recorded log path.', example='oss://test/spark-logs/'),
  }(name='Data', description='The queried Spark log configuration.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1919-xxx-ssdfsdff'),
}

model GetSparkConfigLogPathResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSparkConfigLogPathResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function getSparkConfigLogPath(request: GetSparkConfigLogPathRequest): GetSparkConfigLogPathResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkConfigLogPath', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkDefinitionsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-clusterxxx', position='Body'),
}

model GetSparkDefinitionsResponseBody = {
  data?: string(name='Data', description='The common definitions of Spark applications.', example='{"SQLTemplateExample": "-- Here is just an example of SparkSQL. Modify the content and run your spark program.
conf spark.driver.resourceSpec=medium;
conf spark.executor.instances=2;
conf spark.executor.resourceSpec=medium;
conf spark.app.name=Spark SQL Test;
conf spark.adb.connectors=oss;

-- Here are your sql statements
show databases;",
                 "BatchTemplateExample": "{
    "comments": [
        "-- Here is just an example of SparkPi. Modify the content and run your spark program."
    ],
    "args": ["1000"],
  "file":"local:///tmp/spark-examples.jar",
    "name": "SparkPi",
    "className": "org.apache.spark.examples.SparkPi",
    "conf": {      "spark.driver.resourceSpec": "medium",
        "spark.executor.instances": 2,
        "spark.executor.resourceSpec": "medium"
    }
}"'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkDefinitionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSparkDefinitionsResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function getSparkDefinitions(request: GetSparkDefinitionsRequest): GetSparkDefinitionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkDefinitions', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkLogAnalyzeTaskRequest {
  taskId: long(name='TaskId', description='The ID of the Spark log analysis task. You can call the ListSparkLogAnalyzeTasks operation to query the IDs of all Spark log analysis tasks that are submitted in the current cluster.', example='12', minimum=0, position='Body'),
}

model GetSparkLogAnalyzeTaskResponseBody = {
  data?: SparkAnalyzeLogTask(name='Data', description='The information about the Spark log analysis task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1DF5AF5B-C803-1861-A0FF-63666A557709'),
}

model GetSparkLogAnalyzeTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSparkLogAnalyzeTaskResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function getSparkLogAnalyzeTask(request: GetSparkLogAnalyzeTaskRequest): GetSparkLogAnalyzeTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkLogAnalyzeTask', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkSQLEngineStateRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-bp11q28kvl688****', position='Body'),
  resourceGroupName: string(name='ResourceGroupName', description='The name of the job resource group.', example='test_instance', position='Body'),
}

model GetSparkSQLEngineStateResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark application.', example='s202207151211hz0c****'),
    config?: string(name='Config', description='The configuration of the Spark application.', example='{"key1": "value1", "key2": "value2"}'),
    jars?: string(name='Jars', description='The third-party JAR package.', example='oss://test-bucket/test.jar'),
    maxExecutor?: string(name='MaxExecutor', description='The maximum number of started Spark executors.', example='3'),
    minExecutor?: string(name='MinExecutor', description='The minimum number of started Spark executors.', example='1'),
    slotNum?: string(name='SlotNum', description='The slot number of the Spark application.', example='2'),
    state?: string(name='State', description='The execution state of the application. Valid values:

*   SUBMITTED
*   STARTING
*   RUNNING
*   FAILING
*   FAILED
*   KILLING
*   KILLED
*   SUCCEEDING
*   COMPLETED
*   FATAL
*   UNKNOWN', example='COMPLETED'),
    submittedTimeInMillis?: string(name='SubmittedTimeInMillis', description='The timestamp when the Spark SQL application was submitted. Unit: milliseconds.', example='1651213645000'),
  }(name='Data', description='The state information about the Spark SQL engine.'),
  requestId?: string(name='RequestId', description='The request ID.', example='xxxx-xxx-xx'),
}

model GetSparkSQLEngineStateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSparkSQLEngineStateResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function getSparkSQLEngineState(request: GetSparkSQLEngineStateRequest): GetSparkSQLEngineStateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkSQLEngineState', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkTemplateFileContentRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-8vbn8pq537k8w****', maxLength=64, position='Body'),
  id: long(name='Id', description='The application template ID.

>  You can call the [GetSparkTemplateFullTree](~~456205~~) operation to query the application template ID.', example='725204', minimum=0, position='Body'),
}

model GetSparkTemplateFileContentResponseBody = {
  data?: {
    appType?: string(name='AppType', description='The application type. Valid values:

*   **SQL**
*   **STREAMING**
*   **BATCH**', example='SQL'),
    content?: string(name='Content', description='The content of the application template.', example='set spark.driver.resourceSpec=medium;set spark.executor.instances=2;set spark.executor.resourceSpec=medium;set spark.app.name=Spark SQL Test;'),
    id?: long(name='Id', description='The application template ID.', example='725204'),
    resourceGroupName?: string(name='ResourceGroupName', description='The name of the resource group.', example='test'),
    type?: string(name='Type', description='The file type. Valid values:

*   **folder**
*   **file**', example='file'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model GetSparkTemplateFileContentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSparkTemplateFileContentResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function getSparkTemplateFileContent(request: GetSparkTemplateFileContentRequest): GetSparkTemplateFileContentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkTemplateFileContent', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkTemplateFolderTreeRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-bp11q28kvl688****', maxLength=64, position='Body'),
}

model GetSparkTemplateFolderTreeResponseBody = {
  data?: string(name='Data', description='The directory structure of Spark applications, which is in the tree format. Fields in the response parameter:

*   **Uid**: the UID of the Alibaba Cloud account.

*   **Type**: the application template type. Valid values: **FOLDER**

*   **Parent**: indicates whether a child directory exists. Valid values:

    *   **0**: no.
    *   **-1**: yes.

*   **Children**: the child directory.

*   **LastModified**: the time when applications in the directory are last modified. This value is a UNIX timestamp representing the number of seconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **Name**: the name of the directory.

*   **Id**: the directory ID.', example='{           "Uid":195813423****,           "Type":"FOLDER",          "Parent":-1,           "Children":[              {                     "LastModified":1647853173,               "Uid":195813423****,                     "Type":"FOLDER",                     "Parent":0,                     "Id":157,                     "Name":"t"         }       ],            "Id":725204,            "Name":"root"      }'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model GetSparkTemplateFolderTreeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSparkTemplateFolderTreeResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function getSparkTemplateFolderTree(request: GetSparkTemplateFolderTreeRequest): GetSparkTemplateFolderTreeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkTemplateFolderTree', 'POST', '/', 'json', true, 'form', request);
}

model GetSparkTemplateFullTreeRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', maxLength=64, position='Body'),
}

model GetSparkTemplateFullTreeResponseBody = {
  data?: string(name='Data', description='The directory structure of Spark applications. Fields in the response parameter:

*   **Uid**: the UID of the Alibaba Cloud account.

*   **Type**: the application template type. Valid values:

    *   **FOLDER**
    *   **FILE**

*   **Parent**: indicates whether a child directory exists. Valid values:

    *   **0**: no.
    *   **-1**: yes.

*   **Children**: the child directory.

*   **LastModified**: the time when applications are last modified. This value is a UNIX timestamp representing the number of seconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **AppType**: the application type. Valid values:

    *   **SQL**
    *   **STREAMING**
    *   **BATCH**

*   **Name**: the name of the directory or application.

*   **Id**: the directory ID or application ID.', example='{     "Uid": 10415777****,     "Type": "FOLDER",     "Parent": -1,     "Children": [       {         "LastModified": 1648544748,         "Uid": 104157779****,         "Type": "FILE",         "Parent": 0,         "Id": s202204132****,         "AppType": "SQL",         "Name": "f"       },       {         "LastModified": 1648544956,         "Uid": 1041577795****,         "Type": "FOLDER",         "Parent": 0,         "Id": 157,         "Name": "f3333"       }     ],     "Id": 725204,     "Name": "root"   }'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model GetSparkTemplateFullTreeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSparkTemplateFullTreeResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function getSparkTemplateFullTree(request: GetSparkTemplateFullTreeRequest): GetSparkTemplateFullTreeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSparkTemplateFullTree', 'POST', '/', 'json', true, 'form', request);
}

model GetTableRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.', example='amv-*******', position='Query'),
  dbName?: string(name='DbName', description='The name of the database.', example='dbName', position='Query'),
  regionId: string(name='RegionId', description='The ID of the region in which the cluster resides.', example='cn-hangzhou', position='Query'),
  tableName?: string(name='TableName', description='The name of the table.', example='tableName', position='Query'),
}

model GetTableResponseBody = {
  code?: long(name='Code', description='The error code returned.', example='0'),
  message?: string(name='Message', description='The error message returned.', example='""'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  success?: boolean(name='Success', description='Indicates whether the query succeeded.', example='true'),
  table?: TableModel(name='Table', description='The information about the table.'),
}

model GetTableResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTableResponseBody(name='body'),
}

async function getTable(request: GetTableRequest): GetTableResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTable', 'POST', '/', 'json', false, 'json', request);
}

model GetTableColumnsRequest {
  columnName?: string(name='ColumnName', description='The name of the column.', example='assist_user_phone', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The cluster ID.', example='amv-bp11q28kvl688****', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
  tableName?: string(name='TableName', description='The name of the table.', example='test', position='Query'),
}

model GetTableColumnsResponseBody = {
  data?: {
    pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
    table?: TableDetailModel(name='Table', description='The information about the table.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='15'),
  }(name='Data', description='The queried data.'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='15'),
}

model GetTableColumnsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTableColumnsResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function getTableColumns(request: GetTableColumnsRequest): GetTableColumnsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTableColumns', 'POST', '/', 'json', false, 'json', request);
}

model GetTableDDLRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.', example='am-bp1ub9grke1****', position='Query'),
  regionId: string(name='RegionId', description='The region ID.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
  tableName?: string(name='TableName', description='The name of the table.', example='test', position='Query'),
}

model GetTableDDLResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='863D51B7-5321-41D8-A0B6-A088B0******'),
  SQL?: string(name='SQL', description='The SQL statement.', example='create table (
 id varchar(32)
);'),
}

model GetTableDDLResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTableDDLResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function getTableDDL(request: GetTableDDLRequest): GetTableDDLResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTableDDL', 'POST', '/', 'json', false, 'json', request);
}

model GetTableObjectsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the cluster.', example='am-bp1565u55p32****', position='Query'),
  filterDescription?: string(name='FilterDescription', description='The description of the table.', example='description', position='Query'),
  filterOwner?: string(name='FilterOwner', description='The owner of the table.', example='admin', position='Query'),
  filterTblName?: string(name='FilterTblName', description='The name of the table.', example='test_tbl', position='Query'),
  filterTblType?: string(name='FilterTblType', description='The type of the table.

Valid values:

DIMENSION_TABLE

FACT_TABLE

EXTERNAL_TABLE

Default value: null.', example='FACT_TABLE', position='Query'),
  orderBy?: string(name='OrderBy', description='The order in which the fields to be returned are sorted.

Valid values:

*   Asc
*   Desc

Values for fields:

TableName

TableSize

CreateTime

UpdateTime

Default value: {"Type": "Desc","Field": "TableName"};', example='{"Type": "Desc","Field": "TableName"}', position='Query'),
  pageNumber?: long(name='PageNumber', description='The number of the page to return. The value is an integer that is greater than 0. Default value: **1**.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries to return on each page. Valid values:

*   30
*   50
*   100

Default value: 30.', example='30', position='Query'),
  regionId: string(name='RegionId', description='The ID of the region in which the cluster resides.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
}

model GetTableObjectsResponseBody = {
  data?: {
    pageNumber?: long(name='PageNumber', description='The number of the returned page. The value is an integer that is greater than 0. Default value: **1**.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries returned per page. Default value: 30. Valid values:

*   **30**
*   **50**
*   **100**', example='30'),
    tableSummaryModels?: [
      TableSummaryModel
    ](name='TableSummaryModels', description='Details of the tables.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The data returned.'),
  pageNumber?: long(name='PageNumber', description='The number of the returned page. The value is an integer that is greater than 0. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries returned per page. Default value: 30. Valid values:

*   **30**
*   **50**
*   **100**', example='30'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='863D51B7-5321-41D8-A0B6-A088B0******'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model GetTableObjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTableObjectsResponseBody(name='body'),
}

async function getTableObjects(request: GetTableObjectsRequest): GetTableObjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTableObjects', 'POST', '/', 'json', false, 'json', request);
}

model GetViewDDLRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.', example='am-bp1ub9grke1****', position='Query'),
  regionId: string(name='RegionId', description='The region ID.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
  viewName?: string(name='ViewName', description='The name of the view.', example='v_modbus', position='Query'),
}

model GetViewDDLResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='421794A3-72A5-5D27-9E8B-A75A4C503E17'),
  SQL?: string(name='SQL', description='The SQL statement.', example='CREATE VIEW `test`.`test_view` AS SELECT
  `id`
, `name`
FROM
  `test_tbl_adb`'),
}

model GetViewDDLResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetViewDDLResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function getViewDDL(request: GetViewDDLRequest): GetViewDDLResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetViewDDL', 'POST', '/', 'json', false, 'json', request);
}

model GetViewObjectsRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.', example='am-bp1xxxxxxxx47', position='Query'),
  filterOwner?: string(name='FilterOwner', description='The owner of the view.', example='admin', position='Query'),
  filterViewName?: string(name='FilterViewName', description='The name of the view.', example='test_filter', position='Query'),
  filterViewType?: string(name='FilterViewType', description='The type of the view.

Valid values:

\\-VIRTUAL_VIEW

\\-MATERIALIZED_VIEW

Default value: null.', example='VIRTUAL_VIEW', position='Query'),
  orderBy?: string(name='OrderBy', description='The order in which you want to sort the query results. Valid values for Type:

*   Asc
*   Desc

Valid values for Field: -ViewName

\\-CreateTime

\\-UpdateTime

Default value: {"Type": "Desc","Field": "ViewName"}.', example='{"Type": "Desc","Field": "ViewName"}', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30', position='Query'),
  regionId: string(name='RegionId', description='The region ID of the cluster.', example='cn-hangzhou', position='Query'),
  schemaName?: string(name='SchemaName', description='The name of the database.', example='adb_demo', position='Query'),
}

model GetViewObjectsResponseBody = {
  data?: {
    pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
    tableSummaryModels?: [
      TableSummaryModel
    ](name='TableSummaryModels', description='The queried views.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The returned data.'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: **1**.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **30** (default)
*   **50**
*   **100**', example='30'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model GetViewObjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetViewObjectsResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function getViewObjects(request: GetViewObjectsRequest): GetViewObjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetViewObjects', 'POST', '/', 'json', false, 'json', request);
}

model KillSparkAppRequest {
  appId: string(name='AppId', description='The ID of the Spark application that you want to terminate.', example='s202204132018hzprec1ac****', maxLength=64, position='Body'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.', example='amv-bp1ub9grke1****', position='Query'),
}

model KillSparkAppResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The Spark application ID.', example='s202204132018hzprec1ac****'),
    appName?: string(name='AppName', description='The name of the application.', example='LAKEHOUSE-1-1'),
    DBClusterId?: string(name='DBClusterId', description='The cluster ID.', example='amv-bp1c3em7b2e****'),
    message?: string(name='Message', description='The error message returned.', example='[Advisor] Advisor feature is not available for instance: am-2ze292w4fyglwxxxx'),
    state?: string(name='State', description='The execution state of the Spark application. Valid values:

*   **SUBMITTED**
*   **STARTING**
*   **RUNNING**
*   **FAILING**
*   **FAILED**
*   **KILLING**
*   **KILLED**
*   **SUCCEEDING**
*   **COMPLETED**
*   **FATAL**
*   **UNKNOWN**', example='running'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='69D0810B-F9F5-5F4C-A57F-DF36133B63C9'),
}

model KillSparkAppResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: KillSparkAppResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function killSparkApp(request: KillSparkAppRequest): KillSparkAppResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'KillSparkApp', 'POST', '/', 'json', true, 'form', request);
}

model KillSparkLogAnalyzeTaskRequest {
  taskId: long(name='TaskId', description='The ID of the Spark log analysis task. You can call the ListSparkLogAnalyzeTasks operation to query the IDs and states of all analysis tasks in the current cluster.', example='15', minimum=0, position='Body'),
}

model KillSparkLogAnalyzeTaskResponseBody = {
  data?: SparkAnalyzeLogTask(name='Data', description='The information about the Spark log analysis task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1DF5AF5B-C803-1861-A0FF-63666A557709'),
}

model KillSparkLogAnalyzeTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: KillSparkLogAnalyzeTaskResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function killSparkLogAnalyzeTask(request: KillSparkLogAnalyzeTaskRequest): KillSparkLogAnalyzeTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'KillSparkLogAnalyzeTask', 'POST', '/', 'json', true, 'form', request);
}

model KillSparkSQLEngineRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-8vbn8pq537k8w****', position='Body'),
  resourceGroupName: string(name='ResourceGroupName', description='The name of the resource group.', example='spark_test', position='Body'),
}

model KillSparkSQLEngineResponseBody = {
  data?: boolean(name='Data', description='Indicates whether the request was successful.', example='true'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model KillSparkSQLEngineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: KillSparkSQLEngineResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function killSparkSQLEngine(request: KillSparkSQLEngineRequest): KillSparkSQLEngineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'KillSparkSQLEngine', 'POST', '/', 'json', true, 'form', request);
}

model ListSparkAppAttemptsRequest {
  appId: string(name='AppId', description='The ID of the Spark application.

> You can call the [ListSparkApps](~~455888~~) operation to query all application IDs.', example='s202204132018hzprec1ac****', position='Query'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-uf6o6m8p6x***', position='Query'),
  pageNumber: long(name='PageNumber', description='The page number. The value must be an integer that is greater than 0. Default value: **1**.', example='1', minimum=1, position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Valid values:

*   **10** (default)
*   **50**
*   **100**', example='10', minimum=1, maximum=100, position='Query'),
}

model ListSparkAppAttemptsResponseBody = {
  data?: {
    attemptInfoList?: [
      SparkAttemptInfo
    ](name='AttemptInfoList', description='The information about the attempts. Fields in the response parameter:

*   **AttemptId**: the attempt ID.

*   **State**: the state of the Spark application. Valid values:

    *   **SUBMITTED**
    *   **STARTING**
    *   **RUNNING**
    *   **FAILING**
    *   **FAILED**
    *   **KILLING**
    *   **KILLED**
    *   **SUCCEEDING**
    *   **COMPLETED**
    *   **FATAL**
    *   **UNKNOWN**

*   **Message**: the alert message that is returned. If no alert is generated, null is returned.

*   **Data**: the data of the Spark application template.

*   **EstimateExecutionCpuTimeInSeconds**: the amount of time it takes to consume CPU resources for running the Spark application. Unit: milliseconds.

*   **LogRootPath**: the storage path of log files.

*   **LastAttemptId**: the ID of the last attempt.

*   **WebUiAddress**: the web UI address.

*   **SubmittedTimeInMillis**: the time when the Spark application was submitted. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **StartedTimeInMillis**: the time when the Spark application was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **LastUpdatedTimeInMillis**: the time when the Spark application was last updated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **TerminatedTimeInMillis**: the time when the Spark application task was terminated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

*   **DBClusterId**: the ID of the cluster on which the Spark application runs.

*   **ResourceGroupName**: the name of the job resource group.

*   **DurationInMillis**: the amount of time it takes to run the Spark application. Unit: milliseconds.'),
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='3'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ListSparkAppAttemptsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSparkAppAttemptsResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function listSparkAppAttempts(request: ListSparkAppAttemptsRequest): ListSparkAppAttemptsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSparkAppAttempts', 'POST', '/', 'json', false, 'json', request);
}

model ListSparkAppsRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  pageNumber: long(name='PageNumber', description='The number of the page to return. The value must be an integer that is greater than 0. Default value: **1**.', example='1', minimum=1, position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries to return on each page. Default value: 10. Valid values:

- **10**
- **50**
- **100**', example='30', minimum=1, maximum=100, position='Query'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the job resource group.', example='test_instance', position='Query'),
}

model ListSparkAppsResponseBody = {
  data?: {
    appInfoList?: [
      SparkAppInfo
    ](name='AppInfoList', description='Details of the applications. Fields in the response parameter:

- **Data**: the data of the Spark application template.
- **EstimateExecutionCpuTimeInSeconds**: the amount of time it takes to consume CPU resources for running the Spark application. Unit: milliseconds.
- **LogRootPath**: the storage path of log files.
- **LastAttemptId**: the most recent attempt ID.
- **WebUiAddress**: the web UI URL.
- **SubmittedTimeInMillis**: the time when the Spark application was submitted. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
- **StartedTimeInMillis**: the time when the Spark application was created. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
- **LastUpdatedTimeInMillis**: the time when the Spark application was last updated. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
- **TerminatedTimeInMillis**: the time when the Spark application task was terminated. The time is displayed in the UNIX timestamp format. Unit: milliseconds.
- **DBClusterId**: the ID of the cluster on which the Spark application runs.
- **ResourceGroupName**: the name of the job resource group.
- **DurationInMillis**: the amount of time it takes to run the Spark application. Unit: milliseconds.'),
    pageNumber?: long(name='PageNumber', description='The page number of the returned page.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries returned per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The data returned.'),
  pageNumber?: long(name='PageNumber', description='The page number of the returned page.', example='1'),
  pageSize?: long(name='PageSize', description='The number of entries returned per page.', example='10'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
  totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='1'),
}

model ListSparkAppsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSparkAppsResponseBody(name='body'),
}

async function listSparkApps(request: ListSparkAppsRequest): ListSparkAppsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSparkApps', 'POST', '/', 'json', false, 'json', request);
}

model ListSparkLogAnalyzeTasksRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.', example='amv-9scxs****', position='Body'),
  pageNumber: long(name='PageNumber', description='The page number.', example='1', minimum=1, position='Body'),
  pageSize?: long(name='PageSize', description='The number of entries per page.', example='20', minimum=1, maximum=100, position='Body'),
}

model ListSparkLogAnalyzeTasksResponseBody = {
  data?: {
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='20'),
    taskList?: [
      SparkAnalyzeLogTask
    ](name='TaskList', description='The queried Spark log analysis tasks.'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1DF5AF5B-C803-1861-A0FF-63666A557709'),
}

model ListSparkLogAnalyzeTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSparkLogAnalyzeTasksResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function listSparkLogAnalyzeTasks(request: ListSparkLogAnalyzeTasksRequest): ListSparkLogAnalyzeTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSparkLogAnalyzeTasks', 'POST', '/', 'json', true, 'form', request);
}

model ListSparkTemplateFileIdsRequest {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Body'),
}

model ListSparkTemplateFileIdsResponseBody = {
  data?: [ long ](name='Data', description='The IDs of Spark template files.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ListSparkTemplateFileIdsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSparkTemplateFileIdsResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function listSparkTemplateFileIds(request: ListSparkTemplateFileIdsRequest): ListSparkTemplateFileIdsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSparkTemplateFileIds', 'POST', '/', 'json', true, 'form', request);
}

model LoadSampleDataSetRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition clusters within a region.', example='amv-2ze0z517o1mgp66a', position='Query'),
}

model LoadSampleDataSetResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-2ze0z517o1mgp66a'),
  requestId?: string(name='RequestId', description='The request ID.', example='FA31BE84-ABE8-554A-A769-5F860C34EE10'),
}

model LoadSampleDataSetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: LoadSampleDataSetResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function loadSampleDataSet(request: LoadSampleDataSetRequest): LoadSampleDataSetResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'LoadSampleDataSet', 'POST', '/', 'json', false, 'json', request);
}

model ModifyAccountDescriptionRequest {
  accountDescription: string(name='AccountDescription', description='The description of the database account.

*   The description cannot start with `http://` or `https://`.
*   The description must be 2 to 256 characters in length.', example='AccDesc', position='Query'),
  accountName: string(name='AccountName', description='The name of the database account.

>  You can call the [DescribeAccounts](~~612430~~) operation to query the information about database accounts of an AnalyticDB for MySQL cluster, including database account names.', example='testacc', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  engine?: string(name='Engine', description='The database engine of the cluster. Valid values:

*   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
*   **Clickhouse**: the wide table engine.', example='Clickhouse', position='Query'),
}

model ModifyAccountDescriptionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ModifyAccountDescriptionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifyAccountDescriptionResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function modifyAccountDescription(request: ModifyAccountDescriptionRequest): ModifyAccountDescriptionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyAccountDescription', 'POST', '/', 'json', false, 'json', request);
}

model ModifyAccountPrivilegesRequest {
  accountName: string(name='AccountName', description='The name of the database account.', example='account1', position='Query'),
  accountPrivileges: [ 
    {
      privilegeObject?: {
        column?: string(name='Column', description='The columns on which you want to grant permissions. This parameter must be specified when the PrivilegeType parameter is set to Column.', example='column1'),
        database?: string(name='Database', description='The databases on which you want to grant permissions. This parameter must be specified when the PrivilegeType parameter is set to Database, Table, or Column.', example='tsdb1'),
        table?: string(name='Table', description='The tables on which you want to grant permissions. This parameter must be specified when the PrivilegeType parameter is set to Table or Column.', example='table1'),
      }(name='PrivilegeObject', description='The objects on which you want to grant permissions, including databases, tables, and columns.'),
      privilegeType?: string(name='PrivilegeType', description='The permission level that you want to assign to the database account. You can call the `DescribeEnabledPrivileges` operation to query the permission level that can be assigned to the database account.', example='Global'),
      privileges?: [ string ](name='Privileges', description='The permissions that you want to grant to the database account.'),
    }
  ](name='AccountPrivileges', description='The permissions that you want to grant to the database account.', shrink='json', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1k5p066e1a****', position='Query'),
  regionId: string(name='RegionId', description='The region ID.', example='cn-hangzhou', position='Query'),
}

model ModifyAccountPrivilegesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='9DD88DE7-824F-1082-AA57-575AFC6517A8'),
}

model ModifyAccountPrivilegesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifyAccountPrivilegesResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function modifyAccountPrivileges(request: ModifyAccountPrivilegesRequest): ModifyAccountPrivilegesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyAccountPrivileges', 'POST', '/', 'json', false, 'json', request);
}

model ModifyAuditLogConfigRequest {
  auditLogStatus: string(name='AuditLogStatus', description='The status to which you want to change the SQL audit feature. Valid values:

*   **on**
*   **off**

>  After you disable the SQL audit feature, all SQL audit logs are deleted. You must query and export SQL audit logs before you disable SQL audit. For more information, see [DescribeAuditLogRecords](~~612426~~). When you re-enable SQL audit, audit logs that are generated from the time when SQL audit was last enabled are available for queries.', example='on', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

> You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-t4nj8619bz2w3****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  regionId: string(name='RegionId', description='The region ID.

> You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model ModifyAuditLogConfigResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='CDC59E56-BD07-56CA-A05F-B7907DE5C862'),
  updateSucceed?: boolean(name='UpdateSucceed', description='Indicates whether the status of SQL audit is updated. Valid values:

*   **true**
*   **false**', example='true'),
}

model ModifyAuditLogConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifyAuditLogConfigResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function modifyAuditLogConfig(request: ModifyAuditLogConfigRequest): ModifyAuditLogConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyAuditLogConfig', 'POST', '/', 'json', false, 'json', request);
}

model ModifyBackupPolicyRequest {
  backupRetentionPeriod?: string(name='BackupRetentionPeriod', description='The number of days for which to retain full backup files. Valid values: 7 to 730.

>  If you do not specify this parameter, the default value 7 is used.', example='7', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='am-bp1xxxxxxxx47', position='Query'),
  enableBackupLog?: string(name='EnableBackupLog', description='Specifies whether to enable log backup. Valid values:

*   **Enable**
*   **Disable**

>  If you do not specify this parameter, the default value Enable is used.', example='Enable', position='Query'),
  logBackupRetentionPeriod?: int32(name='LogBackupRetentionPeriod', description='The number of days for which to retain log backup files. Valid values: 7 to 730.

>  If you do not specify this parameter, the default value 7 is used.', example='7', minimum=7, maximum=730, position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  preferredBackupPeriod: string(name='PreferredBackupPeriod', description='The days of the week on which to perform a full backup. Separate multiple values with commas (,). Valid values:

*   **Monday**
*   **Tuesday**
*   **Wednesday**
*   **Thursday**
*   **Friday**
*   **Saturday**
*   **Sunday**

>  To ensure data security, we recommend that you specify at least two values.', example='Monday,Wednesday,Friday,Sunday', position='Query'),
  preferredBackupTime: string(name='PreferredBackupTime', description='The start time to perform a full backup. Specify the time in the HH:mmZ-HH:mmZ format. The time must be in UTC.

>  The time range must be 1 hour.', example='18:00Z-19:00Z', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
}

model ModifyBackupPolicyResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ModifyBackupPolicyResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifyBackupPolicyResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function modifyBackupPolicy(request: ModifyBackupPolicyRequest): ModifyBackupPolicyResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyBackupPolicy', 'POST', '/', 'json', false, 'json', request);
}

model ModifyClusterAccessWhiteListRequest {
  DBClusterIPArrayAttribute?: string(name='DBClusterIPArrayAttribute', description='The attribute of the IP address whitelist. By default, this parameter is empty.

> Whitelists with the hidden attribute are not displayed in the console. Those whitelists are used to access Data Transmission Service (DTS) and PolarDB.', example='hidden', position='Query'),
  DBClusterIPArrayName?: string(name='DBClusterIPArrayName', description='The name of the IP address whitelist. If you do not specify this parameter, the Default whitelist is modified.

*   The whitelist name must be 2 to 32 characters in length. The name can contain lowercase letters, digits, and underscores (\\_). The name must start with a lowercase letter and end with a lowercase letter or a digit.
*   Each cluster supports up to 50 IP address whitelists.', example='test', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  modifyMode?: string(name='ModifyMode', description='The method used to modify the IP address whitelist. Valid values:

*   **Cover** (default)
*   **Append**
*   **Delete**', example='Cover', position='Query'),
  securityIps: string(name='SecurityIps', description='The IP addresses in an IP address whitelist of a cluster. Separate multiple IP addresses with commas (,). You can add a maximum of 500 different IP addresses to a whitelist. The entries in the IP address whitelist must be in one of the following formats:

*   IP addresses, such as 10.23.XX.XX.
*   CIDR blocks, such as 10.23.xx.xx/24. In this example, 24 indicates that the prefix of each IP address in the IP whitelist is 24 bits in length. You can replace 24 with a value within the range of 1 to 32.', example='10.23.xx.xx', position='Query'),
}

model ModifyClusterAccessWhiteListResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****'),
  requestId?: string(name='RequestId', description='The request ID.', example='370D09FD-442A-5225-AAD3-7362CAE39177'),
  taskId?: int32(name='TaskId', description='The task ID.', example='1564657730'),
}

model ModifyClusterAccessWhiteListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifyClusterAccessWhiteListResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see Endpoints.
  *
 */
async function modifyClusterAccessWhiteList(request: ModifyClusterAccessWhiteListRequest): ModifyClusterAccessWhiteListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyClusterAccessWhiteList', 'POST', '/', 'json', false, 'json', request);
}

model ModifyClusterConnectionStringRequest {
  connectionStringPrefix: string(name='ConnectionStringPrefix', description='The prefix of the public endpoint.

*   The prefix can contain lowercase letters, digits, and hyphens (-). It must start with a lowercase letter.
*   The prefix can be up to 30 characters in length.', example='test-123', position='Query'),
  currentConnectionString: string(name='CurrentConnectionString', description='The public endpoint of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****.ads.aliyuncs.com', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  port?: int32(name='Port', description='The port number. Set the value to **3306**.', example='3306', position='Query'),
}

model ModifyClusterConnectionStringResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='370D09FD-442A-5225-AAD3-7362CAE39177'),
}

model ModifyClusterConnectionStringResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifyClusterConnectionStringResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function modifyClusterConnectionString(request: ModifyClusterConnectionStringRequest): ModifyClusterConnectionStringResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyClusterConnectionString', 'POST', '/', 'json', false, 'json', request);
}

model ModifyDBClusterRequest {
  computeResource?: string(name='ComputeResource', description='The reserved computing resources. Unit: ACUs. Valid values: 0 to 4096. The value must be in increments of 16 ACUs. Each ACU is approximately equal to 1 core and 4 GB memory.

>  This parameter must be specified with a unit.', example='16ACU', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1r053byu48p****', position='Query'),
  enableDefaultResourcePool?: boolean(name='EnableDefaultResourcePool', description='Specifies whether to allocate all reserved computing resources to the user_default resource group. Valid values:

*   true (default)
*   false', example='true', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  reservedNodeCount?: int32(name='ReservedNodeCount', position='Query'),
  reservedNodeSize?: string(name='ReservedNodeSize', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  storageResource?: string(name='StorageResource', description='The reserved storage resources. Unit: ACUs. Valid values: 0 to 2064. The value must be in increments of 24 ACUs. Each ACU is approximately equal to 1 core and 4 GB memory.

>  This parameter must be specified with a unit.', example='24ACU', position='Query'),
}

model ModifyDBClusterResponseBody = {
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****'),
  orderId?: string(name='OrderId', description='The order ID.', example='2035629****'),
  requestId?: string(name='RequestId', description='The request ID.', example='0D6BF3E2-41D8-57F6-9A62-A13A70377952'),
}

model ModifyDBClusterResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifyDBClusterResponseBody(name='body'),
}

/**
  * ### [](#)
  * *   During a scaling event, you are not allowed to execute the `SUBMIT JOB` statement to submit asynchronous jobs. If your business requires asynchronous jobs, perform scaling during appropriate periods.
  * *   When you scale a cluster, data in the cluster is migrated for redistribution. The amount of time that is required to migrate data is proportional to the data volume. During a scaling event, the services provided by the cluster are not interrupted. When you downgrade cluster specifications, data migration may require up to dozens of hours to complete. Proceed with caution especially if your cluster contains a large amount of data.
  * *   If the cluster has a built-in dataset loaded, make sure that the cluster has reserved storage resources of at least 24 AnalyticDB compute units (ACUs). Otherwise, the built-in dataset cannot be used.
  * *   When the scaling process is about to end, transient connections may occur. We recommend that you scale your cluster during off-peak hours or make sure that your application is configured to automatically reconnect to your cluster.
  * *   You can change an AnalyticDB for MySQL cluster from Data Warehouse Edition to Data Lakehouse Edition, but not the other way around. For more information, see Change a cluster from Data Warehouse Edition to Data Lakehouse Edition.
  * *   For information about the endpoints of the current service, see [Endpoints](~~612373~~).
  *
 */
async function modifyDBCluster(request: ModifyDBClusterRequest): ModifyDBClusterResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyDBCluster', 'POST', '/', 'json', false, 'json', request);
}

model ModifyDBClusterDescriptionRequest {
  DBClusterDescription: string(name='DBClusterDescription', description='The description of the cluster.

*   The description cannot start with `http://` or `https`.
*   The description must be 2 to 256 characters in length.', example='adb_test', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****', position='Query'),
}

model ModifyDBClusterDescriptionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='17F57FEE-EA4F-4337-8D2E-9C23CAA63D74'),
}

model ModifyDBClusterDescriptionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifyDBClusterDescriptionResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function modifyDBClusterDescription(request: ModifyDBClusterDescriptionRequest): ModifyDBClusterDescriptionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyDBClusterDescription', 'POST', '/', 'json', false, 'json', request);
}

model ModifyDBClusterMaintainTimeRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-bp1r053byu48p****', position='Query'),
  maintainTime: string(name='MaintainTime', description='The maintenance window of the cluster. It must be in the hh:mmZ-hh:mmZ format.

> The interval must be 1 hour and start and end at the beginning of an hour.', example='22:00Z-23:00Z', position='Query'),
}

model ModifyDBClusterMaintainTimeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='65BDA532-28AF-4122-AA39-B382721EEE64'),
}

model ModifyDBClusterMaintainTimeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifyDBClusterMaintainTimeResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function modifyDBClusterMaintainTime(request: ModifyDBClusterMaintainTimeRequest): ModifyDBClusterMaintainTimeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyDBClusterMaintainTime', 'POST', '/', 'json', false, 'json', request);
}

model ModifyDBResourceGroupRequest {
  clusterMode?: string(name='ClusterMode', description='A reserved parameter.', example='N/A', position='Query'),
  clusterSizeResource?: string(name='ClusterSizeResource', description='A reserved parameter.', example='N/A', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp1r053byu48p****', position='Query'),
  enableSpot?: boolean(name='EnableSpot', description='Specifies whether to enable the spot instance feature for the resource group. After you enable the spot instance feature, you are charged for resources at a lower unit price but the resources are probably released. You can enable the spot instance feature only for job resource groups. Valid values:

*   **True**
*   **False**', example='true', position='Query'),
  groupName: string(name='GroupName', description='The name of the resource group.

> You can call the [DescribeDBResourceGroup](~~459446~~) operation to query the name of a resource group in a cluster.', example='test', position='Query'),
  groupType: string(name='GroupType', description='The type of the resource group. Valid values:

*   **Interactive**
*   **Job**

> For information about resource groups of Data Lakehouse Edition, see [Resource groups](~~428610~~).', example='Interactive', position='Query'),
  maxClusterCount?: int32(name='MaxClusterCount', description='A reserved parameter.', example='N/A', position='Query'),
  maxComputeResource?: string(name='MaxComputeResource', description='The maximum amount of reserved computing resources. Unit: ACU.

*   If GroupType is set to Interactive, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 16 ACUs.
*   If GroupType is set to Job, the maximum amount of reserved computing resources refers to the amount of resources that are not allocated in the cluster. Set this parameter to a value in increments of 8 ACUs.', example='48ACU', position='Query'),
  minClusterCount?: int32(name='MinClusterCount', description='A reserved parameter.', example='N/A', position='Query'),
  minComputeResource?: string(name='MinComputeResource', description='The minimum amount of reserved computing resources. Unit: AnalyticDB compute units (ACUs).

*   If the GroupType parameter is set to Interactive, set the value to 16ACU.
*   If GroupType is set to Job, set the value to 0ACU.', example='0ACU', position='Query'),
  regionId?: string(name='RegionId', description='The region ID of the cluster.

>  You can call the [DescribeRegions](~~454314~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  rules?: [ 
    {
      groupName?: string(name='GroupName', description='The name of the resource group.', example='user_default'),
      queryTime?: string(name='QueryTime', description='The execution duration of the query. Unit: milliseconds.', example='180000'),
      targetGroupName?: string(name='TargetGroupName', description='The name of the destination resource group.', example='job'),
    }
  ](name='Rules', description='The job resubmission rules.', shrink='json', position='Query'),
}

model ModifyDBResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='805F14E1-0186-520E-A6D5-30188D94E8DA'),
}

model ModifyDBResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifyDBResourceGroupResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function modifyDBResourceGroup(request: ModifyDBResourceGroupRequest): ModifyDBResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyDBResourceGroup', 'POST', '/', 'json', false, 'json', request);
}

model ModifyElasticPlanRequest {
  cronExpression?: string(name='CronExpression', description='A CORN expression that specifies the scaling cycle and time for the scaling plan.', example='0 20 14 * * ?', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The cluster ID.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-wz9509beptiz****', position='Query'),
  elasticPlanName: string(name='ElasticPlanName', description='The name of the scaling plan.

>  You can call the [DescribeElasticPlans](~~601334~~) operation to query the names of scaling plans.', example='test', position='Query'),
  endTime?: string(name='EndTime', description='The end time of the scaling plan.

>  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2025-01-01T12:01:00Z', position='Query'),
  startTime?: string(name='StartTime', description='The start time of the scaling plan.

>  Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2022-01-01T12:01:00Z', position='Query'),
  targetSize?: string(name='TargetSize', description='The desired specifications of elastic resources after scaling.

> 

*   If the scaling plan uses **EIUs** and **Default Proportional Scaling for EIUs** is enabled, you do not need to specify this parameter. In other cases, you must specify this parameter.

*   You can call the [DescribeElasticPlanSpecifications](~~601278~~) operation to query the specifications that are supported for scaling plans.', example='32ACU', position='Query'),
}

model ModifyElasticPlanResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A5C433C2-001F-58E3-99F5-3274C14DF8BD'),
}

model ModifyElasticPlanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifyElasticPlanResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see Endpoints.
  *
 */
async function modifyElasticPlan(request: ModifyElasticPlanRequest): ModifyElasticPlanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyElasticPlan', 'POST', '/', 'json', false, 'json', request);
}

model ModifyPerformanceViewRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.

>  You can call the [DescribeDBClusters](~~612397~~) operation to query the IDs of all AnalyticDB for MySQL Data Lakehouse Edition (V3.0) clusters within a region.', example='amv-bp1ub9grke1****', position='Query'),
  ownerAccount?: string(name='OwnerAccount', position='Query'),
  ownerId?: long(name='OwnerId', position='Query'),
  regionId: string(name='RegionId', description='The region ID.

>  You can call the [DescribeRegions](~~143074~~) operation to query the most recent region list.', example='cn-hangzhou', position='Query'),
  resourceOwnerAccount?: string(name='ResourceOwnerAccount', position='Query'),
  resourceOwnerId?: long(name='ResourceOwnerId', position='Query'),
  viewDetail: {
    categories?: [ 
      {
        category?: string(name='Category', description='The name of the metric category. Valid values:

*   **Node**
*   **DiskData**
*   **WorkLoad**
*   **ResourceGroup**', example='Node'),
        keys?: [ 
          {
            keyName?: string(name='KeyName', description='The name of the metric.', example='AnalyticDB_CPU'),
            selected?: boolean(name='Selected', description='Specifies whether to select the metric. Valid values:

*   true
*   false', example='true'),
          }
        ](name='Keys', description='The metrics.'),
      }
    ](name='Categories', description='The metric categories.'),
    chartLinked?: boolean(name='ChartLinked', description='Specifies whether to enable the filter interaction feature. Valid values:

*   true
*   false', example='true'),
    chartsPerLine?: int32(name='ChartsPerLine', description='The number of charts to display in each row.', example='3'),
  }(name='ViewDetail', description='The new information about the monitoring view.', shrink='json', position='Query'),
  viewName: string(name='ViewName', description='The name of the monitoring view.', position='Query'),
}

model ModifyPerformanceViewResponseBody = {
  accessDeniedDetail?: string(name='AccessDeniedDetail', description='The details about the access denial. This parameter is returned only if Resource Access Management (RAM) permission verification failed.', example='{
    "PolicyType": "AccountLevelIdentityBasedPolicy",
    "AuthPrincipalOwnerId": "1*****************7",
    "EncodedDiagnosticMessage": "AQIBIAAAAOPdwKY2QLOvgMEc7SkkoJfj1kvZwsaRqNYMh10Tv0wTe0fCzaCdrvgazfNb0EnJKETgXyhR+3BIQjx9WAqZryejBsp1Bl4qI5En/D9dEhcXAtKCxCmE2kZCiEzpy8BoEUt+bs0DmlaGWO5xkEpttypLIB4rUhDvZd+zwPg4EXk4KSSWSWsurxtqDkKEMshKlQFBTKvJcKwyhk62IeYly4hQ+5IpXjkh1GQXuDRCQ==",
    "AuthPrincipalType": "SubUser",
    "AuthPrincipalDisplayName": "2***************9",
    "NoPermissionType": "ImplicitDeny",
    "AuthAction": "adb:DescribeExcessivePrimaryKeys"
}'),
  modifyStatus?: string(name='ModifyStatus', description='The modification result. Valid values:

*   **SUCCESS**
*   **FAILED**', example='SUCCESS'),
  requestId?: string(name='RequestId', description='The request ID.', example='C7EDB8E4-9769-4233-88C7-DCA4C9******'),
}

model ModifyPerformanceViewResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifyPerformanceViewResponseBody(name='body'),
}

async function modifyPerformanceView(request: ModifyPerformanceViewRequest): ModifyPerformanceViewResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyPerformanceView', 'POST', '/', 'json', false, 'json', request);
}

model PreloadSparkAppMetricsRequest {
  appId: string(name='AppId', description='The Spark application ID.', example='s202204221525hzca7d8140000003', maxLength=64, position='Body'),
  DBClusterId?: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~129857~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.', example='amv-bp1mfe9qmsw1dzyg', position='Query'),
}

model PreloadSparkAppMetricsResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark application.', example='s202212181815shaccb8be0000253'),
    attemptId?: string(name='AttemptId', description='The retry ID of the Spark application.', example='s202301061000hz57d797b0000201-0001'),
    eventLogPath?: string(name='EventLogPath', description='The event log path.', example='oss://path/to/eventLog'),
    finished?: boolean(name='Finished', description='Indicates whether parsing is complete. Valid values:

*   true
*   false', example='True'),
    scanMetrics?: {
      outputRowsCount?: long(name='OutputRowsCount', description='The number of rows scanned.', example='1000'),
      totalReadFileSizeInByte?: long(name='TotalReadFileSizeInByte', description='The size of the scanned data. Unit: bytes.', example='10000'),
    }(name='ScanMetrics', description='The metrics.'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='84489769-3065-5A28-A4CB-977CD426F1C3'),
}

model PreloadSparkAppMetricsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: PreloadSparkAppMetricsResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function preloadSparkAppMetrics(request: PreloadSparkAppMetricsRequest): PreloadSparkAppMetricsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'PreloadSparkAppMetrics', 'POST', '/', 'json', true, 'form', request);
}

model ReleaseClusterPublicConnectionRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  engine?: string(name='Engine', description='The database engine of the cluster. Valid values:

*   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
*   **Clickhouse**: the wide table engine.', example='Clickhouse', position='Query'),
}

model ReleaseClusterPublicConnectionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A94B6C02-7BD4-5D67-9776-3AC8317E8DD5'),
}

model ReleaseClusterPublicConnectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ReleaseClusterPublicConnectionResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function releaseClusterPublicConnection(request: ReleaseClusterPublicConnectionRequest): ReleaseClusterPublicConnectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ReleaseClusterPublicConnection', 'POST', '/', 'json', false, 'json', request);
}

model RenameSparkTemplateFileRequest {
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-d*****', position='Query'),
  id: long(name='Id', description='The template file ID.', example='1', minimum=0, position='Query'),
  name: string(name='Name', description='The name of the template file that you want to rename.', example='new_template_name', position='Query'),
}

model RenameSparkTemplateFileResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the request was successful. Valid values:

*   True
*   False', example='True'),
  }(name='Data', description='The data returned.'),
  requestId?: string(name='RequestId', description='The request ID.', example='16D332C4-ACEB-526A-9B53-2B708FED594A'),
}

model RenameSparkTemplateFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RenameSparkTemplateFileResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function renameSparkTemplateFile(request: RenameSparkTemplateFileRequest): RenameSparkTemplateFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameSparkTemplateFile', 'POST', '/', 'json', false, 'json', request);
}

model ResetAccountPasswordRequest {
  accountDescription?: string(name='AccountDescription', description='The description of the database account.

*   The description cannot start with `http://` or `https://`.
*   The description must be 2 to 256 characters in length.', example='AccDesc', position='Query'),
  accountName: string(name='AccountName', description='The name of the database account.

>  You can call the [DescribeAccounts](~~612430~~) operation to query the information about database accounts of an AnalyticDB for MySQL cluster, including database account names.', example='test_accout', position='Query'),
  accountPassword: string(name='AccountPassword', description='The password of the database account.

*   The password must contain at least three of the following character types: uppercase letters, lowercase letters, digits, and special characters.
*   Special characters include `! @ # $ % ^ & * ( ) _ + - =`
*   The password must be 8 to 32 characters in length.', example='Test_accout1', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-bp11q28kvl688****', position='Query'),
  engine?: string(name='Engine', description='The database engine of the cluster. Valid values:

*   **AnalyticDB** (default): the AnalyticDB for MySQL engine.
*   **Clickhouse**: the wide table engine.', example='Clickhouse', position='Query'),
}

model ResetAccountPasswordResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model ResetAccountPasswordResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ResetAccountPasswordResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function resetAccountPassword(request: ResetAccountPasswordRequest): ResetAccountPasswordResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ResetAccountPassword', 'POST', '/', 'json', false, 'json', request);
}

model SetSparkAppLogRootPathRequest {
  DBClusterId: string(name='DBClusterId', description='The database ID.', example='am-dbclusterid', maxLength=64, position='Body'),
  ossLogPath?: string(name='OssLogPath', description='The Object Storage Service (OSS) log path.', example='oss://path/to/log', position='Body'),
  useDefaultOss?: boolean(name='UseDefaultOss', description='Specifies whether to use the default OSS log path.', example='true', position='Body'),
}

model SetSparkAppLogRootPathResponseBody = {
  data?: {
    defaultLogPath?: string(name='DefaultLogPath', description='The recommended default OSS log path.', example='oss://path/to/log'),
    isLogPathExists?: boolean(name='IsLogPathExists', description='Indicates whether an OSS log path exists.', example='true'),
    modifiedTimestamp?: string(name='ModifiedTimestamp', description='The time when the modification was last modified.', example='1675236908'),
    modifiedUid?: string(name='ModifiedUid', description='The modifier ID.', example='1111111'),
    recordedLogPath?: string(name='RecordedLogPath', description='The OSS log path.', example='oss://path/to/log'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model SetSparkAppLogRootPathResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetSparkAppLogRootPathResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function setSparkAppLogRootPath(request: SetSparkAppLogRootPathRequest): SetSparkAppLogRootPathResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetSparkAppLogRootPath', 'POST', '/', 'json', true, 'form', request);
}

model StartSparkSQLEngineRequest {
  config?: string(name='Config', description='The configuration that is required to start the Spark SQL engine. Specify this value in the JSON format. For more information, see [Conf configuration parameters](~~471203~~).', example='{ "spark.shuffle.timeout": ":0s" }', position='Body'),
  DBClusterId: string(name='DBClusterId', description='The cluster ID.', example='amv-abcd****', position='Body'),
  jars?: string(name='Jars', description='The Object Storage Service (OSS) paths of third-party JAR packages that are required to start the Spark SQL engine. Separate multiple OSS paths with commas (,).', example='oss://testBuckname/test.jar,oss://testBuckname/test2.jar', position='Body'),
  maxExecutor?: long(name='MaxExecutor', description='The maximum number of executors that are required to execute SQL statements. Valid values: 1 to 2000. If this value exceeds the total number of executes that are supported by the resource group, the Spark SQL engine fails to be started.', example='10', position='Body'),
  minExecutor?: long(name='MinExecutor', description='The minimum number of executors that are required to execute SQL statements. Valid values: 0 to 2000. A value of 0 indicates that no executors are permanent if no SQL statements are executed. If this value exceeds the total number of executors that are supported by the resource group, the Spark SQL engine fails to be started. The value must be less than the value of MaxExecutor.', example='1', position='Body'),
  resourceGroupName: string(name='ResourceGroupName', description='The name of the resource group.', example='spark-rg-name', position='Body'),
  slotNum?: long(name='SlotNum', description='The maximum number of slots that are required to maintain Spark sessions for executing SQL statements. Valid values: 1 to 500.', example='100', position='Body'),
}

model StartSparkSQLEngineResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The ID of the Spark job.', example='s202301xxxx'),
    appName?: string(name='AppName', description='The name of the Spark application.', example='SQLEngine1'),
    state?: string(name='State', description='The state of the Spark SQL engine. Valid values:

*   SUBMITTED
*   STARTING
*   RUNNING
*   FAILED', example='SUBMITTED'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D65A809F-34CE-4550-9BC1-0ED21ETG380'),
}

model StartSparkSQLEngineResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartSparkSQLEngineResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function startSparkSQLEngine(request: StartSparkSQLEngineRequest): StartSparkSQLEngineResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartSparkSQLEngine', 'POST', '/', 'json', true, 'form', request);
}

model SubmitSparkAppRequest {
  agentSource?: string(name='AgentSource', description='The type of the client. The value can be up to 64 characters in length.', example='CONSOLE', position='Body'),
  agentVersion?: string(name='AgentVersion', description='The version of the client. The value can be up to 64 characters in length.', example='1.091', position='Body'),
  appName?: string(name='AppName', description='The name of the application. The value can be up to 64 characters in length.', example='TestApp', position='Body'),
  appType?: string(name='AppType', description='The type of the application. Valid values:

*   **SQL**
*   **STREAMING**
*   **BATCH** (default)', example='SQL', position='Body'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.

>  You can call the [DescribeDBClusters](~~454250~~) operation to query the IDs of all AnalyticDB for MySQL clusters within a region.', example='amv-bp11q28kvl688****', maxLength=64, position='Body'),
  data: string(name='Data', description='The data of the application template.

> For information about the application template configuration, see [Spark application configuration guide](~~452402~~).', example='conf spark.driver.resourceSpec=small; conf spark.executor.instances=1; conf spark.executor.resourceSpec=small; conf spark.app.name=TestApp;', position='Body'),
  resourceGroupName: string(name='ResourceGroupName', description='The name of the job resource group.

>  You can call the [DescribeDBResourceGroup](~~612410~~) operation to query the name of a resource group within a cluster.', example='adb', maxLength=64, position='Body'),
  templateFileId?: long(name='TemplateFileId', description='The ID of the application template.

> You can call the [GetSparkTemplateFullTree](~~456205~~) operation to query the application template ID.', example='15', minimum=0, position='Body'),
}

model SubmitSparkAppResponseBody = {
  data?: {
    appId?: string(name='AppId', description='The application ID.', example='s202204132018hzprec1ac61a000****'),
    appName?: string(name='AppName', description='The name of the application.', example='TestApp'),
    message?: string(name='Message', description='The alert message returned for the operation, such as task execution failure or insufficient resources. If no alert occurs, null is returned.', example='Insufficient resources.'),
    state?: string(name='State', description='The execution state of the application. Valid values:

*   **SUBMITTED**
*   **STARTING**
*   **RUNNING**
*   **FAILING**
*   **FAILED**
*   **KILLING**
*   **KILLED**
*   **SUCCEEDING**
*   **COMPLETED**
*   **FATAL**
*   **UNKNOWN**', example='SUBMITTED'),
  }(name='Data', description='The returned data.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model SubmitSparkAppResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSparkAppResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function submitSparkApp(request: SubmitSparkAppRequest): SubmitSparkAppResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSparkApp', 'POST', '/', 'json', true, 'form', request);
}

model SubmitSparkLogAnalyzeTaskRequest {
  appId: string(name='AppId', description='The ID of the Spark application.', example='s202301121553hzd9c6f7xxxx', position='Body'),
}

model SubmitSparkLogAnalyzeTaskResponseBody = {
  data?: SparkAnalyzeLogTask(name='Data', description='The information about the Spark log analysis task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1DF5AF5B-C803-1861-A0FF-63666A557709'),
}

model SubmitSparkLogAnalyzeTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitSparkLogAnalyzeTaskResponseBody(name='body'),
}

/**
  * *   General endpoint: `adb.aliyuncs.com`.
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  *
 */
async function submitSparkLogAnalyzeTask(request: SubmitSparkLogAnalyzeTaskRequest): SubmitSparkLogAnalyzeTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitSparkLogAnalyzeTask', 'POST', '/', 'json', true, 'form', request);
}

model UnbindAccountRequest {
  accountName: string(name='AccountName', description='The name of the database account.

>  You can call the [DescribeAccounts](~~612430~~) operation to query the information about database accounts of an AnalyticDB for MySQL cluster, including database account names.', example='test_accout', position='Query'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition (V3.0) cluster.', example='amv-wz99d9nh5****', position='Query'),
}

model UnbindAccountResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='93E85E5C-C805-5837-8713-05B69A504EE5'),
}

model UnbindAccountResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UnbindAccountResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function unbindAccount(request: UnbindAccountRequest): UnbindAccountResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UnbindAccount', 'POST', '/', 'json', false, 'json', request);
}

model UnbindDBResourceGroupWithUserRequest {
  DBClusterId: string(name='DBClusterId', description='The cluster ID.', example='am-bp1ub9grke1****', position='Query'),
  groupName?: string(name='GroupName', description='The name of the resource group.', example='test', position='Query'),
  groupUser?: string(name='GroupUser', description='The name of the database account.', example='user1', position='Query'),
}

model UnbindDBResourceGroupWithUserResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1AD222E9-E606-4A42-BF6D-8A4442913CEF'),
}

model UnbindDBResourceGroupWithUserResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UnbindDBResourceGroupWithUserResponseBody(name='body'),
}

/**
  * For information about the endpoints of AnalyticDB for MySQL, see [Endpoints](~~612373~~).
  *
 */
async function unbindDBResourceGroupWithUser(request: UnbindDBResourceGroupWithUserRequest): UnbindDBResourceGroupWithUserResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UnbindDBResourceGroupWithUser', 'POST', '/', 'json', false, 'json', request);
}

model UpdateSparkTemplateFileRequest {
  content?: string(name='Content', description='The template data to be updated.

>  If you do not specify this parameter, the application template is not updated. For information about how to configure a Spark application template, see [Configure a Spark application](~~452402~~).', example='set spark.driver.resourceSpec=medium;set spark.executor.instances=2;set spark.executor.resourceSpec=medium;set spark.app.name=Spark SQL Test;', position='Body'),
  DBClusterId: string(name='DBClusterId', description='The ID of the AnalyticDB for MySQL Data Lakehouse Edition cluster.', example='amv-pz5vp4585l466****', maxLength=64, position='Body'),
  id: long(name='Id', description='The application template ID.

>  You can call the [GetSparkTemplateFullTree](~~456205~~) operation to query the application template ID.', example='718056', minimum=0, position='Body'),
  resourceGroupName?: string(name='ResourceGroupName', description='The name of the job resource group.', example='adb', position='Body'),
}

model UpdateSparkTemplateFileResponseBody = {
  data?: {
    succeeded?: boolean(name='Succeeded', description='Indicates whether the application template is updated.

*   **True**
*   **False**', example='True'),
  }(name='Data', description='The update result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='C3A9594F-1D40-4472-A96C-8FB8AA20D38C'),
}

model UpdateSparkTemplateFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateSparkTemplateFileResponseBody(name='body'),
}

/**
  * *   Regional public endpoint: `adb.<region-id>.aliyuncs.com`. Example: `adb.cn-hangzhou.aliyuncs.com`.
  * *   Regional Virtual Private Cloud (VPC) endpoint: `adb-vpc.<region-id>.aliyuncs.com`. Example: `adb-vpc.cn-hangzhou.aliyuncs.com`.
  * >  If HTTP status code 409 is returned when you call this operation in the China (Qingdao), China (Shenzhen), China (Guangzhou), or China (Hong Kong) region, contact technical support.
  *
 */
async function updateSparkTemplateFile(request: UpdateSparkTemplateFileRequest): UpdateSparkTemplateFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateSparkTemplateFile', 'POST', '/', 'json', true, 'form', request);
}

