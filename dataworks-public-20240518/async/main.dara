/**
  *
  */
import BaseClientBuilder;
import TeaAsyncHandler;
import TeaRequest;
import AsyncRequestBody;
import RequestBody;
import AsyncResponseHandler;
import ClientConfiguration;
import ClientExecutionParams;
extends BaseClientBuilder;
type @product = string
type @version = string
type @endpointRule = string
type @endpointMap = map[string]string
type @REQUEST = TeaRequest
type @handler = TeaAsyncHandler

init(configuration: ClientConfiguration){
  @handler = new TeaAsyncHandler(configuration);
  @product = 'dataworks-public';
  @version = '2024-05-18';
  @endpointRule = 'regional';
  @endpointMap = {
    'ap-northeast-1' = 'dataworks.ap-northeast-1.aliyuncs.com',
    'ap-south-1' = 'dataworks.ap-south-1.aliyuncs.com',
    'ap-southeast-1' = 'dataworks.ap-southeast-1.aliyuncs.com',
    'ap-southeast-2' = 'dataworks.ap-southeast-2.aliyuncs.com',
    'ap-southeast-3' = 'dataworks.ap-southeast-3.aliyuncs.com',
    'ap-southeast-5' = 'dataworks.ap-southeast-5.aliyuncs.com',
    'cn-beijing' = 'dataworks.cn-beijing.aliyuncs.com',
    'cn-chengdu' = 'dataworks.cn-chengdu.aliyuncs.com',
    'cn-hangzhou' = 'dataworks.cn-hangzhou.aliyuncs.com',
    'cn-hongkong' = 'dataworks.cn-hongkong.aliyuncs.com',
    'cn-huhehaote' = 'dataworks.aliyuncs.com',
    'cn-qingdao' = 'dataworks.aliyuncs.com',
    'cn-shanghai' = 'dataworks.cn-shanghai.aliyuncs.com',
    'cn-shenzhen' = 'dataworks.cn-shenzhen.aliyuncs.com',
    'cn-zhangjiakou' = 'dataworks.aliyuncs.com',
    'eu-central-1' = 'dataworks.eu-central-1.aliyuncs.com',
    'eu-west-1' = 'dataworks.eu-west-1.aliyuncs.com',
    'me-east-1' = 'dataworks.me-east-1.aliyuncs.com',
    'us-east-1' = 'dataworks.us-east-1.aliyuncs.com',
    'us-west-1' = 'dataworks.us-west-1.aliyuncs.com',
    'cn-hangzhou-finance' = 'dataworks.aliyuncs.com',
    'cn-shenzhen-finance-1' = 'dataworks.aliyuncs.com',
    'cn-shanghai-finance-1' = 'dataworks.aliyuncs.com',
    'cn-north-2-gov-1' = 'dataworks.aliyuncs.com',
  };
}

function close(): void {
  @handler.close();
}

model Catalog {
  comment?: string(name='Comment'),
  createTime?: long(name='CreateTime'),
  id?: string(name='Id'),
  modifyTime?: long(name='ModifyTime'),
  name?: string(name='Name'),
  parentMetaEntityId?: string(name='ParentMetaEntityId'),
  type?: string(name='Type'),
}

model Column {
  businessMetadata?: {
    description?: string(name='Description', example='字段1的业务描述'),
  }(name='BusinessMetadata'),
  comment?: string(name='Comment', example='字段1'),
  foreignKey?: boolean(name='ForeignKey', example='false'),
  id?: string(name='Id', example='maxcompute-column:123456::test_project:default:test_tbl:col1'),
  name?: string(name='Name', example='col1'),
  partitionKey?: boolean(name='PartitionKey', example='false'),
  position?: int32(name='Position', example='1'),
  primaryKey?: boolean(name='PrimaryKey', example='false'),
  tableId?: string(name='TableId', example='maxcompute-table:123456::test_project:default:test_tbl'),
  type?: string(name='Type', example='bigint'),
}

model CrawlerType {
  displayName?: string(name='DisplayName', example='Data Lake Formation'),
  supportedEntityTypes?: [ 
    {
      optional?: boolean(name='Optional', example='如对于maxcompute-schema类型，schema层级是否存在可选（是否开启三层模型）'),
      parentSubType?: string(name='ParentSubType', example='database'),
      subType?: string(name='SubType', example='table'),
      type?: string(name='Type', example='dlf-table'),
    }
  ](name='SupportedEntityTypes'),
  type?: string(name='Type', example='dlf'),
}

model DataQualityEvaluationTask {
  dataSourceId?: long(name='DataSourceId', example='201'),
  description?: string(name='Description', example='This is a daily run data quality evaluation plan.'),
  hooks?: [ 
    {
      condition?: string(name='Condition', example='${severity} == "High" AND ${status} == "Critical"'),
      type?: string(name='Type', example='BlockTaskInstance'),
    }
  ](name='Hooks'),
  id?: long(name='Id', example='10001'),
  name?: string(name='Name', example='质量校验任务'),
  notifications?: [ 
    {
      condition?: string(name='Condition', example='${blockType} == "Strong"'),
      notifications?: [ 
        {
          notificationChannels?: [ 
            {
              channels?: [ string ](name='Channels'),
            }
          ](name='NotificationChannels'),
          notificationReceivers?: [ 
            {
              extension?: string(name='Extension', example='{"atAll":"true"}'),
              receiverType?: string(name='ReceiverType', example='AliUid'),
              receiverValues?: [ string ](name='ReceiverValues'),
            }
          ](name='NotificationReceivers'),
        }
      ](name='Notifications'),
    }
  ](name='Notifications'),
  projectId?: long(name='ProjectId', example='100'),
  runtimeConf?: string(name='RuntimeConf', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }'),
  target?: {
    databaseType?: string(name='DatabaseType', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', example='ds=$[yyyymmdd-1]'),
    tableGuid?: string(name='TableGuid', example='odps.unit_test.tb_unit_test'),
    type?: string(name='Type', example='Table'),
  }(name='Target'),
  tenantId?: long(name='TenantId', example='10'),
  trigger?: {
    taskIds?: [ long ](name='TaskIds'),
    type?: string(name='Type', example='ByScheduledTaskInstance'),
  }(name='Trigger'),
}

model DataQualityEvaluationTaskInstance {
  createTime?: long(name='CreateTime', example='1710239005403'),
  finishTime?: long(name='FinishTime', example='1710239005403'),
  id?: long(name='Id', example='10001'),
  status?: string(name='Status', example='Passed'),
  task?: {
    dataSourceId?: long(name='DataSourceId', example='201'),
    hooks?: [ 
      {
        condition?: string(name='Condition', example='${severity} == "High" AND ${status} == "Critical"'),
        type?: string(name='Type', example='BlockTaskInstance'),
      }
    ](name='Hooks'),
    id?: long(name='Id', example='10001'),
    name?: string(name='Name', example='质量校验任务'),
    notifications?: [ 
      {
        condition?: string(name='Condition', example='${blockType} == "Strong"'),
        notifications?: [ 
          {
            notificationChannels?: [ 
              {
                channels?: [ string ](name='Channels'),
              }
            ](name='NotificationChannels'),
            notificationReceivers?: [ 
              {
                extension?: string(name='Extension', example='{"atAll":"true"}'),
                receiverType?: string(name='ReceiverType', example='AliUid'),
                receiverValues?: [ string ](name='ReceiverValues'),
              }
            ](name='NotificationReceivers'),
          }
        ](name='Notifications'),
      }
    ](name='Notifications'),
    projectId?: long(name='ProjectId'),
    runtimeConf?: string(name='RuntimeConf', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }'),
    target?: {
      databaseType?: string(name='DatabaseType', example='maxcompute'),
      partitionSpec?: string(name='PartitionSpec', example='ds=$[yyyymmdd-1]'),
      tableGuid?: string(name='TableGuid', example='odps.unit_test.tb_unit_test'),
      type?: string(name='Type', example='Table'),
    }(name='Target'),
    tenantId?: long(name='TenantId'),
    trigger?: {
      taskIds?: [ long ](name='TaskIds'),
      type?: string(name='Type', example='ByScheduledTaskInstance'),
    }(name='Trigger'),
  }(name='Task'),
}

model DataQualityResult {
  details?: [ 
    {
      checkedValue?: string(name='CheckedValue', example='100.0'),
      referencedValue?: string(name='ReferencedValue', example='0.0'),
      status?: string(name='Status', example='Passed'),
    }
  ](name='Details'),
  id?: long(name='Id', example='10001'),
  rule?: {
    checkingConfig?: {
      referencedSamplesFilter?: string(name='ReferencedSamplesFilter', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
      thresholds?: {
        critical?: {
          operator?: string(name='Operator', example='>'),
          value?: string(name='Value', example='100.0'),
        }(name='Critical'),
        expected?: {
          operator?: string(name='Operator', example='>'),
          value?: string(name='Value', example='100.0'),
        }(name='Expected'),
        warned?: {
          operator?: string(name='Operator', example='>'),
          value?: string(name='Value', example='100.0'),
        }(name='Warned'),
      }(name='Thresholds'),
      type?: string(name='Type', example='Fixed'),
    }(name='CheckingConfig'),
    description?: string(name='Description', example='this is a odps _sql task'),
    enabled?: boolean(name='Enabled', example='true'),
    errorHandlers?: [ 
      {
        errorDataFilter?: string(name='ErrorDataFilter', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
        type?: string(name='Type', example='SaveErrorData'),
      }
    ](name='ErrorHandlers'),
    id?: long(name='Id', example='100001'),
    name?: string(name='Name', example='表不能为空'),
    projectId?: long(name='ProjectId', example='100'),
    samplingConfig?: {
      metric?: string(name='Metric', example='Min'),
      metricParameters?: string(name='MetricParameters', example='{ "Columns": [ "id", "name" ] }'),
      samplingFilter?: string(name='SamplingFilter', example='id IS NULL'),
      settingConfig?: string(name='SettingConfig', example='SET odps.sql.udf.timeout=600s;'),
    }(name='SamplingConfig'),
    severity?: string(name='Severity', example='High'),
    target?: {
      databaseType?: string(name='DatabaseType', example='maxcompute'),
      partitionSpec?: string(name='PartitionSpec', example='ds=$[yyyymmdd-1]'),
      tableGuid?: string(name='TableGuid', example='odps.unit_test.tb_unit_test'),
      type?: string(name='Type', example='Table'),
    }(name='Target'),
    templateCode?: string(name='TemplateCode', example='SYSTEM:user_defined_sql'),
    tenantId?: long(name='TenantId', example='1'),
  }(name='Rule'),
  sample?: string(name='Sample', example='[   {     "gender": "male",     "_count": 100   }, {     "gender": "female",     "_count": 100   } ]'),
  status?: string(name='Status', example='Passed'),
  taskInstanceId?: long(name='TaskInstanceId', example='20001'),
}

model DataQualityRule {
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    thresholds?: {
      critical?: {
        expression?: string(name='Expression', example='波动率类型规则使用，通过表达式来表示波动阈值。如：波动上升大于0.01： $checkValue > 0.01  波动下降大于0.01：$checkValue < -0.01   波动率绝对值：abs($checkValue) > 0.01'),
        operator?: string(name='Operator', example='>'),
        value?: string(name='Value', example='100.0'),
      }(name='Critical'),
      expected?: {
        expression?: string(name='Expression', example='波动率类型规则使用，通过表达式来表示波动阈值。如：波动上升大于0.01： $checkValue > 0.01  波动下降大于0.01：$checkValue < -0.01   波动率绝对值：abs($checkValue) > 0.01'),
        operator?: string(name='Operator', example='>'),
        value?: string(name='Value', example='100.0'),
      }(name='Expected'),
      warned?: {
        expression?: string(name='Expression', example='波动率类型规则使用，通过表达式来表示波动阈值。如：波动上升大于0.01： $checkValue > 0.01  波动下降大于0.01：$checkValue < -0.01   波动率绝对值：abs($checkValue) > 0.01'),
        operator?: string(name='Operator', example='>'),
        value?: string(name='Value', example='100.0'),
      }(name='Warned'),
    }(name='Thresholds'),
    type?: string(name='Type', example='Fixed'),
  }(name='CheckingConfig'),
  description?: string(name='Description', example='this is a odps _sql task'),
  enabled?: boolean(name='Enabled', example='true'),
  errorHandlers?: [ 
    {
      errorDataFilter?: string(name='ErrorDataFilter', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
      type?: string(name='Type', example='SaveErrorData'),
    }
  ](name='ErrorHandlers'),
  id?: long(name='Id', example='1'),
  name?: string(name='Name', example='表不能为空'),
  projectId?: long(name='ProjectId', example='100'),
  samplingConfig?: {
    metric?: string(name='Metric', example='Min'),
    metricParameters?: string(name='MetricParameters', example='{ "Columns": [ "id", "name" ] }'),
    samplingFilter?: string(name='SamplingFilter', example='id IS NULL'),
    settingConfig?: string(name='SettingConfig', example='SET odps.sql.udf.timeout=600s;'),
  }(name='SamplingConfig'),
  severity?: string(name='Severity', example='High'),
  target?: {
    databaseType?: string(name='DatabaseType', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', example='ds=$[yyyymmdd-1]'),
    tableGuid?: string(name='TableGuid', example='odps.unit_test.tb_unit_test'),
    type?: string(name='Type', example='Table'),
  }(name='Target'),
  templateCode?: string(name='TemplateCode', example='SYSTEM:user_defined_sql'),
  tenantId?: long(name='TenantId', example='1'),
}

model DataQualityRuleTemplate {
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    type?: string(name='Type', example='Fixed'),
  }(name='CheckingConfig'),
  code?: string(name='Code'),
  directoryPath?: string(name='DirectoryPath', example='/ods/订单数据'),
  name?: string(name='Name'),
  projectId?: long(name='ProjectId'),
  samplingConfig?: {
    metric?: string(name='Metric', example='Min'),
    metricParameters?: string(name='MetricParameters', example='{ "SQL": "SELECT min(id) from table;" }'),
    settingConfig?: string(name='SettingConfig', example='SET odps.sql.udf.timeout=600s;'),
  }(name='SamplingConfig'),
  tenantId?: long(name='TenantId'),
  visibleScope?: string(name='VisibleScope', example='Project'),
}

model Database {
  comment?: string(name='Comment', example='test comment'),
  createTime?: long(name='CreateTime', example='1736852168000'),
  id?: string(name='Id', example='holo-database:h-xxxx::test_db'),
  locationUri?: string(name='LocationUri', example='oss://test-bucket/test_db'),
  modifyTime?: long(name='ModifyTime', example='1736852168000'),
  name?: string(name='Name', example='test_db'),
  parentMetaEntityId?: string(name='ParentMetaEntityId', example='holo:h-xxxx'),
}

model LineageEntity {
  attributes?: map[string]string(name='Attributes', example='{"key1":"value1"}'),
  id?: string(name='Id', example='maxcompute-table:123456::test_project::test_tbl'),
  name?: string(name='Name', example='test_tbl'),
}

model LineageRelationship {
  createTime?: long(name='CreateTime', example='1743040581000'),
  dstEntity?: LineageEntity(name='DstEntity'),
  id?: string(name='Id', example='maxcompute-table.p.table:custom-table.xxx:custom-sql.123'),
  srcEntity?: LineageEntity(name='SrcEntity'),
  task?: LineageTask(name='Task'),
}

model LineageTask {
  attributes?: map[string]string(name='Attributes'),
  id?: string(name='Id', example='12345'),
  type?: string(name='Type', example='custom-sql'),
}

model Partition {
  createTime?: long(name='CreateTime', example='1700192563000'),
  dataSize?: long(name='DataSize', example='4096'),
  modifyTime?: long(name='ModifyTime', example='1700192563000'),
  name?: string(name='Name', example='ds=20250101'),
  recordCount?: long(name='RecordCount', example='1000000'),
  tableId?: string(name='TableId', example='maxcompute-table:accountId::project::table'),
}

model Schema {
  comment?: string(name='Comment', example='test comment'),
  createTime?: long(name='CreateTime', example='1736852168000'),
  id?: string(name='Id', example='maxcompute-schema:123456::test_project:default'),
  modifyTime?: long(name='ModifyTime', example='1736852168000'),
  name?: string(name='Name', example='test_db'),
  parentMetaEntityId?: string(name='ParentMetaEntityId', example='maxcompute-project:123456::test_project'),
  type?: string(name='Type', example='MANAGED'),
}

model Table {
  businessMetadata?: {
    categories?: [[ 
      {
        id?: string(name='Id', example='CATEGORY.456'),
        name?: string(name='Name', example='测试类目'),
        parentId?: string(name='ParentId', example='CATEGORY.123'),
      }
    ]    ](name='Categories'),
    extension?: {
      envType?: string(name='EnvType', example='Dev'),
      favorCount?: long(name='FavorCount', example='0'),
      projectId?: long(name='ProjectId', example='234'),
      readCount?: long(name='ReadCount', example='0'),
      viewCount?: long(name='ViewCount', example='0'),
    }(name='Extension'),
    readme?: string(name='Readme', example='## 使用说明'),
    tags?: [ 
      {
        key?: string(name='Key', example='tag_key'),
        value?: string(name='Value', example='tag_value'),
      }
    ](name='Tags'),
    upstreamTasks?: [ 
      {
        id?: long(name='Id', example='123456'),
        name?: string(name='Name', example='test_task'),
      }
    ](name='UpstreamTasks'),
  }(name='BusinessMetadata'),
  comment?: string(name='Comment', example='测试表'),
  createTime?: long(name='CreateTime', example='1736852168000'),
  id?: string(name='Id', example='maxcompute-table:123456::test_project::test_tbl'),
  modifyTime?: long(name='ModifyTime', example='1736852168000'),
  name?: string(name='Name', example='test_tbl'),
  parentMetaEntityId?: string(name='ParentMetaEntityId', example='maxcompute-project:123456::test_project'),
  partitionKeys?: [ string ](name='PartitionKeys'),
  tableType?: string(name='TableType', example='TABLE'),
  technicalMetadata?: {
    compressed?: boolean(name='Compressed', example='false'),
    inputFormat?: string(name='InputFormat', example='org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'),
    location?: string(name='Location', example='oss://test-bucket/test_tbl'),
    outputFormat?: string(name='OutputFormat', example='org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'),
    owner?: string(name='Owner', example='123456789'),
    parameters?: map[string]string(name='Parameters'),
    serializationLibrary?: string(name='SerializationLibrary', example='org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'),
  }(name='TechnicalMetadata'),
}

model AbolishPipelineRunRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID of the process.

This parameter is required.', example='1606087c-9ac4-43f0-83a8-0b5ced21XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model AbolishPipelineRunResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='55D786C9-DD57-524D-884C-C5239278XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model AbolishPipelineRunResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AbolishPipelineRunResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AbolishPipelineRun  AbolishPipelineRunRequest
  * @return AbolishPipelineRunResponse
 */
async function abolishPipelineRun(request: AbolishPipelineRunRequest): AbolishPipelineRunResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AbolishPipelineRun', 'POST', '/', 'json', true, 'form', request);
}

model AddEntityIntoMetaCollectionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The entity ID. Currently, entities can only be tables. You can call the ListTables operation to query the ID.

This parameter is required.', example='maxcompute-table', position='Query'),
  metaCollectionId: string(name='MetaCollectionId', description='The collection ID. You can call the ListMetaCollections operation to query the ID.

This parameter is required.', example='category.123', position='Query'),
  remark?: string(name='Remark', position='Query'),
}

model AddEntityIntoMetaCollectionResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADE490'),
}

model AddEntityIntoMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddEntityIntoMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AddEntityIntoMetaCollection  AddEntityIntoMetaCollectionRequest
  * @return AddEntityIntoMetaCollectionResponse
 */
async function addEntityIntoMetaCollection(request: AddEntityIntoMetaCollectionRequest): AddEntityIntoMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddEntityIntoMetaCollection', 'POST', '/', 'json', false, 'json', request);
}

model AssociateProjectToResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace with which you want to associate the resource group.

This parameter is required.', example='1000', position='Body'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
}

model AssociateProjectToResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to locate logs and troubleshoot issues.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model AssociateProjectToResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AssociateProjectToResourceGroupResponseBody(name='body'),
}

/**
  * @description 1.  You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * 2.  Your account must be assigned one of the following roles of the desired workspace:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of AssociateProjectToResourceGroup  AssociateProjectToResourceGroupRequest
  * @return AssociateProjectToResourceGroupResponse
 */
async function associateProjectToResourceGroup(request: AssociateProjectToResourceGroupRequest): AssociateProjectToResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AssociateProjectToResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model AttachDataQualityRulesToEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityEvaluationTaskId: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task that is associated with the rule.

This parameter is required.', example='200001', position='Body'),
  dataQualityRuleIds: [ long ](name='DataQualityRuleIds', description='The IDs of the monitoring rules.

This parameter is required.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID. You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model AttachDataQualityRulesToEvaluationTaskResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='E6F0DBDD-5AD8-4870-A6A0'),
  success?: boolean(name='Success', description='The value of the association is as follows:
- true: The call is successful.
- false: the call failed.', example='true'),
}

model AttachDataQualityRulesToEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AttachDataQualityRulesToEvaluationTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AttachDataQualityRulesToEvaluationTask  AttachDataQualityRulesToEvaluationTaskRequest
  * @return AttachDataQualityRulesToEvaluationTaskResponse
 */
async function attachDataQualityRulesToEvaluationTask(request: AttachDataQualityRulesToEvaluationTaskRequest): AttachDataQualityRulesToEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AttachDataQualityRulesToEvaluationTask', 'POST', '/', 'json', true, 'form', request);
}

model BatchUpdateTasksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  tasks?: [ 
    {
      dataSource?: {
        name?: string(name='Name', description='The name of the data source.', example='odps_test'),
      }(name='DataSource', description='The information about the associated data source.'),
      description?: string(name='Description', description='The description.', example='test'),
      envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
      id: long(name='Id', description='The task ID.

This parameter is required.', example='1234'),
      name?: string(name='Name', description='The name.', example='SQL node'),
      owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
      rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
      rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.', example='AllAllowed'),
      rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
      runtimeResource?: {
        cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
        image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
        resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
      }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
      tags?: [ 
        {
          key: string(name='Key', description='The tag key.

This parameter is required.', example='key1'),
          value?: string(name='Value', description='The tag value.', example='value1'),
        }
      ](name='Tags', description='The tags.'),
      timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
      trigger?: {
        cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
        endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler. The value of this parameter is in the `yyyy-mm-dd hh:mm:ss`.', example='9999-01-01 00:00:00'),
        recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler. The value of this parameter is in the `yyyy-mm-dd hh:mm:ss`.', example='1970-01-01 00:00:00'),
        type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
      }(name='Trigger', description='The trigger method.'),
    }
  ](name='Tasks', description='The tasks.', shrink='json', position='Body'),
}

model BatchUpdateTasksResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The task ID serves as a key, and the result serves as a value.'),
}

model BatchUpdateTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: BatchUpdateTasksResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of BatchUpdateTasks  BatchUpdateTasksRequest
  * @return BatchUpdateTasksResponse
 */
async function batchUpdateTasks(request: BatchUpdateTasksRequest): BatchUpdateTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'BatchUpdateTasks', 'POST', '/', 'json', true, 'form', request);
}

model CloneDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  cloneDataSourceName: string(name='CloneDataSourceName', description='The name of the destination data source The name can contain letters, digits, and underscores (_), and must start with a letter. It cannot exceed 60 characters in length.

This parameter is required.', example='demo_holo_datasource', position='Query'),
  id: long(name='Id', description='The data source ID.

This parameter is required.', example='16036', position='Query'),
}

model CloneDataSourceResponseBody = {
  id?: long(name='Id', description='The ID of the cloned data source.', example='19715'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='FCD583B9-346B-5E75-82C1-4A7C192C48DB'),
}

model CloneDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CloneDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of CloneDataSource  CloneDataSourceRequest
  * @return CloneDataSourceResponse
 */
async function cloneDataSource(request: CloneDataSourceRequest): CloneDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CloneDataSource', 'POST', '/', 'json', false, 'json', request);
}

model CreateAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  enabled: boolean(name='Enabled', description='Indicates whether the rule is enabled.

This parameter is required.', example='true', position='Query'),
  name: string(name='Name', description='The name of the rule.

This parameter is required.', example='xm_create_test', position='Query'),
  notification?: {
    channels: [ string ](name='Channels', description='The alert notification channels.

This parameter is required.'),
    intervalInMinutes?: int32(name='IntervalInMinutes', description='The interval at which an alert notification is sent. Unit: minutes. Valid values: [5,10000].', example='30'),
    maximum?: int32(name='Maximum', description='The maximum number of times an alert notification can be sent within a calendar day. Valid values: [1, 10000].', example='3'),
    receivers: [ 
      {
        extension?: string(name='Extension', description='The additional configuration of the alert recipient. If the ReceiverType parameter is set to DingdingUrl, you can set this parameter to {"atAll":true} to remind all members in a DingTalk group.', example='{"atAll":true}'),
        receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid valves:

*   AliUid: Alibaba Cloud account ID.
*   Shift Schedules: the personnel in a shift schedule.
*   TaskOwner: the task owner. The task owner can receive custom alerts and event alerts.
*   Owner: the baseline owner. The baseline owner can receive baseline alerts.
*   WebhookUrl: URL of a custom webhook.
*   DingdingUrl: DingTalk webhook URL.
*   FeishuUrl: Lark webhook URL.
*   WeixinUrl: WeCom webhook URL.', example='TaskOwner'),
        receiverValues?: [ string ](name='ReceiverValues', description='The ID of the alert recipient.'),
      }
    ](name='Receivers', description='The alert recipients.

This parameter is required.'),
    silenceEndTime?: string(name='SilenceEndTime', description='The end time for silence. The time is in the HH:mm format.', example='00:00:00'),
    silenceStartTime?: string(name='SilenceStartTime', description='The start time for silence. The time is in the HH:mm format.', example='00:00:00'),
  }(name='Notification', description='The configuration for the alert notification.', shrink='json', position='Query'),
  owner: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.

This parameter is required.', example='279114181716147735', position='Query'),
  triggerCondition: {
    extension?: {
      cycleUnfinished?: {
        cycleAndTime?: [ 
          {
            cycleId?: int32(name='CycleId', description='The ID of the scheduling cycle of the instance. Valid values: [1,288].', example='1'),
            time?: string(name='Time', description='The latest completion time of the instance within the scheduling cycle. The time is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
          }
        ](name='CycleAndTime', description='The configurations of the scheduling cycle and timeout period of the instance.'),
      }(name='CycleUnfinished', description='The configuration for an alert of the CycleUnfinished type.'),
      error?: {
        autoRerunAlertEnabled?: boolean(name='AutoRerunAlertEnabled', description='Specifies whether to trigger an alert if a batch synchronization task is automatically rerun upon a failure.', example='false'),
        streamTaskIds?: [ long ](name='StreamTaskIds', description='The IDs of the real-time computing tasks. This parameter is required when you monitor real-time computing tasks.'),
      }(name='Error', description='The configuration for an alert of the Error type.'),
      instanceErrorCount?: {
        count?: int32(name='Count', description='The maximum number of instances on which an error occurs. Valid values: [1,10000].', example='5'),
      }(name='InstanceErrorCount', description='The configuration for an alert of the InstanceErrorCount type.'),
      instanceErrorPercentage?: {
        percentage?: int32(name='Percentage', description='The maximum percentage of instances on which an error occurs in the workspace to the total number of instances. Valid values: [1-100].', example='5'),
      }(name='InstanceErrorPercentage', description='The configuration for an alert of the InstanceErrorPercentage type.'),
      instanceTransferFluctuate?: {
        percentage?: int32(name='Percentage', description='The maximum percentage of fluctuation in the number of auto triggered node instances that are generated in your workspace. Valid values: [1-100].', example='10'),
        trend?: string(name='Trend', description='The way in which the number of auto triggered node instances that are generated in your workspace fluctuates. Valid values:

*   abs: the absolute value. The number of instances increases or decreases.
*   increase: The number of instances increases.
*   decrease: The number of instances decreases.', example='abs'),
      }(name='InstanceTransferFluctuate', description='The configuration for an alert of the InstanceTransferFluctuate type.'),
      timeout?: {
        timeoutInMinutes?: int32(name='TimeoutInMinutes', description='The timeout period. Unit: minutes. Valid values: [1, 21600].', example='10'),
      }(name='Timeout', description='The configuration for an alert of the Timeout type.'),
      unFinished?: {
        unFinishedTime?: string(name='UnFinishedTime', description='The latest completion time of the instance. The period is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='30:00'),
      }(name='UnFinished', description='The configuration for an alert of the UnFinished type.'),
    }(name='Extension', description='The extended information about the rule. This parameter is required for specific types of alerts.'),
    target?: {
      allowTasks?: [ long ](name='AllowTasks', description='The nodes that are not to be monitored.'),
      ids?: [ long ](name='Ids', description='The IDs of monitored objects.'),
      type?: string(name='Type', description='The type of the monitored objects. Valid values:

*   Task: node
*   Baseline: baseline
*   Project: workspace
*   BizProcess: workflow', example='Task'),
    }(name='Target', description='The monitored objects.'),
    type?: string(name='Type', description='The alert type. Valid values:

*   Finished: An instance is successfully run.
*   UnFinished: An instance does not finish running before a specified point in time.
*   Error: An error occurs on an instance.
*   CycleUnfinished: An instance does not finish running as expected within a specific cycle.
*   Timeout: An instance times out.
*   InstanceTransferComplete: An instance is generated by the auto triggered node.
*   InstanceTransferFluctuate: The number of generated instances fluctuates.
*   ExhaustedError: An error persists after an instance is automatically rerun.
*   InstanceKeyword: An instance with errors contains specified keywords.
*   InstanceErrorCount: The number of instances on which an error occurs reaches a specified threshold.
*   InstanceErrorPercentage: The proportion of instances on which an error occurs in the workspace to the total number of instances reaches a specified threshold.
*   ResourceGroupPercentage: The usage rate of the resource group reaches a specified threshold.
*   ResourceGroupWaitCount: The number of instances that are waiting for resources in the resource group reaches a specified threshold.', example='Error'),
  }(name='TriggerCondition', description='The alert triggering condition.

This parameter is required.', shrink='json', position='Query'),
}

model CreateAlertRuleResponseBody = {
  id?: long(name='Id', description='The rule ID.', example='123123'),
  requestId?: string(name='RequestId', description='The request ID.', example='A6C6B486-E3A2-5D52-9E76-D9380485D946'),
}

model CreateAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateAlertRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateAlertRule  CreateAlertRuleRequest
  * @return CreateAlertRuleResponse
 */
async function createAlertRule(request: CreateAlertRuleRequest): CreateAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateAlertRule', 'POST', '/', 'json', false, 'json', request);
}

model CreateBusinessRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  businessName: string(name='BusinessName', description='This parameter is required.', example='My business process', position='Body'),
  description?: string(name='Description', position='Body'),
  owner?: string(name='Owner', example='1000000000001', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
  useType?: string(name='UseType', example='NORMAL', position='Body'),
}

model CreateBusinessResponseBody = {
  businessId?: long(name='BusinessId', example='100001'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model CreateBusinessResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateBusinessResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateBusiness  CreateBusinessRequest
  * @return CreateBusinessResponse
 */
async function createBusiness(request: CreateBusinessRequest): CreateBusinessResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateBusiness', 'POST', '/', 'json', true, 'form', request);
}

model CreateDIAlarmRuleRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='ABFUOEUOTRTRJKE', position='Query'),
  DIJobId: long(name='DIJobId', description='The ID of the synchronization task with which the alert rule is associated.

This parameter is required.', example='1', position='Query'),
  description?: string(name='Description', description='The description of the alert rule.', example='The description of the alert rule.', position='Query'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the alert rule. By default, the alert rule is disabled.', example='true', position='Query'),
  metricType: string(name='MetricType', description='The metric type in the alert rule. Valid values:

*   Heartbeat
*   FailoverCount
*   Delay
*   DdlReport
*   ResourceUtilization

This parameter is required.', example='Heartbeat', position='Query'),
  name: string(name='Name', description='The name of the alert rule.

This parameter is required.', example='alartRule', position='Query'),
  notificationSettings: {
    inhibitionInterval?: int32(name='InhibitionInterval', description='This parameter is deprecated and replaced by the MuteInterval parameter.', example='5', deprecated='true'),
    muteInterval?: int32(name='MuteInterval', description='The duration of the alert suppression interval. Default value: 5. Unit: minutes.', example='5'),
    notificationChannels?: [ 
      {
        channels?: [ string ](name='Channels', description='The alert notification method. Valid values:

*   Mail
*   Phone
*   Sms
*   Ding'),
        severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Warning'),
      }
    ](name='NotificationChannels', description='The alert notification methods.'),
    notificationReceivers?: [ 
      {
        receiverType?: string(name='ReceiverType', description='The recipient type. Valid values: AliyunUid, DingToken, FeishuToken, and WebHookUrl.', example='DingToken'),
        receiverValues?: [ string ](name='ReceiverValues', description='The recipient.

*   If the ReceiverType parameter is set to AliyunUid, set this parameter to the Alibaba Cloud account ID of a user.
*   If the ReceiverType parameter is set to DingToken, set this parameter to the token of a DingTalk chatbot.'),
      }
    ](name='NotificationReceivers', description='The settings of alert notification recipients.'),
  }(name='NotificationSettings', description='The alert notification settings.

This parameter is required.', shrink='json', position='Query'),
  triggerConditions: [ 
    {
      ddlReportTags?: [ string ](name='DdlReportTags', description='This parameter is deprecated and replaced by the DdlTypes parameter.', deprecated='true'),
      ddlTypes?: [ string ](name='DdlTypes', description='The types of DDL operations for which the alert rule takes effect.'),
      duration?: long(name='Duration', description='The time interval for alert calculation. Unit: minutes.', example='10'),
      severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Warning'),
      threshold?: long(name='Threshold', description='The alert threshold.

*   If the alert rule is for task status, you do not need to specify a threshold.
*   If the alert rule is for failovers, you must specify the number of failovers.
*   If the alert rule is for latency, you must specify the latency duration, in seconds.', example='10'),
    }
  ](name='TriggerConditions', description='The conditions that can trigger the alert rule.

This parameter is required.', shrink='json', position='Query'),
}

model CreateDIAlarmRuleResponseBody = {
  DIAlarmRuleId?: string(name='DIAlarmRuleId', description='This parameter is deprecated and is replaced by the Id parameter.', example='1', deprecated='true'),
  id?: long(name='Id', description='The ID of the alert rule.', example='1'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='C636A747-7E4E-594D-94CD-2B4F8A9A9A63'),
}

model CreateDIAlarmRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDIAlarmRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDIAlarmRule  CreateDIAlarmRuleRequest
  * @return CreateDIAlarmRuleResponse
 */
async function createDIAlarmRule(request: CreateDIAlarmRuleRequest): CreateDIAlarmRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDIAlarmRule', 'GET', '/', 'json', false, 'json', request);
}

model CreateDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  description?: string(name='Description', description='The description of the synchronization task.', example='The description of the synchronization task.', position='Query'),
  destinationDataSourceSettings: [ 
    {
      dataSourceName?: string(name='DataSourceName', description='The name of the data source.', example='holo_datasource_1'),
    }
  ](name='DestinationDataSourceSettings', description='The settings of the destination. Only a single destination is supported.

This parameter is required.', shrink='json', position='Query'),
  destinationDataSourceType: string(name='DestinationDataSourceType', description='The destination type. Valid values: Hologres, OSS-HDFS, OSS, MaxCompute, LogHub, StarRocks, DataHub, AnalyticDB for MySQL, Kafka, and Hive.

This parameter is required.', example='Hologres', position='Query'),
  jobName?: string(name='JobName', description='This parameter is deprecated and is replaced by the Name parameter.', example='mysql_to_holo_sync_8772', deprecated='true', position='Query'),
  jobSettings?: {
    channelSettings?: string(name='ChannelSettings', description='The channel control settings for the synchronization task. You can configure special channel control settings for the following synchronization links: data synchronization between Hologres data sources and data synchronization from Hologres to Kafka.

1.  Holo2Kafka

*   Example: {"destinationChannelSettings":{"kafkaClientProperties":[{"key":"linger.ms","value":"100"}],"keyColumns":["col3"],"writeMode":"canal"}}
*   kafkaClientProperties: the parameters related to a Kafka producer, which are used when you write data to a Kafka data source.
*   keyColumns: the names of Kafka columns to which you want to write data.
*   writeMode: the writing format of the Kafka data source. Valid values: json and canal.

2.  Holo2Holo

*   Example: {"destinationChannelSettings":{"conflictMode":"replace","dynamicColumnAction":"replay","writeMode":"replay"}}
*   conflictMode: the policy used to handle a conflict that occurs during data writing to Hologres. Valid values: replace and ignore.
*   writeMode: the mode in which you want to write data to Hologres. Valid values: replay and insert.
*   dynamicColumnAction: the mode in which you want to write data to dynamic columns in a Hologres table. Valid values: replay, insert, and ignore.', example='{"structInfo":"MANAGED","storageType":"TEXTFILE","writeMode":"APPEND","partitionColumns":[{"columnName":"pt","columnType":"STRING","comment":""}],"fieldDelimiter":""}'),
    columnDataTypeSettings?: [ 
      {
        destinationDataType?: string(name='DestinationDataType', description='The data type of the destination field. Valid values: bigint, boolean, string, text, datetime, timestamp, decimal, and binary. Different types of data sources support different data types.', example='text'),
        sourceDataType?: string(name='SourceDataType', description='The data type of the source field. Valid values: Valid values: bigint, boolean, string, text, datetime, timestamp, decimal, and binary. Different types of data sources support different data types.', example='bigint'),
      }
    ](name='ColumnDataTypeSettings', description='The data type mappings between source fields and destination fields.

>  "ColumnDataTypeSettings":[ { "SourceDataType":"Bigint", "DestinationDataType":"Text" } ]'),
    cycleScheduleSettings?: {
      cycleMigrationType?: string(name='CycleMigrationType', description='The synchronization type that requires periodic scheduling. Valid values:

*   Full: full synchronization
*   OfflineIncremental: batch incremental synchronization', example='Full'),
      scheduleParameters?: string(name='ScheduleParameters', description='The scheduling parameters.', example='bizdate=$bizdate'),
    }(name='CycleScheduleSettings', description='The settings for periodic scheduling.'),
    ddlHandlingSettings?: [ 
      {
        action?: string(name='Action', description='The processing policy. Valid values:

*   Ignore: ignores a DDL message.
*   Critical: reports an error for a DDL message.
*   Normal: normally processes a DDL message.', example='Critical'),
        type?: string(name='Type', description='The type of the DDL operation. Valid values:

*   RenameColumn
*   ModifyColumn
*   CreateTable
*   TruncateTable
*   DropTable
*   DropColumn
*   AddColumn', example='AddColumn'),
      }
    ](name='DdlHandlingSettings', description='The processing settings for DDL messages.

>  "DDLHandlingSettings":[ { "Type":"Insert", "Action":"Normal" } ]'),
    runtimeSettings?: [ 
      {
        name?: string(name='Name', description='The name of the configuration item. Valid values:

*   src.offline.datasource.max.connection: specifies the maximum number of connections that are allowed for reading data from the source of a batch synchronization task.
*   dst.offline.truncate: specifies whether to clear the destination table before data writing.
*   runtime.offline.speed.limit.enable: specifies whether throttling is enabled for a batch synchronization task.
*   runtime.offline.concurrent: specifies the maximum number of parallel threads that are allowed for a batch synchronization task.
*   runtime.enable.auto.create.schema: specifies whether schemas are automatically created in the destination of a synchronization task.
*   runtime.realtime.concurrent: specifies the maximum number of parallel threads that are allowed for a real-time synchronization task.
*   runtime.realtime.failover.minute.dataxcdc: specifies the maximum waiting duration before a synchronization task retries the next restart if the previous restart fails after failover occurs. Unit: minutes.
*   runtime.realtime.failover.times.dataxcdc: specifies the maximum number of failures that are allowed for restarting a synchronization task after failovers occur.', example='runtime.offline.concurrent'),
        value?: string(name='Value', description='The value of the configuration item.', example='1'),
      }
    ](name='RuntimeSettings', description='The runtime settings.'),
  }(name='JobSettings', description='The settings for the dimension of the synchronization task. The settings include processing policies for DDL messages, policies for data type mappings between source fields and destination fields, and runtime parameters of the synchronization task.', shrink='json', position='Query'),
  jobType?: string(name='JobType', description='The type of the task. This parameter is optional. Valid values:

*   DatabaseRealtimeMigration: A real-time synchronization task used to synchronize only full data, only incremental data, or full and incremental data in multiple tables of multiple databases at the source.
*   DatabaseOfflineMigration: A batch synchronization task used to synchronize only full data, only incremental data, or full and incremental data in multiple tables of multiple databases at the source.
*   SingleTableRealtimeMigration: A real-time synchronization task used to synchronize only data in single table at the source.', example='DatabaseRealtimeMigration', position='Query'),
  migrationType: string(name='MigrationType', description='The synchronization type. Valid values:

*   FullAndRealtimeIncremental: full synchronization and real-time incremental synchronization of data in an entire database
*   RealtimeIncremental: real-time incremental synchronization of data in a single table
*   Full: full batch synchronization of data in an entire database
*   OfflineIncremental: batch incremental synchronization of data in an entire database
*   FullAndOfflineIncremental: full synchronization and batch incremental synchronization of data in an entire database

This parameter is required.', example='FullAndRealtimeIncremental', position='Query'),
  name?: string(name='Name', description='The name of the synchronization task.', example='mysql_to_holo_sync_8772', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
  resourceSettings: {
    offlineResourceSettings?: {
      requestedCu?: double(name='RequestedCu', description='The number of compute units (CUs) in the resource group for Data Integration that are used for batch synchronization.', example='2.0'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The name of the resource group for Data Integration that are used for batch synchronization.', example='S_res_group_111_222'),
    }(name='OfflineResourceSettings', description='The resource settings for batch synchronization.'),
    realtimeResourceSettings?: {
      requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for Data Integration that are used for real-time synchronization.', example='2.0'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The name of the resource group for Data Integration that are used for real-time synchronization.', example='S_res_group_111_222'),
    }(name='RealtimeResourceSettings', description='The resource settings for real-time synchronization.'),
    scheduleResourceSettings?: {
      requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for scheduling that are used for batch synchronization.', example='2.0'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The name of the resource group for scheduling that is used for batch synchronization.', example='S_res_group_235454102432001_1579085295030'),
    }(name='ScheduleResourceSettings', description='The resource settings for scheduling.'),
  }(name='ResourceSettings', description='The resource settings.

This parameter is required.', shrink='json', position='Query'),
  sourceDataSourceSettings: [ 
    {
      dataSourceName?: string(name='DataSourceName', description='The name of the data source.', example='mysql_datasource_1'),
      dataSourceProperties?: {
        encoding?: string(name='Encoding', description='The encoding format of the database.', example='UTF-8'),
        timezone?: string(name='Timezone', description='The time zone.', example='GMT+8'),
      }(name='DataSourceProperties', description='The properties of the data source.'),
    }
  ](name='SourceDataSourceSettings', description='The settings of the source. Only a single source is supported.

This parameter is required.', shrink='json', position='Query'),
  sourceDataSourceType: string(name='SourceDataSourceType', description='The source type. Valid values: PolarDB, MySQL, Kafka, LogHub, Hologres, Oracle, OceanBase, MongoDB, Redshift, Hive, SQL Server, Doris, and ClickHouse.

This parameter is required.', example='MySQL', position='Query'),
  tableMappings: [ 
    {
      sourceObjectSelectionRules?: [ 
        {
          action?: string(name='Action', description='The operation that is performed to select objects. Valid values: Include and Exclude.', example='Include'),
          expression?: string(name='Expression', description='The expression.', example='mysql_table_1'),
          expressionType?: string(name='ExpressionType', description='The expression type. Valid values: Exact and Regex.', example='Exact'),
          objectType?: string(name='ObjectType', description='The object type. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
        }
      ](name='SourceObjectSelectionRules', description='The list of rules used to select synchronization objects in the source.'),
      transformationRules?: [ 
        {
          ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml
*   DefineIncrementalCondition
*   DefineCycleScheduleSettings
*   DefineRuntimeSettings
*   DefinePartitionKey', example='Rename'),
          ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
          ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which you want to perform the action. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
        }
      ](name='TransformationRules', description='The list of transformation rules that you want to apply to the synchronization objects selected from the source. Each entry in the list defines a transformation rule.'),
    }
  ](name='TableMappings', description='The list of mappings between rules used to select synchronization objects in the source and transformation rules applied to the selected synchronization objects. Each entry in the list displays a mapping between a rule used to select synchronization objects and a transformation rule applied to the selected synchronization objects.

>  [ { "SourceObjectSelectionRules":[ { "ObjectType":"Database", "Action":"Include", "ExpressionType":"Exact", "Expression":"biz_db" }, { "ObjectType":"Schema", "Action":"Include", "ExpressionType":"Exact", "Expression":"s1" }, { "ObjectType":"Table", "Action":"Include", "ExpressionType":"Exact", "Expression":"table1" } ], "TransformationRuleNames":[ { "RuleName":"my_database_rename_rule", "RuleActionType":"Rename", "RuleTargetType":"Schema" } ] } ]

This parameter is required.', shrink='json', position='Query'),
  transformationRules?: [ 
    {
      ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml
*   DefineIncrementalCondition
*   DefineCycleScheduleSettings
*   DefinePartitionKey', example='Rename'),
      ruleExpression?: string(name='RuleExpression', description='The expression of the rule. The expression must be a JSON string.

1.  Example of a renaming rule

*   Example: {"expression":"${srcDatasourceName}_${srcDatabaseName}_0922" }
*   expression: the expression of the renaming rule. You can use the following variables in an expression: ${srcDatasourceName}, ${srcDatabaseName}, and ${srcTableName}. ${srcDatasourceName} specifies the name of the source. ${srcDatabaseName} specifies the name of a source database. ${srcTableName} specifies the name of a source table.

2.  Example of a column addition rule

*   Example: {"columns":[{"columnName":"my_add_column","columnValueType":"Constant","columnValue":"123"}]}
*   If you do not configure such a rule, no fields are added to the destination and no values are assigned by default.
*   columnName: the name of the field that is added.
*   columnValueType: the value type of the field. Valid values: Constant and Variable.
*   columnValue: the value of the field. If the columnValueType parameter is set to Constant, set the columnValue parameter to a constant of the STRING data type. If the columnValueType parameter is set to Variable, set the columnValue parameter to a built-in variable. The following built-in variables are supported: EXECUTE_TIME (LONG data type), DB_NAME_SRC (STRING data type), DATASOURCE_NAME_SRC (STRING data type), TABLE_NAME_SRC (STRING data type), DB_NAME_DEST (STRING data type), DATASOURCE_NAME_DEST (STRING data type), TABLE_NAME_DEST (STRING data type), and DB_NAME_SRC_TRANSED (STRING data type). EXECUTE_TIME specifies the execution time. DB_NAME_SRC specifies the name of a source database. DATASOURCE_NAME_SRC specifies the name of the source. TABLE_NAME_SRC specifies the name of a source table. DB_NAME_DEST specifies the name of a destination database. DATASOURCE_NAME_DEST specifies the name of the destination. TABLE_NAME_DEST specifies the name of a destination table. DB_NAME_SRC_TRANSED specifies the database name obtained after a transformation.

3.  Example of a rule used to specify primary key fields for a destination table

*   Example: {"columns":["ukcolumn1","ukcolumn2"]}
*   If you do not configure such a rule, the primary key fields in the mapped source table are used for the destination table by default.
*   If the destination table is an existing table, Data Integration does not modify the schema of the destination table. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run.
*   If the destination table is automatically created by the system, Data Integration automatically creates the schema of the destination table. The schema contains the primary key fields that you specify. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run.

4.  Example of a rule used to process DML messages

*   Example: {"dmlPolicies":[{"dmlType":"Delete","dmlAction":"Filter","filterCondition":"id > 1"}]}
*   If you do not configure such a rule, the default processing policy for messages generated for insert, update, and delete operations is Normal.
*   dmlType: the DML operation. Valid values: Insert, Update, and Delete.
*   dmlAction: the processing policy for DML messages. Valid values: Normal, Ignore, Filter, and LogicalDelete. Filter indicates conditional processing. You can set the dmlAction parameter to Filter only when the dmlType parameter is set to Update or Delete.
*   filterCondition: the condition used to filter DML messages. This parameter is required only when the dmlAction parameter is set to Filter.

5.  Example of a rule used to perform incremental synchronization

*   Example: {"where":"id > 0"}
*   You can configure such a rule to perform incremental synchronization.

6.  Example of a rule used to configure scheduling parameters for an auto triggered task

*   Example: {"cronExpress":" \\* \\* \\* \\* \\* \\*", "cycleType":"1"}
*   You can configure such a rule to configure scheduling parameters for an auto triggered task.

7.  Example of a rule used to specify a partition key

*   Example: {"columns":["id"]}
*   You can configure such a rule to specify a partition key.', example='{"expression":"${srcDatasoureName}_${srcDatabaseName}"}'),
      ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
      ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which you want to perform the action. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
    }
  ](name='TransformationRules', description='The list of transformation rules for objects involved in the synchronization task.

>  [ { "RuleName":"my_database_rename_rule", "RuleActionType":"Rename", "RuleTargetType":"Schema", "RuleExpression":"{"expression":"${srcDatasoureName}_${srcDatabaseName}"}" } ]', shrink='json', position='Query'),
}

model CreateDIJobResponseBody = {
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated and is replaced by the Id parameter.', example='11792', deprecated='true'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11792'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='4F6AB6B3-41FB-5EBB-AFB2-0C98D49DA2BB'),
}

model CreateDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDIJobResponseBody(name='body'),
}

/**
  * @description *   This API operation is available for all DataWorks editions.
  * *   You can call this API operation to create a synchronization task. When you call this API operation, you must configure parameters such as SourceDataSourceSettings, DestinationDataSourceSettings, MigrationType, TransformationRules, TableMappings, and JobSettings. The SourceDataSourceSettings parameter defines the settings related to the source. The DestinationDataSourceSettings parameter defines the settings related to the destination. The MigrationType parameter defines the synchronization task type. The TransformationRules parameter defines the transformation rules for objects involved in the synchronization task. The TableMappings parameter defines the mappings between rules used to select synchronization objects in the source and transformation rules applied to the selected synchronization objects. The JobSettings parameter defines the settings for the dimension of the synchronization task, including policies for data type mappings between source fields and destination fields and settings for periodic scheduling.
  * @param request  the request parameters of CreateDIJob  CreateDIJobRequest
  * @return CreateDIJobResponse
 */
async function createDIJob(request: CreateDIJobRequest): CreateDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDIJob', 'GET', '/', 'json', false, 'json', request);
}

model CreateDataAssetTagRequest {
  regionId?: string(name='RegionId', position='Host'),
  description?: string(name='Description', description='The description of the tag.', example='This is a description', maxLength=1024, position='Query'),
  key: string(name='Key', description='The tag key.

This parameter is required.', example='key1', minLength=1, maxLength=128, position='Query'),
  managers?: [ string ](name='Managers', description='The tag administrators.', shrink='json', position='Query'),
  valueType?: string(name='ValueType', description='The type of the tag value. Valid values:

*   Boolean
*   Int
*   String
*   Double', example='String', position='Query'),
  values?: [ string ](name='Values', description='The tag values.', shrink='json', position='Query'),
}

model CreateDataAssetTagResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateDataAssetTagResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataAssetTagResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of CreateDataAssetTag  CreateDataAssetTagRequest
  * @return CreateDataAssetTagResponse
 */
async function createDataAssetTag(request: CreateDataAssetTagRequest): CreateDataAssetTagResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataAssetTag', 'POST', '/', 'json', false, 'json', request);
}

model CreateDataQualityEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityRules?: [ 
    {
      checkingConfig?: {
        referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain specific types of thresholds, you must query reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{"bizdate": ["-1"]}'),
        thresholds?: {
          critical?: {
            expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
            value?: string(name='Value', description='The threshold value.', example='0.01'),
          }(name='Critical', description='The threshold settings for critical alerts.'),
          expected?: {
            expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='='),
            value?: string(name='Value', description='The threshold value.', example='0'),
          }(name='Expected', description='The expected threshold setting.'),
          warned?: {
            expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
            value?: string(name='Value', description='The threshold value.', example='0.001'),
          }(name='Warned', description='The threshold settings for normal alerts.'),
        }(name='Thresholds', description='The threshold settings.'),
        type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average', example='Fixed'),
      }(name='CheckingConfig', description='The check settings for sample data.'),
      description?: string(name='Description', description='The description of the monitoring rule.', example='OpenAPI test rules', maxLength=500),
      enabled?: boolean(name='Enabled', description='Specifies whether to enable the monitoring rule.', example='true'),
      errorHandlers?: [ 
        {
          errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If you define the rule by using custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM ods_api_log WHERE status = \\"Error\\";'),
          type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
        }
      ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
      id?: long(name='Id', description='The rule ID.', example='2176'),
      name?: string(name='Name', description='The name of the monitoring rule.', example='OpenAPI test rules'),
      samplingConfig?: {
        metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: specifies that data is sampled by executing custom SQL statements.', example='NullValueCount'),
        metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
        samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='status != \\"Succeeded\\"'),
        settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='odps.sql.type.system.odps2=True,odps.sql.hive.compatible=True', maxLength=1000),
      }(name='SamplingConfig', description='The parameters required for sampling.'),
      severity?: string(name='Severity', description='The strength of the monitoring rule. Valid values:

*   Normal
*   High', example='High'),
      templateCode?: string(name='TemplateCode', description='The ID of the template used by the monitoring rule.', example='SYSTEM:field:null_value:fixed:0'),
    }
  ](name='DataQualityRules', description='The list of monitoring rules that are associated with the monitor. If you configure the ID of a monitoring rule by using the DataQualityRule.Id parameter, the system associates the rule with a created monitor. If you do not configure the ID of a monitoring rule, the system creates a new monitoring rule by using other fields and associates the rule with a created monitor.', shrink='json', position='Body'),
  dataSourceId: long(name='DataSourceId', description='The data source ID. You can call the [ListDataSources](https://help.aliyun.com/document_detail/211431.html) operation to query the ID.

This parameter is required.', example='1', position='Body'),
  description?: string(name='Description', description='The description of the monitor.', example='OpenAPI create a data quality monitoring test', maxLength=65535, position='Body'),
  hooks?: [ 
    {
      condition?: string(name='Condition', description='The hook trigger condition. When this condition is met, the hook action is triggered. Only two conditional expressions are supported:

1.  Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
2.  Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
      type?: string(name='Type', description='The hook type. Only one hook type is supported.

*   BlockTaskInstance: Blocks the running of scheduling tasks. A monitor is triggered by scheduling tasks. After a monitor finishes running, the monitor determines whether to block the running of scheduling tasks based on the hook condition.', example='BlockTaskInstance'),
    }
  ](name='Hooks', description='The hook.', shrink='json', position='Body'),
  name: string(name='Name', description='The name of the monitor.

This parameter is required.', example='OpenAPI create a data quality monitoring test', maxLength=255, position='Body'),
  notifications?: {
    condition?: string(name='Condition', description='The notification trigger condition. When this condition is met, the alert notification is triggered. Only two conditional expressions are supported:

Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical. Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
    notifications?: [ 
      {
        notificationChannels?: [ 
          {
            channels?: [ string ](name='Channels', description='The alert notification methods.'),
          }
        ](name='NotificationChannels', description='The alert notification methods.'),
        notificationReceivers?: [ 
          {
            extension?: string(name='Extension', description='The additional parameters that are required when alerts are sent. The parameters are JSON-formatted strings. The following keys are supported:

*   atAll: specifies that all members in a group are mentioned when alerts are sent by using DingTalk. This parameter is valid only if you set ReceiverType to DingdingUrl.', example='{  "atAll": true }'),
            receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid values:

*   WebhookUrl
*   FeishuUrl
*   DingdingUrl
*   WeixinUrl
*   AliUid', example='DingdingUrl'),
            receiverValues?: [ string ](name='ReceiverValues', description='The alert recipient.'),
          }
        ](name='NotificationReceivers', description='The configurations of alert recipients.'),
      }
    ](name='Notifications', description='The configurations of the alert notification.'),
  }(name='Notifications', description='The configurations of alert notifications.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You can use this parameter to specify the DataWorks workspace on which you want to perform the API operation.

This parameter is required.', example='10000', position='Body'),
  runtimeConf?: string(name='RuntimeConf', description='The extended configurations in JSON-formatted strings. You can use this parameter only for monitors that are used to monitor the quality of E-MapReduce (EMR) data.

*   queue: The Yarn queue used when a monitor checks the quality of EMR data. By default, the queue configured for the current workspace is used.

*   sqlEngine: The SQL engine used when a monitor checks the quality of EMR data.

    *   HIVE_SQL
    *   SPARK_SQL', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }', position='Body'),
  target: {
    databaseType: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   hologres
*   cdh
*   analyticdb_for_mysql
*   starrocks
*   emr
*   analyticdb_for_postgresql

This parameter is required.', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='pt=$[yyyymmdd-1]', maxLength=255),
    tableGuid: string(name='TableGuid', description='The ID of the table in Data Map.

This parameter is required.', example='odps.api_test.ods_openapi_log_d'),
  }(name='Target', description='The monitored object of the monitor.

This parameter is required.', shrink='json', position='Body'),
  trigger?: {
    taskIds?: [ long ](name='TaskIds', description='The IDs of scheduling tasks. This parameter is valid only if you set Type to ByScheduledTaskInstance.'),
    type?: string(name='Type', description='The trigger type of the monitor. Valid values:

*   ByManual (default): The monitor is manually triggered.
*   ByScheduledTaskInstance: The monitor is triggered by the associated scheduling tasks.', example='ByScheduledTaskInstance'),
  }(name='Trigger', description='The trigger configuration of the monitor.', shrink='json', position='Body'),
}

model CreateDataQualityEvaluationTaskResponseBody = {
  id?: long(name='Id', description='The ID of the new monitor.', example='10001'),
  requestId?: string(name='RequestId', description='Id of the request', example='2d9ce-38ef-4923-baf6-391a7e656'),
}

model CreateDataQualityEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityEvaluationTaskResponseBody(name='body'),
}

/**
  * @description This API operation is supported in all DataWorks editions.
  * @param request  the request parameters of CreateDataQualityEvaluationTask  CreateDataQualityEvaluationTaskRequest
  * @return CreateDataQualityEvaluationTaskResponse
 */
async function createDataQualityEvaluationTask(request: CreateDataQualityEvaluationTaskRequest): CreateDataQualityEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityEvaluationTask', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataQualityEvaluationTaskInstanceRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityEvaluationTaskId: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task.

This parameter is required.', example='200001', position='Body'),
  parameters: string(name='Parameters', description='Data quality verification execution parameters in JSON format. The available keys are as follows:
- triggerTime: the millisecond timestamp of the trigger time. The baseline time of the $[yyyymmdd] expression in the data range of data quality monitoring. Required.

This parameter is required.', example='{ "triggerTime": 1733284062000 }', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the workspace management page to obtain the ID.

This parameter is used to determine the DataWorks workspaces used for this API call.

This parameter is required.', example='10000', position='Body'),
  runtimeResource?: {
    cu?: double(name='Cu', description='The task runs to configure CU consumption. If Serverless resource groups are used, you must specify this parameter.', example='0.25'),
    resourceGroupId?: string(name='ResourceGroupId', description='The identifier of the scheduling resource group configured for running the task.', example='63900680'),
  }(name='RuntimeResource', description='Resource Group information, which must be filled in when running non-MaxCompute data quality verification.', shrink='json', position='Body'),
}

model CreateDataQualityEvaluationTaskInstanceResponseBody = {
  id?: long(name='Id', description='The ID of the data quality monitoring instance.', example='22130'),
  requestId?: string(name='RequestId', description='Id of the request', example='ecb967ec-c137-48****'),
}

model CreateDataQualityEvaluationTaskInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityEvaluationTaskInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDataQualityEvaluationTaskInstance  CreateDataQualityEvaluationTaskInstanceRequest
  * @return CreateDataQualityEvaluationTaskInstanceResponse
 */
async function createDataQualityEvaluationTaskInstance(request: CreateDataQualityEvaluationTaskInstanceRequest): CreateDataQualityEvaluationTaskInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityEvaluationTaskInstance', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataQualityRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference samples and perform aggregate operations on the reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    thresholds?: {
      critical?: {
        expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Example:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.05'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Critical', description='The threshold settings for critical alerts.'),
      expected?: {
        expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Example:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue <= 0.01'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Expected', description='The expected threshold setting.'),
      warned?: {
        expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Example:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Warned', description='The threshold settings for normal alerts.'),
    }(name='Thresholds', description='The threshold settings.'),
    type?: string(name='Type', description='The method that is used to calculate a threshold. You can leave this parameter empty if you use a rule template. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
  }(name='CheckingConfig', description='The check settings for sample data.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description of the rule. The description can be up to 500 characters in length.', example='this is a odps _sql task', maxLength=500, position='Body'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the monitoring rule.', example='true', position='Body'),
  errorHandlers?: [ 
    {
      errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If you define the rule by using custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
      type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
    }
  ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.', shrink='json', position='Body'),
  name: string(name='Name', description='The name of the rule.

This parameter is required.', example='The table cannot be empty.', maxLength=255, position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='10726', position='Body'),
  samplingConfig?: {
    metric?: string(name='Metric', description='The metrics used for sampling. You can leave this parameter empty if you use a rule template. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: specifies that data is sampled by executing custom SQL statements.', example='Count'),
    metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
    samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='id IS NULL'),
    settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;', maxLength=1000),
  }(name='SamplingConfig', description='The sampling settings.', shrink='json', position='Body'),
  severity?: string(name='Severity', description='The strength of the rule. Valid values:

*   Normal
*   High', example='Normal', position='Body'),
  target?: {
    databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='ds=$[yyyymmdd-1]'),
    tableGuid: string(name='TableGuid', description='The ID of the table that is limited by the rule in Data Map.

This parameter is required.', example='odps.unit_test.tb_unit_test'),
    type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
  }(name='Target', description='The monitored object of the rule.', shrink='json', position='Body'),
  templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='system::user_defined', position='Body'),
}

model CreateDataQualityRuleResponseBody = {
  id?: long(name='Id', description='The ID of the rule.', example='19715'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model CreateDataQualityRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDataQualityRule  CreateDataQualityRuleRequest
  * @return CreateDataQualityRuleResponse
 */
async function createDataQualityRule(request: CreateDataQualityRuleRequest): CreateDataQualityRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityRule', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataQualityRuleTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference samples and perform aggregate operations on the reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
  }(name='CheckingConfig', description='The check settings for sample data.', shrink='json', position='Body'),
  directoryPath?: string(name='DirectoryPath', description='The directory in which the template is stored. Slashes (/) are used to separate directory levels. The name of each directory level can be up to 1,024 characters in length. It cannot contain whitespace characters or slashes (/).', example='/ods/order_data', position='Body'),
  name: string(name='Name', description='The name of the template. The name can be up to 512 characters in length and can contain digits, letters, and punctuation marks.

This parameter is required.', example='Table row Count Verification', maxLength=128, position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='12345', position='Body'),
  samplingConfig?: {
    metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: specifies that data is sampled by executing custom SQL statements.', example='Count'),
    metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{"SQL": "select count(1) from table;"}'),
    settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;', maxLength=1000),
  }(name='SamplingConfig', description='The sampling settings.', shrink='json', position='Body'),
  visibleScope?: string(name='VisibleScope', description='The applicable scope of the template. Valid values:

*   Tenant: The template is available in all workspaces in the current tenant.
*   Project: The template is available only in the current workspace.', example='Project', position='Body'),
}

model CreateDataQualityRuleTemplateResponseBody = {
  code?: string(name='Code', description='The Code of the rule template.', example='UserDefined:3001'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model CreateDataQualityRuleTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityRuleTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDataQualityRuleTemplate  CreateDataQualityRuleTemplateRequest
  * @return CreateDataQualityRuleTemplateResponse
 */
async function createDataQualityRuleTemplate(request: CreateDataQualityRuleTemplateRequest): CreateDataQualityRuleTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityRuleTemplate', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  connectionProperties: string(name='ConnectionProperties', description='The connection configurations of the data source, including the connection address, access identity, and environment information. The envType parameter specifies the environment in which the data source is used. Valid values of the envType parameter:

*   Dev: development environment
*   Prod: production environment

The parameters that you need to configure for the data source vary based on the mode in which the data source is added. For more information, see [Data source connection information (ConnectionProperties)](https://help.aliyun.com/document_detail/2852465.html).

This parameter is required.', example='{
	"envType": "Prod",
	"regionId": "cn-beijing",
    "instanceId": "hgprecn-cn-x0r3oun4k001",
    "database": "testdb",
    "securityProtocol": "authTypeNone",
    "authType": "Executor",
    "authIdentity": "1107550004253538"
}', position='Query'),
  connectionPropertiesMode: string(name='ConnectionPropertiesMode', description='The mode in which you want to add the data source. The mode varies based on the data source type. Valid values for MySQL data sources:

*   InstanceMode: instance mode
*   UrlMode: connection string mode

This parameter is required.', example='UrlMode', position='Query'),
  description?: string(name='Description', description='The description of the data source. The description cannot exceed 3,000 characters in length.', example='this is a holo datasource', position='Query'),
  name: string(name='Name', description='The name of the data source. The name can be up to 255 characters in length and can contain letters, digits, and underscores (_). The name must start with a letter.

This parameter is required.', example='demo_holo_datasource', position='Query'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/overview) and go to the workspace management page to obtain the ID.

This parameter is used to determine the DataWorks workspaces used for this API call.

This parameter is required.', example='2', minimum=0, position='Query'),
  type: string(name='Type', description='The type of the data source. More than 70 types of data sources are supported in DataWorks. For more information, see [Data source types](https://help.aliyun.com/document_detail/2852465.html).

This parameter is required.', example='hologres', position='Query'),
}

model CreateDataSourceResponseBody = {
  id?: long(name='Id', description='The data source ID.', example='22130'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='B62EC203-B39E-5DC1-B5B8-EB3C61707009'),
}

model CreateDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of CreateDataSource  CreateDataSourceRequest
  * @return CreateDataSourceResponse
 */
async function createDataSource(request: CreateDataSourceRequest): CreateDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataSource', 'POST', '/', 'json', false, 'json', request);
}

model CreateDataSourceSharedRuleRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dataSourceId: long(name='DataSourceId', description='The data source ID.

This parameter is required.', example='144544', position='Query'),
  envType: string(name='EnvType', description='Share data sources to the target project environment, including
- Dev (Development Environment)
- Prod (production environment)

This parameter is required.', example='Dev', position='Query'),
  sharedUser?: string(name='SharedUser', description='The user with which you want to share the data source. If you do not configure this parameter, the data source is shared to an entire workspace.', example='1107550004253538', position='Query'),
  targetProjectId: long(name='TargetProjectId', description='The ID of the workspace to which you want to share the data source. You cannot share the data source to the workspace with which the data source is associated.

This parameter is required.', example='106560', position='Query'),
}

model CreateDataSourceSharedRuleResponseBody = {
  id?: long(name='Id', description='The sharing rule ID.', example='105412'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='46F594E6-84AB-5FA5-8144-6F3D149961E1'),
}

model CreateDataSourceSharedRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataSourceSharedRuleResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  If you want to share a data source from Workspace A to Workspace B, you must have the permissions to share the data source in both workspaces. You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Tenant Administrator, Workspace Administrator, and Workspace Owner
  * @param request  the request parameters of CreateDataSourceSharedRule  CreateDataSourceSharedRuleRequest
  * @return CreateDataSourceSharedRuleResponse
 */
async function createDataSourceSharedRule(request: CreateDataSourceSharedRuleRequest): CreateDataSourceSharedRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataSourceSharedRule', 'POST', '/', 'json', false, 'json', request);
}

model CreateFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  advancedSettings?: string(name='AdvancedSettings', example='{"queue":"default","SPARK_CONF":"--conf spark.driver.memory=2g"}', position='Body'),
  applyScheduleImmediately?: boolean(name='ApplyScheduleImmediately', example='true', position='Body'),
  autoParsing?: boolean(name='AutoParsing', example='true', position='Body'),
  autoRerunIntervalMillis?: int32(name='AutoRerunIntervalMillis', example='120000', position='Body'),
  autoRerunTimes?: int32(name='AutoRerunTimes', example='3', position='Body'),
  connectionName?: string(name='ConnectionName', example='odps_source', position='Body'),
  content?: string(name='Content', example='SHOW TABLES;', position='Body'),
  createFolderIfNotExists?: boolean(name='CreateFolderIfNotExists', example='false', position='Body'),
  cronExpress?: string(name='CronExpress', example='00 05 00 * * ?', position='Body'),
  cycleType?: string(name='CycleType', example='DAY', position='Body'),
  dependentNodeIdList?: string(name='DependentNodeIdList', example='abc', position='Body'),
  dependentType?: string(name='DependentType', example='NONE', position='Body'),
  endEffectDate?: long(name='EndEffectDate', example='1671694850000', minimum=0, position='Body'),
  fileDescription?: string(name='FileDescription', position='Body'),
  fileFolderPath?: string(name='FileFolderPath', example='Business_process/First_Business_Process/MaxCompute/Folder_1/Folder_2', position='Body'),
  fileName: string(name='FileName', description='This parameter is required.', example='File name', position='Body'),
  fileType: int32(name='FileType', description='This parameter is required.', example='10', position='Body'),
  ignoreParentSkipRunningProperty?: boolean(name='IgnoreParentSkipRunningProperty', example='false', position='Body'),
  imageId?: string(name='ImageId', example='m-bp1h4b5a8ogkbll2f3tr', position='Body'),
  inputList?: string(name='InputList', example='project_root,project.file1,project.001_out', position='Body'),
  inputParameters?: string(name='InputParameters', example='[{"ValueSource": "project_001.first_node:bizdate_param","ParameterName": "bizdate_input"}]', position='Body'),
  outputParameters?: string(name='OutputParameters', example='[{"Type": 1,"Value": "${bizdate}","ParameterName": "bizdate_param"}]', position='Body'),
  owner?: string(name='Owner', example='1000000000001', position='Body'),
  paraValue?: string(name='ParaValue', example='a=x b=y', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
  rerunMode?: string(name='RerunMode', example='ALL_ALLOWED', position='Body'),
  resourceGroupId?: long(name='ResourceGroupId', example='375827434852437', position='Body'),
  resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', example='S_res_group_559_1613715566828', position='Body'),
  schedulerType?: string(name='SchedulerType', example='NORMAL', position='Body'),
  startEffectDate?: long(name='StartEffectDate', example='1671608450000', minimum=0, position='Body'),
  startImmediately?: boolean(name='StartImmediately', example='true', position='Body'),
  stop?: boolean(name='Stop', example='false', position='Body'),
  timeout?: int32(name='Timeout', example='1', position='Body'),
}

model CreateFileResponseBody = {
  data?: long(name='Data', example='1000001'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG'),
  success?: boolean(name='Success', example='true'),
}

model CreateFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateFile  CreateFileRequest
  * @return CreateFileResponse
 */
async function createFile(request: CreateFileRequest): CreateFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateFile', 'POST', '/', 'json', true, 'form', request);
}

model CreateFolderRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  folderPath: string(name='FolderPath', description='This parameter is required.', example='Business_process/System_Data/MaxCompute/import_layer', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
}

model CreateFolderResponseBody = {
  data?: string(name='Data', example='bdfd68****'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG'),
  success?: boolean(name='Success', example='true'),
}

model CreateFolderResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateFolderResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateFolder  CreateFolderRequest
  * @return CreateFolderResponse
 */
async function createFolder(request: CreateFolderRequest): CreateFolderResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateFolder', 'POST', '/', 'json', true, 'form', request);
}

model CreateFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='12345', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the UDF. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
  "version": "1.1.0",
  "kind": "Function",
  "spec": {
    "functions": [
      {
        "name": "function name",
        "script": {
          "content": "{\\"name\\": \\"function name\\", \\"datasource\\": {\\"type\\": \\"ODPS\\", \\"name\\": \\"ODPS_first\\"}, \\"runtimeResource\\": {\\"resourceGroup\\": \\"s_res_group_xx_xxxx\\"}}",
          "path": "XXX/OpenAPI/function/function name",
          "runtime": {
            "command": "ODPS_FUNCTION"
          }
        },
        "datasource": {
          "name": "ODPS_first",
          "type": "ODPS"
        },
        "runtimeResource": {
          "resourceGroup": "S_res_group_XXXX_XXXX"
        }
      }
    ]
  }
}', position='Body'),
}

model CreateFunctionResponseBody = {
  id?: long(name='Id', description='The ID of the UDF.', example='580667964888595XXXX'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='AE49C88D-5BEE-5ADD-8B8C-C4BBC0D7XXXX'),
}

model CreateFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateFunctionResponseBody(name='body'),
}

/**
  * @description >  You cannot use this API operation to create multiple UDFs at a time. If you specify multiple UDFs by using FlowSpec, the system creates only the first specified UDF.
  * @param request  the request parameters of CreateFunction  CreateFunctionRequest
  * @return CreateFunctionResponse
 */
async function createFunction(request: CreateFunctionRequest): CreateFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateFunction', 'POST', '/', 'json', true, 'form', request);
}

model CreateLineageRelationshipRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dstEntity?: LineageEntity(name='DstEntity', shrink='json', position='Query'),
  srcEntity?: LineageEntity(name='SrcEntity', shrink='json', position='Query'),
  task?: LineageTask(name='Task', description='The task information.', shrink='json', position='Query'),
}

model CreateLineageRelationshipResponseBody = {
  id?: string(name='Id', description='The lineage ID.', example='110xxxx:custom-table.xxxxx:maxcompute-table.project.test_big_lineage_080901:custom-sqlxx.00001'),
  requestId?: string(name='RequestId', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADE490'),
  success?: boolean(name='Success', example='true'),
}

model CreateLineageRelationshipResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLineageRelationshipResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateLineageRelationship  CreateLineageRelationshipRequest
  * @return CreateLineageRelationshipResponse
 */
async function createLineageRelationship(request: CreateLineageRelationshipRequest): CreateLineageRelationshipResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateLineageRelationship', 'POST', '/', 'json', false, 'json', request);
}

model CreateMetaCollectionRequest {
  regionId?: string(name='RegionId', position='Host'),
  description?: string(name='Description', example='test comment', position='Query'),
  name: string(name='Name', description='This parameter is required.', example='test_album', position='Query'),
  parentId?: string(name='ParentId', description='The ID of the collection of an ancestor node.', example='category.123', position='Query'),
  type: string(name='Type', description='This parameter is required.', example='Category', position='Query'),
}

model CreateMetaCollectionResponseBody = {
  id?: string(name='Id', description='The ID of the created collection.', example='category.123'),
  requestId?: string(name='RequestId', description='Id of the request', example='E6F0DBDD-5AD****'),
}

model CreateMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateMetaCollection  CreateMetaCollectionRequest
  * @return CreateMetaCollectionResponse
 */
async function createMetaCollection(request: CreateMetaCollectionRequest): CreateMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateMetaCollection', 'POST', '/', 'json', false, 'json', request);
}

model CreateNetworkRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientToken: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.

This parameter is required.', example='eb870033-74c8-4b1b-9664-04c4e7cc3465', position='Body'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the serverless resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
  vpcId: string(name='VpcId', description='The ID of the virtual private cloud (VPC).

This parameter is required.', example='vpc-m2et4f3oc8msfbccXXXXX', position='Body'),
  vswitchId: string(name='VswitchId', description='The VSwitch ID.

This parameter is required.', example='vsw-uf8usrhs7hjd9amsXXXXX', position='Body'),
}

model CreateNetworkResponseBody = {
  id?: long(name='Id', description='The network ID.', example='1000'),
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateNetworkResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateNetworkResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of CreateNetwork  CreateNetworkRequest
  * @return CreateNetworkResponse
 */
async function createNetwork(request: CreateNetworkRequest): CreateNetworkResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateNetwork', 'POST', '/', 'json', true, 'form', request);
}

model CreateNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  containerId?: long(name='ContainerId', description='The container ID. If you want to create a node in a container, you must configure this parameter to specify the container. The container can be a workflow or a node in a container.

>  If you configure this parameter, the path field defined in FlowSpec becomes invalid.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='123456', position='Body'),
  scene: string(name='Scene', description='The scene of the node. This parameter determines the location (the DataStudio pane or the Manual pane) of the node. You can set this parameter to DataworksManualWorkflow only if the ContainerId parameter is configured and the container specified by ContainerId is a manually triggered workflow.

Valid values:

*   DataworksProject
*   DataworksManualWorkflow
*   DataworksManualTask

This parameter is required.', example='DATAWORKS_PROJECT', position='Body'),
  spec: string(name='Spec', description='{ "type": "object", "description": "CycleWorkflow the structure of the workflow configurations", "properties": { "version": { "type": "string", "description": "the version ID of the workflow configuration files" }, "kind": { "type": "string", "description": "the category ID of the workflow", "enum": [ "CycleWorkflow", "ManualWorkflow", "ManualNode", "TemporaryWorkflow", "PaiFlow", "BatchDeployment", "DataSource", "DataQuality", "DataService", "DataCatalog", "Table", "Node", "Component", "Resource", "Function", "Workflow" ] }, "spec": { "type": "object", "description": "the key configurations of the workflow", "properties": { "name": { "type": "string", "description": "the readable name identifier of the workflow" }, "id": { "type": "string", "description": "the UUID of the workflow" }, "type": { "type": "string", "description": "the type of the workflow instance", "enum": [ "CycleWorkflow", "ManualWorkflow" ] }, "owner": { "type": "string", "description": "the system user ID of the workflow owner" }, "description": { "type": "string", "description": "the detailed description of the features and usage of the workflow" }, "workflows": { "type": "array", "description": an array of node configurations in the workflow. The workflows can be run at the same time", "items": { "type": "object", "properties": { "script": { "type": "object", "description": "the script parameters", "properties": { "path": { "type": "string", "description": "the storage path of the script file. Example: HDFS/S3" }, "runtime": { "type": "object", "description": "the parameter settings for the runtime environment, such as the specifications of computing resources" }, "id": { "type": "string", "description": "the unique identifiers of the script parameters" } } }, "id": { "type": "string", "description": "the ID of the node in the workflow" }, "trigger": { "type": "object", "description": "the rule configurations to trigger the node“, "properties": { "type": { "type": "string", "enum": [ "Scheduler", "Manual", "Streaming", "None" ], "description": "the trigger type. Valid values: Scheduler, Manual, Streaming, and None" }, "id": { "type": "string", "description": "the trigger ID" }, "cron": { "type": "string", "description": "the scheduling rule of the node. The rule is in the cron expression format" }, "startTime": { "type": "string", "description": "the start time for scheduling. The value is in the ISO 8601 format" }, "endTime": { "type": "string", "description": "the end time for scheduling. The value is in the ISO 8601 format" }, "timezone": { "type": "string", "description": "the time zone. Example: UTC+8" }, "delaySeconds": { "type": "number", "description": "the delayed execution time. Unit: seconds" } } }, "strategy": { "type": "object", "description": "the execution policy parameters", "properties": { "timeout": { "type": "number", "description": "the timeout period. Unit: seconds" }, "instanceMode": { "type": "string", "enum": [ "T+1", "Immediately" ], "description": "the instance scheduling mode. Valid values: T+1 and Immediately" }, "rerunMode": { "type": "string", "enum": [ "Allowed", "Denied", "FailureAllowed" ], "description": "the rerun mode. Valid values: Allowed, Denied, and FailureAllowed" }, "rerunTimes": { "type": "number", "description": "the maximum number of reruns allowed after a failure" }, "rerunInterval": { "type": "number", "description": "the rerun interval. Unit: seconds" }, "failureStrategy": { "type": "string", "enum": [ "Continue", "Break" ], "description": "the failure handling policy. Valid values: Continue and Break" }, "recurrenceType": { "type": "string", "enum": [ "Normal", "Pause", "Skip", "NoneAuto" ], "description": "the running mode of the auto triggered node. Valid values: Normal, Pause, Skip, and NoneAuto" } } }, "name": { "type": "string", "description": "the readable name of the node" }, "owner": { "type": "string", "description": "the system ID of the node owner" }, "description": { "type": "string", "description": "the feature description of the node" }, "citable": { "type": "boolean", "description": "specifies whether the node can be referenced by other workflows. Valid values: true and false" }, "metadata": { "type": "object", "description": "the container that stores the metadata information", "properties": { "owner": { "type": "string", "description": "the metadata owner ID" }, "project": { "type": "object", "properties": { "projectIdentifier": { "type": "string", "description": "the unique code of the project" }, "projectName": { "type": "string", "description": "the project name" }, "projectId": { "type": "string", "Description": "the project ID" } } }, "ownerName": { "type": "string", "description": "the name of the project owner" }, "projectId": { "type": "string", "description": "the ID of the associated project" } } }, "inputs": { "type": "object", "description": "the structure of the node input", "properties": { "nodeOutputs": { "type": "array", "description": "the configuration items for node input", "items": { "type": "object", "properties": { "data": { "type": "string", "description": "the content of the node input" }, "artifactType": { "type": "string", "enum": [ "Table", "File", "NodeOutput", "Variable" ], "description": "the type of the node input. Valid values: Table, File, NodeOutput, and Variable" }, "refTableName": { "type": "string", "description": "the name of the referenced table" }, "isDefault": { "type": "boolean", "description": "specifies whether the table is the default output“ } } } }, "tables": { "type": "array", "description": "the metadata collection in the input table", "items": { "type": "object", "properties": { "artifactType": { "type": "string", "enum": [ "Table", "File", "NodeOutput", "Variable" ], "description": "the type of the table" }, "guid": { "type": "string", "description": "the GUID of the table" } } } } } }, "outputs": { "type": "object", "description": "the structure of the node output", "properties": { "nodeOutputs": { "type": "array", "description": "the configuration items for node output", "items": { "type": "object", "properties": { "data": { "type": "string", "description": "the content of the node output" }, "artifactType": { "type": "string", "enum": [ "Table", "File", "NodeOutput", "Variable" ], "description": "the type of the node output. Valid values: Table, File, NodeOutput, and Variable" }, "refTableName": { "type": "string", "description": "the name of the referenced table" }, "isDefault": { "type": "boolean", "description": "specifies whether the table is the default output“ } } } }, "tables": { "type": "array", "description": "the metadata collection in the output table", "items": { "type": "object", "properties": { "artifactType": { "type": "string", "enum": [ "Table", "File", "NodeOutput", "Variable" ], "description": "the type of the table" }, "guid": { "type": "string", "description": "the GUID of the table" } } } } } }, "nodes": { "type": "array", "description": "the configuration items for descendant nodes that are used for workflow nesting", "items": { "type": "object", "properties": { "recurrence": { "type": "string", "enum": [ "Normal", "Pause", "Skip", "NoneAuto" ], "description": "the running mode of the descendant node" }, "id": { "type": "string", "description": "the descendant node ID" }, "timeout": { "type": "number", "description": "the timeout period of the descendant node. Unit: seconds" }, "instanceMode": { "type": "string", "enum": [ "T+1", "Immediately" ], "description": "the instance scheduling mode of the descendant node. Valid values: T+1 and Immediately" }, "rerunMode": { "type": "string", "enum": [ "Allowed", "Denied", "FailureAllowed" ], "description": "the rerun mode of the descendant node" }, "rerunTimes": { "type": "number", "description": "the maximum number of reruns allowed after a failure for the descendant node" }, "rerunInterval": { "type": "number", "description": "the rerun interval" }, "datasource": { "type": "object", "description": "the parameters of the associated data source", "properties": { "name": { "type": "string", "description": "the name of the data source" }, "type": { "type": "string", "description": "the type of the data source. Examples: MySQL and Oracle" } } }, "script": { "type": "object", "description": "the script configurations of the node", "properties": { "language": { "type": "string", "enum": [ "python2", "python3", "java8", "java11", "java17" ], "description": "the programming language of the script" }, "path": { "type": "string", "description": "the storage path of the code" }, "runtime": { "type": "object", "description": "the configurations of the runtime environment" }, "content": { "type": "string", "description": "the content of the inline script" }, "id": { "type": "string", "description": "the identifier of the script content" }, "parameters": { "type": "array", "description": "the parameters for initialization", "items": { "type": "object", "properties": { "name": { "type": "string", "description": "the identifier of the parameter name" }, "artifactType": { "type": "string", "enum": [ "Table", "File", "NodeOutput", "Variable" ], "description": "the identifier of the data type" }, "scope": { "type": "string", "enum": [ "Tenant", "Workspace", "Workflow", "NodeParameter", "NodeContext" ], "description": "the application scope of the parameter" }, "type": { "type": "string", "enum": [ "NoKvVariableExpression", "System", "Constant", "NodeOutput", "PaiOutput", "PassThrough" ], "description": "the type of the parameter" }, "value": { "type": "string", "description": "the default value of the parameter" }, "id": { "type": "string", "description": "the parameter ID" } } } } } }, "trigger": { "type": "object", "description": "the configurations of the trigger at the node level. You can overwrite or inherit the configurations" }, "runtimeResource": { "type": "object", "description": "the configurations of computing resources, such as CPU and memory" }, "name": { "type": "string", "description": "the readable name of the descendant node" }, "owner": { "type": "string", "description": "the ID of the descendant node owner" }, "metadata": { "type": "object", "description": "the extended metadata of the descendant node" }, "inputs": { "type": "object", "description": "the parameter definitions of the node input" }, "outputs": { "type": "object", "description": "the parameter definitions of the node output" } } } }, "dependencies": { "type": "array", "description": "the node dependencies", "items": { "type": "object", "properties": { "nodeId": { "type": "string", "description": "the ID of the current node" }, "depends": { "type": "array", "description": "the ancestor node output", "items": { "type": "object", "properties": { "type": { "type": "string", "enum": [ "Normal", "CrossCycleDependsOnSelf", "CrossCycleDependsOnChildren", "CrossCycleDependsOnOtherNode" ], "description": "the dependency type. Valid values: Normal, CrossCycleDependsOnSelf, CrossCycleDependsOnChildren, and CrossCycleDependsOnOtherNode" }, "output": { "type": "string", "description": "the unique identifier of the ancestor node output" }, "refTableName": { "type": "string", "description": "the identifier of the referenced table name" } } } } } } } } } }, "metadata": { "type": "object", "description": "the high-level metadata of the workflow", "properties": { "innerVersion": { "type": "object", "description": "the mappings between the versions of components", "additionalProperties": { "type": "number" } }, "gmtModified": { "type": "number", "description": "the last modification time. The value is a UNIX timestamp" }, "projectId": { "type": "string", "description": "the ID of the associated project" }, "uuid": { "type": "string", "description": "the GUID of the instance" } } } } } }, "required": [ "version", "kind", "spec" ] }

This parameter is required.', example='{
  "version": "1.1.0",
  "kind": "Node",
  "spec": {
    "nodes": [
      {
        "id": "860438872620113XXXX",
        "recurrence": "Normal",
        "timeout": 0,
        "instanceMode": "T+1",
        "rerunMode": "Allowed",
        "rerunTimes": 3,
        "rerunInterval": 180000,
        "datasource": {
          "name": "ODPS_test",
          "type": "ODPS"
        },
        "script": {
          "path": "XX/OpenAPI test/odpsSQL test",
          "runtime": {
            "command": "ODPS_SQL"
          },
          "content": "select now();"
        },
        "trigger": {
          "type": "Scheduler",
          "cron": "00 00 00 * * ?",
          "startTime": "1970-01-01 00:00:00",
          "endTime": "9999-01-01 00:00:00",
          "timezone": "Asia/Shanghai",
          "delaySeconds": 0
        },
        "runtimeResource": {
          "resourceGroup": "S_res_group_XXXX_XXXX"
        },
        "name": "odpsSQL test",
        "inputs": {
          "nodeOutputs": [
            {
              "data": "lwttest_standard_root",
              "artifactType": "NodeOutput"
            }
          ]
        },
        "outputs": {
          "nodeOutputs": [
            {
              "data": "output_data",
              "artifactType": "NodeOutput",
              "refTableName": "odpsSQL test"
            }
          ]
        }
      }
    ],
    "flow": [
      {
        "nodeId": "860438872620113XXXX",
        "depends": [
          {
            "type": "Normal",
            "output": "project_root"
          }
        ]
      }
    ]
  }
}', position='Body'),
}

model CreateNodeResponseBody = {
  id?: long(name='Id', description='The ID of the node.', example='860438872620113XXXX'),
  requestId?: string(name='RequestId', description='The request ID.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
}

model CreateNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateNodeResponseBody(name='body'),
}

/**
  * @description >  You cannot use this API operation to create multiple nodes at a time. If you specify multiple nodes by using FlowSpec, the system creates only the first specified node.
  * @param request  the request parameters of CreateNode  CreateNodeRequest
  * @return CreateNodeResponse
 */
async function createNode(request: CreateNodeRequest): CreateNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateNode', 'POST', '/', 'json', true, 'form', request);
}

model CreatePipelineRunRequest {
  regionId?: string(name='RegionId', description='区域id

This parameter is required.', position='Host'),
  description?: string(name='Description', description='The description of the process.', example='This is a OdpsSQL-node publishing process. The function is XXXX.', position='Body'),
  objectIds: [ string ](name='ObjectIds', description='The IDs of entities to which you want to apply the process.

>  A process can be applied to only a single entity and its child entities. If you specify multiple entities in the array, the process is applied only to the first entity in the array and its child entities. Make sure that the array in your request contains only one element. Extra elements will be ignored.

This parameter is required.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID. You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
  type: string(name='Type', description='Specifies whether to deploy or undeploy the entity. Valid values:

*   Online: deploys the entity.
*   Offline: undeploys the entity.

This parameter is required.', example='Online', position='Body'),
}

model CreatePipelineRunResponseBody = {
  id?: string(name='Id', description='The ID of the process.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX'),
  requestId?: string(name='RequestId', description='The request ID.', example='7C352CB7-CD88-50CF-9D0D-E81BDF02XXXX'),
}

model CreatePipelineRunResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreatePipelineRunResponseBody(name='body'),
}

/**
  * @description >  You cannot use this API operation to create a process for multiple entities at a time. If you specify multiple entities in a request, the system creates a process only for the first entity.
  * @param request  the request parameters of CreatePipelineRun  CreatePipelineRunRequest
  * @return CreatePipelineRunResponse
 */
async function createPipelineRun(request: CreatePipelineRunRequest): CreatePipelineRunResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreatePipelineRun', 'POST', '/', 'json', true, 'form', request);
}

model CreateProjectRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group to which the workspace belongs. You can log on to the [Resource Management console](https://resourcemanager.console.aliyun.com/resource-groups) and go to the Resource Group page to query the ID.

You must configure this parameter to specify an Alibaba Cloud resource group for the workspace that you want to create.', example='rg-acfmzbn7pti3zff', position='Body'),
  aliyunResourceTags?: [ 
    {
      key?: string(name='Key', description='The tag key.', example='batch'),
      value?: string(name='Value', description='The tag value.', example='blue'),
    }
  ](name='AliyunResourceTags', description='The tags.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description of the workspace.', example='Financial analysis group project data development', position='Body'),
  devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Specifies whether to enable the development environment. Valid values:

*   true : enables the development environment. In this case, the development environment is isolated from the production environment in the workspace.
*   false: disables the development environment. In this case, only the production environment is used in the workspace.', example='false', position='Body'),
  devRoleDisabled?: boolean(name='DevRoleDisabled', description='Specifies whether to disable the Develop role. Valid values:

*   false (default)
*   true', example='true', position='Body'),
  displayName: string(name='DisplayName', description='The display name of the workspace.

This parameter is required.', example='Sora financial analysis', position='Body'),
  name: string(name='Name', description='The name of the workspace.

Limits:

*   The workspace name must be unqiue in a region.
*   The workspace name can contain letters, digits, and underscores (_), and must start with a letter.
*   The workspace name must be 3 to 28 characters in length.

This parameter is required.', example='sora_finance', position='Body'),
  paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Specifies whether to enable scheduling of Platform for AI (PAI) tasks. Valid values:

*   true: enables scheduling of PAI tasks. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: disables scheduling of PAI tasks.', example='true', position='Body'),
}

model CreateProjectResponseBody = {
  id?: long(name='Id', description='The workspace ID.', example='123456'),
  projectId?: long(name='ProjectId', description='The workspace ID. Note: This parameter is deprecated and is replaced by the Id parameter.', example='123456', deprecated='true'),
  requestId?: string(name='RequestId', description='The request ID.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
}

model CreateProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateProject  CreateProjectRequest
  * @return CreateProjectResponse
 */
async function createProject(request: CreateProjectRequest): CreateProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateProject', 'POST', '/', 'json', true, 'form', request);
}

model CreateProjectMemberRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='24054', position='Body'),
  roleCodes: [ string ](name='RoleCodes', description='The codes of the roles in the workspace. You can call the [ListProjectRoles](https://help.aliyun.com/document_detail/2853930.html) operation to query the codes of all roles in the workspace.

This parameter specifies the roles that you can assign to a member when you add the member.

This parameter is required.', shrink='json', position='Body'),
  userId: string(name='UserId', description='The ID of the account that you want to add to the workspace as a member. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click **Tenant Members and Roles**. On the Tenant Members and Roles page, view the ID of the account that you want to add to the workspace as a member.

This parameter is required.', example='123422344899', position='Body'),
}

model CreateProjectMemberResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='2B2F0B26-9253-5780-B6DB-F1A886D44D6F'),
}

model CreateProjectMemberResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateProjectMemberResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of CreateProjectMember  CreateProjectMemberRequest
  * @return CreateProjectMemberResponse
 */
async function createProjectMember(request: CreateProjectMemberRequest): CreateProjectMemberResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateProjectMember', 'POST', '/', 'json', true, 'form', request);
}

model CreateResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group.', example='rg-aek2kqofrgXXXXX', position='Body'),
  aliyunResourceTags?: [ 
    {
      key?: string(name='Key', description='The tag key.', example='key'),
      value?: string(name='Value', description='The tag value.', example='value'),
    }
  ](name='AliyunResourceTags', description='The tags.', shrink='json', position='Body'),
  autoRenewEnabled?: boolean(name='AutoRenewEnabled', description='Specifies whether to enable auto-renewal.', position='Body'),
  clientToken: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.

This parameter is required.', example='eb870033-74c8-4b1b-9664-04c4e7cc3465', position='Body'),
  name: string(name='Name', description='The name of the serverless resource group. The name can be a maximum of 128 characters in length and can contain letters, digits, and underscores (_). The name must start with a letter.

This parameter is required.', example='common_resource_group', position='Body'),
  paymentDuration?: int32(name='PaymentDuration', description='The subscription duration.', example='1', position='Body'),
  paymentDurationUnit?: string(name='PaymentDurationUnit', description='The unit of the subscription duration. Valid values: Month and Year.', example='Month', position='Body'),
  paymentType: string(name='PaymentType', description='The billing method of the serverless resource group. Valid values: PrePaid and PostPaid. The value PrePaid indicates the subscription billing method, and the value PostPaid indicates the pay-as-you-go billing method.

This parameter is required.', example='PrePaid', position='Body'),
  remark?: string(name='Remark', description='The description of the serverless resource group. The description can be a maximum of 128 characters in length and can contain letters, digits, and underscores (_).', example='Create a serverless resource group for common tasks', position='Body'),
  spec?: int32(name='Spec', description='The specifications of the serverless resource group. Unit: CU. This parameter is required only if you set the PaymentType parameter to PrePaid.', example='2', position='Body'),
  vpcId: string(name='VpcId', description='The ID of the virtual private cloud (VPC) with which the serverless resource group is associated by default.

This parameter is required.', example='vpc-m2et4f3oc8msfbccXXXXX', position='Body'),
  vswitchId: string(name='VswitchId', description='The ID of the vSwitch with which the serverless resource group is associated by default.

This parameter is required.', example='vsw-uf8usrhs7hjd9amsXXXXX', position='Body'),
}

model CreateResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  resourceGroupOrder?: {
    id?: string(name='Id', description='The ID of the serverless resource group.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
    orderId?: long(name='OrderId', description='The ID of the order that is used to create the serverless resource group.', example='2391982058XXXXX'),
    orderInstanceId?: string(name='OrderInstanceId', description='The instance ID of the order that is used to create the serverless resource group.', example='c442b330-3b10-4584-959e-736e4edXXXXX'),
  }(name='ResourceGroupOrder', description='The information about the order that is used to create the serverless resource group.'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateResourceGroupResponseBody(name='body'),
}

/**
  * @description 1.  You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * 2.  **Before you call this API operation, you must make sure that you have a good command of the billing details and [pricing](https://help.aliyun.com/document_detail/2680173.html) of serverless resource groups.
  * @param request  the request parameters of CreateResourceGroup  CreateResourceGroupRequest
  * @return CreateResourceGroupResponse
 */
async function createResourceGroup(request: CreateResourceGroupRequest): CreateResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model CreateRouteRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  destinationCidr: string(name='DestinationCidr', description='The CIDR blocks of the destination-based route.

This parameter is required.', example='192.168.0.0/16', position='Body'),
  networkId: long(name='NetworkId', description='The network ID.

This parameter is required.', example='1000', position='Body'),
  resourceGroupId?: string(name='ResourceGroupId', description='Unique identifier of the serverless resource group.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
}

model CreateRouteResponseBody = {
  id?: long(name='Id', description='The route ID.', example='1000'),
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateRouteResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateRouteResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of CreateRoute  CreateRouteRequest
  * @return CreateRouteResponse
 */
async function createRoute(request: CreateRouteRequest): CreateRouteResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateRoute', 'POST', '/', 'json', true, 'form', request);
}

model CreateUdfFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  className: string(name='ClassName', description='This parameter is required.', example='com.alibaba.DataWorks.api.udf.StringConcat', position='Body'),
  cmdDescription?: string(name='CmdDescription', example='StringConcat(String... substrs)', position='Body'),
  createFolderIfNotExists?: boolean(name='CreateFolderIfNotExists', example='false', position='Body'),
  example?: string(name='Example', example='StringConcat(\\"a\\", \\"b\\", \\"c\\")', position='Body'),
  fileFolderPath: string(name='FileFolderPath', description='This parameter is required.', example='Business_process/First_Business_Process/function/string_processing', position='Body'),
  fileName: string(name='FileName', description='This parameter is required.', example='StringConcat', position='Body'),
  functionType: string(name='FunctionType', description='This parameter is required.', example='STRING', position='Body'),
  parameterDescription?: string(name='ParameterDescription', example='List of strings to be connected', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
  resources: string(name='Resources', description='This parameter is required.', example='string-concat-1.0.0.jar,commons-lang-2.6.jar', position='Body'),
  returnValue?: string(name='ReturnValue', example='New strings generated by concatenating all strings before and after the input order', position='Body'),
  udfDescription?: string(name='UdfDescription', example='Concatenate several strings to generate a new string', position='Body'),
}

model CreateUdfFileResponseBody = {
  data?: long(name='Data', example='100000002'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model CreateUdfFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateUdfFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateUdfFile  CreateUdfFileRequest
  * @return CreateUdfFileResponse
 */
async function createUdfFile(request: CreateUdfFileRequest): CreateUdfFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateUdfFile', 'POST', '/', 'json', true, 'form', request);
}

model CreateWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the workflow. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow/).

This parameter is required.', example='{
    "kind": "CycleWorkflow",
    "version": "1.1.0",
    "spec": {
        "name": "OpenAPITestWorkflowDemo",
        "type": "CycleWorkflow",
        "workflows": [
            {
                "script": {
                    "path": "XX/OpenAPITest/WorkflowTest/OpenAPITestWorkflowDemo",
                    "runtime": {
                        "command": "WORKFLOW"
                    }
                },
                "trigger": {
                    "type": "Scheduler",
                    "cron": "00 02 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "strategy": {
                    "timeout": 0,
                    "instanceMode": "T+1",
                    "rerunMode": "Allowed",
                    "rerunTimes": 3,
                    "rerunInterval": 180000,
                    "failureStrategy": "Break"
                },
                "name": "OpenAPITestWorkflowDemo",
                "inputs": {},
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "workflow_output",
                            "artifactType": "NodeOutput",
                            "refTableName": "OpenAPITestWorkflowDemo"
                        }
                    ]
                },
                "nodes": [],
                "dependencies": []
            }
        ]
    }
}', position='Body'),
}

model CreateWorkflowDefinitionResponseBody = {
  id?: long(name='Id', description='The ID of the workflow.', example='463497880880954XXXX'),
  requestId?: string(name='RequestId', description='The request ID.', example='0EF298E5-0940-5AC7-9CB0-65025070XXXX'),
}

model CreateWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @description > You cannot use this API operation to create multiple workflows at a time. If you specify multiple workflows by using FlowSpec, the system creates only the first specified workflow. Other specified workflows and the nodes in the workflows are ignored. You can call the CreateNode operation to create a node.
  * @param request  the request parameters of CreateWorkflowDefinition  CreateWorkflowDefinitionRequest
  * @return CreateWorkflowDefinitionResponse
 */
async function createWorkflowDefinition(request: CreateWorkflowDefinitionRequest): CreateWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model CreateWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  autoStartEnabled?: boolean(name='AutoStartEnabled', description='The default value is true.', example='true', position='Body'),
  comment?: string(name='Comment', description='The reason for the creation.', example='create for test', position='Body'),
  defaultRunProperties?: {
    alert?: {
      noticeType?: string(name='NoticeType', description='The alert notification method. Valid values:

*   Sms
*   Mail
*   SmsMail', example='Sms'),
      type?: string(name='Type', description='The alerting policy. Valid values:

*   SUCCESS: An alert is reported when data backfill succeeds.
*   FAILURE: An alert is reported when data backfill fails.
*   SuccessFailure: An alert is reported regardless of whether data backfill succeeds or fails.', example='Succes'),
    }(name='Alert', description='The alert settings.'),
    analysis?: {
      blocked?: boolean(name='Blocked', description='Specifies whether to block the running of the instance if the analysis fails. If you set the Type parameter to SupplementData, this parameter is required.', example='true'),
      enabled?: boolean(name='Enabled', description='Specifies whether to enable the analysis feature. If you set the Type parameter to SupplementData, this parameter is required.', example='true'),
    }(name='Analysis', description='The configurations for analysis. If you set the Type parameter to SupplementData, this parameter is required.'),
    excludeProjectIds?: [ long ](name='ExcludeProjectIds', description='The IDs of the projects that do not need to be run.'),
    excludeTaskIds?: [ long ](name='ExcludeTaskIds', description='The IDs of the tasks that do not need to be run.'),
    includeProjectIds?: [ long ](name='IncludeProjectIds', description='The IDs of the projects that need to be run.'),
    includeTaskIds?: [ long ](name='IncludeTaskIds', description='The IDs of the tasks that need to be run.'),
    mode?: string(name='Mode', description='The data backfill mode. Default value: ManualSelection. If you set the Type parameter to SupplementData, this parameter is required. Valid values:

*   General: You can specify only `one root task ID`. The `IncludeTaskIds` parameter is optional. If you do not configure the IncludeTaskIds parameter, the tasks that are specified by the `RootTaskIds` parameter are included by default.
*   ManualSelection: You can specify `multiple root task IDs`. The `IncludeTaskIds` parameter is optional. If you do not configure the IncludeTaskIds parameter, the tasks that are specified by the `RootTaskIds` parameter are included by default.
*   Chain: If you set the Mode parameter to Chain, you must leave the `RootTaskIds` parameter empty and set the `IncludeTaskIds` parameter to the start task ID and the end task ID.
*   AllDownstream: You can specify only one `root task ID`.', example='ManualSelection'),
    order?: string(name='Order', description='The running order. Default value: Asc. Valid values:

*   Asc: The tasks are sorted by data timestamp in ascending order.
*   Desc: The tasks are sorted by data timestamp in descending order.', example='Asc'),
    parallelism?: int32(name='Parallelism', description='The number of tasks that can be run in parallel. If you specify a value that ranges from 2 to 10, the value indicates the number of tasks that can be run in parallel. If you set the value to 1, the tasks are run one by one. If you set the Type parameter to SupplementData, this parameter is required.', example='2'),
    priority?: int32(name='Priority'),
    priorityWeightStrategy?: string(name='PriorityWeightStrategy'),
    rootTaskIds?: [ long ](name='RootTaskIds', description='The root task IDs.

*   If you set the Type parameter to SupplementData and the Mode parameter to a value other than Chain, the RootTaskIds parameter is required.
*   If you set the Type parameter to ManualWorkflow, the RootTaskIds parameter is optional. If you do not configure the RootTaskIds parameter, the IDs of the default root nodes of the manually triggered workflow are used.
*   If you set the Type parameter to Manual, the RootTaskIds parameter is required. The RootTaskIds parameter specifies the IDs of the manually triggered tasks that need to be run.
*   If you set the Type parameter to SmokeTest, the RootTaskIds parameter is required. The RootTaskIds parameter specifies the IDs of the test tasks that need to be run.'),
    runPolicy?: {
      endTime?: string(name='EndTime', description='The end time of running. Configure this parameter in the `hh:mm:ss` format. The time must be in the 24-hour clock. This parameter is required if you configure the RunPolicy parameter.', example='23:59:59'),
      immediately?: boolean(name='Immediately', description='Specifies whether the instance can be run immediately during the time period in the future. Default value: false.', example='false'),
      startTime?: string(name='StartTime', description='The start time of running. Configure this parameter in the `hh:mm:ss` format. The time must be in the 24-hour clock. This parameter is required if you configure the RunPolicy parameter.', example='00:00:00'),
      type?: string(name='Type', description='The type of the time period during which the data is backfilled. This parameter is required if you configure the RunPolicy parameter.

*   Daily
*   Weekend', example='Daily'),
    }(name='RunPolicy', description='The policy for running. If you leave this parameter empty, the runtime configuration is used.'),
    runtimeResource?: string(name='RuntimeResource', description='The identifier of the custom resource group for scheduling. If you leave this parameter empty, the runtime configuration is used.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
  }(name='DefaultRunProperties', description='The runtime configuration.', shrink='json', position='Body'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod', position='Body'),
  name: string(name='Name', description='The name.

This parameter is required.', example='WorkflowInstance1', position='Body'),
  periods?: {
    bizDates: [ 
      {
        endBizDate: string(name='EndBizDate', description='The data timestamp at which data is no longer backfilled. Configure this parameter in the `yyyy-mm-dd` format.

This parameter is required.', example='2024-11-24'),
        startBizDate: string(name='StartBizDate', description='The data timestamp at which the data starts to be backfilled. Configure this parameter in the `yyyy-mm-dd` format.

This parameter is required.', example='2024-11-20'),
      }
    ](name='BizDates', description='The data timestamps. You can specify up to seven data timestamps.

This parameter is required.'),
    endTime?: string(name='EndTime', description='The end time of data backfill. Configure this parameter in the `hh:mm:ss` format. The time must be in the 24-hour clock. Default value: 23:59:59.

If you configure this parameter, you must also configure the StartTime parameter.', example='23:59:59'),
    startTime?: string(name='StartTime', description='The start time of data backfill. Configure this parameter in the `hh:mm:ss` format. The time must be in the 24-hour clock. Default value: 00:00:00.

If you configure this parameter, you must also configure the EndTime parameter.', example='00:00:00'),
  }(name='Periods', description='The configuration of the data backfilling period.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The project ID.

This parameter is required.', example='100', position='Body'),
  taskParameters?: string(name='TaskParameters', description='The task-specific parameters. The value is in the JSON format. The key specifies the task ID. You can call the GetTask operation to obtain the format of the value by querying the script parameters.', example='{
  "1001": "key1=val2 key2=val2", 
  "1002": "key1=val2 key2=val2"
}', position='Body'),
  type: string(name='Type', description='The type of the workflow instance. Valid values:

*   SupplementData: The values of the RootTaskIds and IncludeTaskIds parameters vary based on the value of the Mode parameter. For more information, see the Mode parameter in this API operation.
*   ManualWorkflow: If you set the Type parameter to ManualWorkflow, you must set the WorkflowId parameter to the ID of the manually triggered workflow. The RootTaskIds parameter is optional. If you do not configure the RootTaskIds parameter, the IDs of the default root nodes of the manually triggered workflow are used.
*   Manual: You need to configure only the RootTaskIds parameter. The RootTaskIds parameter specifies the IDs of the manually triggered tasks that need to be run.
*   SmokeTest: You need to configure only the RootTaskIds parameter. The RootTaskIds parameter specifies the IDs of the test tasks that need to be run.

This parameter is required.', example='SupplementData', position='Body'),
  workflowId: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs. This parameter is set to 1 for auto triggered tasks.

This parameter is required.', example='1', position='Body'),
  workflowParameters?: string(name='WorkflowParameters', description='The workflow parameters. The priority of workflow parameters is higher than that of task parameters. You can call the GetTask operation to obtain the format of the workflow parameters by querying the Parameters parameter.', example='{ 
  "key1": "value1", 
  "key2": "value2" 
}', position='Body'),
}

model CreateWorkflowInstancesResponseBody = {
  operationId?: string(name='OperationId', description='The ID of the operation. You can use this field to query the results of the creation operation through the GetCreateWorkflowInstancesResult interface.', example='e15ad21c-b0e9-4792-8f55-b037xxxxxxxx'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model CreateWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateWorkflowInstancesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateWorkflowInstances  CreateWorkflowInstancesRequest
  * @return CreateWorkflowInstancesResponse
 */
async function createWorkflowInstances(request: CreateWorkflowInstancesRequest): CreateWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model DeleteAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The rule ID.', example='105412', position='Body'),
}

model DeleteAlertRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='8754EE08-4AA2-5F77-ADD7-754DBBDA9F75'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteAlertRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteAlertRule  DeleteAlertRuleRequest
  * @return DeleteAlertRuleResponse
 */
async function deleteAlertRule(request: DeleteAlertRuleRequest): DeleteAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteAlertRule', 'POST', '/', 'json', true, 'form', request);
}

model DeleteBusinessRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  businessId: long(name='BusinessId', description='This parameter is required.', example='1000001', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
}

model DeleteBusinessResponseBody = {
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model DeleteBusinessResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteBusinessResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteBusiness  DeleteBusinessRequest
  * @return DeleteBusinessResponse
 */
async function deleteBusiness(request: DeleteBusinessRequest): DeleteBusinessResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteBusiness', 'POST', '/', 'json', true, 'form', request);
}

model DeleteCertificateRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the certificate file.

This parameter is required.', example='676303114031776', position='Query'),
  projectId?: long(name='ProjectId', description='The ID of the workspace to which the certificate file belongs.', example='106560', position='Query'),
}

model DeleteCertificateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='D9A61DC0-B922-421B-B706'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteCertificateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCertificateResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks: Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M.
  * @param request  the request parameters of DeleteCertificate  DeleteCertificateRequest
  * @return DeleteCertificateResponse
 */
async function deleteCertificate(request: DeleteCertificateRequest): DeleteCertificateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteCertificate', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDIAlarmRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIAlarmRuleId?: long(name='DIAlarmRuleId', description='This parameter is deprecated. Use the Id parameter instead.', example='2', deprecated='true', position='Query'),
  DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='1', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='2', position='Query'),
}

model DeleteDIAlarmRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADE490'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteDIAlarmRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDIAlarmRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDIAlarmRule  DeleteDIAlarmRuleRequest
  * @return DeleteDIAlarmRuleResponse
 */
async function deleteDIAlarmRule(request: DeleteDIAlarmRuleRequest): DeleteDIAlarmRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDIAlarmRule', 'GET', '/', 'json', false, 'json', request);
}

model DeleteDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='11126', deprecated='true', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11126', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='108864', position='Query'),
}

model DeleteDIJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can troubleshoot issues based on the ID.', example='D33D4A51-5845-579A-B4BA-FAADD0F83D53'),
  success?: boolean(name='Success', description='true', example='true'),
}

model DeleteDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteDIJob  DeleteDIJobRequest
  * @return DeleteDIJobResponse
 */
async function deleteDIJob(request: DeleteDIJobRequest): DeleteDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDIJob', 'GET', '/', 'json', false, 'json', request);
}

model DeleteDataAssetTagRequest {
  regionId?: string(name='RegionId', position='Host'),
  key: string(name='Key', description='The tag key.

This parameter is required.', example='key1', minLength=1, maxLength=128, position='Query'),
  values?: [ string ](name='Values', description='The tag values.', shrink='json', position='Query'),
}

model DeleteDataAssetTagResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1411515937635973****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteDataAssetTagResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataAssetTagResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of DeleteDataAssetTag  DeleteDataAssetTagRequest
  * @return DeleteDataAssetTagResponse
 */
async function deleteDataAssetTag(request: DeleteDataAssetTagRequest): DeleteDataAssetTagResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataAssetTag', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDataQualityEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The ID of the data quality monitor.', example='123123', position='Query'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the workspace management page to obtain the ID.

This parameter is used to determine the DataWorks workspaces used for this API call.', example='10000', position='Query'),
}

model DeleteDataQualityEvaluationTaskResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='0bc1ec92159376****'),
  success?: boolean(name='Success', description='Whether the deletion is successful.
- true: Successful
- false: Failed', example='true'),
}

model DeleteDataQualityEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataQualityEvaluationTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDataQualityEvaluationTask  DeleteDataQualityEvaluationTaskRequest
  * @return DeleteDataQualityEvaluationTaskResponse
 */
async function deleteDataQualityEvaluationTask(request: DeleteDataQualityEvaluationTaskRequest): DeleteDataQualityEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataQualityEvaluationTask', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDataQualityRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id: long(name='Id', description='The rule ID.

This parameter is required.', example='19715', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='17302', position='Query'),
}

model DeleteDataQualityRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteDataQualityRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataQualityRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDataQualityRule  DeleteDataQualityRuleRequest
  * @return DeleteDataQualityRuleResponse
 */
async function deleteDataQualityRule(request: DeleteDataQualityRuleRequest): DeleteDataQualityRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataQualityRule', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDataQualityRuleTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  code: string(name='Code', description='The code for the template.

This parameter is required.', example='USER_DEFINED:123', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10001', position='Query'),
}

model DeleteDataQualityRuleTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteDataQualityRuleTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataQualityRuleTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDataQualityRuleTemplate  DeleteDataQualityRuleTemplateRequest
  * @return DeleteDataQualityRuleTemplateResponse
 */
async function deleteDataQualityRuleTemplate(request: DeleteDataQualityRuleTemplateRequest): DeleteDataQualityRuleTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataQualityRuleTemplate', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The data source ID.

This parameter is required.', example='1234', position='Query'),
}

model DeleteDataSourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='B56432E0-2112-5C97-88D0-AA0AE5C75C74'),
  success?: boolean(name='Success', description='Whether the call is successful.
- true: Successful
- false: Failed', example='true'),
}

model DeleteDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all Dataworks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of DeleteDataSource  DeleteDataSourceRequest
  * @return DeleteDataSourceResponse
 */
async function deleteDataSource(request: DeleteDataSourceRequest): DeleteDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataSource', 'GET', '/', 'json', false, 'json', request);
}

model DeleteDataSourceSharedRuleRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The sharing rule ID.

This parameter is required.', example='22127', position='Query'),
}

model DeleteDataSourceSharedRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='64B-587A-8CED-969E1973887FXXX-TT'),
  success?: boolean(name='Success', description='Whether the data source sharing rule is deleted successfully. The value is as follows:
-true: The request is successful.
-false: The request failed.', example='true'),
}

model DeleteDataSourceSharedRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataSourceSharedRuleResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  If you want to delete a sharing rule of a data source from Workspace A to Workspace B, you must have the permissions to share the data source in Workspace A or Workspace B. You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Tenant Administrator, Workspace Administrator, and Workspace Owner
  * @param request  the request parameters of DeleteDataSourceSharedRule  DeleteDataSourceSharedRuleRequest
  * @return DeleteDataSourceSharedRuleResponse
 */
async function deleteDataSourceSharedRule(request: DeleteDataSourceSharedRuleRequest): DeleteDataSourceSharedRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataSourceSharedRule', 'POST', '/', 'json', false, 'json', request);
}

model DeleteFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  fileId: long(name='FileId', description='This parameter is required.', example='10000201', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
}

model DeleteFileResponseBody = {
  deploymentId?: long(name='DeploymentId', example='1000000001'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model DeleteFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteFile  DeleteFileRequest
  * @return DeleteFileResponse
 */
async function deleteFile(request: DeleteFileRequest): DeleteFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteFile', 'POST', '/', 'json', true, 'form', request);
}

model DeleteFolderRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  folderId: string(name='FolderId', description='This parameter is required.', example='2eb6f9****', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
}

model DeleteFolderResponseBody = {
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model DeleteFolderResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteFolderResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteFolder  DeleteFolderRequest
  * @return DeleteFolderResponse
 */
async function deleteFolder(request: DeleteFolderRequest): DeleteFolderResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteFolder', 'POST', '/', 'json', true, 'form', request);
}

model DeleteFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='860438872620113XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID. You can use this parameter to specify the DataWorks workspace on which you want to perform the API operation.

This parameter is required.', example='10000', position='Body'),
}

model DeleteFunctionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='88198F19-A36B-52A9-AE44-4518A688XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteFunctionResponseBody(name='body'),
}

/**
  * @description >  A UDF that is deployed cannot be deleted. If you want to delete such a UDF, you must first undeploy the UDF.
  * @param request  the request parameters of DeleteFunction  DeleteFunctionRequest
  * @return DeleteFunctionResponse
 */
async function deleteFunction(request: DeleteFunctionRequest): DeleteFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteFunction', 'POST', '/', 'json', true, 'form', request);
}

model DeleteLineageRelationshipRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The lineage ID. For more information, see the response returned by the ListLineageRelationships operation.

This parameter is required.', example='110xxxx:custom-table.xxxxx:maxcompute-table.project.test_big_lineage_080901:custom-sqlxx.00001', position='Body'),
}

model DeleteLineageRelationshipResponseBody = {
  requestId?: string(name='RequestId', example='952795279527ab****'),
  success?: boolean(name='Success', example='true'),
}

model DeleteLineageRelationshipResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLineageRelationshipResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLineageRelationship  DeleteLineageRelationshipRequest
  * @return DeleteLineageRelationshipResponse
 */
async function deleteLineageRelationship(request: DeleteLineageRelationshipRequest): DeleteLineageRelationshipResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLineageRelationship', 'POST', '/', 'json', true, 'form', request);
}

model DeleteMetaCollectionRequest {
  regionId?: string(name='RegionId', position='Host'),
  id: string(name='Id', description='The collection ID.

This parameter is required.', example='category.123', position='Query'),
}

model DeleteMetaCollectionResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='45D14A7A-7C28-5547-AB0A-35FBCD9DE7B5'),
}

model DeleteMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteMetaCollection  DeleteMetaCollectionRequest
  * @return DeleteMetaCollectionResponse
 */
async function deleteMetaCollection(request: DeleteMetaCollectionRequest): DeleteMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMetaCollection', 'POST', '/', 'json', false, 'json', request);
}

model DeleteNetworkRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the network that you want to delete.

This parameter is required.', example='1000', position='Body'),
}

model DeleteNetworkResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteNetworkResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteNetworkResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteNetwork  DeleteNetworkRequest
  * @return DeleteNetworkResponse
 */
async function deleteNetwork(request: DeleteNetworkRequest): DeleteNetworkResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteNetwork', 'POST', '/', 'json', true, 'form', request);
}

model DeleteNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='860438872620113XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID.

You can use this parameter to specify the DataWorks workspace on which you want to perform the API operation.

This parameter is required.', example='10000', position='Body'),
}

model DeleteNodeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A1E54497-5122-505E-91C6-BAC14980XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

true\\
false', example='true'),
}

model DeleteNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteNodeResponseBody(name='body'),
}

/**
  * @description >  A node that is deployed cannot be deleted. If you want to delete such a node, you must first undeploy the node.
  * @param request  the request parameters of DeleteNode  DeleteNodeRequest
  * @return DeleteNodeResponse
 */
async function deleteNode(request: DeleteNodeRequest): DeleteNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteNode', 'POST', '/', 'json', true, 'form', request);
}

model DeleteProjectRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='123456', position='Body'),
}

model DeleteProjectResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
}

model DeleteProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteProjectResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteProject  DeleteProjectRequest
  * @return DeleteProjectResponse
 */
async function deleteProject(request: DeleteProjectRequest): DeleteProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteProject', 'POST', '/', 'json', true, 'form', request);
}

model DeleteProjectMemberRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='534752', position='Body'),
  userId: string(name='UserId', description='The ID of the account used by the member in the workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the **Tenant Members and Roles** page, view the ID of the account used by the member in the workspace.

This parameter is required.', example='123422344899', position='Body'),
}

model DeleteProjectMemberResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='1FF0465F-209C-5964-8F30-FAF21B677CC6'),
}

model DeleteProjectMemberResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteProjectMemberResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteProjectMember  DeleteProjectMemberRequest
  * @return DeleteProjectMemberResponse
 */
async function deleteProjectMember(request: DeleteProjectMemberRequest): DeleteProjectMemberResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteProjectMember', 'POST', '/', 'json', true, 'form', request);
}

model DeleteResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the file resource.

This parameter is required.', example='860438872620113XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID. You can use this parameter to specify the DataWorks workspace on which you want to perform the API operation.

This parameter is required.', example='10000', position='Body'),
}

model DeleteResourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='88198F19-A36B-52A9-AE44-4518A688XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteResourceResponseBody(name='body'),
}

/**
  * @description >  A file resource that is deployed cannot be deleted. If you want to delete such a file resource, you must first undeploy the file resource.
  * @param request  the request parameters of DeleteResource  DeleteResourceRequest
  * @return DeleteResourceResponse
 */
async function deleteResource(request: DeleteResourceRequest): DeleteResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteResource', 'POST', '/', 'json', true, 'form', request);
}

model DeleteResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
}

model DeleteResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to locate logs and troubleshoot issues.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteResourceGroupResponseBody(name='body'),
}

/**
  * @description 1.  You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * 2.  **Before you call this API operation, you must make sure that you have a good command of the billing details and [pricing](https://help.aliyun.com/document_detail/2680173.html) of serverless resource groups.
  * @param request  the request parameters of DeleteResourceGroup  DeleteResourceGroupRequest
  * @return DeleteResourceGroupResponse
 */
async function deleteResourceGroup(request: DeleteResourceGroupRequest): DeleteResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model DeleteRouteRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The route ID.

This parameter is required.', example='1000', position='Body'),
}

model DeleteRouteResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteRouteResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteRouteResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteRoute  DeleteRouteRequest
  * @return DeleteRouteResponse
 */
async function deleteRoute(request: DeleteRouteRequest): DeleteRouteResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteRoute', 'POST', '/', 'json', true, 'form', request);
}

model DeleteTaskRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model DeleteTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteTaskResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteTask  DeleteTaskRequest
  * @return DeleteTaskResponse
 */
async function deleteTask(request: DeleteTaskRequest): DeleteTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteTask', 'POST', '/', 'json', false, 'json', request);
}

model DeleteWorkflowRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a workflow asynchronously and implement the idempotence of the workflow. If you do not specify this parameter when you create the workflow, the system automatically generates a unique code. The unique code is uniquely associated with the workflow ID. If you specify this parameter when you update or delete the workflow, the value of this parameter must be the unique code that is used to create the workflow.', example='Workflow_0bc5213917368545132902xxxxxxxx', position='Body'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  id: long(name='Id', description='The workflow ID.

This parameter is required.', example='1234', position='Query'),
}

model DeleteWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteWorkflowResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteWorkflow  DeleteWorkflowRequest
  * @return DeleteWorkflowResponse
 */
async function deleteWorkflow(request: DeleteWorkflowRequest): DeleteWorkflowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteWorkflow', 'POST', '/', 'json', true, 'form', request);
}

model DeleteWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='860438872620113XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Body'),
}

model DeleteWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='B17730C0-D959-548A-AE23-E754177CXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @description >  A workflow that is deployed cannot be deleted. If you want to delete such a workflow, you must first undeploy the workflow.
  * @param request  the request parameters of DeleteWorkflowDefinition  DeleteWorkflowDefinitionRequest
  * @return DeleteWorkflowDefinitionResponse
 */
async function deleteWorkflowDefinition(request: DeleteWorkflowDefinitionRequest): DeleteWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model DeployFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', example='First release task', position='Body'),
  fileId?: long(name='FileId', example='10000001', position='Body'),
  nodeId?: long(name='NodeId', example='2000001', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
}

model DeployFileResponseBody = {
  data?: long(name='Data', example='30000001'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model DeployFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeployFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeployFile  DeployFileRequest
  * @return DeployFileResponse
 */
async function deployFile(request: DeployFileRequest): DeployFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeployFile', 'POST', '/', 'json', true, 'form', request);
}

model DetachDataQualityRulesFromEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityEvaluationTaskId: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task that is associated with the rule.

This parameter is required.', example='10000', position='Body'),
  dataQualityRuleIds: [ long ](name='DataQualityRuleIds', description='The IDs of the monitoring rules.

This parameter is required.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the workspace configuration page to obtain the workspace ID.

This parameter is required.', example='10002', position='Body'),
}

model DetachDataQualityRulesFromEvaluationTaskResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
  success?: boolean(name='Success', description='Whether the call is successful. The values are as follows:
- true: The call is successful.
- false: the call failed.', example='true'),
}

model DetachDataQualityRulesFromEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DetachDataQualityRulesFromEvaluationTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DetachDataQualityRulesFromEvaluationTask  DetachDataQualityRulesFromEvaluationTaskRequest
  * @return DetachDataQualityRulesFromEvaluationTaskResponse
 */
async function detachDataQualityRulesFromEvaluationTask(request: DetachDataQualityRulesFromEvaluationTaskRequest): DetachDataQualityRulesFromEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DetachDataQualityRulesFromEvaluationTask', 'POST', '/', 'json', true, 'form', request);
}

model DissociateProjectFromResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The ID of the workspace from which you want to disassociate the resource group.

This parameter is required.', example='1000', position='Body'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
}

model DissociateProjectFromResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to locate logs and troubleshoot issues.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DissociateProjectFromResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DissociateProjectFromResourceGroupResponseBody(name='body'),
}

/**
  * @description 1.  You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * 2.  Your account must be assigned one of the following roles of the desired workspace:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of DissociateProjectFromResourceGroup  DissociateProjectFromResourceGroupRequest
  * @return DissociateProjectFromResourceGroupResponse
 */
async function dissociateProjectFromResourceGroup(request: DissociateProjectFromResourceGroupRequest): DissociateProjectFromResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DissociateProjectFromResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model EstablishRelationTableToBusinessRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  businessId: string(name='BusinessId', description='This parameter is required.', example='1000001', position='Body'),
  folderId?: string(name='FolderId', example='2eb6f9****', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw', position='Body'),
  tableGuid: string(name='TableGuid', description='This parameter is required.', example='odps.dw_project.tb1', position='Body'),
}

model EstablishRelationTableToBusinessResponseBody = {
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG'),
  success?: boolean(name='Success', example='true'),
}

model EstablishRelationTableToBusinessResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: EstablishRelationTableToBusinessResponseBody(name='body'),
}

/**
  * @param request  the request parameters of EstablishRelationTableToBusiness  EstablishRelationTableToBusinessRequest
  * @return EstablishRelationTableToBusinessResponse
 */
async function establishRelationTableToBusiness(request: EstablishRelationTableToBusinessRequest): EstablishRelationTableToBusinessResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'EstablishRelationTableToBusiness', 'POST', '/', 'json', true, 'form', request);
}

model ExecPipelineRunStageRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  code: string(name='Code', description='The code of the stage in the process. You can call the GetDeployment operation to query the code.

This parameter is required.', example='DEV_CHECK', position='Body'),
  id: string(name='Id', description='The ID of the process.

This parameter is required.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Query'),
}

model ExecPipelineRunStageResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true

*   false

    **

    **Note:** The value of this parameter indicates only whether the stage is triggered but does not indicate whether the execution of the stage is successful.', example='true'),
}

model ExecPipelineRunStageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ExecPipelineRunStageResponseBody(name='body'),
}

/**
  * @description >  The stages in a process are sequential. For more information, see the GetDeployment operation. Skipping or repeating a stage is not allowed.
  * >  The execution of a stage is asynchronous. The response of this operation indicates only whether a stage is triggered but does not indicate whether the execution of the stage is successful. You can call the GetDeployment operation to check whether the execution is successful.
  * @param request  the request parameters of ExecPipelineRunStage  ExecPipelineRunStageRequest
  * @return ExecPipelineRunStageResponse
 */
async function execPipelineRunStage(request: ExecPipelineRunStageRequest): ExecPipelineRunStageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ExecPipelineRunStage', 'POST', '/', 'json', true, 'form', request);
}

model ExecuteAdhocWorkflowInstanceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  bizDate?: long(name='BizDate', description='The data timestamp.', example='1710239005403', position='Body'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  name: string(name='Name', description='The name of the workflow instance.

This parameter is required.', example='WorkflowInstance1', position='Body'),
  owner: string(name='Owner', description='The account ID of the owner.

This parameter is required.', example='1000', position='Body'),
  projectId: long(name='ProjectId', description='The workspace ID.

This parameter is required.', example='100', position='Body'),
  tasks: [ 
    {
      clientUniqueCode: string(name='ClientUniqueCode', description='The unique code of the client. This code uniquely identifies a task.

This parameter is required.', example='Task_0bc5213917368545132902xxxxxxxx'),
      dataSource?: {
        name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
      }(name='DataSource', description='The information about the associated data source.'),
      dependencies?: [ 
        {
          upstreamOutput?: string(name='UpstreamOutput', description='The identifier of the output of the ancestor task.', example='pre.odps_sql_demo_0'),
        }
      ](name='Dependencies', description='The dependency information.'),
      inputs?: {
        variables?: [ 
          {
            name?: string(name='Name', description='The name of the variable.', example='key1'),
            value?: string(name='Value', description='The value of the variable. You must configure this parameter in the `The ancestor output: The output variable name of the ancestor task` format.', example='Value1'),
          }
        ](name='Variables', description='The variables.'),
      }(name='Inputs', description='The input information.'),
      name: string(name='Name', description='The name of the task.

This parameter is required.', example='SQL node.'),
      outputs?: {
        taskOutputs?: [ 
          {
            output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
          }
        ](name='TaskOutputs', description='The task outputs.'),
        variables?: [ 
          {
            name?: string(name='Name', description='The name of the variable.', example='key1'),
            type?: string(name='Type', description='The type. Valid values:

*   System
*   Constant
*   NodeOutput
*   PassThrough', example='Constant'),
            value?: string(name='Value', description='The value of the variable.', example='value1'),
          }
        ](name='Variables', description='The variables.'),
      }(name='Outputs', description='The output information.'),
      owner: string(name='Owner', description='The account ID of the owner.

This parameter is required.', example='1000'),
      runtimeResource: {
        cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
        image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
        resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.

This parameter is required.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
      }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.

This parameter is required.'),
      script?: {
        content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
        parameters?: string(name='Parameters', description='The script parameters.', example='para1=$bizdate'),
      }(name='Script', description='The script information.'),
      timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
      type: string(name='Type', description='The type of the task.

This parameter is required.', example='ODPS_SQL'),
    }
  ](name='Tasks', description='The tasks.

This parameter is required.', shrink='json', position='Body'),
}

model ExecuteAdhocWorkflowInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
}

model ExecuteAdhocWorkflowInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ExecuteAdhocWorkflowInstanceResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ExecuteAdhocWorkflowInstance  ExecuteAdhocWorkflowInstanceRequest
  * @return ExecuteAdhocWorkflowInstanceResponse
 */
async function executeAdhocWorkflowInstance(request: ExecuteAdhocWorkflowInstanceRequest): ExecuteAdhocWorkflowInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ExecuteAdhocWorkflowInstance', 'POST', '/', 'json', true, 'form', request);
}

model GetAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: string(name='Id', description='The rule ID.', example='28547072', position='Query'),
}

model GetAlertRuleResponseBody = {
  alertRule?: {
    enabled?: boolean(name='Enabled', description='Indicates whether the rule is enabled.', example='true'),
    id?: long(name='Id', description='The rule ID.', example='16035'),
    name?: string(name='Name', description='The name of the rule.', example='error_rule'),
    notification?: {
      channels?: [ string ](name='Channels', description='The alert notification channels.'),
      intervalInMinutes?: int32(name='IntervalInMinutes', description='The interval at which an alert notification is sent. Unit: minutes. Valid values: [5,10000].', example='30'),
      maximum?: int32(name='Maximum', description='The maximum number of times an alert notification can be sent within a calendar day. Valid values: [1, 10000].', example='3'),
      receivers?: [ 
        {
          extension?: string(name='Extension', description='The additional configuration of the alert recipient. If the ReceiverType parameter is set to DingdingUrl, you can set this parameter to {"atAll":true} to remind all members in a DingTalk group.', example='{"atAll":true}'),
          receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid valves:

*   AliUid: Alibaba Cloud account ID.
*   Shift Schedules: the personnel in a shift schedule.
*   TaskOwner: the task owner. The task owner can receive custom alerts and event alerts.
*   Owner: the baseline owner. The baseline owner can receive baseline alerts.
*   WebhookUrl: URL of a custom webhook.
*   DingdingUrl: DingTalk webhook URL.
*   FeishuUrl: Lark webhook URL.
*   WeixinUrl: WeCom webhook URL.', example='WebhookUrl'),
          receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
        }
      ](name='Receivers', description='The alert recipients.'),
      silenceEndTime?: string(name='SilenceEndTime', description='The end time for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
      silenceStartTime?: string(name='SilenceStartTime', description='The start time for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
    }(name='Notification', description='The configuration for the alert notification.'),
    owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.', example='279961421580845157'),
    triggerCondition?: {
      extension?: {
        cycleUnfinished?: {
          cycleAndTime?: [ 
            {
              cycleId?: int32(name='CycleId', description='The ID of the scheduling cycle of the instance. Valid values: [1,288].', example='1'),
              time?: string(name='Time', description='The latest completion time of the instance within the scheduling cycle. The time is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
            }
          ](name='CycleAndTime', description='The configurations of the scheduling cycle and timeout period of the instance.'),
        }(name='CycleUnfinished', description='The configuration for an alert of the CycleUnfinished type.'),
        error?: {
          autoRerunAlertEnabled?: boolean(name='AutoRerunAlertEnabled', description='Indicates whether an alert is triggered if a batch synchronization task is automatically rerun upon a failure.', example='false'),
          streamTaskIds?: [ long ](name='StreamTaskIds', description='The IDs of the real-time computing tasks. This parameter is required when you monitor real-time computing tasks.'),
        }(name='Error', description='The configuration for an alert of the Error type.'),
        instanceErrorCount?: {
          count?: int32(name='Count', description='The maximum number of instances on which an error occurs. Valid values: [1,10000].', example='10'),
        }(name='InstanceErrorCount', description='The configuration for an alert of the InstanceErrorCount type.'),
        instanceErrorPercentage?: {
          percentage?: int32(name='Percentage', description='The maximum percentage of instances on which an error occurs in the workspace to the total number of instances. Valid values: [1-100].', example='10'),
        }(name='InstanceErrorPercentage', description='The configuration for an alert of the InstanceErrorPercentage type.'),
        instanceTransferFluctuate?: {
          percentage?: int32(name='Percentage', description='The maximum percentage of fluctuation in the number of auto triggered node instances that are generated in your workspace. Valid values: [1-100].', example='10'),
          trend?: string(name='Trend', description='The way in which the number of auto triggered node instances that are generated in your workspace fluctuates. Valid values:

*   abs: the absolute value. The number of instances increases or decreases.
*   increase: The number of instances increases.
*   decrease: The number of instances decreases.', example='10'),
        }(name='InstanceTransferFluctuate', description='The configuration for an alert of the InstanceTransferFluctuate type.'),
        timeout?: {
          timeoutInMinutes?: int32(name='TimeoutInMinutes', description='The timeout period. Unit: minutes. Valid values: [1, 21600].', example='10'),
        }(name='Timeout', description='The configuration for an alert of the Timeout type.'),
        unFinished?: {
          unFinishedTime?: string(name='UnFinishedTime', description='The latest completion time of the instance. The period is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
        }(name='UnFinished', description='The configuration for an alert of the UnFinished type.'),
      }(name='Extension', description='The extended information about the rule. This parameter is required for specific types of alerts.'),
      target?: {
        allowTasks?: [ long ](name='AllowTasks', description='The nodes that are not to be monitored.'),
        ids?: [ long ](name='Ids', description='The IDs of monitored objects.'),
        type?: string(name='Type', description='The type of the monitored objects. Valid values:

*   Task: node
*   Baseline: baseline
*   project: workspace
*   BizProcess: workflow', example='Task'),
      }(name='Target', description='The monitored objects.'),
      type?: string(name='Type', description='The alert type. Valid values:

*   Finished: An instance is successfully run.
*   UnFinished: An instance does not finish running before a specified point in time.
*   Error: An error occurs on an instance.
*   CycleUnfinished: An instance does not finish running as expected within a specific cycle.
*   Timeout: An instance times out.
*   InstanceTransferComplete: An instance is generated by the auto triggered node.
*   InstanceTransferFluctuate: The number of generated instances fluctuates.
*   ExhaustedError: An error persists after an instance is automatically rerun.
*   InstanceKeyword: An instance with errors contains specified keywords.
*   InstanceErrorCount: The number of instances on which an error occurs reaches a specified threshold.
*   InstanceErrorPercentage: The proportion of instances on which an error occurs in the workspace to the total number of instances reaches a specified threshold.
*   ResourceGroupPercentage: The usage rate of the resource group reaches a specified threshold.
*   ResourceGroupWaitCount: The number of instances that are waiting for resources in the resource group reaches a specified threshold.', example='Error'),
    }(name='TriggerCondition', description='The alert triggering condition.'),
  }(name='AlertRule', description='The information about the rule.'),
  requestId?: string(name='RequestId', description='The request ID.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
}

model GetAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAlertRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetAlertRule  GetAlertRuleRequest
  * @return GetAlertRuleResponse
 */
async function getAlertRule(request: GetAlertRuleRequest): GetAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAlertRule', 'GET', '/', 'json', false, 'json', request);
}

model GetBusinessRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  businessId: long(name='BusinessId', description='This parameter is required.', example='1000000111', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
}

model GetBusinessResponseBody = {
  data?: {
    businessId?: long(name='BusinessId', example='1000001'),
    businessName?: string(name='BusinessName', example='The first business process'),
    description?: string(name='Description', example='This is my first business process.'),
    owner?: string(name='Owner', example='20000****'),
    projectId?: string(name='ProjectId', example='10000'),
    useType?: string(name='UseType', example='NORMAL'),
  }(name='Data'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model GetBusinessResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetBusinessResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetBusiness  GetBusinessRequest
  * @return GetBusinessResponse
 */
async function getBusiness(request: GetBusinessRequest): GetBusinessResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetBusiness', 'POST', '/', 'json', true, 'form', request);
}

model GetCatalogRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='Data catalog entity ID. Currently, only DLF and StarRocks types are supported. You can refer to the response of the ListCatalogs operation and [the description of metadata entity concepts.](https://help.aliyun.com/document_detail/2880092.html)

*   For the DLF type, the format is `dlf-catalog::catalog_id`.
*   For the StarRocks type, the format is `starrocks-catalog:(instance_id|encoded_jdbc_url):catalog_name`.

>  Parameter descriptions:\\
`catalog_id`: The DLF catalog ID.\\
`instance_id`: The instance ID, required for the data source registered in instance mode.\\
`encoded_jdbc_url`: The JDBC connection string that has been URL encoded, required for the data source registered via a connection string.\\
`catalog_name`: The name of the StarRocks catalog.

This parameter is required.', example='dlf-catalog:123456XXX:test_catalog
starrocks-catalog:c-abc123xxx:default_catalog', position='Query'),
}

model GetCatalogResponseBody = {
  catalog?: Catalog(name='Catalog'),
  requestId?: string(name='RequestId', example='1AFAE64E-D1BE-432B-A9****'),
  success?: boolean(name='Success', example='true'),
}

model GetCatalogResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCatalogResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetCatalog  GetCatalogRequest
  * @return GetCatalogResponse
 */
async function getCatalog(request: GetCatalogRequest): GetCatalogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCatalog', 'GET', '/', 'json', false, 'json', request);
}

model GetCertificateRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the certificate file.

This parameter is required.', example='676303114031776', position='Query'),
  projectId?: long(name='ProjectId', description='The ID of the workspace to which the certificate file belongs.', example='1065601', position='Query'),
}

model GetCertificateResponseBody = {
  certificate?: {
    createTime?: long(name='CreateTime', description='The time when the certificate file was created. The value is a UNIX timestamp. Unit: milliseconds.', example='1730217600000'),
    createUser?: string(name='CreateUser', description='The ID of the user who created the certificate file.', example='1107550004253538'),
    description?: string(name='Description', description='The description.', example='This is a file'),
    fileSizeInBytes?: long(name='FileSizeInBytes', description='The size of the certificate file, in bytes.', example='77549'),
    id?: long(name='Id', description='The ID of the certificate file.', example='676303114031776'),
    name?: string(name='Name', description='The name of the certificate file.', example='ca1.crt'),
    projectId?: long(name='ProjectId', description='The ID of the workspace to which the certificate file belongs.', example='177161'),
  }(name='Certificate', description='The details of the certificate file.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
}

model GetCertificateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCertificateResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks: Tenant Owner, Workspace Administrator, Deploy, Develop, Workspace Owner, and O\\&M.
  * @param request  the request parameters of GetCertificate  GetCertificateRequest
  * @return GetCertificateResponse
 */
async function getCertificate(request: GetCertificateRequest): GetCertificateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCertificate', 'GET', '/', 'json', false, 'json', request);
}

model GetColumnRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID. You can refer to the response of the ListColumns operation and the [description of concepts related to metadata entities.](https://help.aliyun.com/document_detail/2880092.html)

The format: `${EntityType}:${Instance ID or escaped URL}:${Catalog name}:${Database name}`. Use empty strings as placeholders for levels that do not exist.

>  For the MaxCompute and DLF types, the instance ID level must be left empty. For the MaxCompute type, the instance ID level is represented by an empty string. The database name is the name of the MaxCompute project with schema enabled.

>  The catalog identifier of the StarRocks is the catalog name, and the catalog identifier of the DLF type is the catalog ID. Other types do not support catalog levels and can use empty strings as placeholders.

Examples of common ID formats

`maxcompute-column:::project_name:[schema_name]:table_name:column_name`

`dlf-column::catalog_id:database_name::table_name:column_name`

`hms-column:instance_id::database_name::table_name:column_name`

`holo-column:instance_id::database_name:schema_name:table_name:column_name`

`mysql-column:(instance_id|encoded_jdbc_url)::database_name::table_name:column_name`

> \\
`instance_id`: the ID of the instance, which is required when the data source is registered in instance mode.\\
`encoded_jdbc_url`: the URL-encoded JDBC connection string, which is required when the data source is registered via a connection string.\\
`catalog_id`: The DLF catalog ID.\\
`project_name`: The MaxCompute project name.\\
`database_name`: The database name.\\
`schema_name`: The schema name. For the MaxCompute type, this is required only if the project has enabled schema; otherwise, use an empty string as a placeholder.\\
`table_name`: The table name.\\
`column_name`: The field name.

This parameter is required.', example='maxcompute-column:11075xxxx::test_project:test_schema:test_table:test_column', position='Query'),
}

model GetColumnResponseBody = {
  column?: Column(name='Column'),
  requestId?: string(name='RequestId', example='D1E2E5BC-xxxx-xxxx-xxxx-xxxxxx'),
  success?: boolean(name='Success', example='true'),
}

model GetColumnResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetColumnResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetColumn  GetColumnRequest
  * @return GetColumnResponse
 */
async function getColumn(request: GetColumnRequest): GetColumnResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetColumn', 'GET', '/', 'json', false, 'json', request);
}

model GetCreateWorkflowInstancesResultRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  operationId: string(name='OperationId', description='The operation ID. This parameter is used to query the result of asynchronously creating a workflow instance. You can call the CreateWorkflowInstances operation to query the ID.

This parameter is required.', example='e15ad21c-b0e9-4792-8f55-b037xxxxxxxx', position='Query'),
}

model GetCreateWorkflowInstancesResultResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  result?: {
    failureMessage?: string(name='FailureMessage', description='The error message. This parameter is returned only if the creation fails.', example='Invalid Param xxx'),
    status?: string(name='Status', description='The creation status. Valid values:

*   Creating
*   Created
*   CreateFailure', example='Created'),
    workflowInstanceIds?: [ long ](name='WorkflowInstanceIds', description='The workflow instance IDs. This parameter is returned only if the creation is successful.'),
  }(name='Result', description='The result of asynchronously creating a workflow instance.'),
}

model GetCreateWorkflowInstancesResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCreateWorkflowInstancesResultResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetCreateWorkflowInstancesResult  GetCreateWorkflowInstancesResultRequest
  * @return GetCreateWorkflowInstancesResultResponse
 */
async function getCreateWorkflowInstancesResult(request: GetCreateWorkflowInstancesResultRequest): GetCreateWorkflowInstancesResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCreateWorkflowInstancesResult', 'GET', '/', 'json', false, 'json', request);
}

model GetDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='11588', deprecated='true', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11588', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
  withDetails?: boolean(name='WithDetails', description='Specifies whether to return detailed configuration information, including TransformationRules, TableMappings, and JobSettings. Valid values: true and false. Default value: true.', example='true', position='Query'),
}

model GetDIJobResponseBody = {
  pagingInfo?: {
    DIJobId?: string(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='32601', deprecated='true'),
    description?: string(name='Description', description='The description of the synchronization task.', example='description'),
    destinationDataSourceSettings?: [ 
      {
        dataSourceName?: string(name='DataSourceName', description='The name of the data source.', example='dw_mysql'),
      }
    ](name='DestinationDataSourceSettings', description='The properties of the destination.'),
    destinationDataSourceType?: string(name='DestinationDataSourceType', description='The destination type. Valid values: Hologres, OSS-HDFS, OSS, MaxCompute, LogHub, StarRocks, DataHub, AnalyticDB_For_MySQL, Kafka, Hive.', example='Hologres'),
    id?: long(name='Id', description='The ID of the synchronization task.', example='32601'),
    jobName?: string(name='JobName', description='The name of the synchronization task.', example='imp_ods_dms_det_dealer_info_df'),
    jobSettings?: {
      channelSettings?: string(name='ChannelSettings', description='The channel control settings for the synchronization task. You can configure special channel control settings for the following synchronization links: data synchronization between Hologres data sources and data synchronization from Hologres to Kafka.

1.  Holo2Kafka

*   Example: {"destinationChannelSettings":{"kafkaClientProperties":[{"key":"linger.ms","value":"100"}],"keyColumns":["col3"],"writeMode":"canal"}}
*   kafkaClientProperties: the parameters related to a Kafka producer, which are used when you write data to a Kafka data source.
*   keyColumns: the names of Kafka columns to which data is written.
*   writeMode: the writing format. Valid values: json and canal.

2.  Holo2Holo

*   Example: {"destinationChannelSettings":{"conflictMode":"replace","dynamicColumnAction":"replay","writeMode":"replay"}}
*   conflictMode: the policy used to handle a conflict that occurs during data writing to Hologres. Valid values: replace and ignore.
*   writeMode: the mode in which data is written to Hologres. Valid values: replay and insert.
*   dynamicColumnAction: the mode in which data is written to dynamic columns in a Hologres table. Valid values: replay, insert, and ignore.', example='{"structInfo":"MANAGED","storageType":"TEXTFILE","writeMode":"APPEND","partitionColumns":[{"columnName":"pt","columnType":"STRING","comment":""}],"fieldDelimiter":""}'),
      columnDataTypeSettings?: [ 
        {
          destinationDataType?: string(name='DestinationDataType', description='The data type of the destination field. Valid values: bigint, boolean, string, text, datetime, timestamp, decimal, and binary. Different types of data sources support different data types.', example='text'),
          sourceDataType?: string(name='SourceDataType', description='The data type of the source field. Valid values: bigint, boolean, string, text, datetime, timestamp, decimal, and binary. Different types of data sources support different data types.', example='bigint'),
        }
      ](name='ColumnDataTypeSettings', description='The data type mappings between source fields and destination fields.'),
      cycleScheduleSettings?: {
        cycleMigrationType?: string(name='CycleMigrationType', description='The synchronization type that requires periodic scheduling. Valid values:

*   Full: full synchronization
*   OfflineIncremental: batch incremental synchronization', example='Full'),
        scheduleParameters?: string(name='ScheduleParameters', description='The scheduling parameters.', example='bizdate=$bizdate'),
      }(name='CycleScheduleSettings', description='The settings for periodic scheduling.'),
      ddlHandlingSettings?: [ 
        {
          action?: string(name='Action', description='The processing policy for a specific type of DDL message. Valid values:

*   Ignore: ignores a DDL message.
*   Critical: reports an error for a DDL message.
*   Normal: normally processes a DDL message.', example='Ignore'),
          type?: string(name='Type', description='The DDL operation type. Valid values:

*   RenameColumn
*   ModifyColumn
*   CreateTable
*   TruncateTable
*   DropTable', example='CreateTable'),
        }
      ](name='DdlHandlingSettings', description='The DDL operation types. Valid values:

*   RenameColumn
*   ModifyColumn
*   CreateTable
*   TruncateTable
*   DropTable
*   DropColumn
*   AddColumn'),
      runtimeSettings?: [ 
        {
          name?: string(name='Name', description='The name of the configuration item. Valid values:

*   src.offline.datasource.max.connection: indicates the maximum number of connections that are allowed for reading data from the source of a batch synchronization task.
*   dst.offline.truncate: indicates whether to clear the destination table before data writing.
*   runtime.offline.speed.limit.enable: indicates whether throttling is enabled for a batch synchronization task.
*   runtime.offline.concurrent: indicates the maximum number of parallel threads that are allowed for a batch synchronization task.
*   runtime.enable.auto.create.schema: indicates whether schemas are automatically created in the destination of a synchronization task.
*   runtime.realtime.concurrent: indicates the maximum number of parallel threads that are allowed for a real-time synchronization task.
*   runtime.realtime.failover.minute.dataxcdc: indicates the maximum waiting duration before a synchronization task retries the next restart if the previous restart fails after failover occurs. Unit: minutes.
*   runtime.realtime.failover.times.dataxcdc: indicates the maximum number of failures that are allowed for restarting a synchronization task after failovers occur.', example='runtime.offline.concurrent'),
          value?: string(name='Value', description='The value of the configuration item.', example='1'),
        }
      ](name='RuntimeSettings', description='The runtime settings.'),
    }(name='JobSettings', description='The runtime settings.'),
    jobStatus?: string(name='JobStatus', description='The status of the job.', example='Running'),
    jobType?: string(name='JobType', description='任务类型

- DatabaseRealtimeMigration(整库实时):将源端多个库的多个表进行流同步，支持仅全量，仅增量，或全量+增量。

- DatabaseOfflineMigration(整库离线):将源端多个库的多个表进行批同步，支持仅全量，仅增量，或全量+增量。

- SingleTableRealtimeMigration(单表实时):将源端单个表进行流同步。', example='DatabaseRealtimeMigration'),
    migrationType?: string(name='MigrationType', description='The synchronization type. Valid values:

*   FullAndRealtimeIncremental: full synchronization and real-time incremental synchronization of data in an entire database
*   RealtimeIncremental: real-time incremental synchronization of data in a single table
*   Full: full batch synchronization of data in an entire database
*   OfflineIncremental: batch incremental synchronization of data in an entire database
*   FullAndOfflineIncremental: full synchronization and batch incremental synchronization of data in an entire database', example='FullAndRealtimeIncremental'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter indicates the DataWorks workspace to which the API operation is applied.', example='98330'),
    resourceSettings?: {
      offlineResourceSettings?: {
        requestedCu?: double(name='RequestedCu', description='The number of compute units (CUs) in the resource group for scheduling that are used for batch synchronization.', example='2.0'),
        resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for Data Integration used for batch synchronization.', example='S_res_group_7708_1667792816832'),
      }(name='OfflineResourceSettings', description='The resource used for batch synchronization.'),
      realtimeResourceSettings?: {
        requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for Data Integration that are used for real-time synchronization.', example='2.0'),
        resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for Data Integration used for real-time synchronization.', example='S_res_group_235454102432001_1579085295030'),
      }(name='RealtimeResourceSettings', description='The resource used for real-time synchronization.'),
      scheduleResourceSettings?: {
        requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for Data Integration that are used for scheduling.', example='2.0'),
        resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for scheduling used by the synchronization task.', example='S_res_group_235454102432001_1718359176885'),
      }(name='ScheduleResourceSettings', description='The resource used for scheduling.'),
    }(name='ResourceSettings', description='The resource settings.'),
    sourceDataSourceSettings?: [ 
      {
        dataSourceName?: string(name='DataSourceName', description='The name of the data source.', example='dw_mysql'),
        dataSourceProperties?: {
          encoding?: string(name='Encoding', description='The encoding format of the database.', example='UTF-8'),
          timezone?: string(name='Timezone', description='The time zone.', example='GMT+8'),
        }(name='DataSourceProperties', description='The properties of the data source.'),
      }
    ](name='SourceDataSourceSettings', description='The settings of the source. Only a single source is supported.'),
    sourceDataSourceType?: string(name='SourceDataSourceType', description='The source type. Valid values: PolarDB, MySQL, Kafka, LogHub, Hologres, Oracle, OceanBase, MongoDB, RedShift, Hive, SQLServer, Doris, ClickHouse.', example='Mysql'),
    tableMappings?: [ 
      {
        sourceObjectSelectionRules?: [ 
          {
            action?: string(name='Action', description='The operation that is performed to select objects. Valid values: Include and Exclude.', example='Include'),
            expression?: string(name='Expression', description='The expression.', example='mysql_table_1'),
            expressionType?: string(name='ExpressionType', description='The expression type. Valid values: Exact and Regex.', example='Exact'),
            objectType?: string(name='ObjectType', description='The object type. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
          }
        ](name='SourceObjectSelectionRules', description='The list of rules used to select synchronization objects in the source.'),
        transformationRules?: [ 
          {
            ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml', example='AddColumn'),
            ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
            ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which the action is performed. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
          }
        ](name='TransformationRules', description='The list of transformation rules that are applied to the synchronization objects selected from the source. Each entry in the list defines a transformation rule.'),
      }
    ](name='TableMappings', description='The list of mappings between rules used to select synchronization objects in the source and transformation rules applied to the selected synchronization objects. Each entry in the list displays a mapping between a rule used to select synchronization objects and a transformation rule applied to the selected synchronization objects.

>  [ { "SourceObjectSelectionRules":[ { "ObjectType":"Database", "Action":"Include", "ExpressionType":"Exact", "Expression":"biz_db" }, { "ObjectType":"Schema", "Action":"Include", "ExpressionType":"Exact", "Expression":"s1" }, { "ObjectType":"Table", "Action":"Include", "ExpressionType":"Exact", "Expression":"table1" } ], "TransformationRuleNames":[ { "RuleName":"my_database_rename_rule", "RuleActionType":"Rename", "RuleTargetType":"Schema" } ] } ]'),
    transformationRules?: [ 
      {
        ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml
*   DefineIncrementalCondition
*   DefineCycleScheduleSettings
*   DefinePartitionKey', example='Rename'),
        ruleExpression?: string(name='RuleExpression', description='The expression of the rule. The expression is a JSON string.

1.  Example of a renaming rule

*   Example: {"expression":"${srcDatasourceName}_${srcDatabaseName}_0922" }
*   expression: the expression of the renaming rule. You can use the following variables in an expression: ${srcDatasourceName}, ${srcDatabaseName}, and ${srcTableName}. ${srcDatasourceName} indicates the name of the source. ${srcDatabaseName} indicates the name of a source database. ${srcTableName} indicates the name of a source table.

2.  Example of a column addition rule

*   Example: {"columns":[{"columnName":"my_add_column","columnValueType":"Constant","columnValue":"123"}]}
*   If no rule of this type is configured, no fields are added to the destination and no values are assigned by default.
*   columnName: the name of the field that is added.
*   columnValueType: the value type of the field. Valid values: Constant and Variable.
*   columnValue: the value of the field. If the columnValueType parameter is set to Constant, the value of the columnValue parameter is a constant of the STRING data type. If the columnValueType parameter is set to Variable, the value of the columnValue parameter is a built-in variable. The following built-in variables are supported: EXECUTE_TIME (LONG data type), DB_NAME_SRC (STRING data type), DATASOURCE_NAME_SRC (STRING data type), TABLE_NAME_SRC (STRING data type), DB_NAME_DEST (STRING data type), DATASOURCE_NAME_DEST (STRING data type), TABLE_NAME_DEST (STRING data type), and DB_NAME_SRC_TRANSED (STRING data type). EXECUTE_TIME indicates the execution time. DB_NAME_SRC indicates the name of a source database. DATASOURCE_NAME_SRC indicates the name of the source. TABLE_NAME_SRC indicates the name of a source table. DB_NAME_DEST indicates the name of a destination database. DATASOURCE_NAME_DEST indicates the name of the destination. TABLE_NAME_DEST indicates the name of a destination table. DB_NAME_SRC_TRANSED indicates the database name obtained after a transformation.

3.  Example of a rule used to specify primary key fields for a destination table

*   Example: {"columns":["ukcolumn1","ukcolumn2"]}
*   If no rule of this type is configured, the primary key fields in the mapped source table are used for the destination table by default.
*   If the destination table is an existing table, Data Integration does not modify the schema of the destination table. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run.
*   If the destination table is automatically created by the system, Data Integration automatically creates the schema of the destination table. The schema contains the primary key fields that you specify. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run.

4.  Example of a rule used to process DML messages

*   Example: {"dmlPolicies":[{"dmlType":"Delete","dmlAction":"Filter","filterCondition":"id > 1"}]}
*   If no rule of this type is configured, the default processing policy for messages generated for insert, update, and delete operations is Normal.
*   dmlType: the DML operation. Valid values: Insert, Update, and Delete.
*   dmlAction: the processing policy for DML messages. Valid values: Normal, Ignore, Filter, and LogicalDelete. Filter indicates conditional processing. The value Filter is returned for the dmlAction parameter only when the value of the dmlType parameter is Update or Delete.
*   filterCondition: the condition used to filter DML messages. This parameter is returned only when the value of the dmlAction parameter is Filter.

5.  Example of a rule used to perform incremental synchronization

*   Example: {"where":"id > 0"}
*   The rule used to perform incremental synchronization is returned.

6.  Example of a rule used to configure scheduling parameters for an auto triggered task

*   Example: {"cronExpress":" \\* \\* \\* \\* \\* \\*", "cycleType":"1"}
*   The rule used to configure scheduling parameters for an auto triggered task is returned.

7.  Example of a rule used to specify a partition key

*   Example: {"columns":["id"]}
*   The rule used to specify a partition key is returned.', example='{"expression":"${srcDatasoureName}_${srcDatabaseName}"}'),
        ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
        ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which the action is performed. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
      }
    ](name='TransformationRules', description='The list of transformation rules that are applied to the synchronization objects selected from the source.

>  [ { "RuleName":"my_database_rename_rule", "RuleActionType":"Rename", "RuleTargetType":"Schema", "RuleExpression":"{"expression":"${srcDatasoureName}_${srcDatabaseName}"}" } ]'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADE490'),
}

model GetDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDIJob  GetDIJobRequest
  * @return GetDIJobResponse
 */
async function getDIJob(request: GetDIJobRequest): GetDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDIJob', 'GET', '/', 'json', false, 'json', request);
}

model GetDIJobLogRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='10000', deprecated='true', position='Query'),
  failoverId?: long(name='FailoverId', description='The failover ID.', example='10', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='10000', position='Query'),
  instanceId?: long(name='InstanceId', description='The instance ID.', example='6153616438', position='Query'),
  nodeType?: string(name='NodeType', description='The type of the node. This parameter is applicable only to the tasks that are run on serverless resource groups. Valid values:

*   **MASTER**: the master node, which is used to query the logs of JobManagers.
*   **WORKER**: the worker node, which is used to query the logs of TaskManagers.', example='MASTER', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number of the pagination query. The value is a positive integer greater than or equal to 1.', example='1', position='Query'),
}

model GetDIJobLogResponseBody = {
  log?: string(name='Log', description='The log.', example='>>>>>>>> stdout:n++++++++++++++++++executing sql: create database if not exists jindo_test location \\"oss://pangbei-hdfs/tmp/hive\\" n++n'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='1AFAE64E-D1BE-432B-A9****'),
}

model GetDIJobLogResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDIJobLogResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDIJobLog  GetDIJobLogRequest
  * @return GetDIJobLogResponse
 */
async function getDIJobLog(request: GetDIJobLogRequest): GetDIJobLogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDIJobLog', 'GET', '/', 'json', false, 'json', request);
}

model GetDataQualityEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The ID of the data quality monitor.', example='1006455182', position='Query'),
}

model GetDataQualityEvaluationTaskResponseBody = {
  dataQualityEvaluationTask?: {
    dataSourceId?: long(name='DataSourceId', description='The ID of the data source used for the monitor.', example='45238'),
    description?: string(name='Description', description='The description of the monitor.', example='The description of the quality monitoring task.'),
    hooks?: [ 
      {
        condition?: string(name='Condition', description='The hook trigger condition. When this condition is met, the hook action is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
        type?: string(name='Type', description='The hook type. Only one hook type is supported.

*   BlockTaskInstance: Blocks the running of scheduling tasks. A monitor is triggered by scheduling tasks. After a monitor finishes running, the monitor determines whether to block the running of scheduling tasks based on the hook condition.', example='BlockTaskInstance'),
      }
    ](name='Hooks', description='The hook.'),
    id?: long(name='Id', description='The ID of the data quality monitor.', example='2178'),
    name: string(name='Name', description='The name of the monitor.

This parameter is required.', example='OpenAPI create a data quality monitoring test'),
    notifications?: {
      condition?: string(name='Condition', description='The notification trigger condition. When this condition is met, the alert notification is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High"AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
      notifications?: [ 
        {
          notificationChannels?: [ 
            {
              channels?: [ string ](name='Channels', description='The alert notification methods.'),
            }
          ](name='NotificationChannels', description='The alert notification methods.'),
          notificationReceivers?: [ 
            {
              extension?: string(name='Extension', description='The extended information.', example='{  "atAll": true }'),
              receiverType?: string(name='ReceiverType', description='The additional parameters that are required when alerts are sent. The parameters are JSON-formatted strings. The following keys are supported:

*   atAll: specifies that all members in a group are mentioned when alerts are sent by using DingTalk. This parameter is valid only if you set ReceiverType to DingdingUrl.

Valid values:

*   WebhookUrl
*   FeishuUrl
*   DingdingUrl
*   WeixinUrl
*   AliUid', example='DingdingUrl'),
              receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
            }
          ](name='NotificationReceivers', description='The configurations of alert recipients.'),
        }
      ](name='Notifications', description='The configurations of alert notifications.'),
    }(name='Notifications', description='The configurations of alert notifications.'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='2626'),
    runtimeConf?: string(name='RuntimeConf', description='Extended configuration, JSON-formatted string, takes effect only for EMR-type data quality monitoring.

- queue: the yarn queue used when performing EMR data quality verification. The default queue is the queue configured for this project.
- sqlEngine: SQL engine used when performing EMR data verification
    - HIVE_ SQL
    - SPARK_ SQL', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }'),
    target?: {
      databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   hologres
*   cdh
*   analyticdb_for_mysql
*   starrocks
*   emr
*   analyticdb_for_postgresql', example='maxcompute'),
      partitionSpec?: string(name='PartitionSpec', description='Data quality monitoring partition range settings.', example='pt=$[yyyymmdd-1]'),
      tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.meta_open_api_test_sz.test_partition_tbl'),
      type?: string(name='Type', description='The type of the monitoring object.

- Table: Table.', example='Table'),
    }(name='Target', description='The monitored object of the monitor.'),
    trigger?: {
      taskIds?: [ long ](name='TaskIds', description='The IDs of scheduling tasks. This parameter is valid only if you set Type to ByScheduledTaskInstance.'),
      type?: string(name='Type', description='The trigger type of the monitor. Valid values:

*   ByManual: The monitor is manually triggered.
*   ByScheduledTaskInstance: The monitor is triggered by associated scheduling tasks.
*   ByQualityNode: The monitor is triggered by created data quality monitoring nodes.', example='ByScheduledTaskInstance'),
    }(name='Trigger', description='The trigger configuration of the monitor.'),
  }(name='DataQualityEvaluationTask', description='The details of the monitor.'),
  requestId?: string(name='RequestId', description='Id of the request', example='SDFSDFSDF-SDFSDF-SDFDSF-SDFSDF'),
}

model GetDataQualityEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityEvaluationTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDataQualityEvaluationTask  GetDataQualityEvaluationTaskRequest
  * @return GetDataQualityEvaluationTaskResponse
 */
async function getDataQualityEvaluationTask(request: GetDataQualityEvaluationTaskRequest): GetDataQualityEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityEvaluationTask', 'GET', '/', 'json', false, 'json', request);
}

model GetDataQualityEvaluationTaskInstanceRequest {
  regionId?: string(name='RegionId', position='Host'),
  id: long(name='Id', description='The ID of the data quality monitoring instance.

This parameter is required.', example='7227550902', position='Query'),
}

model GetDataQualityEvaluationTaskInstanceResponseBody = {
  dataQualityEvaluationTaskInstance?: {
    createTime?: long(name='CreateTime', description='The creation time.', example='1716344665000'),
    finishTime?: long(name='FinishTime', description='The end time of the instance.', example='1716344665000'),
    id?: long(name='Id', description='The ID of the data quality monitoring instance.', example='7234231689'),
    parameters?: string(name='Parameters', description='Data quality verification execution parameters in JSON format. The available keys are as follows:
- triggerTime: the millisecond timestamp of the trigger time. The baseline time of the $[yyyymmdd] expression in the data range of data quality monitoring. Required.', example='{ "triggerTime": 1733284062000 }'),
    projectId?: long(name='ProjectId', description='The ID of the workspace.', example='98330'),
    results?: [ 
      {
        createTime?: long(name='CreateTime'),
        details?: [ 
          {
            checkedValue?: string(name='CheckedValue'),
            referencedValue?: string(name='ReferencedValue'),
            status?: string(name='Status'),
          }
        ](name='Details'),
        id?: long(name='Id'),
        rule?: {
          checkingConfig?: {
            referencedSamplesFilter?: string(name='ReferencedSamplesFilter'),
            thresholds?: {
              critical?: {
                expression?: string(name='Expression'),
                operator?: string(name='Operator'),
                value?: string(name='Value'),
              }(name='Critical'),
              expected?: {
                expression?: string(name='Expression'),
                operator?: string(name='Operator'),
                value?: string(name='Value'),
              }(name='Expected'),
              warned?: {
                expression?: string(name='Expression'),
                operator?: string(name='Operator'),
                value?: string(name='Value'),
              }(name='Warned'),
            }(name='Thresholds'),
            type?: string(name='Type'),
          }(name='CheckingConfig'),
          description?: string(name='Description'),
          enabled?: boolean(name='Enabled'),
          errorHandlers?: [ 
            {
              errorDataFilter?: string(name='ErrorDataFilter'),
              type?: string(name='Type'),
            }
          ](name='ErrorHandlers'),
          id?: long(name='Id'),
          name?: string(name='Name'),
          projectId?: long(name='ProjectId'),
          samplingConfig?: {
            metric?: string(name='Metric'),
            metricParameters?: string(name='MetricParameters'),
            samplingFilter?: string(name='SamplingFilter'),
            settingConfig?: string(name='SettingConfig'),
          }(name='SamplingConfig'),
          severity?: string(name='Severity'),
          target?: {
            databaseType?: string(name='DatabaseType'),
            tableGuid?: string(name='TableGuid'),
            type?: string(name='Type'),
          }(name='Target'),
          templateCode?: string(name='TemplateCode'),
        }(name='Rule'),
        sample?: string(name='Sample'),
        status?: string(name='Status'),
        taskInstanceId?: long(name='TaskInstanceId'),
      }
    ](name='Results'),
    status?: string(name='Status', description='The status of the data quality monitoring instance.
- Running: Verifying
- Error: A rule verification Error occurred.
- Passed: all rules are verified
- Warned: normal alarm threshold triggered by rules
- Critical: Threshold for serious alerts triggered by rules', example='Passed'),
    task?: {
      description?: string(name='Description', description='The description of the monitor.', example='OpenAPI quality monitoring test'),
      hooks?: [ 
        {
          condition?: string(name='Condition', description='The hook trigger condition. When this condition is met, the hook action is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
          type?: string(name='Type', description='Hook type. Currently, only one type is supported:

- BlockTaskInstance: the blocking scheduling task continues to run. Data quality monitoring is triggered by the scheduling task. After the data quality monitoring is completed, the Hook.Condition is used to determine whether the blocking scheduling task continues to run.', example='BlockTaskInstance'),
        }
      ](name='Hooks', description='The hook.'),
      id?: long(name='Id', description='The ID of the data quality monitor.', example='28544990'),
      name?: string(name='Name', description='The name of the monitor.', example='Data quality OpenAPI monitoring test'),
      notifications?: {
        condition?: string(name='Condition', description='The notification trigger condition. When this condition is met, the alert notification is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='${severity} == "High" AND ${status} == "Critical"'),
        notifications?: [ 
          {
            notificationChannels?: [ 
              {
                channels?: [ string ](name='Channels', description='The notification method.'),
              }
            ](name='NotificationChannels', description='The notification method.'),
            notificationReceivers?: [ 
              {
                extension?: string(name='Extension', description='Additional parameter settings for sending alerts in json format. The supported keys are as follows:

- atAll: when sending DingTalk alerts, do you need to @ everyone in the group. It takes effect when ReceiverType is DingdingUrl.', example='{ "atAll": true }'),
                receiverType?: string(name='ReceiverType', description='The type of alert recipient.', example='DingdingUrl'),
                receiverValues?: [ string ](name='ReceiverValues', description='The recipient of the alert.'),
              }
            ](name='NotificationReceivers', description='The value of the receiver.'),
          }
        ](name='Notifications', description='The alert notification methods.'),
      }(name='Notifications', description='The configurations of alert notifications.'),
      projectId?: long(name='ProjectId', description='The ID of the workspace.', example='20629'),
      runtimeConf?: string(name='RuntimeConf', description='Extended configuration, JSON-formatted string, takes effect only for EMR-type data quality monitoring.

- queue: the yarn queue used when performing EMR data quality verification. The default queue is the queue configured for this project.
- sqlEngine: SQL engine used when performing EMR data verification
  - HIVE_ SQL
  - SPARK_ SQL', example='{ "queue": "default" }'),
      target?: {
        databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs.', example='maxcompute'),
        partitionSpec?: string(name='PartitionSpec', description='The partition range monitored.', example='pt=$[yyyymmdd-1]'),
        tableGuid?: string(name='TableGuid', description='The unique ID of the table in the data map.', example='odps.api_trace.ods_d_api_log'),
        type?: string(name='Type', description='The type of the monitoring object.
- Table: Table', example='Table'),
      }(name='Target', description='The monitored object of the monitor.'),
      trigger?: {
        taskIds?: [ long ](name='TaskIds', description='The Id list of the scheduled task, which is valid when the Type is ByScheduledTaskInstance.'),
        type?: string(name='Type', description='The trigger type of the monitor. Valid values:

*   ByManual (default): The monitor is manually triggered.
*   ByScheduledTaskInstance: The monitor is triggered by the associated scheduling tasks.', example='ByScheduledTaskInstance'),
      }(name='Trigger', description='The trigger configuration of the monitor.'),
    }(name='Task', description='The monitor.'),
    triggerContext?: string(name='TriggerContext', description='The context information when the instance is triggered, in JSON format. The possible keys are as follows:
- TriggerClient: the trigger source of the data quality monitoring instance, such as CWF2 (scheduling system), may be added later.
- TriggerClientId: associated with a specific business resource in the source system. For example, if TriggerClient is CWF2, the ID of the scheduling task is recorded here.', example='{ "triggerClient": "CWF2", "triggerClientId": 70001238945 }'),
  }(name='DataQualityEvaluationTaskInstance', description='The details of the monitor instance.'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
}

model GetDataQualityEvaluationTaskInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityEvaluationTaskInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDataQualityEvaluationTaskInstance  GetDataQualityEvaluationTaskInstanceRequest
  * @return GetDataQualityEvaluationTaskInstanceResponse
 */
async function getDataQualityEvaluationTaskInstance(request: GetDataQualityEvaluationTaskInstanceRequest): GetDataQualityEvaluationTaskInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityEvaluationTaskInstance', 'GET', '/', 'json', false, 'json', request);
}

model GetDataQualityRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id: long(name='Id', description='The rule ID.

This parameter is required.', example='19715', position='Query'),
}

model GetDataQualityRuleResponseBody = {
  dataQualityRule?: {
    checkingConfig?: {
      referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference values. In this example, an expression is used to indicate the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
      thresholds?: {
        critical?: {
          expression?: string(name='Expression', description='The threshold expression.', example='$checkValue > 0.05'),
          operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
          value?: string(name='Value', description='The threshold value.', example='100.0'),
        }(name='Critical', description='The threshold settings for critical alerts.'),
        expected?: {
          expression?: string(name='Expression', description='The threshold expression.', example='$checkValue <= 0.01'),
          operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
          value?: string(name='Value', description='The threshold value.', example='100.0'),
        }(name='Expected', description='The expected threshold setting.'),
        warned?: {
          expression?: string(name='Expression', description='The threshold expression.', example='$checkValue > 0.01'),
          operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
          value?: string(name='Value', description='The threshold value.', example='100.0'),
        }(name='Warned', description='The threshold settings for normal alerts.'),
      }(name='Thresholds', description='The threshold settings.'),
      type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
    }(name='CheckingConfig', description='The check settings for sample data.'),
    description?: string(name='Description', description='The description of the rule. The description can be up to 500 characters in length.', example='this is a odps _sql task'),
    enabled?: boolean(name='Enabled', description='Indicates whether the rule is enabled.', example='true'),
    errorHandlers?: [ 
      {
        errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If you define the rule by using custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
        type?: string(name='Type', description='Processor type:
- SaveErrorData', example='SaveErrorData'),
      }
    ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
    id?: long(name='Id', description='The rule ID.', example='16033'),
    name?: string(name='Name', description='The rule name.', example='The table cannot be empty.'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='1948'),
    samplingConfig?: {
      metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='Max'),
      metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
      samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='id IS NULL'),
      settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;'),
    }(name='SamplingConfig', description='The sampling settings.'),
    severity?: string(name='Severity', description='Rule for the business level (corresponding to the strong and weak rules on the page), optional enumeration value:
- Normal
- High', example='High'),
    target?: {
      databaseType?: string(name='DatabaseType', description='The dataset of the table type. The database type to which the table belongs.
- maxcompute
- emr
- cdh
- hologres
- analyticdb_for_postgresql
- analyticdb_for_mysql
- starrocks', example='maxcompute'),
      partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='ds=$[yyyymmdd-1]'),
      tableGuid?: string(name='TableGuid', description='The ID of the table that is limited by the rule in Data Map.', example='odps.unit_test.tb_unit_test'),
      type?: string(name='Type', description='Monitoring object type

- Table', example='Table'),
    }(name='Target', description='The monitored object of the rule.'),
    templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='system::user_defined'),
  }(name='DataQualityRule', description='The information about the rule.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model GetDataQualityRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityRuleResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDataQualityRule  GetDataQualityRuleRequest
  * @return GetDataQualityRuleResponse
 */
async function getDataQualityRule(request: GetDataQualityRuleRequest): GetDataQualityRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityRule', 'GET', '/', 'json', false, 'json', request);
}

model GetDataQualityRuleTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  code: string(name='Code', description='The code for the template.

This parameter is required.', example='USER_DEFINED:123', position='Query'),
}

model GetDataQualityRuleTemplateResponseBody = {
  dataQualityRuleTemplate?: {
    checkingConfig?: {
      referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference samples and perform aggregate operations on the reference values. In this example, an expression is used to indicate the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
      type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
    }(name='CheckingConfig', description='The check settings for sample data.'),
    code?: string(name='Code', description='The code for the template.', example='USER_DEFINED:123'),
    directoryPath?: string(name='DirectoryPath', description='The directory in which the template is stored. Slashes (/) are used to separate directory levels. The name of each directory level can be up to 1,024 characters in length. It cannot contain whitespace characters or slashes (/).', example='/ods/order_data'),
    name?: string(name='Name', description='The name of the template. The name can be up to 512 characters in length and can contain digits, letters, and punctuation marks.', example='Table row Count Verification'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='4020'),
    samplingConfig?: {
      metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='Max'),
      metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{"SQL": "select count(1) from table;"}'),
      settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;'),
    }(name='SamplingConfig', description='The sampling settings.'),
    visibleScope?: string(name='VisibleScope', description='Available range of templates:
- Tenant: all tenants are available
- Project: only available in the current Project', example='Project'),
  }(name='DataQualityRuleTemplate', description='The information about the template.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model GetDataQualityRuleTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityRuleTemplateResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDataQualityRuleTemplate  GetDataQualityRuleTemplateRequest
  * @return GetDataQualityRuleTemplateResponse
 */
async function getDataQualityRuleTemplate(request: GetDataQualityRuleTemplateRequest): GetDataQualityRuleTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityRuleTemplate', 'GET', '/', 'json', false, 'json', request);
}

model GetDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The data source ID.

This parameter is required.', example='16035', position='Query'),
}

model GetDataSourceResponseBody = {
  dataSource?: {
    connectionProperties?: any(name='ConnectionProperties', description='The connection configurations of the data source, including the connection address, access identity, and environment information. The envType parameter specifies the environment in which the data source is used. Valid values of the envType parameter:

*   Dev: development environment
*   Prod: production environment

The parameters that you need to configure for the data source vary based on the mode in which the data source is added. For more information, see [Data source connection information (ConnectionProperties)](https://help.aliyun.com/document_detail/2852465.html).', example='{
	"envType": "Prod",
	"regionId": "cn-beijing",
    "instanceId": "hgprecn-cn-x0r3oun4k001",
    "database": "testdb",
    "securityProtocol": "authTypeNone",
    "authType": "Executor",
    "authIdentity": "1107550004253538"
}'),
    connectionPropertiesMode?: string(name='ConnectionPropertiesMode', description='The mode in which the data source is added. The mode varies based on the data source type. Valid values:

*   InstanceMode: instance mode
*   UrlMode: connection string mode
*   CdhMode: CDH cluster mode', example='UrlMode'),
    createTime?: long(name='CreateTime', description='The time when the data source was added. This value is a UNIX timestamp.', example='1698286929333'),
    createUser?: string(name='CreateUser', description='The ID of the user who adds the data source.', example='1107550004253538'),
    description?: string(name='Description', description='The description of the data source.', example='test'),
    id?: long(name='Id', description='The data source ID.', example='16738'),
    modifyTime?: long(name='ModifyTime', description='The time when the data source was last modified. This value is a UNIX timestamp.', example='1698286929333'),
    modifyUser?: string(name='ModifyUser', description='The ID of the user who modifies the data source.', example='1107550004253538'),
    name?: string(name='Name', description='The name of the data source.', example='test'),
    projectId?: long(name='ProjectId', description='The ID of the workspace with which the data source is associated.', example='52660'),
    qualifiedName?: string(name='QualifiedName', description='The unique business key of the data source. For example, the unique business key of a Hologres data source is in the `${tenantOwnerId}:${regionId}:${type}:${instanceId}:${database}` format.', example='1107550004253538:cn-beijing:holo:hgprecn-cn-x0r3oun4k001:testdb'),
    type?: string(name='Type', description='The type of the data source.', example='hologres'),
  }(name='DataSource', description='The information about the data source.'),
  requestId?: string(name='RequestId', description='The request ID.', example='9252F32F-D855-549E-8898-61CF5A733050'),
}

model GetDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Deployment, Development, Project Owner, and O\\&M
  * @param request  the request parameters of GetDataSource  GetDataSourceRequest
  * @return GetDataSourceResponse
 */
async function getDataSource(request: GetDataSourceRequest): GetDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataSource', 'GET', '/', 'json', false, 'json', request);
}

model GetDatabaseRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='Database entity ID. You can refer to the response of the ListDatabases operation and [the description of metadata entity concepts.](https://help.aliyun.com/document_detail/2880092.html)

The format is `${EntityType}:${Instance ID or encoded URL}:${Catalog identifier}:${Database name}`. Use empty strings as placeholders for non-existent levels.

>  For StarRocks, the catalog identifier is the catalog name. For DLF, the catalog identifier is the catalog ID. For other types, catalog hierarchy is not supported, and an empty string can be used as a placeholder.

Examples of common ID formats

`dlf-database::catalog_id:database_name`

`holo-database:instance_id::database_name`

`mysql-database:(instance_id|encoded_jdbc_url)::database_name`

>  Parameter descriptions\\
`catalog_id`: The DLF catalog ID.\\
`instance_id`: The instance ID, required for a data source registered in instance mode.\\
`encoded_jdbc_url`: The JDBC connection string that has been URL encoded. This parameter is required for the data source registered via a connection string.\\
`database_name`: The database name.

This parameter is required.', example='mysql-database:rm-abc123xxx::test_db', position='Query'),
}

model GetDatabaseResponseBody = {
  database?: Database(name='Database'),
  requestId?: string(name='RequestId', example='1AFAE64E-D1BE-432B-A9****'),
  success?: boolean(name='Success', example='true'),
}

model GetDatabaseResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDatabaseResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDatabase  GetDatabaseRequest
  * @return GetDatabaseResponse
 */
async function getDatabase(request: GetDatabaseRequest): GetDatabaseResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDatabase', 'GET', '/', 'json', false, 'json', request);
}

model GetDeploymentPackageRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  deploymentId: long(name='DeploymentId', description='This parameter is required.', example='1000000001', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
}

model GetDeploymentPackageResponseBody = {
  data?: {
    deployedItems?: [ 
      {
        fileId?: long(name='FileId', example='5076****'),
        fileVersion?: long(name='FileVersion', example='7'),
        status?: int32(name='Status', example='1'),
      }
    ](name='DeployedItems'),
    deployment?: {
      checkingStatus?: int32(name='CheckingStatus', example='7'),
      createTime?: long(name='CreateTime', example='1593877765000'),
      creatorId?: string(name='CreatorId', example='20030****'),
      errorMessage?: string(name='ErrorMessage', example='Success'),
      executeTime?: long(name='ExecuteTime', example='1593877765000'),
      fromEnvironment?: int32(name='FromEnvironment', example='0'),
      handlerId?: string(name='HandlerId', example='2003****'),
      name?: string(name='Name', example='ods_user_info_d-2020-07-04_20030****'),
      status?: int32(name='Status', example='1'),
      toEnvironment?: int32(name='ToEnvironment', example='1'),
    }(name='Deployment'),
  }(name='Data'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='You have no permission.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0bc1ec92159376****'),
  success?: boolean(name='Success', example='true'),
}

model GetDeploymentPackageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDeploymentPackageResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDeploymentPackage  GetDeploymentPackageRequest
  * @return GetDeploymentPackageResponse
 */
async function getDeploymentPackage(request: GetDeploymentPackageRequest): GetDeploymentPackageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDeploymentPackage', 'POST', '/', 'json', true, 'form', request);
}

model GetFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  fileId?: long(name='FileId', description='The file ID. You can call the [ListFiles](https://help.aliyun.com/document_detail/173942.html) operation to query the ID.', example='100000001', position='Body'),
  nodeId?: long(name='NodeId', description='The ID of the node that is scheduled. You can call the [ListFiles](https://help.aliyun.com/document_detail/173942.html) operation to query the ID.', example='200000001', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure either this parameter or the ProjectIdentifier parameter to determine the DataWorks workspace to which the operation is applied.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the name.

You must configure either this parameter or the ProjectId parameter to determine the DataWorks workspace to which the operation is applied.', example='dw_project', position='Body'),
}

model GetFileResponseBody = {
  data?: {
    file?: {
      advancedSettings?: string(name='AdvancedSettings', description='The advanced configurations of the node.

This parameter is valid for an EMR node. This parameter corresponds to the Advanced Settings tab in the right-side navigation pane on the configuration tab of the node in the [DataWorks console](https://workbench.data.aliyun.com/console).

>  You cannot configure advanced parameters for EMR Shell nodes.

For information about the advanced parameters of each type of EMR node, see [Develop EMR tasks](https://help.aliyun.com/document_detail/473077.html).', example='{\\"priority\\":\\"1\\",\\"ENABLE_SPARKSQL_JDBC\\":false,\\"FLOW_SKIP_SQL_ANALYZE\\":false,\\"queue\\":\\"default\\"}'),
      autoParsing?: boolean(name='AutoParsing', description='Indicates whether the automatic parsing feature is enabled for the file. Valid values:

*   true
*   false

This parameter corresponds to the Automatic Parsing From Code Before Node Committing parameter that is displayed after you select Same Cycle in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='true'),
      bizId?: long(name='BizId', description='The ID of the workflow to which the file belongs. This parameter is deprecated and replaced by the BusinessId parameter.', example='1000001'),
      businessId?: long(name='BusinessId', description='The ID of the workflow to which the file belongs.', example='1000001'),
      commitStatus?: int32(name='CommitStatus', description='Indicates whether the latest code in the file is committed. Valid values: 0 and 1. The value 0 indicates that the latest code in the file is not committed. The value 1 indicates that the latest code in the file is committed.', example='0'),
      connectionName?: string(name='ConnectionName', description='The name of the data source that is used to run the node that corresponds to the file.', example='odps_source'),
      content?: string(name='Content', description='The code in the file.', example='SHOW TABLES;'),
      createTime?: long(name='CreateTime', description='The time when the file was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1593879116000'),
      createUser?: string(name='CreateUser', description='The ID of the Alibaba Cloud account used to create the file.', example='424732****'),
      currentVersion?: int32(name='CurrentVersion', description='The latest version number of the file.', example='3'),
      deletedStatus?: string(name='DeletedStatus', description='The status of the file. Valid values:

*   NORMAL: The file is not deleted.
*   RECYCLE_BIN: The file is stored in the recycle bin.
*   DELETED: The file is deleted.', example='RECYCLE'),
      fileDescription?: string(name='FileDescription', description='The description of the file.', example='My first DataWorks file'),
      fileFolderId?: string(name='FileFolderId', description='The ID of the folder to which the file belongs.', example='2735c2****'),
      fileId?: long(name='FileId', description='The file ID.', example='100000001'),
      fileName?: string(name='FileName', description='The name of the file.', example='ods_user_info_d'),
      fileType?: int32(name='FileType', description='The type of the code for the file. The code for files varies based on the file type. For more information, see [DataWorks nodes](https://help.aliyun.com/document_detail/600169.html).', example='10'),
      isMaxCompute?: boolean(name='IsMaxCompute', description='Indicates whether the resource file needs to be uploaded to MaxCompute. This parameter is returned only if the file is a MaxCompute resource file.', example='true'),
      lastEditTime?: long(name='LastEditTime', description='The time when the file was last modified. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1593879116000'),
      lastEditUser?: string(name='LastEditUser', description='The ID of the Alibaba Cloud account used to last modify the file.', example='424732****'),
      nodeId?: long(name='NodeId', description='The ID of the auto triggered node that is generated in the scheduling system after the file is committed.', example='300001'),
      owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the file owner.', example='7775674356****'),
      parentId?: long(name='ParentId', description='The ID of the node group file to which the current file belongs. This parameter is returned only if the current file is an inner file of the node group file.', example='-1'),
      useType?: string(name='UseType', description='The module to which the file belongs. Valid values:

*   NORMAL: The file is used for DataStudio.
*   MANUAL: The file is used for a manually triggered node.
*   MANUAL_BIZ: The file is used for a manually triggered workflow.
*   SKIP: The file is used for a dry-run node in DataStudio.
*   ADHOCQUERY: The file is used for an ad hoc query.
*   COMPONENT: The file is used for a script template.', example='NORMAL'),
    }(name='File', description='The basic information about the file.'),
    nodeConfiguration?: {
      applyScheduleImmediately?: string(name='ApplyScheduleImmediately', description='Indicates whether scheduling configurations immediately take effect after the deployment.', example='true'),
      autoRerunIntervalMillis?: int32(name='AutoRerunIntervalMillis', description='The interval between automatic reruns after an error occurs. Unit: milliseconds.

This parameter corresponds to the Rerun interval parameter that is displayed after the Auto Rerun upon Failure check box is selected in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console). The interval that you specify in the DataWorks console is measured in minutes. Pay attention to the conversion between the units of time when you call the operation.', example='120000'),
      autoRerunTimes?: int32(name='AutoRerunTimes', description='The number of automatic reruns that are allowed after an error occurs.', example='3'),
      cronExpress?: string(name='CronExpress', description='The cron expression that represents the periodic scheduling policy of the node.', example='00 05 00 * * ?'),
      cycleType?: string(name='CycleType', description='The type of the scheduling cycle. Valid values: NOT_DAY and DAY. The value NOT_DAY indicates that the node is scheduled to run by minute or hour. The value DAY indicates that the node is scheduled to run by day, week, or month.

This parameter corresponds to the Scheduling Cycle parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='DAY'),
      dependentNodeIdList?: string(name='DependentNodeIdList', description='The ID of the node on which the node that corresponds to the file depends when the DependentType parameter is set to USER_DEFINE. Multiple IDs are separated by commas (,).

The value of this parameter is equivalent to the ID of the node that you specified after you select Previous Cycle and set Depend On to Other Nodes in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='5,10,15,20'),
      dependentType?: string(name='DependentType', description='The type of the cross-cycle scheduling dependency of the node. Valid values:

*   SELF: The instance generated for the node in the current cycle depends on the instance generated for the node in the previous cycle.
*   CHILD: The instance generated for the node in the current cycle depends on the instances generated for the descendant nodes at the nearest level of the node in the previous cycle.
*   USER_DEFINE: The instance generated for the node in the current cycle depends on the instances generated for one or more specified nodes in the previous cycle.
*   NONE: No cross-cycle scheduling dependency type is selected for the node.', example='USER_DEFINE'),
      endEffectDate?: long(name='EndEffectDate', description='The end of the time range for automatic scheduling. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

Configuring this parameter is equivalent to specifying an end time for the Validity Period parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='4155787800000'),
      ignoreParentSkipRunningProperty?: string(name='IgnoreParentSkipRunningProperty', description='Indicates whether the dry-run property of the ancestor nodes of the node is skipped. This parameter corresponds to the Skip the dry-run property of the ancestor node parameter that is displayed after you configure the Depend On parameter in the Dependencies section of the Properties tab on the DataStudio page in the DataWorks console.', example='true'),
      imageId?: string(name='ImageId', description='The custom image ID.', example='m-bp1h4b5a8ogkbll2f3tr'),
      inputList?: [ 
        {
          input?: string(name='Input', description='The output name of the parent file on which the current file depends.

This parameter corresponds to the Output Name of Ancestor Node parameter under Parent Nodes after Same Cycle is selected in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='project.001_out'),
          parseType?: string(name='ParseType', description='The mode of the configuration file dependency. Valid values:

*   MANUAL: Scheduling dependencies are manually configured.
*   AUTO: Scheduling dependencies are automatically parsed.', example='MANUAL'),
        }
      ](name='InputList', description='The output information about the parent files on which the current file depends.'),
      inputParameters?: [ 
        {
          parameterName?: string(name='ParameterName', description='The name of the input parameter of the node. In the code, you can use the ${...} method to reference the input parameter of the node.

This parameter corresponds to the Parameter Name parameter in the Input Parameters table in the Input and Output Parameters section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='input'),
          valueSource?: string(name='ValueSource', description='The value source of the input parameter of the node.

This parameter corresponds to the Value Source parameter in the Input Parameters table in the Input and Output Parameters section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='project_001.parent_node:outputs'),
        }
      ](name='InputParameters', description='The input parameters of the node.'),
      outputList?: [ 
        {
          output?: string(name='Output', description='The output name of the current file.

This parameter corresponds to the Output Name parameter under Output after Same Cycle is selected in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='dw_project.002_out'),
          refTableName?: string(name='RefTableName', description='The output table name of the current file.

This parameter corresponds to the Output Table Name parameter under Output after Same Cycle is selected in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='ods_user_info_d'),
        }
      ](name='OutputList', description='The output information about the current file.'),
      outputParameters?: [ 
        {
          description?: string(name='Description', description='The description of the output parameter of the node.', example='It\\"s a context output parameter.'),
          parameterName?: string(name='ParameterName', description='The name of the output parameter of the node.

This parameter corresponds to the Parameter Name parameter in the Output Parameters table in the Input and Output Parameters section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='output'),
          type?: string(name='Type', description='The type of the output parameter of the node. Valid values:

*   1: indicates a constant.
*   2: indicates a variable.
*   3: indicates a pass-through variable.

This parameter corresponds to the Type parameter in the Output Parameters table in the Input and Output Parameters section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='1'),
          value?: string(name='Value', description='The value of the output parameter of the node.

This parameter corresponds to the Value parameter in the Output Parameters table in the Input and Output Parameters section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='${bizdate}'),
        }
      ](name='OutputParameters', description='The output parameters of the node.'),
      paraValue?: string(name='ParaValue', description='The scheduling parameters of the node.

This parameter corresponds to the Scheduling Parameter section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console). For more information about the configurations of scheduling parameters, see [Configure scheduling parameters](https://help.aliyun.com/document_detail/137548.html).', example='a=x b=y'),
      rerunMode?: string(name='RerunMode', description='Indicates whether the node that corresponds to the file can be rerun. Valid values:

*   ALL_ALLOWED: The node can be rerun regardless of whether it is successfully run or fails to run.
*   FAILURE_ALLOWED: The node can be rerun only after it fails to run.
*   ALL_DENIED: The node cannot be rerun regardless of whether it is successfully run or fails to run.

This parameter corresponds to the Rerun parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='ALL_ALLOWED'),
      resourceGroupId?: long(name='ResourceGroupId', description='The ID of the resource group that is used to run the node that corresponds to the file. You can call the [ListResourceGroups](https://help.aliyun.com/document_detail/173913.html) operation to query the available resource groups in the workspace.', example='375827434852437'),
      schedulerType?: string(name='SchedulerType', description='The scheduling type of the node. Valid values:

*   NORMAL: The node is an auto triggered node.
*   MANUAL: The node is a manually triggered node. Manually triggered nodes cannot be automatically triggered. They correspond to the nodes in the Manually Triggered Workflows pane.
*   PAUSE: The node is a paused node.
*   SKIP: The node is a dry-run node. Dry-run nodes are started as scheduled, but the system sets the status of the nodes to successful when it starts to run them.', example='NORMAL'),
      startEffectDate?: long(name='StartEffectDate', description='The beginning of the time range for automatic scheduling. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

Configuring this parameter is equivalent to specifying a start time for the Validity Period parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='936923400000'),
      startImmediately?: boolean(name='StartImmediately', description='Indicates whether a node is immediately run after the node is deployed to the production environment.

This parameter is valid only for an EMR Spark Streaming node or an EMR Streaming SQL node. This parameter corresponds to the Start Method parameter in the Schedule section of the Configure tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='true'),
      stop?: boolean(name='Stop', description='Indicates whether the scheduling for the node is suspended Valid values:

*   true
*   false

This parameter corresponds to the Recurrence parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='false'),
      timeout?: int32(name='Timeout', description='The timeout period.', example='1'),
    }(name='NodeConfiguration', description='The scheduling configurations of the file.'),
    resourceDownloadLink?: {
      downloadLink?: string(name='downloadLink', description='The download URL of the resource.', example='http://xx'),
    }(name='ResourceDownloadLink', description='The download URL of the resource.'),
  }(name='Data', description='The details of the file.'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetFile  GetFileRequest
  * @return GetFileResponse
 */
async function getFile(request: GetFileRequest): GetFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetFile', 'POST', '/', 'json', true, 'form', request);
}

model GetFileVersionRequest {
  regionId?: string(name='RegionId', position='Host'),
  fileId: long(name='FileId', description='The file ID. You can call the [ListFiles](https://help.aliyun.com/document_detail/173942.html) operation to query the ID.

This parameter is required.', example='1000001', position='Body'),
  fileVersion: int32(name='FileVersion', description='The file version whose information you want to query.

This parameter is required.', example='2', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can click the Workspace Manage icon in the upper-right corner of the DataStudio page to go to the Workspace page and query the workspace ID.', example='1000011', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The unique identifier of the DataWorks workspace. You can view the identifier in the upper part of the DataStudio page. You can also select another identifier to switch to another workspace.

You must configure either this parameter or the ProjectId parameter to determine the DataWorks workspace to which the operation is applied.', example='dw_project', position='Body'),
}

model GetFileVersionResponseBody = {
  data?: {
    changeType?: string(name='ChangeType', description='The type of the change to the file of the current version. Valid values: CREATE, UPDATE, and DELETE.', example='UPDATE'),
    comment?: string(name='Comment', description='The description of the file version.', example='Second version submission'),
    commitTime?: long(name='CommitTime', description='The time when the file version was generated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1593881265000'),
    commitUser?: string(name='CommitUser', description='The ID of the Alibaba Cloud account that is used to generate the file of the current version.', example='7384234****'),
    fileContent?: string(name='FileContent', description='The code in the file of the current version.', example='SHOW TABLES;'),
    fileName?: string(name='FileName', description='The name of the file of the current version.', example='ods_user_info_d'),
    filePropertyContent?: string(name='FilePropertyContent', description='The basic information about the file of the current version.', example='{"fileName":"ods_user_info_d","fileType":10}'),
    fileVersion?: int32(name='FileVersion', description='The file version.', example='2'),
    isCurrentProd?: boolean(name='IsCurrentProd', description='Indicates whether the version is the latest version in the production environment. Valid values:

*   true
*   false', example='true'),
    nodeContent?: string(name='NodeContent', description='The scheduling configurations of the node that corresponds to the file of the current version.', example='{"cycleType":0,"cronExpress":"00 05 00 * * ?"}'),
    nodeId?: long(name='NodeId', description='The ID of the node that corresponds to the file version.', example='3000001'),
    status?: string(name='Status', description='The status of the file version. Valid values:

*   COMMITTING
*   COMMITTED or CHECK_OK
*   PACKAGED
*   DEPLOYING
*   DEPLOYED
*   CANCELLED', example='COMMITTED'),
    useType?: string(name='UseType', description='The module to which the file belongs. Valid values:

*   0: NORMAL, which indicates that the file is used for DataStudio.
*   1: MANUAL, which indicates that the file is used for a manually triggered node.
*   2: MANUAL_BIZ, which indicates that the file is used for a manually triggered workflow.
*   3: SKIP, which indicates that the file is used for a dry-run node in DataStudio.
*   10: ADHOCQUERY, which indicates that the file is used for an ad hoc query.
*   30: COMPONENT, which indicates that the file is used for a script template.', example='0'),
  }(name='Data', description='The details of the file version.'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetFileVersionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetFileVersionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetFileVersion  GetFileVersionRequest
  * @return GetFileVersionResponse
 */
async function getFileVersion(request: GetFileVersionRequest): GetFileVersionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetFileVersion', 'POST', '/', 'json', true, 'form', request);
}

model GetFolderRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  folderId?: string(name='FolderId', example='273****', position='Body'),
  folderPath?: string(name='FolderPath', example='Business_process/my_first_business_process/MaxCompute/ods_layer', minLength=1, position='Body'),
  projectId?: long(name='ProjectId', example='1000011', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
}

model GetFolderResponseBody = {
  data?: {
    folderId?: string(name='FolderId', example='2735****'),
    folderPath?: string(name='FolderPath', example='Business_process/my_first_business_process/MaxCompute/ods_layer'),
  }(name='Data'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model GetFolderResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetFolderResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetFolder  GetFolderRequest
  * @return GetFolderResponse
 */
async function getFolder(request: GetFolderRequest): GetFolderResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetFolder', 'POST', '/', 'json', true, 'form', request);
}

model GetFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
}

model GetFunctionResponseBody = {
  function?: {
    createTime?: long(name='CreateTime', description='The time when the UDF was created. This value is a UNIX timestamp.', example='1724505917000'),
    id?: long(name='Id', description='The ID of the UDF.', example='860438872620113XXXX'),
    modifyTime?: long(name='ModifyTime', description='The time when the UDF was last modified. This value is a UNIX timestamp.', example='1724506661000'),
    name?: string(name='Name', description='The name of the UDF.', example='Function name'),
    owner?: string(name='Owner', description='The owner of the UDF.', example='110755000425XXXX'),
    projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace to which the UDF belongs.', example='10000'),
    spec?: string(name='Spec', description='The FlowSpec field information about the UDF. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).', example='{
    "version": "1.1.0",
    "kind": "Function",
    "spec": {
        "functions": [
            {
                "name": "Function_Name",
                "id": "580667964888595XXXX",
                "script": {
                    "content": "{  \\"uuid\\": \\"580667964888595XXXX\\",  \\"name\\": \\"Function_Name\\",  \\"datasource\\": {    \\"type\\": \\"odps\\",    \\"name\\": \\"odps_first\\"  },  \\"runtimeResource\\": {    \\"resourceGroup\\": \\"S_res_group_XXXX_XXXX\\",    \\"resourceGroupId\\": 6591XXXX  }}",
                    "path": "XXX/OpenAPI/Function/Function_Name",
                    "runtime": {
                        "command": "ODPS_FUNCTION"
                    }
                },
                "datasource": {
                    "name": "odps_first",
                    "type": "odps"
                },
                "runtimeResource": {
                    "resourceGroup": "S_res_group_XXXX_XXXX",
                    "id": "723932906364267XXXX",
                    "resourceGroupId": "6591XXXX"
                },
                "metadata": {
                    "owner": "110755000425XXXX"
                }
            }
        ]
    }
}'),
  }(name='Function', description='The information about the UDF.'),
  requestId?: string(name='RequestId', description='The request ID.', example='6CF95929-6D12-5A88-8CC3-4B2F4C2EXXXX'),
}

model GetFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetFunctionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetFunction  GetFunctionRequest
  * @return GetFunctionResponse
 */
async function getFunction(request: GetFunctionRequest): GetFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetFunction', 'GET', '/', 'json', false, 'json', request);
}

model GetIDEEventDetailRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  messageId: string(name='MessageId', description='The message ID in DataWorks OpenEvent. You can obtain the ID from a received message when an extension point event is triggered.

This parameter is required.', example='8abcb91f-d266-4073-b907-2ed67****1', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can obtain the ID from the message.

This parameter is required.', example='10000', position='Body'),
}

model GetIDEEventDetailResponseBody = {
  eventDetail?: {
    committedFile?: {
      changeType?: string(name='ChangeType', description='The type of the change to the file of the current version. Valid values: CREATE, UPDATE, and DELETE.', example='UPDATE'),
      comment?: string(name='Comment', description='The description of the file version.', example='Second version submission'),
      committor?: string(name='Committor', description='The ID of the Alibaba Cloud account that is used to generate the file of the current version.', example='7384234****'),
      content?: string(name='Content', description='The code in the file of the current version.', example='SHOW TABLES;'),
      fileId?: long(name='FileId', description='The file ID.', example='1234123'),
      fileName?: string(name='FileName', description='The name of the file.', example='hello_dataworks.sql'),
      filePropertyContent?: {
        businessId?: long(name='BusinessId', description='The ID of the workflow to which the file belongs.', example='74328'),
        currentVersion?: long(name='CurrentVersion', description='The latest version number of the file.', example='1'),
        dataSourceName?: string(name='DataSourceName', description='The name of the data source with which the file is associated.', example='odps_source'),
        folderId?: string(name='FolderId', description='The ID of the folder to which the file belongs. You can call the [GetFolder](https://help.aliyun.com/document_detail/173952.html) operation to query the details of the file based on the folder ID.', example='aldurie78l2falure'),
        owner?: string(name='Owner', description='The file owner.', example='7384234****'),
        parentFileId?: long(name='ParentFileId', description='The ID of the do-while node or for-each node that corresponds to the file.', example='1234122'),
      }(name='FilePropertyContent', description='The details of the file.'),
      fileType?: long(name='FileType', description='The file type. The code for files varies based on the file type. For more information, see [DataWorks nodes](https://help.aliyun.com/document_detail/600169.html).', example='10'),
      nodeConfiguration?: {
        autoRerunIntervalMillis?: long(name='AutoRerunIntervalMillis', description='The interval at which the node corresponding to the file is rerun. Unit: milliseconds.', example='120000'),
        autoRerunTimes?: long(name='AutoRerunTimes', description='The number of times that the node corresponding to the file can be rerun.', example='3'),
        cronExpress?: string(name='CronExpress', description='The cron expression that is used to schedule the node corresponding to the file.', example='00 05 00 * * ?'),
        cycleType?: string(name='CycleType', description='The type of the scheduling cycle of the node that corresponds to the file. Valid values: NOT_DAY and DAY. The value NOT_DAY indicates that the node is scheduled to run by minute or hour. The value DAY indicates that the node is scheduled to run by day, week, or month.

This parameter corresponds to the Scheduling Cycle parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='DAY'),
        dependentNodeIdList?: string(name='DependentNodeIdList', description='The ID of the node on which the node that corresponds to the file depends when the DependentType parameter is set to USER_DEFINE. Multiple IDs are separated by commas (,).

The value of this parameter is equivalent to the ID of the node that you specified after you select Other Nodes for Cross-Cycle Dependency (Original Previous-Cycle Dependency) in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='5,10,15,20'),
        dependentType?: string(name='DependentType', description='The type of the cross-cycle scheduling dependency of the node. Valid values:

*   SELF: The instance generated for the node in the current cycle depends on the instance generated for the node in the previous cycle.
*   CHILD: The instance generated for the node in the current cycle depends on the instances generated for the descendant nodes at the nearest level of the node in the previous cycle.
*   USER_DEFINE: The instance generated for the node in the current cycle depends on the instances generated for one or more specified nodes in the previous cycle.
*   NONE: No cross-cycle scheduling dependency type is selected for the node.', example='USER_DEFINE'),
        inputList?: [ 
          {
            input?: string(name='Input', description='The output name of the parent file on which the current file depends.

This parameter corresponds to the Output Name of Ancestor Node parameter under Parent Nodes in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='dw_project_root'),
            parseType?: string(name='ParseType', description='The mode of the configuration file dependency. Valid values:

*   MANUAL: Scheduling dependencies are manually configured.
*   AUTO: Scheduling dependencies are automatically parsed.', example='MANUAL'),
          }
        ](name='InputList', description='The output information about the parent files on which the current file depends.'),
        outputList?: [ 
          {
            output?: string(name='Output', description='The output name of the current file.

This parameter corresponds to the Output Name parameter under Output Name of Current Node in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='dw_project.002_out'),
            refTableName?: string(name='RefTableName', description='The output table name of the current file.

This parameter corresponds to the Output Table Name parameter under Output Name of Current Node in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='ods_user_info_d'),
          }
        ](name='OutputList', description='The output information about the current file.'),
        paraValue?: string(name='ParaValue', description='The scheduling parameters of the node.

This parameter corresponds to the Scheduling Parameter section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console). For more information about the configurations of scheduling parameters, see [Configure scheduling parameters](https://help.aliyun.com/document_detail/137548.html).', example='a=x b=y'),
        rerunMode?: string(name='RerunMode', description='Indicates whether the node that corresponds to the file can be rerun. Valid values:

*   ALL_ALLOWED: The node can be rerun regardless of whether it is successfully run or fails to run.
*   FAILURE_ALLOWED: The node can be rerun only after it fails to run.
*   ALL_DENIED: The node cannot be rerun regardless of whether it is successfully run or fails to run.

This parameter corresponds to the Rerun parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='ALL_ALLOWED'),
        resourceGroupId?: long(name='ResourceGroupId', description='The ID of the resource group that is used to run the node that corresponds to the file. You can call the [ListResourceGroups](https://help.aliyun.com/document_detail/173913.html) operation to query the available resource groups in the workspace.', example='375827434852437'),
        schedulerType?: string(name='SchedulerType', description='The scheduling type of the node. Valid values:

*   NORMAL: The node is an auto triggered node.
*   MANUAL: The node is a manually triggered node. Manually triggered nodes cannot be automatically triggered. They correspond to the nodes in the Manually Triggered Workflows pane.
*   PAUSE: The node is a paused node.
*   SKIP: The node is a dry-run node. Dry-run nodes are started as scheduled, but the system sets the status of the nodes to successful when it starts to run them.', example='NORMAL'),
      }(name='NodeConfiguration', description='The scheduling properties of the node that corresponds to the file.'),
      nodeId?: long(name='NodeId', description='The ID of the node that is scheduled.', example='421429'),
      useType?: string(name='UseType', description='The module to which the file belongs. Valid values:

*   NORMAL: The file is used for DataStudio.
*   MANUAL: The file is used for a manually triggered node.
*   MANUAL_BIZ: The file is used for a manually triggered workflow.
*   SKIP: The file is used for a dry-run node in DataStudio.
*   ADHOCQUERY: The file is used for an ad hoc query.
*   COMPONENT: The file is used for a script template.', example='NORMAL'),
    }(name='CommittedFile', description='The data snapshot when the file is committed and deployed.

This parameter is valid only if the message type is IDE_FILE_SUBMIT_BEFORE or IDE_FILE_DEPLOY_BEFORE.'),
    deletedFile?: {
      businessId?: long(name='BusinessId', description='The ID of the workflow to which the file belongs.', example='74328'),
      content?: string(name='Content', description='The code in the file of the current version.', example='SHOW TABLES;'),
      currentVersion?: long(name='CurrentVersion', description='The latest version number of the file.', example='1'),
      dataSourceName?: string(name='DataSourceName', description='The name of the data source with which the file is associated.', example='odps_source'),
      fileId?: long(name='FileId', description='The file ID.', example='1234123'),
      fileName?: string(name='FileName', description='The name of the file.', example='hello_dataworks.sql'),
      fileType?: long(name='FileType', description='The file type. The code for files varies based on the file type. For more information, see [DataWorks nodes](https://help.aliyun.com/document_detail/600169.html).', example='10'),
      folderId?: string(name='FolderId', description='The ID of the folder to which the file belongs. You can call the [GetFolder](https://help.aliyun.com/document_detail/173952.html) operation to query the details of the file based on the folder ID.', example='aldurie78l2falure'),
      nodeId?: long(name='NodeId', description='The ID of the node that is scheduled.', example='421429'),
      owner?: string(name='Owner', description='The file owner.', example='7384234****'),
      parentFileId?: long(name='ParentFileId', description='The ID of the do-while node or for-each node that corresponds to the file.', example='1234122'),
      useType?: string(name='UseType', description='The module to which the file belongs. Valid values:

*   NORMAL: The file is used for DataStudio.
*   MANUAL: The file is used for a manually triggered node.
*   MANUAL_BIZ: The file is used for a manually triggered workflow.
*   SKIP: The file is used for a dry-run node in DataStudio.
*   ADHOCQUERY: The file is used for an ad hoc query.
*   COMPONENT: The file is used for a script template.', example='NORMAL'),
    }(name='DeletedFile', description='The data snapshot when the file is deleted. This parameter is valid only if the message type is IDE_FILE_DELETE_BEFORE.'),
    fileExecutionCommand?: {
      content?: string(name='Content', description='The code in the file of the current version.', example='SHOW TABLES;'),
      dataSourceName?: string(name='DataSourceName', description='The name of the data source with which the file is associated.', example='odps_source'),
      fileId?: long(name='FileId', description='The file ID.', example='1234123'),
      fileType?: long(name='FileType', description='The file type. The code for files varies based on the file type. For more information, see [DataWorks nodes](https://help.aliyun.com/document_detail/600169.html).', example='10'),
    }(name='FileExecutionCommand', description='The data snapshot when the code in the file is run. This parameter is valid only if the message type is IDE_FILE_EXECUTE_BEFORE.'),
    tableModel?: {
      columns?: [ 
        {
          columnName?: string(name='ColumnName', description='The name of the column.', example='ID'),
          columnType?: string(name='ColumnType', description='The data type of the column.', example='BIGINT'),
          comment?: string(name='Comment', description='The remarks of the column.', example='ID'),
          isPartitionColumn?: boolean(name='IsPartitionColumn', description='Indicates whether the column is a partition key column. Valid values:

*   true
*   false', example='false'),
        }
      ](name='Columns', description='The columns in the table.'),
      comment?: string(name='Comment', description='The remarks of the table.', example='A new table'),
      dataSourceName?: string(name='DataSourceName', description='The name of the data source to which the table belongs.', example='odps_source'),
      env?: string(name='Env', description='The environment in which the table is used. Valid values:

*   DEV
*   PROD', example='DEV'),
      lifeCycle?: long(name='LifeCycle', description='The lifecycle of the table. Unit: day.', example='7'),
      location?: string(name='Location', description='The path of the table.', example='hdfs://path/to/object'),
      tableName?: string(name='TableName', description='The name of the table.', example='tb_hello'),
    }(name='TableModel', description='The data snapshot when the table is committed and deployed. This parameter is valid only if the message type is IDE_TABLE_SUBMIT_BEFORE or IDE_TABLE_DEPLOY_BEFORE.'),
  }(name='EventDetail', description='The data snapshot that is generated when an extension point event is triggered.

The fields contained in data snapshots vary based on the types of the triggered extension point events. For more information, see the description of the fields.'),
  requestId?: string(name='RequestId', description='The request ID.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
}

model GetIDEEventDetailResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetIDEEventDetailResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetIDEEventDetail  GetIDEEventDetailRequest
  * @return GetIDEEventDetailResponse
 */
async function getIDEEventDetail(request: GetIDEEventDetailRequest): GetIDEEventDetailResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetIDEEventDetail', 'POST', '/', 'json', true, 'form', request);
}

model GetJobStatusRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  jobId: string(name='JobId', description='The ID of the asynchronous task that is generated after you call an asynchronous operation.

This parameter is required.', example='70ecdaec-bf21-4c11-8ecb-4f77453ceea8', position='Query'),
}

model GetJobStatusResponseBody = {
  jobStatus?: {
    completed?: string(name='Completed', description='Indicates whether the asynchronous task is complete. Valid values: True False', example='False'),
    createTime?: string(name='CreateTime', description='The time when the asynchronous task was created.', example='1729063449802'),
    error?: string(name='Error', description='The error message returned if the asynchronous task fails.', example='Not Found'),
    jobId?: string(name='JobId', description='The ID of the asynchronous task.', example='C664CDE3-9C0B-5792-B17F-6C543783BBBC'),
    jobType?: string(name='JobType', description='The type of the asynchronous task. Valid values:

*   **Create**: The asynchronous task is used to create an object.
*   **Update**: The asynchronous task is used to update an object.
*   **Cancel**: The asynchronous task is used to cancel an operation.', example='Create'),
    status?: string(name='Status', description='The status of the asynchronous task. Valid values:

*   **Success**
*   **Fail**
*   **Cancel**
*   **Running**', example='Success'),
  }(name='JobStatus', description='The real-time status information of the asynchronous task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='5E2BFE96-C0E0-5A98-85C8-633EC803198D'),
}

model GetJobStatusResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetJobStatusResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetJobStatus  GetJobStatusRequest
  * @return GetJobStatusResponse
 */
async function getJobStatus(request: GetJobStatusRequest): GetJobStatusResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetJobStatus', 'GET', '/', 'json', false, 'json', request);
}

model GetLineageRelationshipRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The lineage ID. For more information, see the response returned by the ListLineageRelationships operation.

This parameter is required.', example='110xxxx:custom-table.xxxxx:maxcompute-table.project.test_big_lineage_080901:custom-sqlxx.00001', position='Query'),
}

model GetLineageRelationshipResponseBody = {
  lineageRelationship?: LineageRelationship(name='LineageRelationship'),
  requestId?: string(name='RequestId', example='58D5334A-B013-430E'),
}

model GetLineageRelationshipResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLineageRelationshipResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLineageRelationship  GetLineageRelationshipRequest
  * @return GetLineageRelationshipResponse
 */
async function getLineageRelationship(request: GetLineageRelationshipRequest): GetLineageRelationshipResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLineageRelationship', 'GET', '/', 'json', false, 'json', request);
}

model GetMetaCollectionRequest {
  regionId?: string(name='RegionId', position='Host'),
  id: string(name='Id', description='The collection ID.

This parameter is required.', example='category.123', position='Query'),
}

model GetMetaCollectionResponseBody = {
  metaCollection?: {
    administrators?: [ long ](name='Administrators'),
    createTime?: long(name='CreateTime', example='1668568601000'),
    createUser?: string(name='CreateUser', example='456789'),
    description?: string(name='Description'),
    id?: string(name='Id', description='The collection ID.', example='category.123'),
    modifyTime?: long(name='ModifyTime', example='1668568601000'),
    name?: string(name='Name', example='test_category'),
    parentId?: string(name='ParentId', description='The ID of the collection of the ancestor node. This parameter can be left empty.', example='category.12'),
    type?: string(name='Type', example='Category'),
  }(name='MetaCollection', description='The information about the collection.'),
  requestId?: string(name='RequestId', description='Id of the request', example='1AFAE64E-D1BE-432B-A9****'),
}

model GetMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetMetaCollection  GetMetaCollectionRequest
  * @return GetMetaCollectionResponse
 */
async function getMetaCollection(request: GetMetaCollectionRequest): GetMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMetaCollection', 'GET', '/', 'json', false, 'json', request);
}

model GetNetworkRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The network ID.

This parameter is required.', example='1000', position='Query'),
}

model GetNetworkResponseBody = {
  network?: {
    createTime?: long(name='CreateTime', description='The time when the network resource was created. The value is a 64-bit timestamp.', example='1727055811000'),
    createUser?: string(name='CreateUser', description='The ID of the user who creates the network resource.', example='11075500042XXXXX'),
    id?: long(name='Id', description='The network ID.', example='1000'),
    resourceGroupId?: string(name='ResourceGroupId', description='The ID of the serverless resource group.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
    securityGroupId?: string(name='SecurityGroupId', description='The security group ID.', example='sg-2ze13vamugr7jenXXXXX'),
    status?: string(name='Status', description='The status of the network resource. Valid values:

*   Pending: The network resource is waiting to be created.
*   Creating: The network resource is being created.
*   Running: The network resource is running as expected.
*   Deleting: The network resource is being deleted.
*   Deleted: The network resource is deleted.', example='Running'),
    vpcId?: string(name='VpcId', description='The ID of the virtual private cloud (VPC).', example='vpc-m2et4f3oc8msfbccXXXXX'),
    vswitchId?: string(name='VswitchId', description='The VSwitch ID.', example='vsw-uf8usrhs7hjd9amsXXXXX'),
  }(name='Network', description='The information about the network resource.'),
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetNetworkResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetNetworkResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetNetwork  GetNetworkRequest
  * @return GetNetworkResponse
 */
async function getNetwork(request: GetNetworkRequest): GetNetworkResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetNetwork', 'GET', '/', 'json', false, 'json', request);
}

model GetNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
}

model GetNodeResponseBody = {
  node?: {
    createTime?: long(name='CreateTime', description='The time when the node was created. This value is a UNIX timestamp.', example='1700539206000'),
    id?: long(name='Id', description='The ID of the node.', example='860438872620113XXXX'),
    modifyTime?: long(name='ModifyTime', description='The time when the node was last modified. This value is a UNIX timestamp.', example='1700539206000'),
    name?: string(name='Name', description='The name of the node.', example='Node name'),
    owner?: string(name='Owner', description='The owner of the node.', example='196596664824XXXX'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10000'),
    spec?: string(name='Spec', description='The FlowSpec field information about this node. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow).', example='{
    "version": "1.1.0",
    "kind": "Node",
    "spec": {
        "nodes": [
            {
                "recurrence": "Normal",
                "id": "860438872620113XXXX",
                "timeout": 0,
                "instanceMode": "T+1",
                "rerunMode": "Allowed",
                "rerunTimes": 3,
                "rerunInterval": 180000,
                "datasource": {
                    "name": "odps_test",
                    "type": "odps"
                },
                "script": {
                    "language": "odps-sql",
                    "path": "XX/OpenAPI_Test/ODPS_SQL_Test",
                    "runtime": {
                        "command": "ODPS_SQL",
                        "commandTypeId": 10
                    },
                    "content": "select now();",
                    "id": "853573334108680XXXX"
                },
                "trigger": {
                    "type": "Scheduler",
                    "id": "543680677872062XXXX",
                    "cron": "00 00 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "runtimeResource": {
                    "resourceGroup": "S_res_group_XXXX_XXXX",
                    "id": "623731286945488XXXX",
                    "resourceGroupId": "7201XXXX"
                },
                "name": "ODPS_SQL_Test",
                "owner": "110755000425XXXX",
                "metadata": {
                    "owner": "110755000425XXXX",
                    "ownerName": "XXXXX@test.XXX.com",
                    "projectId": "307XXX"
                },
                "inputs": {
                    "nodeOutputs": [
                        {
                            "data": "lwttest_standard_root",
                            "artifactType": "NodeOutput"
                        }
                    ]
                },
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "860438872620113XXXX",
                            "artifactType": "NodeOutput",
                            "refTableName": "ODPS_SQL_Test",
                            "isDefault": true
                        }
                    ]
                }
            }
        ],
        "flow": [
            {
                "nodeId": "860438872620113XXXX",
                "depends": [
                    {
                        "type": "Normal",
                        "output": "lwttest_standard_root"
                    }
                ]
            }
        ]
    },
    "metadata": {
        "uuid": "860438872620113XXXX"
    }
}'),
    taskId?: long(name='TaskId', description='The Id of the scheduled task after the node is published.', example='700006680527'),
  }(name='Node', description='The information about the node.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model GetNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetNodeResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetNode  GetNodeRequest
  * @return GetNodeResponse
 */
async function getNode(request: GetNodeRequest): GetNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetNode', 'GET', '/', 'json', false, 'json', request);
}

model GetPartitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  name: string(name='Name', description='This parameter is required.', example='ds=20250101', position='Query'),
  tableId: string(name='TableId', description='The table ID. For more details, refer to the response of the ListTables operation and [description of concepts related to metadata entities.](https://help.aliyun.com/document_detail/2880092.html)

This parameter is required.', example='maxcompute-column:11075xxxx::test_project:test_schema:test_table', position='Query'),
}

model GetPartitionResponseBody = {
  partition?: Partition(name='Partition'),
  requestId?: string(name='RequestId', example='D1E2E5BC-xxxx-xxxx-xxxx-xxxxxx'),
  success?: boolean(name='Success', example='true'),
}

model GetPartitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPartitionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetPartition  GetPartitionRequest
  * @return GetPartitionResponse
 */
async function getPartition(request: GetPartitionRequest): GetPartitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPartition', 'GET', '/', 'json', false, 'json', request);
}

model GetPipelineRunRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID of the process.

This parameter is required.', example='a7ef0634-20ec-4a7c-a214-54020f****', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Query'),
}

model GetPipelineRunResponseBody = {
  pipeline?: {
    createTime?: long(name='CreateTime', description='The time when the process was created. This value is a UNIX timestamp.', example='1724984066000'),
    creator?: string(name='Creator', description='The creator of the process.', example='137946317766XXXX'),
    id?: string(name='Id', description='The process ID.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX'),
    message?: string(name='Message', description='The error message returned when the process fails.', example='Error message'),
    modifyTime?: long(name='ModifyTime', description='The time when the process was modified. This value is a UNIX timestamp.', example='1724984066000'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='56160'),
    stages?: [ 
      {
        code?: string(name='Code', description='The code of the stage.', example='DEV_CHECK'),
        description?: string(name='Description', description='The description of the stage.', example='Phase description'),
        detail?: map[string]any(name='Detail', description='The details of the stage.'),
        message?: string(name='Message', description='The error message returned for the stage.', example='Exception information XXX'),
        name?: string(name='Name', description='The name of the stage.', example='Publish package build'),
        status?: string(name='Status', description='The status of the stage.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='Running'),
        step?: int32(name='Step', description='The step number of the stage.', example='1'),
        type?: string(name='Type', description='The type of the stage.

Valid values:

*   Deploy
*   Check
*   Offline
*   Build
*   Delete', example='Check'),
      }
    ](name='Stages', description='The information about stages in the process.'),
    status?: string(name='Status', description='The status of the process.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='Running'),
  }(name='Pipeline', description='The information about the process.'),
  requestId?: string(name='RequestId', description='The request ID.', example='08468352-032C-5262-AEDC-68C9FA05XXXX'),
}

model GetPipelineRunResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPipelineRunResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetPipelineRun  GetPipelineRunRequest
  * @return GetPipelineRunResponse
 */
async function getPipelineRun(request: GetPipelineRunRequest): GetPipelineRunResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPipelineRun', 'GET', '/', 'json', false, 'json', request);
}

model GetProjectRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='123456', position='Query'),
}

model GetProjectResponseBody = {
  project?: {
    aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group to which the workspace belongs.', example='rg-acfmzbn7pti3zfa'),
    aliyunResourceTags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='batch'),
        value?: string(name='Value', description='The tag value.', example='blue'),
      }
    ](name='AliyunResourceTags', description='The tags.'),
    description?: string(name='Description', description='The description of the workspace.', example='Financial analysis group project data development'),
    devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Indicates whether the development environment is enabled. Valid values:

*   true: The development environment is enabled. In this case, the development environment is isolated from the production environment in the workspace.
*   false: The development environment is disabled. In this case, only the production environment is used in the workspace.', example='true'),
    devRoleDisabled?: boolean(name='DevRoleDisabled', description='Indicates whether the Develop role is disabled. Valid values:

*   false
*   true', example='false'),
    displayName?: string(name='DisplayName', description='The display name of the workspace.', example='Sora financial analysis'),
    id?: long(name='Id', description='The workspace ID.', example='28477242'),
    name?: string(name='Name', description='The name of the workspace.', example='sora_finance'),
    owner?: string(name='Owner', description='The ID of the Alibaba Cloud account to which the workspace belongs.', example='207947397706614299'),
    paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Indicates whether scheduling of PAI tasks is enabled. Valid values:

*   true: Scheduling of PAI tasks is enabled. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: Scheduling of PAI tasks is disabled.', example='true'),
    status?: string(name='Status', description='The status of the workspace. Valid values:

*   Available
*   Initializing
*   InitFailed
*   Forbidden
*   Deleting
*   DeleteFailed
*   Frozen
*   Updating
*   UpdateFailed', example='Available'),
  }(name='Project', description='The information about the workspace.'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model GetProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetProjectResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetProject  GetProjectRequest
  * @return GetProjectResponse
 */
async function getProject(request: GetProjectRequest): GetProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetProject', 'GET', '/', 'json', false, 'json', request);
}

model GetProjectMemberRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='88757', position='Body'),
  userId: string(name='UserId', description='The ID of the account used by the member in the workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the Tenant Members and Roles page, view the ID of the account used by the member in the workspace.

This parameter is required.', example='123422344899', position='Body'),
}

model GetProjectMemberResponseBody = {
  projectMember?: {
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='88757'),
    roles?: [ 
      {
        code?: string(name='Code', description='The code of the role. Valid values:

*   role_project_admin: Workspace Administrator
*   role_project_dev: Develop
*   role_project_dg_admin: Data Governance Administrator
*   role_project_guest: Visitor
*   role_project_security: Security Administrator
*   role_project_deploy: Deploy
*   role_project_owner: Workspace Owner
*   role_project_data_analyst: Data Analyst
*   role_project_pe: O\\&M
*   role_project_erd: Model Designer', example='role_project_guest'),
        name?: string(name='Name', description='The name of the role.', example='Visitors'),
        type?: string(name='Type', description='The type of the role. Valid values:

*   UserCustom: custom role
*   System: built-in role', example='System'),
      }
    ](name='Roles', description='The roles that are assigned to the member in the workspace.'),
    status?: string(name='Status', description='The status of the member.

*   Normal
*   Forbidden', example='Normal'),
    userId?: string(name='UserId', description='The ID of the account used by the member in the workspace.', example='123422344899'),
  }(name='ProjectMember', description='The details about the member in the workspace.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
}

model GetProjectMemberResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetProjectMemberResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetProjectMember  GetProjectMemberRequest
  * @return GetProjectMemberResponse
 */
async function getProjectMember(request: GetProjectMemberRequest): GetProjectMemberResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetProjectMember', 'POST', '/', 'json', true, 'form', request);
}

model GetProjectRoleRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  code: string(name='Code', description='The code of the role in the DataWorks workspace. Valid values:

*   role_project_admin: workspace administrator
*   role_project_dev: developer
*   role_project_dg_admin: data governance administrator
*   role_project_guest: visitor
*   role_project_security: security administrator
*   role_project_deploy: deployer
*   role_project_owner: workspace owner
*   role_project_data_analyst: data analyst
*   role_project_pe: O\\&M engineer
*   role_project_erd: model designer

This parameter is required.', example='role_project_guest', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10002', position='Query'),
}

model GetProjectRoleResponseBody = {
  projectRole?: {
    code?: string(name='Code', description='The code of the role in the DataWorks workspace.', example='role_project_guest'),
    name?: string(name='Name', description='The name of the role in the DataWorks workspace.', example='Visitors'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10002'),
    type?: string(name='Type', description='The type of the role in the DataWorks workspace. Valid values:

*   UserCustom: user-defined role
*   System: system role', example='System'),
  }(name='ProjectRole', description='The role in the DataWorks workspace.'),
  requestId?: string(name='RequestId', description='The request ID.', example='82F28E60-CF48-5EDF-AB25-D806847B97D1'),
}

model GetProjectRoleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetProjectRoleResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetProjectRole  GetProjectRoleRequest
  * @return GetProjectRoleResponse
 */
async function getProjectRole(request: GetProjectRoleRequest): GetProjectRoleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetProjectRole', 'POST', '/', 'json', false, 'json', request);
}

model GetRerunWorkflowInstancesResultRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  operationId: string(name='OperationId', description='The operation ID used to asynchronously query the result of the workflow instance rerun. This value is obtained from the RerunWorkflowInstances operation.

This parameter is required.', example='e15ad21c-b0e9-4792-8f55-b037xxxxxxxx', position='Query'),
}

model GetRerunWorkflowInstancesResultResponseBody = {
  requestId?: string(name='RequestId', description='The request ID, used for log tracing and troubleshooting.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  result?: {
    failureMessage?: string(name='FailureMessage', description='The failure message. Returned if the rerun fails.', example='Invalid Param xxx'),
    status?: string(name='Status', description='The status. NotRun Success Failure', example='Success'),
  }(name='Result', description='The result of the workflow instance rerun.'),
}

model GetRerunWorkflowInstancesResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetRerunWorkflowInstancesResultResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetRerunWorkflowInstancesResult  GetRerunWorkflowInstancesResultRequest
  * @return GetRerunWorkflowInstancesResultResponse
 */
async function getRerunWorkflowInstancesResult(request: GetRerunWorkflowInstancesResultRequest): GetRerunWorkflowInstancesResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetRerunWorkflowInstancesResult', 'POST', '/', 'json', false, 'json', request);
}

model GetResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the file resource.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
}

model GetResourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='E871F6C0-2EFF-5790-A00D-C57543EEXXXX'),
  resource?: {
    createTime?: long(name='CreateTime', description='The time when the file resource was created. This value is a UNIX timestamp.', example='1700539206000'),
    id?: long(name='Id', description='The ID of the file resource.', example='860438872620113XXXX'),
    modifyTime?: long(name='ModifyTime', description='The time when the file resource was last modified. This value is a UNIX timestamp.', example='1700539206000'),
    name?: string(name='Name', description='The name of the file resource.', example='OpenAPI_Test_Resource. py'),
    owner?: string(name='Owner', description='The owner of the file resource.', example='110755000425XXXX'),
    projectId?: long(name='ProjectId', description='The ID of the workspace to which the file resource belongs.', example='10000'),
    spec?: string(name='Spec', description='The FlowSpec field information about the file resource. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow).', example='{
    "version": "1.1.0",
    "kind": "Resource",
    "spec": {
        "fileResources": [
            {
                "name": "OpenAPI_Test_Resource.py",
                "id": "631478864897630XXXX",
                "script": {
                    "content": "",
                    "path": "XX/OpenAPI_Test/Resource_Test/OpenAPI_Test_Resource.py",
                    "runtime": {
                        "command": "ODPS_PYTHON"
                    }
                },
                "type": "python",
                "file": {
                    "storage": {}
                },
                "datasource": {
                    "name": "odps_first",
                    "type": "odps"
                },
                "metadata": {
                    "owner": "110755000425XXXX"
                }
            }
        ]
    }
}'),
  }(name='Resource', description='The information about the file resource.'),
}

model GetResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetResource  GetResourceRequest
  * @return GetResourceResponse
 */
async function getResource(request: GetResourceRequest): GetResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetResource', 'GET', '/', 'json', false, 'json', request);
}

model GetResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Query'),
}

model GetResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  resourceGroup?: {
    aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group.', example='rg-aek2kqofrgXXXXX'),
    aliyunResourceTags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='key'),
        value?: string(name='Value', description='The tag value.', example='value'),
      }
    ](name='AliyunResourceTags', description='The tags.'),
    createTime?: long(name='CreateTime', description='The time when the resource group was created. The value is a 64-bit timestamp.', example='1727055811000'),
    createUser?: string(name='CreateUser', description='The ID of the account that is used to create the resource group.', example='11075500042XXXXX'),
    defaultVpcId?: string(name='DefaultVpcId', description='The ID of the virtual private cloud (VPC) with which the resource group is associated by default.', example='vpc-m2et4f3oc8msfbccXXXXX'),
    defaultVswitchId?: string(name='DefaultVswitchId', description='The ID of the vSwitch with which the resource group is associated by default.', example='vsw-uf8usrhs7hjd9amsXXXXX'),
    id?: string(name='Id', description='The ID of the resource group.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
    name?: string(name='Name', description='The name of the resource group.', example='common_resource_group'),
    orderInstanceId?: string(name='OrderInstanceId', description='The instance ID of the order that is used to create the resource group.', example='c442b330-3b10-4584-959e-736e4edXXXXX'),
    paymentType?: string(name='PaymentType', description='The billing method of the resource group. Valid values: PrePaid and PostPaid. The value PrePaid indicates the subscription billing method, and the value PostPaid indicates the pay-as-you-go billing method.', example='PrePaid'),
    remark?: string(name='Remark', description='The description of the resource group.', example='Create a common resource group for common tasks'),
    resourceGroupType?: string(name='ResourceGroupType', description='The type of the resource group. Valid values:

*   CommonV2: serverless resource group
*   ExclusiveDataIntegration: exclusive resource group for Data Integration
*   ExclusiveScheduler: exclusive resource group for scheduling
*   ExclusiveDataService: exclusive resource group for DataService Studio', example='CommonV2'),
    spec?: {
      amount?: int32(name='Amount', description='The number of resources in the resource group.', example='1'),
      standard?: string(name='Standard', description='The number of compute units (CUs) in the resource group.', example='2CU'),
    }(name='Spec', description='The specifications of the resource group.'),
    status?: string(name='Status', description='The status of the resource group. Valid values:

*   Normal: The resource group is running or in use.
*   Stop: The resource group is expired.
*   Deleted: The resource group is released or destroyed.
*   Creating: The resource group is being created.
*   CreateFailed: The resource group fails to be created.
*   Updating: The resource group is being scaled in or out, or the configurations of the resource group are being changed.
*   UpdateFailed: The resource group fails to be scaled out or upgraded.
*   Deleting: The resource group is being released or destroyed.
*   DeleteFailed: The resource group fails to be released or destroyed.
*   Timeout: The operations that are performed on the resource group time out.
*   Freezed: The resource group is frozen.
*   Starting: The resource group is being started.', example='Normal'),
  }(name='ResourceGroup', description='The details about the resource group.'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetResourceGroupResponseBody(name='body'),
}

/**
  * @description You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * @param request  the request parameters of GetResourceGroup  GetResourceGroupRequest
  * @return GetResourceGroupResponse
 */
async function getResourceGroup(request: GetResourceGroupRequest): GetResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetResourceGroup', 'GET', '/', 'json', false, 'json', request);
}

model GetRouteRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The route ID.

This parameter is required.', example='1000', position='Query'),
}

model GetRouteResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  route?: {
    createTime?: long(name='CreateTime', description='The time when the route was created. The value is a 64-bit timestamp.', example='1727055811000'),
    destinationCidr?: string(name='DestinationCidr', description='The CIDR block of the destination-based route.', example='192.168.0.0/16'),
    id?: long(name='Id', description='The route ID.', example='1000'),
    networkId?: long(name='NetworkId', description='The network ID.', example='1000'),
    resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
    resourceId?: string(name='ResourceId', description='The network resource ID.', example='ns-679XXXXX'),
  }(name='Route', description='The information about the route.'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetRouteResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetRouteResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetRoute  GetRouteRequest
  * @return GetRouteResponse
 */
async function getRoute(request: GetRouteRequest): GetRouteResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetRoute', 'GET', '/', 'json', false, 'json', request);
}

model GetSchemaRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The schema ID. You can call the ListSchemas operation to query the ID. For more information, see [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

The common format of this parameter is `${Entity type}:${Instance ID or escaped URL}:${Catalog identifier}:${Database name}:${Schema name}`. If a level does not exist, specify an empty string as a placeholder.

>  For MaxCompute tables, specify an empty string at the Instance ID level and a MaxCompute project name at the Database name level. Make sure that the three-layer model is enabled for the MaxCompute project.

You can configure this parameter in one of the following formats based on your data source type:

`maxcompute-schema:::project_name:schema_name` (Three-layer model is enabled for the MaxCompute project.)

`holo-schema:instance_id::database_name:schema_name`

> \\
`instance_id`: the ID of a Hologres instance\\
`database_name`: the name of a database\\
`project_name`: the name of a MaxCompute project\\
`schema_name`: the name of a schema

This parameter is required.', example='maxcompute-schema:123456XXX::test_project:default
holo-schema:h-abc123xxx::test_db:test_schema', position='Query'),
}

model GetSchemaResponseBody = {
  requestId?: string(name='RequestId', example='A89B5D9D-74EA-XXXXXX'),
  schema?: Schema(name='Schema'),
  success?: boolean(name='Success', example='true'),
}

model GetSchemaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSchemaResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this API operation to query the information only about MaxCompute and Hologres schemas.
  * @param request  the request parameters of GetSchema  GetSchemaRequest
  * @return GetSchemaResponse
 */
async function getSchema(request: GetSchemaRequest): GetSchemaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSchema', 'GET', '/', 'json', false, 'json', request);
}

model GetTableRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The table ID. For more information, see [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

The common format of this parameter is `${Entity type}:${Instance ID or escaped URL}:${Catalog identifier}:${Database name}:${Schema name}:${Table name}`. If a level does not exist, specify an empty string as a placeholder.

>  For MaxCompute and DLF data sources, specify an empty string at the Instance ID level.

>  For StarRocks data sources, specify a catalog name at the Catalog identifier level. For DLF data sources, specify a catalog ID at the Catalog identifier level. Other types of data sources do not support the Catalog identifier level. You can specify an empty string as a placeholder.

>  For MaxCompute data sources, specify a MaxCompute project name at the Database name level. If the three-layer model is enabled for your MaxCompute project, you must specify a schema name at the Schema name level. Otherwise, you can specify an empty string as a placeholder.

You can configure this parameter in one of the following formats based on your data source type:

`maxcompute-table:::project_name:[schema_name]:table_name`

`dlf-table::catalog_id:database_name::table_name`

`hms-table:instance_id::database_name::table_name`

`holo-table:instance_id::database_name:schema_name:table_name`

`mysql-table:(instance_id|encoded_jdbc_url)::database_name::table_name`

> \\
`instance_id`: the ID of an instance. If the related data source is added to DataWorks in Alibaba Cloud instance mode, you must configure this parameter.\\
`encoded_jdbc_url`: the JDBC connection string that is URL-encoded. If the related data source is added to DataWorks in connection string mode, you must configure this parameter.\\
`catalog_id`: the ID of a DLF catalog.\\
`project_name`: the name of a MaxCompute project.\\
`database_name`: the name of a database.\\
`schema_name`: the name of a schema. For a MaxCompute table, if the three-layer model is enabled for the MaxCompute project to which the table belongs, you must configure this parameter. Otherwise, you can specify an empty string for schema_name as a placeholder.\\
`table_name`: the name of a table.

This parameter is required.', example='maxcompute-table:123456XXX::test_project::test_tbl
dlf-table:123456XXX:test_catalog:test_db::test_tbl
hms-table:c-abc123xxx::test_db::test_tbl
holo-table:h-abc123xxx::test_db:test_schema:test_tbl', position='Query'),
  includeBusinessMetadata?: boolean(name='IncludeBusinessMetadata', example='true', position='Query'),
}

model GetTableResponseBody = {
  requestId?: string(name='RequestId', example='7B3435F4-2D91-XXX'),
  success?: boolean(name='Success', example='true'),
  table?: Table(name='Table'),
}

model GetTableResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTableResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTable  GetTableRequest
  * @return GetTableResponse
 */
async function getTable(request: GetTableRequest): GetTableResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTable', 'GET', '/', 'json', false, 'json', request);
}

model GetTaskRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model GetTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  task?: {
    baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
    createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
    createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
    dataSource?: {
      name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
    }(name='DataSource', description='The information about the associated data source.'),
    dependencies?: [ 
      {
        type?: string(name='Type', description='The dependency type. Valid values:

*   CrossCycleDependsOnChildren: cross-cycle dependency on level-1 descendant nodes
*   CrossCycleDependsOnSelf: cross-cycle dependency on the current node
*   CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
*   Normal: same-cycle scheduling dependency', example='Normal'),
        upstreamOutput?: string(name='UpstreamOutput', description='The identifier of the output of the ancestor task. This parameter is returned only if `same-cycle scheduling dependencies` and the node input are configured.', example='pre.odps_sql_demo_0'),
        upstreamTaskId?: string(name='UpstreamTaskId', description='The ancestor task ID. This parameter is returned only if `cross-cycle scheduling dependencies` or `same-cycle scheduling dependencies` and the node input are not configured.', example='1234'),
      }
    ](name='Dependencies', description='The dependency information.'),
    description?: string(name='Description', description='The description of the task.', example='test'),
    envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
    id?: long(name='Id', description='The instance ID.', example='1234'),
    inputs?: {
      variables?: [ 
        {
          name?: string(name='Name', description='The name of the variable.', example='key1'),
          type?: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output', example='Constant'),
          value?: string(name='Value', description='The value of the variable.', example='Value1'),
        }
      ](name='Variables', description='The variables.'),
    }(name='Inputs', description='The input information.'),
    instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
    modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
    modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
    name?: string(name='Name', description='The name of the task.', example='SQL node'),
    outputs?: {
      taskOutputs?: [ 
        {
          output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
        }
      ](name='TaskOutputs', description='The task outputs.'),
      variables?: [ 
        {
          name?: string(name='Name', description='The name of the variable.', example='key1'),
          type?: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output', example='Constant'),
          value?: string(name='Value', description='The value of the variable.', example='value1'),
        }
      ](name='Variables', description='The variables.'),
    }(name='Outputs', description='The output information.'),
    owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
    priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
    projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', deprecated='true'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
    rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
    rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to be run.
*   FailureAllowed: The task can be rerun only after it fails to be run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to be run.', example='AllAllowed'),
    rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
    runtimeResource?: {
      cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
      image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
      resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
    }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
    script?: {
      content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
      parameters?: string(name='Parameters', description='The script parameters.', example='para1=$bizdate'),
    }(name='Script', description='The script information.'),
    subTasks?: {
      subTasks?: [ 
        {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='The baseline ID.'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description of the task.', example='test'),
          envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
          id?: long(name='Id', description='The task ID.', example='1234'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          name?: string(name='Name', description='The name of the task.', example='SQL node'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
          projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', deprecated='true'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='180'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to be run.
*   FailureAllowed: The task can be rerun only after it fails to be run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to be run.', example='AllAllowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of CUs configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The runtime environment configuration of the task, such as the resource group.'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
          trigger?: {
            cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
            endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
            recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
            startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
            type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: periodic scheduling
*   Manual: manual scheduling', example='Scheduler'),
          }(name='Trigger', description='The method to trigger task scheduling.'),
          type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
        }
      ](name='SubTasks', description='The subtasks.'),
      type?: string(name='Type', description='The type of the subtask. Valid values:

*   DoWhile: do-while node
*   Combined: node group
*   ForEach: for-each node', example='Combined'),
    }(name='SubTasks', description='The configurations of the subtasks, such as a do-while node.'),
    tags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='key1'),
        value?: string(name='Value', description='The tag value.', example='value1'),
      }
    ](name='Tags', description='The tags.'),
    timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
    trigger?: {
      cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
      endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
      recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
      startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
      type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: periodic scheduling
*   Manual: manual scheduling', example='Scheduler'),
    }(name='Trigger', description='The method to trigger task scheduling.'),
    type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
    workflowId?: long(name='WorkflowId', description='The workflow ID.', example='1234'),
  }(name='Task', description='The details of the task.'),
}

model GetTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTask  GetTaskRequest
  * @return GetTaskResponse
 */
async function getTask(request: GetTaskRequest): GetTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTask', 'GET', '/', 'json', false, 'json', request);
}

model GetTaskInstanceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
}

model GetTaskInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  taskInstance?: {
    baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
    bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
    createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
    createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
    dataSource?: {
      name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
    }(name='DataSource', description='The information about the associated data source.'),
    description?: string(name='Description', description='The description.', example='test'),
    finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
    id?: long(name='Id', description='The instance ID.', example='1234'),
    inputs?: {
      variables?: [ 
        {
          name?: string(name='Name', description='The name of the variable.', example='Key1'),
          type?: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output', example='Constant'),
          value?: string(name='Value', description='The value of the variable.', example='Value1'),
        }
      ](name='Variables', description='The variables.'),
    }(name='Inputs', description='The input information.'),
    modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
    modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
    outputs?: {
      taskOutputs?: [ 
        {
          output?: string(name='Output', description='The output identifier.', example='pre.odps_sql_demo_0'),
        }
      ](name='TaskOutputs', description='The task outputs.'),
      variables?: [ 
        {
          name?: string(name='Name', description='The name of the variable.', example='key1'),
          type?: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output', example='Constant'),
          value?: string(name='Value', description='The value of the variable.', example='value1'),
        }
      ](name='Variables', description='The variables.'),
    }(name='Outputs', description='The output information.'),
    owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
    periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
    priority?: int32(name='Priority', description='The task priority. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
    projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
    rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.', example='AllAllowed'),
    runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
    runtime?: {
      gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
      processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
    }(name='Runtime', description='The runtime information about the instance.'),
    runtimeResource?: {
      cu?: string(name='Cu', description='The default number of CUs configured for task running.', example='0.25'),
      image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
      resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
    }(name='RuntimeResource', description='The information about the resource group with which the instance is associated.'),
    script?: {
      content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
      parameters?: string(name='Parameters', description='The script parameters.', example='para1=$bizdate'),
    }(name='Script', description='The script information.'),
    startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
    status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
    tags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='key1'),
        value?: string(name='Value', description='The tag value.', example='value1'),
      }
    ](name='Tags', description='The tags of the task.'),
    taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
    taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
    taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
    timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='1'),
    triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
    triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
    triggerType?: string(name='TriggerType', description='The method to trigger instance scheduling. The value of the Trigger.Type parameter in the response of the GetTask operation is used. Valid values:

*   Scheduler
*   Manual', example='Scheduler'),
    waitingResourceTime?: long(name='WaitingResourceTime', example='1710239005403'),
    waitingTriggerTime?: long(name='WaitingTriggerTime', example='1710239005403'),
    workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
    workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
    workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   SmokeTest
*   SupplementData
*   Manual
*   ManualWorkflow
*   Normal
*   ManualFlow', example='Normal'),
    workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
  }(name='TaskInstance', description='The details of the task instance.'),
}

model GetTaskInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTaskInstanceResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetTaskInstance  GetTaskInstanceRequest
  * @return GetTaskInstanceResponse
 */
async function getTaskInstance(request: GetTaskInstanceRequest): GetTaskInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTaskInstance', 'GET', '/', 'json', false, 'json', request);
}

model GetTaskInstanceLogRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  runNumber?: int32(name='RunNumber', description='The sequence number of an instance run. Minimum value: 1. By default, the latest run is used.', example='1', position='Query'),
}

model GetTaskInstanceLogResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  taskInstanceLog?: string(name='TaskInstanceLog', description='The run log of the instance.', example='This is running log'),
}

model GetTaskInstanceLogResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTaskInstanceLogResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetTaskInstanceLog  GetTaskInstanceLogRequest
  * @return GetTaskInstanceLogResponse
 */
async function getTaskInstanceLog(request: GetTaskInstanceLogRequest): GetTaskInstanceLogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTaskInstanceLog', 'GET', '/', 'json', false, 'json', request);
}

model GetWorkflowRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
  id: long(name='Id', description='The workflow ID.

This parameter is required.', example='1234', position='Query'),
}

model GetWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  workflow?: {
    clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a workflow asynchronously and implement the idempotence of the workflow. If you do not specify this parameter when you create the workflow, the system automatically generates a unique code. The unique code is uniquely associated with the workflow ID. If you specify this parameter when you update or delete the workflow, the value of this parameter must be the unique code that is used to create the workflow.', example='Workflow_0bc5213917368545132902xxxxxxxx'),
    createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
    createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
    dependencies?: [ 
      {
        type?: string(name='Type', description='The scheduling dependency type. Valid values:

*   CrossCycleDependsOnChildren: cross-cycle dependency on the level-1 descendant nodes of a node
*   CrossCycleDependsOnSelf: cross-cycle dependency on the current node
*   CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
*   Normal: same-cycle scheduling dependency', example='Normal'),
        upstreamOutput?: string(name='UpstreamOutput', description='The identifier of the output of the ancestor task. This parameter is returned only if `same-cycle scheduling dependencies` and the node input are configured.', example='pre.odps_sql_demo_0'),
        upstreamTaskId?: long(name='UpstreamTaskId', description='The ancestor task ID. This parameter is returned only if `cross-cycle scheduling dependencies` or `same-cycle scheduling dependencies` and the node input are not configured.', example='1234'),
      }
    ](name='Dependencies', description='The dependency information.'),
    description?: string(name='Description', description='The description of the workflow.', example='Test workflow'),
    envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
    id?: long(name='Id', description='The workflow ID.', example='1234'),
    modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
    modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
    name?: string(name='Name', description='The name of the workflow.', example='Workflow'),
    outputs?: {
      taskOutputs?: [ 
        {
          output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
        }
      ](name='TaskOutputs', description='The task outputs.'),
    }(name='Outputs', description='The output information.'),
    owner?: string(name='Owner', description='The account ID of the workflow owner.', example='1000'),
    parameters?: string(name='Parameters', description='The parameters.', example='para1=$bizdate para2=$[yyyymmdd]'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
    tags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='key1'),
        value?: string(name='Value', description='The tag value.', example='value1'),
      }
    ](name='Tags', description='The tags.'),
    tasks?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a task asynchronously and implement the idempotence of the task. If you do not specify this parameter when you create the task, the system automatically generates a unique code. The unique code is uniquely associated with the task ID. If you specify this parameter when you update or delete the task, the value of this parameter must be the unique code that is used to create the task.', example='Task_0bc5213917368545132902xxxxxxxx'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description of the task.', example='Test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        id?: long(name='Id', description='The task ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name of the task.', example='SQL node'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
        rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.', example='AllAllowed'),
        rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
        triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the task after it is triggered. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
      }
    ](name='Tasks', description='The tasks.'),
    trigger?: {
      cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
      endTime?: string(name='EndTime', description='The end time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
      recurrence?: string(name='Recurrence', description='The running mode of the workflow after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
      startTime?: string(name='StartTime', description='The start time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
      type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
    }(name='Trigger', description='The trigger method.'),
  }(name='Workflow', description='The information about the workflow.'),
}

model GetWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkflowResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetWorkflow  GetWorkflowRequest
  * @return GetWorkflowResponse
 */
async function getWorkflow(request: GetWorkflowRequest): GetWorkflowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetWorkflow', 'GET', '/', 'json', false, 'json', request);
}

model GetWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  includeScriptContent?: boolean(name='IncludeScriptContent', description='查询结果是否包含工作流内部节点的脚本内容（对于内容较多的节点，可能存在较长的网络传输延时）。', example='false', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
}

model GetWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='F2BDD628-8A21-5BD1-B930-1A2D5989XXXX'),
  workflowDefinition?: {
    createTime?: long(name='CreateTime', description='The time when the workflow was created. This value is a UNIX timestamp.', example='1708481905000'),
    id?: long(name='Id', description='The ID of the workflow.', example='463497880880954XXXX'),
    modifyTime?: long(name='ModifyTime', description='The time when the workflow was last modified. This value is a UNIX timestamp.', example='1708481905000'),
    name?: string(name='Name', description='The name of the workflow.', example='OpenAPI test workflow Demo'),
    owner?: string(name='Owner', description='The owner of the workflow.', example='110755000425XXXX'),
    projectId?: long(name='ProjectId', description='The ID of the workspace to which the workflow belongs.', example='307XXX'),
    spec?: string(name='Spec', description='The FlowSpec field information about the workflow. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow/).', example='{
    "metadata": {
        "tenantId": "52425742456XXXX",
        "projectId": "307XXXX",
        "uuid": "463497880880954XXXX"
    },
    "kind": "CycleWorkflow",
    "version": "1.1.0",
    "spec": {
        "name": "OpenAPI_Test_Workflow_Demo",
        "id": "463497880880954XXXX",
        "type": "CycleWorkflow",
        "owner": "110755000425XXXX",
        "workflows": [
            {
                "script": {
                    "path": "XX/OpenAPI_Test/Workflow_Test/OpenAPI_Test_Workflow_Demo",
                    "runtime": {
                        "command": "WORKFLOW"
                    },
                    "id": "698002781368644XXXX"
                },
                "id": "463497880880954XXXX",
                "trigger": {
                    "type": "Scheduler",
                    "id": "652567824470354XXXX",
                    "cron": "00 02 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "strategy": {
                    "timeout": 0,
                    "instanceMode": "T+1",
                    "rerunMode": "Allowed",
                    "rerunTimes": 3,
                    "rerunInterval": 180000,
                    "failureStrategy": "Break"
                },
                "name": "OpenAPI_Test_Workflow_Demo",
                "owner": "110755000425XXXX",
                "metadata": {
                    "owner": "110755000425XXXX",
                    "ownerName": "XXXX@test.XXXX.com",
                    "tenantId": "52425742456XXXX",
                    "project": {
                        "mode": "STANDARD",
                        "projectId": "307303",
                        "projectIdentifier": "lwttest_standard",
                        "projectName": "XXXX",
                        "projectOwnerId": "110755000425XXXX",
                        "simple": false,
                        "tenantId": "52425742456XXXX"
                    },
                    "projectId": "307XXXX"
                },
                "inputs": {},
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "463497880880954XXXX",
                            "artifactType": "NodeOutput",
                            "refTableName": "OpenAPI_Test_Workflow_Demo",
                            "isDefault": true
                        }
                    ]
                },
                "nodes": [],
                "dependencies": []
            }
        ]
    }
}'),
    workflowId?: long(name='WorkflowId', description='The ID of the workflow on the scheduling side after publishing.', example='700006657495'),
  }(name='WorkflowDefinition', description='The information about the workflow.'),
}

model GetWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetWorkflowDefinition  GetWorkflowDefinitionRequest
  * @return GetWorkflowDefinitionResponse
 */
async function getWorkflowDefinition(request: GetWorkflowDefinitionRequest): GetWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetWorkflowDefinition', 'GET', '/', 'json', false, 'json', request);
}

model GetWorkflowInstanceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow instance.

This parameter is required.', example='1234', position='Query'),
}

model GetWorkflowInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  workflowInstance?: {
    bizDate?: long(name='BizDate', description='The data timestamp.', example='1710239005403'),
    createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
    createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
    envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
    finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
    id?: long(name='Id', description='The ID of the workflow instance.', example='1234'),
    modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
    modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
    name?: string(name='Name', description='The name of the workflow instance.', example='WorkInstance1'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
    startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
    status?: string(name='Status', description='The status of the workflow instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
    type?: string(name='Type', description='The type of the workflow instance. Valid values:

*   Normal
*   Manual
*   SmokeTest
*   SupplementData
*   ManualWorkflow', example='Normal'),
    workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
  }(name='WorkflowInstance', description='The information about the workflow instance.'),
}

model GetWorkflowInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkflowInstanceResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetWorkflowInstance  GetWorkflowInstanceRequest
  * @return GetWorkflowInstanceResponse
 */
async function getWorkflowInstance(request: GetWorkflowInstanceRequest): GetWorkflowInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetWorkflowInstance', 'GET', '/', 'json', false, 'json', request);
}

model GrantMemberProjectRolesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='105149', position='Body'),
  roleCodes: [ string ](name='RoleCodes', description='The codes of the roles in the workspace. You can call the [ListProjectRoles](https://help.aliyun.com/document_detail/2853930.html) operation to query the codes of all roles in the workspace.

You must configure this parameter to specify the roles that you want to assign to members in the workspace.

This parameter is required.', shrink='json', position='Body'),
  userId: string(name='UserId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the Tenant Members and Roles page, view the IDs of the accounts used by the members in the workspace.

This parameter is required.', example='123422344899', position='Body'),
}

model GrantMemberProjectRolesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='2d9ced66-38ef-4923-baf6-391dd3a7e656'),
}

model GrantMemberProjectRolesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GrantMemberProjectRolesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GrantMemberProjectRoles  GrantMemberProjectRolesRequest
  * @return GrantMemberProjectRolesResponse
 */
async function grantMemberProjectRoles(request: GrantMemberProjectRolesRequest): GrantMemberProjectRolesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GrantMemberProjectRoles', 'POST', '/', 'json', true, 'form', request);
}

model ImportWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='123456', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the workflow. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow/).

This parameter is required.', example='{
    "version": "1.1.0",
    "kind": "CycleWorkflow",
    "spec": {
        "name": "Asynchronous_Workflow_Creation_Test",
        "id": "632647691239009XXXX",
        "type": "CycleWorkflow",
        "workflows": [
            {
                "script": {
                    "path": "XX/OpenAPI_Test/Workflow_Test/Asynchronous_Workflow_Creation_Test",
                    "runtime": {
                        "command": "WORKFLOW"
                    }
                },
                "id": "632647691239009XXXX",
                "trigger": {
                    "type": "Scheduler",
                    "cron": "00 03 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "strategy": {
                    "timeout": 0,
                    "instanceMode": "T+1",
                    "rerunMode": "Allowed",
                    "rerunTimes": 3,
                    "rerunInterval": 180000,
                    "failureStrategy": "Break"
                },
                "name": "Asynchronous_Workflow_Creation_Test",
                "inputs": {},
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "632647691239009XXXX",
                            "artifactType": "NodeOutput",
                            "refTableName": "Asynchronous_Workflow_Creation_Test"
                        }
                    ]
                },
                "nodes": [
                    {
                        "recurrence": "Normal",
                        "id": "742981001612325XXXX",
                        "timeout": 0,
                        "instanceMode": "T+1",
                        "rerunMode": "Allowed",
                        "rerunTimes": 3,
                        "rerunInterval": 180000,
                        "script": {
                            "path": "XX/OpenAPI_Test/Workflow_Test/Asynchronous_Workflow_Creation_Test/111",
                            "runtime": {
                                "command": "ODPS_SQL"
                            },
                            "content": "select now();\\n"
                        },
                        "trigger": {
                            "type": "Scheduler",
                            "cron": "00 24 00 * * ?",
                            "startTime": "1970-01-01 00:00:00",
                            "endTime": "9999-01-01 00:00:00",
                            "timezone": "Asia/Shanghai",
                            "delaySeconds": 0
                        },
                        "name": "111",
                        "inputs": {},
                        "outputs": {
                            "nodeOutputs": [
                                {
                                    "data": "742981001612325XXXX",
                                    "artifactType": "NodeOutput",
                                    "refTableName": "111"
                                }
                            ]
                        }
                    },
                    {
                        "recurrence": "Normal",
                        "id": "595182137303408XXXX",
                        "timeout": 0,
                        "instanceMode": "T+1",
                        "rerunMode": "Allowed",
                        "rerunTimes": 3,
                        "rerunInterval": 180000,
                        "script": {
                            "path": "XX/OpenAPI_Test/Workflow_Test/Asynchronous_Workflow_Creation_Test/222",
                            "runtime": {
                                "command": "ODPS_SQL"
                            },
                            "content": "select now();\\n select 1;"
                        },
                        "trigger": {
                            "type": "Scheduler",
                            "cron": "00 00 00 * * ?",
                            "startTime": "1970-01-01 00:00:00",
                            "endTime": "9999-01-01 00:00:00",
                            "timezone": "Asia/Shanghai",
                            "delaySeconds": 0
                        },
                        "name": "222",
                        "inputs": {},
                        "outputs": {
                            "nodeOutputs": [
                                {
                                    "data": "595182137303408XXXX",
                                    "artifactType": "NodeOutput",
                                    "refTableName": "222"                                
                                }
                            ]
                        }
                    }
                ],
                "dependencies": [
                    {
                        "nodeId": "595182137303408XXXX",
                        "depends": [
                            {
                                "type": "Normal",
                                "output": "742981001612325XXXX",
                                "refTableName": "111"
                            }
                        ]
                    }
                ]
            }
        ]
    }
}', position='Body'),
}

model ImportWorkflowDefinitionResponseBody = {
  asyncJob?: {
    completed?: boolean(name='Completed', description='Indicates whether the asynchronous task is complete.', example='false'),
    createTime?: long(name='CreateTime', description='The time when the asynchronous task was created. This value is a UNIX timestamp.', example='1706581425000'),
    error?: string(name='Error', description='The error message returned if the asynchronous task fails.', example='target folder already exists: XXXX'),
    id?: string(name='Id', description='The ID of the asynchronous task.', example='1234567691239009XXXX'),
    progress?: int32(name='Progress', description='The progress of the asynchronous task. Valid values: 0 to 100.', example='0'),
    response?: string(name='Response', description='The response.

>  The workflow ID is returned.', example='632647691239009XXXX'),
    status?: string(name='Status', description='The status of the asynchronous task.

Valid values:

*   Running: The asynchronous task is running.
*   Success: The asynchronous task is complete.
*   Fail: The asynchronous task fails.
*   Cancel: The asynchronous task is canceled.', example='Running'),
    type?: string(name='Type', description='The type of the asynchronous task.

Valid values:

*   Create: The asynchronous task is used to create an object.
*   Cancel: The asynchronous task is used to cancel an operation.', example='Create'),
  }(name='AsyncJob', description='The status information of the asynchronous task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7C352CB7-CD88-50CF-9D0D-E81BDF020E7F'),
}

model ImportWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ImportWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @description > 
  * *   You cannot use this API operation to import multiple workflows at a time. If you specify multiple workflows by using FlowSpec, the system imports only the first specified workflow.
  * *   ImportWorkflowDefinition is an asynchronous operation. After you send a request, an asynchronous task is generated, and the system returns the ID of the asynchronous task. You can call the GetJobStatus operation to query the status of the asynchronous task.
  * @param request  the request parameters of ImportWorkflowDefinition  ImportWorkflowDefinitionRequest
  * @return ImportWorkflowDefinitionResponse
 */
async function importWorkflowDefinition(request: ImportWorkflowDefinitionRequest): ImportWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ImportWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model ListAlertRulesRequest {
  regionId?: string(name='RegionId', position='Host'),
  name?: string(name='Name', description='The name of the rule.', example='error_rule', position='Query'),
  owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.', example='1933790683****', position='Query'),
  pageNumber: int32(name='PageNumber', description='The page number. Pages start from page 1.

This parameter is required.', example='1', minimum=1, position='Query'),
  pageSize: long(name='PageSize', description='The number of entries per page. Maximum value: 100.

This parameter is required.', example='10', maximum=100, position='Query'),
  receiver?: string(name='Receiver', description='The ID of the Alibaba Cloud account used by the alert recipient.', example='1933790683****', position='Query'),
  taskIds?: [ long ](name='TaskIds', description='The IDs of the scheduling tasks.', shrink='json', position='Query'),
  types?: [ string ](name='Types', description='The alert triggering condition.', shrink='json', position='Query'),
}

model ListAlertRulesResponseBody = {
  pagingInfo?: {
    alertRules?: [ 
      {
        enabled?: boolean(name='Enabled', description='Indicates whether the rule is enabled.', example='true'),
        id?: long(name='Id', description='The rule ID.', example='22125'),
        name?: string(name='Name', description='The name of the rule.', example='error_test'),
        owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.', example='1933790683****'),
        triggerCondition?: {
          extension?: {
            cycleUnfinished?: {
              cycleAndTime?: [ 
                {
                  cycleId?: int32(name='CycleId', description='The ID of the scheduling cycle of the instance. Valid values: [1,288].', example='1'),
                  time?: string(name='Time', description='The latest completion time of the instance within the scheduling cycle. The time is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='01:00'),
                }
              ](name='CycleAndTime', description='The configurations of the scheduling cycle and timeout period of the instance.'),
            }(name='CycleUnfinished', description='The configuration for an alert of the CycleUnfinished type.'),
            error?: {
              autoRerunAlertEnabled?: boolean(name='AutoRerunAlertEnabled', description='Indicates whether an alert is triggered if a batch synchronization task is automatically rerun upon a failure.', example='false'),
              streamTaskIds?: [ long ](name='StreamTaskIds', description='The IDs of the real-time computing tasks. This parameter is required when you monitor real-time computing tasks.'),
            }(name='Error', description='The configuration for an alert of the Error type.'),
            instanceErrorCount?: {
              count?: int32(name='Count', description='The maximum number of instances on which an error occurs. Valid values: [1,10000].', example='10'),
            }(name='InstanceErrorCount', description='The configuration for an alert of the InstanceErrorCount type.'),
            instanceErrorPercentage?: {
              percentage?: int32(name='Percentage', description='The maximum percentage of instances on which an error occurs in the workspace to the total number of instances. Valid values: [1-100].', example='10'),
            }(name='InstanceErrorPercentage', description='The configuration for an alert of the InstanceErrorPercentage type.'),
            instanceTransferFluctuate?: {
              percentage?: int32(name='Percentage', description='The maximum percentage of fluctuation in the number of auto triggered node instances that are generated in your workspace. Valid values: [1-100].', example='10'),
              trend?: string(name='Trend', description='The way in which the number of auto triggered node instances that are generated in your workspace fluctuates. Valid values:

*   abs: the absolute value. The number of instances increases or decreases.
*   increase: The number of instances increases.
*   decrease: The number of instances decreases.', example='abs'),
            }(name='InstanceTransferFluctuate', description='The configuration for an alert of the InstanceTransferFluctuate type.'),
            timeout?: {
              timeoutInMinutes?: int32(name='TimeoutInMinutes', description='The timeout period. Unit: minutes.', example='10'),
            }(name='Timeout', description='The configuration for an alert of the Timeout type.'),
            unFinished?: {
              unFinishedTime?: string(name='UnFinishedTime', description='The latest completion time of the instance. The period is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
            }(name='UnFinished', description='The configuration for an alert of the UnFinished type.'),
          }(name='Extension', description='The extended information about the rule. This parameter is required for specific types of alerts.'),
          target?: {
            allowTasks?: [ long ](name='AllowTasks', description='The nodes that are not to be monitored.'),
            ids?: [ long ](name='Ids', description='The IDs of monitored objects.'),
            type?: string(name='Type', description='The type of the monitored objects. Valid values:

*   Task: node
*   Baseline: baseline
*   Project: workspace
*   BizProcess: workflow', example='Task'),
          }(name='Target', description='The monitored objects.'),
          type?: string(name='Type', description='The alert type. Valid values:

*   Finished: An instance is successfully run.
*   UnFinished: An instance does not finish running before a specified point in time.
*   Error: An error occurs on an instance.
*   CycleUnfinished: An instance does not finish running as expected within a specific cycle.
*   Timeout: An instance times out.
*   InstanceTransferComplete: An instance is generated by the auto triggered node.
*   InstanceTransferFluctuate: The number of generated instances fluctuates.
*   ExhaustedError: An error persists after an instance is automatically rerun.
*   InstanceKeyword: An instance with errors contains specified keywords.
*   InstanceErrorCount: The number of instances on which an error occurs reaches a specified threshold.
*   InstanceErrorPercentage: The proportion of instances on which an error occurs in the workspace to the total number of instances reaches a specified threshold.
*   ResourceGroupPercentage: The usage rate of the resource group reaches a specified threshold.
*   ResourceGroupWaitCount: The number of instances that are waiting for resources in the resource group reaches a specified threshold.', example='Error'),
        }(name='TriggerCondition', description='The alert triggering condition.'),
      }
    ](name='AlertRules', description='The rules.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='5'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='A6C6B486-E3A2-5D52-9E76-D9380485D946'),
}

model ListAlertRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAlertRulesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAlertRules  ListAlertRulesRequest
  * @return ListAlertRulesResponse
 */
async function listAlertRules(request: ListAlertRulesRequest): ListAlertRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAlertRules', 'POST', '/', 'json', false, 'json', request);
}

model ListBusinessRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  keyword?: string(name='Keyword', example='my', position='Body'),
  pageNumber: int32(name='PageNumber', description='This parameter is required.', example='1', minimum=1, position='Body'),
  pageSize: int32(name='PageSize', description='This parameter is required.', example='10', minimum=0, maximum=100, position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
}

model ListBusinessResponseBody = {
  data?: {
    business?: [ 
      {
        businessId?: long(name='BusinessId', example='3000001'),
        businessName?: string(name='BusinessName'),
        description?: string(name='Description'),
        owner?: string(name='Owner', example='34824327****'),
        projectId?: long(name='ProjectId', example='10000'),
        useType?: string(name='UseType', example='NORMAL'),
      }
    ](name='Business'),
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    totalCount?: int32(name='TotalCount', example='13'),
  }(name='Data'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model ListBusinessResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListBusinessResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListBusiness  ListBusinessRequest
  * @return ListBusinessResponse
 */
async function listBusiness(request: ListBusinessRequest): ListBusinessResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListBusiness', 'POST', '/', 'json', true, 'form', request);
}

model ListCatalogsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', example='this is a comment', position='Query'),
  name?: string(name='Name', example='abc', position='Query'),
  order?: string(name='Order', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', example='10', minimum=1, maximum=100, position='Query'),
  parentMetaEntityId: string(name='ParentMetaEntityId', description='The parent entity ID. For more information, see [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

Only DLF and StarRocks data sources support this parameter.

*   For DLF data sources, you can call this API operation to query all catalogs. In this case, you must set the `ParentMetaEntityId` parameter to `dlf`.
*   For StarRocks data sources, you can call this API operation to query the catalogs in a specific instance. In this case, you can configure the `ParentMetaEntityId` parameter in the `starrocks:(instance_id|encoded_jdbc_url)` format.

> \\
`instance_id`: the ID of an instance. If the related data source is added to DataWorks in Alibaba Cloud instance mode, you must configure this parameter.\\
`encoded_jdbc_url`: the JDBC connection string that is URL-encoded. If the related data source is added to DataWorks in connection string mode, you must configure this parameter.

This parameter is required.', example='dlf
starrocks:c-abc123xxx', position='Query'),
  sortBy?: string(name='SortBy', example='CreateTime', position='Query'),
  types?: [ string ](name='Types', shrink='simple', position='Query'),
}

model ListCatalogsResponseBody = {
  pagingInfo?: {
    catalogs?: [
      Catalog
    ](name='Catalogs'),
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    totalCount?: long(name='TotalCount', example='1'),
  }(name='PagingInfo'),
  requestId?: string(name='RequestId', example='317CD7D0-AB36-XXXXXX'),
  success?: boolean(name='Success', example='true'),
}

model ListCatalogsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCatalogsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListCatalogs  ListCatalogsRequest
  * @return ListCatalogsResponse
 */
async function listCatalogs(request: ListCatalogsRequest): ListCatalogsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListCatalogs', 'GET', '/', 'json', false, 'json', request);
}

model ListCertificatesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  createUser?: string(name='CreateUser', description='The ID of the user who created the certificate files.', example='1107550004253538', position='Query'),
  endCreateTime?: long(name='EndCreateTime', description='The time when the certificate file was created. You can call this operation to query the files that are created before the time. Unit: milliseconds.', example='1593877765000', position='Query'),
  name?: string(name='Name', description='The name of the certificate file. Fuzzy match by file name is supported.', example='xm_create_test', position='Query'),
  order?: string(name='Order', description='The order in which you want to sort the certificate files. Valid values: Desc: descending order ASC: ascending order Default value: Asc', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  projectId: long(name='ProjectId', description='The ID of the workspace to which the certificate file belongs.

This parameter is required.', example='10000', position='Query'),
  sortBy?: string(name='SortBy', description='The field used to sort the certificate files. Valid values: CreateTime Id Name Default value: Id', example='Id', position='Query'),
  startCreateTime?: long(name='StartCreateTime', description='The time when the certificate file was created. You can call this operation to query the files that are created after the time. Unit: milliseconds.', example='1730217600000', position='Query'),
}

model ListCertificatesResponseBody = {
  pagingInfo?: {
    certificates?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the certificate file was created. This value is a UNIX timestamp.', example='1730217600000'),
        createUser?: string(name='CreateUser', description='The ID of the user who created the certificate file.', example='1107550004253538'),
        description?: string(name='Description', description='The description.', example='This is a file'),
        fileSizeInBytes?: long(name='FileSizeInBytes', description='The size of the certificate file, in bytes.', example='1024'),
        id?: long(name='Id', description='The ID of the certificate file.', example='676303114031776'),
        name?: string(name='Name', description='The name of the certificate file.', example='ca1.crt'),
      }
    ](name='Certificates', description='The certificate files.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='ecb967ec-c137-48****'),
}

model ListCertificatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCertificatesResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks: Tenant Owner, Workspace Administrator, Deploy, Develop, Visitor, Workspace Owner, O\\&M, Model Designer, Security Administrator, Data Analyst, OpenPlatform Administrator, and Data Governance Administrator.
  * @param request  the request parameters of ListCertificates  ListCertificatesRequest
  * @return ListCertificatesResponse
 */
async function listCertificates(request: ListCertificatesRequest): ListCertificatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListCertificates', 'GET', '/', 'json', false, 'json', request);
}

model ListColumnsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', example='test comment', position='Query'),
  name?: string(name='Name', example='test_table', position='Query'),
  order?: string(name='Order', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', example='10', minimum=1, maximum=100, position='Query'),
  sortBy?: string(name='SortBy', example='Position', position='Query'),
  tableId: string(name='TableId', description='The ID of the table to which the columns belong. You can call the ListTables operation to query the ID. For more information, see [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

This parameter is required.', example='maxcompute-column:11075xxxx::test_project:test_schema:test_table', position='Query'),
}

model ListColumnsResponseBody = {
  pagingInfo?: {
    columns?: [
      Column
    ](name='Columns'),
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    totalCount?: long(name='TotalCount', example='1'),
  }(name='PagingInfo'),
  requestId?: string(name='RequestId', example='D1E2E5BC-xxxx-xxxx-xxxx-xxxxxx'),
  success?: boolean(name='Success', example='true'),
}

model ListColumnsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListColumnsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListColumns  ListColumnsRequest
  * @return ListColumnsResponse
 */
async function listColumns(request: ListColumnsRequest): ListColumnsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListColumns', 'GET', '/', 'json', false, 'json', request);
}

model ListCrawlerTypesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
}

model ListCrawlerTypesResponseBody = {
  crawlerTypes?: [
    CrawlerType
  ](name='CrawlerTypes'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model ListCrawlerTypesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCrawlerTypesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListCrawlerTypes  ListCrawlerTypesRequest
  * @return ListCrawlerTypesResponse
 */
async function listCrawlerTypes(request: ListCrawlerTypesRequest): ListCrawlerTypesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListCrawlerTypes', 'GET', '/', 'json', false, 'json', request);
}

model ListDIAlarmRulesRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIAlarmRuleId?: long(name='DIAlarmRuleId', description='The ID of the alert rule. If you leave this parameter empty, all alert rules of the task are queried.', example='34988', position='Query'),
  jobId?: long(name='JobId', description='The ID of the task for which alert rules are configured.', example='1000001', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
}

model ListDIAlarmRulesResponseBody = {
  pagingInfo?: {
    DIJobAlarmRules?: [ 
      {
        DIAlarmRuleId?: long(name='DIAlarmRuleId', description='This parameter is deprecated. Use the Id parameter instead.', example='72402', deprecated='true'),
        DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='32594'),
        description?: string(name='Description', description='The description of the alert rule.', example='rule descrition'),
        enabled?: boolean(name='Enabled', description='Indicates whether the alert rule is enabled. Valid values: True and False.', example='True'),
        id?: long(name='Id', description='The ID of the alert rule.', example='72402'),
        metricType?: string(name='MetricType', description='The metric type in the alert rule. Valid values:

*   Heartbeat
*   FailoverCount
*   Delay
*   DdlReport
*   ResourceUtilization', example='Heartbeat'),
        name?: string(name='Name', description='The name of the alert rule.', example='rule_name'),
        notificationSettings?: {
          inhibitionInterval?: long(name='InhibitionInterval', description='This parameter is deprecated and replaced by the MuteInterval parameter.', example='5', deprecated='true'),
          muteInterval?: long(name='MuteInterval', description='The duration of the alert suppression interval. Unit: minutes.', example='5'),
          notificationChannels?: [ 
            {
              channels?: [ string ](name='Channels', description='The alert notification methods.'),
              severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Critical'),
            }
          ](name='NotificationChannels', description='The alert notification methods.'),
          notificationReceivers?: [ 
            {
              receiverType?: string(name='ReceiverType', description='The recipient type. Valid values: AliyunUid, DingToken, FeishuToken, and WebHookUrl.', example='DingToken'),
              receiverValues?: [ string ](name='ReceiverValues', description='The recipient.

*   If the value of the ReceiverType parameter is AliyunUid, the value of this parameter is the Alibaba Cloud account ID of a user.
*   If the value of the ReceiverType parameter is DingToken, the value of this parameter is the token of a DingTalk chatbot.'),
            }
          ](name='NotificationReceivers', description='The settings of alert notification recipients.'),
        }(name='NotificationSettings', description='The alert notification method and recipient settings.'),
        triggerConditions?: [ 
          {
            ddlReportTags?: [ string ](name='DdlReportTags', description='This parameter is deprecated and replaced by the DdlTypes parameter.', deprecated='true'),
            ddlTypes?: [ string ](name='DdlTypes', description='The types of DDL operations for which the alert rule takes effect. This parameter is returned only if the MetricType parameter is set to DdlReport.'),
            duration?: long(name='Duration', description='The time interval for alert calculation. Unit: minutes.', example='1'),
            severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Critical'),
            threshold?: long(name='Threshold', description='The alert threshold.

*   If the alert rule is for task status, no threshold is used.
*   If the alert rule is for failovers, the threshold is the number of failovers.
*   If the alert rule is for latency, the threshold is the latency duration, in seconds.', example='5'),
          }
        ](name='TriggerConditions', description='The conditions that are used to trigger the alert rule.'),
      }
    ](name='DIJobAlarmRules', description='The alert rules.'),
    pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='90'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='74C2FECD-5B3A-554A-BCF5-351A36DE9815'),
}

model ListDIAlarmRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIAlarmRulesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDIAlarmRules  ListDIAlarmRulesRequest
  * @return ListDIAlarmRulesResponse
 */
async function listDIAlarmRules(request: ListDIAlarmRulesRequest): ListDIAlarmRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIAlarmRules', 'GET', '/', 'json', false, 'json', request);
}

model ListDIJobEventsRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='11588', position='Query'),
  endTime: long(name='EndTime', description='The end of the time range to query.

This parameter is required.', example='1717971005', position='Query'),
  eventType: string(name='EventType', description='The type of event that you want to query. Valid values: Failover, Alarm, and DDL.

This parameter is required.', example='Alarm', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  startTime: long(name='StartTime', description='The beginning of the time range to query.

This parameter is required.', example='1716971005', position='Query'),
}

model ListDIJobEventsResponseBody = {
  pagingInfo?: {
    DIJobEvent?: [ 
      {
        action?: string(name='Action', description='The processing result of the DDL event. Valid values: Critical, Ignore, Normal, and Warning.', example='Ignore'),
        channels?: string(name='Channels', description='The alert notification method. Valid values: Phone, Mail, Sms, Ding, and Webhook.', example='Phone'),
        createTime?: string(name='CreateTime', description='The time when the event was created.', example='1663573162'),
        detail?: string(name='Detail', description='The alert details.', example='aggregator:avg [**] for 5 minutes, service maybe abnormal'),
        dstSql?: string(name='DstSql', description='The DDL statement of the destination table.', example='alter table table2 ***'),
        dstTable?: string(name='DstTable', description='The name of the destination table.', example='table2'),
        failoverMessage?: string(name='FailoverMessage', description='The error logs for failovers.', example='2024-05-29 15:11:31,377 [main] INFO com.*.**.di.core.metrics.:21 []  {****} 
2024-05-29 15:11:31,384 [main] INFO *.aliyun.*.di.*.*.metrics.*:27 [] - Open MarioDiReporter 
2024-05-29 15:11:33,248 [flink-akka.*.*-dispatcher-17] INFO'),
        id?: string(name='Id', description='The event ID.', example='1'),
        severity?: string(name='Severity', description='The severity level of the alert. Valid values: Warning and Critical.', example='Warning'),
        srcSql?: string(name='SrcSql', description='The DDL statement of the source table.', example='alter table table1 ***'),
        srcTable?: string(name='SrcTable', description='The name of the source table.', example='table1'),
        status?: string(name='Status', description='The sending status of an alert notification. Valid values: Success, Fail, and Silence.', example='Success'),
        type?: string(name='Type', description='The type of the alert event.

*   Heartbeat
*   Delay
*   FailoverCount
*   DdlReport
*   ResourceUtilization', example='Delay'),
      }
    ](name='DIJobEvent', description='The events returned. The value of this parameter is an array.'),
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='2524'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='645F6D68-9C29-5961-80B1-BDD4B794C22D'),
}

model ListDIJobEventsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIJobEventsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDIJobEvents  ListDIJobEventsRequest
  * @return ListDIJobEventsResponse
 */
async function listDIJobEvents(request: ListDIJobEventsRequest): ListDIJobEventsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIJobEvents', 'GET', '/', 'json', false, 'json', request);
}

model ListDIJobMetricsRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='11265', position='Query'),
  endTime: long(name='EndTime', description='The end of the time range to query.

This parameter is required.', example='1712205941', position='Query'),
  metricName: [ string ](name='MetricName', description='The metrics that you want to query.

This parameter is required.', shrink='json', position='Query'),
  startTime: long(name='StartTime', description='The beginning of the time range to query.

This parameter is required.', example='1586509407', position='Query'),
}

model ListDIJobMetricsResponseBody = {
  pagingInfo?: {
    jobMetrics?: [ 
      {
        name?: string(name='Name', description='The name of the metric.', example='JobDelay'),
        seriesList?: [ 
          {
            time?: long(name='Time', description='The point in time at which data is sampled based on the metric.', example='1716881141'),
            value?: double(name='Value', description='The sample value.', example='10'),
          }
        ](name='SeriesList', description='The metric data.'),
      }
    ](name='JobMetrics', description='The metrics returned.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='691CA452-D37A-4ED0-9441'),
}

model ListDIJobMetricsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIJobMetricsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDIJobMetrics  ListDIJobMetricsRequest
  * @return ListDIJobMetricsResponse
 */
async function listDIJobMetrics(request: ListDIJobMetricsRequest): ListDIJobMetricsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIJobMetrics', 'GET', '/', 'json', false, 'json', request);
}

model ListDIJobRunDetailsRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId: long(name='DIJobId', description='The ID of the synchronization task.

This parameter is required.', example='11265', position='Query'),
  instanceId?: long(name='InstanceId', description='The instance ID.', example='1234', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  sourceDataSourceName?: string(name='SourceDataSourceName', description='The name of the source.', example='ds_name', position='Query'),
  sourceDatabaseName?: string(name='SourceDatabaseName', description='The name of the database in the source.', example='db_name', position='Query'),
  sourceSchemaName?: string(name='SourceSchemaName', description='The name of the schema of the source.', example='schema_name', position='Query'),
  sourceTableName?: string(name='SourceTableName', description='The name of the table in the source.', example='table_name', position='Query'),
}

model ListDIJobRunDetailsResponseBody = {
  pagingInfo?: {
    jobRunInfos?: [ 
      {
        destinationDatabaseName?: string(name='DestinationDatabaseName', description='The name of the database in the destination.', example='dst_db'),
        destinationDatasourceName?: string(name='DestinationDatasourceName', description='The name of the destination.', example='dst_name'),
        destinationSchemaName?: string(name='DestinationSchemaName', description='The name of the schema of the destination.', example='dst_schema'),
        destinationTableName?: string(name='DestinationTableName', description='The name of the table in the destination.', example='dst_name'),
        fullMigrationErrorMessage?: string(name='FullMigrationErrorMessage', description='The error message that is returned if an error occurs during full batch synchronization. If no error occurs, no value is returned for this parameter.', example='sync table t1 fail.'),
        fullMigrationStatus?: string(name='FullMigrationStatus', description='The status of full batch synchronization.', example='Finished'),
        offlineErrorRecords?: long(name='OfflineErrorRecords', description='The total number of errors that occur during full synchronization.', example='0'),
        offlineTotalBytes?: long(name='OfflineTotalBytes', description='The total number of bytes that are synchronized during full synchronization.', example='100'),
        offlineTotalRecords?: long(name='OfflineTotalRecords', description='The total number of data records that are synchronized during full synchronization.', example='10'),
        realtimeMigrationErrorMessage?: string(name='RealtimeMigrationErrorMessage', description='The error message that is returned if an error occurs during real-time synchronization. If no error occurs, no value is returned for this parameter.', example='sync table t1 fail.'),
        realtimeMigrationStatus?: string(name='RealtimeMigrationStatus', description='The status of real-time synchronization.', example='Running'),
        sourceDatabaseName?: string(name='SourceDatabaseName', description='The name of the database in the source.', example='db_name'),
        sourceDatasourceName?: string(name='SourceDatasourceName', description='The name of the source.', example='ds_name'),
        sourceSchemaName?: string(name='SourceSchemaName', description='The name of the schema of the source.', example='schema_name'),
        sourceTableName?: string(name='SourceTableName', description='The name of the table in the source.', example='table_name'),
        structureMigrationErrorMessage?: string(name='StructureMigrationErrorMessage', description='The error message that is returned if an error occurs during schema synchronization. If no error occurs, no value is returned for this parameter.', example='create table t1 fail.'),
        structureMigrationStatus?: string(name='StructureMigrationStatus', description='The synchronization status of the schema.', example='Finished'),
      }
    ](name='JobRunInfos', description='The running information about the synchronization task.'),
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='131'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='691CA452-D37A-4ED0-9441'),
}

model ListDIJobRunDetailsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIJobRunDetailsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDIJobRunDetails  ListDIJobRunDetailsRequest
  * @return ListDIJobRunDetailsResponse
 */
async function listDIJobRunDetails(request: ListDIJobRunDetailsRequest): ListDIJobRunDetailsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIJobRunDetails', 'GET', '/', 'json', false, 'json', request);
}

model ListDIJobsRequest {
  regionId?: string(name='RegionId', position='Host'),
  destinationDataSourceType?: string(name='DestinationDataSourceType', description='The destination type. Valid values: Hologres, OSS-HDFS, OSS, MaxCompute, Loghub, STARROCKS, Datahub, ANALYTICDB_FOR_MYSQL, Kafka, and Hive. If you do not configure this parameter, the API operation queries synchronization tasks that use all type of destinations.', example='Hologres', position='Query'),
  migrationType?: string(name='MigrationType', description='The synchronization type. Valid values:

*   FullAndRealtimeIncremental: one-time full synchronization and real-time incremental synchronization
*   RealtimeIncremental: real-time incremental synchronization
*   Full: full synchronization
*   OfflineIncremental: batch incremental synchronization
*   FullAndOfflineIncremental: one-time full synchronization and batch incremental synchronization', example='FullAndRealtimeIncremental', position='Query'),
  name?: string(name='Name', description='The name of the export task.

The name of each export task must be unique. You must make sure that the names of the export tasks in the current workspace are unique.', example='test_export_01', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='1967', position='Query'),
  sourceDataSourceType?: string(name='SourceDataSourceType', description='The source type. Valid values: PolarDB, MySQL, Kafka, Loghub, Hologres, Oracle, OceanBase, MongoDB, RedShift, Hive, SqlServer, Doris, and ClickHouse. If you do not configure this parameter, the API operation queries synchronization tasks that use all types of sources.', example='MySQL', position='Query'),
}

model ListDIJobsResponseBody = {
  pagingInfo?: {
    DIJobs?: [ 
      {
        DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='32599', deprecated='true'),
        destinationDataSourceType?: string(name='DestinationDataSourceType', description='The destination type. Valid values: Hologres, OSS-HDFS, OSS, MaxCompute, Loghub, STARROCKS, DataHub, ANALYTICDB_FOR_MYSQL, Kafka, and Hive.', example='Hologres'),
        id?: long(name='Id', description='The ID of the synchronization task.', example='32599'),
        jobName?: string(name='JobName', description='The name of the synchronization task.', example='mysql_to_holo_sync_35197'),
        jobStatus?: string(name='JobStatus', description='The status of the synchronization task. Valid values:

*   Finished
*   Initialized
*   Stopped
*   Failed
*   Running
*   Stopping', example='Running'),
        migrationType?: string(name='MigrationType', description='The synchronization type. Valid values:

*   FullAndRealtimeIncremental: one-time full synchronization and real-time incremental synchronization
*   RealtimeIncremental: real-time incremental synchronization
*   Full: full synchronization
*   OfflineIncremental: batch incremental synchronization
*   FullAndOfflineIncremental: one-time full synchronization and batch incremental synchronization', example='FullAndRealtimeIncremental'),
        projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace to which the synchronization task belongs.', example='26442'),
        sourceDataSourceType?: string(name='SourceDataSourceType', description='The source type. Valid values: PolarDB, MySQL, Kafka, Loghub, Hologres, Oracle, OceanBase, MongoDB, RedShift, Hive, SqlServer, Doris, and ClickHouse. If you do not configure this parameter, the API operation returns synchronization tasks that use all types of sources.', example='Mysql'),
      }
    ](name='DIJobs', description='The synchronization tasks returned.'),
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='12'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7263E4AC-9D2E-5B29-B8AF-7C5012E92A41'),
}

model ListDIJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIJobsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDIJobs  ListDIJobsRequest
  * @return ListDIJobsResponse
 */
async function listDIJobs(request: ListDIJobsRequest): ListDIJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIJobs', 'GET', '/', 'json', false, 'json', request);
}

model ListDataAssetTagsRequest {
  regionId?: string(name='RegionId', position='Host'),
  category?: string(name='Category', description='The type of the tag. Valid values:

*   Normal
*   System', example='Normal', position='Query'),
  key?: string(name='Key', description='The tag key.', example='key1', minLength=1, maxLength=128, position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', minimum=1, maximum=200, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
}

model ListDataAssetTagsResponseBody = {
  pagingInfo?: {
    dataAssetTags?: [ 
      {
        category?: string(name='Category', description='The type of the tag.

Valid values:

*   Normal
*   System', example='Normal'),
        createTime?: long(name='CreateTime', description='The time when the tag was created.', example='1735890003000'),
        createUser?: string(name='CreateUser', description='The creator of the tag.', example='12345'),
        description?: string(name='Description', description='The description of the tag.', example='This is a description'),
        key?: string(name='Key', description='The tag key.', example='key1'),
        managers?: [ string ](name='Managers', description='The tag administrators.'),
        modifyTime?: long(name='ModifyTime', description='The time when the tag was last modified.', example='1735890003000'),
        modifyUser?: string(name='ModifyUser', description='The user who last modified the tag.', example='1234'),
        valueType?: string(name='ValueType', description='The type of the tag value.', example='String'),
        values?: [ string ](name='Values', description='The tag values.'),
      }
    ](name='DataAssetTags', description='The tags.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='2524'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376****'),
}

model ListDataAssetTagsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataAssetTagsResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of ListDataAssetTags  ListDataAssetTagsRequest
  * @return ListDataAssetTagsResponse
 */
async function listDataAssetTags(request: ListDataAssetTagsRequest): ListDataAssetTagsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataAssetTags', 'GET', '/', 'json', false, 'json', request);
}

model ListDataAssetsRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataAssetIds?: [ string ](name='DataAssetIds', description='The data asset IDs.', shrink='json', position='Query'),
  dataAssetType?: string(name='DataAssetType', description='The type of the data asset. Valid values:

*   ACS::DataWorks::Table
*   ACS::DataWorks::Task', example='ACS::DataWorks::Task', position='Query'),
  envType?: string(name='EnvType', description='The environment of the workspace to which the data asset belongs. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', minimum=1, maximum=200, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10000', position='Query'),
  tags: [ 
    {
      key: string(name='Key', description='The tag key.

The tag key can be up to 64 characters in length and can contain letters, digits, and the following characters: `-@#*<>|[]()+=&%$!~`. It cannot start with `dw:`.

This parameter is required.', example='key'),
      value?: string(name='Value', description='The tag value.', example='value'),
    }
  ](name='Tags', description='The tags that are added to data assets. This parameter specifies a filter condition.

*   You can specify multiple tags, which are in the logical OR relation. For example, you can query the data assets that contain one of the following tags: `["key1:v1", "key2:v1", "key3:v1"]`.
*   If you do not configure this parameter, tag-based filtering is not performed.

This parameter is required.', shrink='json', position='Query'),
}

model ListDataAssetsResponseBody = {
  pagingInfo?: {
    dataAssets?: [ 
      {
        dataAssetTagMappings?: [ 
          {
            autoTraceEnabled?: boolean(name='AutoTraceEnabled', description='Indicates whether the lineage-based automatic backtrack feature is enabled for the mapping.', example='false'),
            creator?: string(name='Creator', description='The creator of the mapping between the data asset and the tag.', example='12345'),
            dataAssetId?: string(name='DataAssetId', description='The data asset ID.', example='7259557313'),
            key?: string(name='Key', description='The tag key.', example='key'),
            tagSource?: string(name='TagSource', description='The way in which the mapping between the data asset and the tag is created. Valid values:

*   System
*   UserDefined', example='UserDefined'),
            value?: string(name='Value', description='The tag value.', example='value'),
          }
        ](name='DataAssetTagMappings', description='The mappings between data assets and tags.'),
        envType?: string(name='EnvType', description='The environment of the workspace to which the data asset belongs. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod'),
        id?: string(name='Id', description='The data asset ID.', example='7259557313'),
        name?: string(name='Name', description='The name of the data asset.', example='ali_cn_es_gfn'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='54275'),
        type?: string(name='Type', description='The type of the data asset. Valid values:

*   ACS::DataWorks::Table
*   ACS::DataWorks::Task', example='ACS::DataWorks::Task'),
      }
    ](name='DataAssets', description='The data assets.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376'),
}

model ListDataAssetsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataAssetsResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of ListDataAssets  ListDataAssetsRequest
  * @return ListDataAssetsResponse
 */
async function listDataAssets(request: ListDataAssetsRequest): ListDataAssetsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataAssets', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityEvaluationTaskInstancesRequest {
  regionId?: string(name='RegionId', position='Host'),
  bizdateFrom?: string(name='BizdateFrom', description='The start time of the data quality monitoring task.', example='2024-04-01', position='Query'),
  bizdateTo?: string(name='BizdateTo', description='The end time of the data quality monitoring task.', example='2024-05-01', position='Query'),
  createTimeFrom?: long(name='CreateTimeFrom', description='The earliest start time at which the instances are generated.', example='1710239005403', position='Query'),
  createTimeTo?: long(name='CreateTimeTo', description='The latest start time at which the instances are generated.', example='1710239005403', position='Query'),
  dataQualityEvaluationTaskId?: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task.', example='10000', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', minimum=1, maximum=200, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100', position='Query'),
  tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test', position='Query'),
  triggerClient?: string(name='TriggerClient', description='The name of the trigger module of the instance.', example='CWF2', position='Query'),
  triggerClientId?: string(name='TriggerClientId', description='The ID of the instance that is generated by the task.', example='1001', position='Query'),
}

model ListDataQualityEvaluationTaskInstancesResponseBody = {
  pagingInfo?: {
    dataQualityEvaluationTaskInstances?: [ 
      {
        createTime?: long(name='CreateTime', description='The time at which the instance was generated.', example='1710239005403'),
        finishTime?: long(name='FinishTime', description='The time at which the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The ID of the instance.', example='10001'),
        parameters?: string(name='Parameters', description='The parameters configured for the instance.', example='{
  "bizdate": "20240517",
  "triggerTime": "1710239005403"
}'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100'),
        status?: string(name='Status', description='The status of the instance. Valid values:

*   Running
*   Error
*   Passed
*   Warned
*   Critical', example='Critical'),
        task?: {
          description?: string(name='Description', description='The description of the task.', example='This is a daily run data quality evaluation plan.'),
          hooks?: [ 
            {
              condition?: string(name='Condition', description='The trigger configuration of the callback event.', example='${severity} == "High" AND ${status} == "Critical"'),
              type?: string(name='Type', description='The type of the callback event. Valid values:

*   BlockTaskInstance. The value indicates that an auto triggered node is blocked.', example='BlockTaskInstance'),
            }
          ](name='Hooks', description='The callback configurations of the task during the instance lifecycle. Blocking an auto triggered node is a type of callback event. Only this type is supported.'),
          id?: long(name='Id', description='The task ID.', example='10001'),
          name: string(name='Name', description='The name of the monitor.

This parameter is required.', example='Quality verification task'),
          notifications?: {
            condition?: string(name='Condition', description='The trigger condition of the alert notification.', example='${severity} == "High"'),
            notifications?: [ 
              {
                nofiticationReceivers?: [ 
                  {
                    extension?: string(name='Extension', description='The extended information in the JSON format. For example, the DingTalk chatbot can remind all members in a DingTalk group by using the at sign (@).', example='{"atAll":"true"}'),
                    receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid values:

*   AliUid: Alibaba Cloud account ID
*   WebhookUrl: URL of a custom webhook
*   DingdingUrl: DingTalk chatbot URL
*   FeishuUrl: Lark chatbot URL
*   WeixinUrl: WeCom chatbot URL', example='AliUid'),
                    receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
                  }
                ](name='NofiticationReceivers', description='The alert recipients.'),
                notificationChannels?: [ 
                  {
                    channels?: [ string ](name='Channels', description='The alert notification methods.'),
                  }
                ](name='NotificationChannels', description='The alert notification methods.'),
              }
            ](name='Notifications', description='The configurations for the alert notification.'),
          }(name='Notifications', description='The configurations for alert notifications.'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          runtimeConf?: string(name='RuntimeConf', description='The configuration of the data source. The value of the queue field is default, and that of the sqlEngine field can be set to SPARK_SQL, KYUUBI, PRESTO_SQL, or HIVE_SQL. The value default indicates the YARN queue for E-MapReduce (EMR) tasks.', example='{ "queue": "default", "sqlEngine": "SPARK-SQL" }'),
          target?: {
            databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='maxcompute'),
            partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='ds=$[yyyymmdd-1]'),
            tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test'),
            type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
          }(name='Target', description='The monitored object of the task.'),
          trigger?: {
            taskIds?: [ long ](name='TaskIds', description='The IDs of the auto triggered nodes of which the instances are successfully run.'),
            type?: string(name='Type', description='The trigger condition of the task. Valid values:

*   ByScheduledTaskInstance. The value indicates that the task is triggered when the instance of an auto triggered node is successfully run.', example='ByScheduledTaskInstance'),
          }(name='Trigger', description='The trigger configuration of the task.'),
        }(name='Task', description='The snapshot of the configurations for the task when the task starts.'),
        triggerContext?: string(name='TriggerContext', description='The information about the trigger module of the instance.', example='{
  "TriggerClientId": 10001,
  "TriggerClient": "CWF2"
}'),
      }
    ](name='DataQualityEvaluationTaskInstances', description='The instances generated by the task.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='294'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityEvaluationTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityEvaluationTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityEvaluationTaskInstances  ListDataQualityEvaluationTaskInstancesRequest
  * @return ListDataQualityEvaluationTaskInstancesResponse
 */
async function listDataQualityEvaluationTaskInstances(request: ListDataQualityEvaluationTaskInstancesRequest): ListDataQualityEvaluationTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityEvaluationTaskInstances', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityEvaluationTasksRequest {
  regionId?: string(name='RegionId', position='Host'),
  name?: string(name='Name', description='The name of the data quality monitoring task. Fuzzy match is supported.', example='Test', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', minimum=1, maximum=200, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100', position='Query'),
  tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test', position='Query'),
}

model ListDataQualityEvaluationTasksResponseBody = {
  pagingInfo?: {
    dataQualityEvaluationTasks?: [ 
      {
        dataSourceId?: long(name='DataSourceId'),
        description?: string(name='Description', description='The description of the data quality monitoring task. The description can be up to 65,535 characters in length.', example='This is a daily run data quality evaluation plan'),
        hooks?: [ 
          {
            condition?: string(name='Condition', description='The trigger configuration of the callback event.', example='${severity} == "High" AND ${status} == "Critical"'),
            type?: string(name='Type', description='The type of the callback event. Valid values:

*   BlockTaskInstance. The value indicates that an auto triggered node is blocked.', example='BlockTaskInstance'),
          }
        ](name='Hooks', description='The callback configurations of the task during the instance lifecycle. Blocking an auto triggered node is a type of callback event. Only this type is supported.'),
        id?: long(name='Id', description='The ID of the data quality monitoring task.', example='10001'),
        name?: string(name='Name', description='The name of the data quality monitoring task. The name can be up to 255 characters in length and can contain digits, letters, and punctuation marks.', example='Data quality verification task'),
        notifications?: {
          condition?: string(name='Condition', description='The trigger condition of the alert notification.', example='${severity} == "High"'),
          notifications?: [ 
            {
              notificationChannels?: [ 
                {
                  channels?: [ string ](name='Channels', description='The alert notification methods.'),
                }
              ](name='NotificationChannels', description='The alert notification methods.'),
              notificationReceivers?: [ 
                {
                  extension?: string(name='Extension', description='The extended information in the JSON format. For example, the DingTalk chatbot can remind all members in a DingTalk group by using the at sign (@).', example='{"atAll":"true"}'),
                  receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid values:

*   AliUid: Alibaba Cloud account ID
*   WebhookUrl: URL of a custom webhook
*   DingdingUrl: DingTalk chatbot URL
*   FeishuUrl: Lark chatbot URL
*   WeixinUrl: WeCom chatbot URL', example='AliUid'),
                  receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
                }
              ](name='NotificationReceivers', description='The alert recipients.'),
            }
          ](name='Notifications', description='The configurations for the alert notification.'),
        }(name='Notifications', description='The configurations for alert notifications.'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100'),
        runtimeConf?: string(name='RuntimeConf', description='The configuration of the data source. The value of the queue field is default, and that of the sqlEngine field can be set to SPARK_SQL, KYUUBI, PRESTO_SQL, or HIVE_SQL. The value default indicates the YARN queue for E-MapReduce (EMR) tasks.', example='{ "queue": "default", "sqlEngine": "SPARK-SQL" }'),
        target?: {
          databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='maxcompute'),
          partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='ds=$[yyyymmdd-1]'),
          tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test'),
          type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
        }(name='Target', description='The monitored object of the task.'),
        trigger?: {
          taskIds?: [ long ](name='TaskIds', description='The IDs of the auto triggered nodes of which the instances are successfully run. This parameter takes effect only if the Type parameter is set to ByScheduledTaskInstance.'),
          type?: string(name='Type', description='The trigger condition of the task. Valid values:

*   ByScheduledTaskInstance. The value indicates that the task is triggered when the instance of an auto triggered node is successfully run.', example='ByScheduledTaskInstance'),
        }(name='Trigger', description='The trigger configuration of the task.'),
      }
    ](name='DataQualityEvaluationTasks', description='The data quality monitoring tasks.'),
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='131'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityEvaluationTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityEvaluationTasksResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityEvaluationTasks  ListDataQualityEvaluationTasksRequest
  * @return ListDataQualityEvaluationTasksResponse
 */
async function listDataQualityEvaluationTasks(request: ListDataQualityEvaluationTasksRequest): ListDataQualityEvaluationTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityEvaluationTasks', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityResultsRequest {
  regionId?: string(name='RegionId', position='Host'),
  bizdateFrom?: string(name='BizdateFrom', description='The beginning of the time range to query.', example='2024-05-01', position='Query'),
  bizdateTo?: string(name='BizdateTo', description='The end of the time range to query.', example='2024-05-04', position='Query'),
  createTimeFrom?: long(name='CreateTimeFrom', description='The earliest time when the data quality check result was generated.', example='1710239005403', position='Query'),
  createTimeTo?: long(name='CreateTimeTo', description='The latest time when the data quality check result was generated.', example='1710239005403', position='Query'),
  dataQualityEvaluationTaskId?: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task.', example='200001', position='Query'),
  dataQualityEvaluationTaskInstanceId?: long(name='DataQualityEvaluationTaskInstanceId', description='The ID of the instance generated by the check.', example='10001', position='Query'),
  dataQualityRuleId?: long(name='DataQualityRuleId', description='The ID of the data quality monitoring rule.', example='100001', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', minimum=1, maximum=200, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100', position='Query'),
}

model ListDataQualityResultsResponseBody = {
  pagingInfo?: {
    dataQualityResults?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the data quality check result was generated.', example='1708284916414'),
        details?: [ 
          {
            checkedValue?: string(name='CheckedValue', description='The value that is used for comparison with the threshold.', example='100.0'),
            referencedValue?: string(name='ReferencedValue', description='The value that is calculated based on sample data. The value serves as a baseline value during the calculation of the value of the CheckedValue parameter.', example='0.0'),
            status?: string(name='Status', description='The comparison result between the value of CheckedValue and the threshold. Valid values:

*   Error
*   Passed
*   Warned
*   Critical', example='PASSED'),
          }
        ](name='Details', description='The information about the data quality check.'),
        id?: long(name='Id', description='The ID of the check result.', example='16033'),
        rule?: {
          checkingConfig?: {
            referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference samples and perform aggregate operations on the reference values. In this example, an expression is used to indicate the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
            thresholds?: {
              critical?: {
                expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
                operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
                value?: string(name='Value', description='The threshold value.', example='100.0'),
              }(name='Critical', description='The threshold settings for critical alerts.'),
              expected?: {
                expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
                operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
                value?: string(name='Value', description='The threshold value.', example='100.0'),
              }(name='Expected', description='The expected threshold setting.'),
              warned?: {
                expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
                operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
                value?: string(name='Value', description='The threshold value.', example='100.0'),
              }(name='Warned', description='The threshold settings for normal alerts.'),
            }(name='Thresholds', description='The threshold settings.'),
            type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='FIXED'),
          }(name='CheckingConfig', description='The check settings for sample data.'),
          description?: string(name='Description', description='The description of the rule. The description can be up to 500 characters in length.', example='this is a odps _sql task'),
          enabled?: boolean(name='Enabled', description='Indicates whether the rule is enabled.', example='true'),
          errorHandlers?: [ 
            {
              errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If the rule is defined by custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
              type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SAVE_ERROR_DATA'),
            }
          ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
          id?: long(name='Id', description='The rule ID.', example='100001'),
          name?: string(name='Name', description='The name of the rule. The name can be up to 255 characters in length and can contain digits, letters, and punctuation marks.', example='The table cannot be empty.'),
          projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100'),
          samplingConfig?: {
            metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='COUNT'),
            metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "columns": [ "id", "name" ] }'),
            samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='id IS NULL'),
            settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s;'),
          }(name='SamplingConfig', description='The sampling settings.'),
          severity?: string(name='Severity', description='The strength of the rule. Valid values:

*   High
*   Normal', example='NORMAL'),
          target?: {
            databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='MAX_COMPUTE'),
            tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test'),
            type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='TABLE'),
          }(name='Target', description='The monitored object of the rule.'),
          templateCode?: string(name='TemplateCode', description='The code of the template that is referenced when you create a rule.', example='system::user_defined'),
        }(name='Rule', description='The snapshot of the rule configuration when the check starts.'),
        sample?: string(name='Sample', description='The sample values used for the check.', example='[
  {
    "gender": "male",
    "_count": 100
  }, {
    "gender": "female",
    "_count": 100
  }
]'),
        status?: string(name='Status', description='The status of the check result. Valid values:

*   Running
*   Error
*   Passed
*   Warned
*   Critical', example='PASSED'),
        taskInstanceId?: long(name='TaskInstanceId', description='The ID of the instance generated by the check.', example='200001'),
      }
    ](name='DataQualityResults', description='The data quality check results.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='219'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityResultsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityResultsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityResults  ListDataQualityResultsRequest
  * @return ListDataQualityResultsResponse
 */
async function listDataQualityResults(request: ListDataQualityResultsRequest): ListDataQualityResultsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityResults', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityRuleTemplatesRequest {
  regionId?: string(name='RegionId', position='Host'),
  creationSource?: string(name='CreationSource', description='The source of the template. This parameter is required. Valid values:

*   System
*   UserDefined', example='System', position='Query'),
  directoryPath?: string(name='DirectoryPath', description='The directory in which the template is stored. Slashes (/) are used to separate directory levels. The name of each directory level can be up to 1,024 characters in length. It cannot contain whitespace characters or slashes (/).', example='/ods/order_data', position='Query'),
  name?: string(name='Name', description='The name of the template. If you want to query a system template, set this parameter to the name of the system template. Fuzzy match is supported.', example='Table rows', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The number of entries per page. Default value: 10.', example='10', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The page number. Default value: 1.', example='1', minimum=1, maximum=200, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='10000', position='Query'),
}

model ListDataQualityRuleTemplatesResponseBody = {
  pagingInfo?: {
    dataQualityRuleTemplates?: [ 
      {
        checkingConfig?: {
          referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='Some types of thresholds need to query some reference samples, and then summarize the values of the reference samples to obtain the threshold for comparison. Here, an expression is used to represent the query method of the reference samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
          type?: string(name='Type', description='Threshold Calculation method
- Fixed
- Fluctation
- FluctationDiscreate
- Auto
- Average
- Variance', example='Fixed'),
        }(name='CheckingConfig', description='Sample verification settings'),
        code?: string(name='Code', description='Rule template Code', example='USER_DEFINED:123'),
        directoryPath?: string(name='DirectoryPath', description='The directory in which the template is stored. Slashes (/) are used to separate directory levels. The name of each directory level can be up to 1,024 characters in length. It cannot contain whitespace characters or slashes (/).', example='/ods/order_data'),
        name?: string(name='Name', description='The name of the template. The name can be up to 512 characters in length and can contain digits, letters, and punctuation marks.', example='Table row Count Verification'),
        projectId?: long(name='ProjectId', description='DataWorks workspace ID', example='2043'),
        samplingConfig?: {
          metric?: string(name='Metric', description='The name of the sampled metric.
- Count: number of table rows
- Min: minimum value of the field
- Max: The maximum value of the field.
- Avg: field mean
- DistinctCount: number of unique field values
- DistinctPercent: the ratio of the number of unique field values to the number of data rows.
- DuplicatedCount: number of duplicate field values
- DuplicatedPercent: the ratio of the number of duplicate field values to the number of data rows.
- TableSize: table size
- NullValueCount: number of rows with empty fields
- NullValuePercent: the proportion of fields that are empty.
- GroupCount: aggregate each value by field value and the corresponding number of data rows
- CountNotIn: the enumerated value does not match the number of rows.
- CountDistinctNotIn: the number of unique values that the enumerated values do not match.
- UserDefinedSql: use custom SQL to collect samples', example='Max'),
          metricParameters?: string(name='MetricParameters', description='Parameters required for sample collection', example='{"Sql": "select count(1) from table;"}'),
          settingConfig?: string(name='SettingConfig', description='Before executing the sample statement, insert some runtime parameter setting statements, which can be up to 1000 characters in length. Currently, only MaxCompute are supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;'),
        }(name='SamplingConfig', description='Settings required for sample collection'),
        visibleScope?: string(name='VisibleScope', description='Available range of templates:
- Tenant: all tenants are available
- Project: only available in the current Project', example='Project'),
      }
    ](name='DataQualityRuleTemplates', description='The templates.'),
    pageNumber?: int32(name='PageNumber', description='Page number', example='1'),
    pageSize?: int32(name='PageSize', description='Page size', example='10'),
    totalCount?: int32(name='TotalCount', description='Total number of entries', example='42'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityRuleTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityRuleTemplatesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDataQualityRuleTemplates  ListDataQualityRuleTemplatesRequest
  * @return ListDataQualityRuleTemplatesResponse
 */
async function listDataQualityRuleTemplates(request: ListDataQualityRuleTemplatesRequest): ListDataQualityRuleTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityRuleTemplates', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityRulesRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityEvaluationTaskId?: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task that is associated with the rule.', example='10000', position='Query'),
  name?: string(name='Name', description='The name of the rule. Fuzzy match is supported.', example='unit_test', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 200.', example='10', minimum=1, maximum=200, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10002', position='Query'),
  tableGuid?: string(name='TableGuid', description='The ID of the table that is limited by the rule in Data Map.', example='odps.unit_test.tb_unit_test', position='Query'),
}

model ListDataQualityRulesResponseBody = {
  pagingInfo?: {
    dataQualityRules?: [ 
      {
        checkingConfig?: {
          referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference values. In this example, an expression is used to indicate the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
          thresholds?: {
            critical?: {
              expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
              operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
              value?: string(name='Value', description='The threshold value.', example='100.0'),
            }(name='Critical', description='The threshold settings for critical alerts.'),
            expected?: {
              expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
              operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
              value?: string(name='Value', description='The threshold value.', example='100.0'),
            }(name='Expected', description='The expected threshold setting.'),
            warned?: {
              expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
              operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
              value?: string(name='Value', description='The threshold value.', example='100.0'),
            }(name='Warned', description='The threshold settings for normal alerts.'),
          }(name='Thresholds', description='The threshold settings.'),
          type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
        }(name='CheckingConfig', description='The check settings for sample data.'),
        description?: string(name='Description', description='The description of the rule. The description can be up to 500 characters in length.', example='this is a odps _sql task'),
        enabled?: boolean(name='Enabled', description='Indicates whether the rule is enabled.', example='true'),
        errorHandlers?: [ 
          {
            errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If the rule is defined by custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
            type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
          }
        ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
        id?: long(name='Id', description='The rule ID.', example='22130'),
        name?: string(name='Name', description='The rule name.', example='The table cannot be empty.'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100001'),
        samplingConfig?: {
          metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the percentage of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values in the field.
*   DuplicatedPercent: the percentage of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field is set to null.
*   NullValuePercent: the percentage of the number of rows in which the field is set to null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that the data is sampled by executing custom SQL statements.', example='Max'),
          metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
          samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='id IS NULL'),
          settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;'),
        }(name='SamplingConfig', description='The settings for sampling.'),
        severity?: string(name='Severity', description='The strength of the rule. Valid values:

*   Normal
*   High', example='High'),
        target?: {
          databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='maxcompute'),
          tableGuid?: string(name='TableGuid', description='The ID of the table that is limited by the rule in Data Map.', example='odps.unit_test.tb_unit_test'),
          type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
        }(name='Target', description='The monitored object of the rule.'),
        templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='system::user_defined'),
      }
    ](name='DataQualityRules', description='The rules.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='294'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityRulesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityRules  ListDataQualityRulesRequest
  * @return ListDataQualityRulesResponse
 */
async function listDataQualityRules(request: ListDataQualityRulesRequest): ListDataQualityRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityRules', 'GET', '/', 'json', false, 'json', request);
}

model ListDataSourceSharedRulesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dataSourceId: long(name='DataSourceId', description='The data source ID.

This parameter is required.', example='1', position='Query'),
  targetProjectId?: long(name='TargetProjectId', description='The ID of the workspace to which the data source is shared. You cannot share the data source to the workspace with which the data source is associated.', example='1', position='Query'),
}

model ListDataSourceSharedRulesResponseBody = {
  dataSourceSharedRules?: [ 
    {
      createTime?: long(name='CreateTime', description='The time when the rule was created. This value is a UNIX timestamp.', example='1724379762000'),
      createUser?: string(name='CreateUser', description='The ID of the user who creates the rule.', example='1'),
      dataSourceId?: long(name='DataSourceId', description='The data source ID. You can call the [ListDataSources](https://help.aliyun.com/document_detail/211431.html) operation to query the ID.', example='1'),
      envType?: string(name='EnvType', description='The environment to which the target data source belongs. The values are as follows:
- Dev: the development environment.
- Prod: the production environment.', example='Dev'),
      id?: long(name='Id', description='The rule ID.', example='1'),
      sharedDataSourceName?: string(name='SharedDataSourceName', description='The name of the data source in the destination workspace.', example='targetProject.datasource'),
      sharedUser?: string(name='SharedUser', description='The user in the workspace to which the data source is shared. If the data source is shared to the entire workspace, this parameter is left empty.', example='1'),
      sourceProjectId?: long(name='SourceProjectId', description='The ID of the workspace with which the data source is associated.', example='1'),
      targetProjectId?: long(name='TargetProjectId', description='The ID of the workspace to which the data source is shared.', example='1'),
    }
  ](name='DataSourceSharedRules', description='The sharing rules of the data source.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
}

model ListDataSourceSharedRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataSourceSharedRulesResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  If you want to query the sharing rules of a data source that is associated with Workspace A, you must have the permissions to share the data source in Workspace A. You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Tenant Administrator, Workspace Administrator, and Workspace Owner
  * @param request  the request parameters of ListDataSourceSharedRules  ListDataSourceSharedRulesRequest
  * @return ListDataSourceSharedRulesResponse
 */
async function listDataSourceSharedRules(request: ListDataSourceSharedRulesRequest): ListDataSourceSharedRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataSourceSharedRules', 'GET', '/', 'json', false, 'json', request);
}

model ListDataSourcesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  envType?: string(name='EnvType', description='The environment in which the data sources are used. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod', position='Query'),
  name?: string(name='Name', description='The name of the data source. Fuzzy match by data source name is supported.', example='test', position='Query'),
  order?: string(name='Order', description='The order in which you want to sort the data sources. Valid values:

*   Desc: descending order
*   Asc: ascending order

Default value: Desc', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='17820', position='Query'),
  sortBy?: string(name='SortBy', description='The field that you want to use to sort the data sources. Valid values:

*   CreateTime
*   Id
*   Name

Default value: CreateTime', example='Id', position='Query'),
  tags?: string(name='Tags', description='The tag of the data source. This parameter specifies a filter condition.

*   You can specify multiple tags, which are in the logical AND relation. For example, you can query the data sources that contain the following tags: `["tag1", "tag2", "tag3"]`.
*   If you do not configure this parameter, tag-based filtering is not performed. You can specify up to 10 tags.', example='["tag1", "tag2", "tag3"]', position='Query'),
  types?: [ string ](name='Types', description='The data source types. This parameter specifies a filter condition. You can specify multiple data source types.', shrink='simple', position='Query'),
}

model ListDataSourcesResponseBody = {
  pagingInfo?: {
    dataSources?: [ 
      {
        dataSource?: [ 
          {
            connectionProperties?: any(name='ConnectionProperties', description='The connection configurations of the data source, including the connection address, access identity, and environment information. The envType parameter specifies the environment in which the data source is used. Valid values of the envType parameter:

*   Dev: development environment
*   Prod: production environment

The parameters that you need to configure for the data source vary based on the mode in which the data source is added. For more information, see [Data source connection information (ConnectionProperties)](https://help.aliyun.com/document_detail/2852465.html).', example='{
	"envType": "Prod",
	"regionId": "cn-beijing",
    "instanceId": "hgprecn-cn-x0r3oun4k001",
    "database": "testdb",
    "securityProtocol": "authTypeNone",
    "authType": "Executor",
    "authIdentity": "1107550004253538"
}'),
            connectionPropertiesMode?: string(name='ConnectionPropertiesMode', description='The mode in which the data source is added. The mode varies based on the data source type. Valid values:

*   InstanceMode: instance mode
*   UrlMode: connection string mode', example='UrlMode'),
            createTime?: long(name='CreateTime', description='The time when the data source was added. This value is a UNIX timestamp.', example='1648711113000'),
            createUser?: string(name='CreateUser', description='The ID of the user who adds the data source.', example='1624387842781448'),
            description?: string(name='Description', description='The description of the data source.', example='test'),
            id?: long(name='Id', description='The ID of the data source.', example='16035'),
            modifyTime?: long(name='ModifyTime', description='The time when the data source was last modified. This value is a UNIX timestamp.', example='1648711113000'),
            modifyUser?: string(name='ModifyUser', description='The ID of the user who modifies the data source.', example='1624387842781448'),
            qualifiedName?: string(name='QualifiedName', description='The unique business key of the data source. For example, the unique business key of a Hologres data source is in the `${tenantOwnerId}:${regionId}:${type}:${instanceId}:${database}` format.', example='1648711121000:cn-beijing:odps:yongxunQA_beijing_standard'),
          }
        ](name='DataSource', description='The data sources. Each element is the information of a single data source with a unique data source ID.'),
        name?: string(name='Name', description='The name of the data source.', example='test'),
        type?: string(name='Type', description='The type of the data source.', example='mysql'),
      }
    ](name='DataSources', description='The data source groups. Each element in the array indicates a data source group. Each data source group contains data sources in the development environment (if any) and the production environment.'),
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='131'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7BE1433F-6D55-5D86-9344-CA6F7DD19B13'),
}

model ListDataSourcesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataSourcesResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Deploy, Develop, Visitor, Workspace Owner, O\\&M, Model Designer, Security Administrator, Data Analyst, OpenPlatform Administrator, and Data Governance Administrator
  * @param request  the request parameters of ListDataSources  ListDataSourcesRequest
  * @return ListDataSourcesResponse
 */
async function listDataSources(request: ListDataSourcesRequest): ListDataSourcesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataSources', 'GET', '/', 'json', false, 'json', request);
}

model ListDatabasesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', example='test comment', position='Query'),
  name?: string(name='Name', example='test_tbl', position='Query'),
  order?: string(name='Order', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', example='10', minimum=1, maximum=100, position='Query'),
  parentMetaEntityId: string(name='ParentMetaEntityId', description='The parent entity ID. For more information, see [description of concepts related to metadata entities.](https://help.aliyun.com/document_detail/2880092.html)

The type of the parent entity can be found in the response of the ListCrawlerTypes operation.

*   If the parent entity is a catalog, the format of `ParentMetaEntityId` follows the response of the ListCatalogs API.
*   If the parent entity is a metadata crawler, the format of `ParentMetaEntityId` is `${CrawlerType}:${Instance ID or encoded URL}.`

ParentMetaEntityId format examples

`dlf-catalog::catalog_id`

`holo:instance_id`

`mysql:(instance_id|encoded_jdbc_url)`

> \\
`catalog_id`: The DLF catalog ID.\\
`instance_id`: The instance ID, required for the data source registered in instance mode.\\
`encoded_jdbc_url`: The JDBC connection string that has been URL encoded, required for the data source registered via a connection string.

This parameter is required.', example='mysql:rm-abc123xxx
dlf-catalog:123456XXX:test_catalog', position='Query'),
  sortBy?: string(name='SortBy', example='CreateTime', position='Query'),
}

model ListDatabasesResponseBody = {
  pagingInfo?: {
    databases?: [
      Database
    ](name='Databases'),
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    totalCount?: long(name='TotalCount', example='1'),
  }(name='PagingInfo'),
  requestId?: string(name='RequestId', example='9DD08926-38B9-XXXXXXX'),
  success?: boolean(name='Success', example='true'),
}

model ListDatabasesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDatabasesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDatabases  ListDatabasesRequest
  * @return ListDatabasesResponse
 */
async function listDatabases(request: ListDatabasesRequest): ListDatabasesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDatabases', 'GET', '/', 'json', false, 'json', request);
}

model ListDeploymentPackageFilesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  businessId?: long(name='BusinessId', description='The workflow ID. You can call the [ListBusiness](https://help.aliyun.com/document_detail/173945.html) operation to query the workflow ID by name.', example='100001', position='Query'),
  changeType?: int32(name='ChangeType', description='The change type. Valid values:

*   0: addition
*   1: update
*   2: deletion', example='0', position='Query'),
  commitFrom?: string(name='CommitFrom', description='The start date for committing. Specify the date in the yyyy-MM-dd format.', example='2025-01-01', position='Query'),
  commitTo?: string(name='CommitTo', description='The end date (included) for committing. Specify the date in the yyyy-MM-dd format.', example='2025-01-31', position='Query'),
  commitUserId?: string(name='CommitUserId', description='The ID of the user who commits the file.', example='2003****', position='Query'),
  fileIds?: [ string ](name='FileIds', description='The IDs of the files to be queried.', shrink='json', position='Query'),
  fileName?: string(name='FileName', description='The name of the file.', example='Filename', position='Query'),
  fileType?: int32(name='FileType', description='The type of the code for the file.

The code for files varies based on the file type. For more information, see [DataWorks nodes](https://help.aliyun.com/document_detail/600169.html). You can call the [ListFileType](https://help.aliyun.com/document_detail/212428.html) operation to query the type of the code for the file.', example='10', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='20', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='12345', position='Query'),
  solutionId?: long(name='SolutionId', description='The solution ID.', example='8065', position='Query'),
}

model ListDeploymentPackageFilesResponseBody = {
  pagingInfo?: {
    deploymentPackageFiles?: [ 
      {
        changeType?: int32(name='ChangeType', description='The change type, which is an integer. Valid values:

*   0: addition
*   1: update
*   2: deletion', example='0'),
        comment?: string(name='Comment', description='The comment for committing.'),
        commitTime?: string(name='CommitTime', description='The time for committing.', example='2025-04-10 15:55:47'),
        commitUser?: string(name='CommitUser', description='The ID of the Alibaba Cloud account used by the user who committed the file.', example='446***'),
        commitUserName?: string(name='CommitUserName', description='The name of the Alibaba Cloud account used by the user who committed the file.', example='user***'),
        fileId?: long(name='FileId', description='The file ID.', example='520246913'),
        fileName?: string(name='FileName', description='The name of the file of the current version.', example='bak_part_basc_person_relation_all_da'),
        fileType?: int32(name='FileType', description='The file type. The code for files varies based on the file type. For more information, see [DataWorks nodes](https://help.aliyun.com/document_detail/600169.html).', example='13'),
        fileVersion?: long(name='FileVersion', description='The file version.', example='34'),
        id?: long(name='Id', description='The unique ID.', example='650433503'),
        isSameAsProductionVersion?: boolean(name='IsSameAsProductionVersion', description='Indicates whether the version is a version in the production environment of the scheduling system.', example='true'),
        nodeConfiguration?: string(name='NodeConfiguration', description='The scheduling property configurations of the node that corresponds to the file, which is a JSON string.', example='{
	"tagList": [],
	"fileId": -1,
	"taskRerunTime": 0,
	"taskRerunInterval": 0,
	"reRunAble": 1,
	"nodeId": 125803000,
	"nodeName": "new",
	"nodeType": 0,
	"isStop": 0,
	"paraValue": "",
	"startEffectDate": "1970-01-01 00:00:00",
	"endEffectDate": "9999-01-01 00:00:00",
	"cronExpress": "00 26 00 * * ?",
	"owner": "1107550004250000",
	"resgroupId": 6300000,
	"cu": "0.25",
	"appId": 170000,
	"tenantId": 524257424560000,
	"createTime": "2025-04-10 15:55:01",
	"createUser": "1107550004250000",
	"lastModifyTime": "2025-04-10 15:55:41",
	"cycleType": 0,
	"dependentType": 0,
	"dependentTypeList": [0],
	"lastModifyUser": "1107550004250000",
	"dependentDataNode": "",
	"input": "[{\\"regionId\\":\\"cn-hangzhou\\",\\"str\\":\\"root_input\\",\\"parseType\\":1}]",
	"output": "[{\\"str\\":\\"project_root.526586287_out\\",\\"parseType\\":2},{\\"str\\":\\"project_root.new\\",\\"parseType\\":1}]",
	"inputList": [{
		"regionId": "cn-hangzhou",
		"str": "root_input",
		"parseType": 1
	}],
	"outputList": [{
		"str": "project_root.526586287_out",
		"parseType": 2
	}, {
		"str": "project_root.new",
		"parseType": 1
	}],
	"isAutoParse": 1,
	"startRightNow": false,
	"extConfig": "{\\"openCustomCron\\":false,\\"formCron\\":\\"\\"}",
	"inputContextList": [],
	"outputContextList": []
}'),
        nodeId?: long(name='NodeId', description='The ID of the auto triggered node that corresponds to the file.', example='700005008419'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='27595'),
        smokeTestStatus?: string(name='SmokeTestStatus', description='The test status in the development environment.'),
        status?: int32(name='Status', description='The status of the code for the file of the current version. Valid values:

*   10: committing
*   11: committed to the development environment of the scheduling system
*   20: review passed
*   21: review failed
*   80: deployment package creation succeeded
*   100: deploying
*   101: deployed to the production environment
*   200: cancelled', example='100'),
        tenantId?: long(name='TenantId', description='The DataWorks tenant ID.', example='639415964191360'),
        useType?: string(name='UseType', description='The module to which the file belongs. Valid values:

*   NORMAL: The file is used for DataStudio.
*   MANUAL: The file is used for a manually triggered node.
*   MANUAL_BIZ: The file is used for a manually triggered workflow.
*   SKIP: The file is used for a dry-run node in DataStudio.
*   ADHOCQUERY: The file is used for an ad hoc query.
*   COMPONENT: The file is used for a script template.', example='NORMAL'),
      }
    ](name='DeploymentPackageFiles', description='The details of the versions of the files to be deployed.'),
    pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
}

model ListDeploymentPackageFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDeploymentPackageFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDeploymentPackageFiles  ListDeploymentPackageFilesRequest
  * @return ListDeploymentPackageFilesResponse
 */
async function listDeploymentPackageFiles(request: ListDeploymentPackageFilesRequest): ListDeploymentPackageFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDeploymentPackageFiles', 'POST', '/', 'json', false, 'json', request);
}

model ListDeploymentPackagesRequest {
  region?: string(name='Region', position='Host'),
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  creator?: string(name='Creator', example='110755000425****', position='Body'),
  endCreateTime?: long(name='EndCreateTime', example='1593877765000', position='Body'),
  endExecuteTime?: long(name='EndExecuteTime', example='1593877765000', position='Body'),
  executor?: string(name='Executor', example='2003****', position='Body'),
  keyword?: string(name='Keyword', example='abc', position='Body'),
  pageNumber?: int32(name='PageNumber', example='1', position='Body'),
  pageSize?: int32(name='PageSize', example='10', maximum=100, position='Body'),
  projectId?: long(name='ProjectId', example='10003', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
  status?: int32(name='Status', example='1', position='Body'),
}

model ListDeploymentPackagesResponseBody = {
  data?: {
    deployments?: [ 
      {
        createTime?: long(name='CreateTime', example='1593877765000'),
        creator?: string(name='Creator', example='2003****'),
        errorMessage?: string(name='ErrorMessage', example='OK'),
        executeTime?: long(name='ExecuteTime', example='1593877765000'),
        executor?: string(name='Executor', example='2003****'),
        id?: long(name='Id', example='11111'),
        name?: string(name='Name', example='auto_created'),
        status?: int32(name='Status', example='1'),
      }
    ](name='Deployments'),
    pageNumber?: long(name='PageNumber', example='1'),
    pageSize?: long(name='PageSize', example='10'),
    totalCount?: long(name='TotalCount', example='20'),
  }(name='Data'),
  requestId?: string(name='RequestId', example='952795279527ab****'),
}

model ListDeploymentPackagesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDeploymentPackagesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDeploymentPackages  ListDeploymentPackagesRequest
  * @return ListDeploymentPackagesResponse
 */
async function listDeploymentPackages(request: ListDeploymentPackagesRequest): ListDeploymentPackagesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDeploymentPackages', 'POST', '/', 'json', true, 'form', request);
}

model ListDownstreamTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
}

model ListDownstreamTaskInstancesResponseBody = {
  pagingInfo?: {
    downstreamTaskInstances?: [ 
      {
        dependencyType?: string(name='DependencyType', description='The scheduling dependency type. Valid values:

*   Normal
*   CrossCycle', example='Normal'),
        taskInstance?: {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
          bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description.', example='test'),
          envType?: string(name='EnvType', description='The environment in which the data source is used. Valid values:

*   Dev
*   Prod', example='Prod'),
          finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
          id?: long(name='Id', description='The instance ID.', example='1234'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
          priority?: int32(name='Priority', description='The priority of the task. Minimum value: 1. Maximum value: 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunMode?: string(name='RerunMode', description='The rerun mode.', example='AllAllowed'),
          runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
          runtime?: {
            gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
            processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
          }(name='Runtime', description='The runtime information about the instance.'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
          startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
          status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.
*   WaitTrigger: The instance is waiting to be triggered by external scheduling systems.', example='Success'),
          taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
          taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
          taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='3600'),
          triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
          triggerType?: string(name='TriggerType', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
          workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
          workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   Normal
*   Manual
*   SmokeTest
*   SupplementData
*   ManualWorkflow', example='Normal'),
          workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
        }(name='TaskInstance', description='The information about a task instance.'),
      }
    ](name='DownstreamTaskInstances', description='The descendant instances.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    taskInstances?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description.', example='test'),
        envType?: string(name='EnvType', description='The environment in which the data source is used. Valid values:

*   Dev
*   Prod', example='Prod'),
        finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The instance ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='100'),
        periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter. Valid values:', example='Prod', deprecated='true'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunMode?: string(name='RerunMode', description='The rerun mode.

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether it is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
        runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
        runtime?: {
          gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
          processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
        }(name='Runtime', description='The runtime information about the instance.'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The information about the resource group with which the instance is associated.'),
        startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
        status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.
*   WaitTrigger: The instance is waiting to be triggered by external scheduling systems.', example='Success'),
        stepType?: string(name='StepType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
        taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
        taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='1'),
        triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
        triggerType?: string(name='TriggerType', description='The method to trigger instance scheduling.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
        workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
        workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance.

Valid values:

*   SmokeTest
*   SupplementData
*   Manual
*   ManualWorkflow
*   Normal
*   ManualFlow', example='Normal'),
        workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
      }
    ](name='TaskInstances', description='The instances. This parameter is deprecated and replaced by the DownstreamTaskInstances parameter.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListDownstreamTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDownstreamTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDownstreamTaskInstances  ListDownstreamTaskInstancesRequest
  * @return ListDownstreamTaskInstancesResponse
 */
async function listDownstreamTaskInstances(request: ListDownstreamTaskInstancesRequest): ListDownstreamTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDownstreamTaskInstances', 'GET', '/', 'json', false, 'json', request);
}

model ListDownstreamTasksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model ListDownstreamTasksResponseBody = {
  pagingInfo?: {
    downstreamTasks?: [ 
      {
        dependencyType?: string(name='DependencyType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        task?: {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description.', example='test'),
          envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
          id?: long(name='Id', description='The task ID.', example='1234'),
          instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          name?: string(name='Name', description='The name of the task.', example='SQL node'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8.', example='1'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
          trigger?: {
            cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
            endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
            recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
            startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
            timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
            type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
          }(name='Trigger', description='The trigger method.'),
          type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
        }(name='Task', description='The information about the task.'),
      }
    ](name='DownstreamTasks', description='The descendant tasks.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    tasks?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description of the task.', example='test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        id?: long(name='Id', description='The task ID.', example='1234'),
        instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name of the task.', example='SQL node'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter.

Valid values:

*   Prod
*   Dev', example='Prod', deprecated='true'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
        rerunMode?: string(name='RerunMode', description='The rerun mode.

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether it is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
        rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        stepType?: string(name='StepType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
          recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
          timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
          type?: string(name='Type', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        }(name='Trigger', description='The method to trigger task scheduling.'),
        type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
      }
    ](name='Tasks', description='The tasks. This parameter is deprecated and replaced by the DownstreamTasks parameter.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListDownstreamTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDownstreamTasksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDownstreamTasks  ListDownstreamTasksRequest
  * @return ListDownstreamTasksResponse
 */
async function listDownstreamTasks(request: ListDownstreamTasksRequest): ListDownstreamTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDownstreamTasks', 'GET', '/', 'json', false, 'json', request);
}

model ListEntitiesInMetaCollectionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  entityDescription?: string(name='EntityDescription', position='Query'),
  entityName?: string(name='EntityName', example='test1', position='Query'),
  entityType?: string(name='EntityType', example='dlf-table', position='Query'),
  id: string(name='Id', description='The collection ID.

This parameter is required.', example='category.123', position='Query'),
  order?: string(name='Order', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', example='1', position='Query'),
  pageSize?: int32(name='PageSize', example='10', position='Query'),
  sortBy?: string(name='SortBy', example='Name', position='Query'),
}

model ListEntitiesInMetaCollectionResponseBody = {
  pagingInfo?: {
    entities?: [ 
      {
        comment?: string(name='Comment'),
        createTime?: long(name='CreateTime', example='1737078994080'),
        description?: string(name='Description'),
        id?: string(name='Id', description='The entity ID. Entities can only be tables. This parameter is left empty if the entity is deleted.', example='dlf-table:123456789:test_catalog:test_database::test_table'),
        modifyTime?: long(name='ModifyTime', example='1737078994080'),
        name?: string(name='Name', example='test_table'),
        type?: string(name='Type', description='The type of the entity.', example='dlf-table'),
      }
    ](name='Entities', description='The entities in the collection.'),
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='1'),
    totalCount?: int32(name='TotalCount', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='Id of the request', example='F05080B0-CCE6-5D22-B284-34A51C5D4E28'),
}

model ListEntitiesInMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListEntitiesInMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListEntitiesInMetaCollection  ListEntitiesInMetaCollectionRequest
  * @return ListEntitiesInMetaCollectionResponse
 */
async function listEntitiesInMetaCollection(request: ListEntitiesInMetaCollectionRequest): ListEntitiesInMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListEntitiesInMetaCollection', 'GET', '/', 'json', false, 'json', request);
}

model ListFileVersionsRequest {
  regionId?: string(name='RegionId', position='Host'),
  fileId: long(name='FileId', description='This parameter is required.', example='100000001', position='Body'),
  pageNumber?: int32(name='PageNumber', example='1', minimum=1, position='Body'),
  pageSize?: int32(name='PageSize', example='10', minimum=0, maximum=100, position='Body'),
  projectId?: long(name='ProjectId', example='100001', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
}

model ListFileVersionsResponseBody = {
  data?: {
    fileVersions?: [ 
      {
        changeType?: string(name='ChangeType', example='UPDATE'),
        comment?: string(name='Comment', example='Second version submission'),
        commitTime?: long(name='CommitTime', example='1593881265000'),
        commitUser?: string(name='CommitUser', example='73842342****'),
        fileContent?: string(name='FileContent', example='SHOW TABLES;'),
        fileName?: string(name='FileName', example='ods_user_info_d'),
        filePropertyContent?: string(name='FilePropertyContent', example='{"fileName":"ods_user_info_d","fileType":10}'),
        fileVersion?: int32(name='FileVersion', example='2'),
        isCurrentProd?: boolean(name='IsCurrentProd', example='false'),
        nodeContent?: string(name='NodeContent', example='{"cycleType":0,"cronExpress":"00 05 00 * * ?"}'),
        nodeId?: long(name='NodeId', example='1234'),
        status?: string(name='Status', example='COMMITTED'),
        useType?: string(name='UseType', example='NORMAL'),
      }
    ](name='FileVersions'),
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    totalCount?: int32(name='TotalCount', example='13'),
  }(name='Data'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model ListFileVersionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListFileVersionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListFileVersions  ListFileVersionsRequest
  * @return ListFileVersionsResponse
 */
async function listFileVersions(request: ListFileVersionsRequest): ListFileVersionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListFileVersions', 'POST', '/', 'json', true, 'form', request);
}

model ListFilesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  commitStatus?: int32(name='CommitStatus', example='1', position='Body'),
  exactFileName?: string(name='ExactFileName', example='ods_create.sql', position='Body'),
  fileFolderPath?: string(name='FileFolderPath', example='Business_process/my_first_business_process/MaxCompute/ods_layer', position='Body'),
  fileIdIn?: string(name='FileIdIn', example='78237,816123', position='Body'),
  fileTypes?: string(name='FileTypes', example='10,23', position='Body'),
  keyword?: string(name='Keyword', example='ods', position='Body'),
  lastEditUser?: string(name='LastEditUser', example='11233***', position='Body'),
  needAbsoluteFolderPath?: boolean(name='NeedAbsoluteFolderPath', example='false', position='Body'),
  needContent?: boolean(name='NeedContent', example='false', position='Body'),
  nodeId?: long(name='NodeId', example='123541234', position='Body'),
  owner?: string(name='Owner', example='3726346****', position='Body'),
  pageNumber?: int32(name='PageNumber', example='1', minimum=1, position='Body'),
  pageSize?: int32(name='PageSize', example='10', minimum=0, maximum=100, position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
  useType?: string(name='UseType', example='NORMAL', position='Body'),
}

model ListFilesResponseBody = {
  data?: {
    files?: [ 
      {
        absoluteFolderPath?: string(name='AbsoluteFolderPath', example='Business_process/my_first_business_process/MaxCompute/ods_layer'),
        autoParsing?: boolean(name='AutoParsing', example='true'),
        bizId?: long(name='BizId', example='300000'),
        businessId?: long(name='BusinessId', example='300000'),
        commitStatus?: int32(name='CommitStatus', example='1'),
        connectionName?: string(name='ConnectionName', example='odps_source'),
        content?: string(name='Content', example='SHOW TABLES;'),
        createTime?: long(name='CreateTime', example='1593950832000'),
        createUser?: string(name='CreateUser', example='382762****'),
        currentVersion?: int32(name='CurrentVersion', example='2'),
        fileDescription?: string(name='FileDescription', example='my test datastudio file'),
        fileFolderId?: string(name='FileFolderId', example='2735c2****'),
        fileId?: long(name='FileId', example='10000001'),
        fileName?: string(name='FileName', example='ods_user_info_d'),
        fileType?: int32(name='FileType', example='10'),
        isMaxCompute?: boolean(name='IsMaxCompute', example='false'),
        lastEditTime?: long(name='LastEditTime', example='1593950832000'),
        lastEditUser?: string(name='LastEditUser', example='382762****'),
        nodeId?: long(name='NodeId', example='300001'),
        owner?: string(name='Owner', example='3872572****'),
        parentId?: long(name='ParentId', example='-1'),
        useType?: string(name='UseType', example='NORMAL'),
      }
    ](name='Files'),
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    totalCount?: int32(name='TotalCount', example='13'),
  }(name='Data'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-****'),
  success?: boolean(name='Success', example='true'),
}

model ListFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListFiles  ListFilesRequest
  * @return ListFilesResponse
 */
async function listFiles(request: ListFilesRequest): ListFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListFiles', 'POST', '/', 'json', true, 'form', request);
}

model ListFoldersRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  pageNumber: int32(name='PageNumber', description='This parameter is required.', example='1', minimum=1, position='Body'),
  pageSize: int32(name='PageSize', description='This parameter is required.', example='10', minimum=0, maximum=100, position='Body'),
  parentFolderPath: string(name='ParentFolderPath', description='This parameter is required.', example='Business_process/my_first_business_process/MaxCompute', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
}

model ListFoldersResponseBody = {
  data?: {
    folders?: [ 
      {
        folderId?: string(name='FolderId', example='2735c2****'),
        folderPath?: string(name='FolderPath', example='Business_process/my_first_business_process/MaxCompute/ods_layer'),
      }
    ](name='Folders'),
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    totalCount?: int32(name='TotalCount', example='13'),
  }(name='Data'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-****'),
  success?: boolean(name='Success', example='true'),
}

model ListFoldersResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListFoldersResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListFolders  ListFoldersRequest
  * @return ListFoldersResponse
 */
async function listFolders(request: ListFoldersRequest): ListFoldersResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListFolders', 'POST', '/', 'json', true, 'form', request);
}

model ListFunctionsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  name?: string(name='Name', position='Query'),
  owner?: string(name='Owner', description='The ID of the owner of the UDF. This parameter specifies a filter condition.', example='110755000425XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1. Minimum value: 1.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='12345', position='Query'),
  type?: string(name='Type', description='The user-defined function (UDF) type. This parameter specifies a filter condition.

Valid values:

*   Math: mathematical operation function
*   Aggregate: aggregate function
*   String: string processing function
*   Date: date function
*   Analytic: window function
*   Other: other functions', example='MATH', position='Query'),
}

model ListFunctionsResponseBody = {
  pagingInfo?: {
    functions?: [ 
      {
        armResource?: string(name='ArmResource', description='The file resources in an Advanced RISC Machines (ARM) cluster.', example='xxx.jar,yyy.jar'),
        className?: string(name='ClassName', description='The fully qualified class name of the UDF.', example='com.demo.Main'),
        commandDescription?: string(name='CommandDescription', description='The description of the command.', example='testUdf(xx,yy)'),
        createTime?: long(name='CreateTime', description='The time when the UDF was created. This value is a UNIX timestamp.', example='1655953028000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='odps_first'),
          type?: string(name='Type', description='The type of the data source.', example='odps'),
        }(name='DataSource', description='The data source information about the UDF.'),
        databaseName?: string(name='DatabaseName', description='The name of the database. This parameter is returned for E-MapReduce (EMR) functions.', example='odps_first'),
        description?: string(name='Description', description='The overall description of the UDF.', example='Description'),
        embeddedCode?: string(name='EmbeddedCode', description='The code of the embedded UDF.', example='print(\\"hello,world!\\")'),
        embeddedCodeType?: string(name='EmbeddedCodeType', description='The type of the nested code.

Valid values:

*   Python2
*   Python3
*   Java8
*   Java11
*   Java17', example='Python2'),
        embeddedResourceType?: string(name='EmbeddedResourceType', description='The type of the nested resource.

Valid values:

*   File: general resources
*   Embedded: embedded resources', example='File'),
        exampleDescription?: string(name='ExampleDescription', description='The description of the example.', example='Example description >>> select tsetUdf(xx,yy);
abc'),
        fileResource?: string(name='FileResource', description='The files resources.', example='xxx.jar,yyy.jar'),
        id?: long(name='Id', description='The ID of the UDF.', example='580667964888595XXXX'),
        modifyTime?: long(name='ModifyTime', description='The time when the UDF was last modified. This value is a UNIX timestamp.', example='1655953028000'),
        name?: string(name='Name', description='The name of the UDF.', example='Function name'),
        owner?: string(name='Owner', description='The owner of the UDF.', example='110755000425XXXX'),
        parameterDescription?: string(name='ParameterDescription', description='The description of the parameter.', example='xx: parameter information XXX
yy: parameter information YYY'),
        projectId?: long(name='ProjectId', description='The ID of the workspace to which the UDF belongs.', example='307XXX'),
        returnValueDescription?: string(name='ReturnValueDescription', description='The description of the return value.', example='The return value is a string.'),
        runtimeResource?: {
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group used when you run the UDF.', example='S_resgrop_xxx'),
        }(name='RuntimeResource', description='The information about the resource group used when you run the UDF.'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='652567824470354XXXX'),
          path?: string(name='Path', description='The script path.', example='XXX/OpenAPI/function/function_name'),
          runtime?: {
            command?: string(name='Command', description='The command.', example='ODPS_FUNCTION'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information about the UDF.'),
        type?: string(name='Type', description='The UDF type.

Valid values:

*   Math: mathematical operation function
*   Aggregate: aggregate function
*   String: string processing function
*   Date: date function
*   Analytic: window function
*   Other: other functions', example='MATH'),
      }
    ](name='Functions', description='The UDFs.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='294'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='89FB2BF0-EB00-5D03-9C34-05931001XXXX'),
}

model ListFunctionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListFunctionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListFunctions  ListFunctionsRequest
  * @return ListFunctionsResponse
 */
async function listFunctions(request: ListFunctionsRequest): ListFunctionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListFunctions', 'GET', '/', 'json', false, 'json', request);
}

model ListLineageRelationshipsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dstEntityId: string(name='DstEntityId', description='The destination entity ID. For more information, see the table ID or field ID in the response returned by the ListTables or ListColumns operation. You can also specify a custom entity ID.

This parameter is required.', example='maxcompute-table:123456XXX::test_project::test_tbl
dlf-table:123456XXX:test_catalog:test_db::test_tbl
hms-table:c-abc123xxx::test_db::test_tbl
holo-table:h-abc123xxx::test_db:test_schema:test_tbl
custom-api:api123
custom-table:table456', position='Query'),
  dstEntityName?: string(name='DstEntityName', example='dstName', position='Query'),
  order?: string(name='Order', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', example='10', minimum=1, maximum=100, position='Query'),
  sortBy?: string(name='SortBy', example='Name', position='Query'),
  srcEntityId: string(name='SrcEntityId', description='The source entity ID. For more information, see the table ID or field ID in the response returned by the ListTables or ListColumns operation. You can also specify a custom entity ID.

This parameter is required.', example='maxcompute-table:123456XXX::test_project::test_tbl
dlf-table:123456XXX:test_catalog:test_db::test_tbl
hms-table:c-abc123xxx::test_db::test_tbl
holo-table:h-abc123xxx::test_db:test_schema:test_tbl
custom-api:api123
custom-table:table456', position='Query'),
  srcEntityName?: string(name='SrcEntityName', example='srcName', position='Query'),
}

model ListLineageRelationshipsResponseBody = {
  pagingInfo?: {
    lineageRelationships?: [
      LineageRelationship
    ](name='LineageRelationships'),
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    totalCount?: long(name='TotalCount', example='123'),
  }(name='PagingInfo'),
  requestId?: string(name='RequestId', example='SDFSDFSDF-SDFSDF-SDFDSF-SDFSDF'),
  success?: boolean(name='Success', example='true'),
}

model ListLineageRelationshipsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLineageRelationshipsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLineageRelationships  ListLineageRelationshipsRequest
  * @return ListLineageRelationshipsResponse
 */
async function listLineageRelationships(request: ListLineageRelationshipsRequest): ListLineageRelationshipsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLineageRelationships', 'GET', '/', 'json', false, 'json', request);
}

model ListLineagesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dstEntityId?: string(name='DstEntityId', description='The destination entity ID. For more information, see the table ID or field ID in the response returned by the ListTables or ListColumns operation. You can also specify a custom entity ID.', example='maxcompute-table:123456XXX::test_project::test_tbl
dlf-table:123456XXX:test_catalog:test_db::test_tbl
hms-table:c-abc123xxx::test_db::test_tbl
holo-table:h-abc123xxx::test_db:test_schema:test_tbl
custom-api:api123
custom-table:table456', position='Query'),
  dstEntityName?: string(name='DstEntityName', example='dstName1', position='Query'),
  needAttachRelationship?: boolean(name='NeedAttachRelationship', example='false', position='Query'),
  order?: string(name='Order', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', example='10', minimum=1, maximum=100, position='Query'),
  sortBy?: string(name='SortBy', example='Name', position='Query'),
  srcEntityId?: string(name='SrcEntityId', description='The source entity ID. For more information, see the table ID or field ID in the response returned by the ListTables or ListColumns operation. You can also specify a custom entity ID.', example='maxcompute-table:123456XXX::test_project::test_tbl
dlf-table:123456XXX:test_catalog:test_db::test_tbl
hms-table:c-abc123xxx::test_db::test_tbl
holo-table:h-abc123xxx::test_db:test_schema:test_tbl
custom-api:api123
custom-table:table456', position='Query'),
  srcEntityName?: string(name='SrcEntityName', example='srcName1', position='Query'),
}

model ListLineagesResponseBody = {
  pagingInfo?: {
    lineages?: [ 
      {
        dstEntity?: LineageEntity(name='DstEntity'),
        relationships?: [
          LineageRelationship
        ](name='Relationships'),
        srcEntity?: LineageEntity(name='SrcEntity'),
      }
    ](name='Lineages'),
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    totalCount?: long(name='TotalCount', example='12'),
  }(name='PagingInfo'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model ListLineagesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLineagesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLineages  ListLineagesRequest
  * @return ListLineagesResponse
 */
async function listLineages(request: ListLineagesRequest): ListLineagesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLineages', 'GET', '/', 'json', false, 'json', request);
}

model ListMetaCollectionsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  administrator?: string(name='Administrator', example='12345', position='Query'),
  createUser?: string(name='CreateUser', example='123456', position='Query'),
  description?: string(name='Description', position='Query'),
  name?: string(name='Name', example='test', position='Query'),
  order?: string(name='Order', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', example='1', position='Query'),
  pageSize?: int32(name='PageSize', example='10', position='Query'),
  parentId?: string(name='ParentId', description='The ID of the collection of an ancestor node.', example='category.123', position='Query'),
  sortBy?: string(name='SortBy', example='Name', position='Query'),
  type: string(name='Type', description='The type of the collection. Valid values:

*   Category
*   Album
*   AlbumCategory

This parameter is required.', example='Category', position='Query'),
}

model ListMetaCollectionsResponseBody = {
  data?: {
    metaCollections?: [ 
      {
        administrators?: [ string ](name='Administrators'),
        createTime?: long(name='CreateTime', description='The time when the collection was created. The value is a UNIX timestamp. Unit: milliseconds.', example='1668568601000'),
        createUser?: string(name='CreateUser', example='456789'),
        description?: string(name='Description'),
        id?: string(name='Id', description='The ID of the collection.', example='category.123'),
        modifyTime?: long(name='ModifyTime', description='The time when the collection was modified. The value is a UNIX timestamp. Unit: milliseconds.', example='1668568601000'),
        name?: string(name='Name', example='test_category'),
        parentId?: string(name='ParentId', description='The ID of the collection of the ancestor node. This parameter can be left empty.', example='category.1'),
        type?: string(name='Type', example='Category'),
      }
    ](name='MetaCollections', description='The collections.'),
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    totalCount?: int32(name='TotalCount', example='10'),
  }(name='Data', description='The data.'),
  requestId?: string(name='RequestId', description='Id of the request', example='E25887B7-579C-54A5-9C4F-83A0DE367DDE'),
}

model ListMetaCollectionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMetaCollectionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListMetaCollections  ListMetaCollectionsRequest
  * @return ListMetaCollectionsResponse
 */
async function listMetaCollections(request: ListMetaCollectionsRequest): ListMetaCollectionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMetaCollections', 'GET', '/', 'json', false, 'json', request);
}

model ListNetworksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10', position='Query'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Query'),
  sortBy?: string(name='SortBy', description='The fields used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   Id (Desc/Asc): the network ID
*   Status (Desc/Asc): the network status
*   CreateUser (Desc/Asc): the user who created the network
*   CreateTime (Desc/Asc): the time when the network was created

Default value: CreateTime Asc.', example='CreateTime Asc', position='Query'),
}

model ListNetworksResponseBody = {
  pagingInfo?: {
    networkList?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the network resource was created. The value is a 64-bit timestamp.', example='1727055811000'),
        createUser?: string(name='CreateUser', description='The ID of the user who creates the network resource.', example='11075500042XXXXX'),
        id?: long(name='Id', description='The network ID.', example='1000'),
        resourceGroupId?: string(name='ResourceGroupId', description='The ID of the serverless resource group.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
        securityGroupId?: string(name='SecurityGroupId', description='The security group ID.', example='sg-2ze13vamugr7jenXXXXX'),
        status?: string(name='Status', description='The status of the network resource. Valid values: Pending, Creating, Running, Deleting, and Deleted.', example='Running'),
        vpcId?: string(name='VpcId', description='The ID of the virtual private cloud (VPC).', example='vpc-m2et4f3oc8msfbccXXXXX'),
        vswitchId?: string(name='VswitchId', description='The VSwitch ID.', example='vsw-uf8usrhs7hjd9amsXXXXX'),
      }
    ](name='NetworkList', description='The network resources of the serverless resource group.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListNetworksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListNetworksResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListNetworks  ListNetworksRequest
  * @return ListNetworksResponse
 */
async function listNetworks(request: ListNetworksRequest): ListNetworksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListNetworks', 'GET', '/', 'json', false, 'json', request);
}

model ListNodeDependenciesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10001', position='Query'),
}

model ListNodeDependenciesResponseBody = {
  pagingInfo?: {
    nodes?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the node was created. This value is a UNIX timestamp.', example='1724505917000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='odps_first'),
          type?: string(name='Type', description='The type of the data source.', example='odps'),
        }(name='DataSource', description='The information about the data source.'),
        description?: string(name='Description', description='The description of the node.', example='Node description'),
        id?: long(name='Id', description='The ID of the node.', example='723932906364267XXXX'),
        inputs?: {
          nodeOutputs?: [ 
            {
              data?: string(name='Data', description='The node output.', example='860438872620113XXXX'),
            }
          ](name='NodeOutputs', description='The node outputs.'),
          tables?: [ 
            {
              guid?: string(name='Guid', description='The table ID.', example='odps.autotest.test_output_table_1'),
            }
          ](name='Tables', description='The tables.'),
          variables?: [ 
            {
              artifactType?: string(name='ArtifactType', description='The artifact type.', example='Variable'),
              id?: long(name='Id', description='The variable ID.', example='543218872620113XXXX'),
              name?: string(name='Name', description='The name of the variable.', example='input'),
              node?: {
                output?: string(name='Output', description='The output of the node.', example='860438872620113XXXX'),
              }(name='Node', description='The node to which the variable belongs.'),
              scope?: string(name='Scope', description='The scope of the variable. Valid values:

*   NodeParameter
*   NodeContext
*   Workflow
*   Workspace', example='NodeParameter'),
              type?: string(name='Type', description='The type of the variable. Valid values:

*   NoKvVariableExpression
*   Constant
*   PassThrough
*   System
*   NodeOutput', example='Constant'),
              value?: string(name='Value', description='The value of the variable.', example='111'),
            }
          ](name='Variables', description='The variables.'),
        }(name='Inputs', description='The input of the node.'),
        modifyTime?: long(name='ModifyTime', description='The time when the node was last modified. This value is a UNIX timestamp.', example='1724505917000'),
        name?: string(name='Name', description='The name of the node.', example='Node name'),
        outputs?: {
          nodeOutputs?: [ 
            {
              data?: string(name='Data', description='The node output.', example='463497880880954XXXX'),
            }
          ](name='NodeOutputs', description='The node outputs.'),
          tables?: [ 
            {
              guid?: string(name='Guid', description='The table ID.', example='odps.autotest.test_output_table_1'),
            }
          ](name='Tables', description='The tables.'),
          variables?: [ 
            {
              artifactType?: string(name='ArtifactType', description='The artifact type.', example='Variable'),
              id?: long(name='Id', description='The variable ID.', example='543217824470354XXXX'),
              name?: string(name='Name', description='The name of the variable.', example='output'),
              node?: {
                output?: string(name='Output', description='The output of the node to which the variable belongs.', example='463497880880954XXXX'),
              }(name='Node', description='The node to which the variable belongs.'),
              scope?: string(name='Scope', description='The scope of the variable. Valid values:

*   NodeParameter
*   NodeContext
*   Workflow
*   Workspace', example='NodeParameter'),
              type?: string(name='Type', description='The type of the variable. Valid values:

*   NoKvVariableExpression
*   Constant
*   PassThrough
*   System
*   NodeOutput', example='Constant'),
              value?: string(name='Value', description='The value of the variable.', example='111'),
            }
          ](name='Variables', description='The variables.'),
        }(name='Outputs', description='The output of the node.'),
        owner?: string(name='Owner', description='The owner of the node.', example='110755000425XXXX'),
        projectId?: long(name='ProjectId', description='The ID of the workspace to which the node belongs.', example='65133'),
        recurrence?: string(name='Recurrence', description='The scheduling type.

Valid values:

*   Normal: Nodes are scheduled as expected.
*   Pause: Nodes are paused, and the running of their descendant nodes is blocked.
*   Skip: Nodes are dry run. The system does not actually run the nodes but directly prompts that the nodes are successfully run. The running duration of the nodes is 0 seconds. In addition, the nodes do not occupy resources or block the running of their descendant nodes.', example='Normal'),
        runtimeResource?: {
          resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='S_res_group_XXXX_XXXX'),
        }(name='RuntimeResource', description='The information about the resource group.'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='853573334108680XXXX'),
          path?: string(name='Path', description='The script path.', example='root/demo'),
          runtime?: {
            command?: string(name='Command', description='The command used to distinguish node types.', example='ODPS_SQL'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information.'),
        strategy?: {
          instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval after a failure. Unit: milliseconds.', example='180000'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   Allowed
*   Denied
*   FailureAllowed', example='Allowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of reruns after a failure.', example='3'),
          timeout?: int32(name='Timeout', description='The timeout period. Unit: milliseconds.', example='0'),
        }(name='Strategy', description='The scheduling policy.'),
        tags?: [ 
          {
            key?: string(name='Key', description='The tag key.', example='null'),
            value?: string(name='Value', description='The tag value.', example='null'),
          }
        ](name='Tags', description='The tags. This parameter is not in use.'),
        taskId?: long(name='TaskId', description='The scheduling task ID.', example='580667964888595XXXX'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression for scheduling.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the validity period of the scheduling. The time is in the yyyy-MM-dd HH:mm:ss format.', example='9999-01-01 00:00:00'),
          id?: long(name='Id', description='The trigger ID.', example='543680677872062XXXX'),
          startTime?: string(name='StartTime', description='The start time of the validity period of the scheduling. The time is in the yyyy-MM-dd HH:mm:ss format.', example='1970-01-01 00:00:00'),
          timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
          type?: string(name='Type', description='The type of the trigger.

Valid values:

*   Scheduler
*   Manual
*   Streaming', example='Scheduler'),
        }(name='Trigger', description='The trigger.'),
      }
    ](name='Nodes', description='The descendant nodes.'),
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='90'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='204EAF68-CCE3-5112-8DA0-E7A60F02XXXX'),
}

model ListNodeDependenciesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListNodeDependenciesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListNodeDependencies  ListNodeDependenciesRequest
  * @return ListNodeDependenciesResponse
 */
async function listNodeDependencies(request: ListNodeDependenciesRequest): ListNodeDependenciesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListNodeDependencies', 'GET', '/', 'json', false, 'json', request);
}

model ListNodesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  containerId?: long(name='ContainerId', description='The container ID, which is a filter condition. If you do not want to use this condition for filtering, you do not need to configure this parameter. The container ID that you specify is unrelated to the resource group ID indicated by the ResourceGroupId parameter.', example='860438872620113XXXX', position='Query'),
  name?: string(name='Name', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='12345', position='Query'),
  recurrence?: string(name='Recurrence', description='The scheduling type, which is a filter condition. Valid values:

*   Normal: The nodes are scheduled as expected.
*   Pause: The nodes are paused, and the running of their descendant nodes is blocked.
*   Skip: The nodes are dry run. The system does not actually run the nodes, but directly returns a success response. The running duration of the nodes is 0 seconds. In addition, the nodes do not occupy resources or block the running of their descendant nodes.', example='Normal', position='Query'),
  rerunMode?: string(name='RerunMode', description='The rerun property, which is a filter condition. If you do not want to use this condition for filtering, you do not need to configure this parameter. Valid values:

*   Allowed: The nodes can be rerun regardless of whether they are successfully run or fail to run.
*   FailureAllowed: The nodes can be rerun only after they fail to run.
*   Denied: The nodes cannot be rerun regardless of whether they are successfully run or fail to run.', example='Allowed', position='Query'),
  scene?: string(name='Scene', description='The location of the nodes in the left-side navigation pane of the Data Studio page, which is a filter condition. If you do not want to use this condition for filtering, you do not need to configure this parameter. Valid values:

*   DataworksProject
*   DataworksManualWorkflow
*   DataworksManualTask', example='DATAWORKS_PROJECT', position='Query'),
}

model ListNodesResponseBody = {
  pagingInfo?: {
    nodes?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the node was created. This value is a UNIX timestamp.', example='1722910655000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='odps_first'),
          type?: string(name='Type', description='The type of the data source.', example='odps'),
        }(name='DataSource', description='The information about the data source.'),
        description?: string(name='Description', description='The description of the node.', example='Node description'),
        id?: long(name='Id', description='The ID of the node.', example='860438872620113XXXX'),
        inputs?: {
          nodeOutputs?: [ 
            {
              data?: string(name='Data', description='The node output.', example='623731286945488XXXX'),
            }
          ](name='NodeOutputs', description='The node outputs.'),
          tables?: [ 
            {
              guid?: string(name='Guid', description='The table ID.', example='odps.autotest.test_output_table_1'),
            }
          ](name='Tables', description='The tables.'),
          variables?: [ 
            {
              artifactType?: string(name='ArtifactType', description='The artifact type.', example='Variable'),
              id?: long(name='Id', description='The variable ID.', example='543211286945488XXXX'),
              name?: string(name='Name', description='The name of the variable.', example='input'),
              node?: {
                output?: string(name='Output', description='The output of the node.', example='623731286945488XXXX'),
              }(name='Node', description='The node to which the variable belongs.'),
              scope?: string(name='Scope', description='The scope of the variable. Valid values:

*   WorkSpace
*   NodeParameter
*   NodeContext
*   Workflow', example='NodeParameter'),
              type?: string(name='Type', description='The type of the variable. Valid values:

*   NoKvVariableExpression
*   Constant
*   PassThrough
*   System
*   NodeOutput', example='Constant'),
              value?: string(name='Value', description='The value of the variable.', example='222'),
            }
          ](name='Variables', description='The variables.'),
        }(name='Inputs', description='The input of the node.'),
        modifyTime?: long(name='ModifyTime', description='The time when the node was last modified. This value is a UNIX timestamp.', example='1722910655000'),
        name?: string(name='Name', description='The name of the node.', example='test'),
        outputs?: {
          nodeOutputs?: [ 
            {
              data?: string(name='Data', description='The node output.', example='860438872620113XXXX'),
            }
          ](name='NodeOutputs', description='The node outputs.'),
          tables?: [ 
            {
              guid?: string(name='Guid', description='The table ID.', example='odps.autotest.test_output_table_1'),
            }
          ](name='Tables', description='The tables.'),
          variables?: [ 
            {
              artifactType?: string(name='ArtifactType', description='The artifact type.', example='Variable'),
              id?: long(name='Id', description='The variable ID.', example='623731286945488XXXX'),
              name?: string(name='Name', description='The name of the variable.', example='output'),
              node?: {
                output?: string(name='Output', description='The output of the node.', example='860438872620113XXXX'),
              }(name='Node', description='The node to which the variable belongs.'),
              scope?: string(name='Scope', description='The scope of the variable. Valid values:

*   NodeParameter
*   NodeContext
*   Workflow
*   Workspace', example='NodeParameter'),
              type?: string(name='Type', description='The type of the variable. Valid values:

*   NoKvVariableExpression
*   Constant
*   PassThrough
*   System
*   NodeOutput', example='Constant'),
              value?: string(name='Value', description='The value of the variable.', example='111'),
            }
          ](name='Variables', description='The variables.'),
        }(name='Outputs', description='The output of the node.'),
        owner?: string(name='Owner', description='The owner of the node.', example='110755000425XXXX'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.', example='33233'),
        recurrence?: string(name='Recurrence', description='The scheduling type.

Valid values:

*   Normal: The node is scheduled as expected.
*   Pause: The node is paused, and the running of its descendant nodes is blocked.
*   Skip: The node is dry run. The system does not actually run the node but directly prompts that the node is successfully run. The running duration of the node is 0 seconds. In addition, the node does not occupy resources or block the running of its descendant nodes.', example='Normal'),
        runtimeResource?: {
          resourceGroup?: string(name='ResourceGroup'),
          resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='S_resgrop_xxx'),
        }(name='RuntimeResource', description='The information about the resource group.'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='853573334108680XXXX'),
          path?: string(name='Path', description='The script path.', example='root/demo'),
          runtime?: {
            command?: string(name='Command', description='The command used to distinguish node types.', example='ODPS_SQL'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information.'),
        strategy?: {
          instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: milliseconds.', example='180000'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   Allowed
*   Denied
*   FailureAllowed', example='Allowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of reruns.', example='3'),
          timeout?: int32(name='Timeout', description='The timeout period.', example='0'),
        }(name='Strategy', description='The scheduling policy.'),
        tags?: [ 
          {
            key?: string(name='Key', description='The tag key.', example='null'),
            value?: string(name='Value', description='The tag value', example='null'),
          }
        ](name='Tags', description='The tags. This parameter is not in use.'),
        taskId?: long(name='TaskId', description='The scheduling task ID.', example='88888888888'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression for scheduling.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the validity period of the trigger.', example='9999-01-01 00:00:00'),
          id?: long(name='Id', description='The trigger ID.', example='543680677872062XXXX'),
          startTime?: string(name='StartTime', description='The start time of the validity period of the trigger.', example='1970-01-01 00:00:00'),
          timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
          type?: string(name='Type', description='The type of the trigger.

Valid values:

*   Scheduler
*   Manual
*   Steaming', example='Scheduler'),
        }(name='Trigger', description='The trigger.'),
      }
    ](name='Nodes', description='The nodes.'),
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='42'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='2197B9C4-39CE-55EA-8EEA-FDBAE52DXXXX'),
}

model ListNodesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListNodesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListNodes  ListNodesRequest
  * @return ListNodesResponse
 */
async function listNodes(request: ListNodesRequest): ListNodesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListNodes', 'GET', '/', 'json', false, 'json', request);
}

model ListPartitionsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  name?: string(name='Name', example='ds=20250101', position='Query'),
  order?: string(name='Order', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', example='10', minimum=1, maximum=100, position='Query'),
  sortBy?: string(name='SortBy', example='CreateTime', position='Query'),
  tableId: string(name='TableId', description='The ID of the table to which the partitions belong. You can call the ListTables operation to query the ID. For more information, see [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

This parameter is required.', example='maxcompute-column:11075xxxx::test_project:test_schema:test_table', position='Query'),
}

model ListPartitionsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    partitionList?: [
      Partition
    ](name='PartitionList'),
    totalCount?: long(name='TotalCount', example='1'),
  }(name='PagingInfo'),
  requestId?: string(name='RequestId', example='D1E2E5BC-xxxx-xxxx-xxxx-xxxxxx'),
  success?: boolean(name='Success', example='true'),
}

model ListPartitionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPartitionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListPartitions  ListPartitionsRequest
  * @return ListPartitionsResponse
 */
async function listPartitions(request: ListPartitionsRequest): ListPartitionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListPartitions', 'GET', '/', 'json', false, 'json', request);
}

model ListPipelineRunItemsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  pageNumber?: int32(name='PageNumber', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', example='10', minimum=10, maximum=100, position='Query'),
  pipelineRunId: string(name='PipelineRunId', description='This parameter is required.', example='097c73fe-ed6e-4fb1-b109-a5d59e46cd58', position='Query'),
  projectId: long(name='ProjectId', description='This parameter is required.', example='10001', position='Query'),
}

model ListPipelineRunItemsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    pipelineRunItems?: [ 
      {
        createTime?: long(name='CreateTime', description='发布包创建时间戳', example='1724984066000'),
        id?: long(name='Id', example='860438872620113XXXX'),
        message?: string(name='Message', description='创建人', example='Error Message'),
        modifyTime?: long(name='ModifyTime', description='修改时间', example='1724984066000'),
        name?: string(name='Name', example='test'),
        spec?: string(name='Spec', example='{ "version": "1.1.0", "kind": "Node", "spec": { "nodes": [ { "recurrence": "Normal", "id": "860438872620113XXXX", "timeout": 0, "instanceMode": "T+1", "rerunMode": "Allowed", "rerunTimes": 3, "rerunInterval": 180000, "datasource": { "name": "odps_test", "type": "odps" }, "script": { "language": "odps-sql", "path": "XX/OpenAPI_Test/ODPS_SQL_Test", "runtime": { "command": "ODPS_SQL", "commandTypeId": 10 }, "content": "select now();", "id": "853573334108680XXXX" }, "trigger": { "type": "Scheduler", "id": "543680677872062XXXX", "cron": "00 00 00 * * ?", "startTime": "1970-01-01 00:00:00", "endTime": "9999-01-01 00:00:00", "timezone": "Asia/Shanghai", "delaySeconds": 0 }, "runtimeResource": { "resourceGroup": "S_res_group_XXXX_XXXX", "id": "623731286945488XXXX", "resourceGroupId": "7201XXXX" }, "name": "ODPS_SQL_Test", "owner": "110755000425XXXX", "metadata": { "owner": "110755000425XXXX", "ownerName": "XXXXX@test.XXX.com", "projectId": "307XXX" }, "inputs": { "nodeOutputs": [ { "data": "lwttest_standard_root", "artifactType": "NodeOutput" } ] }, "outputs": { "nodeOutputs": [ { "data": "860438872620113XXXX", "artifactType": "NodeOutput", "refTableName": "ODPS_SQL_Test", "isDefault": true } ] } } ], "flow": [ { "nodeId": "860438872620113XXXX", "depends": [ { "type": "Normal", "output": "lwttest_standard_root" } ] } ] }, "metadata": { "uuid": "860438872620113XXXX" } }'),
        status?: string(name='Status', description='发布流程状态', example='Running'),
        type?: string(name='Type', example='Node'),
        version?: long(name='Version', description='项目Id', example='1'),
      }
    ](name='PipelineRunItems'),
    totalCount?: int32(name='TotalCount', example='12'),
  }(name='PagingInfo'),
  requestId?: string(name='RequestId', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADE490'),
}

model ListPipelineRunItemsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPipelineRunItemsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListPipelineRunItems  ListPipelineRunItemsRequest
  * @return ListPipelineRunItemsResponse
 */
async function listPipelineRunItems(request: ListPipelineRunItemsRequest): ListPipelineRunItemsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListPipelineRunItems', 'GET', '/', 'json', false, 'json', request);
}

model ListPipelineRunsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  creator?: string(name='Creator', description='The ID of the user who creates the processes. This parameter specifies a filter condition.', example='110755000425****', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Query'),
  status?: string(name='Status', description='The status of the processes. This parameter specifies a filter condition.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='Running', position='Query'),
}

model ListPipelineRunsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    pipelineRuns?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the process was created. This value is a UNIX timestamp.', example='1702736654000'),
        creator?: string(name='Creator', description='The creator of the process.', example='110755000425XXXX'),
        id?: string(name='Id', description='The process ID.', example='097c73fe-ed6e-4fb1-b109-a5d59e46cd58'),
        message?: string(name='Message', description='The error message returned during the stage.', example='Error message'),
        modifyTime?: long(name='ModifyTime', description='The time when the process was modified. This value is a UNIX timestamp.', example='1702736654000'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='70199'),
        stages?: [ 
          {
            code?: string(name='Code', description='The code of the stage.', example='DEV_CHECK'),
            description?: string(name='Description', description='The description of the stage.', example='Check before going online to development'),
            detail?: map[string]any(name='Detail', description='The additional information about the stage.'),
            message?: string(name='Message', description='The error message returned during the stage.', example='Error message'),
            name?: string(name='Name', description='The name of the stage.', example='Check before going online to development'),
            status?: string(name='Status', description='The status of the stage.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='Running'),
            step?: int32(name='Step', description='The step number of the stage.', example='1'),
            type?: string(name='Type', description='The type of the stage. This parameter indicates the operation type in the stage.

Valid values:

*   Deploy
*   Check
*   Offline
*   Build
*   Delete', example='Check'),
          }
        ](name='Stages', description='The stages of the process.'),
        status?: string(name='Status', description='The status of the process.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='Running'),
      }
    ](name='PipelineRuns', description='The processes.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='2524'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7C352CB7-CD88-50CF-9D0D-E81BDF02XXXX'),
}

model ListPipelineRunsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPipelineRunsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListPipelineRuns  ListPipelineRunsRequest
  * @return ListPipelineRunsResponse
 */
async function listPipelineRuns(request: ListPipelineRunsRequest): ListPipelineRunsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListPipelineRuns', 'GET', '/', 'json', false, 'json', request);
}

model ListProjectMembersRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='62136', position='Body'),
  roleCodes?: [ string ](name='RoleCodes', description='The codes of the roles in the workspace. You can call the [ListProjectRoles](https://help.aliyun.com/document_detail/2853930.html) operation to query the codes of all roles in the workspace.', shrink='json', position='Body'),
  userIds?: [ string ](name='UserIds', description='The IDs of the accounts used by the members in the workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the Tenant Members and Roles page, view the IDs of the accounts used by the members in the workspace.', shrink='json', position='Body'),
}

model ListProjectMembersResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    projectMembers?: [ 
      {
        projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace.', example='62136'),
        roles?: [ 
          {
            code?: string(name='Code', description='The code of the role.', example='role_project_guest'),
            name?: string(name='Name', description='The name of the role.', example='Visitors'),
            type?: string(name='Type', description='The type of the role. Valid values:

*   UserCustom: user-defined role
*   System: system role', example='System'),
          }
        ](name='Roles', description='The roles that are assigned to the member.'),
        status?: string(name='Status', description='The status of the member. Valid values:

*   Normal
*   Forbidden', example='Normal'),
        userId?: string(name='UserId', description='The ID of the account used by the member.', example='123422344899'),
      }
    ](name='ProjectMembers', description='The members in the workspace.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='12'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='9FBBBB1F-DD5E-5D8E-8F50-37F77460F056'),
}

model ListProjectMembersResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListProjectMembersResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListProjectMembers  ListProjectMembersRequest
  * @return ListProjectMembersResponse
 */
async function listProjectMembers(request: ListProjectMembersRequest): ListProjectMembersResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListProjectMembers', 'POST', '/', 'json', true, 'form', request);
}

model ListProjectRolesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  codes?: [ string ](name='Codes', description='The codes of roles in the DataWorks workspace.', shrink='json', position='Body'),
  names?: [ string ](name='Names', description='The names of roles in the DataWorks workspace.', shrink='json', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='21229', position='Body'),
  type?: string(name='Type', description='The type of the role. Valid values:

*   UserCustom: user-defined role
*   System: system role', example='System', position='Body'),
}

model ListProjectRolesResponseBody = {
  pagingInfo?: {
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    projectRoles?: [ 
      {
        code?: string(name='Code', description='The code of the role in the DataWorks workspace.', example='role_project_guest'),
        name?: string(name='Name', description='The name of the role.', example='Visitors'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='21229'),
        type?: string(name='Type', description='The type of the role in the DataWorks workspace.', example='System'),
      }
    ](name='ProjectRoles', description='The roles in the DataWorks workspace.'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='42'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='61649187-0BCF-5E75-8D4B-64FDBEBBB447'),
}

model ListProjectRolesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListProjectRolesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListProjectRoles  ListProjectRolesRequest
  * @return ListProjectRolesResponse
 */
async function listProjectRoles(request: ListProjectRolesRequest): ListProjectRolesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListProjectRoles', 'POST', '/', 'json', true, 'form', request);
}

model ListProjectsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group to which the workspaces belong. You can log on to the [Resource Management console](https://resourcemanager.console.aliyun.com/resource-groups) and go to the Resource Group page to query the ID.

This parameter is used to query the information about workspaces that belong to a specific resource group.', example='rg-acfmzbn7pti3zff', position='Body'),
  aliyunResourceTags?: [ 
    {
      key?: string(name='Key', description='The tag key.', example='batch'),
      value?: string(name='Value', description='The tag value.', example='blue'),
    }
  ](name='AliyunResourceTags', description='The tags.', shrink='json', position='Body'),
  devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Specifies whether the development environment is enabled. Valid values:

*   true: The development environment is enabled. In this case, the development environment is isolated from the production environment in a workspace.
*   false: The development environment is disabled. In this case, only the production environment is used in a workspace.', example='true', position='Body'),
  devRoleDisabled?: boolean(name='DevRoleDisabled', description='Specifies whether the Develop role is disabled. Valid values:

*   false (default)
*   true', example='false', position='Body'),
  ids?: [ long ](name='Ids', description='The IDs of the DataWorks workspaces.', shrink='json', position='Body'),
  names?: [ string ](name='Names', description='The names of the DataWorks workspaces.', shrink='json', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Body'),
  paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Specifies whether scheduling of Platform for AI (PAI) tasks is enabled. Valid values:

*   true: Scheduling of PAI tasks is enabled. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: Scheduling of PAI tasks is disabled.', example='true', position='Body'),
  status?: string(name='Status', description='The status of the workspaces. Valid values:

*   Available
*   Initializing
*   InitFailed
*   Forbidden
*   Deleting
*   DeleteFailed
*   Frozen
*   Updating
*   UpdateFailed', example='Available', position='Body'),
}

model ListProjectsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='10'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='1'),
    projects?: [ 
      {
        aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group to which the workspace belongs.', example='rg-acfmzbn7pti3zfa'),
        aliyunResourceTags?: [ 
          {
            key?: string(name='Key', description='The tag key.', example='batch'),
            value?: string(name='Value', description='The tag value.', example='blue'),
          }
        ](name='AliyunResourceTags', description='The tags.'),
        description?: string(name='Description', description='The description of the workspace.', example='Financial analysis group project data development'),
        devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Indicates whether the development environment is enabled. Valid values:

*   true: The development environment is enabled. In this case, the development environment is isolated from the production environment in the workspace.
*   false: The development environment is disabled. In this case, only the production environment is used in the workspace.', example='true'),
        devRoleDisabled?: boolean(name='DevRoleDisabled', description='Indicates whether the Develop role is disabled. Valid values:

*   false (default)
*   true', example='false'),
        displayName?: string(name='DisplayName', description='The display name of the workspace.', example='Sora financial analysis'),
        id?: long(name='Id', description='The workspace ID.', example='123456'),
        name?: string(name='Name', description='The name of the workspace.', example='sora_finance'),
        owner?: string(name='Owner', description='The ID of the Alibaba Cloud account to which the workspace belongs.', example='123532153125'),
        paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Indicates whether scheduling of PAI tasks is enabled. Valid values:

*   true: Scheduling of PAI tasks is enabled. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: Scheduling of PAI tasks is disabled.', example='true'),
        status?: string(name='Status', description='The status of the workspace. Valid values:

*   Available
*   Initializing
*   InitFailed
*   Forbidden
*   Deleting
*   DeleteFailed
*   Frozen
*   Updating
*   UpdateFailed', example='Available'),
      }
    ](name='Projects', description='The workspaces.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='6D24AD9A-652F-59E2-AC1F-05029300F8A4'),
}

model ListProjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListProjectsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListProjects  ListProjectsRequest
  * @return ListProjectsResponse
 */
async function listProjects(request: ListProjectsRequest): ListProjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListProjects', 'POST', '/', 'json', true, 'form', request);
}

model ListResourceGroupsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='Alibaba Cloud Resource Group ID', example='rg-aek2kqofrgXXXXX', position='Query'),
  aliyunResourceTags?: [ 
    {
      key?: string(name='Key', description='Tag Key', example='key'),
      value?: string(name='Value', description='Tag Value', example='value'),
    }
  ](name='AliyunResourceTags', description='Alibaba Cloud tag list', shrink='json', position='Query'),
  name?: string(name='Name', description='The name of a resource group, which is used for fuzzy match.', example='Resource', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100', position='Query'),
  paymentType?: string(name='PaymentType', description='The billing method of resource groups. Valid values:

*   PrePaid
*   PostPaid', example='PrePaid', position='Query'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace.', example='1000', position='Query'),
  resourceGroupTypes?: [ string ](name='ResourceGroupTypes', description='The types of resource groups to query. If you do not configure this parameter, only serverless resource groups are returned by default.', shrink='json', position='Query'),
  sortBy?: string(name='SortBy', description='The fields used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   Id (Desc/Asc): the resource group ID
*   Name (Desc/Asc): the name of the resource group
*   Remark (Desc/Asc): the remarks of the resource group
*   Type (Desc/Asc): the type of the resource group
*   Status (Desc/Asc): the status of the resource group
*   Spec (Desc/Asc): the specifications of the resource group
*   CreateUser (Desc/Asc): the creator of the resource group
*   CreateTime (Desc/Asc): the time when the resource group is created

Default value: CreateTime Asc', example='CreateTime Asc', position='Query'),
  statuses?: [ string ](name='Statuses', description='The statuses of resource groups.', shrink='json', position='Query'),
}

model ListResourceGroupsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100'),
    resourceGroupList?: [ 
      {
        aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='Alibaba Cloud Resource Group ID', example='rg-aek2kqofrgXXXXX'),
        aliyunResourceTags?: [ 
          {
            key?: string(name='Key', description='Tag Key', example='Key'),
            value?: string(name='Value', description='Tag Value', example='Value'),
          }
        ](name='AliyunResourceTags', description='Alibaba Cloud tag list'),
        createTime?: long(name='CreateTime', description='The creation time, which is a 64-bit timestamp.', example='1727055811000'),
        createUser?: string(name='CreateUser', description='The ID of the user who created the resource group.', example='11075500042XXXXX'),
        defaultVpcId?: string(name='DefaultVpcId', description='Default VPC ID bound to a common resource group', example='vpc-m2et4f3oc8msfbccXXXXX'),
        defaultVswicthId?: string(name='DefaultVswicthId', description='The default switch ID bound to the common resource group.', example='vsw-uf8usrhs7hjd9amsXXXXX'),
        id?: string(name='Id', description='Unique identifier of a resource group', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
        name?: string(name='Name', description='The name of the resource group.', example='common_resource_group'),
        orderInstanceId?: string(name='OrderInstanceId', description='The order instance ID of the resource group.', example='c442b330-3b10-4584-959e-736e4edXXXXX'),
        paymentType?: string(name='PaymentType', description='The billing method of the resource group. Valid values: PrePaid and PostPaid. The value PrePaid indicates the subscription billing method, and the value PostPaid indicates the pay-as-you-go billing method.', example='PrePaid'),
        remark?: string(name='Remark', description='Remarks for resource groups', example='Create a common resource group for common tasks'),
        resourceGroupType?: string(name='ResourceGroupType', description='The type of the resource group. Valid values:

*   CommonV2: serverless resource group
*   ExclusiveDataIntegration: exclusive resource group for Data Integration
*   ExclusiveScheduler: exclusive resource group for scheduling
*   ExclusiveDataService: exclusive resource group for DataService Studio', example='CommonV2'),
        spec?: {
          amount?: int32(name='Amount', description='Quantity', example='1'),
          standard?: string(name='Standard', description='Specification details', example='2CU'),
        }(name='Spec', description='Resource Group specifications'),
        status?: string(name='Status', description='The status of the resource group. Valid values:

*   Normal: The resource group is running or in use.
*   Stop: The resource group is expired.
*   Deleted: The resource group is released or destroyed.
*   Creating: The resource group is being created.
*   CreateFailed: The resource group fails to be created.
*   Updating: The resource group is being scaled in or out, or the configurations of the resource group are being changed.
*   UpdateFailed: The resource group fails to be scaled out or upgraded.
*   Deleting: The resource group is being released or destroyed.
*   DeleteFailed: The resource group fails to be released or destroyed.
*   Timeout: The operations that are performed on the resource group time out.
*   Freezed: The resource group is frozen.
*   Starting: The resource group is being started.', example='Normal'),
      }
    ](name='ResourceGroupList', description='The resource groups returned.'),
    totalCount?: int32(name='TotalCount', description='All data entries', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true and false.', example='true'),
}

model ListResourceGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListResourceGroupsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListResourceGroups  ListResourceGroupsRequest
  * @return ListResourceGroupsResponse
 */
async function listResourceGroups(request: ListResourceGroupsRequest): ListResourceGroupsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListResourceGroups', 'GET', '/', 'json', false, 'json', request);
}

model ListResourcesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  name?: string(name='Name', position='Query'),
  owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the workspace administrator. You can log on to the Alibaba Cloud Management Console and view the ID on the Security Settings page.', example='110755000425XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10002', position='Query'),
  type?: string(name='Type', description='The resource type. This parameter specifies a filter condition.

Valid values:

*   Python
*   Jar
*   Archive
*   File', example='python', position='Query'),
}

model ListResourcesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    resources?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the file resource was created. This value is a UNIX timestamp.', example='1724505917000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='odps_first'),
          type?: string(name='Type', description='The type of the data source.', example='odps'),
        }(name='DataSource', description='The information about the data source.'),
        id?: long(name='Id', description='The ID of the file resource.', example='631478864897630XXXX'),
        modifyTime?: long(name='ModifyTime', description='The times when the file resource was last modified. This value is a UNIX timestamp.', example='1724505917000'),
        name?: string(name='Name', description='The name of the file resource.', example='math.py'),
        owner?: string(name='Owner', description='The owner of the file resource.', example='110755000425XXXX'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID.', example='344247'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='123348864897630XXXX'),
          path?: string(name='Path', description='The script path.', example='root/demo'),
          runtime?: {
            command?: string(name='Command', description='The command used to distinguish file resource types.', example='ODPS_PYTHON'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information.'),
        sourcePath?: string(name='SourcePath', description='The path of the source of the file resource. If the SourecType parameter is set to Local, this parameter is left empty.', example='XXX/unknown/ide/1/XXX/20240820200851_963a9da676de44ef8d06a6576a8c4d6a.py'),
        sourceType?: string(name='SourceType', description='The storage type of the source of the file resource.

Valid values:

*   Local
*   Oss', example='local'),
        targetPath?: string(name='TargetPath', description='The storage path of the destination of the file resource.', example='XXX/unknown/ide/1/XXX/20240820200851_963a9da676de44ef8d06a6576a8c4d6a.py'),
        targetType?: string(name='TargetType', description='The storage type of the destination of the file resource.

Valid values:

*   Gateway
*   Oss
*   Hdfs', example='oss'),
        type?: string(name='Type', description='The type of the file resource.

Valid values:

*   Python
*   Jar
*   Archive
*   File', example='jar'),
      }
    ](name='Resources', description='The queried file resources.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='131'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='99EBE7CF-69C0-5089-BE3E-79563C31XXXX'),
}

model ListResourcesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListResourcesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListResources  ListResourcesRequest
  * @return ListResourcesResponse
 */
async function listResources(request: ListResourcesRequest): ListResourcesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListResources', 'GET', '/', 'json', false, 'json', request);
}

model ListRoutesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  networkId?: long(name='NetworkId', description='The network ID.', example='1000', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100', position='Query'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Query'),
  sortBy?: string(name='SortBy', description='The fields used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   Id (Desc/Asc): the route ID
*   DestinationCidr (Desc/Asc): the destination CIDR block of the route
*   CreateTime (Desc/Asc): the time when the route is created

Default value: CreateTime Asc.', example='CreateTime Asc', position='Query'),
}

model ListRoutesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100'),
    routeList?: [ 
      {
        createTime?: long(name='CreateTime', description='The creation time, which is a 64-bit timestamp.', example='1727055811000'),
        destinationCidr?: string(name='DestinationCidr', description='Route destination CIDR', example='192.168.0.0/16'),
        id?: long(name='Id', description='Route ID', example='1000'),
        networkId?: long(name='NetworkId', description='Network Resource ID', example='1000'),
        resourceGroupId?: string(name='ResourceGroupId', description='Unique identifier of the resource group to which it belongs', example='Serverless_res_group_524257424564736_6831777003****'),
        resourceId?: string(name='ResourceId', description='Unique identifier of network resource', example='ns-679XXXXXX'),
      }
    ](name='RouteList', description='The list of network resource routing information obtained.'),
    totalCount?: int32(name='TotalCount', description='All data entries', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListRoutesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListRoutesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListRoutes  ListRoutesRequest
  * @return ListRoutesResponse
 */
async function listRoutes(request: ListRoutesRequest): ListRoutesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListRoutes', 'GET', '/', 'json', false, 'json', request);
}

model ListSchemasRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The comment. Fuzzy match is supported.', example='test comment', position='Query'),
  name?: string(name='Name', description='The name. Fuzzy match is supported.', example='abc', position='Query'),
  order?: string(name='Order', description='The order in which schemas are sorted. Default value: Asc. Valid values:

*   Asc: ascending order
*   Desc: descending order', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
  parentMetaEntityId: string(name='ParentMetaEntityId', description='The parent entity ID. For more information, see [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html). For the Hologres metadata crawler type, you can call the ListDatabases operation to query the settings of the `ParentMetaEntityId` parameter.

Configure the `ParentMetaEntityId` parameter in the `${EntityType}:${Instance ID or escaped URL}:${Catalog identifier}:${Database name}` format. If a level does not exist, leave the level empty.

>  If you want to query the information about a MaxCompute schema, specify an empty string at the Instance ID level as a placeholder and a MaxCompute project name at the Database name level. Make sure that the schema feature is enabled for the MaxCompute project.

This parameter is required.', example='maxcompute-project:123456XXX::test_project
holo-database:h-abc123xxx::test_db', position='Query'),
  sortBy?: string(name='SortBy', description='The field used for sorting. Default value: CreateTime. Valid values:

*   CreateTime
*   ModifyTime
*   Name
*   Type', example='CreateTime', position='Query'),
  types?: [ string ](name='Types', description='The types. Exact match is supported. If this parameter is left empty, all types are queried.', shrink='simple', position='Query'),
}

model ListSchemasResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    schemas?: [
      Schema
    ](name='Schemas', description='The schemas.'),
    totalCount?: long(name='TotalCount', example='1'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='235BBA5E-3428-XXXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListSchemasResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSchemasResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSchemas  ListSchemasRequest
  * @return ListSchemasResponse
 */
async function listSchemas(request: ListSchemasRequest): ListSchemasResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSchemas', 'GET', '/', 'json', false, 'json', request);
}

model ListTablesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', example='this is a comment', position='Query'),
  name?: string(name='Name', example='abc', position='Query'),
  order?: string(name='Order', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', example='10', minimum=1, maximum=100, position='Query'),
  parentMetaEntityId: string(name='ParentMetaEntityId', description='The parent metadata entity ID. You can refer to the responses of the ListDatabases or ListSchemas operation and [Description of concepts related to metadata entities.](https://help.aliyun.com/document_detail/2880092.html)

*   The parent metadata entity is a database: The format of `ParentMetaEntityId` is `${EntityType}:${Instance ID or encoded URL}:${Catalog Identifier}:${Database Name}`. Use an empty string (\\`""\\`) as a placeholder for any non-existent level.
*   The parent metadata entity is a database schema:. The format of `ParentMetaEntityId` is `${EntityType}:${Instance ID or encoded URL}:${Catalog Identifier}:${Database Name}:${Schema Name}`. Use an empty string (\\`""\\`) as a placeholder for any non-existent level.

>  The schema level in `ParentMetaEntityId` is supported only for database types that support schemas, such as MaxCompute (with schema enabled), Hologres, PostgreSQL, SQL Server, HybridDB for PostgreSQL, and Oracle.``

>  For MaxCompute and DLF types, use empty strings as the instance ID. For MaxCompute, the database name is the same as the project name.

>  For the StarRocks type, the catalog identifier is the catalog name. For the DLF type, it refers to the catalog ID. Other types do not support a catalog-level hierarchy and the catalog identifier must be replaced with an empty string as a placeholder.

Examples of common ParentMetaEntityId formats

`maxcompute-project:::project_name`

`maxcompute-schema:::project_name:schema_name` (for MaxCompute projects with schema enabled)

`dlf-database::catalog_id:database_name`

`hms-database:instance_id::database_name`

`holo-schema:instance_id::database_name:schema_name`

`mysql-database:(instance_id|encoded_jdbc_url)::database_name`

> \\
`instance_id`: The instance ID, required when the data source is registered in instance mode.\\
`encoded_jdbc_url`: The JDBC connection string that has been URL encoded, required for the data source registered via a connection string.\\
`catalog_id`: The DLF catalog ID.\\
`project_name`: The MaxCompute project name.\\
`database_name`: The database name.\\
`schema_name`: The schema name.

This parameter is required.', example='maxcompute-schema:123456XXX::test_project_with_schema:default
maxcompute-project:123456XXX::test_project_without_schema
dlf-database:123456XXX:test_catalog:test_db
hms-database:c-abc123xxx::test_db
holo-schema:h-abc123xxx::test_db:test_schema
mysql-database:jdbc%3Amysql%3A%2F%2F127.0.0.1%3A3306%2Ftest_db::test_db', position='Query'),
  sortBy?: string(name='SortBy', example='CreateTime', position='Query'),
  tableTypes?: [ string ](name='TableTypes', shrink='simple', position='Query'),
}

model ListTablesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    tables?: [
      Table
    ](name='Tables'),
    totalCount?: long(name='TotalCount', example='100'),
  }(name='PagingInfo'),
  requestId?: string(name='RequestId', example='E25887B7-579C-54A5-9C4F-83A****'),
  success?: boolean(name='Success', example='true'),
}

model ListTablesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTablesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListTables  ListTablesRequest
  * @return ListTablesResponse
 */
async function listTables(request: ListTablesRequest): ListTablesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTables', 'GET', '/', 'json', false, 'json', request);
}

model ListTaskInstanceOperationLogsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  date?: long(name='Date', description='The operation date, accurate to the day. The default value is the current day. You can query only the operation logs generated within the previous 31 days. This value is a UNIX timestamp.', example='1710239005403', position='Query'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
}

model ListTaskInstanceOperationLogsResponseBody = {
  pagingInfo?: {
    operationLogs?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the operation log was generated.', example='1710239005403'),
        operationContent?: string(name='OperationContent', description='The operation content.', example='Freeze tasks'),
        operationSeq?: long(name='OperationSeq', description='The serial number of the operation.', example='1111'),
        taskInstanceId?: long(name='TaskInstanceId', description='The ID of the instance on which the operation was performed.', example='1234'),
        user?: string(name='User', description='The account ID of the operator.', example='1000'),
      }
    ](name='OperationLogs', description='The operation logs.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListTaskInstanceOperationLogsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTaskInstanceOperationLogsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * You can call this operation to query only the operation logs generated within the previous 31 days.
  * @param request  the request parameters of ListTaskInstanceOperationLogs  ListTaskInstanceOperationLogsRequest
  * @return ListTaskInstanceOperationLogsResponse
 */
async function listTaskInstanceOperationLogs(request: ListTaskInstanceOperationLogsRequest): ListTaskInstanceOperationLogsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTaskInstanceOperationLogs', 'GET', '/', 'json', false, 'json', request);
}

model ListTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  bizdate: long(name='Bizdate', description='The data timestamp. The value of this parameter is 00:00:00 of the day before the scheduling time of the instance. The value is a UNIX timestamp. Unit: milliseconds. Example: 1743350400000.

This parameter is required.', example='1710239005403', position='Body'),
  id?: long(name='Id', description='The ID of the instance. The instance may be rerun. If the instance is rerun and you configure this parameter, the system returns the historical information of the instance, including the rerun information. You can use the RunNumber parameter to distinguish each entry in the historical information.', example='1234', position='Body'),
  ids?: [ long ](name='Ids', description='The IDs of the instances. You can query multiple instances at a time by instance ID.', shrink='json', position='Body'),
  owner?: string(name='Owner', description='The account ID of the task owner.', example='1000', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='100', position='Body'),
  runtimeResource?: string(name='RuntimeResource', description='The information about the resource group. Set this parameter to the identifier of a resource group for scheduling.', example='S_res_group_524258031846018_1684XXXXXXXXX', position='Body'),
  sortBy?: string(name='SortBy', description='The field used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   `TriggerTime (Desc/Asc)`

*   `StartedTime (Desc/Asc)`

*   `FinishedTime (Desc/Asc)`

*   `CreateTime (Desc/Asc)`

*   `Id (Desc/Asc)`

    Default value: `Id Desc`.', example='Id Desc', position='Body'),
  status?: string(name='Status', example='Success', position='Body'),
  taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234', position='Body'),
  taskIds?: [ long ](name='TaskIds', description='The IDs of the tasks. You can query multiple instances at a time by task ID.', shrink='json', position='Body'),
  taskName?: string(name='TaskName', description='The name of the task. Fuzzy match is supported.', example='SQL node', position='Body'),
  taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL', position='Body'),
  triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal', position='Body'),
  triggerType?: string(name='TriggerType', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Normal', position='Body'),
  workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234', position='Body'),
  workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234', position='Body'),
  workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   SmokeTest
*   Manual
*   SupplementData
*   ManualWorkflow
*   Normal', example='Normal', position='Body'),
}

model ListTaskInstancesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    taskInstances?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the user who creates the instance.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description.', example='test'),
        finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The instance ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the user who modifies the instance.', example='1000'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
        priority?: int32(name='Priority', description='The priority of the task. Minimum value: 1. Maximum value: 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100'),
        rerunMode?: string(name='RerunMode', description='The rerun mode

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.', example='AllAllowed'),
        runNumber?: int32(name='RunNumber', description='The number of times the task is run. By default, the value starts from 1.', example='1'),
        runtime?: {
          gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
          processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
        }(name='Runtime', description='The runtime information about the instance.'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of CUs configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The information about the resource group with which the instance is associated.'),
        scriptParameters?: string(name='ScriptParameters', example='para1=val1 para2=val2'),
        startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
        status?: string(name='Status', description='The status of the instance.

Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
        taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
        taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
        taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='1'),
        triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
        triggerType?: string(name='TriggerType', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        waitingResourceTime?: long(name='WaitingResourceTime', example='1710239005403'),
        waitingTriggerTime?: long(name='WaitingTriggerTime', example='1710239005403'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
        workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
        workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance.

Valid values:

*   SmokeTest
*   SupplementData
*   Manual
*   ManualWorkflow
*   Normal
*   ManualFlow', example='Normal'),
        workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
      }
    ](name='TaskInstances', description='The list of task instances.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination details.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListTaskInstances  ListTaskInstancesRequest
  * @return ListTaskInstancesResponse
 */
async function listTaskInstances(request: ListTaskInstancesRequest): ListTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model ListTaskOperationLogsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  date?: long(name='Date', description='The operation date, accurate to the day. The default value is the current day. You can query only the operation logs generated within the previous 31 days.', example='1710239005403', position='Query'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model ListTaskOperationLogsResponseBody = {
  pagingInfo?: {
    operationLogs?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the operation log was generated.', example='1710239005403'),
        operationContent?: string(name='OperationContent', description='The operation content.', example='Freeze tasks'),
        operationSeq?: long(name='OperationSeq', description='The serial number of the operation.', example='1111'),
        taskId?: long(name='TaskId', description='The ID of the task on which the operation was performed.', example='1234'),
        user?: string(name='User', description='The account ID of the operator.', example='1000'),
      }
    ](name='OperationLogs', description='The operation logs.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListTaskOperationLogsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTaskOperationLogsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * You can call this operation to query only the operation logs generated within the previous 31 days.
  * @param request  the request parameters of ListTaskOperationLogs  ListTaskOperationLogsRequest
  * @return ListTaskOperationLogsResponse
 */
async function listTaskOperationLogs(request: ListTaskOperationLogsRequest): ListTaskOperationLogsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTaskOperationLogs', 'GET', '/', 'json', false, 'json', request);
}

model ListTasksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  ids?: [ long ](name='Ids', description='The ID of the task.', shrink='json', position='Body'),
  name?: string(name='Name', description='The name of the task. Fuzzy match is supported.', example='SQL node', position='Body'),
  owner?: string(name='Owner', description='The account ID of the task owner.', example='1000', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  projectId: long(name='ProjectId', description='The workspace ID.

This parameter is required.', example='100', position='Body'),
  runtimeResource?: string(name='RuntimeResource', description='The information about the resource group. Set this parameter to the ID of a resource group for scheduling.', example='S_res_group_524258031846018_1684XXXXXXXXX', position='Body'),
  sortBy?: string(name='SortBy', description='The field that is used to sort tasks. This parameter is configured in the format of "Sorting field Sorting order". You can set the sorting order to Desc or Asc. If you do not specify the sorting order, Asc is used by default. Valid values:

*   `ModifyTime (Desc/Asc)`

*   `CreateTime (Desc/Asc)`

*   `Id (Desc/Asc)`

    Default value: `Id Desc`.', example='Id Desc', position='Body'),
  taskType?: string(name='TaskType', description='The type of the task. Valid values:

*   ODPS_SQL
*   SPARK
*   PY_ODPS
*   PY_ODPS3
*   ODPS_SCRIPT
*   ODPS_MR
*   COMPONENT_SQL
*   EMR_HIVE
*   EMR_MR
*   EMR_SPARK_SQL
*   EMR_SPARK
*   EMR_SHELL
*   EMR_PRESTO
*   EMR_IMPALA
*   SPARK_STREAMING
*   EMR_KYUUBI
*   EMR_TRINO
*   HOLOGRES_SQL
*   HOLOGRES_SYNC_DDL
*   HOLOGRES_SYNC_DATA', example='ODPS_SQL', position='Body'),
  triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal', position='Body'),
  triggerType?: string(name='TriggerType', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler', position='Body'),
  workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234', position='Body'),
}

model ListTasksResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    tasks?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description of the task.', example='test'),
        id?: long(name='Id', description='The task ID.', example='1234'),
        instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name of the task.', example='SQL node'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
        rerunMode?: string(name='RerunMode', description='The rerun mode.

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
        rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        scriptParameters?: string(name='ScriptParameters', description='The list of script parameters.', example='para1=$bizdate para2=$[yyyymmdd]'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
          recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
          type?: string(name='Type', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        }(name='Trigger', description='The method to trigger task scheduling.'),
        type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
      }
    ](name='Tasks', description='The tasks.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTasksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListTasks  ListTasksRequest
  * @return ListTasksResponse
 */
async function listTasks(request: ListTasksRequest): ListTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTasks', 'POST', '/', 'json', true, 'form', request);
}

model ListUpstreamTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
}

model ListUpstreamTaskInstancesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    taskInstances?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description.', example='test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The instance ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        periodNumber?: int32(name='PeriodNumber', description='The sequence number of the period. Indicates which cycle of the day the task instance is in.', example='1'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', deprecated='true'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.', example='AllAllowed'),
        runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
        runtime?: {
          gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
          processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
        }(name='Runtime', description='The runtime information about the instance.'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
        status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
        stepType?: string(name='StepType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
        taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
        taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='1'),
        triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
        triggerType?: string(name='TriggerType', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
        workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
        workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   SmokeTest
*   SupplementData
*   Manual
*   ManualWorkflow
*   Normal
*   ManualFlow', example='Normal'),
        workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
      }
    ](name='TaskInstances', description='The instances. This parameter is deprecated and replaced by the UpstreamTaskInstances parameter.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
    upstreamTaskInstances?: [ 
      {
        dependencyType?: string(name='DependencyType', description='The scheduling dependency type. Valid values:

*   Normal
*   CrossCycle', example='Normal'),
        taskInstance?: {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
          bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description.', example='test'),
          envType?: string(name='EnvType', description='The environment in which the data source is used. Valid values:

*   Dev
*   Prod', example='Prod'),
          finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
          id?: long(name='Id', description='The instance ID.', example='1234'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
          priority?: int32(name='Priority', description='The priority of the task. Minimum value: 1. Maximum value: 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunMode?: string(name='RerunMode', description='The rerun mode.', example='AllAllowed'),
          runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
          runtime?: {
            gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
            processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
          }(name='Runtime', description='The runtime information about the instance.'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
          startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
          status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.
*   WaitTrigger: The instance is waiting to be triggered by external scheduling systems.', example='Success'),
          taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
          taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
          taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='3600'),
          triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
          triggerType?: string(name='TriggerType', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
          workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
          workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   Normal
*   Manual
*   SmokeTest
*   SupplementData
*   ManualWorkflow', example='Normal'),
          workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
        }(name='TaskInstance', description='The information about a task instance.'),
      }
    ](name='UpstreamTaskInstances', description='The ancestor instances.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListUpstreamTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListUpstreamTaskInstancesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListUpstreamTaskInstances  ListUpstreamTaskInstancesRequest
  * @return ListUpstreamTaskInstancesResponse
 */
async function listUpstreamTaskInstances(request: ListUpstreamTaskInstancesRequest): ListUpstreamTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListUpstreamTaskInstances', 'GET', '/', 'json', false, 'json', request);
}

model ListUpstreamTasksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model ListUpstreamTasksResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    tasks?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description of the task.', example='test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        id?: long(name='Id', description='The task ID.', example='1234'),
        instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name of the task.', example='SQL node'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter.

Valid values:

*   Prod
*   Dev', example='Prod', deprecated='true'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
        rerunMode?: string(name='RerunMode', description='The rerun mode.

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether it is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
        rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        stepType?: string(name='StepType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
          recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
          timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
          type?: string(name='Type', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        }(name='Trigger', description='The method to trigger task scheduling.'),
        type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
      }
    ](name='Tasks', description='The tasks. This parameter is deprecated and replaced by the UpstreamTasks parameter.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
    upstreamTasks?: [ 
      {
        dependencyType?: string(name='DependencyType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        task?: {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description of the task.', example='test'),
          envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
          id?: long(name='Id', description='The task ID.', example='1234'),
          instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          name?: string(name='Name', description='The name of the task.', example='SQL node'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8.', example='1'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.', example='AllAllowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
          trigger?: {
            cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
            endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
            recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
            startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
            timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
            type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
          }(name='Trigger', description='The trigger method.'),
          type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
        }(name='Task', description='The information about the task.'),
      }
    ](name='UpstreamTasks', description='The ancestor tasks.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListUpstreamTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListUpstreamTasksResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListUpstreamTasks  ListUpstreamTasksRequest
  * @return ListUpstreamTasksResponse
 */
async function listUpstreamTasks(request: ListUpstreamTasksRequest): ListUpstreamTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListUpstreamTasks', 'GET', '/', 'json', false, 'json', request);
}

model ListWorkflowDefinitionsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  name?: string(name='Name', position='Query'),
  owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the workspace administrator. You can log on to the Alibaba Cloud Management Console and view the ID on the Security Settings page.', example='110755000425XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Query'),
  type?: string(name='Type', description='The workflow type. This parameter specifies a filter condition.

Valid values:

*   CycleWorkflow
*   ManualWorkflow', example='CycleWorkflow', position='Query'),
}

model ListWorkflowDefinitionsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='227'),
    workflowDefinitions?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the workflow was created. This value is a UNIX timestamp.', example='1698057323000'),
        description?: string(name='Description', description='The description of the workflow.', example='Workflow description'),
        id?: long(name='Id', description='The ID of the workflow.', example='463497880880954XXXX'),
        modifyTime?: long(name='ModifyTime', description='The time when the workflow was last modified. This value is a UNIX timestamp.', example='1698057323000'),
        name?: string(name='Name', description='The name of the workflow.', example='OpenAPI test workflow Demo'),
        owner?: string(name='Owner', description='The owner.', example='110755000425XXXX'),
        projectId: long(name='ProjectId', description='The ID of the DataWorks workspace to which the workflow belongs.

This parameter is required.', example='4710'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='698002781368644XXXX'),
          path?: string(name='Path', description='The script path.', example='XX/OpenAPI_test/workflow_test/OpenAPI_test_workflow_Demo'),
          runtime?: {
            command?: string(name='Command', description='The command.', example='WORKFLOW'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information.'),
        type?: string(name='Type', description='The type of the workflow.

Valid values:

*   CycleWorkflow
*   ManualWorkflow', example='CycleWorkflow'),
      }
    ](name='WorkflowDefinitions', description='The workflows.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='8C3ED0C5-ABAB-55E1-854B-DAC02B11XXXX'),
}

model ListWorkflowDefinitionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListWorkflowDefinitionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListWorkflowDefinitions  ListWorkflowDefinitionsRequest
  * @return ListWorkflowDefinitionsResponse
 */
async function listWorkflowDefinitions(request: ListWorkflowDefinitionsRequest): ListWorkflowDefinitionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListWorkflowDefinitions', 'GET', '/', 'json', false, 'json', request);
}

model ListWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  bizDate: long(name='BizDate', description='The data timestamp. The value of this parameter is 00:00:00 of the day before the scheduling time of the instance. The value is a UNIX timestamp. Unit: milliseconds. Example: 1743350400000.

This parameter is required.', example='1710239005403', position='Body'),
  ids?: [ long ](name='Ids', description='The IDs of the workflow instances. You can query multiple instances at a time by instance ID.', shrink='json', position='Body'),
  name?: string(name='Name', description='The instance name. Fuzzy match is supported.', example='WorkflowInstance1', position='Body'),
  owner?: string(name='Owner', description='The account ID of the workflow instance owner.', example='1000', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  projectId: long(name='ProjectId', description='The workspace ID.

This parameter is required.', example='100', position='Body'),
  sortBy?: string(name='SortBy', description='The fields used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   TriggerTime (Desc/Asc)
*   StartedTime (Desc/Asc)
*   FinishedTime (Desc/Asc)
*   CreateTime (Desc/Asc)
*   Id (Desc/Asc)

Default value: Id Desc.', example='Id Desc', position='Body'),
  type?: string(name='Type', description='The type of the workflow instance. Valid values:

*   Normal
*   Manual
*   SmokeTest
*   SupplementData
*   ManualWorkflow', example='Normal', position='Body'),
  workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234', position='Body'),
}

model ListWorkflowInstancesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
    workflowInstances?: [ 
      {
        bizDate?: long(name='BizDate', example='1710239005403'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='100'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The workflow instance ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='100'),
        name?: string(name='Name', description='The name of the workflow instance.', example='WorkflowInstance1'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
        status?: string(name='Status', description='The status of the workflow instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
        type?: string(name='Type', example='Normal'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
      }
    ](name='WorkflowInstances', description='The workflow instances.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListWorkflowInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListWorkflowInstances  ListWorkflowInstancesRequest
  * @return ListWorkflowInstancesResponse
 */
async function listWorkflowInstances(request: ListWorkflowInstancesRequest): ListWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model ListWorkflowsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  ids?: [ long ](name='Ids', description='The IDs of the workflows. You can query multiple workflows at a time by workflow ID.', shrink='json', position='Body'),
  name?: string(name='Name', description='The name of the workflow. Fuzzy match is supported.', example='Workflow1', position='Body'),
  owner?: string(name='Owner', description='The account ID of the workflow owner.', example='1000', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  projectId: long(name='ProjectId', description='The workspace ID.

This parameter is required.', example='100', position='Body'),
  sortBy?: string(name='SortBy', description='The field used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   ModifyTime (Desc/Asc)
*   CreateTime (Desc/Asc)
*   Id (Desc/Asc)

Default value: Id Desc.', example='Id Desc', position='Body'),
  triggerType?: string(name='TriggerType', description='The trigger type. Valid values:

*   Scheduler
*   Manual', example='Scheduler', position='Body'),
}

model ListWorkflowsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
    workflows?: [ 
      {
        clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a workflow asynchronously and implement the idempotence of the workflow. If you do not specify this parameter when you create the workflow, the system automatically generates a unique code. The unique code is uniquely associated with the workflow ID. If you specify this parameter when you update or delete the workflow, the value of this parameter must be the unique code that is used to create the workflow.', example='Workflow_0bc5213917368545132902xxxxxxxx'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        description?: string(name='Description', description='The description.', example='test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        id?: long(name='Id', description='The workflow ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name.', example='Workflow1'),
        owner?: string(name='Owner', description='The account ID of the owner.', example='1000'),
        parameters?: string(name='Parameters', description='The parameters.', example='para1=$bizdate para2=$[yyyymmdd]'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
          recurrence?: string(name='Recurrence', description='The running mode of the workflow after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          startTime?: string(name='StartTime', description='The start time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
          type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        }(name='Trigger', description='The trigger method.'),
      }
    ](name='Workflows', description='The workflows.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListWorkflowsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListWorkflowsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListWorkflows  ListWorkflowsRequest
  * @return ListWorkflowsResponse
 */
async function listWorkflows(request: ListWorkflowsRequest): ListWorkflowsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListWorkflows', 'POST', '/', 'json', true, 'form', request);
}

model MoveFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='543217824470354XXXX', position='Body'),
  path: string(name='Path', description='The path to which you want to move the UDF. You do not need to specify a UDF name in the path.

For example, if you want to move the test UDF to root/demo/test, you must set this parameter to root/demo.

This parameter is required.', example='root/demo', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID.

This parameter indicates the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='12345', position='Body'),
}

model MoveFunctionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='48C0E2F0-52BA-5888-BDFA-28F1B9AFXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model MoveFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: MoveFunctionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of MoveFunction  MoveFunctionRequest
  * @return MoveFunctionResponse
 */
async function moveFunction(request: MoveFunctionRequest): MoveFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'MoveFunction', 'POST', '/', 'json', true, 'form', request);
}

model MoveNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  path: string(name='Path', description='The path to which you want to move the node. You do not need to specify a node name in the path.

For example, if you want to move the test node to root/demo/test, you must set this parameter to root/demo.

This parameter is required.', example='root/demo', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You can use this parameter to specify the DataWorks workspace on which you want to perform the API operation.

This parameter is required.', example='10000', position='Body'),
}

model MoveNodeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model MoveNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: MoveNodeResponseBody(name='body'),
}

/**
  * @param request  the request parameters of MoveNode  MoveNodeRequest
  * @return MoveNodeResponse
 */
async function moveNode(request: MoveNodeRequest): MoveNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'MoveNode', 'POST', '/', 'json', true, 'form', request);
}

model MoveResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the file resource.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  path: string(name='Path', description='The path to which you want to move the file resource. You do not need to specify a file resource name in the path.

For example, if you want to move the test file resource to root/demo/test, you must set this parameter to root/demo.

This parameter is required.', example='root/demo', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID.

You can use this parameter to specify the DataWorks workspace on which you want to perform the API operation.

This parameter is required.', example='10000', position='Body'),
}

model MoveResourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='F332BED4-DD73-5972-A9C2-642BA6CFXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model MoveResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: MoveResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of MoveResource  MoveResourceRequest
  * @return MoveResourceResponse
 */
async function moveResource(request: MoveResourceRequest): MoveResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'MoveResource', 'POST', '/', 'json', true, 'form', request);
}

model MoveWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='543217824470354XXXX', position='Body'),
  path: string(name='Path', description='The path to which you want to move the workflow. You do not need to specify a workflow name in the path.

For example, if you want to move the test workflow to root/demo/test, you must set this parameter to root/demo.

This parameter is required.', example='root/demo', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID. This parameter indicates the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10001', position='Body'),
}

model MoveWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='05ADAF4F-7709-5FB1-B606-3513483FXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model MoveWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: MoveWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of MoveWorkflowDefinition  MoveWorkflowDefinitionRequest
  * @return MoveWorkflowDefinitionResponse
 */
async function moveWorkflowDefinition(request: MoveWorkflowDefinitionRequest): MoveWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'MoveWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model RemoveEntityFromMetaCollectionRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: string(name='Id', description='The entity ID. Currently, entities can only be tables. You can call the ListTables operation to query the ID.', example='dlf-table:123456789:test_catalog:test_database::test_table', position='Query'),
  metaCollectionId?: string(name='MetaCollectionId', description='The collection ID. You can call the ListMetaCollections operation to query the ID.', example='category.123', position='Query'),
}

model RemoveEntityFromMetaCollectionResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='6D6CD444-DFA0-5180-9763-4A8730F2B382'),
}

model RemoveEntityFromMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RemoveEntityFromMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RemoveEntityFromMetaCollection  RemoveEntityFromMetaCollectionRequest
  * @return RemoveEntityFromMetaCollectionResponse
 */
async function removeEntityFromMetaCollection(request: RemoveEntityFromMetaCollectionRequest): RemoveEntityFromMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RemoveEntityFromMetaCollection', 'POST', '/', 'json', false, 'json', request);
}

model RemoveTaskInstanceDependenciesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  upstreamTaskInstanceIds?: [ long ](name='UpstreamTaskInstanceIds', description='The IDs of ancestor instances of the instance', shrink='json', position='Body'),
}

model RemoveTaskInstanceDependenciesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model RemoveTaskInstanceDependenciesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RemoveTaskInstanceDependenciesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of RemoveTaskInstanceDependencies  RemoveTaskInstanceDependenciesRequest
  * @return RemoveTaskInstanceDependenciesResponse
 */
async function removeTaskInstanceDependencies(request: RemoveTaskInstanceDependenciesRequest): RemoveTaskInstanceDependenciesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RemoveTaskInstanceDependencies', 'POST', '/', 'json', true, 'form', request);
}

model RenameFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='543217824470354XXXX', position='Body'),
  name: string(name='Name', description='The new name.

This parameter is required.', example='Rename', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10002', position='Body'),
}

model RenameFunctionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1ED4C97F-BA2A-57C5-BA7C-8853627EXXXX'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model RenameFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RenameFunctionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RenameFunction  RenameFunctionRequest
  * @return RenameFunctionResponse
 */
async function renameFunction(request: RenameFunctionRequest): RenameFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameFunction', 'POST', '/', 'json', true, 'form', request);
}

model RenameNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  name: string(name='Name', description='The new name.

This parameter is required.', example='Rename', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='12345', position='Body'),
}

model RenameNodeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4CDF7B72-020B-542A-8465-21CFFA81XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model RenameNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RenameNodeResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RenameNode  RenameNodeRequest
  * @return RenameNodeResponse
 */
async function renameNode(request: RenameNodeRequest): RenameNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameNode', 'POST', '/', 'json', true, 'form', request);
}

model RenameResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the file resource.

This parameter is required.', example='543217824470354XXXX', position='Body'),
  name: string(name='Name', description='The new name.

This parameter is required.', example='Rename', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model RenameResourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4CDF7B72-020B-542A-8465-21CFFA8XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model RenameResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RenameResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RenameResource  RenameResourceRequest
  * @return RenameResourceResponse
 */
async function renameResource(request: RenameResourceRequest): RenameResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameResource', 'POST', '/', 'json', true, 'form', request);
}

model RenameWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='463497880880954XXXX', position='Query'),
  name: string(name='Name', description='The new name.

This parameter is required.', example='Rename', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID. You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Query'),
}

model RenameWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can troubleshoot issues based on the ID.', example='975BD43D-C421-595C-A29C-565A8AD5XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model RenameWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RenameWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RenameWorkflowDefinition  RenameWorkflowDefinitionRequest
  * @return RenameWorkflowDefinitionResponse
 */
async function renameWorkflowDefinition(request: RenameWorkflowDefinitionRequest): RenameWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameWorkflowDefinition', 'POST', '/', 'json', false, 'json', request);
}

model RerunTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model RerunTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model RerunTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RerunTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of RerunTaskInstances  RerunTaskInstancesRequest
  * @return RerunTaskInstancesResponse
 */
async function rerunTaskInstances(request: RerunTaskInstancesRequest): RerunTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RerunTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model RerunWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  bizdate?: long(name='Bizdate', description='The business date used for matching manual workflow instances.', example='1710239005403', position='Body'),
  endTriggerTime?: long(name='EndTriggerTime', description='The end trigger time of the manual workflow instance used for matching. This parameter must be used together with the StartTriggerTime.', example='1710239005403', position='Body'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

Prod Dev', example='Prod', position='Body'),
  filter?: {
    rerunDownstreamEnabled?: boolean(name='RerunDownstreamEnabled', description='Specifies whether to rerun the matched instances and all downstream instances.', example='false'),
    taskIds?: [ long ](name='TaskIds', description='The internal task IDs used for matching manual workflow instances.'),
    taskInstanceStatuses?: [ string ](name='TaskInstanceStatuses', description='The statuses of internal tasks used for matching manual workflow instances.'),
    taskName?: string(name='TaskName', description='The internal task name used for matching the manual workflow instance.', example='test'),
    taskTypes?: [ string ](name='TaskTypes', description='Match internal tasks within the manual workflow by type.'),
  }(name='Filter', description='The match conditions for internal instances of manual workflow instances.', shrink='json', position='Body'),
  ids?: [ long ](name='Ids', description='The instance IDs used for matching manual workflow instances.', shrink='json', position='Body'),
  name?: string(name='Name', description='The manual workflow name, used for fuzzy matching.', example='test', position='Body'),
  projectId: long(name='ProjectId', description='The project ID.

This parameter is required.', example='123', position='Body'),
  startTriggerTime?: long(name='StartTriggerTime', description='The start trigger time (creation time) of the manual workflow instance used for matching. This parameter must be used together with EndTriggerTime.', example='1710239005403', position='Body'),
  status?: string(name='Status', description='The status used for matching manual workflow instances.

Valid values:

*   Success
*   Failure', example='Failure', position='Body'),
  type: string(name='Type', description='The type of the workflow instance. Valid values:

ManualWorkflow.

This parameter is required.', example='ManualWorkflow', position='Body'),
  workflowId: long(name='WorkflowId', description='The workflow ID.

This parameter is required.', example='123', position='Body'),
}

model RerunWorkflowInstancesResponseBody = {
  operationId?: string(name='OperationId', description='The operation ID. You can use this value to query the creation result via the GetRerunWorkflowInstancesResult operation.', example='e15ad21c-b0e9-4792-8f55-b037xxxxxxxx'),
  requestId?: string(name='RequestId', description='The request ID. Used for troubleshooting and log tracking.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model RerunWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RerunWorkflowInstancesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RerunWorkflowInstances  RerunWorkflowInstancesRequest
  * @return RerunWorkflowInstancesResponse
 */
async function rerunWorkflowInstances(request: RerunWorkflowInstancesRequest): RerunWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RerunWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model ResumeTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model ResumeTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model ResumeTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ResumeTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ResumeTaskInstances  ResumeTaskInstancesRequest
  * @return ResumeTaskInstancesResponse
 */
async function resumeTaskInstances(request: ResumeTaskInstancesRequest): ResumeTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ResumeTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model RevokeMemberProjectRolesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to query the ID.

This parameter is required.', example='105149', position='Body'),
  roleCodes: [ string ](name='RoleCodes', description='The codes of the roles in the workspace. You can call the [ListProjectRoles](https://help.aliyun.com/document_detail/2853930.html) operation to query the codes of all roles in the workspace.

You must configure this parameter to specify the roles that you want to revoke from the member in the workspace.

This parameter is required.', shrink='json', position='Body'),
  userId: string(name='UserId', description='The ID of the account used by the member in the workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the Tenant Members and Roles page, view the ID of the account used by the member in the workspace.

This parameter is required.', example='123422344899', position='Body'),
}

model RevokeMemberProjectRolesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='676271D6-53B4-57BE-89FA-72F7AE1418DF'),
}

model RevokeMemberProjectRolesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RevokeMemberProjectRolesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of RevokeMemberProjectRoles  RevokeMemberProjectRolesRequest
  * @return RevokeMemberProjectRolesResponse
 */
async function revokeMemberProjectRoles(request: RevokeMemberProjectRolesRequest): RevokeMemberProjectRolesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RevokeMemberProjectRoles', 'POST', '/', 'json', true, 'form', request);
}

model SetSuccessTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model SetSuccessTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model SetSuccessTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetSuccessTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of SetSuccessTaskInstances  SetSuccessTaskInstancesRequest
  * @return SetSuccessTaskInstancesResponse
 */
async function setSuccessTaskInstances(request: SetSuccessTaskInstancesRequest): SetSuccessTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetSuccessTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model StartDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='10000', deprecated='true', position='Query'),
  forceToRerun?: boolean(name='ForceToRerun', description='Specifies whether to forcefully rerun all synchronization steps. If you do not configure this parameter, the system does not perform the forcible rerun operation.

*   If the system does not perform the forcible rerun operation, only the steps that are not run start to run.
*   If the system performs the forcible rerun operation, all steps start to rerun.', example='false', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='10000', position='Query'),
  realtimeStartSettings?: {
    failoverSettings?: {
      interval?: long(name='Interval', description='This parameter is deprecated. Use advanced parameters for failover settings when you create a task.', example='10', deprecated='true'),
      upperLimit?: long(name='UpperLimit', description='This parameter is deprecated. Use advanced parameters for failover settings when you create a task.', example='30', deprecated='true'),
    }(name='FailoverSettings', description='This parameter is deprecated. Use advanced parameters for failover settings when you create a task.', deprecated='true'),
    startTime?: long(name='StartTime', description='The start time.', example='1671516776'),
  }(name='RealtimeStartSettings', description='The settings for starting real-time synchronization.

    {
      "StartTime":1663765058
    }', shrink='json', position='Query'),
}

model StartDIJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='999431B2-6013-577F-B684-36F7433C753B'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model StartDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StartDIJob  StartDIJobRequest
  * @return StartDIJobResponse
 */
async function startDIJob(request: StartDIJobRequest): StartDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartDIJob', 'GET', '/', 'json', false, 'json', request);
}

model StartWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  ids: [ long ](name='Ids', description='The IDs of workflow instances.

This parameter is required.', shrink='json', position='Body'),
}

model StartWorkflowInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17****'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The workflow instance ID serves as a key, and the result serves as a value.'),
}

model StartWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartWorkflowInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StartWorkflowInstances  StartWorkflowInstancesRequest
  * @return StartWorkflowInstancesResponse
 */
async function startWorkflowInstances(request: StartWorkflowInstancesRequest): StartWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model StopDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated and is replaced by the Id parameter.', example='11668', deprecated='true', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11668', position='Query'),
  instanceId?: long(name='InstanceId', description='The instance ID.', example='1234', position='Query'),
}

model StopDIJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='92F778C7-8F00-53B1-AE1A-B3B17101247D'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model StopDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StopDIJob  StopDIJobRequest
  * @return StopDIJobResponse
 */
async function stopDIJob(request: StopDIJobRequest): StopDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopDIJob', 'GET', '/', 'json', false, 'json', request);
}

model StopTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model StopTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model StopTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StopTaskInstances  StopTaskInstancesRequest
  * @return StopTaskInstancesResponse
 */
async function stopTaskInstances(request: StopTaskInstancesRequest): StopTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model StopWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  ids: [ long ](name='Ids', description='The workflow instance IDs.

This parameter is required.', shrink='json', position='Body'),
}

model StopWorkflowInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17****'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The workflow instance ID serves as a key, and the result serves as a value.'),
}

model StopWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopWorkflowInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StopWorkflowInstances  StopWorkflowInstancesRequest
  * @return StopWorkflowInstancesResponse
 */
async function stopWorkflowInstances(request: StopWorkflowInstancesRequest): StopWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model SubmitFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', example='Submit a task for the first time', position='Body'),
  fileId: long(name='FileId', description='This parameter is required.', example='1000000', position='Body'),
  projectId?: long(name='ProjectId', example='100001', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
  skipAllDeployFileExtensions?: boolean(name='SkipAllDeployFileExtensions', example='false', position='Body'),
}

model SubmitFileResponseBody = {
  data?: long(name='Data', example='3000001'),
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model SubmitFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitFile  SubmitFileRequest
  * @return SubmitFileResponse
 */
async function submitFile(request: SubmitFileRequest): SubmitFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitFile', 'POST', '/', 'json', true, 'form', request);
}

model SuspendTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model SuspendTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model SuspendTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SuspendTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of SuspendTaskInstances  SuspendTaskInstancesRequest
  * @return SuspendTaskInstancesResponse
 */
async function suspendTaskInstances(request: SuspendTaskInstancesRequest): SuspendTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SuspendTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model TagDataAssetsRequest {
  regionId?: string(name='RegionId', position='Host'),
  autoTraceEnabled?: boolean(name='AutoTraceEnabled', description='Specifies whether to enable lineage-based automatic backtracking.', example='false', position='Query'),
  dataAssetIds: [ string ](name='DataAssetIds', description='The data asset IDs.

This parameter is required.', shrink='json', position='Query'),
  dataAssetType: string(name='DataAssetType', description='The type of the data asset. Valid values:

*   ACS::DataWorks::Table
*   ACS::DataWorks::Task

This parameter is required.', example='ACS::DataWorks::Task', position='Query'),
  envType?: string(name='EnvType', description='The environment of the workspace to which the data asset belongs. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10000', position='Query'),
  tags: [ 
    {
      key: string(name='Key', description='The tag key.

This parameter is required.', example='key', minLength=1, maxLength=128),
      value?: string(name='Value', description='The tag value.', example='value', maxLength=128),
    }
  ](name='Tags', description='The tags that you want to add to data assets.

This parameter is required.', shrink='json', position='Query'),
}

model TagDataAssetsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model TagDataAssetsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: TagDataAssetsResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of TagDataAssets  TagDataAssetsRequest
  * @return TagDataAssetsResponse
 */
async function tagDataAssets(request: TagDataAssetsRequest): TagDataAssetsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'TagDataAssets', 'POST', '/', 'json', false, 'json', request);
}

model TestDataSourceConnectivityRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dataSourceId: long(name='DataSourceId', description='The ID of the data source for which you want to test the network connectivity.

This parameter is required.', example='144544', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='10001', position='Query'),
  resourceGroupId: string(name='ResourceGroupId', description='The resource group ID.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Query'),
}

model TestDataSourceConnectivityResponseBody = {
  connectivity?: {
    connectMessage?: string(name='ConnectMessage', description='The error message returned if the connectivity test fails. No such a message is returned if the connectivity test is successful.'),
    connectState?: string(name='ConnectState', description='The result of the connectivity test. Valid values: Connectable: The network can be connected. ConfigError: The network can be connected, but the configurations are incorrect. Unreachable: The network cannot be connected. Unsupport: An error is reported due to other causes. For example, the desired resource group is being initialized.', example='Connectable'),
    detailLogs?: [ 
      {
        code?: string(name='Code', description='The code of the test item.', example='validate_input_parameters'),
        endTime?: long(name='EndTime', description='The end time of a step.', example='1730217604002'),
        message?: string(name='Message', description='The name of the step.'),
        startTime?: long(name='StartTime', description='The start time of a step.', example='1730217600001'),
      }
    ](name='DetailLogs', description='The detailed logs of each step in the connectivity test.'),
  }(name='Connectivity', description='The details of the connectivity test.'),
  requestId?: string(name='RequestId', description='The request ID.', example='4CDF7B72-020B-542A-8465-21CFFA81****'),
}

model TestDataSourceConnectivityResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: TestDataSourceConnectivityResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  Your account must be assigned one of the following roles of the desired workspace: Tenant Owner, Workspace Administrator, Deploy, Develop, Workspace Owner, and O\\&M
  * @param request  the request parameters of TestDataSourceConnectivity  TestDataSourceConnectivityRequest
  * @return TestDataSourceConnectivityResponse
 */
async function testDataSourceConnectivity(request: TestDataSourceConnectivityRequest): TestDataSourceConnectivityResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'TestDataSourceConnectivity', 'POST', '/', 'json', false, 'json', request);
}

model TriggerSchedulerTaskInstanceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
  taskId: long(name='TaskId', description='The task ID.

This parameter is required.', example='1234', position='Body'),
  triggerTime: long(name='TriggerTime', description='The time defined by the HTTP Trigger node. This value is a UNIX timestamp.

This parameter is required.', example='1710239005403', position='Body'),
}

model TriggerSchedulerTaskInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model TriggerSchedulerTaskInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: TriggerSchedulerTaskInstanceResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of TriggerSchedulerTaskInstance  TriggerSchedulerTaskInstanceRequest
  * @return TriggerSchedulerTaskInstanceResponse
 */
async function triggerSchedulerTaskInstance(request: TriggerSchedulerTaskInstanceRequest): TriggerSchedulerTaskInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'TriggerSchedulerTaskInstance', 'POST', '/', 'json', true, 'form', request);
}

model UnTagDataAssetsRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataAssetIds: [ string ](name='DataAssetIds', description='The data asset IDs.

This parameter is required.', shrink='json', position='Query'),
  dataAssetType: string(name='DataAssetType', description='The type of the data asset. Valid values:

*   ACS::DataWorks::Table
*   ACS::DataWorks::Task

This parameter is required.', example='ACS::DataWorks::Task', position='Query'),
  envType?: string(name='EnvType', description='The environment of the workspace to which the data asset belongs. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='123', position='Query'),
  tags: [ 
    {
      key: string(name='Key', description='The tag key.

This parameter is required.', example='key', minLength=1, maxLength=128),
      value?: string(name='Value', description='The tag value.', example='value', maxLength=128),
    }
  ](name='Tags', description='The tags that you want to remove.

This parameter is required.', shrink='json', position='Query'),
}

model UnTagDataAssetsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='8754EE08-4AA2-5F77-ADD7-754DBBDA9F75'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UnTagDataAssetsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UnTagDataAssetsResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of UnTagDataAssets  UnTagDataAssetsRequest
  * @return UnTagDataAssetsResponse
 */
async function unTagDataAssets(request: UnTagDataAssetsRequest): UnTagDataAssetsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UnTagDataAssets', 'POST', '/', 'json', false, 'json', request);
}

model UpdateAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the rule.', example='true', position='Query'),
  id?: long(name='Id', description='The rule ID.', example='105412', position='Query'),
  name?: string(name='Name', description='The name of the rule.', example='collection_name', position='Query'),
  notification?: {
    channels?: [ string ](name='Channels', description='The alert notification channels.'),
    intervalInMinutes?: int32(name='IntervalInMinutes', description='The interval at which an alert notification is sent. Unit: minutes. Valid values: [5,10000].', example='30'),
    maximum?: int32(name='Maximum', description='The maximum number of times an alert notification can be sent within a calendar day. Valid values: [1, 10000].', example='3'),
    receivers?: [ 
      {
        extension?: string(name='Extension', description='The additional configuration of the alert recipient. If the ReceiverType parameter is set to DingdingUrl, you can set this parameter to {"atAll":true} to remind all members in a DingTalk group.', example='{"atAll":true}'),
        receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid valves:

*   AliUid: Alibaba Cloud account ID.
*   Shift Schedules: the personnel in a shift schedule.
*   TaskOwner: the task owner. The task owner can receive custom alerts and event alerts.
*   Owner: the baseline owner. The baseline owner can receive baseline alerts.
*   WebhookUrl: URL of a custom webhook.
*   DingdingUrl: DingTalk webhook URL.
*   FeishuUrl: Lark webhook URL.
*   WeixinUrl: WeCom webhook URL.', example='TaskOwner'),
        receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
      }
    ](name='Receivers', description='The alert recipients.'),
    silenceEndTime?: string(name='SilenceEndTime', description='The end time for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
    silenceStartTime?: string(name='SilenceStartTime', description='The start time for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
  }(name='Notification', description='The configuration for the alert notification.', shrink='json', position='Query'),
  owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.', example='193379****', position='Query'),
  triggerCondition?: {
    extension?: {
      cycleUnfinished?: {
        cycleAndTime?: [ 
          {
            cycleId?: int32(name='CycleId', description='The ID of the scheduling cycle of the instance. Valid values: [1,288].', example='1'),
            time?: string(name='Time', description='The latest completion time of the instance within the scheduling cycle. The time is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='01:00'),
          }
        ](name='CycleAndTime', description='The configurations of the scheduling cycle and timeout period of the instance.'),
      }(name='CycleUnfinished', description='The configuration for an alert of the CycleUnfinished type.'),
      error?: {
        autoRerunAlertEnabled?: boolean(name='AutoRerunAlertEnabled', description='Specifies whether to trigger an alert if a batch synchronization task is automatically rerun upon a failure.', example='false'),
        streamTaskIds?: [ long ](name='StreamTaskIds', description='The IDs of the real-time computing tasks. This parameter is required when you monitor real-time computing tasks.'),
      }(name='Error', description='The configuration for an alert of the Error type.'),
      instanceErrorCount?: {
        count?: int32(name='Count', description='The maximum number of instances on which an error occurs. Valid values: [1,10000].', example='10'),
      }(name='InstanceErrorCount', description='The configuration for an alert of the InstanceErrorCount type.'),
      instanceErrorPercentage?: {
        percentage?: int32(name='Percentage', description='The maximum percentage of instances on which an error occurs in the workspace to the total number of instances. Valid values: [1-100].', example='10'),
      }(name='InstanceErrorPercentage', description='The configuration for an alert of the InstanceErrorPercentage type.'),
      instanceTransferFluctuate?: {
        percentage?: int32(name='Percentage', description='The maximum percentage of fluctuation in the number of auto triggered node instances that are generated in your workspace. Valid values: [1-100].', example='10'),
        trend?: string(name='Trend', description='The way in which the number of auto triggered node instances that are generated in your workspace fluctuates. Valid values:

*   abs: the absolute value. The number of instances increases or decreases.
*   increase: The number of instances increases.
*   decrease: The number of instances decreases.', example='abs'),
      }(name='InstanceTransferFluctuate', description='The configuration for an alert of the InstanceTransferFluctuate type.'),
      timeout?: {
        timeoutInMinutes?: int32(name='TimeoutInMinutes', description='The timeout period. Unit: minutes.', example='10'),
      }(name='Timeout', description='The configuration for an alert of the Timeout type.'),
      unFinished?: {
        unFinishedTime?: string(name='UnFinishedTime', description='The latest completion time of the instance. The period is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
      }(name='UnFinished', description='The configuration for an alert of the UnFinished type.'),
    }(name='Extension', description='The extended information about the rule. This parameter is required for specific types of alerts.'),
    target?: {
      allowTasks?: [ long ](name='AllowTasks', description='The nodes that are not to be monitored.'),
      ids?: [ long ](name='Ids', description='The IDs of monitored objects.'),
      type?: string(name='Type', description='The type of the monitored objects. Valid values:

*   Task: node
*   Baseline: baseline
*   project: workspace
*   BizProcess: workflow', example='Task'),
    }(name='Target', description='The monitored objects.'),
    type?: string(name='Type', description='The alert type. Valid values:

*   Finished: An instance is successfully run.
*   UnFinished: An instance does not finish running before a specified point in time.
*   Error: An error occurs on an instance.
*   CycleUnfinished: An instance does not finish running as expected within a specific cycle.
*   Timeout: An instance times out.
*   InstanceTransferComplete: An instance is generated by the auto triggered node.
*   InstanceTransferFluctuate: The number of generated instances fluctuates.
*   ExhaustedError: An error persists after an instance is automatically rerun.
*   InstanceKeyword: An instance with errors contains specified keywords.
*   InstanceErrorCount: The number of instances on which an error occurs reaches a specified threshold.
*   InstanceErrorPercentage: The proportion of instances on which an error occurs in the workspace to the total number of instances reaches a specified threshold.
*   ResourceGroupPercentage: The usage rate of the resource group reaches a specified threshold.
*   ResourceGroupWaitCount: The number of instances that are waiting for resources in the resource group reaches a specified threshold.', example='ERROR'),
  }(name='TriggerCondition', description='The alert triggering condition.', shrink='json', position='Query'),
}

model UpdateAlertRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='D85FEE2B-6174-5817-AF9E-FDD02FEDA5BC'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAlertRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateAlertRule  UpdateAlertRuleRequest
  * @return UpdateAlertRuleResponse
 */
async function updateAlertRule(request: UpdateAlertRuleRequest): UpdateAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateAlertRule', 'POST', '/', 'json', false, 'json', request);
}

model UpdateBusinessRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  businessId: long(name='BusinessId', description='The workflow ID.

You can call the [ListBusiness](https://help.aliyun.com/document_detail/173945.html) operation to query the ID.

This parameter is required.', example='300000', position='Body'),
  businessName?: string(name='BusinessName', description='The name of the workflow.

You can call the [ListBusiness](https://help.aliyun.com/document_detail/173945.html) operation to query the name.', example='MyBusiness', position='Body'),
  description?: string(name='Description', description='The description of the workflow.', example='modified from my first business', position='Body'),
  owner?: string(name='Owner', description='The owner of the workflow.

You can call the [ListBusiness](https://help.aliyun.com/document_detail/173945.html) operation to query the owner.', example='348428****', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to obtain the workspace ID. You must configure either this parameter or the `ProjectIdentifier` parameter to determine the DataWorks workspace to which the operation is applied.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to obtain the name. You must configure either this parameter or the `ProjectId` parameter to determine the DataWorks workspace to which the operation is applied.', example='dw_project', position='Body'),
}

model UpdateBusinessResponseBody = {
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateBusinessResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateBusinessResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateBusiness  UpdateBusinessRequest
  * @return UpdateBusinessResponse
 */
async function updateBusiness(request: UpdateBusinessRequest): UpdateBusinessResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateBusiness', 'POST', '/', 'json', true, 'form', request);
}

model UpdateColumnBusinessMetadataRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  description?: string(name='Description', example='test description', position='Body'),
  id: string(name='Id', description='The column ID. You can call the ListColumns operation to query the ID. For more information, see [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

This parameter is required.', example='maxcompute-column:11075xxxx::test_project:test_schema:test_table:test_column', position='Body'),
}

model UpdateColumnBusinessMetadataResponseBody = {
  requestId?: string(name='RequestId', example='D1E2E5BC-xxxx-xxxx-xxxx-xxxxxx'),
  success?: boolean(name='Success', example='true'),
}

model UpdateColumnBusinessMetadataResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateColumnBusinessMetadataResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateColumnBusinessMetadata  UpdateColumnBusinessMetadataRequest
  * @return UpdateColumnBusinessMetadataResponse
 */
async function updateColumnBusinessMetadata(request: UpdateColumnBusinessMetadataRequest): UpdateColumnBusinessMetadataResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateColumnBusinessMetadata', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDIAlarmRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIAlarmRuleId?: long(name='DIAlarmRuleId', description='This parameter is deprecated. Use the Id parameter instead.', example='34982', deprecated='true', position='Query'),
  DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='1', position='Query'),
  description?: string(name='Description', description='The description of the alert rule.', example='The description of the alert rule.', position='Query'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the alert rule. By default, the alert rule is disabled.', example='true', position='Query'),
  id?: long(name='Id', description='The alert rule Id', example='34982', position='Query'),
  metricType?: string(name='MetricType', description='The metric type in the alert rule. Valid values:

*   Heartbeat
*   FailoverCount
*   Delay
*   DdlReport
*   ResourceUtilization', example='Heartbeat', position='Query'),
  name?: string(name='Name', description='The name of the alert rule.', example='alarm_rule_name', position='Query'),
  notificationSettings?: {
    inhibitionInterval?: long(name='InhibitionInterval', description='This parameter is deprecated and replaced by the MuteInterval parameter.', example='5', deprecated='true'),
    muteInterval?: long(name='MuteInterval', description='The duration of the alert suppression interval. Default value: 5. Unit: minutes.', example='5'),
    notificationChannels?: [ 
      {
        channels?: [ string ](name='Channels', description='The alert notification method. Valid values:

*   Mail
*   Phone
*   Sms
*   Ding'),
        severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Warning'),
      }
    ](name='NotificationChannels', description='The alert notification methods.'),
    notificationReceivers?: [ 
      {
        receiverType?: string(name='ReceiverType', description='The recipient type. Valid values: AliyunUid, DingToken, FeishuToken, and WebHookUrl.', example='DingToken'),
        receiverValues?: [ string ](name='ReceiverValues', description='The recipient.

*   If the ReceiverType parameter is set to AliyunUid, set this parameter to the Alibaba Cloud account ID of a user.
*   If the ReceiverType parameter is set to DingToken, set this parameter to the token of a DingTalk chatbot.'),
      }
    ](name='NotificationReceivers', description='The settings of alert notification recipients.'),
  }(name='NotificationSettings', description='The alert notification settings.', shrink='json', position='Query'),
  triggerConditions?: [ 
    {
      ddlReportTags?: [ string ](name='DdlReportTags', description='This parameter is deprecated and replaced by the DdlTypes parameter.', deprecated='true'),
      ddlTypes?: [ string ](name='DdlTypes', description='The types of DDL operations for which the alert rule takes effect.'),
      duration?: long(name='Duration', description='The time interval for alert calculation. Unit: minutes.', example='15'),
      severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Warning'),
      threshold?: long(name='Threshold', description='The alert threshold.

*   If the alert rule is for task status, you do not need to specify a threshold.
*   If the alert rule is for failovers, you must specify the number of failovers.
*   If the alert rule is for latency, you must specify the latency duration, in seconds.', example='5'),
    }
  ](name='TriggerConditions', description='The conditions that can trigger the alert rule.', shrink='json', position='Query'),
}

model UpdateDIAlarmRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='A6C6B486-E3A2-5D52-9E76-D9380485D946'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateDIAlarmRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDIAlarmRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateDIAlarmRule  UpdateDIAlarmRuleRequest
  * @return UpdateDIAlarmRuleResponse
 */
async function updateDIAlarmRule(request: UpdateDIAlarmRuleRequest): UpdateDIAlarmRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDIAlarmRule', 'GET', '/', 'json', false, 'json', request);
}

model UpdateDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='11588', deprecated='true', position='Query'),
  description?: string(name='Description', description='The description of the synchronization task.', example='The description of the synchronization task.', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11588', position='Query'),
  jobSettings?: {
    channelSettings?: string(name='ChannelSettings', description='The channel control settings for the synchronization task. You can configure special channel control settings for the following synchronization links: data synchronization between Hologres data sources and data synchronization from Hologres to Kafka.

1.  Holo2Kafka

*   Example: {"destinationChannelSettings":{"kafkaClientProperties":[{"key":"linger.ms","value":"100"}],"keyColumns":["col3"],"writeMode":"canal"}}
*   kafkaClientProperties: the parameters related to a Kafka producer, which are used when you read data from a Kafka data source.
*   keyColumns: the names of Kafka columns to which you want to write data.
*   writeMode: the writing format. Valid values: json and canal.

2.  Holo2Holo

*   Example: {"destinationChannelSettings":{"conflictMode":"replace","dynamicColumnAction":"replay","writeMode":"replay"}}
*   conflictMode: the policy used to handle a conflict that occurs during data writing to Hologres. Valid values: replace and ignore.
*   writeMode: the mode in which you want to write data to Hologres. Valid values: replay and insert.
*   dynamicColumnAction: the mode in which you want to write data to dynamic columns in a Hologres table. Valid values: replay, insert, and ignore.', example='{"structInfo":"MANAGED","storageType":"TEXTFILE","writeMode":"APPEND","partitionColumns":[{"columnName":"pt","columnType":"STRING","comment":""}],"fieldDelimiter":""}'),
    columnDataTypeSettings?: [ 
      {
        destinationDataType?: string(name='DestinationDataType', description='The data type of the destination field. Valid values: bigint, boolean, string, text, datetime, timestamp, decimal, and binary. Different types of data sources support different data types.', example='text'),
        sourceDataType?: string(name='SourceDataType', description='The data type of the source field. Valid values: Valid values: bigint, boolean, string, text, datetime, timestamp, decimal, and binary. Different types of data sources support different data types.', example='bigint'),
      }
    ](name='ColumnDataTypeSettings', description='The data type mappings between source fields and destination fields.

>  "ColumnDataTypeSettings":[ { "SourceDataType":"Bigint", "DestinationDataType":"Text" } ]'),
    cycleScheduleSettings?: {
      scheduleParameters?: string(name='ScheduleParameters', description='The scheduling parameters.', example='bizdate=$bizdate'),
    }(name='CycleScheduleSettings', description='The settings for periodic scheduling.'),
    ddlHandlingSettings?: [ 
      {
        action?: string(name='Action', description='The processing policy. Valid values:

*   Ignore: ignores a DDL message.
*   Critical: reports an error for a DDL message.
*   Normal: normally processes a DDL message.', example='Critical'),
        type?: string(name='Type', description='The type of the DDL operation. Valid values:

*   RenameColumn
*   ModifyColumn
*   CreateTable
*   TruncateTable
*   DropTable
*   DropColumn
*   AddColumn', example='AddColumn'),
      }
    ](name='DdlHandlingSettings', description='The processing settings for DDL messages.

>  "DDLHandlingSettings":[ { "Type":"Insert", "Action":"Normal" } ]'),
    runtimeSettings?: [ 
      {
        name?: string(name='Name', description='The name of the configuration item. Valid values:

*   src.offline.datasource.max.connection: specifies the maximum number of connections that are allowed for reading data from the source of a batch synchronization task.
*   dst.offline.truncate: specifies whether to clear the destination table before data writing.
*   runtime.offline.speed.limit.enable: specifies whether throttling is enabled for a batch synchronization task.
*   runtime.offline.concurrent: specifies the maximum number of parallel threads that are allowed for a batch synchronization task.
*   runtime.enable.auto.create.schema: specifies whether schemas are automatically created in the destination of a synchronization task.
*   runtime.realtime.concurrent: specifies the maximum number of parallel threads that are allowed for a real-time synchronization task.
*   runtime.realtime.failover.minute.dataxcdc: specifies the maximum waiting duration before a synchronization task retries the next restart if the previous restart fails after failover occurs. Unit: minutes.
*   runtime.realtime.failover.times.dataxcdc: specifies the maximum number of failures that are allowed for restarting a synchronization task after failovers occur.', example='runtime.offline.concurrent'),
        value?: string(name='Value', description='The value of the configuration item.', example='1'),
      }
    ](name='RuntimeSettings', description='The runtime settings.'),
  }(name='JobSettings', description='The settings for the dimension of the synchronization task. The settings include processing policies for DDL messages, policies for data type mappings between source fields and destination fields, and runtime parameters of the synchronization task.', shrink='json', position='Query'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the workspace ID.

You must configure this parameter to specify the DataWorks workspace to which the operation is applied.', example='10000', position='Query'),
  resourceSettings?: {
    offlineResourceSettings?: {
      requestedCu?: double(name='RequestedCu', description='The number of compute units (CUs) in the resource group for Data Integration that are used for batch synchronization.', example='2.0'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The name of the resource group for Data Integration used for batch synchronization.', example='S_res_group_111_222'),
    }(name='OfflineResourceSettings', description='The resource used for batch synchronization.'),
    realtimeResourceSettings?: {
      requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for Data Integration that are used for real-time synchronization.', example='2.0'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The name of the resource group for Data Integration used for real-time synchronization.', example='S_res_group_111_222'),
    }(name='RealtimeResourceSettings', description='The resource used for real-time synchronization.'),
    scheduleResourceSettings?: {
      requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for scheduling that are used for batch synchronization.', example='2.0'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The name of the resource group for scheduling used for batch synchronization.', example='S_res_group_235454102432001_1721021993437'),
    }(name='ScheduleResourceSettings', description='The resource used for scheduling.'),
  }(name='ResourceSettings', description='The resource settings.', shrink='json', position='Query'),
  tableMappings?: [ 
    {
      sourceObjectSelectionRules?: [ 
        {
          action?: string(name='Action', description='The operation that is performed to select objects. Valid values: Include and Exclude.', example='Include'),
          expression?: string(name='Expression', description='The expression.', example='mysql_table_1'),
          expressionType?: string(name='ExpressionType', description='The expression type. Valid values: Exact and Regex.', example='Exact'),
          objectType?: string(name='ObjectType', description='The object type. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
        }
      ](name='SourceObjectSelectionRules', description='The list of rules that you want to use to select synchronization objects in the source.'),
      transformationRules?: [ 
        {
          ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml', example='Rename'),
          ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
          ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which you want to perform the action. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
        }
      ](name='TransformationRules', description='The transformation rules that you want to apply to the synchronization objects selected from the source.'),
    }
  ](name='TableMappings', description='The list of mappings between rules used to select synchronization objects in the source and transformation rules applied to the selected synchronization objects. Each entry in the list displays a mapping between a rule used to select synchronization objects and a transformation rule applied to the selected synchronization objects.

>  [ { "SourceObjectSelectionRules":[ { "ObjectType":"Database", "Action":"Include", "ExpressionType":"Exact", "Expression":"biz_db" }, { "ObjectType":"Schema", "Action":"Include", "ExpressionType":"Exact", "Expression":"s1" }, { "ObjectType":"Table", "Action":"Include", "ExpressionType":"Exact", "Expression":"table1" } ], "TransformationRuleNames":[ { "RuleName":"my_database_rename_rule", "RuleActionType":"Rename", "RuleTargetType":"Schema" } ] } ]', shrink='json', position='Query'),
  transformationRules?: [ 
    {
      ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml
*   DefineIncrementalCondition
*   DefineCycleScheduleSettings
*   DefinePartitionKey', example='Rename'),
      ruleExpression?: string(name='RuleExpression', description='The expression of the rule. The expression must be a JSON string.

1.  Example of a renaming rule

*   Example: {"expression":"${srcDatasourceName}_${srcDatabaseName}_0922" }
*   expression: the expression of the renaming rule. You can use the following variables in an expression: ${srcDatasourceName}, ${srcDatabaseName}, and ${srcTableName}. ${srcDatasourceName} specifies the name of the source. ${srcDatabaseName} specifies the name of a source database. ${srcTableName} specifies the name of a source table.

2.  Example of a column addition rule

*   Example: {"columns":[{"columnName":"my_add_column","columnValueType":"Constant","columnValue":"123"}]}
*   If you do not configure such a rule, no fields are added to the destination and no values are assigned by default.
*   columnName: the name of the field that is added.
*   columnValueType: the value type of the field. Valid values: Constant and Variable.
*   columnValue: the value of the field. If the columnValueType parameter is set to Constant, set the columnValue parameter to a constant of the STRING data type. If the columnValueType parameter is set to Variable, set the columnValue parameter to a built-in variable. The following built-in variables are supported: EXECUTE_TIME (LONG data type), DB_NAME_SRC (STRING data type), DATASOURCE_NAME_SRC (STRING data type), TABLE_NAME_SRC (STRING data type), DB_NAME_DEST (STRING data type), DATASOURCE_NAME_DEST (STRING data type), TABLE_NAME_DEST (STRING data type), and DB_NAME_SRC_TRANSED (STRING data type). EXECUTE_TIME specifies the execution time. DB_NAME_SRC specifies the name of a source database. DATASOURCE_NAME_SRC specifies the name of the source. TABLE_NAME_SRC specifies the name of a source table. DB_NAME_DEST specifies the name of a destination database. DATASOURCE_NAME_DEST specifies the name of the destination. TABLE_NAME_DEST specifies the name of a destination table. DB_NAME_SRC_TRANSED specifies the database name obtained after a transformation.

3.  Example of a rule used to specify primary key fields for a destination table

*   Example: {"columns":["ukcolumn1","ukcolumn2"]}
*   If you do not configure such a rule, the primary key fields in the mapped source table are used for the destination table by default.
*   If the destination table is an existing table, Data Integration does not modify the schema of the destination table. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run.
*   If the destination table is automatically created by the system, Data Integration automatically creates the schema of the destination table. The schema contains the primary key fields that you specify. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run.

4.  Example of a rule used to process DML messages

*   Example: {"dmlPolicies":[{"dmlType":"Delete","dmlAction":"Filter","filterCondition":"id > 1"}]}
*   If you do not configure such a rule, the default processing policy for messages generated for insert, update, and delete operations is Normal.
*   dmlType: the DML operation. Valid values: Insert, Update, and Delete.
*   dmlAction: the processing policy for DML messages. Valid values: Normal, Ignore, Filter, and LogicalDelete. Filter indicates conditional processing. You can set the dmlAction parameter to Filter only when the dmlType parameter is set to Update or Delete.
*   filterCondition: the condition used to filter DML messages. This parameter is required only when the dmlAction parameter is set to Filter.

5.  Example of a rule used to perform incremental synchronization

*   Example: {"where":"id > 0"}
*   You can configure such a rule to perform incremental synchronization.

6.  Example of a rule used to configure scheduling parameters for an auto triggered task

*   Example: {"cronExpress":" \\* \\* \\* \\* \\* \\*", "cycleType":"1"}
*   You can configure such a rule to configure scheduling parameters for an auto triggered task.

7.  Example of a rule used to specify a partition key

*   Example: {"columns":["id"]}
*   You can configure such a rule to specify a partition key.', example='{"expression":"${srcDatasoureName}_${srcDatabaseName}"}'),
      ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
      ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which you want to perform the action. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
    }
  ](name='TransformationRules', description='The list of transformation rules for objects involved in the synchronization task.

>  [ { "RuleName":"my_database_rename_rule", "RuleActionType":"Rename", "RuleTargetType":"Schema", "RuleExpression":"{"expression":"${srcDatasoureName}_${srcDatabaseName}"}" } ]', shrink='json', position='Query'),
}

model UpdateDIJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='AAC30B35-820D-5F3E-A42C-E96BB6379325'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateDIJob  UpdateDIJobRequest
  * @return UpdateDIJobResponse
 */
async function updateDIJob(request: UpdateDIJobRequest): UpdateDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDIJob', 'GET', '/', 'json', false, 'json', request);
}

model UpdateDataAssetTagRequest {
  regionId?: string(name='RegionId', position='Host'),
  description?: string(name='Description', description='The description of the tag.', example='This is a description.', maxLength=1024, position='Query'),
  key: string(name='Key', description='The tag key.

This parameter is required.', example='key1', minLength=1, maxLength=128, position='Query'),
  managers?: [ string ](name='Managers', description='The tag administrators.', shrink='json', position='Query'),
  values?: [ string ](name='Values', description='The tag values.', shrink='json', position='Query'),
}

model UpdateDataAssetTagResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateDataAssetTagResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataAssetTagResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of UpdateDataAssetTag  UpdateDataAssetTagRequest
  * @return UpdateDataAssetTagResponse
 */
async function updateDataAssetTag(request: UpdateDataAssetTagRequest): UpdateDataAssetTagResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataAssetTag', 'POST', '/', 'json', false, 'json', request);
}

model UpdateDataQualityEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityRules?: [ 
    {
      checkingConfig?: {
        referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain specific types of thresholds, you must query reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{"bizdate": ["-1"]}'),
        thresholds?: {
          critical?: {
            expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
            value?: string(name='Value', description='The threshold value.', example='0.01'),
          }(name='Critical', description='The threshold settings for critical alerts.'),
          expected?: {
            expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='='),
            value?: string(name='Value', description='The threshold value.', example='0'),
          }(name='Expected', description='The expected threshold setting.'),
          warned?: {
            expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
            value?: string(name='Value', description='The threshold value.', example='0.001'),
          }(name='Warned', description='The threshold settings for normal alerts.'),
        }(name='Thresholds', description='The threshold settings.'),
        type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fluctation
*   Auto
*   FluctationDiscreate
*   Average
*   Fixed', example='Fixed'),
      }(name='CheckingConfig', description='The check settings for sample data.'),
      description?: string(name='Description', description='The description of the rule.', example='OpenAPI test rules', maxLength=500),
      enabled?: boolean(name='Enabled', description='Specifies whether to enable the rule.', example='true'),
      errorHandlers?: [ 
        {
          errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If you define the rule by using custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM ods_d_openapi_log WHERE status = \\"Error\\"'),
          type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
        }
      ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
      id?: long(name='Id', description='The rule ID. You can call the [ListQualityRules](https://help.aliyun.com/document_detail/173995.html) operation to query the ID of the monitoring rule.', example='1022171560'),
      name?: string(name='Name', description='The name of the monitoring rule.', example='OpenAPI test rules', maxLength=255),
      samplingConfig?: {
        metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: specifies that data is sampled by executing custom SQL statements.', example='CountNotIn'),
        metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
        samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='status != \\"Succeeded\\"'),
        settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='odps.sql.type.system.odps2=True,odps.sql.hive.compatible=True', maxLength=1000),
      }(name='SamplingConfig', description='The parameters required for sampling.'),
      severity?: string(name='Severity', description='The strength of the rule. Valid values:

*   Normal
*   High', example='Normal'),
      templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='SYSTEM:field:null_value:fixed:0'),
    }
  ](name='DataQualityRules', description='The list of monitoring rules that are associated with the monitor.', shrink='json', position='Body'),
  dataSourceId?: long(name='DataSourceId', description='The data source ID. You can call the [ListDataSources](https://help.aliyun.com/document_detail/211431.html) operation to query the ID.', example='358750', position='Body'),
  description?: string(name='Description', description='The description of the monitor.', example='OpenAPI data quality monitoring test.', maxLength=65535, position='Body'),
  hooks?: [ 
    {
      condition?: string(name='Condition', description='The hook trigger condition. When this condition is met, the hook action is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='${severity} == "High" AND ${status} == "Critical"'),
      type?: string(name='Type', description='The hook type. Valid values:

*   BlockTaskInstance: Blocks the running of scheduling tasks.', example='ByScheduledTaskInstance'),
    }
  ](name='Hooks', description='The hook.', shrink='json', position='Body'),
  id: long(name='Id', description='The ID of the monitor.

This parameter is required.', example='7227061794', position='Body'),
  name?: string(name='Name', description='The name of the monitor.', example='OpenAPI data quality monitoring test.', maxLength=255, position='Body'),
  notifications?: {
    condition?: string(name='Condition', description='The notification trigger condition. When this condition is met, the alert notification is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='${severity} == "High" AND ${status} == "Critical"'),
    notifications?: [ 
      {
        notificationChannels?: [ 
          {
            channels?: [ string ](name='Channels', description='The alert notification methods.'),
          }
        ](name='NotificationChannels', description='The alert notification methods.'),
        notificationReceivers?: [ 
          {
            extension?: string(name='Extension', description='The additional parameters that are required when alerts are sent. The parameters are JSON-formatted strings. The following keys are supported:

*   atAll: specifies that all members in a group are mentioned when alerts are sent by using DingTalk. This parameter is valid only if you set ReceiverType to DingdingUrl.', example='{  "atAll": true }'),
            receiverType?: string(name='ReceiverType', description='The type of the alert recipient.

Valid values:

*   WebhookUrl
*   FeishuUrl
*   DingdingUrl
*   WeixinUrl
*   AliUid', example='DingdingUrl'),
            receiverValues?: [ string ](name='ReceiverValues', description='The alert recipient.'),
          }
        ](name='NotificationReceivers', description='The configurations of alert recipients.'),
      }
    ](name='Notifications', description='The configurations of the alert notification.'),
  }(name='Notifications', description='The configurations of alert notifications.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace.

This parameter is required.', example='10000', position='Body'),
  runtimeConf?: string(name='RuntimeConf', description='The extended configurations in JSON-formatted strings. You can use this parameter only for monitors that are used to monitor the quality of E-MapReduce (EMR) data.

*   queue: The Yarn queue used when a monitor checks the quality of EMR data. By default, the queue configured for the current workspace is used.

*   sqlEngine: The SQL engine used when a monitor checks the quality of EMR data.

    *   HIVE_SQL
    *   SPARK_SQL', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }', position='Body'),
  target?: {
    databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   hologres
*   cdh
*   analyticdb_for_mysql
*   starrocks
*   emr
*   analyticdb_for_postgresql', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='dt=$[yyyymmdd-1]', maxLength=255),
    tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odsp.openapi.ods_d_openapi_log'),
  }(name='Target', description='The monitored object of the data quality monitoring task.', shrink='json', position='Body'),
  trigger?: {
    taskIds?: [ long ](name='TaskIds', description='The IDs of scheduling tasks. This parameter is valid only if you set Type to ByScheduledTaskInstance.'),
    type?: string(name='Type', description='The trigger type of the monitor. Valid values:

*   ByScheduledTaskInstance: The monitor is triggered by the associated scheduling tasks.
*   ByManual: The monitor is manually triggered.', example='ByScheduledTaskInstance'),
  }(name='Trigger', description='The trigger configuration of the monitor.', shrink='json', position='Body'),
}

model UpdateDataQualityEvaluationTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateDataQualityEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataQualityEvaluationTaskResponseBody(name='body'),
}

/**
  * @description This API operation is supported in all DataWorks editions.
  * @param request  the request parameters of UpdateDataQualityEvaluationTask  UpdateDataQualityEvaluationTaskRequest
  * @return UpdateDataQualityEvaluationTaskResponse
 */
async function updateDataQualityEvaluationTask(request: UpdateDataQualityEvaluationTaskRequest): UpdateDataQualityEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataQualityEvaluationTask', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDataQualityRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    thresholds?: {
      critical?: {
        expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue > 0.05'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Critical', description='The threshold settings for critical alerts.'),
      expected?: {
        expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue <= 0.01'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Expected', description='The expected threshold setting.'),
      warned?: {
        expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue > 0.01'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Warned', description='The threshold settings for normal alerts.'),
    }(name='Thresholds', description='The threshold settings.'),
    type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
  }(name='CheckingConfig', description='The check settings for sample data.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description of the rule. The description can be up to 500 characters in length.', example='this is a odps _sql task', maxLength=500, position='Body'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the rule.', example='true', position='Body'),
  errorHandlers?: [ 
    {
      errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If the rule is defined by custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
      type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
    }
  ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.', shrink='json', position='Body'),
  id: long(name='Id', description='The rule ID.

This parameter is required.', example='100001', position='Body'),
  name?: string(name='Name', description='The name of the rule. The name can be up to 255 characters in length and can contain digits, letters, and punctuation marks.', example='The table cannot be empty.', maxLength=255, position='Body'),
  projectId: long(name='ProjectId', description='This parameter is required.', position='Query'),
  samplingConfig?: {
    metric?: string(name='Metric', description='The metrics used for sampling. You can leave this parameter empty if you use a rule template. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='Min'),
    metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
    samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='id IS NULL'),
    settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;', maxLength=1000),
  }(name='SamplingConfig', description='The sampling settings.', shrink='json', position='Body'),
  severity?: string(name='Severity', description='The strength of the rule. Valid values:

*   Normal
*   High', example='High', position='Body'),
  templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='system::user_defined', position='Body'),
}

model UpdateDataQualityRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateDataQualityRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataQualityRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateDataQualityRule  UpdateDataQualityRuleRequest
  * @return UpdateDataQualityRuleResponse
 */
async function updateDataQualityRule(request: UpdateDataQualityRuleRequest): UpdateDataQualityRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataQualityRule', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDataQualityRuleTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference samples and perform aggregate operations on the reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
  }(name='CheckingConfig', description='The check settings for sample data.', shrink='json', position='Body'),
  code: string(name='Code', description='The code for the template.

This parameter is required.', example='USER_DEFINED:123', position='Body'),
  directoryPath?: string(name='DirectoryPath', description='The directory in which the template is stored. Slashes (/) are used to separate directory levels. The name of each directory level can be up to 1,024 characters in length. It cannot contain whitespace characters or slashes (/).', example='/ods/order_data', position='Body'),
  name?: string(name='Name', description='The name of the template. The name can be up to 512 characters in length and can contain digits, letters, and punctuation marks.', example='Table row Count Verification', maxLength=128, position='Body'),
  projectId: long(name='ProjectId', description='This parameter is required.', position='Query'),
  samplingConfig?: {
    metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='Max'),
    metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{"SQL": "select count(1) from table;"}'),
    settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;', maxLength=1000),
  }(name='SamplingConfig', description='The sampling settings.', shrink='json', position='Body'),
}

model UpdateDataQualityRuleTemplateResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='691CA452-D37A-4ED0-9441'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateDataQualityRuleTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataQualityRuleTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateDataQualityRuleTemplate  UpdateDataQualityRuleTemplateRequest
  * @return UpdateDataQualityRuleTemplateResponse
 */
async function updateDataQualityRuleTemplate(request: UpdateDataQualityRuleTemplateRequest): UpdateDataQualityRuleTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataQualityRuleTemplate', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  connectionProperties: string(name='ConnectionProperties', description='The connection configurations of the data source, including the connection address, access identity, and environment information. The envType parameter specifies the environment in which the data source is used. Valid values of the envType parameter:

*   Dev: development environment
*   Prod: production environment

The parameters that you need to configure for the data source vary based on the mode in which the data source is added. For more information, see [Data source connection information (ConnectionProperties)](https://help.aliyun.com/document_detail/2852465.html).

This parameter is required.', example='{
	"envType": "Prod",
	"regionId": "cn-beijing",
    "instanceId": "hgprecn-cn-x0r3oun4k001",
    "database": "testdb",
    "securityProtocol": "authTypeNone",
    "authType": "Executor",
    "authIdentity": "1107550004253538"
}', position='Query'),
  connectionPropertiesMode?: string(name='ConnectionPropertiesMode', description='The mode in which the data source is added. The mode varies based on the data source type. Valid values:

*   InstanceMode: instance mode
*   UrlMode: connection string mode', example='UrlMode', position='Query'),
  description?: string(name='Description', description='The description of the data source. The description cannot exceed 3,000 characters in length.', example='test', position='Query'),
  id: long(name='Id', description='The data source ID.

This parameter is required.', example='16033', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='5678', position='Query'),
}

model UpdateDataSourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='102E8E24-0387-531D-8A75-1C0AE7DD03E5'),
  success?: boolean(name='Success', description='Whether the data source has been modified:

- true: Yes
- false: no', example='true'),
}

model UpdateDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Tenant Administrator, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of UpdateDataSource  UpdateDataSourceRequest
  * @return UpdateDataSourceResponse
 */
async function updateDataSource(request: UpdateDataSourceRequest): UpdateDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataSource', 'POST', '/', 'json', false, 'json', request);
}

model UpdateFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  advancedSettings?: string(name='AdvancedSettings', example='{"queue":"default","SPARK_CONF":"--conf spark.driver.memory=2g"}', position='Body'),
  applyScheduleImmediately?: boolean(name='ApplyScheduleImmediately', example='true', position='Body'),
  autoParsing?: boolean(name='AutoParsing', example='true', position='Body'),
  autoRerunIntervalMillis?: int32(name='AutoRerunIntervalMillis', example='120000', position='Body'),
  autoRerunTimes?: int32(name='AutoRerunTimes', example='3', position='Body'),
  connectionName?: string(name='ConnectionName', example='odps_source', position='Body'),
  content?: string(name='Content', example='SELECT "1";', position='Body'),
  cronExpress?: string(name='CronExpress', example='00 00-59/5 1-23 * * ?', position='Body'),
  cycleType?: string(name='CycleType', example='NOT_DAY', position='Body'),
  dependentNodeIdList?: string(name='DependentNodeIdList', example='5,10,15,20', position='Body'),
  dependentType?: string(name='DependentType', example='USER_DEFINE', position='Body'),
  endEffectDate?: long(name='EndEffectDate', example='4155787800000', minimum=0, position='Body'),
  fileDescription?: string(name='FileDescription', example='Here is the file description', position='Body'),
  fileFolderPath?: string(name='FileFolderPath', example='Business_process/First_Business_Process/data_integration/Folder_1/Folder_2', position='Body'),
  fileId: long(name='FileId', description='This parameter is required.', example='100000001', position='Body'),
  fileName?: string(name='FileName', example='ods_user_info_d', position='Body'),
  ignoreParentSkipRunningProperty?: boolean(name='IgnoreParentSkipRunningProperty', example='true', position='Body'),
  imageId?: string(name='ImageId', example='m-uf6d7npxk1hhek8ng0cb', position='Body'),
  inputList?: string(name='InputList', example='project_root,project.file1,project.001_out', position='Body'),
  inputParameters?: string(name='InputParameters', example='[{"ValueSource": "project_001.first_node:bizdate_param","ParameterName": "bizdate_input"}]', position='Body'),
  outputList?: string(name='OutputList', example='dw_project.ods_user_info_d', position='Body'),
  outputParameters?: string(name='OutputParameters', example='[{"Type": 1,"Value": "${bizdate}","ParameterName": "bizdate_param"}]', position='Body'),
  owner?: string(name='Owner', example='18023848927592', position='Body'),
  paraValue?: string(name='ParaValue', example='x=a y=b z=c', position='Body'),
  projectId?: long(name='ProjectId', example='100001', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
  rerunMode?: string(name='RerunMode', example='ALL_ALLOWED', position='Body'),
  resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', example='default_group', position='Body'),
  schedulerType?: string(name='SchedulerType', example='NORMAL', position='Body'),
  startEffectDate?: long(name='StartEffectDate', example='936923400000', minimum=0, position='Body'),
  startImmediately?: boolean(name='StartImmediately', example='true', position='Body'),
  stop?: boolean(name='Stop', example='false', position='Body'),
  timeout?: int32(name='Timeout', example='1', position='Body'),
}

model UpdateFileResponseBody = {
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFGH-IJKLMNOPQ'),
  success?: boolean(name='Success', example='true'),
}

model UpdateFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateFile  UpdateFileRequest
  * @return UpdateFileResponse
 */
async function updateFile(request: UpdateFileRequest): UpdateFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateFile', 'POST', '/', 'json', true, 'form', request);
}

model UpdateFolderRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  folderId: string(name='FolderId', description='This parameter is required.', example='2735c2c19d58', position='Body'),
  folderName: string(name='FolderName', description='This parameter is required.', example='MySecondFolder', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
}

model UpdateFolderResponseBody = {
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model UpdateFolderResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateFolderResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateFolder  UpdateFolderRequest
  * @return UpdateFolderResponse
 */
async function updateFolder(request: UpdateFolderRequest): UpdateFolderResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateFolder', 'POST', '/', 'json', true, 'form', request);
}

model UpdateFunctionRequest {
  regionId?: string(name='RegionId', description='代表region的资源属性字段

This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='463497880880954XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the UDF. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
    "version": "1.1.0",
    "kind": "Function",
    "spec": {
        "functions": [
            {
                "name": "FunctionName",
                "script": {
                    "content": "{\\"name\\": \\"FunctionName\\", \\"datasource\\": {\\"type\\": \\"odps\\", \\"name\\": \\"odps_first\\"}, \\"runtimeResource\\": {\\"resourceGroup\\": \\"S_res_group_XXXX_XXXX\\"}}",
                    "path": "XXX/OpenAPI/Function/FunctionName",
                    "runtime": {
                        "command": "ODPS_FUNCTION"
                    }
                },
                "datasource": {
                    "name": "odps_first",
                    "type": "odps"
                },
                "runtimeResource": {
                    "resourceGroup": "S_res_group_XXXX_XXXX"
                }
            }
        ]
    }
}', position='Body'),
}

model UpdateFunctionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can troubleshoot issues based on the ID.', example='12123960-CB2C-5086-868E-C6C1D024XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

true

false', example='true'),
}

model UpdateFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateFunctionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateFunction  UpdateFunctionRequest
  * @return UpdateFunctionResponse
 */
async function updateFunction(request: UpdateFunctionRequest): UpdateFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateFunction', 'POST', '/', 'json', true, 'form', request);
}

model UpdateIDEEventResultRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkResult?: string(name='CheckResult', example='OK', position='Body'),
  checkResultTip?: string(name='CheckResultTip', example='Succeeded', position='Body'),
  extensionCode?: string(name='ExtensionCode', example='8abcb91f-d266-4073-b907-2ed670378ed1', position='Body'),
  messageId?: string(name='MessageId', description='扩展点消息UUID', example='8abcb91f-d266-4073-b907-2ed670378ed1', position='Body'),
}

model UpdateIDEEventResultResponseBody = {
  requestId?: string(name='RequestId', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
}

model UpdateIDEEventResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateIDEEventResultResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateIDEEventResult  UpdateIDEEventResultRequest
  * @return UpdateIDEEventResultResponse
 */
async function updateIDEEventResult(request: UpdateIDEEventResultRequest): UpdateIDEEventResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateIDEEventResult', 'POST', '/', 'json', true, 'form', request);
}

model UpdateMetaCollectionRequest {
  regionId?: string(name='RegionId', position='Host'),
  administrators?: [ string ](name='Administrators', description='The collection administrator IDs. This parameter is available only for data albums. The administrator must be an account within the same tenant.', shrink='simple', position='Query'),
  description?: string(name='Description', example='new comment', position='Query'),
  id: string(name='Id', description='The collection ID.

This parameter is required.', example='category.123', position='Query'),
  name?: string(name='Name', example='new_name', position='Query'),
}

model UpdateMetaCollectionResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='0E1C0122-F79F-5C26-B546-47A321691868'),
}

model UpdateMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateMetaCollection  UpdateMetaCollectionRequest
  * @return UpdateMetaCollectionResponse
 */
async function updateMetaCollection(request: UpdateMetaCollectionRequest): UpdateMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMetaCollection', 'POST', '/', 'json', false, 'json', request);
}

model UpdateNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Body'),
  spec: string(name='Spec', description='{ "title": "CycleWorkflow Schema", "description": "the JSON schema that is used to configure the auto triggered workflow and nodes in the workflow", "type": "object", "required": [ "version", "kind", "spec" ], "properties": { "version": { "type": "string", "const": "1.1.0", "description": "the schema version. The value is fixed to 1.1.0" }, "kind": { "type": "string", "enum": [ "Workflow", "Node" ], "description": "the resource type" }, "spec": { "type": "object", "description": "the key configurations of the workflow", "required": [ "nodes" ], "properties": { "nodes": { "type": "array", "description": "the nodes in the workflow", "items": { "type": "object", "required": [ "name", "script" ], "properties": { "recurrence": { "type": "string", "enum": [ "Normal", "Pause", "Skip", "NoneAuto" ], "description": "the running mode of the node. Valid values: Normal, Pause, Skip, and NoneAuto" }, "id": { "type": "string", "description": "the node ID" }, "timeout": { "type": "integer", "minimum": 0, "description": "the timeout period. Unit: seconds" }, "instanceMode": { "type": "string", "enum": [ "T+1", "Immediately" ], "description": "the instance generation mode. Valid values: T+1 and Immediately" }, "rerunMode": { "type": "string", "enum": [ "Allowed", "Denied", "FailureAllowed" ], "description": "the rerun mode. Valid values: AllAllowed, Denied, and FailureAllowed" }, "rerunTimes": { "type": "integer", "minimum": 0, "description": "the maximum number of reruns allowed after a failure" }, "rerunInterval": { "type": "integer", "minimum": 0, "description": "the rerun interval. Unit: seconds" }, "datasource": { "type": "object", "description": "the configurations of the data source", "required": [ "name", "type" ], "properties": { "name": { "type": "string", "description": "the name of the data source" }, "type": { "type": "string", "enum": [ "odps" ], "description": "the type of the data source. Only MaxCompute data sources are supported" } } }, "script": { "type": "object", "description": "the script configurations of the node", "required": [ "path", "runtime" ], "properties": { "language": { "type": "string", "description": "the programming language of the script" }, "path": { "type": "string", "description": "the storage path of the script file. The storage path ends with the node name and does not require a file extension" }, "runtime": { "type": "object", "description": "the configurations of the runtime environment", "required": [ "command" ], "properties": { "command": { "type": "string", "enum": [ "ODPS_SQL" ], "Description": "the command" }, "cu": { "type": "string", "description": "the unit of the computing resource" } } } } }, "trigger": { "type": "object", "description": "the configurations of the node trigger", "required": [ "type" ], "properties": { "type": { "type": "string", "enum": [ "Scheduler", "Manual", "Streaming", "None" ], "description": "the trigger type. Valid values: Scheduler, Manual, Streaming, and None" }, "cron": { "type": "string", "description": "the cron expression, which is suitable for only auto triggered nodes" }, "startTime": { "type": "string", "format": "yyyy-MM-dd hh:mm:ss", "description": "the start time for scheduling" }, "endTime": { "type": "string", "format": "yyyy-MM-dd hh:mm:ss", "description": "the end time for scheduling" } } }, "runtimeResource": { "type": "object", "description": "the resource configurations for running", "required": [ "resourceGroup" ], "properties": { "resourceGroup": { "type": "string", "description": "the name of the resource group" } } }, "name": { "type": "string", "description": "the name of the node" }, "owner": { "type": "string", "description": "the node owner" }, "inputs": { "type": "object", "description": "the node input parameters", "properties": { "nodeOutputs": { "type": "array", "description": "the node dependencies", "items": { "type": "object", "required": [ "data" ], "properties": { "data": { "type": "string", "description": "the identifier of the node dependency" }, "refTableName": { "type": "string", "description": "the name of the table that is associated with the node. You must configure this parameter if the artifactType parameter is set to Table" }, "isDefault": { "type": "boolean", "description": "specifies whether the table is the default input table“ } } } } } }, "outputs": { "type": "object", "description": "the node output parameters", "properties": { "nodeOutputs": { "type": "array", "description": "the node dependencies", "items": { "type": "object", "required": [ "data" ], "properties": { "data": { "type": "string", "description": "the identifier of the node dependency" }, "refTableName": { "type": "string", "description": "the name of the table that is associated with the node. You must configure this parameter if the artifactType parameter is set to Table" }, "isDefault": { "type": "boolean", "description": "specifies whether the table is the default output table“ } } } } } } } } } } } } }

This parameter is required.', example='{
    "version": "1.1.0",
    "kind": "Node",
    "spec": {
        "nodes": [
            {
                "id": "860438872620113XXXX",
                "recurrence": "Normal",
                "timeout": 0,
                "instanceMode": "T+1",
                "rerunMode": "Allowed",
                "rerunTimes": 3,
                "rerunInterval": 180000,
                "datasource": {
                    "name": "odps_test",
                    "type": "odps"
                },
                "script": {
                    "path": "XX/OpenAPI_Test/odpsSQL_Test",
                    "runtime": {
                        "command": "ODPS_SQL"
                    },
                    "content": "select now();"
                },
                "trigger": {
                    "type": "Scheduler",
                    "cron": "00 00 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "runtimeResource": {
                    "resourceGroup": "S_res_group_XXXX_XXXX"
                },
                "name": "odpsSQL_Test",
                "inputs": {
                    "nodeOutputs": [
                        {
                            "data": "lwttest_standard_root",
                            "artifactType": "NodeOutput"
                        }
                    ]
                },
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "output_data",
                            "artifactType": "NodeOutput",
                            "refTableName": "odpsSQL_Test"
                        }
                    ]
                }
            }
        ],
        "flow": [
            {
                "nodeId": "860438872620113XXXX",
                "depends": [
                    {
                        "type": "Normal",
                        "output": "project_root"
                    }
                ]
            }
        ]
    }
}', position='Body'),
}

model UpdateNodeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can troubleshoot issues based on the ID.', example='99EBE7CF-69C0-5089-BE3E-79563C31XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateNodeResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateNode  UpdateNodeRequest
  * @return UpdateNodeResponse
 */
async function updateNode(request: UpdateNodeRequest): UpdateNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateNode', 'POST', '/', 'json', true, 'form', request);
}

model UpdateProjectRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  description?: string(name='Description', description='The description of the workspace.', example='Financial analysis group project data development', position='Body'),
  devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Specifies whether to enable the development environment. Valid values:

*   true: enables the development environment. In this case, the development environment is isolated from the production environment in the workspace.
*   false: disables the development environment. In this case, only the production environment is used in the workspace.', example='true', position='Body'),
  devRoleDisabled?: boolean(name='DevRoleDisabled', description='Specifies whether to disable the Develop role. Valid values:

*   false (default)
*   true

Note: If you disable the Develop role, you cannot assume the Develop role to develop nodes in workflows and edit node code. The Develop role cannot be enabled again after it is disabled.', example='true', position='Body'),
  displayName?: string(name='DisplayName', description='The display name of the workspace.', example='Sora financial analysis Space', position='Body'),
  id: long(name='Id', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the workspace management page to obtain the ID.

This parameter is used to determine the DataWorks workspaces used for this API call.

This parameter is required.', example='123456', position='Body'),
  paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Specifies whether to enable scheduling of Platform for AI (PAI) tasks. Valid values:

*   true: enables scheduling of PAI tasks. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: disables scheduling of PAI tasks.', example='true', position='Body'),
  status?: string(name='Status', description='Specifies whether to disable or enable the workspace. Valid values:

*   Available: enables the workspace.
*   Forbidden: disables the workspace.', example='Forbidden', position='Body'),
}

model UpdateProjectResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
}

model UpdateProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateProject  UpdateProjectRequest
  * @return UpdateProjectResponse
 */
async function updateProject(request: UpdateProjectRequest): UpdateProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateProject', 'POST', '/', 'json', true, 'form', request);
}

model UpdateResourceGroupRequest {
  regionId?: string(name='RegionId', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the new Alibaba Cloud resource group.', example='rg-aek2kqofrgXXXXX', position='Body'),
  id: string(name='Id', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
  name?: string(name='Name', description='The new name that you want to change for the resource group.', example='common_resource_group', position='Body'),
  remark?: string(name='Remark', description='The new remarks that you want to modify for the resource group.', example='Create a common resource group for common tasks', position='Body'),
}

model UpdateResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateResourceGroupResponseBody(name='body'),
}

/**
  * @description You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * @param request  the request parameters of UpdateResourceGroup  UpdateResourceGroupRequest
  * @return UpdateResourceGroupResponse
 */
async function updateResourceGroup(request: UpdateResourceGroupRequest): UpdateResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model UpdateRouteRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  destinationCidr: string(name='DestinationCidr', description='The destination CIDR block of the route that you want to update.

This parameter is required.', example='192.168.0.0/16', position='Body'),
  id: long(name='Id', description='The route ID of the network resource.

This parameter is required.', example='1000', position='Body'),
}

model UpdateRouteResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateRouteResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateRouteResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateRoute  UpdateRouteRequest
  * @return UpdateRouteResponse
 */
async function updateRoute(request: UpdateRouteRequest): UpdateRouteResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateRoute', 'POST', '/', 'json', true, 'form', request);
}

model UpdateTableBusinessMetadataRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The data table ID. You can call the ListTables operation to query the ID.

This parameter is required.', example='maxcompute-table:123456XXX::test_project::test_tbl
dlf-table:123456XXX:test_catalog:test_db::test_tbl
hms-table:c-abc123xxx::test_db::test_tbl
holo-table:h-abc123xxx::test_db:test_schema:test_tbl', position='Body'),
  readme?: string(name='Readme', example='## introduction', position='Body'),
}

model UpdateTableBusinessMetadataResponseBody = {
  requestId?: string(name='RequestId', example='7C352CB7-CD88-XXXXXXX'),
  success?: boolean(name='Success', example='true'),
}

model UpdateTableBusinessMetadataResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateTableBusinessMetadataResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateTableBusinessMetadata  UpdateTableBusinessMetadataRequest
  * @return UpdateTableBusinessMetadataResponse
 */
async function updateTableBusinessMetadata(request: UpdateTableBusinessMetadataRequest): UpdateTableBusinessMetadataResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateTableBusinessMetadata', 'POST', '/', 'json', true, 'form', request);
}

model UpdateTaskRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This code uniquely identifies a task. This parameter is used to create a task asynchronously and implement the idempotence of the task. If you do not specify this parameter when you create the task, the system automatically generates a unique code. The unique code is uniquely associated with the task ID. If you specify this parameter when you update or delete the task, the value of this parameter must be the unique code that is used to create the task.', example='Task_0bc5213917368545132902xxxxxxxx', position='Body'),
  dataSource?: {
    name?: string(name='Name', description='The name of the data source.', example='odps_test'),
  }(name='DataSource', description='The information about the associated data source.', shrink='json', position='Body'),
  dependencies?: [ 
    {
      type: string(name='Type', description='The dependency type. Valid values:

*   CrossCycleDependsOnChildren: cross-cycle dependency on level-1 descendant nodes
*   CrossCycleDependsOnSelf: cross-cycle dependency on the current node
*   CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
*   Normal: same-cycle scheduling dependency

This parameter is required.', example='Normal'),
      upstreamOutput?: string(name='UpstreamOutput', description='The identifier of the output of the ancestor task. This parameter is returned only if `same-cycle scheduling dependencies` and the node input are configured.', example='pre.odps_sql_demo_0'),
      upstreamTaskId?: long(name='UpstreamTaskId', description='The ancestor task ID. This parameter is returned only if `cross-cycle scheduling dependencies` or `same-cycle scheduling dependencies` and the node input are not configured.', example='1234'),
    }
  ](name='Dependencies', description='The dependency information.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description of the task.', example='test', position='Body'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Body'),
  inputs?: {
    variables?: [ 
      {
        name?: string(name='Name', description='The name of the variable.', example='key1'),
        type: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output

This parameter is required.', example='Constant'),
        value?: string(name='Value', description='The value of the variable.', example='value1'),
      }
    ](name='Variables', description='The variables.'),
  }(name='Inputs', description='The input information.', shrink='json', position='Body'),
  instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1', position='Body'),
  name: string(name='Name', description='The name.

This parameter is required.', example='SQL node', position='Body'),
  outputs?: {
    taskOutputs?: [ 
      {
        output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
      }
    ](name='TaskOutputs', description='The task outputs.'),
    variables?: [ 
      {
        name?: string(name='Name', description='The name of the variable.', example='key1'),
        type: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output

This parameter is required.', example='Constant'),
        value?: string(name='Value', description='The value of the variable.', example='value1'),
      }
    ](name='Variables', description='The variables.'),
  }(name='Outputs', description='The output information.', shrink='json', position='Body'),
  owner: string(name='Owner', description='The account ID of the task owner.

This parameter is required.', example='1000', position='Body'),
  rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60', position='Body'),
  rerunMode: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.

This parameter is required.', example='AllAllowed', position='Body'),
  rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3', position='Body'),
  runtimeResource: {
    cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
    image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
    resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.

This parameter is required.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
  }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.

This parameter is required.', shrink='json', position='Body'),
  script?: {
    content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
    parameters?: string(name='Parameters', description='The script parameters.', example='para1=$bizdate'),
  }(name='Script', description='The script information.', shrink='json', position='Body'),
  tags?: [ 
    {
      key: string(name='Key', description='The tag key.

This parameter is required.', example='key1'),
      value?: string(name='Value', description='The tag value.', example='value1'),
    }
  ](name='Tags', description='The tags.', shrink='json', position='Body'),
  timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600', position='Body'),
  trigger: {
    cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
    endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler. The value of this parameter is in the`yyyy-mm-dd hh:mm:ss` format.', example='9999-01-01 00:00:00'),
    recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
    startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler. The value of this parameter is in the`yyyy-mm-dd hh:mm:ss` format.', example='1970-01-01 00:00:00'),
    type: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger

This parameter is required.', example='Scheduler'),
  }(name='Trigger', description='The trigger method.

This parameter is required.', shrink='json', position='Body'),
}

model UpdateTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateTask  UpdateTaskRequest
  * @return UpdateTaskResponse
 */
async function updateTask(request: UpdateTaskRequest): UpdateTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateTask', 'POST', '/', 'json', true, 'form', request);
}

model UpdateTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  taskInstances?: [ 
    {
      dataSource?: {
        name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
      }(name='DataSource', description='The information about the associated data source.'),
      id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234'),
      priority?: int32(name='Priority', description='The priority of the instance. Valid values: 1, 3, 5, 7, and 8.

A larger value indicates a higher priority. Default value: 1.', example='1'),
      runtimeResource?: string(name='RuntimeResource', description='The resource group information. Set this parameter to the ID of a resource group for scheduling.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
    }
  ](name='TaskInstances', description='The instances.', shrink='json', position='Body'),
}

model UpdateTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model UpdateTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateTaskInstances  UpdateTaskInstancesRequest
  * @return UpdateTaskInstancesResponse
 */
async function updateTaskInstances(request: UpdateTaskInstancesRequest): UpdateTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model UpdateUdfFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  className: string(name='ClassName', description='This parameter is required.', example='com.alibaba.DataWorks.api.udf.StringConcat', position='Body'),
  cmdDescription?: string(name='CmdDescription', example='StringConcat(String... substrs)', position='Body'),
  example?: string(name='Example', example='StringConcat(\\"a\\", \\"b\\", \\"c\\")', position='Body'),
  fileFolderPath?: string(name='FileFolderPath', example='Business_process/First_Business_Process/function/string_processing_function', position='Body'),
  fileId: string(name='FileId', description='This parameter is required.', example='10000001', position='Body'),
  functionType: string(name='FunctionType', description='This parameter is required.', example='STRING', position='Body'),
  parameterDescription?: string(name='ParameterDescription', example='List of strings to be connected', position='Body'),
  projectId?: long(name='ProjectId', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', example='dw_project', position='Body'),
  resources: string(name='Resources', description='This parameter is required.', example='string-concat-1.0.0.jar,commons-lang-2.6.jar', position='Body'),
  returnValue?: string(name='ReturnValue', example='New strings generated by concatenating all strings before and after the input order', position='Body'),
  udfDescription?: string(name='UdfDescription', example='Concatenate several strings to generate a new string', position='Body'),
}

model UpdateUdfFileResponseBody = {
  errorCode?: string(name='ErrorCode', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', example='200'),
  requestId?: string(name='RequestId', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', example='true'),
}

model UpdateUdfFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateUdfFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateUdfFile  UpdateUdfFileRequest
  * @return UpdateUdfFileResponse
 */
async function updateUdfFile(request: UpdateUdfFileRequest): UpdateUdfFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateUdfFile', 'POST', '/', 'json', true, 'form', request);
}

model UpdateWorkflowRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a workflow asynchronously and implement the idempotence of the workflow. If you do not specify this parameter when you create the workflow, the system automatically generates a unique code. The unique code is uniquely associated with the workflow ID. If you specify this parameter when you update or delete the workflow, the value of this parameter must be the unique code that is used to create the workflow.', example='Workflow_0bc5213917368545132902xxxxxxxx', position='Body'),
  dependencies?: [ 
    {
      type: string(name='Type', description='The dependency type. Valid values:

*   CrossCycleDependsOnChildren: cross-cycle dependency on level-1 descendant nodes
*   CrossCycleDependsOnSelf: cross-cycle dependency on the current node
*   CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
*   Normal: same-cycle scheduling dependency

This parameter is required.', example='Normal'),
      upstreamOutput?: string(name='UpstreamOutput', description='The identifier of the output of the ancestor task. This parameter is returned only if `same-cycle scheduling dependencies` and the node input are configured.', example='pre.odps_sql_demo_0'),
      upstreamTaskId?: long(name='UpstreamTaskId', description='The ancestor task ID. This parameter is returned only if `cross-cycle scheduling dependencies` or `same-cycle scheduling dependencies` and the node input are not configured.', example='1234'),
    }
  ](name='Dependencies', description='The dependency information.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description.', example='test', position='Body'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  id: long(name='Id', description='The workflow ID.

This parameter is required.', example='1234', position='Body'),
  instanceMode?: string(name='InstanceMode', position='Body'),
  name: string(name='Name', description='The name of the workflow.

This parameter is required.', example='My Workflow', position='Body'),
  outputs?: {
    taskOutputs?: [ 
      {
        output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
      }
    ](name='TaskOutputs', description='The task outputs.'),
  }(name='Outputs', description='The output information.', shrink='json', position='Body'),
  owner: string(name='Owner', description='The account ID of the owner.

This parameter is required.', example='1000', position='Body'),
  parameters?: string(name='Parameters', description='The parameters.', example='para1=$bizdate para2=$[yyyymmdd]', position='Body'),
  tags?: [ 
    {
      key: string(name='Key', description='The tag key.

This parameter is required.', example='key1'),
      value?: string(name='Value', description='The tag value.', example='value1'),
    }
  ](name='Tags', description='The tags.', shrink='json', position='Body'),
  tasks?: [ 
    {
      baseLineId?: long(name='BaseLineId', description='The baseline ID.', example='1234'),
      clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a task asynchronously and implement the idempotence of the task. If you do not specify this parameter when you create the workflow, the system automatically generates a unique code. The unique code is uniquely associated with the workflow ID. If you specify this parameter when you update or delete the workflow, the value of this parameter must be the unique code that is used to create the workflow.', example='Task_0bc5213917368545132902xxxxxxxx'),
      dataSource?: {
        name?: string(name='Name', description='The name of the data source.', example='odps_test'),
      }(name='DataSource', description='The information about the associated data source.'),
      dependencies?: [ 
        {
          type: string(name='Type', description='The dependency type. Valid values:

*   CrossCycleDependsOnChildren: cross-cycle dependency on level-1 descendant nodes
*   CrossCycleDependsOnSelf: cross-cycle dependency on the current node
*   CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
*   Normal: same-cycle scheduling dependency

This parameter is required.', example='Normal'),
          upstreamOutput?: string(name='UpstreamOutput', description='The identifier of the output of the ancestor task. This parameter is returned only if `same-cycle scheduling dependencies` and the node input are configured.', example='pre.odps_sql_demo_0'),
          upstreamTaskId?: long(name='UpstreamTaskId', description='The ancestor task ID. This parameter is returned only if `cross-cycle scheduling dependencies` or `same-cycle scheduling dependencies` and the node input are not configured.', example='1234'),
        }
      ](name='Dependencies', description='The dependency information.'),
      description?: string(name='Description', description='The description.', example='Test'),
      envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
      id?: long(name='Id', description='The task ID. If you configure this parameter, full update is performed on the task. If you do not configure this parameter, another task is created.', example='1234'),
      inputs?: {
        variables?: [ 
          {
            name?: string(name='Name', description='The name of the variable.', example='key1'),
            type: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output

This parameter is required.', example='Constant'),
            value?: string(name='Value', description='The value of the variable.', example='value1'),
          }
        ](name='Variables', description='The variables.'),
      }(name='Inputs', description='The input information.'),
      name: string(name='Name', description='The name of the task.

This parameter is required.', example='SQL node'),
      outputs?: {
        taskOutputs?: [ 
          {
            output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
          }
        ](name='TaskOutputs', description='The task outputs.'),
        variables?: [ 
          {
            name?: string(name='Name', description='The name of the variable.', example='key1'),
            type: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output

This parameter is required.', example='Constant'),
            value?: string(name='Value', description='The value of the variable.', example='value1'),
          }
        ](name='Variables', description='The variables.'),
      }(name='Outputs', description='The output information.'),
      owner: string(name='Owner', description='The account ID of the owner.

This parameter is required.', example='1000'),
      rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
      rerunMode: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.

This parameter is required.', example='AllAllowed'),
      rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
      runtimeResource: {
        cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
        image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
        resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.

This parameter is required.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
      }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.

This parameter is required.'),
      script?: {
        content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
        parameters?: string(name='Parameters', description='The script parameters.', example='para1=$bizdate'),
      }(name='Script', description='The script information.'),
      tags?: [ 
        {
          key: string(name='Key', description='The tag key.

This parameter is required.', example='key1'),
          value?: string(name='Value', description='The tag value.', example='value1'),
        }
      ](name='Tags', description='The tags.'),
      timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
      trigger: {
        recurrence: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal

This parameter is required.', example='Normal'),
        type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
      }(name='Trigger', description='The trigger method.

This parameter is required.'),
      type: string(name='Type', description='The type of the task.

This parameter is required.', example='ODPS_SQL'),
    }
  ](name='Tasks', description='The tasks.', shrink='json', position='Body'),
  trigger: {
    cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
    endTime?: string(name='EndTime', description='The end time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler. The value of this parameter is in the `yyyy-mm-dd hh:mm:ss` format.', example='9999-01-01 00:00:00'),
    startTime?: string(name='StartTime', description='The start time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler. The value of this parameter is in the `yyyy-mm-dd hh:mm:ss` format.', example='1970-01-01 00:00:00'),
    type: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger

This parameter is required.', example='Scheduler'),
  }(name='Trigger', description='The trigger method.

This parameter is required.', shrink='json', position='Body'),
}

model UpdateWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateWorkflowResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateWorkflow  UpdateWorkflowRequest
  * @return UpdateWorkflowResponse
 */
async function updateWorkflow(request: UpdateWorkflowRequest): UpdateWorkflowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateWorkflow', 'POST', '/', 'json', true, 'form', request);
}

model UpdateWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='代表region的资源属性字段

This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10001', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the workflow. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
    "kind": "CycleWorkflow",
    "version": "1.1.0",
    "spec": {
        "name": "OpenAPI Test Workflow Demo",
        "type": "CycleWorkflow",
        "id": "652567824470354XXXX",
        "workflows": [
            {
                "id": "652567824470354XXXX",
                "script": {
                    "path": "XX/OpenAPI_Test/Workflow_Test/OpenAPI_Test_Workflow_Demo",
                    "runtime": {
                        "command": "WORKFLOW"
                    }
                },
                "trigger": {
                    "type": "Scheduler",
                    "cron": "00 02 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "strategy": {
                    "timeout": 0,
                    "instanceMode": "T+1",
                    "rerunMode": "Allowed",
                    "rerunTimes": 3,
                    "rerunInterval": 180000,
                    "failureStrategy": "Break"
                },
                "name": "OpenAPI Test Workflow Demo",
                "inputs": {},
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "workflow_output",
                            "artifactType": "NodeOutput",
                            "refTableName": "OpenAPI_Test_Workflow_Demo"
                        }
                    ]
                },
                "nodes": [],
                "dependencies": []
            }
        ]
    }
}', position='Body'),
}

model UpdateWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='20BF7E80-668A-5620-8AD8-879B8FEAXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @description >  You cannot use this API operation to create multiple workflows at a time. If you specify multiple workflows in the FlowSpec filed, only the first workflow is created. Other specified workflows and the nodes in the workflows are ignored. You can call the UpdateNode operation to update a node.
  * @param request  the request parameters of UpdateWorkflowDefinition  UpdateWorkflowDefinitionRequest
  * @return UpdateWorkflowDefinitionResponse
 */
async function updateWorkflowDefinition(request: UpdateWorkflowDefinitionRequest): UpdateWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model SuccessInfoValue = {
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
  message?: string(name='Message', description='The error message.', example='The task does not exist.'),
}

