/**
  *
  */
import BaseClientBuilder;
import TeaAsyncHandler;
import TeaRequest;
import AsyncRequestBody;
import RequestBody;
import AsyncResponseHandler;
import ClientConfiguration;
import ClientExecutionParams;
extends BaseClientBuilder;
type @product = string
type @version = string
type @endpointRule = string
type @endpointMap = map[string]string
type @REQUEST = TeaRequest
type @handler = TeaAsyncHandler

init(configuration: ClientConfiguration){
  @handler = new TeaAsyncHandler(configuration);
  @product = 'dataworks-public';
  @version = '2024-05-18';
  @endpointRule = 'regional';
  @endpointMap = {
    'ap-northeast-1' = 'dataworks.ap-northeast-1.aliyuncs.com',
    'ap-south-1' = 'dataworks.ap-south-1.aliyuncs.com',
    'ap-southeast-1' = 'dataworks.ap-southeast-1.aliyuncs.com',
    'ap-southeast-2' = 'dataworks.ap-southeast-2.aliyuncs.com',
    'ap-southeast-3' = 'dataworks.ap-southeast-3.aliyuncs.com',
    'ap-southeast-5' = 'dataworks.ap-southeast-5.aliyuncs.com',
    'cn-beijing' = 'dataworks.cn-beijing.aliyuncs.com',
    'cn-chengdu' = 'dataworks.cn-chengdu.aliyuncs.com',
    'cn-hangzhou' = 'dataworks.cn-hangzhou.aliyuncs.com',
    'cn-hongkong' = 'dataworks.cn-hongkong.aliyuncs.com',
    'cn-huhehaote' = 'dataworks.aliyuncs.com',
    'cn-qingdao' = 'dataworks.aliyuncs.com',
    'cn-shanghai' = 'dataworks.cn-shanghai.aliyuncs.com',
    'cn-shenzhen' = 'dataworks.cn-shenzhen.aliyuncs.com',
    'cn-zhangjiakou' = 'dataworks.aliyuncs.com',
    'eu-central-1' = 'dataworks.eu-central-1.aliyuncs.com',
    'eu-west-1' = 'dataworks.eu-west-1.aliyuncs.com',
    'me-east-1' = 'dataworks.me-east-1.aliyuncs.com',
    'us-east-1' = 'dataworks.us-east-1.aliyuncs.com',
    'us-west-1' = 'dataworks.us-west-1.aliyuncs.com',
    'cn-hangzhou-finance' = 'dataworks.aliyuncs.com',
    'cn-shenzhen-finance-1' = 'dataworks.aliyuncs.com',
    'cn-shanghai-finance-1' = 'dataworks.aliyuncs.com',
    'cn-north-2-gov-1' = 'dataworks.aliyuncs.com',
  };
}

function close(): void {
  @handler.close();
}

model Catalog {
  comment?: string(name='Comment'),
  createTime?: long(name='CreateTime'),
  id?: string(name='Id'),
  modifyTime?: long(name='ModifyTime'),
  name?: string(name='Name'),
  parentMetaEntityId?: string(name='ParentMetaEntityId'),
  type?: string(name='Type'),
}

model Column {
  businessMetadata?: {
    description?: string(name='Description', example='字段1的业务描述'),
  }(name='BusinessMetadata'),
  comment?: string(name='Comment', example='字段1'),
  foreignKey?: boolean(name='ForeignKey', example='false'),
  id?: string(name='Id', example='maxcompute-column:123456::test_project:default:test_tbl:col1'),
  name?: string(name='Name', example='col1'),
  partitionKey?: boolean(name='PartitionKey', example='false'),
  position?: int32(name='Position', example='1'),
  primaryKey?: boolean(name='PrimaryKey', example='false'),
  tableId?: string(name='TableId', example='maxcompute-table:123456::test_project:default:test_tbl'),
  type?: string(name='Type', example='bigint'),
}

model CrawlerType {
  displayName?: string(name='DisplayName', example='Data Lake Formation'),
  supportedEntityTypes?: [ 
    {
      optional?: boolean(name='Optional', example='如对于maxcompute-schema类型，schema层级是否存在可选（是否开启三层模型）'),
      parentSubType?: string(name='ParentSubType', example='database'),
      subType?: string(name='SubType', example='table'),
      type?: string(name='Type', example='dlf-table'),
    }
  ](name='SupportedEntityTypes'),
  type?: string(name='Type', example='dlf'),
}

model DataQualityEvaluationTask {
  dataSourceId?: long(name='DataSourceId', example='201'),
  description?: string(name='Description', example='This is a daily run data quality evaluation plan.'),
  hooks?: [ 
    {
      condition?: string(name='Condition', example='${severity} == "High" AND ${status} == "Critical"'),
      type?: string(name='Type', example='BlockTaskInstance'),
    }
  ](name='Hooks'),
  id?: long(name='Id', example='10001'),
  name?: string(name='Name', example='质量校验任务'),
  notifications?: [ 
    {
      condition?: string(name='Condition', example='${blockType} == "Strong"'),
      notifications?: [ 
        {
          notificationChannels?: [ 
            {
              channels?: [ string ](name='Channels'),
            }
          ](name='NotificationChannels'),
          notificationReceivers?: [ 
            {
              extension?: string(name='Extension', example='{"atAll":"true"}'),
              receiverType?: string(name='ReceiverType', example='AliUid'),
              receiverValues?: [ string ](name='ReceiverValues'),
            }
          ](name='NotificationReceivers'),
        }
      ](name='Notifications'),
    }
  ](name='Notifications'),
  projectId?: long(name='ProjectId', example='100'),
  runtimeConf?: string(name='RuntimeConf', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }'),
  target?: {
    databaseType?: string(name='DatabaseType', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', example='ds=$[yyyymmdd-1]'),
    tableGuid?: string(name='TableGuid', example='odps.unit_test.tb_unit_test'),
    type?: string(name='Type', example='Table'),
  }(name='Target'),
  tenantId?: long(name='TenantId', example='10'),
  trigger?: {
    taskIds?: [ long ](name='TaskIds'),
    type?: string(name='Type', example='ByScheduledTaskInstance'),
  }(name='Trigger'),
}

model DataQualityEvaluationTaskInstance {
  createTime?: long(name='CreateTime', example='1710239005403'),
  finishTime?: long(name='FinishTime', example='1710239005403'),
  id?: long(name='Id', example='10001'),
  status?: string(name='Status', example='Passed'),
  task?: {
    dataSourceId?: long(name='DataSourceId', example='201'),
    hooks?: [ 
      {
        condition?: string(name='Condition', example='${severity} == "High" AND ${status} == "Critical"'),
        type?: string(name='Type', example='BlockTaskInstance'),
      }
    ](name='Hooks'),
    id?: long(name='Id', example='10001'),
    name?: string(name='Name', example='质量校验任务'),
    notifications?: [ 
      {
        condition?: string(name='Condition', example='${blockType} == "Strong"'),
        notifications?: [ 
          {
            notificationChannels?: [ 
              {
                channels?: [ string ](name='Channels'),
              }
            ](name='NotificationChannels'),
            notificationReceivers?: [ 
              {
                extension?: string(name='Extension', example='{"atAll":"true"}'),
                receiverType?: string(name='ReceiverType', example='AliUid'),
                receiverValues?: [ string ](name='ReceiverValues'),
              }
            ](name='NotificationReceivers'),
          }
        ](name='Notifications'),
      }
    ](name='Notifications'),
    projectId?: long(name='ProjectId'),
    runtimeConf?: string(name='RuntimeConf', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }'),
    target?: {
      databaseType?: string(name='DatabaseType', example='maxcompute'),
      partitionSpec?: string(name='PartitionSpec', example='ds=$[yyyymmdd-1]'),
      tableGuid?: string(name='TableGuid', example='odps.unit_test.tb_unit_test'),
      type?: string(name='Type', example='Table'),
    }(name='Target'),
    tenantId?: long(name='TenantId'),
    trigger?: {
      taskIds?: [ long ](name='TaskIds'),
      type?: string(name='Type', example='ByScheduledTaskInstance'),
    }(name='Trigger'),
  }(name='Task'),
}

model DataQualityResult {
  details?: [ 
    {
      checkedValue?: string(name='CheckedValue', example='100.0'),
      referencedValue?: string(name='ReferencedValue', example='0.0'),
      status?: string(name='Status', example='Passed'),
    }
  ](name='Details'),
  id?: long(name='Id', example='10001'),
  rule?: {
    checkingConfig?: {
      referencedSamplesFilter?: string(name='ReferencedSamplesFilter', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
      thresholds?: {
        critical?: {
          operator?: string(name='Operator', example='>'),
          value?: string(name='Value', example='100.0'),
        }(name='Critical'),
        expected?: {
          operator?: string(name='Operator', example='>'),
          value?: string(name='Value', example='100.0'),
        }(name='Expected'),
        warned?: {
          operator?: string(name='Operator', example='>'),
          value?: string(name='Value', example='100.0'),
        }(name='Warned'),
      }(name='Thresholds'),
      type?: string(name='Type', example='Fixed'),
    }(name='CheckingConfig'),
    description?: string(name='Description', example='this is a odps _sql task'),
    enabled?: boolean(name='Enabled', example='true'),
    errorHandlers?: [ 
      {
        errorDataFilter?: string(name='ErrorDataFilter', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
        type?: string(name='Type', example='SaveErrorData'),
      }
    ](name='ErrorHandlers'),
    id?: long(name='Id', example='100001'),
    name?: string(name='Name', example='表不能为空'),
    projectId?: long(name='ProjectId', example='100'),
    samplingConfig?: {
      metric?: string(name='Metric', example='Min'),
      metricParameters?: string(name='MetricParameters', example='{ "Columns": [ "id", "name" ] }'),
      samplingFilter?: string(name='SamplingFilter', example='id IS NULL'),
      settingConfig?: string(name='SettingConfig', example='SET odps.sql.udf.timeout=600s;'),
    }(name='SamplingConfig'),
    severity?: string(name='Severity', example='High'),
    target?: {
      databaseType?: string(name='DatabaseType', example='maxcompute'),
      partitionSpec?: string(name='PartitionSpec', example='ds=$[yyyymmdd-1]'),
      tableGuid?: string(name='TableGuid', example='odps.unit_test.tb_unit_test'),
      type?: string(name='Type', example='Table'),
    }(name='Target'),
    templateCode?: string(name='TemplateCode', example='SYSTEM:user_defined_sql'),
    tenantId?: long(name='TenantId', example='1'),
  }(name='Rule'),
  sample?: string(name='Sample', example='[   {     "gender": "male",     "_count": 100   }, {     "gender": "female",     "_count": 100   } ]'),
  status?: string(name='Status', example='Passed'),
  taskInstanceId?: long(name='TaskInstanceId', example='20001'),
}

model DataQualityRule {
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    thresholds?: {
      critical?: {
        expression?: string(name='Expression', example='波动率类型规则使用，通过表达式来表示波动阈值。如：波动上升大于0.01： $checkValue > 0.01  波动下降大于0.01：$checkValue < -0.01   波动率绝对值：abs($checkValue) > 0.01'),
        operator?: string(name='Operator', example='>'),
        value?: string(name='Value', example='100.0'),
      }(name='Critical'),
      expected?: {
        expression?: string(name='Expression', example='波动率类型规则使用，通过表达式来表示波动阈值。如：波动上升大于0.01： $checkValue > 0.01  波动下降大于0.01：$checkValue < -0.01   波动率绝对值：abs($checkValue) > 0.01'),
        operator?: string(name='Operator', example='>'),
        value?: string(name='Value', example='100.0'),
      }(name='Expected'),
      warned?: {
        expression?: string(name='Expression', example='波动率类型规则使用，通过表达式来表示波动阈值。如：波动上升大于0.01： $checkValue > 0.01  波动下降大于0.01：$checkValue < -0.01   波动率绝对值：abs($checkValue) > 0.01'),
        operator?: string(name='Operator', example='>'),
        value?: string(name='Value', example='100.0'),
      }(name='Warned'),
    }(name='Thresholds'),
    type?: string(name='Type', example='Fixed'),
  }(name='CheckingConfig'),
  description?: string(name='Description', example='this is a odps _sql task'),
  enabled?: boolean(name='Enabled', example='true'),
  errorHandlers?: [ 
    {
      errorDataFilter?: string(name='ErrorDataFilter', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
      type?: string(name='Type', example='SaveErrorData'),
    }
  ](name='ErrorHandlers'),
  id?: long(name='Id', example='1'),
  name?: string(name='Name', example='表不能为空'),
  projectId?: long(name='ProjectId', example='100'),
  samplingConfig?: {
    metric?: string(name='Metric', example='Min'),
    metricParameters?: string(name='MetricParameters', example='{ "Columns": [ "id", "name" ] }'),
    samplingFilter?: string(name='SamplingFilter', example='id IS NULL'),
    settingConfig?: string(name='SettingConfig', example='SET odps.sql.udf.timeout=600s;'),
  }(name='SamplingConfig'),
  severity?: string(name='Severity', example='High'),
  target?: {
    databaseType?: string(name='DatabaseType', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', example='ds=$[yyyymmdd-1]'),
    tableGuid?: string(name='TableGuid', example='odps.unit_test.tb_unit_test'),
    type?: string(name='Type', example='Table'),
  }(name='Target'),
  templateCode?: string(name='TemplateCode', example='SYSTEM:user_defined_sql'),
  tenantId?: long(name='TenantId', example='1'),
}

model DataQualityRuleTemplate {
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    type?: string(name='Type', example='Fixed'),
  }(name='CheckingConfig'),
  code?: string(name='Code'),
  directoryPath?: string(name='DirectoryPath', example='/ods/订单数据'),
  name?: string(name='Name'),
  projectId?: long(name='ProjectId'),
  samplingConfig?: {
    metric?: string(name='Metric', example='Min'),
    metricParameters?: string(name='MetricParameters', example='{ "SQL": "SELECT min(id) from table;" }'),
    settingConfig?: string(name='SettingConfig', example='SET odps.sql.udf.timeout=600s;'),
  }(name='SamplingConfig'),
  tenantId?: long(name='TenantId'),
  visibleScope?: string(name='VisibleScope', example='Project'),
}

model Database {
  comment?: string(name='Comment', example='test comment'),
  createTime?: long(name='CreateTime', example='1736852168000'),
  id?: string(name='Id', example='holo-database:h-xxxx::test_db'),
  locationUri?: string(name='LocationUri', example='oss://test-bucket/test_db'),
  modifyTime?: long(name='ModifyTime', example='1736852168000'),
  name?: string(name='Name', example='test_db'),
  parentMetaEntityId?: string(name='ParentMetaEntityId', example='holo:h-xxxx'),
}

model Dataset {
  comment?: string(name='Comment'),
  createTime?: long(name='CreateTime'),
  creatorId?: string(name='CreatorId'),
  dataType?: string(name='DataType'),
  id?: string(name='Id'),
  labels?: [
    DatasetLabel
  ](name='Labels'),
  latestVersion?: DatasetVersion(name='LatestVersion'),
  modifyTime?: long(name='ModifyTime'),
  name?: string(name='Name'),
  origin?: string(name='Origin'),
  projectId?: long(name='ProjectId'),
  readme?: string(name='Readme'),
  storageType?: string(name='StorageType'),
}

model DatasetLabel {
  key?: string(name='Key'),
  value?: string(name='Value'),
}

model DatasetVersion {
  comment?: string(name='Comment'),
  createTime?: long(name='CreateTime'),
  creatorId?: string(name='CreatorId'),
  datasetId?: string(name='DatasetId'),
  id?: string(name='Id'),
  importInfo?: map[string]string(name='ImportInfo'),
  labels?: [
    DatasetLabel
  ](name='Labels'),
  modifyTime?: long(name='ModifyTime'),
  mountPath?: string(name='MountPath'),
  storageType?: string(name='StorageType'),
  url?: string(name='Url'),
  versionNumber?: int32(name='VersionNumber'),
}

model IdentifyCredential {
  dataSource?: {
    instanceId?: string(name='InstanceId'),
    instanceName?: string(name='InstanceName'),
    password?: string(name='Password'),
    role?: string(name='Role'),
    type?: string(name='Type'),
    userName?: string(name='UserName'),
  }(name='DataSource'),
  projectId?: string(name='ProjectId'),
  userId?: string(name='UserId'),
  userType?: string(name='UserType'),
}

model LineageEntity {
  attributes?: map[string]string(name='Attributes', example='{"key1":"value1"}'),
  id?: string(name='Id', example='maxcompute-table:123456::test_project::test_tbl'),
  name?: string(name='Name', example='test_tbl'),
}

model LineageRelationship {
  createTime?: long(name='CreateTime', example='1743040581000'),
  dstEntity?: LineageEntity(name='DstEntity'),
  id?: string(name='Id', example='maxcompute-table.p.table:custom-table.xxx:custom-sql.123'),
  srcEntity?: LineageEntity(name='SrcEntity'),
  task?: LineageTask(name='Task'),
}

model LineageTask {
  attributes?: map[string]string(name='Attributes'),
  id?: string(name='Id', example='12345'),
  type?: string(name='Type', example='custom-sql'),
}

model Partition {
  createTime?: long(name='CreateTime', example='1700192563000'),
  dataSize?: long(name='DataSize', example='4096'),
  modifyTime?: long(name='ModifyTime', example='1700192563000'),
  name?: string(name='Name', example='ds=20250101'),
  recordCount?: long(name='RecordCount', example='1000000'),
  tableId?: string(name='TableId', example='maxcompute-table:accountId::project::table'),
}

model Schema {
  comment?: string(name='Comment', example='test comment'),
  createTime?: long(name='CreateTime', example='1736852168000'),
  id?: string(name='Id', example='maxcompute-schema:123456::test_project:default'),
  modifyTime?: long(name='ModifyTime', example='1736852168000'),
  name?: string(name='Name', example='test_db'),
  parentMetaEntityId?: string(name='ParentMetaEntityId', example='maxcompute-project:123456::test_project'),
  type?: string(name='Type', example='MANAGED'),
}

model Table {
  businessMetadata?: {
    categories?: [[ 
      {
        id?: string(name='Id', example='CATEGORY.456'),
        name?: string(name='Name', example='测试类目'),
        parentId?: string(name='ParentId', example='CATEGORY.123'),
      }
    ]    ](name='Categories'),
    extension?: {
      envType?: string(name='EnvType', example='Dev'),
      favorCount?: long(name='FavorCount', example='0'),
      projectId?: long(name='ProjectId', example='234'),
      readCount?: long(name='ReadCount', example='0'),
      viewCount?: long(name='ViewCount', example='0'),
    }(name='Extension'),
    readme?: string(name='Readme', example='## 使用说明'),
    tags?: [ 
      {
        key?: string(name='Key', example='tag_key'),
        value?: string(name='Value', example='tag_value'),
      }
    ](name='Tags'),
    upstreamTasks?: [ 
      {
        id?: long(name='Id', example='123456'),
        name?: string(name='Name', example='test_task'),
      }
    ](name='UpstreamTasks'),
  }(name='BusinessMetadata'),
  comment?: string(name='Comment', example='测试表'),
  createTime?: long(name='CreateTime', example='1736852168000'),
  id?: string(name='Id', example='maxcompute-table:123456::test_project::test_tbl'),
  modifyTime?: long(name='ModifyTime', example='1736852168000'),
  name?: string(name='Name', example='test_tbl'),
  parentMetaEntityId?: string(name='ParentMetaEntityId', example='maxcompute-project:123456::test_project'),
  partitionKeys?: [ string ](name='PartitionKeys'),
  tableType?: string(name='TableType', example='TABLE'),
  technicalMetadata?: {
    compressed?: boolean(name='Compressed', example='false'),
    inputFormat?: string(name='InputFormat', example='org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'),
    location?: string(name='Location', example='oss://test-bucket/test_tbl'),
    outputFormat?: string(name='OutputFormat', example='org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'),
    owner?: string(name='Owner', example='123456789'),
    parameters?: map[string]string(name='Parameters'),
    serializationLibrary?: string(name='SerializationLibrary', example='org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'),
  }(name='TechnicalMetadata'),
}

model AbolishPipelineRunRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID of the process.

This parameter is required.', example='1606087c-9ac4-43f0-83a8-0b5ced21XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model AbolishPipelineRunResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='55D786C9-DD57-524D-884C-C5239278XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model AbolishPipelineRunResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AbolishPipelineRunResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AbolishPipelineRun  AbolishPipelineRunRequest
  * @return AbolishPipelineRunResponse
 */
async function abolishPipelineRun(request: AbolishPipelineRunRequest): AbolishPipelineRunResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AbolishPipelineRun', 'POST', '/', 'json', true, 'form', request);
}

model AddEntityIntoMetaCollectionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The entity ID. Currently, only table entities are supported. You can call the ListTables operation to obtain the ID.

This parameter is required.', example='maxcompute-table', position='Query'),
  metaCollectionId: string(name='MetaCollectionId', description='The collection ID. You can refer to the return result of the ListMetaCollections operation.

This parameter is required.', example='category.123', position='Query'),
  remark?: string(name='Remark', description='Remarks added when adding the entity to a collection. This parameter is currently valid only for album collections.', example='test', position='Query'),
}

model AddEntityIntoMetaCollectionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADE490'),
}

model AddEntityIntoMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddEntityIntoMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AddEntityIntoMetaCollection  AddEntityIntoMetaCollectionRequest
  * @return AddEntityIntoMetaCollectionResponse
 */
async function addEntityIntoMetaCollection(request: AddEntityIntoMetaCollectionRequest): AddEntityIntoMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddEntityIntoMetaCollection', 'POST', '/', 'json', false, 'json', request);
}

model AssociateProjectToResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace with which you want to associate the resource group.

This parameter is required.', example='1000', position='Body'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
}

model AssociateProjectToResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to locate logs and troubleshoot issues.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model AssociateProjectToResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AssociateProjectToResourceGroupResponseBody(name='body'),
}

/**
  * @description 1.  You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * 2.  Your account must be assigned one of the following roles of the desired workspace:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of AssociateProjectToResourceGroup  AssociateProjectToResourceGroupRequest
  * @return AssociateProjectToResourceGroupResponse
 */
async function associateProjectToResourceGroup(request: AssociateProjectToResourceGroupRequest): AssociateProjectToResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AssociateProjectToResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model AttachDataQualityRulesToEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityEvaluationTaskId: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task that is associated with the rule.

This parameter is required.', example='200001', position='Body'),
  dataQualityRuleIds: [ long ](name='DataQualityRuleIds', description='The IDs of the monitoring rules.

This parameter is required.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID. You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model AttachDataQualityRulesToEvaluationTaskResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='E6F0DBDD-5AD8-4870-A6A0'),
  success?: boolean(name='Success', description='The value of the association is as follows:
- true: The call is successful.
- false: the call failed.', example='true'),
}

model AttachDataQualityRulesToEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AttachDataQualityRulesToEvaluationTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AttachDataQualityRulesToEvaluationTask  AttachDataQualityRulesToEvaluationTaskRequest
  * @return AttachDataQualityRulesToEvaluationTaskResponse
 */
async function attachDataQualityRulesToEvaluationTask(request: AttachDataQualityRulesToEvaluationTaskRequest): AttachDataQualityRulesToEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AttachDataQualityRulesToEvaluationTask', 'POST', '/', 'json', true, 'form', request);
}

model BatchUpdateTasksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  tasks?: [ 
    {
      dataSource?: {
        name?: string(name='Name', description='The data source name.', example='odps_test'),
      }(name='DataSource', description='Associated data source information.'),
      description?: string(name='Description', description='The description.', example='test'),
      envType?: string(name='EnvType', description='The project environment.

*   Prod: Production
*   Dev: Development', example='Prod'),
      id: long(name='Id', description='The task ID.

This parameter is required.', example='1234'),
      name?: string(name='Name', description='The name.', example='SQL node'),
      owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
      rerunInterval?: int32(name='RerunInterval', description='The retry interval in seconds.', example='60'),
      rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun.
*   FailureAllowed: The task can be rerun only after it fails.
*   AllAllowed: The task can always be rerun.', example='AllAllowed'),
      rerunTimes?: int32(name='RerunTimes', description='The number of retry attempts. Takes effect when the task is configured to allow reruns.', example='3'),
      runtimeResource?: {
        cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
        image?: string(name='Image', description='The image ID used in the task runtime configuration.', example='i-xxxxxx'),
        resourceGroupId?: string(name='ResourceGroupId', description='The identifier of the scheduling resource group used in the task runtime configuration.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
      }(name='RuntimeResource', description='Runtime environment configurations, such as resource group information.'),
      tags?: [ 
        {
          key: string(name='Key', description='The tag key.

This parameter is required.', example='key1'),
          value?: string(name='Value', description='The tag value.', example='value1'),
        }
      ](name='Tags', description='The list of task tags.'),
      timeout?: int32(name='Timeout', description='The task execution timeout in seconds. The value should be greater than 3600.', example='3600'),
      trigger?: {
        cron?: string(name='Cron', description='The cron expression. Takes effect when type=Scheduler.', example='00 00 00 * * ?'),
        endTime?: string(name='EndTime', description='The expiration time of periodic triggering. Takes effect only when type is set to Scheduler. The value of this parameter is in the`yyyy-mm-dd hh:mm:ss` format.', example='9999-01-01 00:00:00'),
        recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        startTime?: string(name='StartTime', description='The time when periodic triggering takes effect. This parameter takes effect only if the Type parameter is set to Scheduler. The value of this parameter is in the `yyyy-mm-dd hh:mm:ss` format.', example='1970-01-01 00:00:00'),
        type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: periodically triggered
*   Manual', example='Scheduler'),
      }(name='Trigger', description='The task trigger configurations.'),
    }
  ](name='Tasks', description='The list of tasks.', shrink='json', position='Body'),
}

model BatchUpdateTasksResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The task ID serves as a key, and the result serves as a value.'),
}

model BatchUpdateTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: BatchUpdateTasksResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of BatchUpdateTasks  BatchUpdateTasksRequest
  * @return BatchUpdateTasksResponse
 */
async function batchUpdateTasks(request: BatchUpdateTasksRequest): BatchUpdateTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'BatchUpdateTasks', 'POST', '/', 'json', true, 'form', request);
}

model CloneDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  cloneDataSourceName: string(name='CloneDataSourceName', description='The name of the destination data source The name can contain letters, digits, and underscores (_), and must start with a letter. It cannot exceed 60 characters in length.

This parameter is required.', example='demo_holo_datasource', position='Query'),
  id: long(name='Id', description='The data source ID.

This parameter is required.', example='16036', position='Query'),
}

model CloneDataSourceResponseBody = {
  id?: long(name='Id', description='The ID of the cloned data source.', example='19715'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='FCD583B9-346B-5E75-82C1-4A7C192C48DB'),
}

model CloneDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CloneDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of CloneDataSource  CloneDataSourceRequest
  * @return CloneDataSourceResponse
 */
async function cloneDataSource(request: CloneDataSourceRequest): CloneDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CloneDataSource', 'POST', '/', 'json', false, 'json', request);
}

model CreateAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  enabled: boolean(name='Enabled', description='Indicates whether the rule is enabled.

This parameter is required.', example='true', position='Query'),
  name: string(name='Name', description='The name of the rule.

This parameter is required.', example='xm_create_test', position='Query'),
  notification?: {
    channels: [ string ](name='Channels', description='The alert notification channels.

This parameter is required.'),
    intervalInMinutes?: int32(name='IntervalInMinutes', description='The interval at which an alert notification is sent. Unit: minutes. Valid values: [5,10000].', example='30'),
    maximum?: int32(name='Maximum', description='The maximum number of times an alert notification can be sent within a calendar day. Valid values: [1, 10000].', example='3'),
    receivers: [ 
      {
        extension?: string(name='Extension', description='The additional configuration of the alert recipient. If the ReceiverType parameter is set to DingdingUrl, you can set this parameter to {"atAll":true} to remind all members in a DingTalk group.', example='{"atAll":true}'),
        receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid valves:

*   AliUid: Alibaba Cloud account ID.
*   Shift Schedules: the personnel in a shift schedule.
*   TaskOwner: the task owner. The task owner can receive custom alerts and event alerts.
*   Owner: the baseline owner. The baseline owner can receive baseline alerts.
*   WebhookUrl: URL of a custom webhook.
*   DingdingUrl: DingTalk webhook URL.
*   FeishuUrl: Lark webhook URL.
*   WeixinUrl: WeCom webhook URL.', example='TaskOwner'),
        receiverValues?: [ string ](name='ReceiverValues', description='The ID of the alert recipient.'),
      }
    ](name='Receivers', description='The alert recipients.

This parameter is required.'),
    silenceEndTime?: string(name='SilenceEndTime', description='The end time for silence. The time is in the HH:mm format.', example='00:00:00'),
    silenceStartTime?: string(name='SilenceStartTime', description='The start time for silence. The time is in the HH:mm format.', example='00:00:00'),
  }(name='Notification', description='The configuration for the alert notification.', shrink='json', position='Query'),
  owner: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.

This parameter is required.', example='279114181716147735', position='Query'),
  triggerCondition: {
    extension?: {
      cycleUnfinished?: {
        cycleAndTime?: [ 
          {
            cycleId?: int32(name='CycleId', description='The ID of the scheduling cycle of the instance. Valid values: [1,288].', example='1'),
            time?: string(name='Time', description='The latest completion time of the instance within the scheduling cycle. The time is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
          }
        ](name='CycleAndTime', description='The configurations of the scheduling cycle and timeout period of the instance.'),
      }(name='CycleUnfinished', description='The configuration for an alert of the CycleUnfinished type.'),
      error?: {
        autoRerunAlertEnabled?: boolean(name='AutoRerunAlertEnabled', description='Specifies whether to trigger an alert if a batch synchronization task is automatically rerun upon a failure.', example='false'),
        streamTaskIds?: [ long ](name='StreamTaskIds', description='The IDs of the real-time computing tasks. This parameter is required when you monitor real-time computing tasks.'),
      }(name='Error', description='The configuration for an alert of the Error type.'),
      instanceErrorCount?: {
        count?: int32(name='Count', description='The maximum number of instances on which an error occurs. Valid values: [1,10000].', example='5'),
      }(name='InstanceErrorCount', description='The configuration for an alert of the InstanceErrorCount type.'),
      instanceErrorPercentage?: {
        percentage?: int32(name='Percentage', description='The maximum percentage of instances on which an error occurs in the workspace to the total number of instances. Valid values: [1-100].', example='5'),
      }(name='InstanceErrorPercentage', description='The configuration for an alert of the InstanceErrorPercentage type.'),
      instanceTransferFluctuate?: {
        percentage?: int32(name='Percentage', description='The maximum percentage of fluctuation in the number of auto triggered node instances that are generated in your workspace. Valid values: [1-100].', example='10'),
        trend?: string(name='Trend', description='The way in which the number of auto triggered node instances that are generated in your workspace fluctuates. Valid values:

*   abs: the absolute value. The number of instances increases or decreases.
*   increase: The number of instances increases.
*   decrease: The number of instances decreases.', example='abs'),
      }(name='InstanceTransferFluctuate', description='The configuration for an alert of the InstanceTransferFluctuate type.'),
      timeout?: {
        timeoutInMinutes?: int32(name='TimeoutInMinutes', description='The timeout period. Unit: minutes. Valid values: [1, 21600].', example='10'),
      }(name='Timeout', description='The configuration for an alert of the Timeout type.'),
      unFinished?: {
        unFinishedTime?: string(name='UnFinishedTime', description='The latest completion time of the instance. The period is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='30:00'),
      }(name='UnFinished', description='The configuration for an alert of the UnFinished type.'),
    }(name='Extension', description='The extended information about the rule. This parameter is required for specific types of alerts.'),
    target?: {
      allowTasks?: [ long ](name='AllowTasks', description='The nodes that are not to be monitored.'),
      ids?: [ long ](name='Ids', description='The IDs of monitored objects.'),
      type?: string(name='Type', description='The type of the monitored objects. Valid values:

*   Task: node
*   Baseline: baseline
*   Project: workspace
*   BizProcess: workflow', example='Task'),
    }(name='Target', description='The monitored objects.'),
    type?: string(name='Type', description='The alert type. Valid values:

*   Finished: An instance is successfully run.
*   UnFinished: An instance does not finish running before a specified point in time.
*   Error: An error occurs on an instance.
*   CycleUnfinished: An instance does not finish running as expected within a specific cycle.
*   Timeout: An instance times out.
*   InstanceTransferComplete: An instance is generated by the auto triggered node.
*   InstanceTransferFluctuate: The number of generated instances fluctuates.
*   ExhaustedError: An error persists after an instance is automatically rerun.
*   InstanceKeyword: An instance with errors contains specified keywords.
*   InstanceErrorCount: The number of instances on which an error occurs reaches a specified threshold.
*   InstanceErrorPercentage: The proportion of instances on which an error occurs in the workspace to the total number of instances reaches a specified threshold.
*   ResourceGroupPercentage: The usage rate of the resource group reaches a specified threshold.
*   ResourceGroupWaitCount: The number of instances that are waiting for resources in the resource group reaches a specified threshold.', example='Error'),
  }(name='TriggerCondition', description='The alert triggering condition.

This parameter is required.', shrink='json', position='Query'),
}

model CreateAlertRuleResponseBody = {
  id?: long(name='Id', description='The rule ID.', example='123123'),
  requestId?: string(name='RequestId', description='The request ID.', example='A6C6B486-E3A2-5D52-9E76-D9380485D946'),
}

model CreateAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateAlertRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateAlertRule  CreateAlertRuleRequest
  * @return CreateAlertRuleResponse
 */
async function createAlertRule(request: CreateAlertRuleRequest): CreateAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateAlertRule', 'POST', '/', 'json', false, 'json', request);
}

model CreateBusinessRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  businessName: string(name='BusinessName', description='The name of the workflow. Workflow names must be unique within the same workspace.

This parameter is required.', example='My business process', position='Body'),
  description?: string(name='Description', description='The description of the workflow.', example='test', position='Body'),
  owner?: string(name='Owner', description='The Alibaba Cloud account ID of the person responsible for the workflow. You can view the account ID by hovering over the user avatar in the top-right corner of the [DataWorks console](https://workbench.data.aliyun.com/console). If this parameter is not specified, the account ID of the API caller is used by default.', example='1000000000001', position='Body'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace. You can view the workspace ID on the workspace management page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The unique identifier of the DataWorks workspace, This is the identifier shown in the workspace switch at the top of the Data Studio page. Either this parameter or ProjectId must be specified to determine which DataWorks project this API call operates on.', example='dw_project', position='Body'),
  useType?: string(name='UseType', description='The module to which the workflow belongs. Valid values:

*   NORMAL: Data Studio
*   MANUAL_BIZ: Manually triggered workflow', example='NORMAL', position='Body'),
}

model CreateBusinessResponseBody = {
  businessId?: long(name='BusinessId', description='The workflow ID.', example='100001'),
  errorCode?: string(name='ErrorCode', description='The error code.

*   Request succeeded: The ErrorCode field is not returned.
*   Request failed: The ErrorCode field is returned.

For more information, see the error code section.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The unique ID of this request. You can troubleshoot issues based on the ID.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the call succeeded. Valid values:

*   true
*   false', example='true'),
}

model CreateBusinessResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateBusinessResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateBusiness  CreateBusinessRequest
  * @return CreateBusinessResponse
 */
async function createBusiness(request: CreateBusinessRequest): CreateBusinessResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateBusiness', 'POST', '/', 'json', true, 'form', request);
}

model CreateComponentRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='1AFAE64E-D1BE-432B-A9****', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can call the [ListProjects](https://help.aliyun.com/document_detail/2852607.html) operation to obtain the ID.

This parameter is required.', example='10000', position='Body'),
  spec: string(name='Spec', description='The FlowSpec information for this UDF function. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
    "kind": "Component",
    "name": "com1",
    "spec": {
        "components": [
            {
                "name": "test11",
                "id": "1234",
                "owner": "1234456",
                "description": "",
                "script": {
                    "language": "odps-sql",
                    "path": "test11",
                    "content": "select \\"@@{bizdate}\\", \\"@@{my_input_table}\\"",
                    "runtime": {
                        "command": "SQL_COMPONENT"
                    }
                },
                "inputs": [
                    {
                        "name": "bizdate",
                        "type": "string"
                    },
                    {
                        "name": "my_input_table",
                        "type": "string"
                    }
                ],
                "outputs": [
                    {
                        "name": "my_output_table1",
                        "type": "string"
                    }
                ]
            }
        ]
    }
}', position='Body'),
}

model CreateComponentResponseBody = {
  componentId?: string(name='ComponentId', description='The ID of the dataset acceleration component. To obtain the component ID, see [ListComponents](https://help.aliyun.com/document_detail/2979566.html).', example='123123123123123'),
  requestId?: string(name='RequestId', description='Id of the request', example='adssd****'),
}

model CreateComponentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateComponentResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateComponent  CreateComponentRequest
  * @return CreateComponentResponse
 */
async function createComponent(request: CreateComponentRequest): CreateComponentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateComponent', 'POST', '/', 'json', true, 'form', request);
}

model CreateComputeResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  connectionProperties: string(name='ConnectionProperties', description='This parameter is required.', example='{     "EndpointMode": "custom",     "Database": "testdb",     "TaskSubmitter": "1107550004253538",     "InstanceId": "hgprecn-cn-x0r3oun4k001",     "SecurityProtocol": "authTypeNone",     "RegionId": "cn-beijing",     "EnvType": "Prod",     "AuthType": "Executor" }', position='Query'),
  connectionPropertiesMode: string(name='ConnectionPropertiesMode', description='This parameter is required.', position='Query'),
  description?: string(name='Description', example='demo_holo_cs', position='Query'),
  name: string(name='Name', description='This parameter is required.', example='demo_holo_cs', position='Query'),
  projectId: long(name='ProjectId', description='This parameter is required.', example='2', minimum=0, position='Query'),
  type: string(name='Type', description='This parameter is required.', example='hologres', position='Query'),
}

model CreateComputeResourceResponseBody = {
  id?: long(name='Id', example='10001'),
  requestId?: string(name='RequestId', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model CreateComputeResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateComputeResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateComputeResource  CreateComputeResourceRequest
  * @return CreateComputeResourceResponse
 */
async function createComputeResource(request: CreateComputeResourceRequest): CreateComputeResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateComputeResource', 'POST', '/', 'json', false, 'json', request);
}

model CreateDIAlarmRuleRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='ABFUOEUOTRTRJKE', position='Query'),
  DIJobId: long(name='DIJobId', description='The ID of the synchronization task with which the alert rule is associated.

This parameter is required.', example='1', position='Query'),
  description?: string(name='Description', description='The description of the alert rule.', example='The description of the alert rule.', position='Query'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the alert rule. By default, the alert rule is disabled.', example='true', position='Query'),
  metricType: string(name='MetricType', description='The metric type in the alert rule. Valid values:

*   Heartbeat
*   FailoverCount
*   Delay
*   DdlReport
*   ResourceUtilization

This parameter is required.', example='Heartbeat', position='Query'),
  name: string(name='Name', description='The name of the alert rule.

This parameter is required.', example='alartRule', position='Query'),
  notificationSettings: {
    inhibitionInterval?: int32(name='InhibitionInterval', description='This parameter is deprecated and replaced by the MuteInterval parameter.', example='5', deprecated='true'),
    muteInterval?: int32(name='MuteInterval', description='The duration of the alert suppression interval. Default value: 5. Unit: minutes.', example='5'),
    notificationChannels?: [ 
      {
        channels?: [ string ](name='Channels', description='The alert notification method. Valid values:

*   Mail
*   Phone
*   Sms
*   Ding'),
        severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Warning'),
      }
    ](name='NotificationChannels', description='The alert notification methods.'),
    notificationReceivers?: [ 
      {
        receiverType?: string(name='ReceiverType', description='The recipient type. Valid values: AliyunUid, DingToken, FeishuToken, and WebHookUrl.', example='DingToken'),
        receiverValues?: [ string ](name='ReceiverValues', description='The recipient.

*   If the ReceiverType parameter is set to AliyunUid, set this parameter to the Alibaba Cloud account ID of a user.
*   If the ReceiverType parameter is set to DingToken, set this parameter to the token of a DingTalk chatbot.'),
      }
    ](name='NotificationReceivers', description='The settings of alert notification recipients.'),
  }(name='NotificationSettings', description='The alert notification settings.

This parameter is required.', shrink='json', position='Query'),
  triggerConditions: [ 
    {
      ddlReportTags?: [ string ](name='DdlReportTags', description='This parameter is deprecated and replaced by the DdlTypes parameter.', deprecated='true'),
      ddlTypes?: [ string ](name='DdlTypes', description='The types of DDL operations for which the alert rule takes effect.'),
      duration?: long(name='Duration', description='The time interval for alert calculation. Unit: minutes.', example='10'),
      severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Warning'),
      threshold?: long(name='Threshold', description='The alert threshold.

*   If the alert rule is for task status, you do not need to specify a threshold.
*   If the alert rule is for failovers, you must specify the number of failovers.
*   If the alert rule is for latency, you must specify the latency duration, in seconds.', example='10'),
    }
  ](name='TriggerConditions', description='The conditions that can trigger the alert rule.

This parameter is required.', shrink='json', position='Query'),
}

model CreateDIAlarmRuleResponseBody = {
  DIAlarmRuleId?: string(name='DIAlarmRuleId', description='This parameter is deprecated and is replaced by the Id parameter.', example='1', deprecated='true'),
  id?: long(name='Id', description='The ID of the alert rule.', example='1'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='C636A747-7E4E-594D-94CD-2B4F8A9A9A63'),
}

model CreateDIAlarmRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDIAlarmRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDIAlarmRule  CreateDIAlarmRuleRequest
  * @return CreateDIAlarmRuleResponse
 */
async function createDIAlarmRule(request: CreateDIAlarmRuleRequest): CreateDIAlarmRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDIAlarmRule', 'GET', '/', 'json', false, 'json', request);
}

model CreateDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  description?: string(name='Description', position='Body'),
  destinationDataSourceSettings: [ 
    {
      dataSourceName?: string(name='DataSourceName'),
    }
  ](name='DestinationDataSourceSettings', description='This parameter is required.', shrink='json', position='Body'),
  destinationDataSourceType: string(name='DestinationDataSourceType', description='The destination type. Valid values: Hologres, OSS-HDFS, OSS, MaxCompute, LogHub, StarRocks, DataHub, AnalyticDB for MySQL, Kafka, and Hive.

This parameter is required.', example='Hologres', position='Query'),
  jobName?: string(name='JobName', description='This parameter is deprecated and is replaced by the Name parameter.', example='mysql_to_holo_sync_8772', deprecated='true', position='Query'),
  jobSettings?: {
    channelSettings?: string(name='ChannelSettings'),
    columnDataTypeSettings?: [ 
      {
        destinationDataType?: string(name='DestinationDataType'),
        sourceDataType?: string(name='SourceDataType'),
      }
    ](name='ColumnDataTypeSettings'),
    cycleScheduleSettings?: {
      cycleMigrationType?: string(name='CycleMigrationType'),
      scheduleParameters?: string(name='ScheduleParameters'),
    }(name='CycleScheduleSettings'),
    ddlHandlingSettings?: [ 
      {
        action?: string(name='Action'),
        type?: string(name='Type'),
      }
    ](name='DdlHandlingSettings'),
    runtimeSettings?: [ 
      {
        name?: string(name='Name'),
        value?: string(name='Value'),
      }
    ](name='RuntimeSettings'),
  }(name='JobSettings', shrink='json', position='Body'),
  jobType?: string(name='JobType', description='The type of the synchronization task. Valid values:

*   DatabaseRealtimeMigration: A real-time synchronization task used to synchronize only full data, only incremental data, or full and incremental data in multiple tables of multiple databases in the source.
*   DatabaseOfflineMigration: A batch synchronization task used to synchronize only full data, only incremental data, or full and incremental data in multiple tables of multiple databases in the source.
*   SingleTableRealtimeMigration: A real-time synchronization task used to synchronize data only in a single table in the source.', example='DatabaseRealtimeMigration', position='Query'),
  migrationType: string(name='MigrationType', description='The synchronization type. Valid values:

*   FullAndRealtimeIncremental
*   RealtimeIncremental
*   Full
*   OfflineIncremental
*   FullAndOfflineIncremental

This parameter is required.', example='FullAndRealtimeIncremental', position='Query'),
  name?: string(name='Name', description='The name of the synchronization task.', example='mysql_to_holo_sync_8772', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
  resourceSettings: {
    offlineResourceSettings?: {
      requestedCu?: double(name='RequestedCu'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier'),
    }(name='OfflineResourceSettings'),
    realtimeResourceSettings?: {
      requestedCu?: double(name='RequestedCu'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier'),
    }(name='RealtimeResourceSettings'),
    scheduleResourceSettings?: {
      requestedCu?: double(name='RequestedCu'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier'),
    }(name='ScheduleResourceSettings'),
  }(name='ResourceSettings', description='This parameter is required.', shrink='json', position='Body'),
  sourceDataSourceSettings: [ 
    {
      dataSourceName?: string(name='DataSourceName'),
      dataSourceProperties?: {
        encoding?: string(name='Encoding'),
        timezone?: string(name='Timezone'),
      }(name='DataSourceProperties'),
    }
  ](name='SourceDataSourceSettings', description='This parameter is required.', shrink='json', position='Body'),
  sourceDataSourceType: string(name='SourceDataSourceType', description='The source type. Valid values: PolarDB, MySQL, Kafka, LogHub, Hologres, Oracle, OceanBase, MongoDB, Redshift, Hive, SQL Server, Doris, and ClickHouse.

This parameter is required.', example='MySQL', position='Query'),
  tableMappings: [ 
    {
      sourceObjectSelectionRules?: [ 
        {
          action?: string(name='Action'),
          expression?: string(name='Expression'),
          expressionType?: string(name='ExpressionType'),
          objectType?: string(name='ObjectType'),
        }
      ](name='SourceObjectSelectionRules'),
      transformationRules?: [ 
        {
          ruleActionType?: string(name='RuleActionType'),
          ruleName?: string(name='RuleName'),
          ruleTargetType?: string(name='RuleTargetType'),
        }
      ](name='TransformationRules'),
    }
  ](name='TableMappings', description='This parameter is required.', shrink='json', position='Body'),
  transformationRules?: [ 
    {
      ruleActionType?: string(name='RuleActionType'),
      ruleExpression?: string(name='RuleExpression'),
      ruleName?: string(name='RuleName'),
      ruleTargetType?: string(name='RuleTargetType'),
    }
  ](name='TransformationRules', shrink='json', position='Body'),
}

model CreateDIJobResponseBody = {
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated and is replaced by the Id parameter.', example='11792', deprecated='true'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11792'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='4F6AB6B3-41FB-5EBB-AFB2-0C98D49DA2BB'),
}

model CreateDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDIJobResponseBody(name='body'),
}

/**
  * @description *   This API operation is available for all DataWorks editions.
  * *   You can call this API operation to create a synchronization task. When you call this API operation, you must configure parameters such as SourceDataSourceSettings, DestinationDataSourceSettings, MigrationType, TransformationRules, TableMappings, and JobSettings. The SourceDataSourceSettings parameter defines the settings related to the source. The DestinationDataSourceSettings parameter defines the settings related to the destination. The MigrationType parameter defines the synchronization task type. The TransformationRules parameter defines the transformation rules for objects involved in the synchronization task. The TableMappings parameter defines the mappings between rules used to select synchronization objects in the source and transformation rules applied to the selected synchronization objects. The JobSettings parameter defines the settings for the dimension of the synchronization task, including policies for data type mappings between source fields and destination fields and settings for periodic scheduling.
  * @param request  the request parameters of CreateDIJob  CreateDIJobRequest
  * @return CreateDIJobResponse
 */
async function createDIJob(request: CreateDIJobRequest): CreateDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDIJob', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataAssetTagRequest {
  regionId?: string(name='RegionId', position='Host'),
  description?: string(name='Description', description='The description of the tag.', example='This is a description', maxLength=1024, position='Query'),
  key: string(name='Key', description='The tag key.

This parameter is required.', example='key1', minLength=1, maxLength=128, position='Query'),
  managers?: [ string ](name='Managers', description='The tag administrators.', shrink='json', position='Query'),
  valueType?: string(name='ValueType', description='The type of the tag value. Valid values:

*   Boolean
*   Int
*   String
*   Double', example='String', position='Query'),
  values?: [ string ](name='Values', description='The tag values.', shrink='json', position='Query'),
}

model CreateDataAssetTagResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateDataAssetTagResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataAssetTagResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of CreateDataAssetTag  CreateDataAssetTagRequest
  * @return CreateDataAssetTagResponse
 */
async function createDataAssetTag(request: CreateDataAssetTagRequest): CreateDataAssetTagResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataAssetTag', 'POST', '/', 'json', false, 'json', request);
}

model CreateDataQualityAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  condition: string(name='Condition', description='The alert condition of the data quality monitoring rule.

This parameter is required.', example='results.any { r -> r.status == \\"fail\\" && r.rule.severity == \\"High\\" }', position='Body'),
  notification: {
    channels: [ string ](name='Channels', description='The list of alert channels. You can set both `Email` and `Sms` at the same time. In other cases, only one channel can be set.

This parameter is required.'),
    receivers: [ 
      {
        extension?: string(name='Extension', description='Additional configurations required for the alert recipients. When ReceiverType is DingdingUrl, you can set `{"atAll":true}` to mention all members.', example='{"atAll":true}'),
        receiverType: string(name='ReceiverType', description='The type of alert recipients.

*   AliUid
*   WebhookUrl
*   DingdingUrl
*   WeixinUrl
*   FeishuUrl
*   TaskOwner
*   DataQualityScanOwner
*   ShiftSchedule

This parameter is required.', example='TaskOwner'),
        receiverValues?: [ string ](name='ReceiverValues', description='The value of alert recipients.'),
      }
    ](name='Receivers', description='The alert recipients.

This parameter is required.'),
  }(name='Notification', description='The list of alert channels.

This parameter is required.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The project ID.

This parameter is required.', example='10001', position='Body'),
  target: {
    ids: [ long ](name='Ids', description='The list of monitored target IDs. Currently, only one ID can be set.

This parameter is required.'),
    type: string(name='Type', description='The type of the monitored target. Only DataQualityScan is supported.

This parameter is required.', example='DataQualityScan'),
  }(name='Target', description='The monitored target of the data quality monitoring rule.

This parameter is required.', shrink='json', position='Body'),
}

model CreateDataQualityAlertRuleResponseBody = {
  id?: long(name='Id', description='The user-defined rule ID returned after the monitoring rule is successfully created.', example='1010543619'),
  requestId?: string(name='RequestId', description='The request ID.', example='0bc14115***159376359'),
}

model CreateDataQualityAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityAlertRuleResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of CreateDataQualityAlertRule  CreateDataQualityAlertRuleRequest
  * @return CreateDataQualityAlertRuleResponse
 */
async function createDataQualityAlertRule(request: CreateDataQualityAlertRuleRequest): CreateDataQualityAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityAlertRule', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataQualityEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityRules?: [ 
    {
      checkingConfig?: {
        referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain specific types of thresholds, you must query reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{"bizdate": ["-1"]}'),
        thresholds?: {
          critical?: {
            expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
            value?: string(name='Value', description='The threshold value.', example='0.01'),
          }(name='Critical', description='The threshold settings for critical alerts.'),
          expected?: {
            expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='='),
            value?: string(name='Value', description='The threshold value.', example='0'),
          }(name='Expected', description='The expected threshold setting.'),
          warned?: {
            expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
            value?: string(name='Value', description='The threshold value.', example='0.001'),
          }(name='Warned', description='The threshold settings for normal alerts.'),
        }(name='Thresholds', description='The threshold settings.'),
        type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average', example='Fixed'),
      }(name='CheckingConfig', description='The check settings for sample data.'),
      description?: string(name='Description', description='The description of the monitoring rule.', example='OpenAPI test rules', maxLength=500),
      enabled?: boolean(name='Enabled', description='Specifies whether to enable the monitoring rule.', example='true'),
      errorHandlers?: [ 
        {
          errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If you define the rule by using custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM ods_api_log WHERE status = \\"Error\\";'),
          type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
        }
      ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
      id?: long(name='Id', description='The rule ID.', example='2176'),
      name?: string(name='Name', description='The name of the monitoring rule.', example='OpenAPI test rules'),
      samplingConfig?: {
        metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: specifies that data is sampled by executing custom SQL statements.', example='NullValueCount'),
        metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
        samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='status != \\"Succeeded\\"'),
        settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='odps.sql.type.system.odps2=True,odps.sql.hive.compatible=True', maxLength=1000),
      }(name='SamplingConfig', description='The parameters required for sampling.'),
      severity?: string(name='Severity', description='The strength of the monitoring rule. Valid values:

*   Normal
*   High', example='High'),
      templateCode?: string(name='TemplateCode', description='The ID of the template used by the monitoring rule.', example='SYSTEM:field:null_value:fixed:0'),
    }
  ](name='DataQualityRules', description='The list of monitoring rules that are associated with the monitor. If you configure the ID of a monitoring rule by using the DataQualityRule.Id parameter, the system associates the rule with a created monitor. If you do not configure the ID of a monitoring rule, the system creates a new monitoring rule by using other fields and associates the rule with a created monitor.', shrink='json', position='Body'),
  dataSourceId: long(name='DataSourceId', description='The data source ID. You can call the [ListDataSources](https://help.aliyun.com/document_detail/211431.html) operation to query the ID.

This parameter is required.', example='1', position='Body'),
  description?: string(name='Description', description='The description of the monitor.', example='OpenAPI create a data quality monitoring test', maxLength=65535, position='Body'),
  hooks?: [ 
    {
      condition?: string(name='Condition', description='The hook trigger condition. When this condition is met, the hook action is triggered. Only two conditional expressions are supported:

1.  Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
2.  Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
      type?: string(name='Type', description='The hook type. Only one hook type is supported.

*   BlockTaskInstance: Blocks the running of scheduling tasks. A monitor is triggered by scheduling tasks. After a monitor finishes running, the monitor determines whether to block the running of scheduling tasks based on the hook condition.', example='BlockTaskInstance'),
    }
  ](name='Hooks', description='The hook.', shrink='json', position='Body'),
  name: string(name='Name', description='The name of the monitor.

This parameter is required.', example='OpenAPI create a data quality monitoring test', maxLength=255, position='Body'),
  notifications?: {
    condition?: string(name='Condition', description='The notification trigger condition. When this condition is met, the alert notification is triggered. Only two conditional expressions are supported:

Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical. Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
    notifications?: [ 
      {
        notificationChannels?: [ 
          {
            channels?: [ string ](name='Channels', description='The alert notification methods.'),
          }
        ](name='NotificationChannels', description='The alert notification methods.'),
        notificationReceivers?: [ 
          {
            extension?: string(name='Extension', description='The additional parameters that are required when alerts are sent. The parameters are JSON-formatted strings. The following keys are supported:

*   atAll: specifies that all members in a group are mentioned when alerts are sent by using DingTalk. This parameter is valid only if you set ReceiverType to DingdingUrl.', example='{  "atAll": true }'),
            receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid values:

*   WebhookUrl
*   FeishuUrl
*   DingdingUrl
*   WeixinUrl
*   AliUid', example='DingdingUrl'),
            receiverValues?: [ string ](name='ReceiverValues', description='The alert recipient.'),
          }
        ](name='NotificationReceivers', description='The configurations of alert recipients.'),
      }
    ](name='Notifications', description='The configurations of the alert notification.'),
  }(name='Notifications', description='The configurations of alert notifications.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You can use this parameter to specify the DataWorks workspace on which you want to perform the API operation.

This parameter is required.', example='10000', position='Body'),
  runtimeConf?: string(name='RuntimeConf', description='The extended configurations in JSON-formatted strings. You can use this parameter only for monitors that are used to monitor the quality of E-MapReduce (EMR) data.

*   queue: The Yarn queue used when a monitor checks the quality of EMR data. By default, the queue configured for the current workspace is used.

*   sqlEngine: The SQL engine used when a monitor checks the quality of EMR data.

    *   HIVE_SQL
    *   SPARK_SQL', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }', position='Body'),
  target: {
    databaseType: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   hologres
*   cdh
*   analyticdb_for_mysql
*   starrocks
*   emr
*   analyticdb_for_postgresql

This parameter is required.', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='pt=$[yyyymmdd-1]', maxLength=255),
    tableGuid: string(name='TableGuid', description='The ID of the table in Data Map.

This parameter is required.', example='odps.api_test.ods_openapi_log_d'),
  }(name='Target', description='The monitored object of the monitor.

This parameter is required.', shrink='json', position='Body'),
  trigger?: {
    taskIds?: [ long ](name='TaskIds', description='The IDs of scheduling tasks. This parameter is valid only if you set Type to ByScheduledTaskInstance.'),
    type?: string(name='Type', description='The trigger type of the monitor. Valid values:

*   ByManual (default): The monitor is manually triggered.
*   ByScheduledTaskInstance: The monitor is triggered by the associated scheduling tasks.', example='ByScheduledTaskInstance'),
  }(name='Trigger', description='The trigger configuration of the monitor.', shrink='json', position='Body'),
}

model CreateDataQualityEvaluationTaskResponseBody = {
  id?: long(name='Id', description='The ID of the new monitor.', example='10001'),
  requestId?: string(name='RequestId', description='Id of the request', example='2d9ce-38ef-4923-baf6-391a7e656'),
}

model CreateDataQualityEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityEvaluationTaskResponseBody(name='body'),
}

/**
  * @description This API operation is supported in all DataWorks editions.
  * @param request  the request parameters of CreateDataQualityEvaluationTask  CreateDataQualityEvaluationTaskRequest
  * @return CreateDataQualityEvaluationTaskResponse
 */
async function createDataQualityEvaluationTask(request: CreateDataQualityEvaluationTaskRequest): CreateDataQualityEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityEvaluationTask', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataQualityEvaluationTaskInstanceRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityEvaluationTaskId: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task.

This parameter is required.', example='200001', position='Body'),
  parameters: string(name='Parameters', description='Data quality verification execution parameters in JSON format. The available keys are as follows:
- triggerTime: the millisecond timestamp of the trigger time. The baseline time of the $[yyyymmdd] expression in the data range of data quality monitoring. Required.

This parameter is required.', example='{ "triggerTime": 1733284062000 }', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the workspace management page to obtain the ID.

This parameter is used to determine the DataWorks workspaces used for this API call.

This parameter is required.', example='10000', position='Body'),
  runtimeResource?: {
    cu?: double(name='Cu', description='The task runs to configure CU consumption. If Serverless resource groups are used, you must specify this parameter.', example='0.25'),
    resourceGroupId?: string(name='ResourceGroupId', description='The identifier of the scheduling resource group configured for running the task.', example='63900680'),
  }(name='RuntimeResource', description='Resource Group information, which must be filled in when running non-MaxCompute data quality verification.', shrink='json', position='Body'),
}

model CreateDataQualityEvaluationTaskInstanceResponseBody = {
  id?: long(name='Id', description='The ID of the data quality monitoring instance.', example='22130'),
  requestId?: string(name='RequestId', description='Id of the request', example='ecb967ec-c137-48****'),
}

model CreateDataQualityEvaluationTaskInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityEvaluationTaskInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDataQualityEvaluationTaskInstance  CreateDataQualityEvaluationTaskInstanceRequest
  * @return CreateDataQualityEvaluationTaskInstanceResponse
 */
async function createDataQualityEvaluationTaskInstance(request: CreateDataQualityEvaluationTaskInstanceRequest): CreateDataQualityEvaluationTaskInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityEvaluationTaskInstance', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataQualityRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference samples and perform aggregate operations on the reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    thresholds?: {
      critical?: {
        expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Example:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.05'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Critical', description='The threshold settings for critical alerts.'),
      expected?: {
        expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Example:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue <= 0.01'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Expected', description='The expected threshold setting.'),
      warned?: {
        expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Example:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Warned', description='The threshold settings for normal alerts.'),
    }(name='Thresholds', description='The threshold settings.'),
    type?: string(name='Type', description='The method that is used to calculate a threshold. You can leave this parameter empty if you use a rule template. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
  }(name='CheckingConfig', description='The check settings for sample data.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description of the rule. The description can be up to 500 characters in length.', example='this is a odps _sql task', maxLength=500, position='Body'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the monitoring rule.', example='true', position='Body'),
  errorHandlers?: [ 
    {
      errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If you define the rule by using custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
      type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
    }
  ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.', shrink='json', position='Body'),
  name: string(name='Name', description='The name of the rule.

This parameter is required.', example='The table cannot be empty.', maxLength=255, position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='10726', position='Body'),
  samplingConfig?: {
    metric?: string(name='Metric', description='The metrics used for sampling. You can leave this parameter empty if you use a rule template. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: specifies that data is sampled by executing custom SQL statements.', example='Count'),
    metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
    samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='id IS NULL'),
    settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;', maxLength=1000),
  }(name='SamplingConfig', description='The sampling settings.', shrink='json', position='Body'),
  severity?: string(name='Severity', description='The strength of the rule. Valid values:

*   Normal
*   High', example='Normal', position='Body'),
  target?: {
    databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='ds=$[yyyymmdd-1]'),
    tableGuid: string(name='TableGuid', description='The ID of the table that is limited by the rule in Data Map.

This parameter is required.', example='odps.unit_test.tb_unit_test'),
    type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
  }(name='Target', description='The monitored object of the rule.', shrink='json', position='Body'),
  templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='system::user_defined', position='Body'),
}

model CreateDataQualityRuleResponseBody = {
  id?: long(name='Id', description='The ID of the rule.', example='19715'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model CreateDataQualityRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDataQualityRule  CreateDataQualityRuleRequest
  * @return CreateDataQualityRuleResponse
 */
async function createDataQualityRule(request: CreateDataQualityRuleRequest): CreateDataQualityRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityRule', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataQualityRuleTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference samples and perform aggregate operations on the reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
  }(name='CheckingConfig', description='The check settings for sample data.', shrink='json', position='Body'),
  directoryPath?: string(name='DirectoryPath', description='The directory in which the template is stored. Slashes (/) are used to separate directory levels. The name of each directory level can be up to 1,024 characters in length. It cannot contain whitespace characters or slashes (/).', example='/ods/order_data', position='Body'),
  name: string(name='Name', description='The name of the template. The name can be up to 512 characters in length and can contain digits, letters, and punctuation marks.

This parameter is required.', example='Table row Count Verification', maxLength=128, position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='12345', position='Body'),
  samplingConfig?: {
    metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: specifies that data is sampled by executing custom SQL statements.', example='Count'),
    metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{"SQL": "select count(1) from table;"}'),
    settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;', maxLength=1000),
  }(name='SamplingConfig', description='The sampling settings.', shrink='json', position='Body'),
  visibleScope?: string(name='VisibleScope', description='The applicable scope of the template. Valid values:

*   Tenant: The template is available in all workspaces in the current tenant.
*   Project: The template is available only in the current workspace.', example='Project', position='Body'),
}

model CreateDataQualityRuleTemplateResponseBody = {
  code?: string(name='Code', description='The Code of the rule template.', example='UserDefined:3001'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model CreateDataQualityRuleTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityRuleTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDataQualityRuleTemplate  CreateDataQualityRuleTemplateRequest
  * @return CreateDataQualityRuleTemplateResponse
 */
async function createDataQualityRuleTemplate(request: CreateDataQualityRuleTemplateRequest): CreateDataQualityRuleTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityRuleTemplate', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataQualityScanRequest {
  regionId?: string(name='RegionId', position='Host'),
  clientToken: string(name='ClientToken', description='The idempotency token.

This parameter is required.', example='a-customized-uuid', position='Body'),
  computeResource?: {
    envType?: string(name='EnvType', description='The workspace environment to which the compute engine belongs.

Valid values:

*   Prod: production environment .
*   Dev: development environment.', example='Dev'),
    name?: string(name='Name', description='The name of the compute engine, which is a unique identifier.', example='emr_first'),
    runtime?: {
      engine?: string(name='Engine', description='The type of the compute engine. Only EMR compute engines support these settings.

Valid values:

*   Hive: Hive SQL
*   Spark: Spark SQL
*   Kyuubi', example='Hive'),
      hiveConf?: map[string]any(name='HiveConf', description='Additional Hive engine parameters. Currently, only the mapreduce.job.queuename parameter is supported.', example='mapreduce.job.queuename=dq_queue'),
      sparkConf?: map[string]any(name='SparkConf', description='Additional Spark engine parameters. Currently, only the spark.yarn.queue parameter is supported.', example='spark.yarn.queue=dq_queue'),
    }(name='Runtime', description='More settings for data quality monitoring at runtime.'),
  }(name='ComputeResource', description='The compute engine used at runtime. If not specified, the data source defined in the Spec is used.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description of the data quality monitor.', example='Daily data quality scanning of ods tables.', position='Body'),
  hooks?: [ 
    {
      condition?: string(name='Condition', description='The Hook trigger condition. The hook will run if the condition is met. Currently, only one type of expression syntax is supported:

You can specify multiple combinations of rule severity levels and validation statuses using an expression such as `results.any { r -> r.status == \\"Fail\\" && r.rule.severity == \\"Normal\\" || r.status == \\"Error\\" && r.rule.severity == \\"High\\" || r.status == \\"Warn\\" && r.rule.severity == \\"High\\" }`. This expression means the condition is met if any executed rule has a result of Fail with severity Normal, Error with severity High, or Warn with severity High. In the condition expression, the values of severity and status are predefined enums. The values of severity must match those defined in the Spec, and the values of status must match those in DataQualityResult.', example='results.any { r -> r.status == \\"Fail\\" && r.rule.severity == \\"Normal\\" || r.status == \\"Error\\" && r.rule.severity == \\"High\\" || r.status == \\"Warn\\" && r.rule.severity == \\"High\\" }'),
      type?: string(name='Type', description='The type of the Hook.

Valid values:

*   BlockTaskInstance: Blocks the scheduling of the task instance.', example='BlockTaskInstance'),
    }
  ](name='Hooks', description='The Hook configurations after the data quality monitoring run ends.', shrink='json', position='Body'),
  name?: string(name='Name', description='The data quality monitoring name.', example='data_quality_scan_001', position='Body'),
  owner?: string(name='Owner', description='The ID of the user who owns of the data quality monitor.', example='95279527****', position='Body'),
  parameters?: [ 
    {
      name?: string(name='Name', description='The parameter name.', example='triggerTime'),
      value?: string(name='Value', description='The parameter values.', example='$[yyyymmdd-1]'),
    }
  ](name='Parameters', description='The definition of execution parameters for the data quality monitoring.', shrink='json', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the DataWorks console and go to the workspace configuration page to obtain the workspace ID. This parameter is required to specify the target DataWorks workspace for this API operation.', example='101', position='Body'),
  runtimeResource?: {
    cu?: float(name='Cu', description='The default number of CUs configured for task running.', example='0.25'),
    id?: string(name='Id', description='The resource group ID.', example='0525242e-d0ee-4bda-bc73-765d82f6a34a'),
    image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
  }(name='RuntimeResource', description='The resource group used during execution of the data quality monitoring.', shrink='json', position='Body'),
  spec?: string(name='Spec', description='Spec code for the content of the data quality monitoring.', example='{
    "datasets": [
        {
            "type": "Table",
            "dataSource": {
                "name": "odps_first",
                "envType": "Prod"
            },
            "tables": [
                "ods_d_user_info"
            ],
            "filter": "pt = $[yyyymmdd-1]"
        }
    ],
    "rules": [
        {
            "assertion": "row_count > 0"
        }, {
            "templateId": "SYSTEM:field:null_value:fixed",
            "pass": "when = 0",
            "name": "The id cannot be empty.",
            "severity": "High",
             "identity": "a-customized-data-quality-rule-uuid"
        }
    ]
}', position='Body'),
  trigger?: {
    taskIds?: [ long ](name='TaskIds', description='If the trigger mode is set to BySchedule, the scheduling task ID must be specified.'),
    type?: string(name='Type', description='The trigger mode of the monitoring task.

Valid values:

*   ByManual: Manual trigger. This is the default setting.
*   BySchedule: Triggered by a scheduled task instance.', example='BySchedule'),
  }(name='Trigger', description='The trigger configurations of the data quality monitoring task.', shrink='json', position='Body'),
}

model CreateDataQualityScanResponseBody = {
  id?: long(name='Id', description='Returns the ID of the created data source sharing rule, which uniquely identifies the rule.', example='676303114031776'),
  requestId?: string(name='RequestId', description='Id of the request', example='0000-ABCD-EFG****'),
}

model CreateDataQualityScanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityScanResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of CreateDataQualityScan  CreateDataQualityScanRequest
  * @return CreateDataQualityScanResponse
 */
async function createDataQualityScan(request: CreateDataQualityScanRequest): CreateDataQualityScanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityScan', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataQualityScanRunRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityScanId?: long(name='DataQualityScanId', description='The ID of the data quality monitor.', example='20000001', position='Body'),
  parameters?: [ 
    {
      name?: string(name='Name', description='The parameter name.', example='regiondt'),
      value?: string(name='Value', description='The parameter value. You can use a scheduling time expression.', example='cn-shanghai$[yyyy-mm-dd-1]'),
    }
  ](name='Parameters', description='The parameter settings used during the actual run. The `triggerTime` parameter is required.', shrink='json', position='Body'),
  projectId?: long(name='ProjectId', description='The project ID.', example='10000', position='Body'),
  runtimeResource?: {
    cu?: float(name='Cu', description='The Compute Resources (CUs) reserved for running the data quality monitor in the resource group.', example='0.25'),
    id?: string(name='Id', description='The resource group ID.', example='e9455a13-ff00-4965-833c-337546ba4854'),
    image?: string(name='Image', description='The image settings used when running the data quality monitor in the resource group.', example='i-xxxxxx'),
  }(name='RuntimeResource', description='The scheduling resource group used when running the data quality monitor. This resource group uses the same data structure as in the scheduling API.', shrink='json', position='Body'),
}

model CreateDataQualityScanRunResponseBody = {
  id?: long(name='Id', description='The RunId that was successfully triggered.', example='248840'),
  requestId?: string(name='RequestId', description='The request ID.', example='0bc14115***159376359'),
}

model CreateDataQualityScanRunResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityScanRunResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of CreateDataQualityScanRun  CreateDataQualityScanRunRequest
  * @return CreateDataQualityScanRunResponse
 */
async function createDataQualityScanRun(request: CreateDataQualityScanRunRequest): CreateDataQualityScanRunResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityScanRun', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataQualityTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  owner?: string(name='Owner', description='The owner ID.', example='1000000000001', position='Body'),
  projectId?: long(name='ProjectId', description='The project ID.', example='10000', position='Body'),
  spec?: string(name='Spec', description='Detailed configuration Spec code of the rule template. For more information, see [Data quality Spec configuration description](~2963394~).', example='{
    "assertion": "anomaly detection fro id_not_null_cnt",
    "id_not_null_cnt": {
        "query": "SELECT COUNT(*) AS cnt FROM ${tableName} WHERE dt = \\"$[yyyymmdd-1]\\";"
    },
    "identity": "819cf1f8-29be-4f94-a9d0-c5c06c0c3d2a"
}', position='Body'),
}

model CreateDataQualityTemplateResponseBody = {
  id?: string(name='Id', description='The unique identifier of the newly created rule template.', example='USER-DEFINED:2001'),
  requestId?: string(name='RequestId', description='The API request ID, which is generated as a UUID.', example='0bc14115***159376359'),
}

model CreateDataQualityTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityTemplateResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of CreateDataQualityTemplate  CreateDataQualityTemplateRequest
  * @return CreateDataQualityTemplateResponse
 */
async function createDataQualityTemplate(request: CreateDataQualityTemplateRequest): CreateDataQualityTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityTemplate', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  connectionProperties: string(name='ConnectionProperties', description='The connection configurations of the data source, including the connection address, access identity, and environment information. The envType parameter specifies the environment in which the data source is used. Valid values of the envType parameter:

*   Dev: development environment
*   Prod: production environment

The parameters that you need to configure for the data source vary based on the mode in which the data source is added. For more information, see [Data source connection information (ConnectionProperties)](https://help.aliyun.com/document_detail/2852465.html).

This parameter is required.', example='{
	"envType": "Prod",
	"regionId": "cn-beijing",
    "instanceId": "hgprecn-cn-x0r3oun4k001",
    "database": "testdb",
    "securityProtocol": "authTypeNone",
    "authType": "Executor",
    "authIdentity": "1107550004253538"
}', position='Query'),
  connectionPropertiesMode: string(name='ConnectionPropertiesMode', description='The mode in which you want to add the data source. The mode varies based on the data source type. Valid values for MySQL data sources:

*   InstanceMode: instance mode
*   UrlMode: connection string mode

This parameter is required.', example='UrlMode', position='Query'),
  description?: string(name='Description', description='The description of the data source. The description cannot exceed 3,000 characters in length.', example='this is a holo datasource', position='Query'),
  name: string(name='Name', description='The name of the data source. The name can be up to 255 characters in length and can contain letters, digits, and underscores (_). The name must start with a letter.

This parameter is required.', example='demo_holo_datasource', position='Query'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/overview) and go to the workspace management page to obtain the ID.

This parameter is used to determine the DataWorks workspaces used for this API call.

This parameter is required.', example='2', minimum=0, position='Query'),
  type: string(name='Type', description='The type of the data source. More than 70 types of data sources are supported in DataWorks. For more information, see [Data source types](https://help.aliyun.com/document_detail/2852465.html).

This parameter is required.', example='hologres', position='Query'),
}

model CreateDataSourceResponseBody = {
  id?: long(name='Id', description='The data source ID.', example='22130'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='B62EC203-B39E-5DC1-B5B8-EB3C61707009'),
}

model CreateDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of CreateDataSource  CreateDataSourceRequest
  * @return CreateDataSourceResponse
 */
async function createDataSource(request: CreateDataSourceRequest): CreateDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataSource', 'POST', '/', 'json', false, 'json', request);
}

model CreateDataSourceSharedRuleRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dataSourceId: long(name='DataSourceId', description='The data source ID.

This parameter is required.', example='144544', position='Query'),
  envType: string(name='EnvType', description='Share data sources to the target project environment, including
- Dev (Development Environment)
- Prod (production environment)

This parameter is required.', example='Dev', position='Query'),
  sharedUser?: string(name='SharedUser', description='The user with which you want to share the data source. If you do not configure this parameter, the data source is shared to an entire workspace.', example='1107550004253538', position='Query'),
  targetProjectId: long(name='TargetProjectId', description='The ID of the workspace to which you want to share the data source. You cannot share the data source to the workspace with which the data source is associated.

This parameter is required.', example='106560', position='Query'),
}

model CreateDataSourceSharedRuleResponseBody = {
  id?: long(name='Id', description='The sharing rule ID.', example='105412'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='46F594E6-84AB-5FA5-8144-6F3D149961E1'),
}

model CreateDataSourceSharedRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataSourceSharedRuleResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  If you want to share a data source from Workspace A to Workspace B, you must have the permissions to share the data source in both workspaces. You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Tenant Administrator, Workspace Administrator, and Workspace Owner
  * @param request  the request parameters of CreateDataSourceSharedRule  CreateDataSourceSharedRuleRequest
  * @return CreateDataSourceSharedRuleResponse
 */
async function createDataSourceSharedRule(request: CreateDataSourceSharedRuleRequest): CreateDataSourceSharedRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataSourceSharedRule', 'POST', '/', 'json', false, 'json', request);
}

model CreateDatasetRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', example='this is a comment', position='Body'),
  dataType?: string(name='DataType', example='COMMON', position='Body'),
  initVersion: {
    comment?: string(name='Comment', example='Initial Version'),
    importInfo?: map[string]string(name='ImportInfo'),
    mountPath?: string(name='MountPath', example='/mnt/data'),
    url: string(name='Url', description='This parameter is required.', example='oss://test-oss-bucket/test_dir/'),
  }(name='InitVersion', description='This parameter is required.', shrink='json', position='Body'),
  name: string(name='Name', description='This parameter is required.', example='test_oss_dataset', position='Body'),
  origin?: string(name='Origin', example='DataWorks', position='Body'),
  projectId: long(name='ProjectId', description='This parameter is required.', example='12345', position='Body'),
  storageType: string(name='StorageType', description='This parameter is required.', example='OSS', position='Body'),
}

model CreateDatasetResponseBody = {
  id?: string(name='Id', description='ID', example='dataworks-dataset:3pXXXb8o0ngr07njhps1'),
  requestId?: string(name='RequestId', description='Id of the request', example='99EBE7CF-69C0-5089-BE3E-79563C31XXXX'),
  success?: boolean(name='Success', example='true'),
}

model CreateDatasetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDatasetResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDataset  CreateDatasetRequest
  * @return CreateDatasetResponse
 */
async function createDataset(request: CreateDatasetRequest): CreateDatasetResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataset', 'POST', '/', 'json', true, 'form', request);
}

model CreateDatasetVersionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', example='this is a comment', position='Body'),
  datasetId: string(name='DatasetId', description='This parameter is required.', example='dataworks-dataset:3pXXXb8o0ngr07njhps1', position='Body'),
  importInfo?: map[string]string(name='ImportInfo', shrink='json', position='Body'),
  mountPath?: string(name='MountPath', example='/mnt/data', position='Body'),
  url: string(name='Url', description='This parameter is required.', example='oss://test-oss-bucket/test_dir/', position='Body'),
}

model CreateDatasetVersionResponseBody = {
  id?: string(name='Id', description='ID', example='dataworks-datasetVersion:3pXXXb8o0ngr07njhps1
:2'),
  requestId?: string(name='RequestId', description='Id of the request', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', example='true'),
}

model CreateDatasetVersionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDatasetVersionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDatasetVersion  CreateDatasetVersionRequest
  * @return CreateDatasetVersionResponse
 */
async function createDatasetVersion(request: CreateDatasetVersionRequest): CreateDatasetVersionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDatasetVersion', 'POST', '/', 'json', true, 'form', request);
}

model CreateFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  advancedSettings?: string(name='AdvancedSettings', description='The advanced settings of the node.

This parameter corresponds to the Advanced Settings section in the right-side navigation pane on the configuration tab of EMR Spark Streaming and EMR Streaming SQL nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).

Only EMR Spark Streaming and EMR Streaming SQL nodes support this parameter. The value must be in the JSON format.', example='{"queue":"default","SPARK_CONF":"--conf spark.driver.memory=2g"}', position='Body'),
  applyScheduleImmediately?: boolean(name='ApplyScheduleImmediately', description='Specifies whether to apply the scheduling configuration immediately after the file is published.', example='true', position='Body'),
  autoParsing?: boolean(name='AutoParsing', description='Specifies whether to enable automatic parsing for the file. Valid values:

*   true
*   false

This parameter corresponds to the Analyze Code setting in Properties > Dependencies for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='true', position='Body'),
  autoRerunIntervalMillis?: int32(name='AutoRerunIntervalMillis', description='The interval at which the node is automatically rerun after a failure. Unit: milliseconds. Maximum value: 1800000 milliseconds (30 minutes).

This parameter corresponds to the Rerun interval parameter in Properties > Schedule > Auto Rerun upon Failure for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console). In the console, the unit of the rerun interval is minutes. Convert the time unit when you call this operation.', example='120000', position='Body'),
  autoRerunTimes?: int32(name='AutoRerunTimes', description='The number of automatic reruns after an error occurs. Maximum value: 10.', example='3', position='Body'),
  connectionName?: string(name='ConnectionName', description='The data source used when the task published from the file is run.

You can call the [UpdateDataSource](https://help.aliyun.com/document_detail/211432.html) operation to query the available data sources in the workspace.', example='odps_source', position='Body'),
  content?: string(name='Content', description='The file code content. Different code types (fileType) have different code formats. In Operation Center, you can find a task of the corresponding type, right-click it, and select View Code to view the specific code format.', example='SHOW TABLES;', position='Body'),
  createFolderIfNotExists?: boolean(name='CreateFolderIfNotExists', description='Specifies whether to automatically create the directory specified by FileFolderPath if the directory does not exist. Valid values:

*   true: If the directory does not exist, automatically create it.
*   false: If the directory does not exist, the call fails.', example='false', position='Body'),
  cronExpress?: string(name='CronExpress', description='The cron expression for scheduled execution. This parameter corresponds to the Cron Expression setting in Scheduling > Scheduling Time for Data Studio tasks in the [DataWorks console](https://workbench.data.aliyun.com/console). After you configure Scheduling Cycle and Scheduled Time, DataWorks automatically generates a cron expression.

Examples:

*   Scheduled at 05:30 every day: `00 30 05 * * ?`
*   Scheduled at the 15th minute of every hour: `00 15 00-23/1 * * ?`
*   Scheduled every 10 minutes: `00 00/10 * * * ?`
*   Scheduled every 10 minutes between 08:00 and 17:00 every day: `00 00-59/10 8-17 * * * ?`
*   Scheduled at 00:20 on the 1st day of every month: `00 20 00 1 * ?`
*   Scheduled every 3 months starting from 00:10 on January 1: `00 10 00 1 1-12/3 ?`
*   Scheduled at 00:05 on every Tuesday and Friday: `00 05 00 * * 2,5`

Due to the rules of the DataWorks scheduling system, cron expressions have the following restrictions:

*   The minimum scheduling interval is 5 minutes.
*   The earliest scheduling time each day is 00:05.', example='00 05 00 * * ?', position='Body'),
  cycleType?: string(name='CycleType', description='The type of scheduling cycle. Valid values: NOT_DAY (minute, hour) and DAY (day, week, month).

This parameter corresponds to the Scheduling Cycle setting in Scheduling > Scheduling Time for Data Studio tasks in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='DAY', position='Body'),
  dependentNodeIdList?: string(name='DependentNodeIdList', description='The IDs of the nodes on which the current node depends. This parameter takes effect only when the DependentType parameter is set to USER_DEFINE. Separate multiple node IDs with commas (,).

This parameter corresponds to the Other Nodes option in Properties > Dependencies > Cross-cycle Dependency (Original Previous-cycle Dependency) for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='abc', position='Body'),
  dependentType?: string(name='DependentType', description='The dependency mode on the previous cycle. Valid values:

*   SELF: Depends on the current node.
*   CHILD: Depends on the child nodes.
*   USER_DEFINE: Depends on other nodes.
*   NONE: No dependencies. Does not depend on the previous cycle.
*   USER_DEFINE_AND_SELF: Depends on both the current node and other nodes in the previous cycle.
*   CHILD_AND_SELF: Depends on both the current node and its child nodes in the previous cycle.', example='NONE', position='Body'),
  endEffectDate?: long(name='EndEffectDate', description='The timestamp (in milliseconds) when automatic scheduling stops.

This parameter corresponds to the end time of Effective Period in Scheduling > Scheduling Time for Data Studio tasks in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='1671694850000', minimum=0, position='Body'),
  fileDescription?: string(name='FileDescription', description='The description of the file.', example='test', position='Body'),
  fileFolderPath?: string(name='FileFolderPath', description='The file path.', example='Business_process/First_Business_Process/MaxCompute/Folder_1/Folder_2', position='Body'),
  fileName: string(name='FileName', description='The file name.

This parameter is required.', example='File name', position='Body'),
  fileType: int32(name='FileType', description='The code type of the file. Different file types have different code. For more information, see [DataWorks node types](https://help.aliyun.com/document_detail/600169.html). You can call the [ListFileType](https://help.aliyun.com/document_detail/212428.html) operation to query the code types of files.

This parameter is required.', example='10', position='Body'),
  ignoreParentSkipRunningProperty?: boolean(name='IgnoreParentSkipRunningProperty', description='Specifies whether to inherit the dry-run status from the previous cycle. Valid values:

*   true: Inherit the dry-run status from the previous cycle.
*   false: Do not inherit the dry-run status from the previous cycle.', example='false', position='Body'),
  imageId?: string(name='ImageId', description='The custom image ID.', example='m-bp1h4b5a8ogkbll2f3tr', position='Body'),
  inputList?: string(name='InputList', description='The output names of the ancestor nodes on which the current node depends. Separate multiple output names with commas (,).

This parameter corresponds to the Output Name of Ancestor Node setting in Properties > Dependencies for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='project_root,project.file1,project.001_out', position='Body'),
  inputParameters?: string(name='InputParameters', description='The input context parameters of the node. The value must be in the JSON format. For more information about the parameter structure, see the InputContextParameterList parameter in the response parameters of the [GetFile](https://help.aliyun.com/document_detail/173954.html) operation.

This parameter corresponds to the Input Parameters setting in Properties > Input and Output Parameters for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='[{"ValueSource": "project_001.first_node:bizdate_param","ParameterName": "bizdate_input"}]', position='Body'),
  outputParameters?: string(name='OutputParameters', description='The output context parameters of the node. The value must be in the JSON format. For more information about the parameter structure, see the OutputContextParameterList parameter in the response parameters of the [GetFile](https://help.aliyun.com/document_detail/173954.html) operation.

This parameter corresponds to the Output Parameters setting in Properties > Input and Output Parameters for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='[{"Type": 1,"Value": "${bizdate}","ParameterName": "bizdate_param"}]', position='Body'),
  owner?: string(name='Owner', description='The Alibaba Cloud account ID of the file owner. If this parameter is not specified, the Alibaba Cloud account ID of the caller is used by default.', example='1000000000001', position='Body'),
  paraValue?: string(name='ParaValue', description='The scheduling parameters of the node. Separate multiple parameters with spaces.

This parameter corresponds to the Scheduling Parameter setting in Properties for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console). For more information, see [Scheduling parameters](https://help.aliyun.com/document_detail/137548.html).', example='a=x b=y', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. To obtain the workspace ID, log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and navigate to the workspace configuration page. You must configure either this parameter or the ProjectIdentifier parameter to determine the DataWorks workspace to which the operation is applied.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The DataWorks workspace name. To obtain the workspace name, log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and navigate to the workspace configuration page.

You must specify either this parameter or ProjectId to identify the target DataWorks workspace for this API call.', example='dw_project', position='Body'),
  rerunMode?: string(name='RerunMode', description='The rerun policy. Valid values:

*   ALL_ALLOWED: Reruns are allowed regardless of whether the task succeeds or fails.
*   FAILURE_ALLOWED: Reruns are allowed only when the task fails.
*   ALL_DENIED: Reruns are not allowed regardless of whether the task succeeds or fails.

This parameter corresponds to the Support for Rerun setting in Scheduling > Scheduling Policies for Data Studio tasks in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='ALL_ALLOWED', position='Body'),
  resourceGroupId?: long(name='ResourceGroupId', description='This parameter is deprecated.', example='375827434852437', position='Body'),
  resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The resource group for the task published from the file. To obtain the ID, log on to the [DataWorks console](https://workbench.data.aliyun.com/console), navigate to the workspace configuration page, and click Resource Groups in the left-side navigation pane to view the IDs of resource groups bound to the current workspace.', example='S_res_group_559_1613715566828', position='Body'),
  schedulerType?: string(name='SchedulerType', description='The scheduling type. Valid values:

*   NORMAL: Normal scheduled task.
*   MANUAL: Manually triggered node. Not scheduled for daily execution. Corresponds to nodes in manually triggered workflows.
*   PAUSE: Paused task.
*   SKIP: Dry-run task. Scheduled for daily execution but is directly marked as successful when scheduling starts.', example='NORMAL', position='Body'),
  startEffectDate?: long(name='StartEffectDate', description='The timestamp (in milliseconds) when automatic scheduling starts.

This parameter corresponds to the start time of Effective Period in Scheduling > Scheduling Time for Data Studio tasks in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='1671608450000', minimum=0, position='Body'),
  startImmediately?: boolean(name='StartImmediately', description='Specifies whether to immediately run the node after the node is deployed.

This parameter corresponds to the Start Method setting in Settings > Schedule in the right-side navigation pane on the configuration tab of EMR Spark Streaming and EMR Streaming SQL nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='true', position='Body'),
  stop?: boolean(name='Stop', description='Specifies whether to skip execution. Valid values:

*   true
*   false

This parameter corresponds to the Skip Execution option in Properties > Schedule > Recurrence for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='false', position='Body'),
  timeout?: int32(name='Timeout', description='The timeout settings for scheduling configuration.', example='1', position='Body'),
}

model CreateFileResponseBody = {
  data?: long(name='Data', description='The file ID.', example='1000001'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID. Use this ID to troubleshoot issues.', example='0000-ABCD-EFG'),
  success?: boolean(name='Success', description='Indicates whether the call succeeded. Valid values:

*   true: The call succeeded.
*   false: The call failed.', example='true'),
}

model CreateFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateFile  CreateFileRequest
  * @return CreateFileResponse
 */
async function createFile(request: CreateFileRequest): CreateFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateFile', 'POST', '/', 'json', true, 'form', request);
}

model CreateFolderRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  folderPath: string(name='FolderPath', description='The path of the folder.

This parameter is required.', example='Business_process/System_Data/MaxCompute/import_layer', position='Body'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace. You can obtain the workspace ID from the workspace configuration page in the DataWorks console. Either this parameter or **ProjectIdentifier** must be specified to determine which DataWorks workspace this API call operates on.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can obtain the workspace name from the workspace configuration page in the DataWorks console. Either this parameter or **ProjectId** must be specified to determine which DataWorks workspace this API call operates on.', example='dw_project', position='Body'),
}

model CreateFolderResponseBody = {
  data?: string(name='Data', description='The unique identifier of the newly created folder.', example='bdfd68****'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID. Used for troubleshooting when errors occur.', example='0000-ABCD-EFG'),
  success?: boolean(name='Success', description='Indicates whether the call succeeded. Valid values:

true

false', example='true'),
}

model CreateFolderResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateFolderResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateFolder  CreateFolderRequest
  * @return CreateFolderResponse
 */
async function createFolder(request: CreateFolderRequest): CreateFolderResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateFolder', 'POST', '/', 'json', true, 'form', request);
}

model CreateFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='12345', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the UDF. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
  "version": "1.1.0",
  "kind": "Function",
  "spec": {
    "functions": [
      {
        "name": "function name",
        "script": {
          "content": "{\\"name\\": \\"function name\\", \\"datasource\\": {\\"type\\": \\"ODPS\\", \\"name\\": \\"ODPS_first\\"}, \\"runtimeResource\\": {\\"resourceGroup\\": \\"s_res_group_xx_xxxx\\"}}",
          "path": "XXX/OpenAPI/function/function name",
          "runtime": {
            "command": "ODPS_FUNCTION"
          }
        },
        "datasource": {
          "name": "ODPS_first",
          "type": "ODPS"
        },
        "runtimeResource": {
          "resourceGroup": "S_res_group_XXXX_XXXX"
        }
      }
    ]
  }
}', position='Body'),
}

model CreateFunctionResponseBody = {
  id?: long(name='Id', description='The ID of the UDF.', example='580667964888595XXXX'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='AE49C88D-5BEE-5ADD-8B8C-C4BBC0D7XXXX'),
}

model CreateFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateFunctionResponseBody(name='body'),
}

/**
  * @description >  You cannot use this API operation to create multiple UDFs at a time. If you specify multiple UDFs by using FlowSpec, the system creates only the first specified UDF.
  * @param request  the request parameters of CreateFunction  CreateFunctionRequest
  * @return CreateFunctionResponse
 */
async function createFunction(request: CreateFunctionRequest): CreateFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateFunction', 'POST', '/', 'json', true, 'form', request);
}

model CreateIdentifyCredentialRequest {
  regionId?: string(name='RegionId', position='Host'),
  identifyCredential?: IdentifyCredential(name='IdentifyCredential', shrink='json', position='Body'),
}

model CreateIdentifyCredentialResponseBody = {
  data?: string(name='Data', description='success true or false', example='{   "HttpStatusCode": 200,   "Success": true }'),
  requestId?: string(name='RequestId', description='Id of the request', example='0000-ABCD-EFG****'),
}

model CreateIdentifyCredentialResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateIdentifyCredentialResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateIdentifyCredential  CreateIdentifyCredentialRequest
  * @return CreateIdentifyCredentialResponse
 */
async function createIdentifyCredential(request: CreateIdentifyCredentialRequest): CreateIdentifyCredentialResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateIdentifyCredential', 'POST', '/', 'json', true, 'form', request);
}

model CreateLineageRelationshipRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dstEntity?: LineageEntity(name='DstEntity', description='The destination entity.', shrink='json', position='Query'),
  srcEntity?: LineageEntity(name='SrcEntity', description='The source entity.', shrink='json', position='Query'),
  task?: LineageTask(name='Task', description='The task information.', shrink='json', position='Query'),
}

model CreateLineageRelationshipResponseBody = {
  id?: string(name='Id', description='The lineage ID.', example='110xxxx:custom-table.xxxxx:maxcompute-table.project.test_big_lineage_080901:custom-sqlxx.00001'),
  requestId?: string(name='RequestId', description='The request ID. The unique identifier of a request.', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADE490'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateLineageRelationshipResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateLineageRelationshipResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateLineageRelationship  CreateLineageRelationshipRequest
  * @return CreateLineageRelationshipResponse
 */
async function createLineageRelationship(request: CreateLineageRelationshipRequest): CreateLineageRelationshipResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateLineageRelationship', 'POST', '/', 'json', false, 'json', request);
}

model CreateMetaCollectionRequest {
  regionId?: string(name='RegionId', position='Host'),
  description?: string(name='Description', description='The collection description.', example='test comment', position='Query'),
  name: string(name='Name', description='The ID of the collection.

This parameter is required.', example='test_album', position='Query'),
  parentId?: string(name='ParentId', description='The parent collection ID.', example='category.123', position='Query'),
  type: string(name='Type', description='The collection name.

*   Category
*   Album
*   AlbumCategory: Album subcategory.

This parameter is required.', example='Category', position='Query'),
}

model CreateMetaCollectionResponseBody = {
  id?: string(name='Id', description='The collection ID returned after a successful creation.', example='category.123'),
  requestId?: string(name='RequestId', description='The request ID.', example='E6F0DBDD-5AD****'),
}

model CreateMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateMetaCollection  CreateMetaCollectionRequest
  * @return CreateMetaCollectionResponse
 */
async function createMetaCollection(request: CreateMetaCollectionRequest): CreateMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateMetaCollection', 'POST', '/', 'json', false, 'json', request);
}

model CreateNetworkRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientToken: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.

This parameter is required.', example='eb870033-74c8-4b1b-9664-04c4e7cc3465', position='Body'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the serverless resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
  vpcId: string(name='VpcId', description='The ID of the virtual private cloud (VPC).

This parameter is required.', example='vpc-m2et4f3oc8msfbccXXXXX', position='Body'),
  vswitchId: string(name='VswitchId', description='The VSwitch ID.

This parameter is required.', example='vsw-uf8usrhs7hjd9amsXXXXX', position='Body'),
}

model CreateNetworkResponseBody = {
  id?: long(name='Id', description='The network ID.', example='1000'),
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateNetworkResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateNetworkResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of CreateNetwork  CreateNetworkRequest
  * @return CreateNetworkResponse
 */
async function createNetwork(request: CreateNetworkRequest): CreateNetworkResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateNetwork', 'POST', '/', 'json', true, 'form', request);
}

model CreateNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  containerId?: long(name='ContainerId', description='The container ID. If you want to create a node in a container, you must configure this parameter to specify the container. The container can be a workflow or a node in a container.

>  If you configure this parameter, the path field defined in FlowSpec becomes invalid.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='123456', position='Body'),
  scene: string(name='Scene', description='The scene of the node. This parameter determines the location (the DataStudio pane or the Manual pane) of the node. You can set this parameter to DataworksManualWorkflow only if the ContainerId parameter is configured and the container specified by ContainerId is a manually triggered workflow.

Valid values:

*   DataworksProject
*   DataworksManualWorkflow
*   DataworksManualTask

This parameter is required.', example='DATAWORKS_PROJECT', position='Body'),
  spec: string(name='Spec', description='{ "type": "object", "description": "CycleWorkflow the structure of the workflow configurations", "properties": { "version": { "type": "string", "description": "the version ID of the workflow configuration files" }, "kind": { "type": "string", "description": "the category ID of the workflow", "enum": [ "CycleWorkflow", "ManualWorkflow", "ManualNode", "TemporaryWorkflow", "PaiFlow", "BatchDeployment", "DataSource", "DataQuality", "DataService", "DataCatalog", "Table", "Node", "Component", "Resource", "Function", "Workflow" ] }, "spec": { "type": "object", "description": "the key configurations of the workflow", "properties": { "name": { "type": "string", "description": "the readable name identifier of the workflow" }, "id": { "type": "string", "description": "the UUID of the workflow" }, "type": { "type": "string", "description": "the type of the workflow instance", "enum": [ "CycleWorkflow", "ManualWorkflow" ] }, "owner": { "type": "string", "description": "the system user ID of the workflow owner" }, "description": { "type": "string", "description": "the detailed description of the features and usage of the workflow" }, "workflows": { "type": "array", "description": an array of node configurations in the workflow. The workflows can be run at the same time", "items": { "type": "object", "properties": { "script": { "type": "object", "description": "the script parameters", "properties": { "path": { "type": "string", "description": "the storage path of the script file. Example: HDFS/S3" }, "runtime": { "type": "object", "description": "the parameter settings for the runtime environment, such as the specifications of computing resources" }, "id": { "type": "string", "description": "the unique identifiers of the script parameters" } } }, "id": { "type": "string", "description": "the ID of the node in the workflow" }, "trigger": { "type": "object", "description": "the rule configurations to trigger the node“, "properties": { "type": { "type": "string", "enum": [ "Scheduler", "Manual", "Streaming", "None" ], "description": "the trigger type. Valid values: Scheduler, Manual, Streaming, and None" }, "id": { "type": "string", "description": "the trigger ID" }, "cron": { "type": "string", "description": "the scheduling rule of the node. The rule is in the cron expression format" }, "startTime": { "type": "string", "description": "the start time for scheduling. The value is in the ISO 8601 format" }, "endTime": { "type": "string", "description": "the end time for scheduling. The value is in the ISO 8601 format" }, "timezone": { "type": "string", "description": "the time zone. Example: UTC+8" }, "delaySeconds": { "type": "number", "description": "the delayed execution time. Unit: seconds" } } }, "strategy": { "type": "object", "description": "the execution policy parameters", "properties": { "timeout": { "type": "number", "description": "the timeout period. Unit: seconds" }, "instanceMode": { "type": "string", "enum": [ "T+1", "Immediately" ], "description": "the instance scheduling mode. Valid values: T+1 and Immediately" }, "rerunMode": { "type": "string", "enum": [ "Allowed", "Denied", "FailureAllowed" ], "description": "the rerun mode. Valid values: Allowed, Denied, and FailureAllowed" }, "rerunTimes": { "type": "number", "description": "the maximum number of reruns allowed after a failure" }, "rerunInterval": { "type": "number", "description": "the rerun interval. Unit: seconds" }, "failureStrategy": { "type": "string", "enum": [ "Continue", "Break" ], "description": "the failure handling policy. Valid values: Continue and Break" }, "recurrenceType": { "type": "string", "enum": [ "Normal", "Pause", "Skip", "NoneAuto" ], "description": "the running mode of the auto triggered node. Valid values: Normal, Pause, Skip, and NoneAuto" } } }, "name": { "type": "string", "description": "the readable name of the node" }, "owner": { "type": "string", "description": "the system ID of the node owner" }, "description": { "type": "string", "description": "the feature description of the node" }, "citable": { "type": "boolean", "description": "specifies whether the node can be referenced by other workflows. Valid values: true and false" }, "metadata": { "type": "object", "description": "the container that stores the metadata information", "properties": { "owner": { "type": "string", "description": "the metadata owner ID" }, "project": { "type": "object", "properties": { "projectIdentifier": { "type": "string", "description": "the unique code of the project" }, "projectName": { "type": "string", "description": "the project name" }, "projectId": { "type": "string", "Description": "the project ID" } } }, "ownerName": { "type": "string", "description": "the name of the project owner" }, "projectId": { "type": "string", "description": "the ID of the associated project" } } }, "inputs": { "type": "object", "description": "the structure of the node input", "properties": { "nodeOutputs": { "type": "array", "description": "the configuration items for node input", "items": { "type": "object", "properties": { "data": { "type": "string", "description": "the content of the node input" }, "artifactType": { "type": "string", "enum": [ "Table", "File", "NodeOutput", "Variable" ], "description": "the type of the node input. Valid values: Table, File, NodeOutput, and Variable" }, "refTableName": { "type": "string", "description": "the name of the referenced table" }, "isDefault": { "type": "boolean", "description": "specifies whether the table is the default output“ } } } }, "tables": { "type": "array", "description": "the metadata collection in the input table", "items": { "type": "object", "properties": { "artifactType": { "type": "string", "enum": [ "Table", "File", "NodeOutput", "Variable" ], "description": "the type of the table" }, "guid": { "type": "string", "description": "the GUID of the table" } } } } } }, "outputs": { "type": "object", "description": "the structure of the node output", "properties": { "nodeOutputs": { "type": "array", "description": "the configuration items for node output", "items": { "type": "object", "properties": { "data": { "type": "string", "description": "the content of the node output" }, "artifactType": { "type": "string", "enum": [ "Table", "File", "NodeOutput", "Variable" ], "description": "the type of the node output. Valid values: Table, File, NodeOutput, and Variable" }, "refTableName": { "type": "string", "description": "the name of the referenced table" }, "isDefault": { "type": "boolean", "description": "specifies whether the table is the default output“ } } } }, "tables": { "type": "array", "description": "the metadata collection in the output table", "items": { "type": "object", "properties": { "artifactType": { "type": "string", "enum": [ "Table", "File", "NodeOutput", "Variable" ], "description": "the type of the table" }, "guid": { "type": "string", "description": "the GUID of the table" } } } } } }, "nodes": { "type": "array", "description": "the configuration items for descendant nodes that are used for workflow nesting", "items": { "type": "object", "properties": { "recurrence": { "type": "string", "enum": [ "Normal", "Pause", "Skip", "NoneAuto" ], "description": "the running mode of the descendant node" }, "id": { "type": "string", "description": "the descendant node ID" }, "timeout": { "type": "number", "description": "the timeout period of the descendant node. Unit: seconds" }, "instanceMode": { "type": "string", "enum": [ "T+1", "Immediately" ], "description": "the instance scheduling mode of the descendant node. Valid values: T+1 and Immediately" }, "rerunMode": { "type": "string", "enum": [ "Allowed", "Denied", "FailureAllowed" ], "description": "the rerun mode of the descendant node" }, "rerunTimes": { "type": "number", "description": "the maximum number of reruns allowed after a failure for the descendant node" }, "rerunInterval": { "type": "number", "description": "the rerun interval" }, "datasource": { "type": "object", "description": "the parameters of the associated data source", "properties": { "name": { "type": "string", "description": "the name of the data source" }, "type": { "type": "string", "description": "the type of the data source. Examples: MySQL and Oracle" } } }, "script": { "type": "object", "description": "the script configurations of the node", "properties": { "language": { "type": "string", "enum": [ "python2", "python3", "java8", "java11", "java17" ], "description": "the programming language of the script" }, "path": { "type": "string", "description": "the storage path of the code" }, "runtime": { "type": "object", "description": "the configurations of the runtime environment" }, "content": { "type": "string", "description": "the content of the inline script" }, "id": { "type": "string", "description": "the identifier of the script content" }, "parameters": { "type": "array", "description": "the parameters for initialization", "items": { "type": "object", "properties": { "name": { "type": "string", "description": "the identifier of the parameter name" }, "artifactType": { "type": "string", "enum": [ "Table", "File", "NodeOutput", "Variable" ], "description": "the identifier of the data type" }, "scope": { "type": "string", "enum": [ "Tenant", "Workspace", "Workflow", "NodeParameter", "NodeContext" ], "description": "the application scope of the parameter" }, "type": { "type": "string", "enum": [ "NoKvVariableExpression", "System", "Constant", "NodeOutput", "PaiOutput", "PassThrough" ], "description": "the type of the parameter" }, "value": { "type": "string", "description": "the default value of the parameter" }, "id": { "type": "string", "description": "the parameter ID" } } } } } }, "trigger": { "type": "object", "description": "the configurations of the trigger at the node level. You can overwrite or inherit the configurations" }, "runtimeResource": { "type": "object", "description": "the configurations of computing resources, such as CPU and memory" }, "name": { "type": "string", "description": "the readable name of the descendant node" }, "owner": { "type": "string", "description": "the ID of the descendant node owner" }, "metadata": { "type": "object", "description": "the extended metadata of the descendant node" }, "inputs": { "type": "object", "description": "the parameter definitions of the node input" }, "outputs": { "type": "object", "description": "the parameter definitions of the node output" } } } }, "dependencies": { "type": "array", "description": "the node dependencies", "items": { "type": "object", "properties": { "nodeId": { "type": "string", "description": "the ID of the current node" }, "depends": { "type": "array", "description": "the ancestor node output", "items": { "type": "object", "properties": { "type": { "type": "string", "enum": [ "Normal", "CrossCycleDependsOnSelf", "CrossCycleDependsOnChildren", "CrossCycleDependsOnOtherNode" ], "description": "the dependency type. Valid values: Normal, CrossCycleDependsOnSelf, CrossCycleDependsOnChildren, and CrossCycleDependsOnOtherNode" }, "output": { "type": "string", "description": "the unique identifier of the ancestor node output" }, "refTableName": { "type": "string", "description": "the identifier of the referenced table name" } } } } } } } } } }, "metadata": { "type": "object", "description": "the high-level metadata of the workflow", "properties": { "innerVersion": { "type": "object", "description": "the mappings between the versions of components", "additionalProperties": { "type": "number" } }, "gmtModified": { "type": "number", "description": "the last modification time. The value is a UNIX timestamp" }, "projectId": { "type": "string", "description": "the ID of the associated project" }, "uuid": { "type": "string", "description": "the GUID of the instance" } } } } } }, "required": [ "version", "kind", "spec" ] }

This parameter is required.', example='{
  "version": "1.1.0",
  "kind": "Node",
  "spec": {
    "nodes": [
      {
        "id": "860438872620113XXXX",
        "recurrence": "Normal",
        "timeout": 0,
        "instanceMode": "T+1",
        "rerunMode": "Allowed",
        "rerunTimes": 3,
        "rerunInterval": 180000,
        "datasource": {
          "name": "ODPS_test",
          "type": "ODPS"
        },
        "script": {
          "path": "XX/OpenAPI test/odpsSQL test",
          "runtime": {
            "command": "ODPS_SQL"
          },
          "content": "select now();"
        },
        "trigger": {
          "type": "Scheduler",
          "cron": "00 00 00 * * ?",
          "startTime": "1970-01-01 00:00:00",
          "endTime": "9999-01-01 00:00:00",
          "timezone": "Asia/Shanghai",
          "delaySeconds": 0
        },
        "runtimeResource": {
          "resourceGroup": "S_res_group_XXXX_XXXX"
        },
        "name": "odpsSQL test",
        "inputs": {
          "nodeOutputs": [
            {
              "data": "lwttest_standard_root",
              "artifactType": "NodeOutput"
            }
          ]
        },
        "outputs": {
          "nodeOutputs": [
            {
              "data": "output_data",
              "artifactType": "NodeOutput",
              "refTableName": "odpsSQL test"
            }
          ]
        }
      }
    ],
    "flow": [
      {
        "nodeId": "860438872620113XXXX",
        "depends": [
          {
            "type": "Normal",
            "output": "project_root"
          }
        ]
      }
    ]
  }
}', position='Body'),
}

model CreateNodeResponseBody = {
  id?: long(name='Id', description='The ID of the node.', example='860438872620113XXXX'),
  requestId?: string(name='RequestId', description='The request ID.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
}

model CreateNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateNodeResponseBody(name='body'),
}

/**
  * @description >  You cannot use this API operation to create multiple nodes at a time. If you specify multiple nodes by using FlowSpec, the system creates only the first specified node.
  * @param request  the request parameters of CreateNode  CreateNodeRequest
  * @return CreateNodeResponse
 */
async function createNode(request: CreateNodeRequest): CreateNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateNode', 'POST', '/', 'json', true, 'form', request);
}

model CreatePipelineRunRequest {
  regionId?: string(name='RegionId', description='区域id

This parameter is required.', position='Host'),
  description?: string(name='Description', description='The description of the process.', example='This is a OdpsSQL-node publishing process. The function is XXXX.', position='Body'),
  objectIds: [ string ](name='ObjectIds', description='The IDs of entities to which you want to apply the process.

>  A process can be applied to only a single entity and its child entities. If you specify multiple entities in the array, the process is applied only to the first entity in the array and its child entities. Make sure that the array in your request contains only one element. Extra elements will be ignored.

This parameter is required.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID. You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
  type: string(name='Type', description='Specifies whether to deploy or undeploy the entity. Valid values:

*   Online: deploys the entity.
*   Offline: undeploys the entity.

This parameter is required.', example='Online', position='Body'),
}

model CreatePipelineRunResponseBody = {
  id?: string(name='Id', description='The ID of the process.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX'),
  requestId?: string(name='RequestId', description='The request ID.', example='7C352CB7-CD88-50CF-9D0D-E81BDF02XXXX'),
}

model CreatePipelineRunResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreatePipelineRunResponseBody(name='body'),
}

/**
  * @description >  You cannot use this API operation to create a process for multiple entities at a time. If you specify multiple entities in a request, the system creates a process only for the first entity.
  * @param request  the request parameters of CreatePipelineRun  CreatePipelineRunRequest
  * @return CreatePipelineRunResponse
 */
async function createPipelineRun(request: CreatePipelineRunRequest): CreatePipelineRunResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreatePipelineRun', 'POST', '/', 'json', true, 'form', request);
}

model CreateProjectRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group to which the workspace belongs. You can log on to the [Resource Management console](https://resourcemanager.console.aliyun.com/resource-groups) and go to the Resource Group page to query the ID.

You must configure this parameter to specify an Alibaba Cloud resource group for the workspace that you want to create.', example='rg-acfmzbn7pti3zff', position='Body'),
  aliyunResourceTags?: [ 
    {
      key?: string(name='Key', description='The tag key.', example='batch'),
      value?: string(name='Value', description='The tag value.', example='blue'),
    }
  ](name='AliyunResourceTags', description='The tags.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description of the workspace.', example='Financial analysis group project data development', position='Body'),
  devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Specifies whether to enable the development environment. Valid values:

*   true : enables the development environment. In this case, the development environment is isolated from the production environment in the workspace.
*   false: disables the development environment. In this case, only the production environment is used in the workspace.', example='false', position='Body'),
  devRoleDisabled?: boolean(name='DevRoleDisabled', description='Specifies whether to disable the Develop role. Valid values:

*   false (default)
*   true', example='true', position='Body'),
  displayName: string(name='DisplayName', description='The display name of the workspace.

This parameter is required.', example='Sora financial analysis', position='Body'),
  name: string(name='Name', description='The name of the workspace.

Limits:

*   The workspace name must be unqiue in a region.
*   The workspace name can contain letters, digits, and underscores (_), and must start with a letter.
*   The workspace name must be 3 to 28 characters in length.

This parameter is required.', example='sora_finance', position='Body'),
  paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Specifies whether to enable scheduling of Platform for AI (PAI) tasks. Valid values:

*   true: enables scheduling of PAI tasks. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: disables scheduling of PAI tasks.', example='true', position='Body'),
}

model CreateProjectResponseBody = {
  id?: long(name='Id', description='The workspace ID.', example='123456'),
  projectId?: long(name='ProjectId', description='The workspace ID. Note: This parameter is deprecated and is replaced by the Id parameter.', example='123456', deprecated='true'),
  requestId?: string(name='RequestId', description='The request ID.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
}

model CreateProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateProject  CreateProjectRequest
  * @return CreateProjectResponse
 */
async function createProject(request: CreateProjectRequest): CreateProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateProject', 'POST', '/', 'json', true, 'form', request);
}

model CreateProjectMemberRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='24054', position='Body'),
  roleCodes: [ string ](name='RoleCodes', description='The codes of the roles in the workspace. You can call the [ListProjectRoles](https://help.aliyun.com/document_detail/2853930.html) operation to query the codes of all roles in the workspace.

This parameter specifies the roles that you can assign to a member when you add the member.

This parameter is required.', shrink='json', position='Body'),
  userId: string(name='UserId', description='The ID of the account that you want to add to the workspace as a member. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click **Tenant Members and Roles**. On the Tenant Members and Roles page, view the ID of the account that you want to add to the workspace as a member.

This parameter is required.', example='123422344899', position='Body'),
}

model CreateProjectMemberResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='2B2F0B26-9253-5780-B6DB-F1A886D44D6F'),
}

model CreateProjectMemberResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateProjectMemberResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of CreateProjectMember  CreateProjectMemberRequest
  * @return CreateProjectMemberResponse
 */
async function createProjectMember(request: CreateProjectMemberRequest): CreateProjectMemberResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateProjectMember', 'POST', '/', 'json', true, 'form', request);
}

model CreateResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group.', example='rg-aek2kqofrgXXXXX', position='Body'),
  aliyunResourceTags?: [ 
    {
      key?: string(name='Key', description='The tag key.', example='key'),
      value?: string(name='Value', description='The tag value.', example='value'),
    }
  ](name='AliyunResourceTags', description='The tags.', shrink='json', position='Body'),
  autoRenewEnabled?: boolean(name='AutoRenewEnabled', description='Specifies whether to enable auto-renewal.', position='Body'),
  clientToken: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.

This parameter is required.', example='eb870033-74c8-4b1b-9664-04c4e7cc3465', position='Body'),
  name: string(name='Name', description='The name of the serverless resource group. The name can be a maximum of 128 characters in length and can contain letters, digits, and underscores (_). The name must start with a letter.

This parameter is required.', example='common_resource_group', position='Body'),
  paymentDuration?: int32(name='PaymentDuration', description='The subscription duration.', example='1', position='Body'),
  paymentDurationUnit?: string(name='PaymentDurationUnit', description='The unit of the subscription duration. Valid values: Month and Year.', example='Month', position='Body'),
  paymentType: string(name='PaymentType', description='The billing method of the serverless resource group. Valid values: PrePaid and PostPaid. The value PrePaid indicates the subscription billing method, and the value PostPaid indicates the pay-as-you-go billing method.

This parameter is required.', example='PrePaid', position='Body'),
  remark?: string(name='Remark', description='The description of the serverless resource group. The description can be a maximum of 128 characters in length and can contain letters, digits, and underscores (_).', example='Create a serverless resource group for common tasks', position='Body'),
  spec?: int32(name='Spec', description='The specifications of the serverless resource group. Unit: CU. This parameter is required only if you set the PaymentType parameter to PrePaid.', example='2', position='Body'),
  vpcId: string(name='VpcId', description='The ID of the virtual private cloud (VPC) with which the serverless resource group is associated by default.

This parameter is required.', example='vpc-m2et4f3oc8msfbccXXXXX', position='Body'),
  vswitchId: string(name='VswitchId', description='The ID of the vSwitch with which the serverless resource group is associated by default.

This parameter is required.', example='vsw-uf8usrhs7hjd9amsXXXXX', position='Body'),
}

model CreateResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  resourceGroupOrder?: {
    id?: string(name='Id', description='The ID of the serverless resource group.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
    orderId?: long(name='OrderId', description='The ID of the order that is used to create the serverless resource group.', example='2391982058XXXXX'),
    orderInstanceId?: string(name='OrderInstanceId', description='The instance ID of the order that is used to create the serverless resource group.', example='c442b330-3b10-4584-959e-736e4edXXXXX'),
  }(name='ResourceGroupOrder', description='The information about the order that is used to create the serverless resource group.'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateResourceGroupResponseBody(name='body'),
}

/**
  * @description 1.  You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * 2.  **Before you call this API operation, you must make sure that you have a good command of the billing details and [pricing](https://help.aliyun.com/document_detail/2680173.html) of serverless resource groups.
  * @param request  the request parameters of CreateResourceGroup  CreateResourceGroupRequest
  * @return CreateResourceGroupResponse
 */
async function createResourceGroup(request: CreateResourceGroupRequest): CreateResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model CreateRouteRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  destinationCidr: string(name='DestinationCidr', description='The CIDR blocks of the destination-based route.

This parameter is required.', example='192.168.0.0/16', position='Body'),
  networkId: long(name='NetworkId', description='The network ID.

This parameter is required.', example='1000', position='Body'),
  resourceGroupId?: string(name='ResourceGroupId', description='Unique identifier of the serverless resource group.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
}

model CreateRouteResponseBody = {
  id?: long(name='Id', description='The route ID.', example='1000'),
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateRouteResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateRouteResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of CreateRoute  CreateRouteRequest
  * @return CreateRouteResponse
 */
async function createRoute(request: CreateRouteRequest): CreateRouteResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateRoute', 'POST', '/', 'json', true, 'form', request);
}

model CreateUdfFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  className: string(name='ClassName', description='The class name where the function is defined, corresponding to the class name field in the Create Function form.

This parameter is required.', example='com.alibaba.DataWorks.api.udf.StringConcat', position='Body'),
  cmdDescription?: string(name='CmdDescription', description='The command format for invoking the function, corresponding to the command format field in the Create Function form.', example='StringConcat(String... substrs)', position='Body'),
  createFolderIfNotExists?: boolean(name='CreateFolderIfNotExists', description='Specifies whether to automatically create the directory if the specified path (FileFolderPath) does not exist. Valid values:

*   true: Automatically creates the directory if it does not exist.
*   false: The call fails if the directory does not exist.', example='false', position='Body'),
  example?: string(name='Example', description='An example demonstrating how to call the function, corresponding to the example field in the Create Function form.', example='StringConcat(\\"a\\", \\"b\\", \\"c\\")', position='Body'),
  fileFolderPath: string(name='FileFolderPath', description='The path to the folder containing the function file.

This parameter is required.', example='Business_process/First_Business_Process/function/string_processing', position='Body'),
  fileName: string(name='FileName', description='The function name.

This parameter is required.', example='StringConcat', position='Body'),
  functionType: string(name='FunctionType', description='The function category, corresponding to the function type field in the Create Function form. Valid values: MATH (mathematical functions), AGGREGATE (aggregate functions), STRING (string processing functions), DATE (date processing functions), ANALYTIC (window functions), and OTHER (other functions).

This parameter is required.', example='STRING', position='Body'),
  parameterDescription?: string(name='ParameterDescription', description='The function parameter description, corresponding to the parameter description field in the Create Function form.', example='List of strings to be connected', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. To find this, click the wrench icon in the upper-right corner and navigate to the workspace management page.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The unique identifier of the DataWorks workspace, which is the identifier at the top of the Data Studio page where you switch workspaces.', example='dw_project', position='Body'),
  resources: string(name='Resources', description='A comma-separated list of resource names referenced by the function, corresponding to the resource list field in the Create Function form.

This parameter is required.', example='string-concat-1.0.0.jar,commons-lang-2.6.jar', position='Body'),
  returnValue?: string(name='ReturnValue', description='The return value description, corresponding to the return value field in the Create Function form.', example='New strings generated by concatenating all strings before and after the input order', position='Body'),
  udfDescription?: string(name='UdfDescription', description='The function purpose description, corresponding to the description field in the Create Function form.', example='Concatenate several strings to generate a new string', position='Body'),
}

model CreateUdfFileResponseBody = {
  data?: long(name='Data', description='The file ID after successful creation.', example='100000002'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The unique ID for this request. Use this ID for troubleshooting if an error occurs.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the request succeeded.

*   true
*   false', example='true'),
}

model CreateUdfFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateUdfFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateUdfFile  CreateUdfFileRequest
  * @return CreateUdfFileResponse
 */
async function createUdfFile(request: CreateUdfFileRequest): CreateUdfFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateUdfFile', 'POST', '/', 'json', true, 'form', request);
}

model CreateWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the workflow. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow/).

This parameter is required.', example='{
    "kind": "CycleWorkflow",
    "version": "1.1.0",
    "spec": {
        "name": "OpenAPITestWorkflowDemo",
        "type": "CycleWorkflow",
        "workflows": [
            {
                "script": {
                    "path": "XX/OpenAPITest/WorkflowTest/OpenAPITestWorkflowDemo",
                    "runtime": {
                        "command": "WORKFLOW"
                    }
                },
                "trigger": {
                    "type": "Scheduler",
                    "cron": "00 02 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "strategy": {
                    "timeout": 0,
                    "instanceMode": "T+1",
                    "rerunMode": "Allowed",
                    "rerunTimes": 3,
                    "rerunInterval": 180000,
                    "failureStrategy": "Break"
                },
                "name": "OpenAPITestWorkflowDemo",
                "inputs": {},
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "workflow_output",
                            "artifactType": "NodeOutput",
                            "refTableName": "OpenAPITestWorkflowDemo"
                        }
                    ]
                },
                "nodes": [],
                "dependencies": []
            }
        ]
    }
}', position='Body'),
}

model CreateWorkflowDefinitionResponseBody = {
  id?: long(name='Id', description='The ID of the workflow.', example='463497880880954XXXX'),
  requestId?: string(name='RequestId', description='The request ID.', example='0EF298E5-0940-5AC7-9CB0-65025070XXXX'),
}

model CreateWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @description > You cannot use this API operation to create multiple workflows at a time. If you specify multiple workflows by using FlowSpec, the system creates only the first specified workflow. Other specified workflows and the nodes in the workflows are ignored. You can call the CreateNode operation to create a node.
  * @param request  the request parameters of CreateWorkflowDefinition  CreateWorkflowDefinitionRequest
  * @return CreateWorkflowDefinitionResponse
 */
async function createWorkflowDefinition(request: CreateWorkflowDefinitionRequest): CreateWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model CreateWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  autoStartEnabled?: boolean(name='AutoStartEnabled', description='The default value is true.', example='true', position='Body'),
  comment?: string(name='Comment', description='The reason for the creation.', example='create for test', position='Body'),
  defaultRunProperties?: {
    alert?: {
      noticeType?: string(name='NoticeType', description='The alert notification method. Valid values:

*   Sms: SMS only.
*   Mail: Mail only.
*   SmsMail: SMS and mail.', example='Sms'),
      type?: string(name='Type', description='The alerting policy. Valid values:

*   Success: Alerts on success.
*   Failure: Alerts on failure.
*   SuccessFailure: Alerts on both success and failure.', example='Succes'),
    }(name='Alert', description='The alert settings.'),
    analysis?: {
      blocked?: boolean(name='Blocked', description='Specifies whether to block execution if the analysis fails. Required when Type = SupplementData.', example='true'),
      enabled?: boolean(name='Enabled', description='Specifies whether to enable the analysis feature. Required when Type = SupplementData.', example='true'),
    }(name='Analysis', description='The analysis configuration. Required when Type = SupplementData.'),
    excludeProjectIds?: [ long ](name='ExcludeProjectIds', description='The IDs of the projects not to run.'),
    excludeTaskIds?: [ long ](name='ExcludeTaskIds', description='The IDs of the tasks not to run.'),
    includeProjectIds?: [ long ](name='IncludeProjectIds', description='The IDs of the projects to run.'),
    includeTaskIds?: [ long ](name='IncludeTaskIds', description='The IDs of the tasks to run.'),
    mode?: string(name='Mode', description='The data backfill mode. Default value: ManualSelection. Required when Type is set to SupplementData.

*   General: You can specify only one value for `RootTaskIds`. The `IncludeTaskIds` parameter is optional. If it\\"s not specified, it defaults to including `RootTaskIds`.
*   ManualSelection: You can specify multiple values for `RootTaskIds`. The `IncludeTaskIds` parameter is optional. If it is not specified, it defaults to including `RootTaskIds`.
*   Chain: If you set the Mode parameter to Chain, leave the `RootTaskIds` parameter empty and set the `IncludeTaskIds` parameter to the start task ID and the end task ID.
*   AllDownstream: Only one `RootTaskId` can be specified.', example='ManualSelection'),
    order?: string(name='Order', description='The execution order. Default value: Asc.

*   Asc: ascending by business date.
*   Desc: descending by business date.', example='Asc'),
    parallelism?: int32(name='Parallelism', description='The task concurrency. Values from 2 to 10 indicate concurrency. A value of 1 indicates sequential execution. Required when Type = SupplementData.', example='2'),
    priority?: int32(name='Priority', description='The execution priority, range: 1–11. A higher value indicates higher priority.', example='1'),
    priorityWeightStrategy?: string(name='PriorityWeightStrategy', description='The priority weighting policy.

*   `Disable` (default): Do not enable.
*   `Upstream`: The priority is based on the total weight of upstream nodes. The deeper the hierarchy, the higher the weight.', example='Upstream'),
    rootTaskIds?: [ long ](name='RootTaskIds', description='The list of root task IDs.

*   When Type is set to SupplementData, RootTaskIds is required unless Mode is set to Chain.
*   When Type is set to ManualWorkflow, RootTaskIds is optional. If it is not specified, the default root nodes of the manual workflow are used.
*   When Type is set to Manual, RootTaskIds is required and specifies the list of manual tasks to run.
*   When Type is set to SmokeTest, RootTaskIds is required and specifies the list of test tasks to run.'),
    runPolicy?: {
      endTime?: string(name='EndTime', description='The end time of running. Configure this parameter in the `hh:mm:ss` format (24-hour clock). This parameter is required if you configure the RunPolicy parameter. Valid values:', example='23:59:59'),
      immediately?: boolean(name='Immediately', description='Specifies whether a task whose scheduled run time is in the future can be run immediately. Default value: false.', example='false'),
      startTime?: string(name='StartTime', description='The start time of running. Configure this parameter in the `hh:mm:ss` format (24-hour clock). This parameter is required if you configure the RunPolicy parameter.', example='00:00:00'),
      type?: string(name='Type', description='The time period type. This parameter is required if you configure the RunPolicy parameter. Valid values:

*   Daily
*   Weekend', example='Daily'),
    }(name='RunPolicy', description='The run policy. If the parameter is left empty, the task configuration is used.'),
    runtimeResource?: string(name='RuntimeResource', description='The custom scheduling resource group ID. If left empty, the task configuration is used.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
  }(name='DefaultRunProperties', description='The runtime configuration.', shrink='json', position='Body'),
  envType?: string(name='EnvType', description='The project environment. Valid values:

*   Prod
*   Dev', example='Prod', position='Body'),
  name: string(name='Name', description='The name.

This parameter is required.', example='WorkflowInstance1', position='Body'),
  periods?: {
    bizDates: [ 
      {
        endBizDate: string(name='EndBizDate', description='The data timestamp at which data is no longer backfilled. Configure this parameter in the `yyyy-mm-dd` format.

This parameter is required.', example='2024-11-24'),
        startBizDate: string(name='StartBizDate', description='The data timestamp at which the data starts to be backfilled. Configure this parameter in the `yyyy-mm-dd` format.

This parameter is required.', example='2024-11-20'),
      }
    ](name='BizDates', description='The data timestamps. You can specify up to seven data timestamps.

This parameter is required.'),
    endTime?: string(name='EndTime', description='The end time of data backfill. Configure this parameter in the `hh:mm:ss` format. The time must be in the 24-hour clock. Default value: 23:59:59.

If you configure this parameter, you must also configure the StartTime parameter.', example='23:59:59'),
    startTime?: string(name='StartTime', description='The start time of data backfill. Configure this parameter in the `hh:mm:ss` format. The time must be in the 24-hour clock. Default value: 00:00:00.

If you configure this parameter, you must also configure the EndTime parameter.', example='00:00:00'),
  }(name='Periods', description='The configuration of the data backfilling period.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The project ID.

This parameter is required.', example='100', position='Body'),
  tagCreationPolicy?: string(name='TagCreationPolicy', description='The tag creation policy. Valid values:

*   Append: New tags are added on top of the existing tags of the manual workflow.
*   Overwrite: Existing tags of the manual workflow are not inherited. New tags are created directly.', example='Append', position='Body'),
  tags?: [ 
    {
      key?: string(name='Key', description='The tag key.', example='tagKey'),
      value?: string(name='Value', description='The tag value.', example='tagValue'),
    }
  ](name='Tags', description='The task tag list.', shrink='json', position='Body'),
  taskParameters?: string(name='TaskParameters', description='The task-specific parameters. The value is in the JSON format. The key specifies the task ID. You can call the GetTask operation to obtain the format of the value by querying the script parameters.', example='{
  "1001": "key1=val2 key2=val2", 
  "1002": "key1=val2 key2=val2"
}', position='Body'),
  type: string(name='Type', description='The type of the workflow instance. Valid values:

*   SupplementData: Data backfill. The usage of RootTaskIds and IncludeTaskIds varies based on the backfill mode. See the description of the DefaultRunProperties.Mode parameter.
*   ManualWorkflow: Manually triggered workflow. WorkflowId is required for a manual workflow. RootTaskIds is optional. If not specified, the system uses the default root task list of the manual workflow.
*   Manual: Manual task. You only need to specify RootTaskIds. This is the list of manual tasks to run.
*   SmokeTest: Smoke test. You only need to specify RootTaskIds. This is the list of test tasks to run.
*   TriggerWorkflow: Triggered Workflow You must specify the WorkflowId of the triggered workflow. IncludeTaskIds is optional. If you do not specify IncludeTaskIds, the entire workflow runs.

This parameter is required.', example='SupplementData', position='Body'),
  workflowId: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs. This parameter is set to 1 for auto triggered tasks.

This parameter is required.', example='1', position='Body'),
  workflowParameters?: string(name='WorkflowParameters', description='The workflow parameters. This parameter takes effect when a specific workflow is specified (`WorkflowId != 1`). For scheduled workflows and triggered workflows, the format is key=value, and these parameters have lower priority than task parameters. For manual workflows, the format is JSON, and these parameters have higher priority than task parameters.', example='{ 
  "key1": "value1", 
  "key2": "value2" 
}', position='Body'),
}

model CreateWorkflowInstancesResponseBody = {
  operationId?: string(name='OperationId', description='The ID of the operation. You can use this field to query the results of the creation operation through the GetCreateWorkflowInstancesResult interface.', example='e15ad21c-b0e9-4792-8f55-b037xxxxxxxx'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model CreateWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateWorkflowInstancesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateWorkflowInstances  CreateWorkflowInstancesRequest
  * @return CreateWorkflowInstancesResponse
 */
async function createWorkflowInstances(request: CreateWorkflowInstancesRequest): CreateWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model DeleteAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The rule ID.', example='105412', position='Body'),
}

model DeleteAlertRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='8754EE08-4AA2-5F77-ADD7-754DBBDA9F75'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteAlertRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteAlertRule  DeleteAlertRuleRequest
  * @return DeleteAlertRuleResponse
 */
async function deleteAlertRule(request: DeleteAlertRuleRequest): DeleteAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteAlertRule', 'POST', '/', 'json', true, 'form', request);
}

model DeleteBusinessRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  businessId: long(name='BusinessId', description='The workflow ID. You can call the [ListBusiness](https://help.aliyun.com/document_detail/173945.html) operation to query the ID of a workflow by name.

This parameter is required.', example='1000001', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the DataWorks console and go to the Workspace page to query the ID. You must specify either this parameter or the ProjectIdentifier parameter to identify the DataWorks workspace when you call this operation.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can log on to the DataWorks console and go to the Workspace page to query the workspace name. You must specify either this parameter or the ProjectId parameter to identify the DataWorks workspace when you call this operation.', example='dw_project', position='Body'),
}

model DeleteBusinessResponseBody = {
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID. Used to troubleshoot issues when an error occurs.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true: success.
*   false: failure.', example='true'),
}

model DeleteBusinessResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteBusinessResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteBusiness  DeleteBusinessRequest
  * @return DeleteBusinessResponse
 */
async function deleteBusiness(request: DeleteBusinessRequest): DeleteBusinessResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteBusiness', 'POST', '/', 'json', true, 'form', request);
}

model DeleteCertificateRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the certificate file.

This parameter is required.', example='676303114031776', position='Query'),
  projectId?: long(name='ProjectId', description='The ID of the workspace to which the certificate file belongs.', example='106560', position='Query'),
}

model DeleteCertificateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='D9A61DC0-B922-421B-B706'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteCertificateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCertificateResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks: Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M.
  * @param request  the request parameters of DeleteCertificate  DeleteCertificateRequest
  * @return DeleteCertificateResponse
 */
async function deleteCertificate(request: DeleteCertificateRequest): DeleteCertificateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteCertificate', 'POST', '/', 'json', false, 'json', request);
}

model DeleteComponentRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  componentId: string(name='ComponentId', description='The component ID. It can be used as a request parameter for querying the list of production studio components and modifying production studio components.

This parameter is required.', example='123123123123', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter specifies the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='1000', position='Body'),
}

model DeleteComponentResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='0000-ABCD-EF****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteComponentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteComponentResponseBody(name='body'),
}

/**
  * @description >  A UDF that is deployed cannot be deleted. If you want to delete such a UDF, you must first undeploy the UDF.
  * @param request  the request parameters of DeleteComponent  DeleteComponentRequest
  * @return DeleteComponentResponse
 */
async function deleteComponent(request: DeleteComponentRequest): DeleteComponentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteComponent', 'POST', '/', 'json', true, 'form', request);
}

model DeleteComputeResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='This parameter is required.', example='1234', position='Query'),
  projectId: long(name='ProjectId', description='This parameter is required.', example='1234', position='Query'),
}

model DeleteComputeResourceResponseBody = {
  requestId?: string(name='RequestId', example='B56432E0-2112-5C97-88D0-AA0AE5****'),
  success?: boolean(name='Success', example='true'),
}

model DeleteComputeResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteComputeResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteComputeResource  DeleteComputeResourceRequest
  * @return DeleteComputeResourceResponse
 */
async function deleteComputeResource(request: DeleteComputeResourceRequest): DeleteComputeResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteComputeResource', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDIAlarmRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIAlarmRuleId?: long(name='DIAlarmRuleId', description='This parameter is deprecated. Use the Id parameter instead.', example='2', deprecated='true', position='Query'),
  DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='1', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='2', position='Query'),
}

model DeleteDIAlarmRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADE490'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteDIAlarmRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDIAlarmRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDIAlarmRule  DeleteDIAlarmRuleRequest
  * @return DeleteDIAlarmRuleResponse
 */
async function deleteDIAlarmRule(request: DeleteDIAlarmRuleRequest): DeleteDIAlarmRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDIAlarmRule', 'GET', '/', 'json', false, 'json', request);
}

model DeleteDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='11126', deprecated='true', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11126', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='108864', position='Query'),
}

model DeleteDIJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can troubleshoot issues based on the ID.', example='D33D4A51-5845-579A-B4BA-FAADD0F83D53'),
  success?: boolean(name='Success', description='true', example='true'),
}

model DeleteDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteDIJob  DeleteDIJobRequest
  * @return DeleteDIJobResponse
 */
async function deleteDIJob(request: DeleteDIJobRequest): DeleteDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDIJob', 'GET', '/', 'json', false, 'json', request);
}

model DeleteDataAssetTagRequest {
  regionId?: string(name='RegionId', position='Host'),
  key: string(name='Key', description='The tag key.

This parameter is required.', example='key1', minLength=1, maxLength=128, position='Query'),
  values?: [ string ](name='Values', description='The tag values.', shrink='json', position='Query'),
}

model DeleteDataAssetTagResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1411515937635973****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteDataAssetTagResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataAssetTagResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of DeleteDataAssetTag  DeleteDataAssetTagRequest
  * @return DeleteDataAssetTagResponse
 */
async function deleteDataAssetTag(request: DeleteDataAssetTagRequest): DeleteDataAssetTagResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataAssetTag', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDataQualityAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The ID of the data quality rule template.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX', position='Body'),
}

model DeleteDataQualityAlertRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc14115***159376359'),
  success?: boolean(name='Success', description='Indicates whether the alert rule is deleted.', example='true'),
}

model DeleteDataQualityAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataQualityAlertRuleResponseBody(name='body'),
}

/**
  * @description Subscribe to DataWorks Basic Edition or a higher version to use this API.
  * @param request  the request parameters of DeleteDataQualityAlertRule  DeleteDataQualityAlertRuleRequest
  * @return DeleteDataQualityAlertRuleResponse
 */
async function deleteDataQualityAlertRule(request: DeleteDataQualityAlertRuleRequest): DeleteDataQualityAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataQualityAlertRule', 'POST', '/', 'json', true, 'form', request);
}

model DeleteDataQualityEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The ID of the data quality monitor.', example='123123', position='Query'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the workspace management page to obtain the ID.

This parameter is used to determine the DataWorks workspaces used for this API call.', example='10000', position='Query'),
}

model DeleteDataQualityEvaluationTaskResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='0bc1ec92159376****'),
  success?: boolean(name='Success', description='Whether the deletion is successful.
- true: Successful
- false: Failed', example='true'),
}

model DeleteDataQualityEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataQualityEvaluationTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDataQualityEvaluationTask  DeleteDataQualityEvaluationTaskRequest
  * @return DeleteDataQualityEvaluationTaskResponse
 */
async function deleteDataQualityEvaluationTask(request: DeleteDataQualityEvaluationTaskRequest): DeleteDataQualityEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataQualityEvaluationTask', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDataQualityRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id: long(name='Id', description='The rule ID.

This parameter is required.', example='19715', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='17302', position='Query'),
}

model DeleteDataQualityRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteDataQualityRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataQualityRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDataQualityRule  DeleteDataQualityRuleRequest
  * @return DeleteDataQualityRuleResponse
 */
async function deleteDataQualityRule(request: DeleteDataQualityRuleRequest): DeleteDataQualityRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataQualityRule', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDataQualityRuleTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  code: string(name='Code', description='The code for the template.

This parameter is required.', example='USER_DEFINED:123', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10001', position='Query'),
}

model DeleteDataQualityRuleTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteDataQualityRuleTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataQualityRuleTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDataQualityRuleTemplate  DeleteDataQualityRuleTemplateRequest
  * @return DeleteDataQualityRuleTemplateResponse
 */
async function deleteDataQualityRuleTemplate(request: DeleteDataQualityRuleTemplateRequest): DeleteDataQualityRuleTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataQualityRuleTemplate', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDataQualityScanRequest {
  regionId?: string(name='RegionId', position='Host'),
  description?: string(name='Description', description='The deprecated parameter. No configuration is required.', example='null', position='Body'),
  id?: long(name='Id', description='The ID of the data quality monitor.', example='123123', position='Body'),
}

model DeleteDataQualityScanResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='2197B9C4-39CE-55EA-8EEA-FDBAE52DXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:', example='true'),
}

model DeleteDataQualityScanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataQualityScanResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteDataQualityScan  DeleteDataQualityScanRequest
  * @return DeleteDataQualityScanResponse
 */
async function deleteDataQualityScan(request: DeleteDataQualityScanRequest): DeleteDataQualityScanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataQualityScan', 'POST', '/', 'json', true, 'form', request);
}

model DeleteDataQualityTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: string(name='Id', description='The ID of the custom rule template.', example='USER_DEFINED:2001', position='Body'),
}

model DeleteDataQualityTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The API request ID, which is generated as a UUID.', example='0bc14115****159376359'),
  success?: boolean(name='Success', description='Deleted', example='true'),
}

model DeleteDataQualityTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataQualityTemplateResponseBody(name='body'),
}

/**
  * @description ## [](#)Request description
  * *   **Id**: the unique identifier of the user-defined rule template, in the format `USER_DEFINED:<template_id>`.
  * *   **ProjectId**: The ID of the DataWorks project to which the rule template belongs.
  * This API is used to remove data quality rule templates that are no longer needed from the system. Make sure the provided `Id` and `ProjectId` are correct when calling this API operation; otherwise, the deletion may fail or lead to unexpected data loss. Use this function with caution and verify the exact information of the template before performing the operation.
  * @param request  the request parameters of DeleteDataQualityTemplate  DeleteDataQualityTemplateRequest
  * @return DeleteDataQualityTemplateResponse
 */
async function deleteDataQualityTemplate(request: DeleteDataQualityTemplateRequest): DeleteDataQualityTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataQualityTemplate', 'POST', '/', 'json', true, 'form', request);
}

model DeleteDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The data source ID.

This parameter is required.', example='1234', position='Query'),
}

model DeleteDataSourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='B56432E0-2112-5C97-88D0-AA0AE5C75C74'),
  success?: boolean(name='Success', description='Whether the call is successful.
- true: Successful
- false: Failed', example='true'),
}

model DeleteDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all Dataworks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of DeleteDataSource  DeleteDataSourceRequest
  * @return DeleteDataSourceResponse
 */
async function deleteDataSource(request: DeleteDataSourceRequest): DeleteDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataSource', 'GET', '/', 'json', false, 'json', request);
}

model DeleteDataSourceSharedRuleRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The sharing rule ID.

This parameter is required.', example='22127', position='Query'),
}

model DeleteDataSourceSharedRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='64B-587A-8CED-969E1973887FXXX-TT'),
  success?: boolean(name='Success', description='Whether the data source sharing rule is deleted successfully. The value is as follows:
-true: The request is successful.
-false: The request failed.', example='true'),
}

model DeleteDataSourceSharedRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataSourceSharedRuleResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  If you want to delete a sharing rule of a data source from Workspace A to Workspace B, you must have the permissions to share the data source in Workspace A or Workspace B. You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Tenant Administrator, Workspace Administrator, and Workspace Owner
  * @param request  the request parameters of DeleteDataSourceSharedRule  DeleteDataSourceSharedRuleRequest
  * @return DeleteDataSourceSharedRuleResponse
 */
async function deleteDataSourceSharedRule(request: DeleteDataSourceSharedRuleRequest): DeleteDataSourceSharedRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataSourceSharedRule', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDatasetRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='This parameter is required.', example='dataworks-dataset:3pXXXb8o0ngr07njhps1', position='Query'),
}

model DeleteDatasetResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='AAC30B35-820D-5F3E-A42C-E96BB****'),
  success?: boolean(name='Success', example='true'),
}

model DeleteDatasetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDatasetResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDataset  DeleteDatasetRequest
  * @return DeleteDatasetResponse
 */
async function deleteDataset(request: DeleteDatasetRequest): DeleteDatasetResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataset', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDatasetVersionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='This parameter is required.', example='dataworks-datasetVersion:3pXXXb8o0ngr07njhps1
:2', position='Query'),
}

model DeleteDatasetVersionResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='6AABBBD3-F2E4-5860-8CF7-2E9CEE3BDXXX'),
  success?: boolean(name='Success', example='true'),
}

model DeleteDatasetVersionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDatasetVersionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDatasetVersion  DeleteDatasetVersionRequest
  * @return DeleteDatasetVersionResponse
 */
async function deleteDatasetVersion(request: DeleteDatasetVersionRequest): DeleteDatasetVersionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDatasetVersion', 'POST', '/', 'json', false, 'json', request);
}

model DeleteFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  fileId: long(name='FileId', description='The file ID. You can call the [ListFiles](https://help.aliyun.com/document_detail/173942.html) operation to obtain the folder ID.

This parameter is required.', example='10000201', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID.

You must specify either this parameter or the ProjectIdentifier parameter to identify the DataWorks workspace when you call this operation.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the name.

You must specify either this parameter or the ProjectId parameter to identify the DataWorks workspace when you call this operation.', example='dw_project', position='Body'),
}

model DeleteFileResponseBody = {
  deploymentId?: long(name='DeploymentId', description='If the file has already been submitted, the DeleteFile operation also triggers an asynchronous deletion process in the scheduling system. You must use the DeploymentId returned by the DeleteFile operation to call GetDeployment and poll the status of the triggered asynchronous deletion process.

If this field is empty, the file has been deleted and no further polling is required.', example='1000000001'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID. Used for troubleshooting when an error occurs.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the call was successful. Valid values:

*   true: success.
*   false: failure.', example='true'),
}

model DeleteFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteFile  DeleteFileRequest
  * @return DeleteFileResponse
 */
async function deleteFile(request: DeleteFileRequest): DeleteFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteFile', 'POST', '/', 'json', true, 'form', request);
}

model DeleteFolderRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  folderId: string(name='FolderId', description='The folder ID. You can call the [ListFolders](https://help.aliyun.com/document_detail/173955.html) operation to obtain the folder ID.

This parameter is required.', example='2eb6f9****', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the DataWorks console and go to the Workspace page to query the ID. You must specify either this parameter or the ProjectIdentifier parameter to identify the DataWorks workspace when you call this operation.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can log on to the DataWorks console and go to the Workspace page to query the workspace name. You must specify either this parameter or the ProjectId parameter to identify the DataWorks workspace when you call this operation.', example='dw_project', position='Body'),
}

model DeleteFolderResponseBody = {
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID. Used for troubleshooting when an error occurs.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the call was successful. Valid values:

*   true: success.
*   false: failure.', example='true'),
}

model DeleteFolderResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteFolderResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteFolder  DeleteFolderRequest
  * @return DeleteFolderResponse
 */
async function deleteFolder(request: DeleteFolderRequest): DeleteFolderResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteFolder', 'POST', '/', 'json', true, 'form', request);
}

model DeleteFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='860438872620113XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID. You can use this parameter to specify the DataWorks workspace on which you want to perform the API operation.

This parameter is required.', example='10000', position='Body'),
}

model DeleteFunctionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='88198F19-A36B-52A9-AE44-4518A688XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteFunctionResponseBody(name='body'),
}

/**
  * @description >  A UDF that is deployed cannot be deleted. If you want to delete such a UDF, you must first undeploy the UDF.
  * @param request  the request parameters of DeleteFunction  DeleteFunctionRequest
  * @return DeleteFunctionResponse
 */
async function deleteFunction(request: DeleteFunctionRequest): DeleteFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteFunction', 'POST', '/', 'json', true, 'form', request);
}

model DeleteLineageRelationshipRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The lineage ID. You can refer to the ListLineageRelationships operation.

This parameter is required.', example='110xxxx:custom-table.xxxxx:maxcompute-table.project.test_big_lineage_080901:custom-sqlxx.00001', position='Body'),
}

model DeleteLineageRelationshipResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='952795279527ab****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true: success.
*   false: failure.', example='true'),
}

model DeleteLineageRelationshipResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteLineageRelationshipResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteLineageRelationship  DeleteLineageRelationshipRequest
  * @return DeleteLineageRelationshipResponse
 */
async function deleteLineageRelationship(request: DeleteLineageRelationshipRequest): DeleteLineageRelationshipResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteLineageRelationship', 'POST', '/', 'json', true, 'form', request);
}

model DeleteMetaCollectionRequest {
  regionId?: string(name='RegionId', position='Host'),
  id: string(name='Id', description='The collection ID.

This parameter is required.', example='category.123', position='Query'),
}

model DeleteMetaCollectionResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='45D14A7A-7C28-5547-AB0A-35FBCD9DE7B5'),
}

model DeleteMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteMetaCollection  DeleteMetaCollectionRequest
  * @return DeleteMetaCollectionResponse
 */
async function deleteMetaCollection(request: DeleteMetaCollectionRequest): DeleteMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteMetaCollection', 'POST', '/', 'json', false, 'json', request);
}

model DeleteNetworkRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the network that you want to delete.

This parameter is required.', example='1000', position='Body'),
}

model DeleteNetworkResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteNetworkResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteNetworkResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteNetwork  DeleteNetworkRequest
  * @return DeleteNetworkResponse
 */
async function deleteNetwork(request: DeleteNetworkRequest): DeleteNetworkResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteNetwork', 'POST', '/', 'json', true, 'form', request);
}

model DeleteNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='860438872620113XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID.

You can use this parameter to specify the DataWorks workspace on which you want to perform the API operation.

This parameter is required.', example='10000', position='Body'),
}

model DeleteNodeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A1E54497-5122-505E-91C6-BAC14980XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

true\\
false', example='true'),
}

model DeleteNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteNodeResponseBody(name='body'),
}

/**
  * @description >  A node that is deployed cannot be deleted. If you want to delete such a node, you must first undeploy the node.
  * @param request  the request parameters of DeleteNode  DeleteNodeRequest
  * @return DeleteNodeResponse
 */
async function deleteNode(request: DeleteNodeRequest): DeleteNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteNode', 'POST', '/', 'json', true, 'form', request);
}

model DeleteProjectRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='123456', position='Body'),
}

model DeleteProjectResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
}

model DeleteProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteProjectResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteProject  DeleteProjectRequest
  * @return DeleteProjectResponse
 */
async function deleteProject(request: DeleteProjectRequest): DeleteProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteProject', 'POST', '/', 'json', true, 'form', request);
}

model DeleteProjectMemberRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='534752', position='Body'),
  userId: string(name='UserId', description='The ID of the account used by the member in the workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the **Tenant Members and Roles** page, view the ID of the account used by the member in the workspace.

This parameter is required.', example='123422344899', position='Body'),
}

model DeleteProjectMemberResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='1FF0465F-209C-5964-8F30-FAF21B677CC6'),
}

model DeleteProjectMemberResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteProjectMemberResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteProjectMember  DeleteProjectMemberRequest
  * @return DeleteProjectMemberResponse
 */
async function deleteProjectMember(request: DeleteProjectMemberRequest): DeleteProjectMemberResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteProjectMember', 'POST', '/', 'json', true, 'form', request);
}

model DeleteResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the file resource.

This parameter is required.', example='860438872620113XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID. You can use this parameter to specify the DataWorks workspace on which you want to perform the API operation.

This parameter is required.', example='10000', position='Body'),
}

model DeleteResourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='88198F19-A36B-52A9-AE44-4518A688XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteResourceResponseBody(name='body'),
}

/**
  * @description >  A file resource that is deployed cannot be deleted. If you want to delete such a file resource, you must first undeploy the file resource.
  * @param request  the request parameters of DeleteResource  DeleteResourceRequest
  * @return DeleteResourceResponse
 */
async function deleteResource(request: DeleteResourceRequest): DeleteResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteResource', 'POST', '/', 'json', true, 'form', request);
}

model DeleteResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
}

model DeleteResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to locate logs and troubleshoot issues.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteResourceGroupResponseBody(name='body'),
}

/**
  * @description 1.  You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * 2.  **Before you call this API operation, you must make sure that you have a good command of the billing details and [pricing](https://help.aliyun.com/document_detail/2680173.html) of serverless resource groups.
  * @param request  the request parameters of DeleteResourceGroup  DeleteResourceGroupRequest
  * @return DeleteResourceGroupResponse
 */
async function deleteResourceGroup(request: DeleteResourceGroupRequest): DeleteResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model DeleteRouteRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The route ID.

This parameter is required.', example='1000', position='Body'),
}

model DeleteRouteResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteRouteResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteRouteResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteRoute  DeleteRouteRequest
  * @return DeleteRouteResponse
 */
async function deleteRoute(request: DeleteRouteRequest): DeleteRouteResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteRoute', 'POST', '/', 'json', true, 'form', request);
}

model DeleteTaskRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model DeleteTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteTaskResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteTask  DeleteTaskRequest
  * @return DeleteTaskResponse
 */
async function deleteTask(request: DeleteTaskRequest): DeleteTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteTask', 'POST', '/', 'json', false, 'json', request);
}

model DeleteWorkflowRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a workflow asynchronously and implement the idempotence of the workflow. If you do not specify this parameter when you create the workflow, the system automatically generates a unique code. The unique code is uniquely associated with the workflow ID. If you specify this parameter when you update or delete the workflow, the value of this parameter must be the unique code that is used to create the workflow.', example='Workflow_0bc5213917368545132902xxxxxxxx', position='Body'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  id: long(name='Id', description='The workflow ID.

This parameter is required.', example='1234', position='Query'),
}

model DeleteWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteWorkflowResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteWorkflow  DeleteWorkflowRequest
  * @return DeleteWorkflowResponse
 */
async function deleteWorkflow(request: DeleteWorkflowRequest): DeleteWorkflowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteWorkflow', 'POST', '/', 'json', true, 'form', request);
}

model DeleteWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='860438872620113XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Body'),
}

model DeleteWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='B17730C0-D959-548A-AE23-E754177CXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @description >  A workflow that is deployed cannot be deleted. If you want to delete such a workflow, you must first undeploy the workflow.
  * @param request  the request parameters of DeleteWorkflowDefinition  DeleteWorkflowDefinitionRequest
  * @return DeleteWorkflowDefinitionResponse
 */
async function deleteWorkflowDefinition(request: DeleteWorkflowDefinitionRequest): DeleteWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model DeployFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The description of the deployment.', example='First release task', position='Body'),
  fileId?: long(name='FileId', description='The file ID. You can call the [ListFiles](https://help.aliyun.com/document_detail/173942.html) operation to obtain the ID. You need to configure either this parameter or the NodeId parameter.', example='10000001', position='Body'),
  nodeId?: long(name='NodeId', description='The task ID of the file to be deployed in the scheduling system. You need to configure either this parameter or the FileId parameter.', example='2000001', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the DataWorks console and go to the Workspace page to query the ID. You must specify either this parameter or the ProjectIdentifier parameter to identify the DataWorks workspace when you call this operation.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can log on to the DataWorks console and go to the Workspace page to query the workspace name. You must specify either this parameter or the ProjectId parameter to identify the DataWorks workspace when you call this operation.', example='dw_project', position='Body'),
}

model DeployFileResponseBody = {
  data?: long(name='Data', description='The deployment package ID. You must specify this ID as a parameter when you call the [GetDeployment](https://help.aliyun.com/document_detail/173950.html) operation to query the details of the deployment.', example='30000001'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the call was successful. Valid values:

*   true: success.
*   false: failure.', example='true'),
}

model DeployFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeployFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeployFile  DeployFileRequest
  * @return DeployFileResponse
 */
async function deployFile(request: DeployFileRequest): DeployFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeployFile', 'POST', '/', 'json', true, 'form', request);
}

model DetachDataQualityRulesFromEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityEvaluationTaskId: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task that is associated with the rule.

This parameter is required.', example='10000', position='Body'),
  dataQualityRuleIds: [ long ](name='DataQualityRuleIds', description='The IDs of the monitoring rules.

This parameter is required.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the workspace configuration page to obtain the workspace ID.

This parameter is required.', example='10002', position='Body'),
}

model DetachDataQualityRulesFromEvaluationTaskResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
  success?: boolean(name='Success', description='Whether the call is successful. The values are as follows:
- true: The call is successful.
- false: the call failed.', example='true'),
}

model DetachDataQualityRulesFromEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DetachDataQualityRulesFromEvaluationTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DetachDataQualityRulesFromEvaluationTask  DetachDataQualityRulesFromEvaluationTaskRequest
  * @return DetachDataQualityRulesFromEvaluationTaskResponse
 */
async function detachDataQualityRulesFromEvaluationTask(request: DetachDataQualityRulesFromEvaluationTaskRequest): DetachDataQualityRulesFromEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DetachDataQualityRulesFromEvaluationTask', 'POST', '/', 'json', true, 'form', request);
}

model DissociateProjectFromResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The ID of the workspace from which you want to disassociate the resource group.

This parameter is required.', example='1000', position='Body'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
}

model DissociateProjectFromResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to locate logs and troubleshoot issues.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DissociateProjectFromResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DissociateProjectFromResourceGroupResponseBody(name='body'),
}

/**
  * @description 1.  You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * 2.  Your account must be assigned one of the following roles of the desired workspace:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of DissociateProjectFromResourceGroup  DissociateProjectFromResourceGroupRequest
  * @return DissociateProjectFromResourceGroupResponse
 */
async function dissociateProjectFromResourceGroup(request: DissociateProjectFromResourceGroupRequest): DissociateProjectFromResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DissociateProjectFromResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model EstablishRelationTableToBusinessRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  businessId: string(name='BusinessId', description='The workflow ID. You can call the [ListBusiness](https://help.aliyun.com/document_detail/173945.html) operation to obtain the workflow ID.

This parameter is required.', example='1000001', position='Body'),
  folderId?: string(name='FolderId', description='The ID of the folder. You can call the [GetFolder](https://help.aliyun.com/document_detail/173952.html) or [ListFolders](https://help.aliyun.com/document_detail/173955.html) operation to obtain the folder ID.', example='2eb6f9****', position='Body'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace. You can click the wrench icon in the top-right corner to access the workspace management page and view the ID.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The unique identifier of the DataWorks workspace. This is the identifier shown in the workspace switcher at the top of the Data Studio page.

Either this parameter or ProjectId must be specified to determine which DataWorks workspace this API call operates on.', example='dw', position='Body'),
  tableGuid: string(name='TableGuid', description='The UUID of the table. You can call the [SearchMetaTables](https://help.aliyun.com/document_detail/173919.html) operation to obtain the table UUID.

This parameter is required.', example='odps.dw_project.tb1', position='Body'),
}

model EstablishRelationTableToBusinessResponseBody = {
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The unique ID of this request. You can use this ID to troubleshoot issues if errors occur.', example='0000-ABCD-EFG'),
  success?: boolean(name='Success', description='Indicates whether the request succeeded. Valid values:

*   true
*   false', example='true'),
}

model EstablishRelationTableToBusinessResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: EstablishRelationTableToBusinessResponseBody(name='body'),
}

/**
  * @param request  the request parameters of EstablishRelationTableToBusiness  EstablishRelationTableToBusinessRequest
  * @return EstablishRelationTableToBusinessResponse
 */
async function establishRelationTableToBusiness(request: EstablishRelationTableToBusinessRequest): EstablishRelationTableToBusinessResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'EstablishRelationTableToBusiness', 'POST', '/', 'json', true, 'form', request);
}

model ExecPipelineRunStageRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  code: string(name='Code', description='The code of the stage in the process. You can call the GetDeployment operation to query the code.

This parameter is required.', example='DEV_CHECK', position='Body'),
  id: string(name='Id', description='The ID of the process.

This parameter is required.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Query'),
}

model ExecPipelineRunStageResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true

*   false

    **

    **Note:** The value of this parameter indicates only whether the stage is triggered but does not indicate whether the execution of the stage is successful.', example='true'),
}

model ExecPipelineRunStageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ExecPipelineRunStageResponseBody(name='body'),
}

/**
  * @description >  The stages in a process are sequential. For more information, see the GetDeployment operation. Skipping or repeating a stage is not allowed.
  * >  The execution of a stage is asynchronous. The response of this operation indicates only whether a stage is triggered but does not indicate whether the execution of the stage is successful. You can call the GetDeployment operation to check whether the execution is successful.
  * @param request  the request parameters of ExecPipelineRunStage  ExecPipelineRunStageRequest
  * @return ExecPipelineRunStageResponse
 */
async function execPipelineRunStage(request: ExecPipelineRunStageRequest): ExecPipelineRunStageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ExecPipelineRunStage', 'POST', '/', 'json', true, 'form', request);
}

model ExecuteAdhocWorkflowInstanceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  bizDate?: long(name='BizDate', description='The data timestamp.', example='1710239005403', position='Body'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  name: string(name='Name', description='The name of the workflow instance.

This parameter is required.', example='WorkflowInstance1', position='Body'),
  owner: string(name='Owner', description='The account ID of the owner.

This parameter is required.', example='1000', position='Body'),
  projectId: long(name='ProjectId', description='The workspace ID.

This parameter is required.', example='100', position='Body'),
  tasks: [ 
    {
      clientUniqueCode: string(name='ClientUniqueCode', description='The unique code of the client. This code uniquely identifies a task.

This parameter is required.', example='Task_0bc5213917368545132902xxxxxxxx'),
      dataSource?: {
        name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
      }(name='DataSource', description='The information about the associated data source.'),
      dependencies?: [ 
        {
          upstreamOutput?: string(name='UpstreamOutput', description='The identifier of the output of the ancestor task.', example='pre.odps_sql_demo_0'),
        }
      ](name='Dependencies', description='The dependency information.'),
      inputs?: {
        variables?: [ 
          {
            name?: string(name='Name', description='The name of the variable.', example='key1'),
            value?: string(name='Value', description='The value of the variable. You must configure this parameter in the `The ancestor output: The output variable name of the ancestor task` format.', example='Value1'),
          }
        ](name='Variables', description='The variables.'),
      }(name='Inputs', description='The input information.'),
      name: string(name='Name', description='The name of the task.

This parameter is required.', example='SQL node.'),
      outputs?: {
        taskOutputs?: [ 
          {
            output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
          }
        ](name='TaskOutputs', description='The task outputs.'),
        variables?: [ 
          {
            name?: string(name='Name', description='The name of the variable.', example='key1'),
            type?: string(name='Type', description='The type. Valid values:

*   System
*   Constant
*   NodeOutput
*   PassThrough', example='Constant'),
            value?: string(name='Value', description='The value of the variable.', example='value1'),
          }
        ](name='Variables', description='The variables.'),
      }(name='Outputs', description='The output information.'),
      owner: string(name='Owner', description='The account ID of the owner.

This parameter is required.', example='1000'),
      runtimeResource: {
        cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
        image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
        resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.

This parameter is required.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
      }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.

This parameter is required.'),
      script?: {
        content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
        parameters?: string(name='Parameters', description='The script parameters.', example='para1=$bizdate'),
      }(name='Script', description='The script information.'),
      timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
      type: string(name='Type', description='The type of the task.

This parameter is required.', example='ODPS_SQL'),
    }
  ](name='Tasks', description='The tasks.

This parameter is required.', shrink='json', position='Body'),
}

model ExecuteAdhocWorkflowInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
}

model ExecuteAdhocWorkflowInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ExecuteAdhocWorkflowInstanceResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ExecuteAdhocWorkflowInstance  ExecuteAdhocWorkflowInstanceRequest
  * @return ExecuteAdhocWorkflowInstanceResponse
 */
async function executeAdhocWorkflowInstance(request: ExecuteAdhocWorkflowInstanceRequest): ExecuteAdhocWorkflowInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ExecuteAdhocWorkflowInstance', 'POST', '/', 'json', true, 'form', request);
}

model GetAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: string(name='Id', description='The rule ID.', example='28547072', position='Query'),
}

model GetAlertRuleResponseBody = {
  alertRule?: {
    enabled?: boolean(name='Enabled', description='Indicates whether the rule is enabled.', example='true'),
    id?: long(name='Id', description='The rule ID.', example='16035'),
    name?: string(name='Name', description='The name of the rule.', example='error_rule'),
    notification?: {
      channels?: [ string ](name='Channels', description='The alert notification channels.'),
      intervalInMinutes?: int32(name='IntervalInMinutes', description='The interval at which an alert notification is sent. Unit: minutes. Valid values: [5,10000].', example='30'),
      maximum?: int32(name='Maximum', description='The maximum number of times an alert notification can be sent within a calendar day. Valid values: [1, 10000].', example='3'),
      receivers?: [ 
        {
          extension?: string(name='Extension', description='The additional configuration of the alert recipient. If the ReceiverType parameter is set to DingdingUrl, you can set this parameter to {"atAll":true} to remind all members in a DingTalk group.', example='{"atAll":true}'),
          receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid valves:

*   AliUid: Alibaba Cloud account ID.
*   Shift Schedules: the personnel in a shift schedule.
*   TaskOwner: the task owner. The task owner can receive custom alerts and event alerts.
*   Owner: the baseline owner. The baseline owner can receive baseline alerts.
*   WebhookUrl: URL of a custom webhook.
*   DingdingUrl: DingTalk webhook URL.
*   FeishuUrl: Lark webhook URL.
*   WeixinUrl: WeCom webhook URL.', example='WebhookUrl'),
          receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
        }
      ](name='Receivers', description='The alert recipients.'),
      silenceEndTime?: string(name='SilenceEndTime', description='The end time for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
      silenceStartTime?: string(name='SilenceStartTime', description='The start time for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
    }(name='Notification', description='The configuration for the alert notification.'),
    owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.', example='279961421580845157'),
    triggerCondition?: {
      extension?: {
        cycleUnfinished?: {
          cycleAndTime?: [ 
            {
              cycleId?: int32(name='CycleId', description='The ID of the scheduling cycle of the instance. Valid values: [1,288].', example='1'),
              time?: string(name='Time', description='The latest completion time of the instance within the scheduling cycle. The time is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
            }
          ](name='CycleAndTime', description='The configurations of the scheduling cycle and timeout period of the instance.'),
        }(name='CycleUnfinished', description='The configuration for an alert of the CycleUnfinished type.'),
        error?: {
          autoRerunAlertEnabled?: boolean(name='AutoRerunAlertEnabled', description='Indicates whether an alert is triggered if a batch synchronization task is automatically rerun upon a failure.', example='false'),
          streamTaskIds?: [ long ](name='StreamTaskIds', description='The IDs of the real-time computing tasks. This parameter is required when you monitor real-time computing tasks.'),
        }(name='Error', description='The configuration for an alert of the Error type.'),
        instanceErrorCount?: {
          count?: int32(name='Count', description='The maximum number of instances on which an error occurs. Valid values: [1,10000].', example='10'),
        }(name='InstanceErrorCount', description='The configuration for an alert of the InstanceErrorCount type.'),
        instanceErrorPercentage?: {
          percentage?: int32(name='Percentage', description='The maximum percentage of instances on which an error occurs in the workspace to the total number of instances. Valid values: [1-100].', example='10'),
        }(name='InstanceErrorPercentage', description='The configuration for an alert of the InstanceErrorPercentage type.'),
        instanceTransferFluctuate?: {
          percentage?: int32(name='Percentage', description='The maximum percentage of fluctuation in the number of auto triggered node instances that are generated in your workspace. Valid values: [1-100].', example='10'),
          trend?: string(name='Trend', description='The way in which the number of auto triggered node instances that are generated in your workspace fluctuates. Valid values:

*   abs: the absolute value. The number of instances increases or decreases.
*   increase: The number of instances increases.
*   decrease: The number of instances decreases.', example='10'),
        }(name='InstanceTransferFluctuate', description='The configuration for an alert of the InstanceTransferFluctuate type.'),
        timeout?: {
          timeoutInMinutes?: int32(name='TimeoutInMinutes', description='The timeout period. Unit: minutes. Valid values: [1, 21600].', example='10'),
        }(name='Timeout', description='The configuration for an alert of the Timeout type.'),
        unFinished?: {
          unFinishedTime?: string(name='UnFinishedTime', description='The latest completion time of the instance. The period is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
        }(name='UnFinished', description='The configuration for an alert of the UnFinished type.'),
      }(name='Extension', description='The extended information about the rule. This parameter is required for specific types of alerts.'),
      target?: {
        allowTasks?: [ long ](name='AllowTasks', description='The nodes that are not to be monitored.'),
        ids?: [ long ](name='Ids', description='The IDs of monitored objects.'),
        type?: string(name='Type', description='The type of the monitored objects. Valid values:

*   Task: node
*   Baseline: baseline
*   project: workspace
*   BizProcess: workflow', example='Task'),
      }(name='Target', description='The monitored objects.'),
      type?: string(name='Type', description='The alert type. Valid values:

*   Finished: An instance is successfully run.
*   UnFinished: An instance does not finish running before a specified point in time.
*   Error: An error occurs on an instance.
*   CycleUnfinished: An instance does not finish running as expected within a specific cycle.
*   Timeout: An instance times out.
*   InstanceTransferComplete: An instance is generated by the auto triggered node.
*   InstanceTransferFluctuate: The number of generated instances fluctuates.
*   ExhaustedError: An error persists after an instance is automatically rerun.
*   InstanceKeyword: An instance with errors contains specified keywords.
*   InstanceErrorCount: The number of instances on which an error occurs reaches a specified threshold.
*   InstanceErrorPercentage: The proportion of instances on which an error occurs in the workspace to the total number of instances reaches a specified threshold.
*   ResourceGroupPercentage: The usage rate of the resource group reaches a specified threshold.
*   ResourceGroupWaitCount: The number of instances that are waiting for resources in the resource group reaches a specified threshold.', example='Error'),
    }(name='TriggerCondition', description='The alert triggering condition.'),
  }(name='AlertRule', description='The information about the rule.'),
  requestId?: string(name='RequestId', description='The request ID.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
}

model GetAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAlertRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetAlertRule  GetAlertRuleRequest
  * @return GetAlertRuleResponse
 */
async function getAlertRule(request: GetAlertRuleRequest): GetAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAlertRule', 'GET', '/', 'json', false, 'json', request);
}

model GetBusinessRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  businessId: long(name='BusinessId', description='The workflow ID. You can call the [ListBusiness](https://help.aliyun.com/document_detail/173945.html) operation to obtain the folder ID.

This parameter is required.', example='1000000111', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the DataWorks console and go to the Workspace page to query the ID. You must specify either this parameter or the ProjectIdentifier parameter to identify the DataWorks workspace when you call this operation.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can log on to the DataWorks console and go to the Workspace page to query the workspace name. You must specify either this parameter or the ProjectId parameter to identify the DataWorks workspace when you call this operation.', example='dw_project', position='Body'),
}

model GetBusinessResponseBody = {
  data?: {
    businessId?: long(name='BusinessId', description='The workflow ID.', example='1000001'),
    businessName?: string(name='BusinessName', description='The name of the workflow. Workflow names must be unique within the same workspace.', example='The first business process'),
    description?: string(name='Description', description='The description of the workflow.', example='This is my first business process.'),
    owner?: string(name='Owner', description='The Alibaba Cloud account ID of the workflow owner.', example='20000****'),
    projectId?: string(name='ProjectId', description='The ID of the workspace where the workflow resides.', example='10000'),
    useType?: string(name='UseType', description='The functional module to which the workflow belongs. Valid values: NORMAL (Data Studio) and MANUAL_BIZ (Manually Triggered Workflow)', example='NORMAL'),
  }(name='Data', description='Details of the workflow.'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID. Used for troubleshooting when an error occurs.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the call was successful. Valid values:

*   true: success.
*   false: failure.', example='true'),
}

model GetBusinessResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetBusinessResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetBusiness  GetBusinessRequest
  * @return GetBusinessResponse
 */
async function getBusiness(request: GetBusinessRequest): GetBusinessResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetBusiness', 'POST', '/', 'json', true, 'form', request);
}

model GetCatalogRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The catalog entity ID. Currently supports dlf and starrocks types. You can refer to the results returned by the ListCatalogs operation and the [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

*   For the DLF type, the format is `dlf-catalog::catalog_id`.
*   For the StarRocks type, the format is `starrocks-catalog:(instance_id|encoded_jdbc_url):catalog_name`.

> \\
`catalog_id`: The ID of the DLF catalog.\\
`instance_id`: The instance ID, required if the data source is registered in instance mode.\\
`encoded_jdbc_url`: The URL-encoded JDBC connection string. Required if the data source is registered in connection string mode.\\
`catalog_name`: The name of the StarRocks catalog.

This parameter is required.', example='dlf-catalog:123456XXX:test_catalog
starrocks-catalog:c-abc123xxx:default_catalog', position='Query'),
}

model GetCatalogResponseBody = {
  catalog?: Catalog(name='Catalog', description='Catalog information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AFAE64E-D1BE-432B-A9****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetCatalogResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCatalogResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetCatalog  GetCatalogRequest
  * @return GetCatalogResponse
 */
async function getCatalog(request: GetCatalogRequest): GetCatalogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCatalog', 'GET', '/', 'json', false, 'json', request);
}

model GetCertificateRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the certificate file.

This parameter is required.', example='676303114031776', position='Query'),
  projectId?: long(name='ProjectId', description='The ID of the workspace to which the certificate file belongs.', example='1065601', position='Query'),
}

model GetCertificateResponseBody = {
  certificate?: {
    createTime?: long(name='CreateTime', description='The time when the certificate file was created. The value is a UNIX timestamp. Unit: milliseconds.', example='1730217600000'),
    createUser?: string(name='CreateUser', description='The ID of the user who created the certificate file.', example='1107550004253538'),
    description?: string(name='Description', description='The description.', example='This is a file'),
    fileSizeInBytes?: long(name='FileSizeInBytes', description='The size of the certificate file, in bytes.', example='77549'),
    id?: long(name='Id', description='The ID of the certificate file.', example='676303114031776'),
    name?: string(name='Name', description='The name of the certificate file.', example='ca1.crt'),
    projectId?: long(name='ProjectId', description='The ID of the workspace to which the certificate file belongs.', example='177161'),
  }(name='Certificate', description='The details of the certificate file.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
}

model GetCertificateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCertificateResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks: Tenant Owner, Workspace Administrator, Deploy, Develop, Workspace Owner, and O\\&M.
  * @param request  the request parameters of GetCertificate  GetCertificateRequest
  * @return GetCertificateResponse
 */
async function getCertificate(request: GetCertificateRequest): GetCertificateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCertificate', 'GET', '/', 'json', false, 'json', request);
}

model GetColumnRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID. You can refer to the response of the ListColumns operation and the [description of concepts related to metadata entities.](https://help.aliyun.com/document_detail/2880092.html)

The format: `${EntityType}:${Instance ID or escaped URL}:${Catalog identifier}:${Database name}:${Schema name}:${Table name}:${Column name}`. Use empty strings as placeholders for levels that do not exist.

>  For the MaxCompute and DLF types, use an empty string as the placeholder for the instance ID. For MaxCompute, the database name refers to the MaxCompute project name. If the project has schema enabled, you must specify the schema name. Otherwise, use an empty string as the placeholder for the schema name.

>  The catalog identifier of the StarRocks is the catalog name, and the catalog identifier of the DLF type is the catalog ID. Other types do not support catalog levels. Use empty strings as placeholders.

Examples of common ID formats

`maxcompute-column:::project_name:[schema_name]:table_name:column_name`

`dlf-column::catalog_id:database_name::table_name:column_name`

`hms-column:instance_id::database_name::table_name:column_name`

`holo-column:instance_id::database_name:schema_name:table_name:column_name`

`mysql-column:(instance_id|encoded_jdbc_url)::database_name::table_name:column_name`

> \\
`instance_id`: the ID of the instance, which is required when the data source is registered in instance mode.\\
`encoded_jdbc_url`: The URL-encoded JDBC connection string, which is required when the data source is registered via a connection string.\\
`catalog_id`: The DLF catalog ID.\\
`project_name`: The MaxCompute project name.\\
`database_name`: The database name.\\
`schema_name`: The schema name. For the MaxCompute type, this is required only if the project has enabled schema; otherwise, use an empty string as a placeholder.\\
`table_name`: The table name.\\
`column_name`: The field name.

This parameter is required.', example='maxcompute-column:11075xxxx::test_project:test_schema:test_table:test_column', position='Query'),
}

model GetColumnResponseBody = {
  column?: Column(name='Column', description='The columns in the table.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D1E2E5BC-xxxx-xxxx-xxxx-xxxxxx'),
  success?: boolean(name='Success', description='Indicates whether the request succeeded.', example='true'),
}

model GetColumnResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetColumnResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetColumn  GetColumnRequest
  * @return GetColumnResponse
 */
async function getColumn(request: GetColumnRequest): GetColumnResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetColumn', 'GET', '/', 'json', false, 'json', request);
}

model GetComponentRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  componentId: string(name='ComponentId', description='The component ID.

This parameter is required.', example='1112312312312', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the DataWorks console and go to the Workspace page to query the ID. You must configure either this parameter or the ProjectIdentifier parameter to determine the DataWorks workspace to which the operation is applied.', example='10000', position='Query'),
}

model GetComponentResponseBody = {
  component?: {
    componentId?: string(name='ComponentId', description='The ID of the dataset acceleration component. For information on how to obtain the component ID, see [ListComponents](https://help.aliyun.com/document_detail/2979566.html).', example='43cd873b-235c-44f8-be07-e4d4cf7e73b0'),
    createTime?: string(name='CreateTime', description='The creation time.

Use the UTC time format: yyyy-MM-ddTHH:mm:ss.SSSZ', example='2017-04-27T05:37:05Z'),
    description?: string(name='Description', description='The description.', example='None'),
    modifyTime?: string(name='ModifyTime', description='The modification time (millisecond-level timestamp).

Use the UTC time format: yyyy-MM-ddTHH:mm:ss.SSSZ', example='2024-01-26T07:44:21Z'),
    name?: string(name='Name', description='Parameter', example='dim_whse_epet_warehouse_jz_storage_stock_lot_relation_id'),
    owner?: string(name='Owner', description='The ID of the task owner.', example='207316543660665792'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='64623'),
    regionId?: string(name='RegionId', description='The region ID, such as ap-southeast-1. The region ID is automatically parsed from your endpoint.', example='cn-hangzhou'),
    spec?: string(name='Spec', description='The FlowSpec information for this workflow. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow/).', example='{
    "kind": "Component",
    "name": "com1",
    "spec": {
        "components": [
            {
                "name": "test11",
                "id": "8196828925037*****",
                "owner": "054664",
                "description": "",
                "script": {
                    "language": "odps-sql",
                    "path": "test11",
                    "content": "select \\"@@{bizdate}\\", \\"@@{my_input_table}\\"",
                    "runtime": {
                        "command": "SQL_COMPONENT"
                    }
                },
                "inputs": [
                    {
                        "name": "bizdate",
                        "type": "string"
                    },
                    {
                        "name": "my_input_table",
                        "type": "string"
                    }
                ],
                "outputs": [
                    {
                        "name": "my_output_table1",
                        "type": "string"
                    }
                ]
            }
        ]
    }
}'),
  }(name='Component', description='JSON serialization of the component module.'),
  requestId?: string(name='RequestId', description='Id of the request', example='0000-ABCD-EFG****'),
}

model GetComponentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetComponentResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetComponent  GetComponentRequest
  * @return GetComponentResponse
 */
async function getComponent(request: GetComponentRequest): GetComponentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetComponent', 'POST', '/', 'json', false, 'json', request);
}

model GetComputeResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='This parameter is required.', position='Query'),
  projectId: long(name='ProjectId', description='This parameter is required.', position='Query'),
}

model GetComputeResourceResponseBody = {
  computeResource?: {
    connectionProperties?: any(name='ConnectionProperties', example='{
	"envType": "Prod",
	"regionId": "cn-beijing",
    "instanceId": "hgprecn-cn-x0r3oun4k001",
    "database": "testdb",
    "securityProtocol": "authTypeNone",
    "authType": "Executor",
    "authIdentity": "1107550004253538"
}'),
    connectionPropertiesMode?: string(name='ConnectionPropertiesMode', example='InstanceMode'),
    createTime?: long(name='CreateTime', example='1698286929333'),
    createUser?: string(name='CreateUser', example='1107550004253538'),
    description?: string(name='Description', example='My Description'),
    id?: long(name='Id', example='16738'),
    modifyTime?: long(name='ModifyTime', example='1698286929333'),
    modifyUser?: string(name='ModifyUser', example='1107550004253538'),
    name?: string(name='Name', example='MyCs'),
    projectId?: long(name='ProjectId', example='52660'),
    qualifiedName?: string(name='QualifiedName', example='1107550004253538:cn-beijing:holo:hgprecn-cn-x0r3oun4k001:testdb'),
    type?: string(name='Type', example='hologres'),
    whetherDefault?: boolean(name='WhetherDefault', example='true'),
  }(name='ComputeResource'),
  requestId?: string(name='RequestId', example='9252F32F-D855-549E-8898-61CF5A733050'),
}

model GetComputeResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetComputeResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetComputeResource  GetComputeResourceRequest
  * @return GetComputeResourceResponse
 */
async function getComputeResource(request: GetComputeResourceRequest): GetComputeResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetComputeResource', 'POST', '/', 'json', false, 'json', request);
}

model GetCreateWorkflowInstancesResultRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  operationId: string(name='OperationId', description='The operation ID. This parameter is used to query the result of asynchronously creating a workflow instance. You can call the CreateWorkflowInstances operation to query the ID.

This parameter is required.', example='e15ad21c-b0e9-4792-8f55-b037xxxxxxxx', position='Query'),
}

model GetCreateWorkflowInstancesResultResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  result?: {
    failureMessage?: string(name='FailureMessage', description='The error message. This parameter is returned only if the creation fails.', example='Invalid Param xxx'),
    status?: string(name='Status', description='The creation status. Valid values:

*   Creating
*   Created
*   CreateFailure', example='Created'),
    unifiedWorkflowInstanceIds?: [ long ](name='UnifiedWorkflowInstanceIds'),
    workflowInstanceIds?: [ long ](name='WorkflowInstanceIds', description='The workflow instance IDs. This parameter is returned only if the creation is successful.'),
    workflowTaskInstanceIds?: [ long ](name='WorkflowTaskInstanceIds'),
  }(name='Result', description='The creation result of the workflow instance.'),
}

model GetCreateWorkflowInstancesResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCreateWorkflowInstancesResultResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetCreateWorkflowInstancesResult  GetCreateWorkflowInstancesResultRequest
  * @return GetCreateWorkflowInstancesResultResponse
 */
async function getCreateWorkflowInstancesResult(request: GetCreateWorkflowInstancesResultRequest): GetCreateWorkflowInstancesResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCreateWorkflowInstancesResult', 'GET', '/', 'json', false, 'json', request);
}

model GetDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='11588', deprecated='true', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11588', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
  withDetails?: boolean(name='WithDetails', description='Specifies whether to return detailed configuration information, including TransformationRules, TableMappings, and JobSettings. Valid values: true and false. Default value: true.', example='true', position='Query'),
}

model GetDIJobResponseBody = {
  pagingInfo?: {
    DIJobId?: string(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='32601', deprecated='true'),
    description?: string(name='Description', description='The description of the synchronization task.', example='description'),
    destinationDataSourceSettings?: [ 
      {
        dataSourceName?: string(name='DataSourceName', description='The name of the data source.', example='dw_mysql'),
      }
    ](name='DestinationDataSourceSettings', description='The properties of the destination.'),
    destinationDataSourceType?: string(name='DestinationDataSourceType', description='The destination type. Valid values: Hologres, OSS-HDFS, OSS, MaxCompute, LogHub, StarRocks, DataHub, AnalyticDB_For_MySQL, Kafka, Hive.', example='Hologres'),
    id?: long(name='Id', description='The ID of the synchronization task.', example='32601'),
    jobName?: string(name='JobName', description='The name of the synchronization task.', example='imp_ods_dms_det_dealer_info_df'),
    jobSettings?: {
      channelSettings?: string(name='ChannelSettings', description='The channel control settings for the synchronization task. You can configure special channel control settings for the following synchronization links: data synchronization between Hologres data sources and data synchronization from Hologres to Kafka.

1.  Holo2Kafka

*   Example: {"destinationChannelSettings":{"kafkaClientProperties":[{"key":"linger.ms","value":"100"}],"keyColumns":["col3"],"writeMode":"canal"}}
*   kafkaClientProperties: the parameters related to a Kafka producer, which are used when you write data to a Kafka data source.
*   keyColumns: the names of Kafka columns to which data is written.
*   writeMode: the writing format. Valid values: json and canal.

2.  Holo2Holo

*   Example: {"destinationChannelSettings":{"conflictMode":"replace","dynamicColumnAction":"replay","writeMode":"replay"}}
*   conflictMode: the policy used to handle a conflict that occurs during data writing to Hologres. Valid values: replace and ignore.
*   writeMode: the mode in which data is written to Hologres. Valid values: replay and insert.
*   dynamicColumnAction: the mode in which data is written to dynamic columns in a Hologres table. Valid values: replay, insert, and ignore.', example='{"structInfo":"MANAGED","storageType":"TEXTFILE","writeMode":"APPEND","partitionColumns":[{"columnName":"pt","columnType":"STRING","comment":""}],"fieldDelimiter":""}'),
      columnDataTypeSettings?: [ 
        {
          destinationDataType?: string(name='DestinationDataType', description='The data type of the destination field. Valid values: bigint, boolean, string, text, datetime, timestamp, decimal, and binary. Different types of data sources support different data types.', example='text'),
          sourceDataType?: string(name='SourceDataType', description='The data type of the source field. Valid values: bigint, boolean, string, text, datetime, timestamp, decimal, and binary. Different types of data sources support different data types.', example='bigint'),
        }
      ](name='ColumnDataTypeSettings', description='The data type mappings between source fields and destination fields.'),
      cycleScheduleSettings?: {
        cycleMigrationType?: string(name='CycleMigrationType', description='The synchronization type that requires periodic scheduling. Valid values:

*   Full: full synchronization
*   OfflineIncremental: batch incremental synchronization', example='Full'),
        scheduleParameters?: string(name='ScheduleParameters', description='The scheduling parameters.', example='bizdate=$bizdate'),
      }(name='CycleScheduleSettings', description='The settings for periodic scheduling.'),
      ddlHandlingSettings?: [ 
        {
          action?: string(name='Action', description='The processing policy for a specific type of DDL message. Valid values:

*   Ignore: ignores a DDL message.
*   Critical: reports an error for a DDL message.
*   Normal: normally processes a DDL message.', example='Ignore'),
          type?: string(name='Type', description='The DDL operation type. Valid values:

*   RenameColumn
*   ModifyColumn
*   CreateTable
*   TruncateTable
*   DropTable', example='CreateTable'),
        }
      ](name='DdlHandlingSettings', description='The DDL operation types. Valid values:

*   RenameColumn
*   ModifyColumn
*   CreateTable
*   TruncateTable
*   DropTable
*   DropColumn
*   AddColumn'),
      runtimeSettings?: [ 
        {
          name?: string(name='Name', description='The name of the configuration item. Valid values:

*   src.offline.datasource.max.connection: indicates the maximum number of connections that are allowed for reading data from the source of a batch synchronization task.
*   dst.offline.truncate: indicates whether to clear the destination table before data writing.
*   runtime.offline.speed.limit.enable: indicates whether throttling is enabled for a batch synchronization task.
*   runtime.offline.concurrent: indicates the maximum number of parallel threads that are allowed for a batch synchronization task.
*   runtime.enable.auto.create.schema: indicates whether schemas are automatically created in the destination of a synchronization task.
*   runtime.realtime.concurrent: indicates the maximum number of parallel threads that are allowed for a real-time synchronization task.
*   runtime.realtime.failover.minute.dataxcdc: indicates the maximum waiting duration before a synchronization task retries the next restart if the previous restart fails after failover occurs. Unit: minutes.
*   runtime.realtime.failover.times.dataxcdc: indicates the maximum number of failures that are allowed for restarting a synchronization task after failovers occur.', example='runtime.offline.concurrent'),
          value?: string(name='Value', description='The value of the configuration item.', example='1'),
        }
      ](name='RuntimeSettings', description='The runtime settings.'),
    }(name='JobSettings', description='The runtime settings.'),
    jobStatus?: string(name='JobStatus', description='The status of the job.', example='Running'),
    jobType?: string(name='JobType', description='任务类型

- DatabaseRealtimeMigration(整库实时):将源端多个库的多个表进行流同步，支持仅全量，仅增量，或全量+增量。

- DatabaseOfflineMigration(整库离线):将源端多个库的多个表进行批同步，支持仅全量，仅增量，或全量+增量。

- SingleTableRealtimeMigration(单表实时):将源端单个表进行流同步。', example='DatabaseRealtimeMigration'),
    migrationType?: string(name='MigrationType', description='The synchronization type. Valid values:

*   FullAndRealtimeIncremental: full synchronization and real-time incremental synchronization of data in an entire database
*   RealtimeIncremental: real-time incremental synchronization of data in a single table
*   Full: full batch synchronization of data in an entire database
*   OfflineIncremental: batch incremental synchronization of data in an entire database
*   FullAndOfflineIncremental: full synchronization and batch incremental synchronization of data in an entire database', example='FullAndRealtimeIncremental'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter indicates the DataWorks workspace to which the API operation is applied.', example='98330'),
    resourceSettings?: {
      offlineResourceSettings?: {
        requestedCu?: double(name='RequestedCu', description='The number of compute units (CUs) in the resource group for scheduling that are used for batch synchronization.', example='2.0'),
        resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for Data Integration used for batch synchronization.', example='S_res_group_7708_1667792816832'),
      }(name='OfflineResourceSettings', description='The resource used for batch synchronization.'),
      realtimeResourceSettings?: {
        requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for Data Integration that are used for real-time synchronization.', example='2.0'),
        resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for Data Integration used for real-time synchronization.', example='S_res_group_235454102432001_1579085295030'),
      }(name='RealtimeResourceSettings', description='The resource used for real-time synchronization.'),
      scheduleResourceSettings?: {
        requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for Data Integration that are used for scheduling.', example='2.0'),
        resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for scheduling used by the synchronization task.', example='S_res_group_235454102432001_1718359176885'),
      }(name='ScheduleResourceSettings', description='The resource used for scheduling.'),
    }(name='ResourceSettings', description='The resource settings.'),
    sourceDataSourceSettings?: [ 
      {
        dataSourceName?: string(name='DataSourceName', description='The name of the data source.', example='dw_mysql'),
        dataSourceProperties?: {
          encoding?: string(name='Encoding', description='The encoding format of the database.', example='UTF-8'),
          timezone?: string(name='Timezone', description='The time zone.', example='GMT+8'),
        }(name='DataSourceProperties', description='The properties of the data source.'),
      }
    ](name='SourceDataSourceSettings', description='The settings of the source. Only a single source is supported.'),
    sourceDataSourceType?: string(name='SourceDataSourceType', description='The source type. Valid values: PolarDB, MySQL, Kafka, LogHub, Hologres, Oracle, OceanBase, MongoDB, RedShift, Hive, SQLServer, Doris, ClickHouse.', example='Mysql'),
    tableMappings?: [ 
      {
        sourceObjectSelectionRules?: [ 
          {
            action?: string(name='Action', description='The operation that is performed to select objects. Valid values: Include and Exclude.', example='Include'),
            expression?: string(name='Expression', description='The expression.', example='mysql_table_1'),
            expressionType?: string(name='ExpressionType', description='The expression type. Valid values: Exact and Regex.', example='Exact'),
            objectType?: string(name='ObjectType', description='The object type. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
          }
        ](name='SourceObjectSelectionRules', description='The list of rules used to select synchronization objects in the source.'),
        transformationRules?: [ 
          {
            ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml', example='AddColumn'),
            ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
            ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which the action is performed. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
          }
        ](name='TransformationRules', description='The list of transformation rules that are applied to the synchronization objects selected from the source. Each entry in the list defines a transformation rule.'),
      }
    ](name='TableMappings', description='The list of mappings between rules used to select synchronization objects in the source and transformation rules applied to the selected synchronization objects. Each entry in the list displays a mapping between a rule used to select synchronization objects and a transformation rule applied to the selected synchronization objects.

>  [ { "SourceObjectSelectionRules":[ { "ObjectType":"Database", "Action":"Include", "ExpressionType":"Exact", "Expression":"biz_db" }, { "ObjectType":"Schema", "Action":"Include", "ExpressionType":"Exact", "Expression":"s1" }, { "ObjectType":"Table", "Action":"Include", "ExpressionType":"Exact", "Expression":"table1" } ], "TransformationRuleNames":[ { "RuleName":"my_database_rename_rule", "RuleActionType":"Rename", "RuleTargetType":"Schema" } ] } ]'),
    transformationRules?: [ 
      {
        ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml
*   DefineIncrementalCondition
*   DefineCycleScheduleSettings
*   DefinePartitionKey', example='Rename'),
        ruleExpression?: string(name='RuleExpression', description='The expression of the rule. The expression is a JSON string.

1.  Example of a renaming rule

*   Example: {"expression":"${srcDatasourceName}_${srcDatabaseName}_0922" }
*   expression: the expression of the renaming rule. You can use the following variables in an expression: ${srcDatasourceName}, ${srcDatabaseName}, and ${srcTableName}. ${srcDatasourceName} indicates the name of the source. ${srcDatabaseName} indicates the name of a source database. ${srcTableName} indicates the name of a source table.

2.  Example of a column addition rule

*   Example: {"columns":[{"columnName":"my_add_column","columnValueType":"Constant","columnValue":"123"}]}
*   If no rule of this type is configured, no fields are added to the destination and no values are assigned by default.
*   columnName: the name of the field that is added.
*   columnValueType: the value type of the field. Valid values: Constant and Variable.
*   columnValue: the value of the field. If the columnValueType parameter is set to Constant, the value of the columnValue parameter is a constant of the STRING data type. If the columnValueType parameter is set to Variable, the value of the columnValue parameter is a built-in variable. The following built-in variables are supported: EXECUTE_TIME (LONG data type), DB_NAME_SRC (STRING data type), DATASOURCE_NAME_SRC (STRING data type), TABLE_NAME_SRC (STRING data type), DB_NAME_DEST (STRING data type), DATASOURCE_NAME_DEST (STRING data type), TABLE_NAME_DEST (STRING data type), and DB_NAME_SRC_TRANSED (STRING data type). EXECUTE_TIME indicates the execution time. DB_NAME_SRC indicates the name of a source database. DATASOURCE_NAME_SRC indicates the name of the source. TABLE_NAME_SRC indicates the name of a source table. DB_NAME_DEST indicates the name of a destination database. DATASOURCE_NAME_DEST indicates the name of the destination. TABLE_NAME_DEST indicates the name of a destination table. DB_NAME_SRC_TRANSED indicates the database name obtained after a transformation.

3.  Example of a rule used to specify primary key fields for a destination table

*   Example: {"columns":["ukcolumn1","ukcolumn2"]}
*   If no rule of this type is configured, the primary key fields in the mapped source table are used for the destination table by default.
*   If the destination table is an existing table, Data Integration does not modify the schema of the destination table. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run.
*   If the destination table is automatically created by the system, Data Integration automatically creates the schema of the destination table. The schema contains the primary key fields that you specify. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run.

4.  Example of a rule used to process DML messages

*   Example: {"dmlPolicies":[{"dmlType":"Delete","dmlAction":"Filter","filterCondition":"id > 1"}]}
*   If no rule of this type is configured, the default processing policy for messages generated for insert, update, and delete operations is Normal.
*   dmlType: the DML operation. Valid values: Insert, Update, and Delete.
*   dmlAction: the processing policy for DML messages. Valid values: Normal, Ignore, Filter, and LogicalDelete. Filter indicates conditional processing. The value Filter is returned for the dmlAction parameter only when the value of the dmlType parameter is Update or Delete.
*   filterCondition: the condition used to filter DML messages. This parameter is returned only when the value of the dmlAction parameter is Filter.

5.  Example of a rule used to perform incremental synchronization

*   Example: {"where":"id > 0"}
*   The rule used to perform incremental synchronization is returned.

6.  Example of a rule used to configure scheduling parameters for an auto triggered task

*   Example: {"cronExpress":" \\* \\* \\* \\* \\* \\*", "cycleType":"1"}
*   The rule used to configure scheduling parameters for an auto triggered task is returned.

7.  Example of a rule used to specify a partition key

*   Example: {"columns":["id"]}
*   The rule used to specify a partition key is returned.', example='{"expression":"${srcDatasoureName}_${srcDatabaseName}"}'),
        ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
        ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which the action is performed. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
      }
    ](name='TransformationRules', description='The list of transformation rules that are applied to the synchronization objects selected from the source.

>  [ { "RuleName":"my_database_rename_rule", "RuleActionType":"Rename", "RuleTargetType":"Schema", "RuleExpression":"{"expression":"${srcDatasoureName}_${srcDatabaseName}"}" } ]'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADE490'),
}

model GetDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDIJob  GetDIJobRequest
  * @return GetDIJobResponse
 */
async function getDIJob(request: GetDIJobRequest): GetDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDIJob', 'GET', '/', 'json', false, 'json', request);
}

model GetDIJobLogRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='10000', deprecated='true', position='Query'),
  failoverId?: long(name='FailoverId', description='The failover ID.', example='10', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='10000', position='Query'),
  instanceId?: long(name='InstanceId', description='The instance ID.', example='6153616438', position='Query'),
  nodeType?: string(name='NodeType', description='The type of the node. This parameter is applicable only to the tasks that are run on serverless resource groups. Valid values:

*   **MASTER**: the master node, which is used to query the logs of JobManagers.
*   **WORKER**: the worker node, which is used to query the logs of TaskManagers.', example='MASTER', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number of the pagination query. The value is a positive integer greater than or equal to 1.', example='1', position='Query'),
}

model GetDIJobLogResponseBody = {
  log?: string(name='Log', description='The log.', example='>>>>>>>> stdout:n++++++++++++++++++executing sql: create database if not exists jindo_test location \\"oss://pangbei-hdfs/tmp/hive\\" n++n'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='1AFAE64E-D1BE-432B-A9****'),
}

model GetDIJobLogResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDIJobLogResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDIJobLog  GetDIJobLogRequest
  * @return GetDIJobLogResponse
 */
async function getDIJobLog(request: GetDIJobLogRequest): GetDIJobLogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDIJobLog', 'GET', '/', 'json', false, 'json', request);
}

model GetDataQualityAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The data quality monitoring alert rule ID.', example='113642', position='Query'),
}

model GetDataQualityAlertRuleResponseBody = {
  dataQualityAlertRule?: {
    condition?: string(name='Condition', description='Alert conditions of the data quality monitoring alert rule.', example='results.any { r -> r.status == \\"fail\\" && r.rule.severity == \\"High\\" }'),
    id?: long(name='Id', description='The ID of the data quality monitoring alert rule.', example='21045'),
    notification?: {
      channels?: [ string ](name='Channels', description='In Channels, you can set both Email and Sms at the same time. In other cases, only one channel can be set.'),
      receivers?: [ 
        {
          extension?: string(name='Extension', description='Additional configurations required for the alert recipients. When ReceiverType is DingdingUrl, you can set `{"atAll":true}` to mention all members.', example='{"atAll":true}'),
          receiverType?: string(name='ReceiverType', description='The type of alert recipients.

*   ShiftSchedule
*   WebhookUrl
*   FeishuUrl
*   TaskOwner
*   WeixinUrl
*   DingdingUrl
*   DataQualityScanOwner
*   AliUid', example='TaskOwner'),
          receiverValues?: [ string ](name='ReceiverValues', description='The value of alert recipients.'),
        }
      ](name='Receivers', description='The alert recipients.'),
    }(name='Notification', description='Alert notification settings.'),
    projectId?: long(name='ProjectId', description='The project ID.', example='90912'),
    target?: {
      ids?: [ long ](name='Ids', description='The list of monitored target IDs.'),
      type?: string(name='Type', description='The type of the monitored target. Only `DataQualityScan` is supported.', example='DataQualityScan'),
    }(name='Target', description='The monitored target of the data quality monitoring alert rule.'),
  }(name='DataQualityAlertRule', description='Data quality monitoring alert rules.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0bc14115****159376359'),
}

model GetDataQualityAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityAlertRuleResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDataQualityAlertRule  GetDataQualityAlertRuleRequest
  * @return GetDataQualityAlertRuleResponse
 */
async function getDataQualityAlertRule(request: GetDataQualityAlertRuleRequest): GetDataQualityAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityAlertRule', 'POST', '/', 'json', false, 'json', request);
}

model GetDataQualityEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The ID of the data quality monitor.', example='1006455182', position='Query'),
}

model GetDataQualityEvaluationTaskResponseBody = {
  dataQualityEvaluationTask?: {
    dataSourceId?: long(name='DataSourceId', description='The ID of the data source used for the monitor.', example='45238'),
    description?: string(name='Description', description='The description of the monitor.', example='The description of the quality monitoring task.'),
    hooks?: [ 
      {
        condition?: string(name='Condition', description='The hook trigger condition. When this condition is met, the hook action is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
        type?: string(name='Type', description='The hook type. Only one hook type is supported.

*   BlockTaskInstance: Blocks the running of scheduling tasks. A monitor is triggered by scheduling tasks. After a monitor finishes running, the monitor determines whether to block the running of scheduling tasks based on the hook condition.', example='BlockTaskInstance'),
      }
    ](name='Hooks', description='The hook.'),
    id?: long(name='Id', description='The ID of the data quality monitor.', example='2178'),
    name: string(name='Name', description='The name of the monitor.

This parameter is required.', example='OpenAPI create a data quality monitoring test'),
    notifications?: {
      condition?: string(name='Condition', description='The notification trigger condition. When this condition is met, the alert notification is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High"AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
      notifications?: [ 
        {
          notificationChannels?: [ 
            {
              channels?: [ string ](name='Channels', description='The alert notification methods.'),
            }
          ](name='NotificationChannels', description='The alert notification methods.'),
          notificationReceivers?: [ 
            {
              extension?: string(name='Extension', description='The extended information.', example='{  "atAll": true }'),
              receiverType?: string(name='ReceiverType', description='The additional parameters that are required when alerts are sent. The parameters are JSON-formatted strings. The following keys are supported:

*   atAll: specifies that all members in a group are mentioned when alerts are sent by using DingTalk. This parameter is valid only if you set ReceiverType to DingdingUrl.

Valid values:

*   WebhookUrl
*   FeishuUrl
*   DingdingUrl
*   WeixinUrl
*   AliUid', example='DingdingUrl'),
              receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
            }
          ](name='NotificationReceivers', description='The configurations of alert recipients.'),
        }
      ](name='Notifications', description='The configurations of alert notifications.'),
    }(name='Notifications', description='The configurations of alert notifications.'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='2626'),
    runtimeConf?: string(name='RuntimeConf', description='Extended configuration, JSON-formatted string, takes effect only for EMR-type data quality monitoring.

- queue: the yarn queue used when performing EMR data quality verification. The default queue is the queue configured for this project.
- sqlEngine: SQL engine used when performing EMR data verification
    - HIVE_ SQL
    - SPARK_ SQL', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }'),
    target?: {
      databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   hologres
*   cdh
*   analyticdb_for_mysql
*   starrocks
*   emr
*   analyticdb_for_postgresql', example='maxcompute'),
      partitionSpec?: string(name='PartitionSpec', description='Data quality monitoring partition range settings.', example='pt=$[yyyymmdd-1]'),
      tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.meta_open_api_test_sz.test_partition_tbl'),
      type?: string(name='Type', description='The type of the monitoring object.

- Table: Table.', example='Table'),
    }(name='Target', description='The monitored object of the monitor.'),
    trigger?: {
      taskIds?: [ long ](name='TaskIds', description='The IDs of scheduling tasks. This parameter is valid only if you set Type to ByScheduledTaskInstance.'),
      type?: string(name='Type', description='The trigger type of the monitor. Valid values:

*   ByManual: The monitor is manually triggered.
*   ByScheduledTaskInstance: The monitor is triggered by associated scheduling tasks.
*   ByQualityNode: The monitor is triggered by created data quality monitoring nodes.', example='ByScheduledTaskInstance'),
    }(name='Trigger', description='The trigger configuration of the monitor.'),
  }(name='DataQualityEvaluationTask', description='The details of the monitor.'),
  requestId?: string(name='RequestId', description='Id of the request', example='SDFSDFSDF-SDFSDF-SDFDSF-SDFSDF'),
}

model GetDataQualityEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityEvaluationTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDataQualityEvaluationTask  GetDataQualityEvaluationTaskRequest
  * @return GetDataQualityEvaluationTaskResponse
 */
async function getDataQualityEvaluationTask(request: GetDataQualityEvaluationTaskRequest): GetDataQualityEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityEvaluationTask', 'GET', '/', 'json', false, 'json', request);
}

model GetDataQualityEvaluationTaskInstanceRequest {
  regionId?: string(name='RegionId', position='Host'),
  id: long(name='Id', description='The ID of the data quality monitoring instance.

This parameter is required.', example='7227550902', position='Query'),
}

model GetDataQualityEvaluationTaskInstanceResponseBody = {
  dataQualityEvaluationTaskInstance?: {
    createTime?: long(name='CreateTime', description='The creation time.', example='1716344665000'),
    finishTime?: long(name='FinishTime', description='The end time of the instance.', example='1716344665000'),
    id?: long(name='Id', description='The ID of the data quality monitoring instance.', example='7234231689'),
    parameters?: string(name='Parameters', description='Data quality verification execution parameters in JSON format. The available keys are as follows:
- triggerTime: the millisecond timestamp of the trigger time. The baseline time of the $[yyyymmdd] expression in the data range of data quality monitoring. Required.', example='{ "triggerTime": 1733284062000 }'),
    projectId?: long(name='ProjectId', description='The ID of the workspace.', example='98330'),
    results?: [ 
      {
        createTime?: long(name='CreateTime'),
        details?: [ 
          {
            checkedValue?: string(name='CheckedValue'),
            referencedValue?: string(name='ReferencedValue'),
            status?: string(name='Status'),
          }
        ](name='Details'),
        id?: long(name='Id'),
        rule?: {
          checkingConfig?: {
            referencedSamplesFilter?: string(name='ReferencedSamplesFilter'),
            thresholds?: {
              critical?: {
                expression?: string(name='Expression'),
                operator?: string(name='Operator'),
                value?: string(name='Value'),
              }(name='Critical'),
              expected?: {
                expression?: string(name='Expression'),
                operator?: string(name='Operator'),
                value?: string(name='Value'),
              }(name='Expected'),
              warned?: {
                expression?: string(name='Expression'),
                operator?: string(name='Operator'),
                value?: string(name='Value'),
              }(name='Warned'),
            }(name='Thresholds'),
            type?: string(name='Type'),
          }(name='CheckingConfig'),
          description?: string(name='Description'),
          enabled?: boolean(name='Enabled'),
          errorHandlers?: [ 
            {
              errorDataFilter?: string(name='ErrorDataFilter'),
              type?: string(name='Type'),
            }
          ](name='ErrorHandlers'),
          id?: long(name='Id'),
          name?: string(name='Name'),
          projectId?: long(name='ProjectId'),
          samplingConfig?: {
            metric?: string(name='Metric'),
            metricParameters?: string(name='MetricParameters'),
            samplingFilter?: string(name='SamplingFilter'),
            settingConfig?: string(name='SettingConfig'),
          }(name='SamplingConfig'),
          severity?: string(name='Severity'),
          target?: {
            databaseType?: string(name='DatabaseType'),
            tableGuid?: string(name='TableGuid'),
            type?: string(name='Type'),
          }(name='Target'),
          templateCode?: string(name='TemplateCode'),
        }(name='Rule'),
        sample?: string(name='Sample'),
        status?: string(name='Status'),
        taskInstanceId?: long(name='TaskInstanceId'),
      }
    ](name='Results'),
    status?: string(name='Status', description='The status of the data quality monitoring instance.
- Running: Verifying
- Error: A rule verification Error occurred.
- Passed: all rules are verified
- Warned: normal alarm threshold triggered by rules
- Critical: Threshold for serious alerts triggered by rules', example='Passed'),
    task?: {
      description?: string(name='Description', description='The description of the monitor.', example='OpenAPI quality monitoring test'),
      hooks?: [ 
        {
          condition?: string(name='Condition', description='The hook trigger condition. When this condition is met, the hook action is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
          type?: string(name='Type', description='Hook type. Currently, only one type is supported:

- BlockTaskInstance: the blocking scheduling task continues to run. Data quality monitoring is triggered by the scheduling task. After the data quality monitoring is completed, the Hook.Condition is used to determine whether the blocking scheduling task continues to run.', example='BlockTaskInstance'),
        }
      ](name='Hooks', description='The hook.'),
      id?: long(name='Id', description='The ID of the data quality monitor.', example='28544990'),
      name?: string(name='Name', description='The name of the monitor.', example='Data quality OpenAPI monitoring test'),
      notifications?: {
        condition?: string(name='Condition', description='The notification trigger condition. When this condition is met, the alert notification is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='${severity} == "High" AND ${status} == "Critical"'),
        notifications?: [ 
          {
            notificationChannels?: [ 
              {
                channels?: [ string ](name='Channels', description='The notification method.'),
              }
            ](name='NotificationChannels', description='The notification method.'),
            notificationReceivers?: [ 
              {
                extension?: string(name='Extension', description='Additional parameter settings for sending alerts in json format. The supported keys are as follows:

- atAll: when sending DingTalk alerts, do you need to @ everyone in the group. It takes effect when ReceiverType is DingdingUrl.', example='{ "atAll": true }'),
                receiverType?: string(name='ReceiverType', description='The type of alert recipient.', example='DingdingUrl'),
                receiverValues?: [ string ](name='ReceiverValues', description='The recipient of the alert.'),
              }
            ](name='NotificationReceivers', description='The value of the receiver.'),
          }
        ](name='Notifications', description='The alert notification methods.'),
      }(name='Notifications', description='The configurations of alert notifications.'),
      projectId?: long(name='ProjectId', description='The ID of the workspace.', example='20629'),
      runtimeConf?: string(name='RuntimeConf', description='Extended configuration, JSON-formatted string, takes effect only for EMR-type data quality monitoring.

- queue: the yarn queue used when performing EMR data quality verification. The default queue is the queue configured for this project.
- sqlEngine: SQL engine used when performing EMR data verification
  - HIVE_ SQL
  - SPARK_ SQL', example='{ "queue": "default" }'),
      target?: {
        databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs.', example='maxcompute'),
        partitionSpec?: string(name='PartitionSpec', description='The partition range monitored.', example='pt=$[yyyymmdd-1]'),
        tableGuid?: string(name='TableGuid', description='The unique ID of the table in the data map.', example='odps.api_trace.ods_d_api_log'),
        type?: string(name='Type', description='The type of the monitoring object.
- Table: Table', example='Table'),
      }(name='Target', description='The monitored object of the monitor.'),
      trigger?: {
        taskIds?: [ long ](name='TaskIds', description='The Id list of the scheduled task, which is valid when the Type is ByScheduledTaskInstance.'),
        type?: string(name='Type', description='The trigger type of the monitor. Valid values:

*   ByManual (default): The monitor is manually triggered.
*   ByScheduledTaskInstance: The monitor is triggered by the associated scheduling tasks.', example='ByScheduledTaskInstance'),
      }(name='Trigger', description='The trigger configuration of the monitor.'),
    }(name='Task', description='The monitor.'),
    triggerContext?: string(name='TriggerContext', description='The context information when the instance is triggered, in JSON format. The possible keys are as follows:
- TriggerClient: the trigger source of the data quality monitoring instance, such as CWF2 (scheduling system), may be added later.
- TriggerClientId: associated with a specific business resource in the source system. For example, if TriggerClient is CWF2, the ID of the scheduling task is recorded here.', example='{ "triggerClient": "CWF2", "triggerClientId": 70001238945 }'),
  }(name='DataQualityEvaluationTaskInstance', description='The details of the monitor instance.'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
}

model GetDataQualityEvaluationTaskInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityEvaluationTaskInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDataQualityEvaluationTaskInstance  GetDataQualityEvaluationTaskInstanceRequest
  * @return GetDataQualityEvaluationTaskInstanceResponse
 */
async function getDataQualityEvaluationTaskInstance(request: GetDataQualityEvaluationTaskInstanceRequest): GetDataQualityEvaluationTaskInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityEvaluationTaskInstance', 'GET', '/', 'json', false, 'json', request);
}

model GetDataQualityRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id: long(name='Id', description='The rule ID.

This parameter is required.', example='19715', position='Query'),
}

model GetDataQualityRuleResponseBody = {
  dataQualityRule?: {
    checkingConfig?: {
      referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference values. In this example, an expression is used to indicate the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
      thresholds?: {
        critical?: {
          expression?: string(name='Expression', description='The threshold expression.', example='$checkValue > 0.05'),
          operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
          value?: string(name='Value', description='The threshold value.', example='100.0'),
        }(name='Critical', description='The threshold settings for critical alerts.'),
        expected?: {
          expression?: string(name='Expression', description='The threshold expression.', example='$checkValue <= 0.01'),
          operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
          value?: string(name='Value', description='The threshold value.', example='100.0'),
        }(name='Expected', description='The expected threshold setting.'),
        warned?: {
          expression?: string(name='Expression', description='The threshold expression.', example='$checkValue > 0.01'),
          operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
          value?: string(name='Value', description='The threshold value.', example='100.0'),
        }(name='Warned', description='The threshold settings for normal alerts.'),
      }(name='Thresholds', description='The threshold settings.'),
      type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
    }(name='CheckingConfig', description='The check settings for sample data.'),
    description?: string(name='Description', description='The description of the rule. The description can be up to 500 characters in length.', example='this is a odps _sql task'),
    enabled?: boolean(name='Enabled', description='Indicates whether the rule is enabled.', example='true'),
    errorHandlers?: [ 
      {
        errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If you define the rule by using custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
        type?: string(name='Type', description='Processor type:
- SaveErrorData', example='SaveErrorData'),
      }
    ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
    id?: long(name='Id', description='The rule ID.', example='16033'),
    name?: string(name='Name', description='The rule name.', example='The table cannot be empty.'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='1948'),
    samplingConfig?: {
      metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='Max'),
      metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
      samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='id IS NULL'),
      settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;'),
    }(name='SamplingConfig', description='The sampling settings.'),
    severity?: string(name='Severity', description='Rule for the business level (corresponding to the strong and weak rules on the page), optional enumeration value:
- Normal
- High', example='High'),
    target?: {
      databaseType?: string(name='DatabaseType', description='The dataset of the table type. The database type to which the table belongs.
- maxcompute
- emr
- cdh
- hologres
- analyticdb_for_postgresql
- analyticdb_for_mysql
- starrocks', example='maxcompute'),
      partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='ds=$[yyyymmdd-1]'),
      tableGuid?: string(name='TableGuid', description='The ID of the table that is limited by the rule in Data Map.', example='odps.unit_test.tb_unit_test'),
      type?: string(name='Type', description='Monitoring object type

- Table', example='Table'),
    }(name='Target', description='The monitored object of the rule.'),
    templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='system::user_defined'),
  }(name='DataQualityRule', description='The information about the rule.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model GetDataQualityRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityRuleResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDataQualityRule  GetDataQualityRuleRequest
  * @return GetDataQualityRuleResponse
 */
async function getDataQualityRule(request: GetDataQualityRuleRequest): GetDataQualityRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityRule', 'GET', '/', 'json', false, 'json', request);
}

model GetDataQualityRuleTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  code: string(name='Code', description='The code for the template.

This parameter is required.', example='USER_DEFINED:123', position='Query'),
}

model GetDataQualityRuleTemplateResponseBody = {
  dataQualityRuleTemplate?: {
    checkingConfig?: {
      referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference samples and perform aggregate operations on the reference values. In this example, an expression is used to indicate the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
      type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
    }(name='CheckingConfig', description='The check settings for sample data.'),
    code?: string(name='Code', description='The code for the template.', example='USER_DEFINED:123'),
    directoryPath?: string(name='DirectoryPath', description='The directory in which the template is stored. Slashes (/) are used to separate directory levels. The name of each directory level can be up to 1,024 characters in length. It cannot contain whitespace characters or slashes (/).', example='/ods/order_data'),
    name?: string(name='Name', description='The name of the template. The name can be up to 512 characters in length and can contain digits, letters, and punctuation marks.', example='Table row Count Verification'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='4020'),
    samplingConfig?: {
      metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='Max'),
      metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{"SQL": "select count(1) from table;"}'),
      settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;'),
    }(name='SamplingConfig', description='The sampling settings.'),
    visibleScope?: string(name='VisibleScope', description='Available range of templates:
- Tenant: all tenants are available
- Project: only available in the current Project', example='Project'),
  }(name='DataQualityRuleTemplate', description='The information about the template.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model GetDataQualityRuleTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityRuleTemplateResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDataQualityRuleTemplate  GetDataQualityRuleTemplateRequest
  * @return GetDataQualityRuleTemplateResponse
 */
async function getDataQualityRuleTemplate(request: GetDataQualityRuleTemplateRequest): GetDataQualityRuleTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityRuleTemplate', 'GET', '/', 'json', false, 'json', request);
}

model GetDataQualityScanRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The ID of the monitor.', example='10001', position='Query'),
}

model GetDataQualityScanResponseBody = {
  dataQualityScan?: {
    computeResource?: {
      envType?: string(name='EnvType', description='The workspace environment to which the compute engine belongs.

Valid values:

*   Prod: production environment .
*   Dev: development environment.', example='Prod'),
      name?: string(name='Name', description='The name of the compute engine, which is a unique identifier.', example='polardb_to_holo'),
      runtime?: {
        engine?: string(name='Engine', description='The type of the compute engine. Only EMR compute engines support these settings.

Valid values:

*   Hive: Hive SQL
*   Spark: Spark SQL
*   Kyuubi', example='Hive'),
        hiveConf?: map[string]any(name='HiveConf', description='Additional Hive engine parameters. Currently, only the mapreduce.job.queuename parameter is supported.', example='mapreduce.job.queuename=dq_queue'),
        sparkConf?: map[string]any(name='SparkConf', description='Additional Spark engine parameters. Currently, only the spark.yarn.queue parameter is supported.', example='spark.yarn.queue=dq_queue'),
      }(name='Runtime', description='More settings for data quality monitor at runtime.'),
    }(name='ComputeResource', description='The compute engine used at runtime. Optional. If not specified, the data source defined in the Spec is used.'),
    createTime?: long(name='CreateTime', description='The creation time of the data quality monitor.', example='1731550150000'),
    createUser?: string(name='CreateUser', description='The ID of the user who creates the data quality monitor.', example='2374924198591250'),
    description?: string(name='Description', description='The data quality monitor description.', example='aily data quality scanning of ods tables.'),
    hooks?: [ 
      {
        condition?: string(name='Condition', description='The Hook trigger condition. The hook will run if the condition is met. Currently, only one type of expression syntax is supported:

*   You can specify multiple combinations of rule severity levels and validation statuses using an expression such as `results.any { r -> r.status == \\"Fail\\" && r.rule.severity == \\"Normal\\" || r.status == \\"Error\\" && r.rule.severity == \\"High\\" || r.status == \\"Warn\\" && r.rule.severity == \\"High\\" }`. This expression means the condition is met if any executed rule has a result of Fail with severity Normal, Error with severity High, or Warn with severity High. In the condition expression, the values of severity and status are predefined enums. The values of severity must match those defined in the Spec, and the values of status must match those in DataQualityResult.', example='results.any { r -> r.status == \\"Fail\\" && r.rule.severity == \\"Normal\\" || r.status == \\"Error\\" && r.rule.severity == \\"High\\" || r.status == \\"Warn\\" && r.rule.severity == \\"High\\" }'),
        type?: string(name='Type', description='The type of the Hook.

Valid values:

*   BlockTaskInstance: BlockTaskInstance: Blocks the scheduling of the task instance.', example='BlockTaskInstance'),
      }
    ](name='Hooks', description='The Hook configurations after the data quality monitoring run ends.'),
    id?: long(name='Id', description='The data quality monitoring ID.', example='10001'),
    modifyTime?: long(name='ModifyTime', description='Last modified time of the data quality monitor.', example='1731550150000'),
    modifyUser?: string(name='ModifyUser', description='The ID of the user who last modifies the data quality monitor.', example='23482597582479'),
    name?: string(name='Name', description='The data quality monitor name.', example='data_quality_scan_001'),
    owner?: string(name='Owner', description='The ID of the user who owns the data quality monitor.', example='231263586109857423'),
    parameters?: [ 
      {
        name?: string(name='Name', description='The parameter value.', example='e2e_autolabel'),
        value?: string(name='Value', description='The parameter name.', example='10'),
      }
    ](name='Parameters', description='The definition of execution parameters for the data quality monitor.'),
    projectId?: long(name='ProjectId', description='The workspace ID where the data quality monitor resides. You can obtain the workspace ID by calling the [ListProjects](https://help.aliyun.com/document_detail/2780068.html) operation.', example='101'),
    runtimeResource?: {
      cu?: float(name='Cu', description='Reserved compute units (CU) for the resource group.', example='10'),
      id?: string(name='Id', description='The resource group ID.', example='122878'),
      image?: string(name='Image', description='The image ID used in the runtime configuration.', example='hp-tlp-e2e-repo-registry-vpc.cn-heyuan-acdr-1.cr.aliyuncs.com/hp-service/worker:9b28b6d-202506091008'),
    }(name='RuntimeResource', description='The resource group used during the running of the data quality monitor.'),
    spec?: string(name='Spec', description='Spec code for the content of the data quality monitoring.', example='{
    "datasets": [
        {
            "type": "Table",
            "dataSource": {
                "name": "odps_first",
                "envType": "Prod"
            },
            "tables": [
                "ods_d_user_info"
            ],
            "filter": "pt = $[yyyymmdd-1]"
        }
    ],
    "rules": [
        {
            "assertion": "row_count > 0"
        }, {
            "templateId": "SYSTEM:field:null_value:fixed",
            "pass": "when = 0",
            "name": "The id cannot be empty.",
            "severity": "High",
             "identity": "a-customized-data-quality-rule-uuid"
        }
    ]
}'),
    trigger?: {
      taskIds?: [ long ](name='TaskIds', description='If the trigger mode is set to BySchedule, the scheduling task ID must be specified.'),
      type?: string(name='Type', description='The trigger mode of the monitoring task.

Valid values:

*   ByManual: Manual trigger. This is the default setting.
*   BySchedule: Triggered by a scheduled task instance.', example='BySchedule'),
    }(name='Trigger', description='The trigger configurations of the data quality monitoring task.'),
  }(name='DataQualityScan', description='Data quality monitoring details.'),
  requestId?: string(name='RequestId', description='Id of the request', example='204EAF68-CCE3-5112-8DA0-E7A60F02XXXX'),
}

model GetDataQualityScanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityScanResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDataQualityScan  GetDataQualityScanRequest
  * @return GetDataQualityScanResponse
 */
async function getDataQualityScan(request: GetDataQualityScanRequest): GetDataQualityScanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityScan', 'POST', '/', 'json', false, 'json', request);
}

model GetDataQualityScanRunRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The data quality monitoring run record ID.', example='1006059507', position='Query'),
}

model GetDataQualityScanRunResponseBody = {
  dataQualityScanRun?: {
    createTime?: long(name='CreateTime', description='The time when the data quality monitor starts running.', example='1706247622000'),
    finishTime?: long(name='FinishTime', description='The time when the data quality monitor stops.', example='1706247622000'),
    id?: long(name='Id', description='The running record ID.', example='1016440997'),
    parameters?: [ 
      {
        name?: string(name='Name', description='The parameter name.', example='dt'),
        value?: string(name='Value', description='The parameter value.', example='$[yyyy-mm-dd-1]'),
      }
    ](name='Parameters', description='The parameter settings used during the actual running.'),
    results?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the validation result is generated.', example='1725506795000'),
        details?: [ 
          {
            checkValue?: string(name='CheckValue', description='The final value used for comparison with the threshold.', example='100.0'),
            referenceValue?: string(name='ReferenceValue', description='The reference sample used as the baseline for calculating the CheckedValue.', example='0.0'),
            status?: string(name='Status', description='The final comparison result status.

*   Pass
*   Error
*   Warn
*   Fail', example='Fail'),
          }
        ](name='Details', description='The information about the data quality check.'),
        rule?: string(name='Rule', description='The snapshot of the rule Spec at the start of the validation.', example='{
    "templateId": "SYSTEM:field:null_value:fixed",
    "pass": "when = 0",
    "name": "The id cannot be empty.",
    "severity": "High",
    "identity": "a-customized-data-quality-rule-uuid"
}'),
        sample?: string(name='Sample', description='The sample value used in the validation.', example='{
  "value": "100.0"
}'),
        status?: string(name='Status', description='The validation result status.

*   Pass
*   Running
*   Error
*   Warn
*   Fail', example='Fail'),
      }
    ](name='Results', description='The validation results of each rule.'),
    scan?: {
      computeResource?: {
        envType?: string(name='EnvType', description='The workspace environment to which the compute engine belongs.

*   Prod
*   Dev', example='Dev'),
        name?: string(name='Name', description='The name of the computing resource, which corresponds to the Name attribute in the ComputeResource data structure of the computing resource API.', example='emr_cluster_001'),
        runtime?: {
          engine?: string(name='Engine', description='The type of the compute engine. Only EMR compute engines support these settings.

*   Hive
*   Spark
*   Kyuubi', example='Hive'),
          hiveConf?: map[string]any(name='HiveConf', description='Additional parameters for the Hive engine. Currently, only mapreduce.job.queuename is supported to specify the queue.', example='mapreduce.job.queuename=dq_queue'),
          sparkConf?: map[string]any(name='SparkConf', description='Additional parameters for the Spark engine. Currently, only spark.yarn.queue is supported to specify the queue.', example='spark.yarn.queue=dq_queue'),
        }(name='Runtime', description='The additional runtime settings of the data quality monitor.'),
      }(name='ComputeResource', description='The computing resource settings of the data quality monitor.'),
      createTime?: long(name='CreateTime', description='The creation time of the data quality monitor.', example='1706247622000'),
      createUser?: string(name='CreateUser', description='The creator of the data quality monitor.', example='7892346529452'),
      description?: string(name='Description', description='The description of the data quality validation task. Maximum length: 65,535 characters.', example='This is a hourly run data quality evaluation plan.'),
      hooks?: [ 
        {
          condition?: string(name='Condition', description='The hook trigger condition. Currently, only one type of expression syntax is supported:

*   Specify combinations of severity levels and validation statuses for multiple rules, such as `results.any { r -> r.status == \\"Fail\\" && r.rule.severity == \\"Normal\\" || r.status == \\"Error\\" && r.rule.severity == \\"High\\" || r.status == \\"Warn\\" && r.rule.severity == \\"High\\" }`. This means the hook is triggered if any executed rule has Fail with Normal severity, Error with High severity, or Warn with High severity. In the conditional expression, the severity value matches that in the Spec code, and the status value matches that in DataQualityResult.', example='results.any { r -> r.status == \\"fail\\" && r.rule.severity == \\"High\\" }'),
          type?: string(name='Type', description='The type of the hook.

*   BlockTaskInstance', example='BlockTaskInstance'),
        }
      ](name='Hooks', description='The hook configurations after the data quality monitor stops.'),
      id?: long(name='Id', description='The data quality monitor ID.', example='21077'),
      modifyTime?: long(name='ModifyTime', description='The last update time of the data quality monitor.', example='1706247622000'),
      modifyUser?: string(name='ModifyUser', description='The last updater of the data quality monitor.', example='7892346529452'),
      name?: string(name='Name', description='The name of the data quality validation task. It can contain digits, letters, Chinese characters, and both half-width and full-width punctuation marks, with a maximum length of 255 characters.', example='Hourly partition quality monitoring'),
      owner?: string(name='Owner', description='The owner of the data quality monitor.', example='7892346529452'),
      parameters?: [ 
        {
          name?: string(name='Name', description='The parameter name.', example='dt'),
          value?: string(name='Value', description='The parameter value.', example='$[yyyy-mm-dd-1]'),
        }
      ](name='Parameters', description='The parameter settings of the data quality monitor.'),
      projectId?: long(name='ProjectId', description='The project ID.', example='164024'),
      runtimeResource?: {
        cu?: float(name='Cu', description='Reserved CUs for the resource group.', example='1'),
        id?: string(name='Id', description='The resource group ID.', example='60597'),
        image?: string(name='Image', description='The image ID of the run configuration.', example='i-xxxx'),
      }(name='RuntimeResource', description='The resource group used for running the data quality monitor.'),
      spec?: string(name='Spec', description='The data quality monitor Spec. For more information, see [Data quality Spec configuration description](https://help.aliyun.com/document_detail/2963394.html).', example='{
    "datasets": [
        {
            "type": "Table",
            "dataSource": {
                "name": "odps_first",
                "envType": "Prod"
            },
            "tables": [
                "ods_d_user_info"
            ],
            "filter": "pt = $[yyyymmdd-1]"
        }
    ],
    "rules": [
        {
            "assertion": "row_count > 0"
        }, {
            "templateId": "SYSTEM:field:null_value:fixed",
            "pass": "when = 0",
            "name": "The id cannot be empty.",
            "severity": "High",
             "identity": "a-customized-data-quality-rule-uuid"
        }
    ]
}'),
      trigger?: {
        taskIds?: [ long ](name='TaskIds', description='If the trigger mode is set to BySchedule, the scheduling task ID must be specified.'),
        type?: string(name='Type', description='The trigger method of the data quality monitor.

*   ByManual
*   BySchedule', example='BySchedule'),
      }(name='Trigger', description='The trigger configurations of the data quality monitor.'),
    }(name='Scan', description='The snapshot of the data quality monitor configuration at the start of the validation.'),
    status?: string(name='Status', description='The current running status.

*   Pass
*   Running
*   Error
*   Warn
*   Fail', example='Fail'),
  }(name='DataQualityScanRun', description='Data quality monitoring running records.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0bc14115****159376359'),
}

model GetDataQualityScanRunResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityScanRunResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDataQualityScanRun  GetDataQualityScanRunRequest
  * @return GetDataQualityScanRunResponse
 */
async function getDataQualityScanRun(request: GetDataQualityScanRunRequest): GetDataQualityScanRunResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityScanRun', 'POST', '/', 'json', false, 'json', request);
}

model GetDataQualityScanRunLogRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The ID of the data quality monitor run record.', example='10001', position='Query'),
  offset?: long(name='Offset', description='The starting position of the log, in bytes, relative to the beginning of the file. Each query returns a maximum of 512 KB of content.', example='200', position='Query'),
}

model GetDataQualityScanRunLogResponseBody = {
  logSegment?: {
    log?: string(name='Log', description='The task log.', example='Running on Serverless_resource_group_xxxxx
Begin to check rule ***'),
    nextOffset?: long(name='NextOffset', description='The starting offset of the next log segment. A value of -1 indicates that all logs have been read.', example='512000'),
  }(name='LogSegment', description='The task log information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0bc14115***159376359'),
}

model GetDataQualityScanRunLogResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityScanRunLogResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDataQualityScanRunLog  GetDataQualityScanRunLogRequest
  * @return GetDataQualityScanRunLogResponse
 */
async function getDataQualityScanRunLog(request: GetDataQualityScanRunLogRequest): GetDataQualityScanRunLogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityScanRunLog', 'POST', '/', 'json', false, 'json', request);
}

model GetDataQualityTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: string(name='Id', description='The data quality rule template ID.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX', position='Query'),
}

model GetDataQualityTemplateResponseBody = {
  dataQualityTemplate?: {
    createTime?: long(name='CreateTime', description='The time when the data quality rule template was created.', example='1606724043000'),
    createUser?: string(name='CreateUser', description='The creator of the data quality rule template.', example='238428342865'),
    id?: string(name='Id', description='The ID of the data quality rule template.', example='10001'),
    modifyTime?: long(name='ModifyTime', description='The time when the data quality rule template was updated.', example='1606724043000'),
    modifyUser?: string(name='ModifyUser', description='The last updater of the data quality rule template.', example='238428342865'),
    owner?: string(name='Owner', description='The owner of the data quality rule template.', example='238428342865'),
    projectId?: long(name='ProjectId', description='The project ID.', example='97535'),
    spec?: string(name='Spec', description='Specific configurations of the data quality rule template. For more information, see [Data quality Spec configuration description](~2963394~).', example='{
    "assertion": "anomaly detection fro id_not_null_cnt",
    "id_not_null_cnt": {
        "query": "SELECT COUNT(*) AS cnt FROM ${tableName} WHERE dt = \\"$[yyyymmdd-1]\\";"
    },
    "identity": "819cf1f8-29be-4f94-a9d0-c5c06c0c3d2a"
}'),
  }(name='DataQualityTemplate', description='The data quality rule template.'),
  requestId?: string(name='RequestId', description='The API request ID, which is generated as a UUID.', example='0bc14115***159376359'),
}

model GetDataQualityTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityTemplateResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDataQualityTemplate  GetDataQualityTemplateRequest
  * @return GetDataQualityTemplateResponse
 */
async function getDataQualityTemplate(request: GetDataQualityTemplateRequest): GetDataQualityTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityTemplate', 'POST', '/', 'json', false, 'json', request);
}

model GetDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The data source ID.

This parameter is required.', example='16035', position='Query'),
}

model GetDataSourceResponseBody = {
  dataSource?: {
    connectionProperties?: any(name='ConnectionProperties', description='The connection configurations of the data source, including the connection address, access identity, and environment information. The envType parameter specifies the environment in which the data source is used. Valid values of the envType parameter:

*   Dev: development environment
*   Prod: production environment

The parameters that you need to configure for the data source vary based on the mode in which the data source is added. For more information, see [Data source connection information (ConnectionProperties)](https://help.aliyun.com/document_detail/2852465.html).', example='{
	"envType": "Prod",
	"regionId": "cn-beijing",
    "instanceId": "hgprecn-cn-x0r3oun4k001",
    "database": "testdb",
    "securityProtocol": "authTypeNone",
    "authType": "Executor",
    "authIdentity": "1107550004253538"
}'),
    connectionPropertiesMode?: string(name='ConnectionPropertiesMode', description='The mode in which the data source is added. The mode varies based on the data source type. Valid values:

*   InstanceMode: instance mode
*   UrlMode: connection string mode
*   CdhMode: CDH cluster mode', example='UrlMode'),
    createTime?: long(name='CreateTime', description='The time when the data source was added. This value is a UNIX timestamp.', example='1698286929333'),
    createUser?: string(name='CreateUser', description='The ID of the user who adds the data source.', example='1107550004253538'),
    description?: string(name='Description', description='The description of the data source.', example='test'),
    id?: long(name='Id', description='The data source ID.', example='16738'),
    modifyTime?: long(name='ModifyTime', description='The time when the data source was last modified. This value is a UNIX timestamp.', example='1698286929333'),
    modifyUser?: string(name='ModifyUser', description='The ID of the user who modifies the data source.', example='1107550004253538'),
    name?: string(name='Name', description='The name of the data source.', example='test'),
    projectId?: long(name='ProjectId', description='The ID of the workspace with which the data source is associated.', example='52660'),
    qualifiedName?: string(name='QualifiedName', description='The unique business key of the data source. For example, the unique business key of a Hologres data source is in the `${tenantOwnerId}:${regionId}:${type}:${instanceId}:${database}` format.', example='1107550004253538:cn-beijing:holo:hgprecn-cn-x0r3oun4k001:testdb'),
    type?: string(name='Type', description='The type of the data source.', example='hologres'),
  }(name='DataSource', description='The information about the data source.'),
  requestId?: string(name='RequestId', description='The request ID.', example='9252F32F-D855-549E-8898-61CF5A733050'),
}

model GetDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Deployment, Development, Project Owner, and O\\&M
  * @param request  the request parameters of GetDataSource  GetDataSourceRequest
  * @return GetDataSourceResponse
 */
async function getDataSource(request: GetDataSourceRequest): GetDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataSource', 'GET', '/', 'json', false, 'json', request);
}

model GetDatabaseRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='Database entity ID. You can refer to the response of the ListDatabases operation and [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

The format: `${EntityType}:${Instance ID or escaped URL}:${Catalog identifier}:${Database name}`. Use empty strings as placeholders for levels that do not exist.

>  For StarRocks, the catalog identifier is the catalog name. For DLF, the catalog identifier is the catalog ID. For other types, the catalog-level hierarchy is not supported, and an empty string can be used as a placeholder.

Examples of common ID formats

*   `dlf-database::catalog_id:database_name`
*   `holo-database:instance_id::database_name`
*   `mysql-database:(instance_id|encoded_jdbc_url)::database_name`

> 

*   `catalog_id`: The ID of the DLF catalog.

*   `instance_id`: The instance ID, which is required when the data source is registered in instance mode.

*   `encoded_jdbc_url`: The encoded JDBC connection string, which is required when the data source is registered in connection-string mode.

*   `database_name`: The database name.

This parameter is required.', example='mysql-database:rm-abc123xxx::test_db', position='Query'),
}

model GetDatabaseResponseBody = {
  database?: Database(name='Database', description='The database details.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AFAE64E-D1BE-432B-A9****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetDatabaseResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDatabaseResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDatabase  GetDatabaseRequest
  * @return GetDatabaseResponse
 */
async function getDatabase(request: GetDatabaseRequest): GetDatabaseResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDatabase', 'GET', '/', 'json', false, 'json', request);
}

model GetDatasetRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='This parameter is required.', example='dataworks-dataset:3pXXXb8o0ngr07njhps1', position='Query'),
}

model GetDatasetResponseBody = {
  dataset?: Dataset(name='Dataset'),
  requestId?: string(name='RequestId', description='Id of the request', example='204EAF68-CCE3-5112-8DA0-E7A60F02XXXX'),
  success?: boolean(name='Success', example='true'),
}

model GetDatasetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDatasetResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDataset  GetDatasetRequest
  * @return GetDatasetResponse
 */
async function getDataset(request: GetDatasetRequest): GetDatasetResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataset', 'POST', '/', 'json', false, 'json', request);
}

model GetDatasetVersionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='This parameter is required.', example='dataworks-datasetVersion:3pXXXb8o0ngr07njhps1
:2', position='Query'),
}

model GetDatasetVersionResponseBody = {
  datasetVersion?: DatasetVersion(name='DatasetVersion'),
  requestId?: string(name='RequestId', description='Id of the request', example='4CDF7B72-020B-542A-8465-21CFFA8XXXXX'),
  success?: boolean(name='Success', example='true'),
}

model GetDatasetVersionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDatasetVersionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDatasetVersion  GetDatasetVersionRequest
  * @return GetDatasetVersionResponse
 */
async function getDatasetVersion(request: GetDatasetVersionRequest): GetDatasetVersionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDatasetVersion', 'POST', '/', 'json', false, 'json', request);
}

model GetDeploymentPackageRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  deploymentId: long(name='DeploymentId', description='The deployment package ID. This ID is generated when you call [SubmitFile](https://help.aliyun.com/document_detail/173944.html) or [DeployFile](https://help.aliyun.com/document_detail/173956.html).

This parameter is required.', example='1000000001', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID. This parameter identifies the DataWorks workspace for this API call.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The unique identifier of the DataWorks workspace. This is the identifier shown in the workspace switcher at the top of the Data Studio page.

Either this parameter or ProjectId must be specified to determine which DataWorks workspace this API call operates on.', example='dw_project', position='Body'),
}

model GetDeploymentPackageResponseBody = {
  data?: {
    deployedItems?: [ 
      {
        fileId?: long(name='FileId', description='The file ID.', example='5076****'),
        fileVersion?: long(name='FileVersion', description='The file version.', example='7'),
        status?: int32(name='Status', description='*   UNPUBLISHED(0)
*   SUCCESS(1)
*   ERROR(2)
*   CLONED(3)
*   DEPLOY_ERROR(4)
*   CLONING(5)
*   REJECT(6)', example='1'),
      }
    ](name='DeployedItems', description='The deployment item details.'),
    deployment?: {
      checkingStatus?: int32(name='CheckingStatus', description='The validation status of nodes in the deployment package. For packages deployed to the development environment (toEnviroment=1), you can only proceed to deploy to production if the package Status is 1 (succeeded) and CheckingStatus is empty (validation complete).

*   7: Validation failed
*   8: Validation in progress', example='7'),
      createTime?: long(name='CreateTime', description='The timestamp (in milliseconds) when the deployment package was created.', example='1593877765000'),
      creatorId?: string(name='CreatorId', description='The Alibaba Cloud account ID of the user who created the deployment package.', example='20030****'),
      errorMessage?: string(name='ErrorMessage', description='The detailed error message when the deployment package fails (status is 2).', example='Success'),
      executeTime?: long(name='ExecuteTime', description='The timestamp (in milliseconds) when the deployment started.', example='1593877765000'),
      fromEnvironment?: int32(name='FromEnvironment', description='The environment where the deployment is executed. Valid values: 0 (local) and 1 (development).', example='0'),
      handlerId?: string(name='HandlerId', description='The Alibaba Cloud account ID of the user who executed the deployment.', example='2003****'),
      name?: string(name='Name', description='The deployment package name, displayed on the Deploy Center > Deployment Packages page.', example='ods_user_info_d-2020-07-04_20030****'),
      status?: int32(name='Status', description='The current status of the deployment package. Valid values: 0 (ready), 1 (succeeded), and 2 (failed).', example='1'),
      toEnvironment?: int32(name='ToEnvironment', description='The target environment for the deployment. Valid values: 1 (development) and 2 (production).', example='1'),
    }(name='Deployment', description='The deployment package details.'),
  }(name='Data', description='The deployment package details.'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='You have no permission.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID. Use this ID to locate logs and troubleshoot issues.', example='0bc1ec92159376****'),
  success?: boolean(name='Success', description='Indicates whether the call succeeded. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetDeploymentPackageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDeploymentPackageResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDeploymentPackage  GetDeploymentPackageRequest
  * @return GetDeploymentPackageResponse
 */
async function getDeploymentPackage(request: GetDeploymentPackageRequest): GetDeploymentPackageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDeploymentPackage', 'POST', '/', 'json', true, 'form', request);
}

model GetFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  fileId?: long(name='FileId', description='The file ID. You can call the [ListFiles](https://help.aliyun.com/document_detail/173942.html) operation to query the ID.', example='100000001', position='Body'),
  nodeId?: long(name='NodeId', description='The ID of the node that is scheduled. You can call the [ListFiles](https://help.aliyun.com/document_detail/173942.html) operation to query the ID.', example='200000001', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure either this parameter or the ProjectIdentifier parameter to determine the DataWorks workspace to which the operation is applied.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the name.

You must configure either this parameter or the ProjectId parameter to determine the DataWorks workspace to which the operation is applied.', example='dw_project', position='Body'),
}

model GetFileResponseBody = {
  data?: {
    file?: {
      advancedSettings?: string(name='AdvancedSettings', description='The advanced configurations of the node.

This parameter is valid for an EMR node. This parameter corresponds to the Advanced Settings tab in the right-side navigation pane on the configuration tab of the node in the [DataWorks console](https://workbench.data.aliyun.com/console).

>  You cannot configure advanced parameters for EMR Shell nodes.

For information about the advanced parameters of each type of EMR node, see [Develop EMR tasks](https://help.aliyun.com/document_detail/473077.html).', example='{\\"priority\\":\\"1\\",\\"ENABLE_SPARKSQL_JDBC\\":false,\\"FLOW_SKIP_SQL_ANALYZE\\":false,\\"queue\\":\\"default\\"}'),
      autoParsing?: boolean(name='AutoParsing', description='Indicates whether the automatic parsing feature is enabled for the file. Valid values:

*   true
*   false

This parameter corresponds to the Automatic Parsing From Code Before Node Committing parameter that is displayed after you select Same Cycle in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='true'),
      bizId?: long(name='BizId', description='The ID of the workflow to which the file belongs. This parameter is deprecated and replaced by the BusinessId parameter.', example='1000001'),
      businessId?: long(name='BusinessId', description='The ID of the workflow to which the file belongs.', example='1000001'),
      commitStatus?: int32(name='CommitStatus', description='Indicates whether the latest code in the file is committed. Valid values: 0 and 1. The value 0 indicates that the latest code in the file is not committed. The value 1 indicates that the latest code in the file is committed.', example='0'),
      connectionName?: string(name='ConnectionName', description='The name of the data source that is used to run the node that corresponds to the file.', example='odps_source'),
      content?: string(name='Content', description='The code in the file.', example='SHOW TABLES;'),
      createTime?: long(name='CreateTime', description='The time when the file was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1593879116000'),
      createUser?: string(name='CreateUser', description='The ID of the Alibaba Cloud account used to create the file.', example='424732****'),
      currentVersion?: int32(name='CurrentVersion', description='The latest version number of the file.', example='3'),
      deletedStatus?: string(name='DeletedStatus', description='The status of the file. Valid values:

*   NORMAL: The file is not deleted.
*   RECYCLE_BIN: The file is stored in the recycle bin.
*   DELETED: The file is deleted.', example='RECYCLE'),
      fileDescription?: string(name='FileDescription', description='The description of the file.', example='My first DataWorks file'),
      fileFolderId?: string(name='FileFolderId', description='The ID of the folder to which the file belongs.', example='2735c2****'),
      fileId?: long(name='FileId', description='The file ID.', example='100000001'),
      fileName?: string(name='FileName', description='The name of the file.', example='ods_user_info_d'),
      fileType?: int32(name='FileType', description='The type of the code for the file. The code for files varies based on the file type. For more information, see [DataWorks nodes](https://help.aliyun.com/document_detail/600169.html).', example='10'),
      isMaxCompute?: boolean(name='IsMaxCompute', description='Indicates whether the resource file needs to be uploaded to MaxCompute. This parameter is returned only if the file is a MaxCompute resource file.', example='true'),
      lastEditTime?: long(name='LastEditTime', description='The time when the file was last modified. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1593879116000'),
      lastEditUser?: string(name='LastEditUser', description='The ID of the Alibaba Cloud account used to last modify the file.', example='424732****'),
      nodeId?: long(name='NodeId', description='The ID of the auto triggered node that is generated in the scheduling system after the file is committed.', example='300001'),
      owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the file owner.', example='7775674356****'),
      parentId?: long(name='ParentId', description='The ID of the node group file to which the current file belongs. This parameter is returned only if the current file is an inner file of the node group file.', example='-1'),
      useType?: string(name='UseType', description='The module to which the file belongs. Valid values:

*   NORMAL: The file is used for DataStudio.
*   MANUAL: The file is used for a manually triggered node.
*   MANUAL_BIZ: The file is used for a manually triggered workflow.
*   SKIP: The file is used for a dry-run node in DataStudio.
*   ADHOCQUERY: The file is used for an ad hoc query.
*   COMPONENT: The file is used for a script template.', example='NORMAL'),
    }(name='File', description='The basic information about the file.'),
    nodeConfiguration?: {
      applyScheduleImmediately?: string(name='ApplyScheduleImmediately', description='Indicates whether scheduling configurations immediately take effect after the deployment.', example='true'),
      autoRerunIntervalMillis?: int32(name='AutoRerunIntervalMillis', description='The interval between automatic reruns after an error occurs. Unit: milliseconds.

This parameter corresponds to the Rerun interval parameter that is displayed after the Auto Rerun upon Failure check box is selected in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console). The interval that you specify in the DataWorks console is measured in minutes. Pay attention to the conversion between the units of time when you call the operation.', example='120000'),
      autoRerunTimes?: int32(name='AutoRerunTimes', description='The number of automatic reruns that are allowed after an error occurs.', example='3'),
      cronExpress?: string(name='CronExpress', description='The cron expression that represents the periodic scheduling policy of the node.', example='00 05 00 * * ?'),
      cycleType?: string(name='CycleType', description='The type of the scheduling cycle. Valid values: NOT_DAY and DAY. The value NOT_DAY indicates that the node is scheduled to run by minute or hour. The value DAY indicates that the node is scheduled to run by day, week, or month.

This parameter corresponds to the Scheduling Cycle parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='DAY'),
      dependentNodeIdList?: string(name='DependentNodeIdList', description='The ID of the node on which the node that corresponds to the file depends when the DependentType parameter is set to USER_DEFINE. Multiple IDs are separated by commas (,).

The value of this parameter is equivalent to the ID of the node that you specified after you select Previous Cycle and set Depend On to Other Nodes in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='5,10,15,20'),
      dependentType?: string(name='DependentType', description='The type of the cross-cycle scheduling dependency of the node. Valid values:

*   SELF: The instance generated for the node in the current cycle depends on the instance generated for the node in the previous cycle.
*   CHILD: The instance generated for the node in the current cycle depends on the instances generated for the descendant nodes at the nearest level of the node in the previous cycle.
*   USER_DEFINE: The instance generated for the node in the current cycle depends on the instances generated for one or more specified nodes in the previous cycle.
*   NONE: No cross-cycle scheduling dependency type is selected for the node.', example='USER_DEFINE'),
      endEffectDate?: long(name='EndEffectDate', description='The end of the time range for automatic scheduling. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

Configuring this parameter is equivalent to specifying an end time for the Validity Period parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='4155787800000'),
      ignoreParentSkipRunningProperty?: string(name='IgnoreParentSkipRunningProperty', description='Indicates whether the dry-run property of the ancestor nodes of the node is skipped. This parameter corresponds to the Skip the dry-run property of the ancestor node parameter that is displayed after you configure the Depend On parameter in the Dependencies section of the Properties tab on the DataStudio page in the DataWorks console.', example='true'),
      imageId?: string(name='ImageId', description='The custom image ID.', example='m-bp1h4b5a8ogkbll2f3tr'),
      inputList?: [ 
        {
          input?: string(name='Input', description='The output name of the parent file on which the current file depends.

This parameter corresponds to the Output Name of Ancestor Node parameter under Parent Nodes after Same Cycle is selected in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='project.001_out'),
          parseType?: string(name='ParseType', description='The mode of the configuration file dependency. Valid values:

*   MANUAL: Scheduling dependencies are manually configured.
*   AUTO: Scheduling dependencies are automatically parsed.', example='MANUAL'),
        }
      ](name='InputList', description='The output information about the parent files on which the current file depends.'),
      inputParameters?: [ 
        {
          parameterName?: string(name='ParameterName', description='The name of the input parameter of the node. In the code, you can use the ${...} method to reference the input parameter of the node.

This parameter corresponds to the Parameter Name parameter in the Input Parameters table in the Input and Output Parameters section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='input'),
          valueSource?: string(name='ValueSource', description='The value source of the input parameter of the node.

This parameter corresponds to the Value Source parameter in the Input Parameters table in the Input and Output Parameters section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='project_001.parent_node:outputs'),
        }
      ](name='InputParameters', description='The input parameters of the node.'),
      outputList?: [ 
        {
          output?: string(name='Output', description='The output name of the current file.

This parameter corresponds to the Output Name parameter under Output after Same Cycle is selected in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='dw_project.002_out'),
          refTableName?: string(name='RefTableName', description='The output table name of the current file.

This parameter corresponds to the Output Table Name parameter under Output after Same Cycle is selected in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='ods_user_info_d'),
        }
      ](name='OutputList', description='The output information about the current file.'),
      outputParameters?: [ 
        {
          description?: string(name='Description', description='The description of the output parameter of the node.', example='It\\"s a context output parameter.'),
          parameterName?: string(name='ParameterName', description='The name of the output parameter of the node.

This parameter corresponds to the Parameter Name parameter in the Output Parameters table in the Input and Output Parameters section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='output'),
          type?: string(name='Type', description='The type of the output parameter of the node. Valid values:

*   1: indicates a constant.
*   2: indicates a variable.
*   3: indicates a pass-through variable.

This parameter corresponds to the Type parameter in the Output Parameters table in the Input and Output Parameters section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='1'),
          value?: string(name='Value', description='The value of the output parameter of the node.

This parameter corresponds to the Value parameter in the Output Parameters table in the Input and Output Parameters section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='${bizdate}'),
        }
      ](name='OutputParameters', description='The output parameters of the node.'),
      paraValue?: string(name='ParaValue', description='The scheduling parameters of the node.

This parameter corresponds to the Scheduling Parameter section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console). For more information about the configurations of scheduling parameters, see [Configure scheduling parameters](https://help.aliyun.com/document_detail/137548.html).', example='a=x b=y'),
      rerunMode?: string(name='RerunMode', description='Indicates whether the node that corresponds to the file can be rerun. Valid values:

*   ALL_ALLOWED: The node can be rerun regardless of whether it is successfully run or fails to run.
*   FAILURE_ALLOWED: The node can be rerun only after it fails to run.
*   ALL_DENIED: The node cannot be rerun regardless of whether it is successfully run or fails to run.

This parameter corresponds to the Rerun parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='ALL_ALLOWED'),
      resourceGroupId?: long(name='ResourceGroupId', description='The ID of the resource group that is used to run the node that corresponds to the file. You can call the [ListResourceGroups](https://help.aliyun.com/document_detail/173913.html) operation to query the available resource groups in the workspace.', example='375827434852437'),
      schedulerType?: string(name='SchedulerType', description='The scheduling type of the node. Valid values:

*   NORMAL: The node is an auto triggered node.
*   MANUAL: The node is a manually triggered node. Manually triggered nodes cannot be automatically triggered. They correspond to the nodes in the Manually Triggered Workflows pane.
*   PAUSE: The node is a paused node.
*   SKIP: The node is a dry-run node. Dry-run nodes are started as scheduled, but the system sets the status of the nodes to successful when it starts to run them.', example='NORMAL'),
      startEffectDate?: long(name='StartEffectDate', description='The beginning of the time range for automatic scheduling. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

Configuring this parameter is equivalent to specifying a start time for the Validity Period parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='936923400000'),
      startImmediately?: boolean(name='StartImmediately', description='Indicates whether a node is immediately run after the node is deployed to the production environment.

This parameter is valid only for an EMR Spark Streaming node or an EMR Streaming SQL node. This parameter corresponds to the Start Method parameter in the Schedule section of the Configure tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='true'),
      stop?: boolean(name='Stop', description='Indicates whether the scheduling for the node is suspended Valid values:

*   true
*   false

This parameter corresponds to the Recurrence parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='false'),
      timeout?: int32(name='Timeout', description='The timeout period.', example='1'),
    }(name='NodeConfiguration', description='The scheduling configurations of the file.'),
    resourceDownloadLink?: {
      downloadLink?: string(name='downloadLink', description='The download URL of the resource.', example='http://xx'),
    }(name='ResourceDownloadLink', description='The download URL of the resource.'),
  }(name='Data', description='The details of the file.'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetFile  GetFileRequest
  * @return GetFileResponse
 */
async function getFile(request: GetFileRequest): GetFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetFile', 'POST', '/', 'json', true, 'form', request);
}

model GetFileVersionRequest {
  regionId?: string(name='RegionId', position='Host'),
  fileId: long(name='FileId', description='The file ID. You can call the [ListFiles](https://help.aliyun.com/document_detail/173942.html) operation to query the ID.

This parameter is required.', example='1000001', position='Body'),
  fileVersion: int32(name='FileVersion', description='The file version whose information you want to query.

This parameter is required.', example='2', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can click the Workspace Manage icon in the upper-right corner of the DataStudio page to go to the Workspace page and query the workspace ID.', example='1000011', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The unique identifier of the DataWorks workspace. You can view the identifier in the upper part of the DataStudio page. You can also select another identifier to switch to another workspace.

You must configure either this parameter or the ProjectId parameter to determine the DataWorks workspace to which the operation is applied.', example='dw_project', position='Body'),
}

model GetFileVersionResponseBody = {
  data?: {
    changeType?: string(name='ChangeType', description='The type of the change to the file of the current version. Valid values: CREATE, UPDATE, and DELETE.', example='UPDATE'),
    comment?: string(name='Comment', description='The description of the file version.', example='Second version submission'),
    commitTime?: long(name='CommitTime', description='The time when the file version was generated. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1593881265000'),
    commitUser?: string(name='CommitUser', description='The ID of the Alibaba Cloud account that is used to generate the file of the current version.', example='7384234****'),
    fileContent?: string(name='FileContent', description='The code in the file of the current version.', example='SHOW TABLES;'),
    fileName?: string(name='FileName', description='The name of the file of the current version.', example='ods_user_info_d'),
    filePropertyContent?: string(name='FilePropertyContent', description='The basic information about the file of the current version.', example='{"fileName":"ods_user_info_d","fileType":10}'),
    fileVersion?: int32(name='FileVersion', description='The file version.', example='2'),
    isCurrentProd?: boolean(name='IsCurrentProd', description='Indicates whether the version is the latest version in the production environment. Valid values:

*   true
*   false', example='true'),
    nodeContent?: string(name='NodeContent', description='The scheduling configurations of the node that corresponds to the file of the current version.', example='{"cycleType":0,"cronExpress":"00 05 00 * * ?"}'),
    nodeId?: long(name='NodeId', description='The ID of the node that corresponds to the file version.', example='3000001'),
    status?: string(name='Status', description='The status of the file version. Valid values:

*   COMMITTING
*   COMMITTED or CHECK_OK
*   PACKAGED
*   DEPLOYING
*   DEPLOYED
*   CANCELLED', example='COMMITTED'),
    useType?: string(name='UseType', description='The module to which the file belongs. Valid values:

*   0: NORMAL, which indicates that the file is used for DataStudio.
*   1: MANUAL, which indicates that the file is used for a manually triggered node.
*   2: MANUAL_BIZ, which indicates that the file is used for a manually triggered workflow.
*   3: SKIP, which indicates that the file is used for a dry-run node in DataStudio.
*   10: ADHOCQUERY, which indicates that the file is used for an ad hoc query.
*   30: COMPONENT, which indicates that the file is used for a script template.', example='0'),
  }(name='Data', description='The details of the file version.'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model GetFileVersionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetFileVersionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetFileVersion  GetFileVersionRequest
  * @return GetFileVersionResponse
 */
async function getFileVersion(request: GetFileVersionRequest): GetFileVersionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetFileVersion', 'POST', '/', 'json', true, 'form', request);
}

model GetFolderRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  folderId?: string(name='FolderId', description='The folder ID. Either this parameter or FolderPath must be specified. You can call the [ListFolders](https://help.aliyun.com/document_detail/173955.html) operation to obtain the folder ID.', example='273****', position='Body'),
  folderPath?: string(name='FolderPath', description='The folder path. Either this parameter or FolderId must be specified. You can call the [ListFolders](https://help.aliyun.com/document_detail/173955.html) operation to obtain the folder path.', example='Business_process/my_first_business_process/MaxCompute/ods_layer', minLength=1, position='Body'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace. You can obtain the workspace ID from the workspace configuration page in the DataWorks console. Either this parameter or ProjectIdentifier must be specified to determine which DataWorks workspace this API call operates on.', example='1000011', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can obtain the workspace name from the workspace configuration page in the DataWorks console. Either this parameter or ProjectId must be specified to determine which DataWorks workspace this API call operates on.', example='dw_project', position='Body'),
}

model GetFolderResponseBody = {
  data?: {
    folderId?: string(name='FolderId', description='The ID of the folder.', example='2735****'),
    folderPath?: string(name='FolderPath', description='The path of the folder.', example='Business_process/my_first_business_process/MaxCompute/ods_layer'),
  }(name='Data', description='Details about the folder.'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID. Used for troubleshooting when errors occur.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the call was successful.

*   **true**
*   **false**', example='true'),
}

model GetFolderResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetFolderResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetFolder  GetFolderRequest
  * @return GetFolderResponse
 */
async function getFolder(request: GetFolderRequest): GetFolderResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetFolder', 'POST', '/', 'json', true, 'form', request);
}

model GetFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
}

model GetFunctionResponseBody = {
  function?: {
    createTime?: long(name='CreateTime', description='The time when the UDF was created. This value is a UNIX timestamp.', example='1724505917000'),
    id?: long(name='Id', description='The ID of the UDF.', example='860438872620113XXXX'),
    modifyTime?: long(name='ModifyTime', description='The time when the UDF was last modified. This value is a UNIX timestamp.', example='1724506661000'),
    name?: string(name='Name', description='The name of the UDF.', example='Function name'),
    owner?: string(name='Owner', description='The owner of the UDF.', example='110755000425XXXX'),
    projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace to which the UDF belongs.', example='10000'),
    spec?: string(name='Spec', description='The FlowSpec field information about the UDF. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).', example='{
    "version": "1.1.0",
    "kind": "Function",
    "spec": {
        "functions": [
            {
                "name": "Function_Name",
                "id": "580667964888595XXXX",
                "script": {
                    "content": "{  \\"uuid\\": \\"580667964888595XXXX\\",  \\"name\\": \\"Function_Name\\",  \\"datasource\\": {    \\"type\\": \\"odps\\",    \\"name\\": \\"odps_first\\"  },  \\"runtimeResource\\": {    \\"resourceGroup\\": \\"S_res_group_XXXX_XXXX\\",    \\"resourceGroupId\\": 6591XXXX  }}",
                    "path": "XXX/OpenAPI/Function/Function_Name",
                    "runtime": {
                        "command": "ODPS_FUNCTION"
                    }
                },
                "datasource": {
                    "name": "odps_first",
                    "type": "odps"
                },
                "runtimeResource": {
                    "resourceGroup": "S_res_group_XXXX_XXXX",
                    "id": "723932906364267XXXX",
                    "resourceGroupId": "6591XXXX"
                },
                "metadata": {
                    "owner": "110755000425XXXX"
                }
            }
        ]
    }
}'),
  }(name='Function', description='The information about the UDF.'),
  requestId?: string(name='RequestId', description='The request ID.', example='6CF95929-6D12-5A88-8CC3-4B2F4C2EXXXX'),
}

model GetFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetFunctionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetFunction  GetFunctionRequest
  * @return GetFunctionResponse
 */
async function getFunction(request: GetFunctionRequest): GetFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetFunction', 'GET', '/', 'json', false, 'json', request);
}

model GetIDEEventDetailRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  messageId: string(name='MessageId', description='The message ID in DataWorks OpenEvent. You can obtain the ID from a received message when an extension point event is triggered.

This parameter is required.', example='8abcb91f-d266-4073-b907-2ed67****1', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can obtain the ID from the message.

This parameter is required.', example='10000', position='Body'),
}

model GetIDEEventDetailResponseBody = {
  eventDetail?: {
    committedFile?: {
      changeType?: string(name='ChangeType', description='The type of the change to the file of the current version. Valid values: CREATE, UPDATE, and DELETE.', example='UPDATE'),
      comment?: string(name='Comment', description='The description of the file version.', example='Second version submission'),
      committor?: string(name='Committor', description='The ID of the Alibaba Cloud account that is used to generate the file of the current version.', example='7384234****'),
      content?: string(name='Content', description='The code in the file of the current version.', example='SHOW TABLES;'),
      fileId?: long(name='FileId', description='The file ID.', example='1234123'),
      fileName?: string(name='FileName', description='The name of the file.', example='hello_dataworks.sql'),
      filePropertyContent?: {
        businessId?: long(name='BusinessId', description='The ID of the workflow to which the file belongs.', example='74328'),
        currentVersion?: long(name='CurrentVersion', description='The latest version number of the file.', example='1'),
        dataSourceName?: string(name='DataSourceName', description='The name of the data source with which the file is associated.', example='odps_source'),
        folderId?: string(name='FolderId', description='The ID of the folder to which the file belongs. You can call the [GetFolder](https://help.aliyun.com/document_detail/173952.html) operation to query the details of the file based on the folder ID.', example='aldurie78l2falure'),
        owner?: string(name='Owner', description='The file owner.', example='7384234****'),
        parentFileId?: long(name='ParentFileId', description='The ID of the do-while node or for-each node that corresponds to the file.', example='1234122'),
      }(name='FilePropertyContent', description='The details of the file.'),
      fileType?: long(name='FileType', description='The file type. The code for files varies based on the file type. For more information, see [DataWorks nodes](https://help.aliyun.com/document_detail/600169.html).', example='10'),
      nodeConfiguration?: {
        autoRerunIntervalMillis?: long(name='AutoRerunIntervalMillis', description='The interval at which the node corresponding to the file is rerun. Unit: milliseconds.', example='120000'),
        autoRerunTimes?: long(name='AutoRerunTimes', description='The number of times that the node corresponding to the file can be rerun.', example='3'),
        cronExpress?: string(name='CronExpress', description='The cron expression that is used to schedule the node corresponding to the file.', example='00 05 00 * * ?'),
        cycleType?: string(name='CycleType', description='The type of the scheduling cycle of the node that corresponds to the file. Valid values: NOT_DAY and DAY. The value NOT_DAY indicates that the node is scheduled to run by minute or hour. The value DAY indicates that the node is scheduled to run by day, week, or month.

This parameter corresponds to the Scheduling Cycle parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='DAY'),
        dependentNodeIdList?: string(name='DependentNodeIdList', description='The ID of the node on which the node that corresponds to the file depends when the DependentType parameter is set to USER_DEFINE. Multiple IDs are separated by commas (,).

The value of this parameter is equivalent to the ID of the node that you specified after you select Other Nodes for Cross-Cycle Dependency (Original Previous-Cycle Dependency) in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='5,10,15,20'),
        dependentType?: string(name='DependentType', description='The type of the cross-cycle scheduling dependency of the node. Valid values:

*   SELF: The instance generated for the node in the current cycle depends on the instance generated for the node in the previous cycle.
*   CHILD: The instance generated for the node in the current cycle depends on the instances generated for the descendant nodes at the nearest level of the node in the previous cycle.
*   USER_DEFINE: The instance generated for the node in the current cycle depends on the instances generated for one or more specified nodes in the previous cycle.
*   NONE: No cross-cycle scheduling dependency type is selected for the node.', example='USER_DEFINE'),
        inputList?: [ 
          {
            input?: string(name='Input', description='The output name of the parent file on which the current file depends.

This parameter corresponds to the Output Name of Ancestor Node parameter under Parent Nodes in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='dw_project_root'),
            parseType?: string(name='ParseType', description='The mode of the configuration file dependency. Valid values:

*   MANUAL: Scheduling dependencies are manually configured.
*   AUTO: Scheduling dependencies are automatically parsed.', example='MANUAL'),
          }
        ](name='InputList', description='The output information about the parent files on which the current file depends.'),
        outputList?: [ 
          {
            output?: string(name='Output', description='The output name of the current file.

This parameter corresponds to the Output Name parameter under Output Name of Current Node in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='dw_project.002_out'),
            refTableName?: string(name='RefTableName', description='The output table name of the current file.

This parameter corresponds to the Output Table Name parameter under Output Name of Current Node in the Dependencies section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='ods_user_info_d'),
          }
        ](name='OutputList', description='The output information about the current file.'),
        paraValue?: string(name='ParaValue', description='The scheduling parameters of the node.

This parameter corresponds to the Scheduling Parameter section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console). For more information about the configurations of scheduling parameters, see [Configure scheduling parameters](https://help.aliyun.com/document_detail/137548.html).', example='a=x b=y'),
        rerunMode?: string(name='RerunMode', description='Indicates whether the node that corresponds to the file can be rerun. Valid values:

*   ALL_ALLOWED: The node can be rerun regardless of whether it is successfully run or fails to run.
*   FAILURE_ALLOWED: The node can be rerun only after it fails to run.
*   ALL_DENIED: The node cannot be rerun regardless of whether it is successfully run or fails to run.

This parameter corresponds to the Rerun parameter in the Schedule section of the Properties tab on the DataStudio page in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='ALL_ALLOWED'),
        resourceGroupId?: long(name='ResourceGroupId', description='The ID of the resource group that is used to run the node that corresponds to the file. You can call the [ListResourceGroups](https://help.aliyun.com/document_detail/173913.html) operation to query the available resource groups in the workspace.', example='375827434852437'),
        schedulerType?: string(name='SchedulerType', description='The scheduling type of the node. Valid values:

*   NORMAL: The node is an auto triggered node.
*   MANUAL: The node is a manually triggered node. Manually triggered nodes cannot be automatically triggered. They correspond to the nodes in the Manually Triggered Workflows pane.
*   PAUSE: The node is a paused node.
*   SKIP: The node is a dry-run node. Dry-run nodes are started as scheduled, but the system sets the status of the nodes to successful when it starts to run them.', example='NORMAL'),
      }(name='NodeConfiguration', description='The scheduling properties of the node that corresponds to the file.'),
      nodeId?: long(name='NodeId', description='The ID of the node that is scheduled.', example='421429'),
      useType?: string(name='UseType', description='The module to which the file belongs. Valid values:

*   NORMAL: The file is used for DataStudio.
*   MANUAL: The file is used for a manually triggered node.
*   MANUAL_BIZ: The file is used for a manually triggered workflow.
*   SKIP: The file is used for a dry-run node in DataStudio.
*   ADHOCQUERY: The file is used for an ad hoc query.
*   COMPONENT: The file is used for a script template.', example='NORMAL'),
    }(name='CommittedFile', description='The data snapshot when the file is committed and deployed.

This parameter is valid only if the message type is IDE_FILE_SUBMIT_BEFORE or IDE_FILE_DEPLOY_BEFORE.'),
    deletedFile?: {
      businessId?: long(name='BusinessId', description='The ID of the workflow to which the file belongs.', example='74328'),
      content?: string(name='Content', description='The code in the file of the current version.', example='SHOW TABLES;'),
      currentVersion?: long(name='CurrentVersion', description='The latest version number of the file.', example='1'),
      dataSourceName?: string(name='DataSourceName', description='The name of the data source with which the file is associated.', example='odps_source'),
      fileId?: long(name='FileId', description='The file ID.', example='1234123'),
      fileName?: string(name='FileName', description='The name of the file.', example='hello_dataworks.sql'),
      fileType?: long(name='FileType', description='The file type. The code for files varies based on the file type. For more information, see [DataWorks nodes](https://help.aliyun.com/document_detail/600169.html).', example='10'),
      folderId?: string(name='FolderId', description='The ID of the folder to which the file belongs. You can call the [GetFolder](https://help.aliyun.com/document_detail/173952.html) operation to query the details of the file based on the folder ID.', example='aldurie78l2falure'),
      nodeId?: long(name='NodeId', description='The ID of the node that is scheduled.', example='421429'),
      owner?: string(name='Owner', description='The file owner.', example='7384234****'),
      parentFileId?: long(name='ParentFileId', description='The ID of the do-while node or for-each node that corresponds to the file.', example='1234122'),
      useType?: string(name='UseType', description='The module to which the file belongs. Valid values:

*   NORMAL: The file is used for DataStudio.
*   MANUAL: The file is used for a manually triggered node.
*   MANUAL_BIZ: The file is used for a manually triggered workflow.
*   SKIP: The file is used for a dry-run node in DataStudio.
*   ADHOCQUERY: The file is used for an ad hoc query.
*   COMPONENT: The file is used for a script template.', example='NORMAL'),
    }(name='DeletedFile', description='The data snapshot when the file is deleted. This parameter is valid only if the message type is IDE_FILE_DELETE_BEFORE.'),
    fileExecutionCommand?: {
      content?: string(name='Content', description='The code in the file of the current version.', example='SHOW TABLES;'),
      dataSourceName?: string(name='DataSourceName', description='The name of the data source with which the file is associated.', example='odps_source'),
      fileId?: long(name='FileId', description='The file ID.', example='1234123'),
      fileType?: long(name='FileType', description='The file type. The code for files varies based on the file type. For more information, see [DataWorks nodes](https://help.aliyun.com/document_detail/600169.html).', example='10'),
    }(name='FileExecutionCommand', description='The data snapshot when the code in the file is run. This parameter is valid only if the message type is IDE_FILE_EXECUTE_BEFORE.'),
    tableModel?: {
      columns?: [ 
        {
          columnName?: string(name='ColumnName', description='The name of the column.', example='ID'),
          columnType?: string(name='ColumnType', description='The data type of the column.', example='BIGINT'),
          comment?: string(name='Comment', description='The remarks of the column.', example='ID'),
          isPartitionColumn?: boolean(name='IsPartitionColumn', description='Indicates whether the column is a partition key column. Valid values:

*   true
*   false', example='false'),
        }
      ](name='Columns', description='The columns in the table.'),
      comment?: string(name='Comment', description='The remarks of the table.', example='A new table'),
      dataSourceName?: string(name='DataSourceName', description='The name of the data source to which the table belongs.', example='odps_source'),
      env?: string(name='Env', description='The environment in which the table is used. Valid values:

*   DEV
*   PROD', example='DEV'),
      lifeCycle?: long(name='LifeCycle', description='The lifecycle of the table. Unit: day.', example='7'),
      location?: string(name='Location', description='The path of the table.', example='hdfs://path/to/object'),
      tableName?: string(name='TableName', description='The name of the table.', example='tb_hello'),
    }(name='TableModel', description='The data snapshot when the table is committed and deployed. This parameter is valid only if the message type is IDE_TABLE_SUBMIT_BEFORE or IDE_TABLE_DEPLOY_BEFORE.'),
  }(name='EventDetail', description='The data snapshot that is generated when an extension point event is triggered.

The fields contained in data snapshots vary based on the types of the triggered extension point events. For more information, see the description of the fields.'),
  requestId?: string(name='RequestId', description='The request ID.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
}

model GetIDEEventDetailResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetIDEEventDetailResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetIDEEventDetail  GetIDEEventDetailRequest
  * @return GetIDEEventDetailResponse
 */
async function getIDEEventDetail(request: GetIDEEventDetailRequest): GetIDEEventDetailResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetIDEEventDetail', 'POST', '/', 'json', true, 'form', request);
}

model GetJobStatusRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  jobId: string(name='JobId', description='The ID of the asynchronous task that is generated after you call an asynchronous operation.

This parameter is required.', example='70ecdaec-bf21-4c11-8ecb-4f77453ceea8', position='Query'),
}

model GetJobStatusResponseBody = {
  jobStatus?: {
    completed?: string(name='Completed', description='Indicates whether the asynchronous task is complete. Valid values: True False', example='False'),
    createTime?: string(name='CreateTime', description='The time when the asynchronous task was created.', example='1729063449802'),
    error?: string(name='Error', description='The error message returned if the asynchronous task fails.', example='Not Found'),
    jobId?: string(name='JobId', description='The ID of the asynchronous task.', example='C664CDE3-9C0B-5792-B17F-6C543783BBBC'),
    jobType?: string(name='JobType', description='The type of the asynchronous task. Valid values:

*   **Create**: The asynchronous task is used to create an object.
*   **Update**: The asynchronous task is used to update an object.
*   **Cancel**: The asynchronous task is used to cancel an operation.', example='Create'),
    status?: string(name='Status', description='The status of the asynchronous task. Valid values:

*   **Success**
*   **Fail**
*   **Cancel**
*   **Running**', example='Success'),
  }(name='JobStatus', description='The real-time status information of the asynchronous task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='5E2BFE96-C0E0-5A98-85C8-633EC803198D'),
}

model GetJobStatusResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetJobStatusResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetJobStatus  GetJobStatusRequest
  * @return GetJobStatusResponse
 */
async function getJobStatus(request: GetJobStatusRequest): GetJobStatusResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetJobStatus', 'GET', '/', 'json', false, 'json', request);
}

model GetLineageRelationshipRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The lineage ID. You can refer to the return result of the ListLineageRelationships operation.

This parameter is required.', example='110xxxx:custom-table.xxxxx:maxcompute-table.project.test_big_lineage_080901:custom-sqlxx.00001', position='Query'),
}

model GetLineageRelationshipResponseBody = {
  lineageRelationship?: LineageRelationship(name='LineageRelationship', description='The lineage structure.'),
  requestId?: string(name='RequestId', description='The request ID.', example='58D5334A-B013-430E'),
}

model GetLineageRelationshipResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetLineageRelationshipResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetLineageRelationship  GetLineageRelationshipRequest
  * @return GetLineageRelationshipResponse
 */
async function getLineageRelationship(request: GetLineageRelationshipRequest): GetLineageRelationshipResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetLineageRelationship', 'GET', '/', 'json', false, 'json', request);
}

model GetMetaCollectionRequest {
  regionId?: string(name='RegionId', position='Host'),
  id: string(name='Id', description='The collection ID.

This parameter is required.', example='category.123', position='Query'),
}

model GetMetaCollectionResponseBody = {
  metaCollection?: {
    administrators?: [ long ](name='Administrators', description='The list of administrator IDs. Valid only for the album type. The IDs must belong to users in the same tenant. Multiple IDs can be specified.'),
    createTime?: long(name='CreateTime', description='The creation time in milliseconds.', example='1668568601000'),
    createUser?: string(name='CreateUser', description='The ID of the creator.', example='456789'),
    description?: string(name='Description', description='The collection description.', example='test'),
    id?: string(name='Id', description='The collection ID.', example='category.123'),
    modifyTime?: long(name='ModifyTime', description='The last modified time in milliseconds.', example='1668568601000'),
    name?: string(name='Name', description='The collection name.', example='test_category'),
    parentId?: string(name='ParentId', description='The parent collection ID. This parameter can be empty.', example='category.12'),
    type?: string(name='Type', description='The collection type. Valid values:

*   Category
*   Album
*   AlbumCategory: Album subcategory.', example='Category'),
  }(name='MetaCollection', description='The collection details.'),
  requestId?: string(name='RequestId', description='The request ID.', example='1AFAE64E-D1BE-432B-A9****'),
}

model GetMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetMetaCollection  GetMetaCollectionRequest
  * @return GetMetaCollectionResponse
 */
async function getMetaCollection(request: GetMetaCollectionRequest): GetMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMetaCollection', 'GET', '/', 'json', false, 'json', request);
}

model GetNetworkRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The network ID.

This parameter is required.', example='1000', position='Query'),
}

model GetNetworkResponseBody = {
  network?: {
    createTime?: long(name='CreateTime', description='The time when the network resource was created. The value is a 64-bit timestamp.', example='1727055811000'),
    createUser?: string(name='CreateUser', description='The ID of the user who creates the network resource.', example='11075500042XXXXX'),
    id?: long(name='Id', description='The network ID.', example='1000'),
    resourceGroupId?: string(name='ResourceGroupId', description='The ID of the serverless resource group.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
    securityGroupId?: string(name='SecurityGroupId', description='The security group ID.', example='sg-2ze13vamugr7jenXXXXX'),
    status?: string(name='Status', description='The status of the network resource. Valid values:

*   Pending: The network resource is waiting to be created.
*   Creating: The network resource is being created.
*   Running: The network resource is running as expected.
*   Deleting: The network resource is being deleted.
*   Deleted: The network resource is deleted.', example='Running'),
    vpcId?: string(name='VpcId', description='The ID of the virtual private cloud (VPC).', example='vpc-m2et4f3oc8msfbccXXXXX'),
    vswitchId?: string(name='VswitchId', description='The VSwitch ID.', example='vsw-uf8usrhs7hjd9amsXXXXX'),
  }(name='Network', description='The information about the network resource.'),
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetNetworkResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetNetworkResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetNetwork  GetNetworkRequest
  * @return GetNetworkResponse
 */
async function getNetwork(request: GetNetworkRequest): GetNetworkResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetNetwork', 'GET', '/', 'json', false, 'json', request);
}

model GetNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
}

model GetNodeResponseBody = {
  node?: {
    createTime?: long(name='CreateTime', description='The time when the node was created. This value is a UNIX timestamp.', example='1700539206000'),
    id?: long(name='Id', description='The ID of the node.', example='860438872620113XXXX'),
    modifyTime?: long(name='ModifyTime', description='The time when the node was last modified. This value is a UNIX timestamp.', example='1700539206000'),
    name?: string(name='Name', description='The name of the node.', example='Node name'),
    owner?: string(name='Owner', description='The owner of the node.', example='196596664824XXXX'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10000'),
    spec?: string(name='Spec', description='The FlowSpec field information about this node. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow).', example='{
    "version": "1.1.0",
    "kind": "Node",
    "spec": {
        "nodes": [
            {
                "recurrence": "Normal",
                "id": "860438872620113XXXX",
                "timeout": 0,
                "instanceMode": "T+1",
                "rerunMode": "Allowed",
                "rerunTimes": 3,
                "rerunInterval": 180000,
                "datasource": {
                    "name": "odps_test",
                    "type": "odps"
                },
                "script": {
                    "language": "odps-sql",
                    "path": "XX/OpenAPI_Test/ODPS_SQL_Test",
                    "runtime": {
                        "command": "ODPS_SQL",
                        "commandTypeId": 10
                    },
                    "content": "select now();",
                    "id": "853573334108680XXXX"
                },
                "trigger": {
                    "type": "Scheduler",
                    "id": "543680677872062XXXX",
                    "cron": "00 00 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "runtimeResource": {
                    "resourceGroup": "S_res_group_XXXX_XXXX",
                    "id": "623731286945488XXXX",
                    "resourceGroupId": "7201XXXX"
                },
                "name": "ODPS_SQL_Test",
                "owner": "110755000425XXXX",
                "metadata": {
                    "owner": "110755000425XXXX",
                    "ownerName": "XXXXX@test.XXX.com",
                    "projectId": "307XXX"
                },
                "inputs": {
                    "nodeOutputs": [
                        {
                            "data": "lwttest_standard_root",
                            "artifactType": "NodeOutput"
                        }
                    ]
                },
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "860438872620113XXXX",
                            "artifactType": "NodeOutput",
                            "refTableName": "ODPS_SQL_Test",
                            "isDefault": true
                        }
                    ]
                }
            }
        ],
        "flow": [
            {
                "nodeId": "860438872620113XXXX",
                "depends": [
                    {
                        "type": "Normal",
                        "output": "lwttest_standard_root"
                    }
                ]
            }
        ]
    },
    "metadata": {
        "uuid": "860438872620113XXXX"
    }
}'),
    taskId?: long(name='TaskId', description='The Id of the scheduled task after the node is published.', example='700006680527'),
  }(name='Node', description='The information about the node.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model GetNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetNodeResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetNode  GetNodeRequest
  * @return GetNodeResponse
 */
async function getNode(request: GetNodeRequest): GetNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetNode', 'GET', '/', 'json', false, 'json', request);
}

model GetPartitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  name: string(name='Name', description='The partition name.

This parameter is required.', example='ds=20250101', position='Query'),
  tableId: string(name='TableId', description='The table ID. You can refer to the result returned by the ListTables operation and [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

This parameter is required.', example='maxcompute-column:11075xxxx::test_project:test_schema:test_table', position='Query'),
}

model GetPartitionResponseBody = {
  partition?: Partition(name='Partition', description='Partition details.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D1E2E5BC-xxxx-xxxx-xxxx-xxxxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetPartitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPartitionResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  This operation supports MaxCompute and HMS (EMR cluster) tables only.
  * @param request  the request parameters of GetPartition  GetPartitionRequest
  * @return GetPartitionResponse
 */
async function getPartition(request: GetPartitionRequest): GetPartitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPartition', 'GET', '/', 'json', false, 'json', request);
}

model GetPipelineRunRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID of the process.

This parameter is required.', example='a7ef0634-20ec-4a7c-a214-54020f****', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Query'),
}

model GetPipelineRunResponseBody = {
  pipeline?: {
    createTime?: long(name='CreateTime', description='The time when the process was created. This value is a UNIX timestamp.', example='1724984066000'),
    creator?: string(name='Creator', description='The creator of the process.', example='137946317766XXXX'),
    id?: string(name='Id', description='The process ID.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX'),
    message?: string(name='Message', description='The error message returned when the process fails.', example='Error message'),
    modifyTime?: long(name='ModifyTime', description='The time when the process was modified. This value is a UNIX timestamp.', example='1724984066000'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='56160'),
    stages?: [ 
      {
        code?: string(name='Code', description='The code of the stage.', example='DEV_CHECK'),
        description?: string(name='Description', description='The description of the stage.', example='Phase description'),
        detail?: map[string]any(name='Detail', description='The details of the stage.'),
        message?: string(name='Message', description='The error message returned for the stage.', example='Exception information XXX'),
        name?: string(name='Name', description='The name of the stage.', example='Publish package build'),
        status?: string(name='Status', description='The status of the stage.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='Running'),
        step?: int32(name='Step', description='The step number of the stage.', example='1'),
        type?: string(name='Type', description='The type of the stage.

Valid values:

*   Deploy
*   Check
*   Offline
*   Build
*   Delete', example='Check'),
      }
    ](name='Stages', description='The information about stages in the process.'),
    status?: string(name='Status', description='The status of the process.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='Running'),
  }(name='Pipeline', description='The information about the process.'),
  requestId?: string(name='RequestId', description='The request ID.', example='08468352-032C-5262-AEDC-68C9FA05XXXX'),
}

model GetPipelineRunResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPipelineRunResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetPipelineRun  GetPipelineRunRequest
  * @return GetPipelineRunResponse
 */
async function getPipelineRun(request: GetPipelineRunRequest): GetPipelineRunResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPipelineRun', 'GET', '/', 'json', false, 'json', request);
}

model GetProjectRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='123456', position='Query'),
}

model GetProjectResponseBody = {
  project?: {
    aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group to which the workspace belongs.', example='rg-acfmzbn7pti3zfa'),
    aliyunResourceTags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='batch'),
        value?: string(name='Value', description='The tag value.', example='blue'),
      }
    ](name='AliyunResourceTags', description='The tags.'),
    description?: string(name='Description', description='The description of the workspace.', example='Financial analysis group project data development'),
    devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Indicates whether the development environment is enabled. Valid values:

*   true: The development environment is enabled. In this case, the development environment is isolated from the production environment in the workspace.
*   false: The development environment is disabled. In this case, only the production environment is used in the workspace.', example='true'),
    devRoleDisabled?: boolean(name='DevRoleDisabled', description='Indicates whether the Develop role is disabled. Valid values:

*   false
*   true', example='false'),
    displayName?: string(name='DisplayName', description='The display name of the workspace.', example='Sora financial analysis'),
    id?: long(name='Id', description='The workspace ID.', example='28477242'),
    name?: string(name='Name', description='The name of the workspace.', example='sora_finance'),
    owner?: string(name='Owner', description='The ID of the Alibaba Cloud account to which the workspace belongs.', example='207947397706614299'),
    paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Indicates whether scheduling of PAI tasks is enabled. Valid values:

*   true: Scheduling of PAI tasks is enabled. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: Scheduling of PAI tasks is disabled.', example='true'),
    status?: string(name='Status', description='The status of the workspace. Valid values:

*   Available
*   Initializing
*   InitFailed
*   Forbidden
*   Deleting
*   DeleteFailed
*   Frozen
*   Updating
*   UpdateFailed', example='Available'),
  }(name='Project', description='The information about the workspace.'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model GetProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetProjectResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetProject  GetProjectRequest
  * @return GetProjectResponse
 */
async function getProject(request: GetProjectRequest): GetProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetProject', 'GET', '/', 'json', false, 'json', request);
}

model GetProjectMemberRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='88757', position='Body'),
  userId: string(name='UserId', description='The ID of the account used by the member in the workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the Tenant Members and Roles page, view the ID of the account used by the member in the workspace.

This parameter is required.', example='123422344899', position='Body'),
}

model GetProjectMemberResponseBody = {
  projectMember?: {
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='88757'),
    roles?: [ 
      {
        code?: string(name='Code', description='The code of the role. Valid values:

*   role_project_admin: Workspace Administrator
*   role_project_dev: Develop
*   role_project_dg_admin: Data Governance Administrator
*   role_project_guest: Visitor
*   role_project_security: Security Administrator
*   role_project_deploy: Deploy
*   role_project_owner: Workspace Owner
*   role_project_data_analyst: Data Analyst
*   role_project_pe: O\\&M
*   role_project_erd: Model Designer', example='role_project_guest'),
        name?: string(name='Name', description='The name of the role.', example='Visitors'),
        type?: string(name='Type', description='The type of the role. Valid values:

*   UserCustom: custom role
*   System: built-in role', example='System'),
      }
    ](name='Roles', description='The roles that are assigned to the member in the workspace.'),
    status?: string(name='Status', description='The status of the member.

*   Normal
*   Forbidden', example='Normal'),
    userId?: string(name='UserId', description='The ID of the account used by the member in the workspace.', example='123422344899'),
    userName?: string(name='UserName'),
  }(name='ProjectMember', description='The details about the member in the workspace.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
}

model GetProjectMemberResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetProjectMemberResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetProjectMember  GetProjectMemberRequest
  * @return GetProjectMemberResponse
 */
async function getProjectMember(request: GetProjectMemberRequest): GetProjectMemberResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetProjectMember', 'POST', '/', 'json', true, 'form', request);
}

model GetProjectRoleRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  code: string(name='Code', description='The code of the role in the DataWorks workspace. Valid values:

*   role_project_admin: workspace administrator
*   role_project_dev: developer
*   role_project_dg_admin: data governance administrator
*   role_project_guest: visitor
*   role_project_security: security administrator
*   role_project_deploy: deployer
*   role_project_owner: workspace owner
*   role_project_data_analyst: data analyst
*   role_project_pe: O\\&M engineer
*   role_project_erd: model designer

This parameter is required.', example='role_project_guest', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10002', position='Query'),
}

model GetProjectRoleResponseBody = {
  projectRole?: {
    code?: string(name='Code', description='The code of the role in the DataWorks workspace.', example='role_project_guest'),
    name?: string(name='Name', description='The name of the role in the DataWorks workspace.', example='Visitors'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10002'),
    type?: string(name='Type', description='The type of the role in the DataWorks workspace. Valid values:

*   UserCustom: user-defined role
*   System: system role', example='System'),
  }(name='ProjectRole', description='The role in the DataWorks workspace.'),
  requestId?: string(name='RequestId', description='The request ID.', example='82F28E60-CF48-5EDF-AB25-D806847B97D1'),
}

model GetProjectRoleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetProjectRoleResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetProjectRole  GetProjectRoleRequest
  * @return GetProjectRoleResponse
 */
async function getProjectRole(request: GetProjectRoleRequest): GetProjectRoleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetProjectRole', 'POST', '/', 'json', false, 'json', request);
}

model GetRerunWorkflowInstancesResultRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  operationId: string(name='OperationId', description='The operation ID used to asynchronously query the result of the workflow instance rerun. This value is obtained from the RerunWorkflowInstances operation.

This parameter is required.', example='e15ad21c-b0e9-4792-8f55-b037xxxxxxxx', position='Query'),
}

model GetRerunWorkflowInstancesResultResponseBody = {
  requestId?: string(name='RequestId', description='The request ID, used for log tracing and troubleshooting.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  result?: {
    failureMessage?: string(name='FailureMessage', description='The failure message. Returned if the rerun fails.', example='Invalid Param xxx'),
    status?: string(name='Status', description='The status. NotRun Success Failure', example='Success'),
  }(name='Result', description='The result of the workflow instance rerun.'),
}

model GetRerunWorkflowInstancesResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetRerunWorkflowInstancesResultResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetRerunWorkflowInstancesResult  GetRerunWorkflowInstancesResultRequest
  * @return GetRerunWorkflowInstancesResultResponse
 */
async function getRerunWorkflowInstancesResult(request: GetRerunWorkflowInstancesResultRequest): GetRerunWorkflowInstancesResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetRerunWorkflowInstancesResult', 'POST', '/', 'json', false, 'json', request);
}

model GetResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the file resource.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
}

model GetResourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='E871F6C0-2EFF-5790-A00D-C57543EEXXXX'),
  resource?: {
    createTime?: long(name='CreateTime', description='The time when the file resource was created. This value is a UNIX timestamp.', example='1700539206000'),
    id?: long(name='Id', description='The ID of the file resource.', example='860438872620113XXXX'),
    modifyTime?: long(name='ModifyTime', description='The time when the file resource was last modified. This value is a UNIX timestamp.', example='1700539206000'),
    name?: string(name='Name', description='The name of the file resource.', example='OpenAPI_Test_Resource. py'),
    owner?: string(name='Owner', description='The owner of the file resource.', example='110755000425XXXX'),
    projectId?: long(name='ProjectId', description='The ID of the workspace to which the file resource belongs.', example='10000'),
    spec?: string(name='Spec', description='The FlowSpec field information about the file resource. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow).', example='{
    "version": "1.1.0",
    "kind": "Resource",
    "spec": {
        "fileResources": [
            {
                "name": "OpenAPI_Test_Resource.py",
                "id": "631478864897630XXXX",
                "script": {
                    "content": "",
                    "path": "XX/OpenAPI_Test/Resource_Test/OpenAPI_Test_Resource.py",
                    "runtime": {
                        "command": "ODPS_PYTHON"
                    }
                },
                "type": "python",
                "file": {
                    "storage": {}
                },
                "datasource": {
                    "name": "odps_first",
                    "type": "odps"
                },
                "metadata": {
                    "owner": "110755000425XXXX"
                }
            }
        ]
    }
}'),
  }(name='Resource', description='The information about the file resource.'),
}

model GetResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetResource  GetResourceRequest
  * @return GetResourceResponse
 */
async function getResource(request: GetResourceRequest): GetResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetResource', 'GET', '/', 'json', false, 'json', request);
}

model GetResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Query'),
}

model GetResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  resourceGroup?: {
    aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group.', example='rg-aek2kqofrgXXXXX'),
    aliyunResourceTags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='key'),
        value?: string(name='Value', description='The tag value.', example='value'),
      }
    ](name='AliyunResourceTags', description='The tags.'),
    createTime?: long(name='CreateTime', description='The time when the resource group was created. The value is a 64-bit timestamp.', example='1727055811000'),
    createUser?: string(name='CreateUser', description='The ID of the account that is used to create the resource group.', example='11075500042XXXXX'),
    defaultVpcId?: string(name='DefaultVpcId', description='The ID of the virtual private cloud (VPC) with which the resource group is associated by default.', example='vpc-m2et4f3oc8msfbccXXXXX'),
    defaultVswitchId?: string(name='DefaultVswitchId', description='The ID of the vSwitch with which the resource group is associated by default.', example='vsw-uf8usrhs7hjd9amsXXXXX'),
    id?: string(name='Id', description='The ID of the resource group.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
    name?: string(name='Name', description='The name of the resource group.', example='common_resource_group'),
    orderInstanceId?: string(name='OrderInstanceId', description='The instance ID of the order that is used to create the resource group.', example='c442b330-3b10-4584-959e-736e4edXXXXX'),
    paymentType?: string(name='PaymentType', description='The billing method of the resource group. Valid values: PrePaid and PostPaid. The value PrePaid indicates the subscription billing method, and the value PostPaid indicates the pay-as-you-go billing method.', example='PrePaid'),
    remark?: string(name='Remark', description='The description of the resource group.', example='Create a common resource group for common tasks'),
    resourceGroupType?: string(name='ResourceGroupType', description='The type of the resource group. Valid values:

*   CommonV2: Serverless resource group.
*   ExclusiveDataIntegration: Exclusive resource group for Data Integration.
*   ExclusiveScheduler: Exclusive resource group for scheduling.
*   ExclusiveDataService: Exclusive resource group for DataService Studio.', example='CommonV2'),
    spec?: {
      amount?: int32(name='Amount', description='The number of resources in the resource group.', example='1'),
      standard?: string(name='Standard', description='The number of compute units (CUs) in the resource group.', example='2CU'),
    }(name='Spec', description='The specifications of the resource group.'),
    status?: string(name='Status', description='The status of the resource group. Valid values:

*   Normal: The resource group is running or in use.
*   Stop: The resource group is expired.
*   Deleted: The resource group is released or destroyed.
*   Creating: The resource group is being created.
*   CreateFailed: The resource group fails to be created.
*   Updating: The resource group is being scaled in or out, or the configurations of the resource group are being changed.
*   UpdateFailed: The resource group fails to be scaled out or upgraded.
*   Deleting: The resource group is being released or destroyed.
*   DeleteFailed: The resource group fails to be released or destroyed.
*   Timeout: The operations that are performed on the resource group time out.
*   Freezed: The resource group is frozen.
*   Starting: The resource group is being started.', example='Normal'),
  }(name='ResourceGroup', description='The details about the resource group.'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetResourceGroupResponseBody(name='body'),
}

/**
  * @description You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * @param request  the request parameters of GetResourceGroup  GetResourceGroupRequest
  * @return GetResourceGroupResponse
 */
async function getResourceGroup(request: GetResourceGroupRequest): GetResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetResourceGroup', 'GET', '/', 'json', false, 'json', request);
}

model GetRouteRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The route ID.

This parameter is required.', example='1000', position='Query'),
}

model GetRouteResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  route?: {
    createTime?: long(name='CreateTime', description='The time when the route was created. The value is a 64-bit timestamp.', example='1727055811000'),
    destinationCidr?: string(name='DestinationCidr', description='The CIDR block of the destination-based route.', example='192.168.0.0/16'),
    id?: long(name='Id', description='The route ID.', example='1000'),
    networkId?: long(name='NetworkId', description='The network ID.', example='1000'),
    resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
    resourceId?: string(name='ResourceId', description='The network resource ID.', example='ns-679XXXXX'),
  }(name='Route', description='The information about the route.'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetRouteResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetRouteResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetRoute  GetRouteRequest
  * @return GetRouteResponse
 */
async function getRoute(request: GetRouteRequest): GetRouteResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetRoute', 'GET', '/', 'json', false, 'json', request);
}

model GetSchemaRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID. You can refer to the ListSchemas operation and [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

The format is `${EntityType}:${Instance ID or escaped URL}:${Catalog ID}:${Database name}:${Schema name}</code>`. Use empty strings as placeholders for missing levels.

>  For the MaxCompute type, use an empty string as the placeholder for the instance ID level. The database name is the MaxCompute project name, and the project must have the three-level model enabled.

Examples:

`maxcompute-schema:::project_name:schema_name` (The three-level model is enabled for the MaxCompute project.)

`holo-schema:instance_id::database_name:schema_name`

> \\
`instance_id`: The Hologres instance ID\\
. `database_name`: The database name\\
. `database_name`: The MaxCompute project name\\
. `schema_name`: The schema name.

This parameter is required.', example='maxcompute-schema:123456XXX::test_project:default
holo-schema:h-abc123xxx::test_db:test_schema', position='Query'),
}

model GetSchemaResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A89B5D9D-74EA-XXXXXX'),
  schema?: Schema(name='Schema', description='The schema information.'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetSchemaResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSchemaResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this API operation to query the information only about MaxCompute and Hologres schemas.
  * @param request  the request parameters of GetSchema  GetSchemaRequest
  * @return GetSchemaResponse
 */
async function getSchema(request: GetSchemaRequest): GetSchemaResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSchema', 'GET', '/', 'json', false, 'json', request);
}

model GetTableRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID. You can refer to the response of the ListTables operation and the [concepts related to metadata entities.](https://help.aliyun.com/document_detail/2880092.html)

The format: `${EntityType}:${Instance ID or escaped URL}:${Catalog identifier}:${Database name}:${Table name}`. Use empty strings as placeholders for levels that do not exist.

>  For the MaxCompute and DLF types, use an empty string as the placeholder for the instance ID.

>  The catalog identifier of the StarRocks is the catalog name, and the catalog identifier of the DLF type is the catalog ID. Other types do not support the catalog level. Use an empty string as a placeholder.

>  For MaxCompute, the database name refers to the MaxCompute project name. If the project has schema enabled, you must specify the schema name. Otherwise, use an empty string as the placeholder for the schema name.

Examples of common ID formats

`maxcompute-table:::project_name:[schema_name]:table_name`

`dlf-table::catalog_id:database_name::table_name`

`hms-table:instance_id::database_name::table_name`

`holo-table:instance_id::database_name:schema_name:table_name`

`mysql-table:(instance_id|encoded_jdbc_url)::database_name::table_name`

> \\
`instance_id`: The instance ID, required when the data source is registered in instance mode.\\
`encoded_jdbc_url`: The URL-encoded JDBC connection string, which is required when the data source is registered via a connection string.\\
`catalog_id`: The DLF catalog ID.\\
`project_name`: The MaxCompute project name.\\
`database_name`: The database name.\\
`schema_name`: The schema name. For the MaxCompute type, this is required only if the project has enabled schema. Otherwise, use an empty string as a placeholder.\\
`table_name`: The table name.

This parameter is required.', example='maxcompute-table:123456XXX::test_project::test_tbl
dlf-table:123456XXX:test_catalog:test_db::test_tbl
hms-table:c-abc123xxx::test_db::test_tbl
holo-table:h-abc123xxx::test_db:test_schema:test_tbl', position='Query'),
  includeBusinessMetadata?: boolean(name='IncludeBusinessMetadata', description='Specifies whether to include metadata. Default: false.', example='true', position='Query'),
}

model GetTableResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='7B3435F4-2D91-XXX'),
  success?: boolean(name='Success', description='Indicates whether the request succeeded.', example='true'),
  table?: Table(name='Table', description='Detailed information about the table.'),
}

model GetTableResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTableResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTable  GetTableRequest
  * @return GetTableResponse
 */
async function getTable(request: GetTableRequest): GetTableResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTable', 'GET', '/', 'json', false, 'json', request);
}

model GetTaskRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model GetTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  task?: {
    baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
    createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
    createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
    dataSource?: {
      name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
    }(name='DataSource', description='The information about the associated data source.'),
    dependencies?: [ 
      {
        type?: string(name='Type', description='The dependency type. Valid values:

*   CrossCycleDependsOnChildren: cross-cycle dependency on level-1 descendant nodes
*   CrossCycleDependsOnSelf: cross-cycle dependency on the current node
*   CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
*   Normal: same-cycle scheduling dependency', example='Normal'),
        upstreamOutput?: string(name='UpstreamOutput', description='The identifier of the output of the ancestor task. This parameter is returned only if `same-cycle scheduling dependencies` and the node input are configured.', example='pre.odps_sql_demo_0'),
        upstreamTaskId?: string(name='UpstreamTaskId', description='The ancestor task ID. This parameter is returned only if `cross-cycle scheduling dependencies` or `same-cycle scheduling dependencies` and the node input are not configured.', example='1234'),
      }
    ](name='Dependencies', description='The dependency information.'),
    description?: string(name='Description', description='The description of the task.', example='test'),
    envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
    id?: long(name='Id', description='The instance ID.', example='1234'),
    inputs?: {
      variables?: [ 
        {
          name?: string(name='Name', description='The name of the variable.', example='key1'),
          type?: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output', example='Constant'),
          value?: string(name='Value', description='The value of the variable.', example='Value1'),
        }
      ](name='Variables', description='The variables.'),
    }(name='Inputs', description='The input information.'),
    instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
    modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
    modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
    name?: string(name='Name', description='The name of the task.', example='SQL node'),
    outputs?: {
      taskOutputs?: [ 
        {
          output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
        }
      ](name='TaskOutputs', description='The task outputs.'),
      variables?: [ 
        {
          name?: string(name='Name', description='The name of the variable.', example='key1'),
          type?: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output', example='Constant'),
          value?: string(name='Value', description='The value of the variable.', example='value1'),
        }
      ](name='Variables', description='The variables.'),
    }(name='Outputs', description='The output information.'),
    owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
    priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
    projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', deprecated='true'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
    rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
    rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to be run.
*   FailureAllowed: The task can be rerun only after it fails to be run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to be run.', example='AllAllowed'),
    rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
    runtimeResource?: {
      cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
      image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
      resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
    }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
    script?: {
      content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
      parameters?: string(name='Parameters', description='The script parameters.', example='para1=$bizdate'),
    }(name='Script', description='The script information.'),
    subTasks?: {
      subTasks?: [ 
        {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='The baseline ID.'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description of the task.', example='test'),
          envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
          id?: long(name='Id', description='The task ID.', example='1234'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          name?: string(name='Name', description='The name of the task.', example='SQL node'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
          projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', deprecated='true'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='180'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to be run.
*   FailureAllowed: The task can be rerun only after it fails to be run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to be run.', example='AllAllowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of CUs configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The runtime environment configuration of the task, such as the resource group.'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
          trigger?: {
            cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
            endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
            recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
            startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
            type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: periodic scheduling
*   Manual: manual scheduling', example='Scheduler'),
          }(name='Trigger', description='The method to trigger task scheduling.'),
          type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
        }
      ](name='SubTasks', description='The subtasks.'),
      type?: string(name='Type', description='The type of the subtask. Valid values:

*   DoWhile: do-while node
*   Combined: node group
*   ForEach: for-each node', example='Combined'),
    }(name='SubTasks', description='The configurations of the subtasks, such as a do-while node.'),
    tags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='key1'),
        value?: string(name='Value', description='The tag value.', example='value1'),
      }
    ](name='Tags', description='The tags.'),
    timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
    trigger?: {
      cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
      endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
      recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
      startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
      type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: periodic scheduling
*   Manual: manual scheduling', example='Scheduler'),
    }(name='Trigger', description='The method to trigger task scheduling.'),
    type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
    workflowId?: long(name='WorkflowId', description='The workflow ID.', example='1234'),
  }(name='Task', description='The details of the task.'),
}

model GetTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTask  GetTaskRequest
  * @return GetTaskResponse
 */
async function getTask(request: GetTaskRequest): GetTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTask', 'GET', '/', 'json', false, 'json', request);
}

model GetTaskInstanceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
}

model GetTaskInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  taskInstance?: {
    baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
    bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
    createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
    createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
    dataSource?: {
      name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
    }(name='DataSource', description='The information about the associated data source.'),
    description?: string(name='Description', description='The description.', example='test'),
    finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
    id?: long(name='Id', description='The instance ID.', example='1234'),
    inputs?: {
      variables?: [ 
        {
          name?: string(name='Name', description='The name of the variable.', example='Key1'),
          type?: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output', example='Constant'),
          value?: string(name='Value', description='The value of the variable.', example='Value1'),
        }
      ](name='Variables', description='The variables.'),
    }(name='Inputs', description='The input information.'),
    modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
    modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
    outputs?: {
      taskOutputs?: [ 
        {
          output?: string(name='Output', description='The output identifier.', example='pre.odps_sql_demo_0'),
        }
      ](name='TaskOutputs', description='The task outputs.'),
      variables?: [ 
        {
          name?: string(name='Name', description='The name of the variable.', example='key1'),
          type?: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output', example='Constant'),
          value?: string(name='Value', description='The value of the variable.', example='value1'),
        }
      ](name='Variables', description='The variables.'),
    }(name='Outputs', description='The output information.'),
    owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
    periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
    priority?: int32(name='Priority', description='The task priority. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
    projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
    rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.', example='AllAllowed'),
    runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
    runtime?: {
      gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
      processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
    }(name='Runtime', description='The runtime information about the instance.'),
    runtimeResource?: {
      cu?: string(name='Cu', description='The default number of CUs configured for task running.', example='0.25'),
      image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
      resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
    }(name='RuntimeResource', description='The information about the resource group with which the instance is associated.'),
    script?: {
      content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
      parameters?: string(name='Parameters', description='The script parameters.', example='para1=$bizdate'),
    }(name='Script', description='The script information.'),
    startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
    status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
    tags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='key1'),
        value?: string(name='Value', description='The tag value.', example='value1'),
      }
    ](name='Tags', description='The tags of the task.'),
    taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
    taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
    taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
    timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='1'),
    triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
    triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
    triggerType?: string(name='TriggerType', description='The method to trigger instance scheduling. The value of the Trigger.Type parameter in the response of the GetTask operation is used. Valid values:

*   Scheduler
*   Manual', example='Scheduler'),
    unifiedWorkflowInstanceId?: long(name='UnifiedWorkflowInstanceId'),
    waitingResourceTime?: long(name='WaitingResourceTime', example='1710239005403'),
    waitingTriggerTime?: long(name='WaitingTriggerTime', example='1710239005403'),
    workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
    workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
    workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   SmokeTest
*   SupplementData
*   Manual
*   ManualWorkflow
*   Normal
*   ManualFlow', example='Normal'),
    workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
  }(name='TaskInstance', description='The details of the task instance.'),
}

model GetTaskInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTaskInstanceResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetTaskInstance  GetTaskInstanceRequest
  * @return GetTaskInstanceResponse
 */
async function getTaskInstance(request: GetTaskInstanceRequest): GetTaskInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTaskInstance', 'GET', '/', 'json', false, 'json', request);
}

model GetTaskInstanceLogRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  runNumber?: int32(name='RunNumber', description='The sequence number of an instance run. Minimum value: 1. By default, the latest run is used.', example='1', position='Query'),
}

model GetTaskInstanceLogResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  taskInstanceLog?: string(name='TaskInstanceLog', description='The run log of the instance.', example='This is running log'),
}

model GetTaskInstanceLogResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTaskInstanceLogResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetTaskInstanceLog  GetTaskInstanceLogRequest
  * @return GetTaskInstanceLogResponse
 */
async function getTaskInstanceLog(request: GetTaskInstanceLogRequest): GetTaskInstanceLogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTaskInstanceLog', 'GET', '/', 'json', false, 'json', request);
}

model GetWorkflowRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
  id: long(name='Id', description='The workflow ID.

This parameter is required.', example='1234', position='Query'),
}

model GetWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  workflow?: {
    clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a workflow asynchronously and implement the idempotence of the workflow. If you do not specify this parameter when you create the workflow, the system automatically generates a unique code. The unique code is uniquely associated with the workflow ID. If you specify this parameter when you update or delete the workflow, the value of this parameter must be the unique code that is used to create the workflow.', example='Workflow_0bc5213917368545132902xxxxxxxx'),
    createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
    createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
    dependencies?: [ 
      {
        type?: string(name='Type', description='The scheduling dependency type. Valid values:

*   CrossCycleDependsOnChildren: cross-cycle dependency on the level-1 descendant nodes of a node
*   CrossCycleDependsOnSelf: cross-cycle dependency on the current node
*   CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
*   Normal: same-cycle scheduling dependency', example='Normal'),
        upstreamOutput?: string(name='UpstreamOutput', description='The identifier of the output of the ancestor task. This parameter is returned only if `same-cycle scheduling dependencies` and the node input are configured.', example='pre.odps_sql_demo_0'),
        upstreamTaskId?: long(name='UpstreamTaskId', description='The ancestor task ID. This parameter is returned only if `cross-cycle scheduling dependencies` or `same-cycle scheduling dependencies` and the node input are not configured.', example='1234'),
      }
    ](name='Dependencies', description='The dependency information.'),
    description?: string(name='Description', description='The description of the workflow.', example='Test workflow'),
    envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
    id?: long(name='Id', description='The workflow ID.', example='1234'),
    modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
    modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
    name?: string(name='Name', description='The name of the workflow.', example='Workflow'),
    outputs?: {
      taskOutputs?: [ 
        {
          output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
        }
      ](name='TaskOutputs', description='The task outputs.'),
    }(name='Outputs', description='The output information.'),
    owner?: string(name='Owner', description='The account ID of the workflow owner.', example='1000'),
    parameters?: string(name='Parameters', description='The parameters.', example='para1=$bizdate para2=$[yyyymmdd]'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
    tags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='key1'),
        value?: string(name='Value', description='The tag value.', example='value1'),
      }
    ](name='Tags', description='The tags.'),
    tasks?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a task asynchronously and implement the idempotence of the task. If you do not specify this parameter when you create the task, the system automatically generates a unique code. The unique code is uniquely associated with the task ID. If you specify this parameter when you update or delete the task, the value of this parameter must be the unique code that is used to create the task.', example='Task_0bc5213917368545132902xxxxxxxx'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description of the task.', example='Test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        id?: long(name='Id', description='The task ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name of the task.', example='SQL node'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
        rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.', example='AllAllowed'),
        rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
        triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the task after it is triggered. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
      }
    ](name='Tasks', description='The tasks.'),
    trigger?: {
      cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
      endTime?: string(name='EndTime', description='The end time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
      recurrence?: string(name='Recurrence', description='The running mode of the workflow after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
      startTime?: string(name='StartTime', description='The start time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
      type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
    }(name='Trigger', description='The trigger method.'),
  }(name='Workflow', description='The information about the workflow.'),
}

model GetWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkflowResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetWorkflow  GetWorkflowRequest
  * @return GetWorkflowResponse
 */
async function getWorkflow(request: GetWorkflowRequest): GetWorkflowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetWorkflow', 'GET', '/', 'json', false, 'json', request);
}

model GetWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  includeScriptContent?: boolean(name='IncludeScriptContent', description='查询结果是否包含工作流内部节点的脚本内容（对于内容较多的节点，可能存在较长的网络传输延时）。', example='false', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
}

model GetWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='F2BDD628-8A21-5BD1-B930-1A2D5989XXXX'),
  workflowDefinition?: {
    createTime?: long(name='CreateTime', description='The time when the workflow was created. This value is a UNIX timestamp.', example='1708481905000'),
    id?: long(name='Id', description='The ID of the workflow.', example='463497880880954XXXX'),
    modifyTime?: long(name='ModifyTime', description='The time when the workflow was last modified. This value is a UNIX timestamp.', example='1708481905000'),
    name?: string(name='Name', description='The name of the workflow.', example='OpenAPI test workflow Demo'),
    owner?: string(name='Owner', description='The owner of the workflow.', example='110755000425XXXX'),
    projectId?: long(name='ProjectId', description='The ID of the workspace to which the workflow belongs.', example='307XXX'),
    spec?: string(name='Spec', description='The FlowSpec field information about the workflow. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow/).', example='{
    "metadata": {
        "tenantId": "52425742456XXXX",
        "projectId": "307XXXX",
        "uuid": "463497880880954XXXX"
    },
    "kind": "CycleWorkflow",
    "version": "1.1.0",
    "spec": {
        "name": "OpenAPI_Test_Workflow_Demo",
        "id": "463497880880954XXXX",
        "type": "CycleWorkflow",
        "owner": "110755000425XXXX",
        "workflows": [
            {
                "script": {
                    "path": "XX/OpenAPI_Test/Workflow_Test/OpenAPI_Test_Workflow_Demo",
                    "runtime": {
                        "command": "WORKFLOW"
                    },
                    "id": "698002781368644XXXX"
                },
                "id": "463497880880954XXXX",
                "trigger": {
                    "type": "Scheduler",
                    "id": "652567824470354XXXX",
                    "cron": "00 02 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "strategy": {
                    "timeout": 0,
                    "instanceMode": "T+1",
                    "rerunMode": "Allowed",
                    "rerunTimes": 3,
                    "rerunInterval": 180000,
                    "failureStrategy": "Break"
                },
                "name": "OpenAPI_Test_Workflow_Demo",
                "owner": "110755000425XXXX",
                "metadata": {
                    "owner": "110755000425XXXX",
                    "ownerName": "XXXX@test.XXXX.com",
                    "tenantId": "52425742456XXXX",
                    "project": {
                        "mode": "STANDARD",
                        "projectId": "307303",
                        "projectIdentifier": "lwttest_standard",
                        "projectName": "XXXX",
                        "projectOwnerId": "110755000425XXXX",
                        "simple": false,
                        "tenantId": "52425742456XXXX"
                    },
                    "projectId": "307XXXX"
                },
                "inputs": {},
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "463497880880954XXXX",
                            "artifactType": "NodeOutput",
                            "refTableName": "OpenAPI_Test_Workflow_Demo",
                            "isDefault": true
                        }
                    ]
                },
                "nodes": [],
                "dependencies": []
            }
        ]
    }
}'),
    workflowId?: long(name='WorkflowId', description='The ID of the workflow on the scheduling side after publishing.', example='700006657495'),
  }(name='WorkflowDefinition', description='The information about the workflow.'),
}

model GetWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetWorkflowDefinition  GetWorkflowDefinitionRequest
  * @return GetWorkflowDefinitionResponse
 */
async function getWorkflowDefinition(request: GetWorkflowDefinitionRequest): GetWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetWorkflowDefinition', 'GET', '/', 'json', false, 'json', request);
}

model GetWorkflowInstanceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow instance.

This parameter is required.', example='1234', position='Query'),
}

model GetWorkflowInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  workflowInstance?: {
    bizDate?: long(name='BizDate', description='The data timestamp.', example='1710239005403'),
    createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
    createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
    envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
    finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
    id?: long(name='Id', description='The ID of the workflow instance.', example='1234'),
    modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
    modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
    name?: string(name='Name', description='The name of the workflow instance.', example='WorkInstance1'),
    owner?: string(name='Owner', example='1000'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
    startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
    status?: string(name='Status', description='The status of the workflow instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
    tags?: [ 
      {
        key?: string(name='Key', description='The key of a tag.', example='key1'),
        value?: string(name='Value', description='The value of a tag.', example='value1'),
      }
    ](name='Tags', description='The task tag.'),
    type?: string(name='Type', description='The type of the workflow instance. Valid values:

*   Normal: Scheduled execution
*   Manual: Manually triggered node
*   SmokeTest: Testing
*   SupplementData: Data backfill
*   ManualWorkflow: Manually triggered workflow
*   TriggerWorkflow: Triggered Workflow', example='Normal'),
    unifiedWorkflowInstanceId?: long(name='UnifiedWorkflowInstanceId'),
    workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
    workflowParameters?: string(name='WorkflowParameters', description='The workflow parameters.'),
    workflowTaskInstanceId?: long(name='WorkflowTaskInstanceId', example='1234'),
  }(name='WorkflowInstance', description='The information about the workflow instance.'),
}

model GetWorkflowInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkflowInstanceResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetWorkflowInstance  GetWorkflowInstanceRequest
  * @return GetWorkflowInstanceResponse
 */
async function getWorkflowInstance(request: GetWorkflowInstanceRequest): GetWorkflowInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetWorkflowInstance', 'GET', '/', 'json', false, 'json', request);
}

model GrantMemberProjectRolesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='105149', position='Body'),
  roleCodes: [ string ](name='RoleCodes', description='The codes of the roles in the workspace. You can call the [ListProjectRoles](https://help.aliyun.com/document_detail/2853930.html) operation to query the codes of all roles in the workspace.

You must configure this parameter to specify the roles that you want to assign to members in the workspace.

This parameter is required.', shrink='json', position='Body'),
  userId: string(name='UserId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the Tenant Members and Roles page, view the IDs of the accounts used by the members in the workspace.

This parameter is required.', example='123422344899', position='Body'),
}

model GrantMemberProjectRolesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='2d9ced66-38ef-4923-baf6-391dd3a7e656'),
}

model GrantMemberProjectRolesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GrantMemberProjectRolesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GrantMemberProjectRoles  GrantMemberProjectRolesRequest
  * @return GrantMemberProjectRolesResponse
 */
async function grantMemberProjectRoles(request: GrantMemberProjectRolesRequest): GrantMemberProjectRolesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GrantMemberProjectRoles', 'POST', '/', 'json', true, 'form', request);
}

model ImportWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='123456', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the workflow. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow/).

This parameter is required.', example='{
    "version": "1.1.0",
    "kind": "CycleWorkflow",
    "spec": {
        "name": "Asynchronous_Workflow_Creation_Test",
        "id": "632647691239009XXXX",
        "type": "CycleWorkflow",
        "workflows": [
            {
                "script": {
                    "path": "XX/OpenAPI_Test/Workflow_Test/Asynchronous_Workflow_Creation_Test",
                    "runtime": {
                        "command": "WORKFLOW"
                    }
                },
                "id": "632647691239009XXXX",
                "trigger": {
                    "type": "Scheduler",
                    "cron": "00 03 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "strategy": {
                    "timeout": 0,
                    "instanceMode": "T+1",
                    "rerunMode": "Allowed",
                    "rerunTimes": 3,
                    "rerunInterval": 180000,
                    "failureStrategy": "Break"
                },
                "name": "Asynchronous_Workflow_Creation_Test",
                "inputs": {},
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "632647691239009XXXX",
                            "artifactType": "NodeOutput",
                            "refTableName": "Asynchronous_Workflow_Creation_Test"
                        }
                    ]
                },
                "nodes": [
                    {
                        "recurrence": "Normal",
                        "id": "742981001612325XXXX",
                        "timeout": 0,
                        "instanceMode": "T+1",
                        "rerunMode": "Allowed",
                        "rerunTimes": 3,
                        "rerunInterval": 180000,
                        "script": {
                            "path": "XX/OpenAPI_Test/Workflow_Test/Asynchronous_Workflow_Creation_Test/111",
                            "runtime": {
                                "command": "ODPS_SQL"
                            },
                            "content": "select now();\\n"
                        },
                        "trigger": {
                            "type": "Scheduler",
                            "cron": "00 24 00 * * ?",
                            "startTime": "1970-01-01 00:00:00",
                            "endTime": "9999-01-01 00:00:00",
                            "timezone": "Asia/Shanghai",
                            "delaySeconds": 0
                        },
                        "name": "111",
                        "inputs": {},
                        "outputs": {
                            "nodeOutputs": [
                                {
                                    "data": "742981001612325XXXX",
                                    "artifactType": "NodeOutput",
                                    "refTableName": "111"
                                }
                            ]
                        }
                    },
                    {
                        "recurrence": "Normal",
                        "id": "595182137303408XXXX",
                        "timeout": 0,
                        "instanceMode": "T+1",
                        "rerunMode": "Allowed",
                        "rerunTimes": 3,
                        "rerunInterval": 180000,
                        "script": {
                            "path": "XX/OpenAPI_Test/Workflow_Test/Asynchronous_Workflow_Creation_Test/222",
                            "runtime": {
                                "command": "ODPS_SQL"
                            },
                            "content": "select now();\\n select 1;"
                        },
                        "trigger": {
                            "type": "Scheduler",
                            "cron": "00 00 00 * * ?",
                            "startTime": "1970-01-01 00:00:00",
                            "endTime": "9999-01-01 00:00:00",
                            "timezone": "Asia/Shanghai",
                            "delaySeconds": 0
                        },
                        "name": "222",
                        "inputs": {},
                        "outputs": {
                            "nodeOutputs": [
                                {
                                    "data": "595182137303408XXXX",
                                    "artifactType": "NodeOutput",
                                    "refTableName": "222"                                
                                }
                            ]
                        }
                    }
                ],
                "dependencies": [
                    {
                        "nodeId": "595182137303408XXXX",
                        "depends": [
                            {
                                "type": "Normal",
                                "output": "742981001612325XXXX",
                                "refTableName": "111"
                            }
                        ]
                    }
                ]
            }
        ]
    }
}', position='Body'),
}

model ImportWorkflowDefinitionResponseBody = {
  asyncJob?: {
    completed?: boolean(name='Completed', description='Indicates whether the asynchronous task is complete.', example='false'),
    createTime?: long(name='CreateTime', description='The time when the asynchronous task was created. This value is a UNIX timestamp.', example='1706581425000'),
    error?: string(name='Error', description='The error message returned if the asynchronous task fails.', example='target folder already exists: XXXX'),
    id?: string(name='Id', description='The ID of the asynchronous task.', example='1234567691239009XXXX'),
    progress?: int32(name='Progress', description='The progress of the asynchronous task. Valid values: 0 to 100.', example='0'),
    response?: string(name='Response', description='The response.

>  The workflow ID is returned.', example='632647691239009XXXX'),
    status?: string(name='Status', description='The status of the asynchronous task.

Valid values:

*   Running: The asynchronous task is running.
*   Success: The asynchronous task is complete.
*   Fail: The asynchronous task fails.
*   Cancel: The asynchronous task is canceled.', example='Running'),
    type?: string(name='Type', description='The type of the asynchronous task.

Valid values:

*   Create: The asynchronous task is used to create an object.
*   Cancel: The asynchronous task is used to cancel an operation.', example='Create'),
  }(name='AsyncJob', description='The status information of the asynchronous task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7C352CB7-CD88-50CF-9D0D-E81BDF020E7F'),
}

model ImportWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ImportWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @description > 
  * *   You cannot use this API operation to import multiple workflows at a time. If you specify multiple workflows by using FlowSpec, the system imports only the first specified workflow.
  * *   ImportWorkflowDefinition is an asynchronous operation. After you send a request, an asynchronous task is generated, and the system returns the ID of the asynchronous task. You can call the GetJobStatus operation to query the status of the asynchronous task.
  * @param request  the request parameters of ImportWorkflowDefinition  ImportWorkflowDefinitionRequest
  * @return ImportWorkflowDefinitionResponse
 */
async function importWorkflowDefinition(request: ImportWorkflowDefinitionRequest): ImportWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ImportWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model ListAlertRulesRequest {
  regionId?: string(name='RegionId', position='Host'),
  name?: string(name='Name', description='The name of the rule.', example='error_rule', position='Query'),
  owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.', example='1933790683****', position='Query'),
  pageNumber: int32(name='PageNumber', description='The page number. Pages start from page 1.

This parameter is required.', example='1', minimum=1, position='Query'),
  pageSize: long(name='PageSize', description='The number of entries per page. Maximum value: 100.

This parameter is required.', example='10', maximum=100, position='Query'),
  receiver?: string(name='Receiver', description='The ID of the Alibaba Cloud account used by the alert recipient.', example='1933790683****', position='Query'),
  taskIds?: [ long ](name='TaskIds', description='The IDs of the scheduling tasks.', shrink='json', position='Query'),
  types?: [ string ](name='Types', description='The alert triggering condition.', shrink='json', position='Query'),
}

model ListAlertRulesResponseBody = {
  pagingInfo?: {
    alertRules?: [ 
      {
        enabled?: boolean(name='Enabled', description='Indicates whether the rule is enabled.', example='true'),
        id?: long(name='Id', description='The rule ID.', example='22125'),
        name?: string(name='Name', description='The name of the rule.', example='error_test'),
        owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.', example='1933790683****'),
        triggerCondition?: {
          extension?: {
            cycleUnfinished?: {
              cycleAndTime?: [ 
                {
                  cycleId?: int32(name='CycleId', description='The ID of the scheduling cycle of the instance. Valid values: [1,288].', example='1'),
                  time?: string(name='Time', description='The latest completion time of the instance within the scheduling cycle. The time is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='01:00'),
                }
              ](name='CycleAndTime', description='The configurations of the scheduling cycle and timeout period of the instance.'),
            }(name='CycleUnfinished', description='The configuration for an alert of the CycleUnfinished type.'),
            error?: {
              autoRerunAlertEnabled?: boolean(name='AutoRerunAlertEnabled', description='Indicates whether an alert is triggered if a batch synchronization task is automatically rerun upon a failure.', example='false'),
              streamTaskIds?: [ long ](name='StreamTaskIds', description='The IDs of the real-time computing tasks. This parameter is required when you monitor real-time computing tasks.'),
            }(name='Error', description='The configuration for an alert of the Error type.'),
            instanceErrorCount?: {
              count?: int32(name='Count', description='The maximum number of instances on which an error occurs. Valid values: [1,10000].', example='10'),
            }(name='InstanceErrorCount', description='The configuration for an alert of the InstanceErrorCount type.'),
            instanceErrorPercentage?: {
              percentage?: int32(name='Percentage', description='The maximum percentage of instances on which an error occurs in the workspace to the total number of instances. Valid values: [1-100].', example='10'),
            }(name='InstanceErrorPercentage', description='The configuration for an alert of the InstanceErrorPercentage type.'),
            instanceTransferFluctuate?: {
              percentage?: int32(name='Percentage', description='The maximum percentage of fluctuation in the number of auto triggered node instances that are generated in your workspace. Valid values: [1-100].', example='10'),
              trend?: string(name='Trend', description='The way in which the number of auto triggered node instances that are generated in your workspace fluctuates. Valid values:

*   abs: the absolute value. The number of instances increases or decreases.
*   increase: The number of instances increases.
*   decrease: The number of instances decreases.', example='abs'),
            }(name='InstanceTransferFluctuate', description='The configuration for an alert of the InstanceTransferFluctuate type.'),
            timeout?: {
              timeoutInMinutes?: int32(name='TimeoutInMinutes', description='The timeout period. Unit: minutes.', example='10'),
            }(name='Timeout', description='The configuration for an alert of the Timeout type.'),
            unFinished?: {
              unFinishedTime?: string(name='UnFinishedTime', description='The latest completion time of the instance. The period is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
            }(name='UnFinished', description='The configuration for an alert of the UnFinished type.'),
          }(name='Extension', description='The extended information about the rule. This parameter is required for specific types of alerts.'),
          target?: {
            allowTasks?: [ long ](name='AllowTasks', description='The nodes that are not to be monitored.'),
            ids?: [ long ](name='Ids', description='The IDs of monitored objects.'),
            type?: string(name='Type', description='The type of the monitored objects. Valid values:

*   Task: node
*   Baseline: baseline
*   Project: workspace
*   BizProcess: workflow', example='Task'),
          }(name='Target', description='The monitored objects.'),
          type?: string(name='Type', description='The alert type. Valid values:

*   Finished: An instance is successfully run.
*   UnFinished: An instance does not finish running before a specified point in time.
*   Error: An error occurs on an instance.
*   CycleUnfinished: An instance does not finish running as expected within a specific cycle.
*   Timeout: An instance times out.
*   InstanceTransferComplete: An instance is generated by the auto triggered node.
*   InstanceTransferFluctuate: The number of generated instances fluctuates.
*   ExhaustedError: An error persists after an instance is automatically rerun.
*   InstanceKeyword: An instance with errors contains specified keywords.
*   InstanceErrorCount: The number of instances on which an error occurs reaches a specified threshold.
*   InstanceErrorPercentage: The proportion of instances on which an error occurs in the workspace to the total number of instances reaches a specified threshold.
*   ResourceGroupPercentage: The usage rate of the resource group reaches a specified threshold.
*   ResourceGroupWaitCount: The number of instances that are waiting for resources in the resource group reaches a specified threshold.', example='Error'),
        }(name='TriggerCondition', description='The alert triggering condition.'),
      }
    ](name='AlertRules', description='The rules.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='5'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='A6C6B486-E3A2-5D52-9E76-D9380485D946'),
}

model ListAlertRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAlertRulesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAlertRules  ListAlertRulesRequest
  * @return ListAlertRulesResponse
 */
async function listAlertRules(request: ListAlertRulesRequest): ListAlertRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAlertRules', 'POST', '/', 'json', false, 'json', request);
}

model ListBusinessRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  keyword?: string(name='Keyword', description='The keyword, used for fuzzy match of workflow names.', example='my', position='Body'),
  pageNumber: int32(name='PageNumber', description='The requested page number, used for pagination.

This parameter is required.', example='1', minimum=1, position='Body'),
  pageSize: int32(name='PageSize', description='The number of records per page. Default: 10. Maximum: 100.

This parameter is required.', example='10', minimum=0, maximum=100, position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the DataWorks console and go to the Workspace page to query the ID. You must specify either this parameter or the ProjectIdentifier parameter to identify the DataWorks workspace when you call this operation.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can log on to the DataWorks console and go to the Workspace page to query the workspace name. You must specify either this parameter or the ProjectId parameter to identify the DataWorks workspace when you call this operation.', example='dw_project', position='Body'),
}

model ListBusinessResponseBody = {
  data?: {
    business?: [ 
      {
        businessId?: long(name='BusinessId', description='The workflow ID.', example='3000001'),
        businessName?: string(name='BusinessName', description='The name of the workflow.', example='test'),
        description?: string(name='Description', description='The description of the workflow.', example='test'),
        owner?: string(name='Owner', description='The owner of the workflow.', example='34824327****'),
        projectId?: long(name='ProjectId', description='The ID of the workspace to which the workflow belongs.', example='10000'),
        useType?: string(name='UseType', description='The module to which the workflow belongs. Valid values: NORMAL (Data Studio) and MANUAL_BIZ (Manually Triggered Workflow).', example='NORMAL'),
      }
    ](name='Business', description='Information about the workflow list.'),
    pageNumber?: int32(name='PageNumber', description='The current page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of records on the current page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of records that meet the query conditions.', example='13'),
  }(name='Data', description='Details of workflows.'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID. Used for troubleshooting when an error occurs.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListBusinessResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListBusinessResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListBusiness  ListBusinessRequest
  * @return ListBusinessResponse
 */
async function listBusiness(request: ListBusinessRequest): ListBusinessResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListBusiness', 'POST', '/', 'json', true, 'form', request);
}

model ListCatalogsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The comment. Supports token-based matching.', example='this is a comment', position='Query'),
  name?: string(name='Name', description='The name. Supports fuzzy matching.', example='abc', position='Query'),
  order?: string(name='Order', description='The order in which the tables are sorted. Default value: Asc. Valid values:

*   Asc: ascending order.
*   Desc: descending order.', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of records per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
  parentMetaEntityId: string(name='ParentMetaEntityId', description='The parent entity ID. For more information, see [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

Currently, only the DLF and StarRocks types are supported.

*   For the DLF type, you can query all catalog lists. The format of `ParentMetaEntityId` is `DLF`.
*   For the StarRocks type, you can query the catalogs of a specific instance. The format of `ParentMetaEntityId` `is StarRocks:(instance_id|encoded_jdbc_url)`.

> \\
`instance_id`: The instance ID. Required if the data source is registered in instance mode.\\
`encoded_jdbc_url`: The JDBC connection string encoded with URL encoding. Required if the data source is registered in connection-string mode.

This parameter is required.', example='dlf
starrocks:c-abc123xxx', position='Query'),
  sortBy?: string(name='SortBy', description='The sort field. Default value: CreateTime. Valid values:

*   CreateTime
*   ModifyTime
*   Name
*   Type', example='CreateTime', position='Query'),
  types?: [ string ](name='Types', description='The type. Supports exact match. If left empty, all types are queried.', shrink='simple', position='Query'),
}

model ListCatalogsResponseBody = {
  pagingInfo?: {
    catalogs?: [
      Catalog
    ](name='Catalogs', description='The catalog.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of records per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of records.', example='1'),
  }(name='PagingInfo', description='The pagination result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='317CD7D0-AB36-XXXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListCatalogsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCatalogsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListCatalogs  ListCatalogsRequest
  * @return ListCatalogsResponse
 */
async function listCatalogs(request: ListCatalogsRequest): ListCatalogsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListCatalogs', 'GET', '/', 'json', false, 'json', request);
}

model ListCertificatesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  createUser?: string(name='CreateUser', description='The ID of the user who created the certificate files.', example='1107550004253538', position='Query'),
  endCreateTime?: long(name='EndCreateTime', description='The time when the certificate file was created. You can call this operation to query the files that are created before the time. Unit: milliseconds.', example='1593877765000', position='Query'),
  name?: string(name='Name', description='The name of the certificate file. Fuzzy match by file name is supported.', example='xm_create_test', position='Query'),
  order?: string(name='Order', description='The order in which you want to sort the certificate files. Valid values: Desc: descending order ASC: ascending order Default value: Asc', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  projectId: long(name='ProjectId', description='The ID of the workspace to which the certificate file belongs.

This parameter is required.', example='10000', position='Query'),
  sortBy?: string(name='SortBy', description='The field used to sort the certificate files. Valid values: CreateTime Id Name Default value: Id', example='Id', position='Query'),
  startCreateTime?: long(name='StartCreateTime', description='The time when the certificate file was created. You can call this operation to query the files that are created after the time. Unit: milliseconds.', example='1730217600000', position='Query'),
}

model ListCertificatesResponseBody = {
  pagingInfo?: {
    certificates?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the certificate file was created. This value is a UNIX timestamp.', example='1730217600000'),
        createUser?: string(name='CreateUser', description='The ID of the user who created the certificate file.', example='1107550004253538'),
        description?: string(name='Description', description='The description.', example='This is a file'),
        fileSizeInBytes?: long(name='FileSizeInBytes', description='The size of the certificate file, in bytes.', example='1024'),
        id?: long(name='Id', description='The ID of the certificate file.', example='676303114031776'),
        name?: string(name='Name', description='The name of the certificate file.', example='ca1.crt'),
      }
    ](name='Certificates', description='The certificate files.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='ecb967ec-c137-48****'),
}

model ListCertificatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCertificatesResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks: Tenant Owner, Workspace Administrator, Deploy, Develop, Visitor, Workspace Owner, O\\&M, Model Designer, Security Administrator, Data Analyst, OpenPlatform Administrator, and Data Governance Administrator.
  * @param request  the request parameters of ListCertificates  ListCertificatesRequest
  * @return ListCertificatesResponse
 */
async function listCertificates(request: ListCertificatesRequest): ListCertificatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListCertificates', 'GET', '/', 'json', false, 'json', request);
}

model ListColumnsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The comment. Fuzzy match is supported.', example='test comment', position='Query'),
  name?: string(name='Name', description='The name. Fuzzy match is supported.', example='test_table', position='Query'),
  order?: string(name='Order', description='The sort order. Default value: Asc. Valid values:

*   Asc
*   Desc', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of records per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
  sortBy?: string(name='SortBy', description='The sort field. Default value: Position. Valid values:

*   Name
*   Position', example='Position', position='Query'),
  tableId: string(name='TableId', description='The table ID. You can refer to the return result of the ListTables operation. and the [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

This parameter is required.', example='maxcompute-column:11075xxxx::test_project:test_schema:test_table', position='Query'),
}

model ListColumnsResponseBody = {
  pagingInfo?: {
    columns?: [
      Column
    ](name='Columns', description='The columns in the table.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of records per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of records returned.', example='1'),
  }(name='PagingInfo', description='The pagination result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D1E2E5BC-xxxx-xxxx-xxxx-xxxxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListColumnsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListColumnsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListColumns  ListColumnsRequest
  * @return ListColumnsResponse
 */
async function listColumns(request: ListColumnsRequest): ListColumnsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListColumns', 'GET', '/', 'json', false, 'json', request);
}

model ListComponentsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  name?: string(name='Name', description='The name of the data source.', example='xm_create_test', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number for pagination.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='1000', minimum=10, maximum=100, position='Query'),
  projectId?: long(name='ProjectId', description='The ID of the workspace associated with the data source. You can call the [ListProjects](https://help.aliyun.com/document_detail/178393.html) operation to obtain the workspace ID.', example='100001', position='Query'),
}

model ListComponentsResponseBody = {
  pagingInfo?: {
    components?: [ 
      {
        componentId?: string(name='ComponentId', description='The component ID. This parameter can be used in requests to query, modify, or delete director components.', example='12312313123'),
        createTime?: string(name='CreateTime', description='The creation time.

Use the UTC time format: yyyy-MM-ddTHH:mm:ss.SSSZ', example='2023-03-13 16:35:59'),
        description?: string(name='Description', description='The description.', example='vpc peering management_staging'),
        inputs?: [ 
          {
            defaultValue?: string(name='DefaultValue', description='The default value of the variable.', example='mdb.shard.2x.2xlarge.d'),
            description?: string(name='Description', description='The parameter description.', example='None'),
            name?: string(name='Name', description='The parameter name.', example='auto_updateAlertRule_test_bULIRo'),
            type?: string(name='Type', description='The parameter type.', example='string'),
          }
        ](name='Inputs', description='The input parameters.'),
        modifyTime?: string(name='ModifyTime', description='The timestamp when the publishing process was modified.

Use the UTC time format: yyyy-MM-ddTHH:mm:ss.SSSZ', example='2023-11-30T13:30:58Z'),
        name?: string(name='Name', description='The resource name.', example='auto_updateAlertRule_test_lJd81f'),
        outputs?: [ 
          {
            defaultValue?: string(name='DefaultValue', description='The default value.', example='32000'),
            description?: string(name='Description', description='The parameter description.', example='zdy'),
            name?: string(name='Name', description='The parameter name.', example='auto_updateAlertRule_test_bULIRo'),
            type?: string(name='Type', description='The parameter type.', example='string'),
          }
        ](name='Outputs', description='The output parameters.'),
        owner?: string(name='Owner', description='The owner.', example='252675537980665607'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID. To obtain the workspace ID, log on to the DataWorks console and navigate to the workspace configuration page. You must specify either this parameter or ProjectIdentifier to identify the target DataWorks workspace for this API call.', example='199925'),
        script?: {
          id?: string(name='Id', description='ID', example='348100'),
          path?: string(name='Path', description='The script path.', example='/'),
          runtime?: {
            command?: string(name='Command', description='The command.', example='SQL_COMPONENT'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information.'),
      }
    ](name='Components', description='The UID of the user who created the dataset acceleration component. In Alibaba Cloud, this is the RAM user ID (or the Alibaba Cloud account ID if created by the account itself).'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. Use this ID for troubleshooting.', example='952795279527ab****'),
}

model ListComponentsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListComponentsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListComponents  ListComponentsRequest
  * @return ListComponentsResponse
 */
async function listComponents(request: ListComponentsRequest): ListComponentsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListComponents', 'POST', '/', 'json', false, 'json', request);
}

model ListComputeResourcesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  envType?: string(name='EnvType', position='Query'),
  name?: string(name='Name', position='Query'),
  order?: string(name='Order', position='Query'),
  pageNumber?: int32(name='PageNumber', position='Query'),
  pageSize?: int32(name='PageSize', position='Query'),
  projectId: long(name='ProjectId', description='This parameter is required.', position='Query'),
  sortBy?: string(name='SortBy', position='Query'),
  types?: [ string ](name='Types', shrink='simple', position='Query'),
}

model ListComputeResourcesResponseBody = {
  pagingInfo?: {
    computeResources?: [ 
      {
        computeResource?: [ 
          {
            connectionProperties?: any(name='ConnectionProperties'),
            connectionPropertiesMode?: string(name='ConnectionPropertiesMode'),
            createTime?: long(name='CreateTime'),
            createUser?: string(name='CreateUser'),
            description?: string(name='Description'),
            id?: long(name='Id'),
            modifyTime?: long(name='ModifyTime'),
            modifyUser?: string(name='ModifyUser'),
            whetherDefault?: boolean(name='WhetherDefault'),
          }
        ](name='ComputeResource'),
        name?: string(name='Name'),
        type?: string(name='Type'),
      }
    ](name='ComputeResources'),
    pageNumber?: long(name='PageNumber'),
    pageSize?: long(name='PageSize'),
    totalCount?: long(name='TotalCount'),
  }(name='PagingInfo'),
  requestId?: string(name='RequestId'),
}

model ListComputeResourcesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListComputeResourcesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListComputeResources  ListComputeResourcesRequest
  * @return ListComputeResourcesResponse
 */
async function listComputeResources(request: ListComputeResourcesRequest): ListComputeResourcesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListComputeResources', 'POST', '/', 'json', false, 'json', request);
}

model ListCrawlerTypesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
}

model ListCrawlerTypesResponseBody = {
  crawlerTypes?: [
    CrawlerType
  ](name='CrawlerTypes', description='The list of metadata crawler types.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListCrawlerTypesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListCrawlerTypesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListCrawlerTypes  ListCrawlerTypesRequest
  * @return ListCrawlerTypesResponse
 */
async function listCrawlerTypes(request: ListCrawlerTypesRequest): ListCrawlerTypesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListCrawlerTypes', 'GET', '/', 'json', false, 'json', request);
}

model ListDIAlarmRulesRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIAlarmRuleId?: long(name='DIAlarmRuleId', description='The ID of the alert rule. If you leave this parameter empty, all alert rules of the task are queried.', example='34988', position='Query'),
  jobId?: long(name='JobId', description='The ID of the task for which alert rules are configured.', example='1000001', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
}

model ListDIAlarmRulesResponseBody = {
  pagingInfo?: {
    DIJobAlarmRules?: [ 
      {
        DIAlarmRuleId?: long(name='DIAlarmRuleId', description='This parameter is deprecated. Use the Id parameter instead.', example='72402', deprecated='true'),
        DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='32594'),
        description?: string(name='Description', description='The description of the alert rule.', example='rule descrition'),
        enabled?: boolean(name='Enabled', description='Indicates whether the alert rule is enabled. Valid values: True and False.', example='True'),
        id?: long(name='Id', description='The ID of the alert rule.', example='72402'),
        metricType?: string(name='MetricType', description='The metric type in the alert rule. Valid values:

*   Heartbeat
*   FailoverCount
*   Delay
*   DdlReport
*   ResourceUtilization', example='Heartbeat'),
        name?: string(name='Name', description='The name of the alert rule.', example='rule_name'),
        notificationSettings?: {
          inhibitionInterval?: long(name='InhibitionInterval', description='This parameter is deprecated and replaced by the MuteInterval parameter.', example='5', deprecated='true'),
          muteInterval?: long(name='MuteInterval', description='The duration of the alert suppression interval. Unit: minutes.', example='5'),
          notificationChannels?: [ 
            {
              channels?: [ string ](name='Channels', description='The alert notification methods.'),
              severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Critical'),
            }
          ](name='NotificationChannels', description='The alert notification methods.'),
          notificationReceivers?: [ 
            {
              receiverType?: string(name='ReceiverType', description='The recipient type. Valid values: AliyunUid, DingToken, FeishuToken, and WebHookUrl.', example='DingToken'),
              receiverValues?: [ string ](name='ReceiverValues', description='The recipient.

*   If the value of the ReceiverType parameter is AliyunUid, the value of this parameter is the Alibaba Cloud account ID of a user.
*   If the value of the ReceiverType parameter is DingToken, the value of this parameter is the token of a DingTalk chatbot.'),
            }
          ](name='NotificationReceivers', description='The settings of alert notification recipients.'),
        }(name='NotificationSettings', description='The alert notification method and recipient settings.'),
        triggerConditions?: [ 
          {
            ddlReportTags?: [ string ](name='DdlReportTags', description='This parameter is deprecated and replaced by the DdlTypes parameter.', deprecated='true'),
            ddlTypes?: [ string ](name='DdlTypes', description='The types of DDL operations for which the alert rule takes effect. This parameter is returned only if the MetricType parameter is set to DdlReport.'),
            duration?: long(name='Duration', description='The time interval for alert calculation. Unit: minutes.', example='1'),
            severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Critical'),
            threshold?: long(name='Threshold', description='The alert threshold.

*   If the alert rule is for task status, no threshold is used.
*   If the alert rule is for failovers, the threshold is the number of failovers.
*   If the alert rule is for latency, the threshold is the latency duration, in seconds.', example='5'),
          }
        ](name='TriggerConditions', description='The conditions that are used to trigger the alert rule.'),
      }
    ](name='DIJobAlarmRules', description='The alert rules.'),
    pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='90'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='74C2FECD-5B3A-554A-BCF5-351A36DE9815'),
}

model ListDIAlarmRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIAlarmRulesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDIAlarmRules  ListDIAlarmRulesRequest
  * @return ListDIAlarmRulesResponse
 */
async function listDIAlarmRules(request: ListDIAlarmRulesRequest): ListDIAlarmRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIAlarmRules', 'GET', '/', 'json', false, 'json', request);
}

model ListDIJobEventsRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='11588', position='Query'),
  endTime: long(name='EndTime', description='The end of the time range to query.

This parameter is required.', example='1717971005', position='Query'),
  eventType: string(name='EventType', description='The type of event that you want to query. Valid values: Failover, Alarm, and DDL.

This parameter is required.', example='Alarm', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  startTime: long(name='StartTime', description='The beginning of the time range to query.

This parameter is required.', example='1716971005', position='Query'),
}

model ListDIJobEventsResponseBody = {
  pagingInfo?: {
    DIJobEvent?: [ 
      {
        action?: string(name='Action', description='The processing result of the DDL event. Valid values: Critical, Ignore, Normal, and Warning.', example='Ignore'),
        channels?: string(name='Channels', description='The alert notification method. Valid values: Phone, Mail, Sms, Ding, and Webhook.', example='Phone'),
        createTime?: string(name='CreateTime', description='The time when the event was created.', example='1663573162'),
        detail?: string(name='Detail', description='The alert details.', example='aggregator:avg [**] for 5 minutes, service maybe abnormal'),
        dstSql?: string(name='DstSql', description='The DDL statement of the destination table.', example='alter table table2 ***'),
        dstTable?: string(name='DstTable', description='The name of the destination table.', example='table2'),
        failoverMessage?: string(name='FailoverMessage', description='The error logs for failovers.', example='2024-05-29 15:11:31,377 [main] INFO com.*.**.di.core.metrics.:21 []  {****} 
2024-05-29 15:11:31,384 [main] INFO *.aliyun.*.di.*.*.metrics.*:27 [] - Open MarioDiReporter 
2024-05-29 15:11:33,248 [flink-akka.*.*-dispatcher-17] INFO'),
        id?: string(name='Id', description='The event ID.', example='1'),
        severity?: string(name='Severity', description='The severity level of the alert. Valid values: Warning and Critical.', example='Warning'),
        srcSql?: string(name='SrcSql', description='The DDL statement of the source table.', example='alter table table1 ***'),
        srcTable?: string(name='SrcTable', description='The name of the source table.', example='table1'),
        status?: string(name='Status', description='The sending status of an alert notification. Valid values: Success, Fail, and Silence.', example='Success'),
        type?: string(name='Type', description='The type of the alert event.

*   Heartbeat
*   Delay
*   FailoverCount
*   DdlReport
*   ResourceUtilization', example='Delay'),
      }
    ](name='DIJobEvent', description='The events returned. The value of this parameter is an array.'),
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='2524'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='645F6D68-9C29-5961-80B1-BDD4B794C22D'),
}

model ListDIJobEventsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIJobEventsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDIJobEvents  ListDIJobEventsRequest
  * @return ListDIJobEventsResponse
 */
async function listDIJobEvents(request: ListDIJobEventsRequest): ListDIJobEventsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIJobEvents', 'GET', '/', 'json', false, 'json', request);
}

model ListDIJobMetricsRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='11265', position='Query'),
  endTime: long(name='EndTime', description='The end of the time range to query.

This parameter is required.', example='1712205941', position='Query'),
  metricName: [ string ](name='MetricName', description='The metrics that you want to query.

This parameter is required.', shrink='json', position='Query'),
  startTime: long(name='StartTime', description='The beginning of the time range to query.

This parameter is required.', example='1586509407', position='Query'),
}

model ListDIJobMetricsResponseBody = {
  pagingInfo?: {
    jobMetrics?: [ 
      {
        name?: string(name='Name', description='The name of the metric.', example='JobDelay'),
        seriesList?: [ 
          {
            time?: long(name='Time', description='The point in time at which data is sampled based on the metric.', example='1716881141'),
            value?: double(name='Value', description='The sample value.', example='10'),
          }
        ](name='SeriesList', description='The metric data.'),
      }
    ](name='JobMetrics', description='The metrics returned.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='691CA452-D37A-4ED0-9441'),
}

model ListDIJobMetricsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIJobMetricsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDIJobMetrics  ListDIJobMetricsRequest
  * @return ListDIJobMetricsResponse
 */
async function listDIJobMetrics(request: ListDIJobMetricsRequest): ListDIJobMetricsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIJobMetrics', 'GET', '/', 'json', false, 'json', request);
}

model ListDIJobRunDetailsRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId: long(name='DIJobId', description='The ID of the synchronization task.

This parameter is required.', example='11265', position='Query'),
  instanceId?: long(name='InstanceId', description='The instance ID.', example='1234', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  sourceDataSourceName?: string(name='SourceDataSourceName', description='The name of the source.', example='ds_name', position='Query'),
  sourceDatabaseName?: string(name='SourceDatabaseName', description='The name of the database in the source.', example='db_name', position='Query'),
  sourceSchemaName?: string(name='SourceSchemaName', description='The name of the schema of the source.', example='schema_name', position='Query'),
  sourceTableName?: string(name='SourceTableName', description='The name of the table in the source.', example='table_name', position='Query'),
}

model ListDIJobRunDetailsResponseBody = {
  pagingInfo?: {
    jobRunInfos?: [ 
      {
        destinationDatabaseName?: string(name='DestinationDatabaseName', description='The name of the database in the destination.', example='dst_db'),
        destinationDatasourceName?: string(name='DestinationDatasourceName', description='The name of the destination.', example='dst_name'),
        destinationSchemaName?: string(name='DestinationSchemaName', description='The name of the schema of the destination.', example='dst_schema'),
        destinationTableName?: string(name='DestinationTableName', description='The name of the table in the destination.', example='dst_name'),
        fullMigrationErrorMessage?: string(name='FullMigrationErrorMessage', description='The error message that is returned if an error occurs during full batch synchronization. If no error occurs, no value is returned for this parameter.', example='sync table t1 fail.'),
        fullMigrationStatus?: string(name='FullMigrationStatus', description='The status of full batch synchronization.', example='Finished'),
        offlineErrorRecords?: long(name='OfflineErrorRecords', description='The total number of errors that occur during full synchronization.', example='0'),
        offlineTotalBytes?: long(name='OfflineTotalBytes', description='The total number of bytes that are synchronized during full synchronization.', example='100'),
        offlineTotalRecords?: long(name='OfflineTotalRecords', description='The total number of data records that are synchronized during full synchronization.', example='10'),
        realtimeMigrationErrorMessage?: string(name='RealtimeMigrationErrorMessage', description='The error message that is returned if an error occurs during real-time synchronization. If no error occurs, no value is returned for this parameter.', example='sync table t1 fail.'),
        realtimeMigrationStatus?: string(name='RealtimeMigrationStatus', description='The status of real-time synchronization.', example='Running'),
        sourceDatabaseName?: string(name='SourceDatabaseName', description='The name of the database in the source.', example='db_name'),
        sourceDatasourceName?: string(name='SourceDatasourceName', description='The name of the source.', example='ds_name'),
        sourceSchemaName?: string(name='SourceSchemaName', description='The name of the schema of the source.', example='schema_name'),
        sourceTableName?: string(name='SourceTableName', description='The name of the table in the source.', example='table_name'),
        structureMigrationErrorMessage?: string(name='StructureMigrationErrorMessage', description='The error message that is returned if an error occurs during schema synchronization. If no error occurs, no value is returned for this parameter.', example='create table t1 fail.'),
        structureMigrationStatus?: string(name='StructureMigrationStatus', description='The synchronization status of the schema.', example='Finished'),
      }
    ](name='JobRunInfos', description='The running information about the synchronization task.'),
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='131'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='691CA452-D37A-4ED0-9441'),
}

model ListDIJobRunDetailsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIJobRunDetailsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDIJobRunDetails  ListDIJobRunDetailsRequest
  * @return ListDIJobRunDetailsResponse
 */
async function listDIJobRunDetails(request: ListDIJobRunDetailsRequest): ListDIJobRunDetailsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIJobRunDetails', 'GET', '/', 'json', false, 'json', request);
}

model ListDIJobsRequest {
  regionId?: string(name='RegionId', position='Host'),
  destinationDataSourceType?: string(name='DestinationDataSourceType', description='The destination type. Valid values: Hologres, OSS-HDFS, OSS, MaxCompute, Loghub, STARROCKS, Datahub, ANALYTICDB_FOR_MYSQL, Kafka, and Hive. If you do not configure this parameter, the API operation queries synchronization tasks that use all type of destinations.', example='Hologres', position='Query'),
  migrationType?: string(name='MigrationType', description='The synchronization type. Valid values:

*   FullAndRealtimeIncremental: one-time full synchronization and real-time incremental synchronization
*   RealtimeIncremental: real-time incremental synchronization
*   Full: full synchronization
*   OfflineIncremental: batch incremental synchronization
*   FullAndOfflineIncremental: one-time full synchronization and batch incremental synchronization', example='FullAndRealtimeIncremental', position='Query'),
  name?: string(name='Name', description='The name of the export task.

The name of each export task must be unique. You must make sure that the names of the export tasks in the current workspace are unique.', example='test_export_01', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='1967', position='Query'),
  sourceDataSourceType?: string(name='SourceDataSourceType', description='The source type. Valid values: PolarDB, MySQL, Kafka, Loghub, Hologres, Oracle, OceanBase, MongoDB, RedShift, Hive, SqlServer, Doris, and ClickHouse. If you do not configure this parameter, the API operation queries synchronization tasks that use all types of sources.', example='MySQL', position='Query'),
}

model ListDIJobsResponseBody = {
  pagingInfo?: {
    DIJobs?: [ 
      {
        DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='32599', deprecated='true'),
        destinationDataSourceType?: string(name='DestinationDataSourceType', description='The destination type. Valid values: Hologres, OSS-HDFS, OSS, MaxCompute, Loghub, STARROCKS, DataHub, ANALYTICDB_FOR_MYSQL, Kafka, and Hive.', example='Hologres'),
        id?: long(name='Id', description='The ID of the synchronization task.', example='32599'),
        jobName?: string(name='JobName', description='The name of the synchronization task.', example='mysql_to_holo_sync_35197'),
        jobStatus?: string(name='JobStatus', description='The status of the synchronization task. Valid values:

*   Finished
*   Initialized
*   Stopped
*   Failed
*   Running
*   Stopping', example='Running'),
        migrationType?: string(name='MigrationType', description='The synchronization type. Valid values:

*   FullAndRealtimeIncremental: one-time full synchronization and real-time incremental synchronization
*   RealtimeIncremental: real-time incremental synchronization
*   Full: full synchronization
*   OfflineIncremental: batch incremental synchronization
*   FullAndOfflineIncremental: one-time full synchronization and batch incremental synchronization', example='FullAndRealtimeIncremental'),
        projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace to which the synchronization task belongs.', example='26442'),
        sourceDataSourceType?: string(name='SourceDataSourceType', description='The source type. Valid values: PolarDB, MySQL, Kafka, Loghub, Hologres, Oracle, OceanBase, MongoDB, RedShift, Hive, SqlServer, Doris, and ClickHouse. If you do not configure this parameter, the API operation returns synchronization tasks that use all types of sources.', example='Mysql'),
      }
    ](name='DIJobs', description='The synchronization tasks returned.'),
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='12'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7263E4AC-9D2E-5B29-B8AF-7C5012E92A41'),
}

model ListDIJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIJobsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDIJobs  ListDIJobsRequest
  * @return ListDIJobsResponse
 */
async function listDIJobs(request: ListDIJobsRequest): ListDIJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIJobs', 'GET', '/', 'json', false, 'json', request);
}

model ListDataAssetTagsRequest {
  regionId?: string(name='RegionId', position='Host'),
  category?: string(name='Category', description='The type of the tag. Valid values:

*   Normal
*   System', example='Normal', position='Query'),
  key?: string(name='Key', description='The tag key.', example='key1', minLength=1, maxLength=128, position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', minimum=1, maximum=200, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
}

model ListDataAssetTagsResponseBody = {
  pagingInfo?: {
    dataAssetTags?: [ 
      {
        category?: string(name='Category', description='The type of the tag.

Valid values:

*   Normal
*   System', example='Normal'),
        createTime?: long(name='CreateTime', description='The time when the tag was created.', example='1735890003000'),
        createUser?: string(name='CreateUser', description='The creator of the tag.', example='12345'),
        description?: string(name='Description', description='The description of the tag.', example='This is a description'),
        key?: string(name='Key', description='The tag key.', example='key1'),
        managers?: [ string ](name='Managers', description='The tag administrators.'),
        modifyTime?: long(name='ModifyTime', description='The time when the tag was last modified.', example='1735890003000'),
        modifyUser?: string(name='ModifyUser', description='The user who last modified the tag.', example='1234'),
        valueType?: string(name='ValueType', description='The type of the tag value.', example='String'),
        values?: [ string ](name='Values', description='The tag values.'),
      }
    ](name='DataAssetTags', description='The tags.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='2524'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376****'),
}

model ListDataAssetTagsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataAssetTagsResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of ListDataAssetTags  ListDataAssetTagsRequest
  * @return ListDataAssetTagsResponse
 */
async function listDataAssetTags(request: ListDataAssetTagsRequest): ListDataAssetTagsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataAssetTags', 'GET', '/', 'json', false, 'json', request);
}

model ListDataAssetsRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataAssetIds?: [ string ](name='DataAssetIds', description='The data asset IDs.', shrink='json', position='Query'),
  dataAssetType?: string(name='DataAssetType', description='The type of the data asset. Valid values:

*   ACS::DataWorks::Table
*   ACS::DataWorks::Task', example='ACS::DataWorks::Task', position='Query'),
  envType?: string(name='EnvType', description='The environment of the workspace to which the data asset belongs. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', minimum=1, maximum=200, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10000', position='Query'),
  tags: [ 
    {
      key: string(name='Key', description='The tag key.

The tag key can be up to 64 characters in length and can contain letters, digits, and the following characters: `-@#*<>|[]()+=&%$!~`. It cannot start with `dw:`.

This parameter is required.', example='key'),
      value?: string(name='Value', description='The tag value.', example='value'),
    }
  ](name='Tags', description='The tags that are added to data assets. This parameter specifies a filter condition.

*   You can specify multiple tags, which are in the logical OR relation. For example, you can query the data assets that contain one of the following tags: `["key1:v1", "key2:v1", "key3:v1"]`.
*   If you do not configure this parameter, tag-based filtering is not performed.

This parameter is required.', shrink='json', position='Query'),
}

model ListDataAssetsResponseBody = {
  pagingInfo?: {
    dataAssets?: [ 
      {
        dataAssetTagMappings?: [ 
          {
            autoTraceEnabled?: boolean(name='AutoTraceEnabled', description='Indicates whether the lineage-based automatic backtrack feature is enabled for the mapping.', example='false'),
            creator?: string(name='Creator', description='The creator of the mapping between the data asset and the tag.', example='12345'),
            dataAssetId?: string(name='DataAssetId', description='The data asset ID.', example='7259557313'),
            key?: string(name='Key', description='The tag key.', example='key'),
            tagSource?: string(name='TagSource', description='The way in which the mapping between the data asset and the tag is created. Valid values:

*   System
*   UserDefined', example='UserDefined'),
            value?: string(name='Value', description='The tag value.', example='value'),
          }
        ](name='DataAssetTagMappings', description='The mappings between data assets and tags.'),
        envType?: string(name='EnvType', description='The environment of the workspace to which the data asset belongs. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod'),
        id?: string(name='Id', description='The data asset ID.', example='7259557313'),
        name?: string(name='Name', description='The name of the data asset.', example='ali_cn_es_gfn'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='54275'),
        type?: string(name='Type', description='The type of the data asset. Valid values:

*   ACS::DataWorks::Table
*   ACS::DataWorks::Task', example='ACS::DataWorks::Task'),
      }
    ](name='DataAssets', description='The data assets.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376'),
}

model ListDataAssetsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataAssetsResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of ListDataAssets  ListDataAssetsRequest
  * @return ListDataAssetsResponse
 */
async function listDataAssets(request: ListDataAssetsRequest): ListDataAssetsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataAssets', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityAlertRulesRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityScanId?: long(name='DataQualityScanId', description='The ID of the data quality monitor that the alert rule targets.', example='10001', position='Query'),
  pageNumber: int32(name='PageNumber', description='The page number of the results.

This parameter is required.', example='1', minimum=1, position='Query'),
  pageSize: int32(name='PageSize', description='The number of records to return on each page.

This parameter is required.', example='10', minimum=1, maximum=200, position='Query'),
  projectId: long(name='ProjectId', description='The project ID.

This parameter is required.', example='10001', position='Query'),
  sortBy?: string(name='SortBy', description='The list of sorting fields. Supports fields such as last modified time and creation time. Format: "SortField+SortOrder (Desc/Asc)", where Asc is the default. Valid values:

*   CreateTime (Desc/Asc)
*   Id (Desc/Asc)', example='CreateTime Desc', position='Query'),
}

model ListDataQualityAlertRulesResponseBody = {
  pageInfo?: {
    dataQualityAlertRules?: [ 
      {
        condition?: string(name='Condition', description='The alert conditions.', example='results.any { r -> r.status == \\"fail\\" && r.rule.severity == \\"High\\" }'),
        id?: long(name='Id', description='The ID of the data quality monitor alert rule.', example='26433'),
        notification?: {
          channels?: [ string ](name='Channels', description='In Channels, you can set both Email and Sms at the same time. In other cases, only one channel can be set.'),
          receivers?: [ 
            {
              extension?: string(name='Extension', description='Additional configurations required for the alert recipients. When ReceiverType is DingdingUrl, you can set `{"atAll":true}` to mention all members.', example='{"atAll":true}'),
              receiverType?: string(name='ReceiverType', description='The type of alert recipients.

*   ShiftSchedule
*   WebhookUrl
*   FeishuUrl
*   TaskOwner
*   WeixinUrl
*   DingdingUrl
*   DataQualityScanOwner
*   AliUid', example='AliUid'),
              receiverValues?: [ string ](name='ReceiverValues', description='The value of alert recipients.'),
            }
          ](name='Receivers', description='The alert recipients.'),
        }(name='Notification', description='Alert notification configurations.'),
        projectId?: long(name='ProjectId', description='The project ID.', example='59094'),
        target?: {
          ids?: [ long ](name='Ids', description='The list of monitored target IDs'),
          type?: string(name='Type', description='The type of the monitored target. Only DataQualityScan is supported.', example='DataQualityScan'),
        }(name='Target', description='Monitored targets of the data quality alert rule.'),
      }
    ](name='DataQualityAlertRules', description='The list of alert rule configurations.'),
    pageNumber?: int32(name='PageNumber', description='The current page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of records per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='335'),
  }(name='PageInfo', description='Alert rule configurations.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0bc14115***159376359'),
}

model ListDataQualityAlertRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityAlertRulesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityAlertRules  ListDataQualityAlertRulesRequest
  * @return ListDataQualityAlertRulesResponse
 */
async function listDataQualityAlertRules(request: ListDataQualityAlertRulesRequest): ListDataQualityAlertRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityAlertRules', 'POST', '/', 'json', false, 'json', request);
}

model ListDataQualityEvaluationTaskInstancesRequest {
  regionId?: string(name='RegionId', position='Host'),
  bizdateFrom?: string(name='BizdateFrom', description='The start time of the data quality monitoring task.', example='2024-04-01', position='Query'),
  bizdateTo?: string(name='BizdateTo', description='The end time of the data quality monitoring task.', example='2024-05-01', position='Query'),
  createTimeFrom?: long(name='CreateTimeFrom', description='The earliest start time at which the instances are generated.', example='1710239005403', position='Query'),
  createTimeTo?: long(name='CreateTimeTo', description='The latest start time at which the instances are generated.', example='1710239005403', position='Query'),
  dataQualityEvaluationTaskId?: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task.', example='10000', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', minimum=1, maximum=200, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100', position='Query'),
  tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test', position='Query'),
  triggerClient?: string(name='TriggerClient', description='The name of the trigger module of the instance.', example='CWF2', position='Query'),
  triggerClientId?: string(name='TriggerClientId', description='The ID of the instance that is generated by the task.', example='1001', position='Query'),
}

model ListDataQualityEvaluationTaskInstancesResponseBody = {
  pagingInfo?: {
    dataQualityEvaluationTaskInstances?: [ 
      {
        createTime?: long(name='CreateTime', description='The time at which the instance was generated.', example='1710239005403'),
        finishTime?: long(name='FinishTime', description='The time at which the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The ID of the instance.', example='10001'),
        parameters?: string(name='Parameters', description='The parameters configured for the instance.', example='{
  "bizdate": "20240517",
  "triggerTime": "1710239005403"
}'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100'),
        status?: string(name='Status', description='The status of the instance. Valid values:

*   Running
*   Error
*   Passed
*   Warned
*   Critical', example='Critical'),
        task?: {
          description?: string(name='Description', description='The description of the task.', example='This is a daily run data quality evaluation plan.'),
          hooks?: [ 
            {
              condition?: string(name='Condition', description='The trigger configuration of the callback event.', example='${severity} == "High" AND ${status} == "Critical"'),
              type?: string(name='Type', description='The type of the callback event. Valid values:

*   BlockTaskInstance. The value indicates that an auto triggered node is blocked.', example='BlockTaskInstance'),
            }
          ](name='Hooks', description='The callback configurations of the task during the instance lifecycle. Blocking an auto triggered node is a type of callback event. Only this type is supported.'),
          id?: long(name='Id', description='The task ID.', example='10001'),
          name: string(name='Name', description='The name of the monitor.

This parameter is required.', example='Quality verification task'),
          notifications?: {
            condition?: string(name='Condition', description='The trigger condition of the alert notification.', example='${severity} == "High"'),
            notifications?: [ 
              {
                nofiticationReceivers?: [ 
                  {
                    extension?: string(name='Extension', description='The extended information in the JSON format. For example, the DingTalk chatbot can remind all members in a DingTalk group by using the at sign (@).', example='{"atAll":"true"}'),
                    receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid values:

*   AliUid: Alibaba Cloud account ID
*   WebhookUrl: URL of a custom webhook
*   DingdingUrl: DingTalk chatbot URL
*   FeishuUrl: Lark chatbot URL
*   WeixinUrl: WeCom chatbot URL', example='AliUid'),
                    receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
                  }
                ](name='NofiticationReceivers', description='The alert recipients.'),
                notificationChannels?: [ 
                  {
                    channels?: [ string ](name='Channels', description='The alert notification methods.'),
                  }
                ](name='NotificationChannels', description='The alert notification methods.'),
              }
            ](name='Notifications', description='The configurations for the alert notification.'),
          }(name='Notifications', description='The configurations for alert notifications.'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          runtimeConf?: string(name='RuntimeConf', description='The configuration of the data source. The value of the queue field is default, and that of the sqlEngine field can be set to SPARK_SQL, KYUUBI, PRESTO_SQL, or HIVE_SQL. The value default indicates the YARN queue for E-MapReduce (EMR) tasks.', example='{ "queue": "default", "sqlEngine": "SPARK-SQL" }'),
          target?: {
            databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='maxcompute'),
            partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='ds=$[yyyymmdd-1]'),
            tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test'),
            type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
          }(name='Target', description='The monitored object of the task.'),
          trigger?: {
            taskIds?: [ long ](name='TaskIds', description='The IDs of the auto triggered nodes of which the instances are successfully run.'),
            type?: string(name='Type', description='The trigger condition of the task. Valid values:

*   ByScheduledTaskInstance. The value indicates that the task is triggered when the instance of an auto triggered node is successfully run.', example='ByScheduledTaskInstance'),
          }(name='Trigger', description='The trigger configuration of the task.'),
        }(name='Task', description='The snapshot of the configurations for the task when the task starts.'),
        triggerContext?: string(name='TriggerContext', description='The information about the trigger module of the instance.', example='{
  "TriggerClientId": 10001,
  "TriggerClient": "CWF2"
}'),
      }
    ](name='DataQualityEvaluationTaskInstances', description='The instances generated by the task.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='294'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityEvaluationTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityEvaluationTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityEvaluationTaskInstances  ListDataQualityEvaluationTaskInstancesRequest
  * @return ListDataQualityEvaluationTaskInstancesResponse
 */
async function listDataQualityEvaluationTaskInstances(request: ListDataQualityEvaluationTaskInstancesRequest): ListDataQualityEvaluationTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityEvaluationTaskInstances', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityEvaluationTasksRequest {
  regionId?: string(name='RegionId', position='Host'),
  name?: string(name='Name', description='The name of the data quality monitoring task. Fuzzy match is supported.', example='Test', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', minimum=1, maximum=200, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100', position='Query'),
  tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test', position='Query'),
}

model ListDataQualityEvaluationTasksResponseBody = {
  pagingInfo?: {
    dataQualityEvaluationTasks?: [ 
      {
        dataSourceId?: long(name='DataSourceId'),
        description?: string(name='Description', description='The description of the data quality monitoring task. The description can be up to 65,535 characters in length.', example='This is a daily run data quality evaluation plan'),
        hooks?: [ 
          {
            condition?: string(name='Condition', description='The trigger configuration of the callback event.', example='${severity} == "High" AND ${status} == "Critical"'),
            type?: string(name='Type', description='The type of the callback event. Valid values:

*   BlockTaskInstance. The value indicates that an auto triggered node is blocked.', example='BlockTaskInstance'),
          }
        ](name='Hooks', description='The callback configurations of the task during the instance lifecycle. Blocking an auto triggered node is a type of callback event. Only this type is supported.'),
        id?: long(name='Id', description='The ID of the data quality monitoring task.', example='10001'),
        name?: string(name='Name', description='The name of the data quality monitoring task. The name can be up to 255 characters in length and can contain digits, letters, and punctuation marks.', example='Data quality verification task'),
        notifications?: {
          condition?: string(name='Condition', description='The trigger condition of the alert notification.', example='${severity} == "High"'),
          notifications?: [ 
            {
              notificationChannels?: [ 
                {
                  channels?: [ string ](name='Channels', description='The alert notification methods.'),
                }
              ](name='NotificationChannels', description='The alert notification methods.'),
              notificationReceivers?: [ 
                {
                  extension?: string(name='Extension', description='The extended information in the JSON format. For example, the DingTalk chatbot can remind all members in a DingTalk group by using the at sign (@).', example='{"atAll":"true"}'),
                  receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid values:

*   AliUid: Alibaba Cloud account ID
*   WebhookUrl: URL of a custom webhook
*   DingdingUrl: DingTalk chatbot URL
*   FeishuUrl: Lark chatbot URL
*   WeixinUrl: WeCom chatbot URL', example='AliUid'),
                  receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
                }
              ](name='NotificationReceivers', description='The alert recipients.'),
            }
          ](name='Notifications', description='The configurations for the alert notification.'),
        }(name='Notifications', description='The configurations for alert notifications.'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100'),
        runtimeConf?: string(name='RuntimeConf', description='The configuration of the data source. The value of the queue field is default, and that of the sqlEngine field can be set to SPARK_SQL, KYUUBI, PRESTO_SQL, or HIVE_SQL. The value default indicates the YARN queue for E-MapReduce (EMR) tasks.', example='{ "queue": "default", "sqlEngine": "SPARK-SQL" }'),
        target?: {
          databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='maxcompute'),
          partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='ds=$[yyyymmdd-1]'),
          tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test'),
          type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
        }(name='Target', description='The monitored object of the task.'),
        trigger?: {
          taskIds?: [ long ](name='TaskIds', description='The IDs of the auto triggered nodes of which the instances are successfully run. This parameter takes effect only if the Type parameter is set to ByScheduledTaskInstance.'),
          type?: string(name='Type', description='The trigger condition of the task. Valid values:

*   ByScheduledTaskInstance. The value indicates that the task is triggered when the instance of an auto triggered node is successfully run.', example='ByScheduledTaskInstance'),
        }(name='Trigger', description='The trigger configuration of the task.'),
      }
    ](name='DataQualityEvaluationTasks', description='The data quality monitoring tasks.'),
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='131'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityEvaluationTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityEvaluationTasksResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityEvaluationTasks  ListDataQualityEvaluationTasksRequest
  * @return ListDataQualityEvaluationTasksResponse
 */
async function listDataQualityEvaluationTasks(request: ListDataQualityEvaluationTasksRequest): ListDataQualityEvaluationTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityEvaluationTasks', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityResultsRequest {
  regionId?: string(name='RegionId', position='Host'),
  bizdateFrom?: string(name='BizdateFrom', description='The beginning of the time range to query.', example='2024-05-01', position='Query'),
  bizdateTo?: string(name='BizdateTo', description='The end of the time range to query.', example='2024-05-04', position='Query'),
  createTimeFrom?: long(name='CreateTimeFrom', description='The earliest time when the data quality check result was generated.', example='1710239005403', position='Query'),
  createTimeTo?: long(name='CreateTimeTo', description='The latest time when the data quality check result was generated.', example='1710239005403', position='Query'),
  dataQualityEvaluationTaskId?: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task.', example='200001', position='Query'),
  dataQualityEvaluationTaskInstanceId?: long(name='DataQualityEvaluationTaskInstanceId', description='The ID of the instance generated by the check.', example='10001', position='Query'),
  dataQualityRuleId?: long(name='DataQualityRuleId', description='The ID of the data quality monitoring rule.', example='100001', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', minimum=1, maximum=200, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100', position='Query'),
}

model ListDataQualityResultsResponseBody = {
  pagingInfo?: {
    dataQualityResults?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the data quality check result was generated.', example='1708284916414'),
        details?: [ 
          {
            checkedValue?: string(name='CheckedValue', description='The value that is used for comparison with the threshold.', example='100.0'),
            referencedValue?: string(name='ReferencedValue', description='The value that is calculated based on sample data. The value serves as a baseline value during the calculation of the value of the CheckedValue parameter.', example='0.0'),
            status?: string(name='Status', description='The comparison result between the value of CheckedValue and the threshold. Valid values:

*   Error
*   Passed
*   Warned
*   Critical', example='PASSED'),
          }
        ](name='Details', description='The information about the data quality check.'),
        id?: long(name='Id', description='The ID of the check result.', example='16033'),
        rule?: {
          checkingConfig?: {
            referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference samples and perform aggregate operations on the reference values. In this example, an expression is used to indicate the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
            thresholds?: {
              critical?: {
                expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
                operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
                value?: string(name='Value', description='The threshold value.', example='100.0'),
              }(name='Critical', description='The threshold settings for critical alerts.'),
              expected?: {
                expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
                operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
                value?: string(name='Value', description='The threshold value.', example='100.0'),
              }(name='Expected', description='The expected threshold setting.'),
              warned?: {
                expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
                operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
                value?: string(name='Value', description='The threshold value.', example='100.0'),
              }(name='Warned', description='The threshold settings for normal alerts.'),
            }(name='Thresholds', description='The threshold settings.'),
            type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='FIXED'),
          }(name='CheckingConfig', description='The check settings for sample data.'),
          description?: string(name='Description', description='The description of the rule. The description can be up to 500 characters in length.', example='this is a odps _sql task'),
          enabled?: boolean(name='Enabled', description='Indicates whether the rule is enabled.', example='true'),
          errorHandlers?: [ 
            {
              errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If the rule is defined by custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
              type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SAVE_ERROR_DATA'),
            }
          ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
          id?: long(name='Id', description='The rule ID.', example='100001'),
          name?: string(name='Name', description='The name of the rule. The name can be up to 255 characters in length and can contain digits, letters, and punctuation marks.', example='The table cannot be empty.'),
          projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100'),
          samplingConfig?: {
            metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='COUNT'),
            metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "columns": [ "id", "name" ] }'),
            samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='id IS NULL'),
            settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s;'),
          }(name='SamplingConfig', description='The sampling settings.'),
          severity?: string(name='Severity', description='The strength of the rule. Valid values:

*   High
*   Normal', example='NORMAL'),
          target?: {
            databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='MAX_COMPUTE'),
            tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test'),
            type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='TABLE'),
          }(name='Target', description='The monitored object of the rule.'),
          templateCode?: string(name='TemplateCode', description='The code of the template that is referenced when you create a rule.', example='system::user_defined'),
        }(name='Rule', description='The snapshot of the rule configuration when the check starts.'),
        sample?: string(name='Sample', description='The sample values used for the check.', example='[
  {
    "gender": "male",
    "_count": 100
  }, {
    "gender": "female",
    "_count": 100
  }
]'),
        status?: string(name='Status', description='The status of the check result. Valid values:

*   Running
*   Error
*   Passed
*   Warned
*   Critical', example='PASSED'),
        taskInstanceId?: long(name='TaskInstanceId', description='The ID of the instance generated by the check.', example='200001'),
      }
    ](name='DataQualityResults', description='The data quality check results.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='219'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityResultsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityResultsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityResults  ListDataQualityResultsRequest
  * @return ListDataQualityResultsResponse
 */
async function listDataQualityResults(request: ListDataQualityResultsRequest): ListDataQualityResultsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityResults', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityRuleTemplatesRequest {
  regionId?: string(name='RegionId', position='Host'),
  creationSource?: string(name='CreationSource', description='The source of the template. This parameter is required. Valid values:

*   System
*   UserDefined', example='System', position='Query'),
  directoryPath?: string(name='DirectoryPath', description='The directory in which the template is stored. Slashes (/) are used to separate directory levels. The name of each directory level can be up to 1,024 characters in length. It cannot contain whitespace characters or slashes (/).', example='/ods/order_data', position='Query'),
  name?: string(name='Name', description='The name of the template. If you want to query a system template, set this parameter to the name of the system template. Fuzzy match is supported.', example='Table rows', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The number of entries per page. Default value: 10.', example='10', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The page number. Default value: 1.', example='1', minimum=1, maximum=200, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='10000', position='Query'),
}

model ListDataQualityRuleTemplatesResponseBody = {
  pagingInfo?: {
    dataQualityRuleTemplates?: [ 
      {
        checkingConfig?: {
          referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='Some types of thresholds need to query some reference samples, and then summarize the values of the reference samples to obtain the threshold for comparison. Here, an expression is used to represent the query method of the reference samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
          type?: string(name='Type', description='Threshold Calculation method
- Fixed
- Fluctation
- FluctationDiscreate
- Auto
- Average
- Variance', example='Fixed'),
        }(name='CheckingConfig', description='Sample verification settings'),
        code?: string(name='Code', description='Rule template Code', example='USER_DEFINED:123'),
        directoryPath?: string(name='DirectoryPath', description='The directory in which the template is stored. Slashes (/) are used to separate directory levels. The name of each directory level can be up to 1,024 characters in length. It cannot contain whitespace characters or slashes (/).', example='/ods/order_data'),
        name?: string(name='Name', description='The name of the template. The name can be up to 512 characters in length and can contain digits, letters, and punctuation marks.', example='Table row Count Verification'),
        projectId?: long(name='ProjectId', description='DataWorks workspace ID', example='2043'),
        samplingConfig?: {
          metric?: string(name='Metric', description='The name of the sampled metric.
- Count: number of table rows
- Min: minimum value of the field
- Max: The maximum value of the field.
- Avg: field mean
- DistinctCount: number of unique field values
- DistinctPercent: the ratio of the number of unique field values to the number of data rows.
- DuplicatedCount: number of duplicate field values
- DuplicatedPercent: the ratio of the number of duplicate field values to the number of data rows.
- TableSize: table size
- NullValueCount: number of rows with empty fields
- NullValuePercent: the proportion of fields that are empty.
- GroupCount: aggregate each value by field value and the corresponding number of data rows
- CountNotIn: the enumerated value does not match the number of rows.
- CountDistinctNotIn: the number of unique values that the enumerated values do not match.
- UserDefinedSql: use custom SQL to collect samples', example='Max'),
          metricParameters?: string(name='MetricParameters', description='Parameters required for sample collection', example='{"Sql": "select count(1) from table;"}'),
          settingConfig?: string(name='SettingConfig', description='Before executing the sample statement, insert some runtime parameter setting statements, which can be up to 1000 characters in length. Currently, only MaxCompute are supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;'),
        }(name='SamplingConfig', description='Settings required for sample collection'),
        visibleScope?: string(name='VisibleScope', description='Available range of templates:
- Tenant: all tenants are available
- Project: only available in the current Project', example='Project'),
      }
    ](name='DataQualityRuleTemplates', description='The templates.'),
    pageNumber?: int32(name='PageNumber', description='Page number', example='1'),
    pageSize?: int32(name='PageSize', description='Page size', example='10'),
    totalCount?: int32(name='TotalCount', description='Total number of entries', example='42'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityRuleTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityRuleTemplatesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDataQualityRuleTemplates  ListDataQualityRuleTemplatesRequest
  * @return ListDataQualityRuleTemplatesResponse
 */
async function listDataQualityRuleTemplates(request: ListDataQualityRuleTemplatesRequest): ListDataQualityRuleTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityRuleTemplates', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityRulesRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityEvaluationTaskId?: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task that is associated with the rule.', example='10000', position='Query'),
  name?: string(name='Name', description='The name of the rule. Fuzzy match is supported.', example='unit_test', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 200.', example='10', minimum=1, maximum=200, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10002', position='Query'),
  tableGuid?: string(name='TableGuid', description='The ID of the table that is limited by the rule in Data Map.', example='odps.unit_test.tb_unit_test', position='Query'),
}

model ListDataQualityRulesResponseBody = {
  pagingInfo?: {
    dataQualityRules?: [ 
      {
        checkingConfig?: {
          referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference values. In this example, an expression is used to indicate the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
          thresholds?: {
            critical?: {
              expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
              operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
              value?: string(name='Value', description='The threshold value.', example='100.0'),
            }(name='Critical', description='The threshold settings for critical alerts.'),
            expected?: {
              expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
              operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
              value?: string(name='Value', description='The threshold value.', example='100.0'),
            }(name='Expected', description='The expected threshold setting.'),
            warned?: {
              expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
              operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
              value?: string(name='Value', description='The threshold value.', example='100.0'),
            }(name='Warned', description='The threshold settings for normal alerts.'),
          }(name='Thresholds', description='The threshold settings.'),
          type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
        }(name='CheckingConfig', description='The check settings for sample data.'),
        description?: string(name='Description', description='The description of the rule. The description can be up to 500 characters in length.', example='this is a odps _sql task'),
        enabled?: boolean(name='Enabled', description='Indicates whether the rule is enabled.', example='true'),
        errorHandlers?: [ 
          {
            errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If the rule is defined by custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
            type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
          }
        ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
        id?: long(name='Id', description='The rule ID.', example='22130'),
        name?: string(name='Name', description='The rule name.', example='The table cannot be empty.'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100001'),
        samplingConfig?: {
          metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the percentage of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values in the field.
*   DuplicatedPercent: the percentage of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field is set to null.
*   NullValuePercent: the percentage of the number of rows in which the field is set to null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that the data is sampled by executing custom SQL statements.', example='Max'),
          metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
          samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='id IS NULL'),
          settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;'),
        }(name='SamplingConfig', description='The settings for sampling.'),
        severity?: string(name='Severity', description='The strength of the rule. Valid values:

*   Normal
*   High', example='High'),
        target?: {
          databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='maxcompute'),
          tableGuid?: string(name='TableGuid', description='The ID of the table that is limited by the rule in Data Map.', example='odps.unit_test.tb_unit_test'),
          type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
        }(name='Target', description='The monitored object of the rule.'),
        templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='system::user_defined'),
      }
    ](name='DataQualityRules', description='The rules.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='294'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityRulesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityRules  ListDataQualityRulesRequest
  * @return ListDataQualityRulesResponse
 */
async function listDataQualityRules(request: ListDataQualityRulesRequest): ListDataQualityRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityRules', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityScanRunsRequest {
  regionId?: string(name='RegionId', position='Host'),
  createTimeFrom?: long(name='CreateTimeFrom', description='The earliest time when the data quality monitor starts to run.', example='1710239005403', position='Query'),
  createTimeTo?: long(name='CreateTimeTo', description='The latest time when the data quality monitor starts to run.', example='1710239005403', position='Query'),
  dataQualityScanId?: long(name='DataQualityScanId', description='The ID of the data quality monitor.', example='10001', position='Query'),
  filter?: map[string]any(name='Filter', shrink='json', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number of the results. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of records per page. Default value: 10.', example='20', position='Query'),
  projectId: long(name='ProjectId', description='The project ID.

This parameter is required.', example='12345', position='Query'),
  sortBy?: string(name='SortBy', description='The list of sorting fields. Supports fields such as last modified time and creation time. Format: "SortField+SortOrder (Desc/Asc)", where Asc is the default. Valid values:

*   CreateTime (Desc/Asc)
*   Id (Desc/Asc)', example='CreateTime Desc', position='Query'),
  status?: string(name='Status', description='The status of the data quality check result.

*   Pass
*   Running
*   Error
*   Fail
*   Warn', example='Fail', position='Query'),
}

model ListDataQualityScanRunsResponseBody = {
  pageInfo?: {
    dataQualityScanRuns?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the data quality monitor starts running.', example='1710239005403'),
        finishTime?: long(name='FinishTime', description='The time when the data quality monitor stops.', example='1710239005403'),
        id?: long(name='Id', description='The ID of the data quality monitor running record.', example='3155'),
        parameters?: [ 
          {
            name?: string(name='Name', description='The parameter name.', example='dt'),
            value?: string(name='Value', description='The parameter value. You can use a scheduling time expression.', example='$[yyyy-mm-dd-1]'),
          }
        ](name='Parameters', description='The parameters configured for the instance.'),
        status?: string(name='Status', description='The status of the instance.

*   Pass
*   Running
*   Error
*   Warn
*   Fail', example='Fail'),
      }
    ](name='DataQualityScanRuns', description='The list of data quality monitor run records.'),
    pageNumber?: int32(name='PageNumber', description='The page number of the results. Default value: 1.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of records per page. Default value: 10.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of records returned.', example='324'),
  }(name='PageInfo', description='The page information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0bc14115***159376359'),
}

model ListDataQualityScanRunsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityScanRunsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityScanRuns  ListDataQualityScanRunsRequest
  * @return ListDataQualityScanRunsResponse
 */
async function listDataQualityScanRuns(request: ListDataQualityScanRunsRequest): ListDataQualityScanRunsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityScanRuns', 'POST', '/', 'json', false, 'json', request);
}

model ListDataQualityScansRequest {
  regionId?: string(name='RegionId', position='Host'),
  name?: string(name='Name', description='The data quality scan task name for fuzzy match.', example='test', position='Query'),
  pageNumber: int32(name='PageNumber', description='The page number. Default value: 1.

This parameter is required.', example='1', minimum=1, maximum=200, position='Query'),
  pageSize: int32(name='PageSize', description='The number of entries per page. Default value: 10.

This parameter is required.', example='10', position='Query'),
  projectId: long(name='ProjectId', description='The project ID.

This parameter is required.', example='10000', position='Query'),
  sortBy?: string(name='SortBy', description='The list of sorting fields. Supports fields such as last modified time and creation time. Format: "SortField+SortOrder (Desc/Asc)", where Asc is the default. Valid values:

*   ModifyTime (Desc/Asc)
*   CreateTime (Desc/Asc)
*   Id (Desc/Asc)', example='ModifyTime Desc', position='Query'),
  table?: string(name='Table', description='Fuzzy match for the monitored table name.', example='video_album', position='Query'),
}

model ListDataQualityScansResponseBody = {
  pageInfo?: {
    dataQualityScans?: [ 
      {
        computeResource?: {
          envType?: string(name='EnvType', description='Workspace environment of the compute engine. Valid values:

*   Prod
*   Dev', example='Prod'),
          name?: string(name='Name', description='The name of the computing engine. Uniquely identifies the engine.', example='emr_cluster_001'),
          runtime?: {
            engine?: string(name='Engine', description='The engine type. These settings are only supported for the EMR compute engine. Valid values:

*   Hive: Hive SQL
*   Spark: Spark SQL
*   Kyuubi', example='Hive'),
            hiveConf?: string(name='HiveConf', description='Additional parameters for the Hive engine. Currently, only mapreduce.job.queuename is supported to set the queue.', example='mapreduce.job.queuename=dq_queue'),
            sparkConf?: string(name='SparkConf', description='Additional parameters for the Spark engine. Currently, only spark.yarn.queue is supported to set the queue.', example='spark.yarn.queue=dq_queue'),
          }(name='Runtime', description='Additional runtime settings for the data quality monitor.'),
        }(name='ComputeResource', description='The compute engine used during execution. If it is not specified, the data source connection defined in the Spec will be used.'),
        createTime?: long(name='CreateTime', description='The creation time of the data quality monitor.', example='1694512304000'),
        createUser?: string(name='CreateUser', description='The creator of the data quality monitor.', example='7892346529452'),
        description?: string(name='Description', description='The description of the data quality scan task. Maximum length: 65,535 characters.', example='This is a hourly run data quality evaluation plan.'),
        hooks?: [ 
          {
            condition?: string(name='Condition', description='The hook trigger condition. When this condition is met, the hook is triggered. Valid expression format:

Specifies multiple combinations of rule severity levels and rule validation statuses, such as `results.any { r -> r.status == \\"Fail\\" && r.rule.severity == \\"Normal\\" || r.status == \\"Error\\" && r.rule.severity == \\"High\\" || r.status == \\"Warn\\" && r.rule.severity == \\"High\\" }`. This means the hook is triggered if any executed rule has Fail with Normal severity, Error with High severity, or Warn with High severity. The severity values must match those defined in the Spec. The status values must match those in DataQualityResult.', example='results.any { r -> r.status == \\"Fail\\" && r.rule.severity == \\"Normal\\" || r.status == \\"Error\\" && r.rule.severity == \\"High\\" || r.status == \\"Warn\\" && r.rule.severity == \\"High\\" }'),
            type?: string(name='Type', description='The type of the hook. Valid values:

*   BlockTaskInstance: Blocks the scheduling of the task instance.', example='BlockTaskInstance'),
          }
        ](name='Hooks', description='The hook configuration after the data quality monitor stops.'),
        id?: long(name='Id', description='The ID of the data quality monitor.', example='26433'),
        modifyTime?: long(name='ModifyTime', description='Last update time of the data quality monitor.', example='17236236472'),
        modifyUser?: string(name='ModifyUser', description='The user ID of the last person who updated the data quality monitor.', example='23782382795249'),
        name?: string(name='Name', description='The name of the data quality scan task. Can include digits, letters, Chinese characters, and both half-width and full-width punctuation marks. Maximum length: 255 characters.', example='Hourly partition quality monitoring'),
        owner?: string(name='Owner', description='The user ID of the owner responsible for the data quality monitor.', example='23782382795249'),
        parameters?: [ 
          {
            name?: string(name='Name', description='The parameter name.', example='dt'),
            value?: string(name='Value', description='The parameter value.', example='$[yyyy-mm-dd-1]'),
          }
        ](name='Parameters', description='Execution parameter definitions for the data quality monitor.'),
        projectId?: long(name='ProjectId', description='The project ID.', example='59094'),
        runtimeResource?: {
          cu?: float(name='Cu', description='CU consumption for task running.', example='0.25'),
          id?: string(name='Id', description='The ID of the resource group.', example='Serverless_resource_group_xxxxx'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxx'),
        }(name='RuntimeResource', description='The resource group used during the execution of the data quality monitor.'),
        trigger?: {
          taskIds?: [ long ](name='TaskIds', description='If the trigger mode is BySchedule, the ID of the scheduling task that triggers the monitor must be configured.'),
          type?: string(name='Type', description='The trigger mode of the data quality monitor. Valid values:

*   ByManual: Manually triggered. Default setting.
*   BySchedule: Triggered by a scheduled task instance.', example='BySchedule'),
        }(name='Trigger', description='Trigger settings for the data quality monitor.'),
      }
    ](name='DataQualityScans', description='The list of data quality monitors.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of records per page. Default value: 10.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of records returned.', example='1'),
  }(name='PageInfo', description='The page information.'),
  requestId?: string(name='RequestId', description='The API request ID, which is generated as a UUID.', example='0bc14115***159376359'),
}

model ListDataQualityScansResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityScansResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityScans  ListDataQualityScansRequest
  * @return ListDataQualityScansResponse
 */
async function listDataQualityScans(request: ListDataQualityScansRequest): ListDataQualityScansResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityScans', 'POST', '/', 'json', false, 'json', request);
}

model ListDataQualityTemplatesRequest {
  regionId?: string(name='RegionId', position='Host'),
  catalog?: string(name='Catalog', description='The directory path to which the data quality template belongs.', example='/timeliness/ods_layer', position='Query'),
  name?: string(name='Name', description='Fuzzy match for the template rule name.', example='table_rows', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The number of records per page. Default value: 10.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The page number of the results. Default value: 1.', example='10', position='Query'),
  projectId?: long(name='ProjectId', description='The project ID.', example='10000', position='Query'),
}

model ListDataQualityTemplatesResponseBody = {
  pageInfo?: {
    dataQualityTemplates?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the data quality rule template was created.', example='1729816478147'),
        createUser?: string(name='CreateUser', description='The creator of the data quality rule template.', example='7892346529452'),
        id?: string(name='Id', description='The ID of the data quality rule template.', example='819cf1f8-29be-4f94-a9d0-c5c06c0c3d2a'),
        modifyTime?: long(name='ModifyTime', description='The time when the data quality rule template was updated.', example='1729816478147'),
        modifyUser?: string(name='ModifyUser', description='The last updater of the data quality rule template.', example='205250754596036836'),
        owner?: string(name='Owner', description='The owner of the data quality rule template.', example='205250754596036836'),
        projectId?: long(name='ProjectId', description='The project ID.', example='7635'),
        spec?: string(name='Spec', description='Specific configurations of the data quality rule template. For more information, see [Data quality Spec configuration description](~2963394~).', example='{
    "assertion": "anomaly detection fro id_not_null_cnt",
    "id_not_null_cnt": {
        "query": "SELECT COUNT(*) AS cnt FROM ${tableName} WHERE dt = \\"$[yyyymmdd-1]\\";"
    },
    "identity": "819cf1f8-29be-4f94-a9d0-c5c06c0c3d2a"
}'),
      }
    ](name='DataQualityTemplates', description='The list of rule templates.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of pages.', example='20'),
    totalCount?: int32(name='TotalCount', description='The total number of records.', example='10'),
  }(name='PageInfo', description='Paged query results of data quality rule templates.'),
  requestId?: string(name='RequestId', description='The API request ID, which is generated as a UUID.', example='0bc14115***159376359'),
}

model ListDataQualityTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityTemplatesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityTemplates  ListDataQualityTemplatesRequest
  * @return ListDataQualityTemplatesResponse
 */
async function listDataQualityTemplates(request: ListDataQualityTemplatesRequest): ListDataQualityTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityTemplates', 'POST', '/', 'json', false, 'json', request);
}

model ListDataSourceSharedRulesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dataSourceId: long(name='DataSourceId', description='The data source ID.

This parameter is required.', example='1', position='Query'),
  targetProjectId?: long(name='TargetProjectId', description='The ID of the workspace to which the data source is shared. You cannot share the data source to the workspace with which the data source is associated.', example='1', position='Query'),
}

model ListDataSourceSharedRulesResponseBody = {
  dataSourceSharedRules?: [ 
    {
      createTime?: long(name='CreateTime', description='The time when the rule was created. This value is a UNIX timestamp.', example='1724379762000'),
      createUser?: string(name='CreateUser', description='The ID of the user who creates the rule.', example='1'),
      dataSourceId?: long(name='DataSourceId', description='The data source ID. You can call the [ListDataSources](https://help.aliyun.com/document_detail/211431.html) operation to query the ID.', example='1'),
      envType?: string(name='EnvType', description='The environment to which the target data source belongs. The values are as follows:
- Dev: the development environment.
- Prod: the production environment.', example='Dev'),
      id?: long(name='Id', description='The rule ID.', example='1'),
      sharedDataSourceName?: string(name='SharedDataSourceName', description='The name of the data source in the destination workspace.', example='targetProject.datasource'),
      sharedUser?: string(name='SharedUser', description='The user in the workspace to which the data source is shared. If the data source is shared to the entire workspace, this parameter is left empty.', example='1'),
      sourceProjectId?: long(name='SourceProjectId', description='The ID of the workspace with which the data source is associated.', example='1'),
      targetProjectId?: long(name='TargetProjectId', description='The ID of the workspace to which the data source is shared.', example='1'),
    }
  ](name='DataSourceSharedRules', description='The sharing rules of the data source.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
}

model ListDataSourceSharedRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataSourceSharedRulesResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  If you want to query the sharing rules of a data source that is associated with Workspace A, you must have the permissions to share the data source in Workspace A. You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Tenant Administrator, Workspace Administrator, and Workspace Owner
  * @param request  the request parameters of ListDataSourceSharedRules  ListDataSourceSharedRulesRequest
  * @return ListDataSourceSharedRulesResponse
 */
async function listDataSourceSharedRules(request: ListDataSourceSharedRulesRequest): ListDataSourceSharedRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataSourceSharedRules', 'GET', '/', 'json', false, 'json', request);
}

model ListDataSourcesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  envType?: string(name='EnvType', description='The environment in which the data sources are used. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod', position='Query'),
  name?: string(name='Name', description='The name of the data source. Fuzzy match by data source name is supported.', example='test', position='Query'),
  order?: string(name='Order', description='The order in which you want to sort the data sources. Valid values:

*   Desc: descending order
*   Asc: ascending order

Default value: Desc', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='17820', position='Query'),
  sortBy?: string(name='SortBy', description='The field that you want to use to sort the data sources. Valid values:

*   CreateTime
*   Id
*   Name

Default value: CreateTime', example='Id', position='Query'),
  tags?: string(name='Tags', description='The tag of the data source. This parameter specifies a filter condition.

*   You can specify multiple tags, which are in the logical AND relation. For example, you can query the data sources that contain the following tags: `["tag1", "tag2", "tag3"]`.
*   If you do not configure this parameter, tag-based filtering is not performed. You can specify up to 10 tags.', example='["tag1", "tag2", "tag3"]', position='Query'),
  types?: [ string ](name='Types', description='The data source types. This parameter specifies a filter condition. You can specify multiple data source types.', shrink='simple', position='Query'),
}

model ListDataSourcesResponseBody = {
  pagingInfo?: {
    dataSources?: [ 
      {
        dataSource?: [ 
          {
            connectionProperties?: any(name='ConnectionProperties', description='The connection configurations of the data source, including the connection address, access identity, and environment information. The envType parameter specifies the environment in which the data source is used. Valid values of the envType parameter:

*   Dev: development environment
*   Prod: production environment

The parameters that you need to configure for the data source vary based on the mode in which the data source is added. For more information, see [Data source connection information (ConnectionProperties)](https://help.aliyun.com/document_detail/2852465.html).', example='{
	"envType": "Prod",
	"regionId": "cn-beijing",
    "instanceId": "hgprecn-cn-x0r3oun4k001",
    "database": "testdb",
    "securityProtocol": "authTypeNone",
    "authType": "Executor",
    "authIdentity": "1107550004253538"
}'),
            connectionPropertiesMode?: string(name='ConnectionPropertiesMode', description='The mode in which the data source is added. The mode varies based on the data source type. Valid values:

*   InstanceMode: instance mode
*   UrlMode: connection string mode', example='UrlMode'),
            createTime?: long(name='CreateTime', description='The time when the data source was added. This value is a UNIX timestamp.', example='1648711113000'),
            createUser?: string(name='CreateUser', description='The ID of the user who adds the data source.', example='1624387842781448'),
            description?: string(name='Description', description='The description of the data source.', example='test'),
            id?: long(name='Id', description='The ID of the data source.', example='16035'),
            modifyTime?: long(name='ModifyTime', description='The time when the data source was last modified. This value is a UNIX timestamp.', example='1648711113000'),
            modifyUser?: string(name='ModifyUser', description='The ID of the user who modifies the data source.', example='1624387842781448'),
            qualifiedName?: string(name='QualifiedName', description='The unique business key of the data source. For example, the unique business key of a Hologres data source is in the `${tenantOwnerId}:${regionId}:${type}:${instanceId}:${database}` format.', example='1648711121000:cn-beijing:odps:yongxunQA_beijing_standard'),
          }
        ](name='DataSource', description='The data sources. Each element is the information of a single data source with a unique data source ID.'),
        name?: string(name='Name', description='The name of the data source.', example='test'),
        type?: string(name='Type', description='The type of the data source.', example='mysql'),
      }
    ](name='DataSources', description='The data source groups. Each element in the array indicates a data source group. Each data source group contains data sources in the development environment (if any) and the production environment.'),
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='131'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7BE1433F-6D55-5D86-9344-CA6F7DD19B13'),
}

model ListDataSourcesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataSourcesResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Deploy, Develop, Visitor, Workspace Owner, O\\&M, Model Designer, Security Administrator, Data Analyst, OpenPlatform Administrator, and Data Governance Administrator
  * @param request  the request parameters of ListDataSources  ListDataSourcesRequest
  * @return ListDataSourcesResponse
 */
async function listDataSources(request: ListDataSourcesRequest): ListDataSourcesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataSources', 'GET', '/', 'json', false, 'json', request);
}

model ListDatabasesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The comment. Supports fuzzy match.', example='test comment', position='Query'),
  name?: string(name='Name', description='The name. Supports fuzzy match.', example='test_tbl', position='Query'),
  order?: string(name='Order', description='The sort order. Default value: Asc. Valid values:

*   Asc: ascending.
*   Desc: descending.', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of records per page. Default: 10. Maximum: 100.', example='10', minimum=1, maximum=100, position='Query'),
  parentMetaEntityId: string(name='ParentMetaEntityId', description='The parent entity ID. For more information, see [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

You can refer to the ListCrawlerTypes operation for the parent entity type.

*   If the parent entity is a catalog, the format of `ParentMetaEntityId` follows the response of the ListCatalogs API.
*   If the parent entity is a metadata crawler, the format of `ParentMetaEntityId` is `${CrawlerType}:${Instance ID or encoded URL}`.

ParentMetaEntityId format examples

*   `dlf-catalog::catalog_id`
*   `holo:instance_id`
*   `mysql:(instance_id|encoded_jdbc_url)`

> 

*   `catalog_id`: The ID of the DLF catalog.
*   `instance_id`: The instance ID. Required when the data source is registered in instance mode.
*   `encoded_jdbc_url`: The URL-encoded JDBC connection string. Required when the data source is registered by connection string.

This parameter is required.', example='mysql:rm-abc123xxx
dlf-catalog:123456XXX:test_catalog', position='Query'),
  sortBy?: string(name='SortBy', description='The sort field. Default value: CreateTime. Valid values:

*   CreateTime
*   ModifyTime
*   Name', example='CreateTime', position='Query'),
}

model ListDatabasesResponseBody = {
  pagingInfo?: {
    databases?: [
      Database
    ](name='Databases', description='The database list.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of records per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of records returned.', example='1'),
  }(name='PagingInfo', description='The pagination result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='9DD08926-38B9-XXXXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListDatabasesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDatabasesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDatabases  ListDatabasesRequest
  * @return ListDatabasesResponse
 */
async function listDatabases(request: ListDatabasesRequest): ListDatabasesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDatabases', 'GET', '/', 'json', false, 'json', request);
}

model ListDatasetVersionsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  creatorId?: string(name='CreatorId', example='12103XXX46492139', position='Body'),
  datasetId: string(name='DatasetId', description='This parameter is required.', example='dataworks-dataset:3pXXXb8o0ngr07njhps1', position='Body'),
  order?: string(name='Order', example='Desc', position='Body'),
  pageNumber?: int32(name='PageNumber', example='1', minimum=1, position='Body'),
  pageSize?: int32(name='PageSize', example='10', minimum=1, maximum=100, position='Body'),
  sortBy?: string(name='SortBy', example='CreateTime', position='Body'),
}

model ListDatasetVersionsResponseBody = {
  pagingInfo?: {
    datasetVersions?: [
      DatasetVersion
    ](name='DatasetVersions'),
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    totalCount?: long(name='TotalCount', example='100'),
  }(name='PagingInfo'),
  requestId?: string(name='RequestId', description='RequestId', example='E25887B7-579C-54A5-9C4F-83A0DE367XXX'),
  success?: boolean(name='Success', example='true'),
}

model ListDatasetVersionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDatasetVersionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDatasetVersions  ListDatasetVersionsRequest
  * @return ListDatasetVersionsResponse
 */
async function listDatasetVersions(request: ListDatasetVersionsRequest): ListDatasetVersionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDatasetVersions', 'POST', '/', 'json', true, 'form', request);
}

model ListDatasetsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  creatorId?: string(name='CreatorId', example='12103XXX46492139', position='Body'),
  dataTypeList?: [ string ](name='DataTypeList', shrink='simple', position='Body'),
  name?: string(name='Name', example='test_dataset', position='Body'),
  order?: string(name='Order', example='Asc', position='Body'),
  origin?: string(name='Origin', example='DataWorks', position='Body'),
  pageNumber?: int32(name='PageNumber', example='1', minimum=1, position='Body'),
  pageSize?: int32(name='PageSize', example='10', minimum=1, maximum=100, position='Body'),
  projectId?: long(name='ProjectId', example='251363', position='Body'),
  sortBy?: string(name='SortBy', example='CreateTime', position='Body'),
  storageTypeList?: [ string ](name='StorageTypeList', shrink='simple', position='Body'),
}

model ListDatasetsResponseBody = {
  pagingInfo?: {
    datasets?: [
      Dataset
    ](name='Datasets'),
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', example='10'),
    totalCount?: long(name='TotalCount', example='100'),
  }(name='PagingInfo'),
  requestId?: string(name='RequestId', description='RequestId', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', example='true'),
}

model ListDatasetsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDatasetsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDatasets  ListDatasetsRequest
  * @return ListDatasetsResponse
 */
async function listDatasets(request: ListDatasetsRequest): ListDatasetsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDatasets', 'POST', '/', 'json', true, 'form', request);
}

model ListDeploymentPackageFilesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  businessId?: long(name='BusinessId', description='The workflow ID. You can call the [ListBusiness](https://help.aliyun.com/document_detail/173945.html) operation to query the workflow ID by name.', example='100001', position='Query'),
  changeType?: int32(name='ChangeType', description='The change type. Valid values:

*   0: addition
*   1: update
*   2: deletion', example='0', position='Query'),
  commitFrom?: string(name='CommitFrom', description='The start date for committing. Specify the date in the yyyy-MM-dd format.', example='2025-01-01', position='Query'),
  commitTo?: string(name='CommitTo', description='The end date (included) for committing. Specify the date in the yyyy-MM-dd format.', example='2025-01-31', position='Query'),
  commitUserId?: string(name='CommitUserId', description='The ID of the user who commits the file.', example='2003****', position='Query'),
  fileIds?: [ string ](name='FileIds', description='The IDs of the files to be queried.', shrink='json', position='Query'),
  fileName?: string(name='FileName', description='The name of the file.', example='Filename', position='Query'),
  fileType?: int32(name='FileType', description='The type of the code for the file.

The code for files varies based on the file type. For more information, see [DataWorks nodes](https://help.aliyun.com/document_detail/600169.html). You can call the [ListFileType](https://help.aliyun.com/document_detail/212428.html) operation to query the type of the code for the file.', example='10', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='20', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='12345', position='Query'),
  solutionId?: long(name='SolutionId', description='The solution ID.', example='8065', position='Query'),
}

model ListDeploymentPackageFilesResponseBody = {
  pagingInfo?: {
    deploymentPackageFiles?: [ 
      {
        changeType?: int32(name='ChangeType', description='The change type, which is an integer. Valid values:

*   0: addition
*   1: update
*   2: deletion', example='0'),
        comment?: string(name='Comment', description='The comment for committing.'),
        commitTime?: string(name='CommitTime', description='The time for committing.', example='2025-04-10 15:55:47'),
        commitUser?: string(name='CommitUser', description='The ID of the Alibaba Cloud account used by the user who committed the file.', example='446***'),
        commitUserName?: string(name='CommitUserName', description='The name of the Alibaba Cloud account used by the user who committed the file.', example='user***'),
        fileId?: long(name='FileId', description='The file ID.', example='520246913'),
        fileName?: string(name='FileName', description='The name of the file of the current version.', example='bak_part_basc_person_relation_all_da'),
        fileType?: int32(name='FileType', description='The file type. The code for files varies based on the file type. For more information, see [DataWorks nodes](https://help.aliyun.com/document_detail/600169.html).', example='13'),
        fileVersion?: long(name='FileVersion', description='The file version.', example='34'),
        id?: long(name='Id', description='The unique ID.', example='650433503'),
        isSameAsProductionVersion?: boolean(name='IsSameAsProductionVersion', description='Indicates whether the version is a version in the production environment of the scheduling system.', example='true'),
        nodeConfiguration?: string(name='NodeConfiguration', description='The scheduling property configurations of the node that corresponds to the file, which is a JSON string.', example='{
	"tagList": [],
	"fileId": -1,
	"taskRerunTime": 0,
	"taskRerunInterval": 0,
	"reRunAble": 1,
	"nodeId": 125803000,
	"nodeName": "new",
	"nodeType": 0,
	"isStop": 0,
	"paraValue": "",
	"startEffectDate": "1970-01-01 00:00:00",
	"endEffectDate": "9999-01-01 00:00:00",
	"cronExpress": "00 26 00 * * ?",
	"owner": "1107550004250000",
	"resgroupId": 6300000,
	"cu": "0.25",
	"appId": 170000,
	"tenantId": 524257424560000,
	"createTime": "2025-04-10 15:55:01",
	"createUser": "1107550004250000",
	"lastModifyTime": "2025-04-10 15:55:41",
	"cycleType": 0,
	"dependentType": 0,
	"dependentTypeList": [0],
	"lastModifyUser": "1107550004250000",
	"dependentDataNode": "",
	"input": "[{\\"regionId\\":\\"cn-hangzhou\\",\\"str\\":\\"root_input\\",\\"parseType\\":1}]",
	"output": "[{\\"str\\":\\"project_root.526586287_out\\",\\"parseType\\":2},{\\"str\\":\\"project_root.new\\",\\"parseType\\":1}]",
	"inputList": [{
		"regionId": "cn-hangzhou",
		"str": "root_input",
		"parseType": 1
	}],
	"outputList": [{
		"str": "project_root.526586287_out",
		"parseType": 2
	}, {
		"str": "project_root.new",
		"parseType": 1
	}],
	"isAutoParse": 1,
	"startRightNow": false,
	"extConfig": "{\\"openCustomCron\\":false,\\"formCron\\":\\"\\"}",
	"inputContextList": [],
	"outputContextList": []
}'),
        nodeId?: long(name='NodeId', description='The ID of the auto triggered node that corresponds to the file.', example='700005008419'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='27595'),
        smokeTestStatus?: string(name='SmokeTestStatus', description='The test status in the development environment.'),
        status?: int32(name='Status', description='The status of the code file of the current version. Valid values:

*   2: Commit check in progress.
*   3: Commit check passed.
*   4: Commit check failed.
*   10: Committing.
*   11: Committed.
*   20: Approved.
*   21: Rejected.
*   22: Warning detected during checking.
*   23: Under code review.
*   24: Code review rejected.
*   80: Deployment package created.
*   100: Deploying.
*   101: Deployed to the production environment.
*   200: Cancelled.', example='100'),
        tenantId?: long(name='TenantId', description='The DataWorks tenant ID.', example='639415964191360'),
        useType?: string(name='UseType', description='The module to which the file belongs. Valid values:

*   NORMAL: The file is used for DataStudio.
*   MANUAL: The file is used for a manually triggered node.
*   MANUAL_BIZ: The file is used for a manually triggered workflow.
*   SKIP: The file is used for a dry-run node in DataStudio.
*   ADHOCQUERY: The file is used for an ad hoc query.
*   COMPONENT: The file is used for a script template.', example='NORMAL'),
      }
    ](name='DeploymentPackageFiles', description='The list of files pending deployment.'),
    pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination details.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
}

model ListDeploymentPackageFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDeploymentPackageFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDeploymentPackageFiles  ListDeploymentPackageFilesRequest
  * @return ListDeploymentPackageFilesResponse
 */
async function listDeploymentPackageFiles(request: ListDeploymentPackageFilesRequest): ListDeploymentPackageFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDeploymentPackageFiles', 'POST', '/', 'json', false, 'json', request);
}

model ListDeploymentPackagesRequest {
  region?: string(name='Region', position='Host'),
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  creator?: string(name='Creator', description='The Alibaba Cloud account ID of the deployment package creator.', example='110755000425****', position='Body'),
  endCreateTime?: long(name='EndCreateTime', description='The maximum millisecond timestamp for when the deployment package was created.', example='1593877765000', position='Body'),
  endExecuteTime?: long(name='EndExecuteTime', description='The maximum millisecond timestamp for when the deployment package started executing.', example='1593877765000', position='Body'),
  executor?: string(name='Executor', description='The Alibaba Cloud account ID of the deployment package executor.', example='2003****', position='Body'),
  keyword?: string(name='Keyword', description='The keyword in the deployment package name. DataWorks supports fuzzy matching, meaning you can enter a keyword to query for deployment packages that contain it.', example='abc', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of records per page. Default value: 10. Maximum value: 100.', example='10', maximum=100, position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the DataWorks console and go to the workspace configuration page to query the ID. You must configure either this parameter or the ProjectIdentifier parameter to determine the DataWorks workspace to which the operation is applied.', example='10003', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The unique identifier of the DataWorks workspace, which is the identifier at the top of the Data Studio page where you switch workspaces. Either this parameter or ProjectId must be specified to determine which DataWorks workspace this API call operates on.', example='dw_project', position='Body'),
  status?: int32(name='Status', description='The status of the deployment package. Valid values:

*   0: It is ready.
*   1: It was successfully deployed.
*   2: It failed to be deployed.
*   6: It was rejected.', example='1', position='Body'),
}

model ListDeploymentPackagesResponseBody = {
  data?: {
    deployments?: [ 
      {
        createTime?: long(name='CreateTime', description='The timestamp when the deployment package was created.', example='1593877765000'),
        creator?: string(name='Creator', description='The Alibaba Cloud account ID of the deployment package creator.', example='2003****'),
        errorMessage?: string(name='ErrorMessage', description='When the deployment package fails to execute, this parameter is used to record the error message.', example='OK'),
        executeTime?: long(name='ExecuteTime', description='The timestamp when the deployment package was executed.', example='1593877765000'),
        executor?: string(name='Executor', description='The Alibaba Cloud account ID of the deployment package executor.', example='2003****'),
        id?: long(name='Id', description='The ID of the deployment package. You can use this ID to call the [GetDeployment](https://help.aliyun.com/document_detail/173950.html) operation to get the deployment package details.', example='11111'),
        name?: string(name='Name', description='The name of the deployment package.', example='auto_created'),
        status?: int32(name='Status', description='The status of the deployment package. Valid values:

*   0: It is ready.
*   1: It was successfully deployed.
*   2: It failed to be deployed.
*   6: It was rejected.', example='1'),
      }
    ](name='Deployments', description='The returned list of deployment packages.'),
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of records per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of records that meet the conditions.', example='20'),
  }(name='Data', description='The list of deployment packages that meet the query conditions.'),
  requestId?: string(name='RequestId', description='The request ID.', example='952795279527ab****'),
}

model ListDeploymentPackagesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDeploymentPackagesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDeploymentPackages  ListDeploymentPackagesRequest
  * @return ListDeploymentPackagesResponse
 */
async function listDeploymentPackages(request: ListDeploymentPackagesRequest): ListDeploymentPackagesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDeploymentPackages', 'POST', '/', 'json', true, 'form', request);
}

model ListDownstreamTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
}

model ListDownstreamTaskInstancesResponseBody = {
  pagingInfo?: {
    downstreamTaskInstances?: [ 
      {
        dependencyType?: string(name='DependencyType', description='The scheduling dependency type. Valid values:

*   Normal
*   CrossCycle', example='Normal'),
        taskInstance?: {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
          bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description.', example='test'),
          envType?: string(name='EnvType', description='The environment in which the data source is used. Valid values:

*   Dev
*   Prod', example='Prod'),
          finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
          id?: long(name='Id', description='The instance ID.', example='1234'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
          priority?: int32(name='Priority', description='The priority of the task. Minimum value: 1. Maximum value: 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunMode?: string(name='RerunMode', description='The rerun mode.', example='AllAllowed'),
          runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
          runtime?: {
            gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
            processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
          }(name='Runtime', description='The runtime information about the instance.'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
          startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
          status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.
*   WaitTrigger: The instance is waiting to be triggered by external scheduling systems.', example='Success'),
          taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
          taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
          taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='3600'),
          triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
          triggerType?: string(name='TriggerType', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
          workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
          workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   Normal
*   Manual
*   SmokeTest
*   SupplementData
*   ManualWorkflow', example='Normal'),
          workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
        }(name='TaskInstance', description='The information about a task instance.'),
      }
    ](name='DownstreamTaskInstances', description='The descendant instances.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    taskInstances?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description.', example='test'),
        envType?: string(name='EnvType', description='The environment in which the data source is used. Valid values:

*   Dev
*   Prod', example='Prod'),
        finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The instance ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='100'),
        periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter. Valid values:', example='Prod', deprecated='true'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunMode?: string(name='RerunMode', description='The rerun mode.

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether it is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
        runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
        runtime?: {
          gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
          processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
        }(name='Runtime', description='The runtime information about the instance.'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The information about the resource group with which the instance is associated.'),
        startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
        status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.
*   WaitTrigger: The instance is waiting to be triggered by external scheduling systems.', example='Success'),
        stepType?: string(name='StepType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
        taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
        taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='1'),
        triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
        triggerType?: string(name='TriggerType', description='The method to trigger instance scheduling.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
        workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
        workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance.

Valid values:

*   SmokeTest
*   SupplementData
*   Manual
*   ManualWorkflow
*   Normal
*   ManualFlow', example='Normal'),
        workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
      }
    ](name='TaskInstances', description='The instances. This parameter is deprecated and replaced by the DownstreamTaskInstances parameter.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListDownstreamTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDownstreamTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDownstreamTaskInstances  ListDownstreamTaskInstancesRequest
  * @return ListDownstreamTaskInstancesResponse
 */
async function listDownstreamTaskInstances(request: ListDownstreamTaskInstancesRequest): ListDownstreamTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDownstreamTaskInstances', 'GET', '/', 'json', false, 'json', request);
}

model ListDownstreamTasksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model ListDownstreamTasksResponseBody = {
  pagingInfo?: {
    downstreamTasks?: [ 
      {
        dependencyType?: string(name='DependencyType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        task?: {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description.', example='test'),
          envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
          id?: long(name='Id', description='The task ID.', example='1234'),
          instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          name?: string(name='Name', description='The name of the task.', example='SQL node'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8.', example='1'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
          trigger?: {
            cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
            endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
            recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
            startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
            timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
            type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
          }(name='Trigger', description='The trigger method.'),
          type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
        }(name='Task', description='The information about the task.'),
      }
    ](name='DownstreamTasks', description='The descendant tasks.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    tasks?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description of the task.', example='test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        id?: long(name='Id', description='The task ID.', example='1234'),
        instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name of the task.', example='SQL node'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter.

Valid values:

*   Prod
*   Dev', example='Prod', deprecated='true'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
        rerunMode?: string(name='RerunMode', description='The rerun mode.

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether it is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
        rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        stepType?: string(name='StepType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
          recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
          timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
          type?: string(name='Type', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        }(name='Trigger', description='The method to trigger task scheduling.'),
        type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
      }
    ](name='Tasks', description='The tasks. This parameter is deprecated and replaced by the DownstreamTasks parameter.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListDownstreamTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDownstreamTasksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDownstreamTasks  ListDownstreamTasksRequest
  * @return ListDownstreamTasksResponse
 */
async function listDownstreamTasks(request: ListDownstreamTasksRequest): ListDownstreamTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDownstreamTasks', 'GET', '/', 'json', false, 'json', request);
}

model ListEntitiesInMetaCollectionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  entityDescription?: string(name='EntityDescription', description='The description specified when the entity was added to the collection. Supports fuzzy matching. Valid only for the album type.', example='test', position='Query'),
  entityName?: string(name='EntityName', description='The entity name. Supports fuzzy matching.', example='test1', position='Query'),
  entityType?: string(name='EntityType', description='The entity type.', example='dlf-table', position='Query'),
  id: string(name='Id', description='The collection ID.

This parameter is required.', example='category.123', position='Query'),
  order?: string(name='Order', description='The sort order. Valid values:

*   Asc (default): ascending order.
*   Desc', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of records per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  sortBy?: string(name='SortBy', description='The sort field. Valid values:

*   Name (default)
*   CreateTime', example='Name', position='Query'),
}

model ListEntitiesInMetaCollectionResponseBody = {
  pagingInfo?: {
    entities?: [ 
      {
        comment?: string(name='Comment', description='The entity comment.', example='test'),
        createTime?: long(name='CreateTime', description='The creation time in milliseconds.', example='1737078994080'),
        description?: string(name='Description', description='The description specified when the entity was added to the collection. Valid only for albums.', example='test'),
        id?: string(name='Id', description='The ID of the entity. Currently, only the Table type is supported. If the entity is deleted, this field is empty.', example='dlf-table:123456789:test_catalog:test_database::test_table'),
        modifyTime?: long(name='ModifyTime', description='The last modified time in milliseconds.', example='1737078994080'),
        name?: string(name='Name', description='The entity name.', example='test_table'),
        type?: string(name='Type', description='The entity type.', example='dlf-table'),
      }
    ](name='Entities', description='The list of entities in the collection.'),
    pageNumber?: int32(name='PageNumber', description='The current page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of records per page.', example='1'),
    totalCount?: int32(name='TotalCount', description='The total number of records.', example='100'),
  }(name='PagingInfo', description='The pagination result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='F05080B0-CCE6-5D22-B284-34A51C5D4E28'),
}

model ListEntitiesInMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListEntitiesInMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListEntitiesInMetaCollection  ListEntitiesInMetaCollectionRequest
  * @return ListEntitiesInMetaCollectionResponse
 */
async function listEntitiesInMetaCollection(request: ListEntitiesInMetaCollectionRequest): ListEntitiesInMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListEntitiesInMetaCollection', 'GET', '/', 'json', false, 'json', request);
}

model ListFileVersionsRequest {
  regionId?: string(name='RegionId', position='Host'),
  fileId: long(name='FileId', description='The file ID. You can call [ListFiles](https://help.aliyun.com/document_detail/173942.html) to query the file ID.

This parameter is required.', example='100000001', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number for pagination.', example='1', minimum=1, position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=0, maximum=100, position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. To find this, click the wrench icon in the upper-right corner and navigate to the workspace management page.', example='100001', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The unique identifier of the DataWorks workspace, which is the identifier at the top of the Data Studio page where you switch workspaces.

Either this parameter or ProjectId must be specified to identify the target DataWorks workspace for this API call.', example='dw_project', position='Body'),
}

model ListFileVersionsResponseBody = {
  data?: {
    fileVersions?: [ 
      {
        changeType?: string(name='ChangeType', description='The change type for this file version. Valid values: CREATE, UPDATE, and DELETE.', example='UPDATE'),
        comment?: string(name='Comment', description='The description of this file version.', example='Second version submission'),
        commitTime?: long(name='CommitTime', description='The timestamp (in milliseconds) when the file version was created.', example='1593881265000'),
        commitUser?: string(name='CommitUser', description='The Alibaba Cloud account ID of the user who created this file version.', example='73842342****'),
        fileContent?: string(name='FileContent', description='The file code for this version.', example='SHOW TABLES;'),
        fileName?: string(name='FileName', description='The file name for this file version.', example='ods_user_info_d'),
        filePropertyContent?: string(name='FilePropertyContent', description='The text information for this file version.', example='{"fileName":"ods_user_info_d","fileType":10}'),
        fileVersion?: int32(name='FileVersion', description='The file version.', example='2'),
        isCurrentProd?: boolean(name='IsCurrentProd', description='Indicates whether this file version is the latest version in the production environment.

*   true
*   false', example='false'),
        nodeContent?: string(name='NodeContent', description='The scheduling configuration for this file version.', example='{"cycleType":0,"cronExpress":"00 05 00 * * ?"}'),
        nodeId?: long(name='NodeId', description='The scheduling task ID associated with this file version.', example='1234'),
        status?: string(name='Status', description='The current status of the file version. Valid values: COMMITTING (committing), COMMITTED or CHECK_OK (committed), PACKAGED (ready for deployment), DEPLOYING (deploying), DEPLOYED (deployed), and CANCELLED (deployment canceled).', example='COMMITTED'),
        useType?: string(name='UseType', description='The functional module to which the file belongs. Valid values: NORMAL (Data Studio), MANUAL (manual task), MANUAL_BIZ (manual workflow), SKIP (dry-run scheduling in Data Studio), ADHOCQUERY (ad hoc query), and COMPONENT (component management).', example='NORMAL'),
      }
    ](name='FileVersions', description='The list of file version details.'),
    pageNumber?: int32(name='PageNumber', description='The current page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries on the current page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='13'),
  }(name='Data', description='The list of file versions.'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the call succeeded. Valid values:

*   true
*   false', example='true'),
}

model ListFileVersionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListFileVersionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListFileVersions  ListFileVersionsRequest
  * @return ListFileVersionsResponse
 */
async function listFileVersions(request: ListFileVersionsRequest): ListFileVersionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListFileVersions', 'POST', '/', 'json', true, 'form', request);
}

model ListFilesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  commitStatus?: int32(name='CommitStatus', description='The current commit status of the file. Valid values: 0 (the latest code is not committed) and 1 (the latest code is committed).', example='1', position='Body'),
  exactFileName?: string(name='ExactFileName', description='The exact file name. The file name in the query result must exactly match this parameter.', example='ods_create.sql', position='Body'),
  fileFolderPath?: string(name='FileFolderPath', description='The path to the folder where the file is located.', example='Business_process/my_first_business_process/MaxCompute/ods_layer', position='Body'),
  fileIdIn?: string(name='FileIdIn', description='The list of file IDs. The file IDs in the query result must be a subset of this list. You can specify up to 50 file IDs at a time.', example='78237,816123', position='Body'),
  fileTypes?: string(name='FileTypes', description='The code type of the file.

The code type of the file. Common code types and their corresponding file types include: 6 (Shell), 10 (ODPS SQL), 11 (ODPS MR), 23 (Data Integration), 24 (ODPS Script), 97 (PAI), 98 (Combined node), 99 (Virtual node), 221 (PyODPS 2), 225 (ODPS Spark), 227 (EMR Hive), 228 (EMR Spark), 229 (EMR Spark SQL), 230 (EMR MR), 239 (OSS object inspection), 257 (EMR Shell), 258 (EMR Spark Shell), 259 (EMR Presto), 260 (EMR Impala), 900 (Real-time sync), 1002 (PAI internal node), 1089 (Cross-tenant node), 1091 (Hologres development), 1093 (Hologres SQL), 1100 (Assignment node), 1106 (ForEach node), 1221 (PyODPS 3).', example='10,23', position='Body'),
  keyword?: string(name='Keyword', description='The keyword for the file name. Fuzzy match is supported. You can enter a keyword to query all files that contain the keyword.', example='ods', position='Body'),
  lastEditUser?: string(name='LastEditUser', description='The Alibaba Cloud account ID of the user who last updated the file.', example='11233***', position='Body'),
  needAbsoluteFolderPath?: boolean(name='NeedAbsoluteFolderPath', description='Specifies whether the query result includes the path to the folder where the file is located.', example='false', position='Body'),
  needContent?: boolean(name='NeedContent', description='Specifies whether the query result includes the file content. For files with large content, network transmission delays may occur.', example='false', position='Body'),
  nodeId?: long(name='NodeId', description='The ID of the scheduling node. You can call the [ListNodes](https://help.aliyun.com/document_detail/173979.html) operation to obtain the node ID.', example='123541234', position='Body'),
  owner?: string(name='Owner', description='The ID of the file owner.', example='3726346****', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number for pagination.', example='1', minimum=1, position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=0, maximum=100, position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID.

You must configure either this parameter or the ProjectIdentifier parameter to determine the DataWorks workspace to which the operation is applied.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The DataWorks workspace name. To obtain the workspace name, log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and navigate to the workspace configuration page.

You must specify either this parameter or ProjectId to identify the target DataWorks workspace for this API call.', example='dw_project', position='Body'),
  useType?: string(name='UseType', description='The functional module to which the file belongs. Valid values:

*   NORMAL: Data Studio
*   MANUAL: Manually triggered node
*   MANUAL_BIZ: Manually triggered workflow
*   SKIP: Dry-run scheduling in Data Studio
*   ADHOCQUERY: Ad hoc query
*   COMPONENT: Component management', example='NORMAL', position='Body'),
}

model ListFilesResponseBody = {
  data?: {
    files?: [ 
      {
        absoluteFolderPath?: string(name='AbsoluteFolderPath', description='The path to the folder where the file is located.', example='Business_process/my_first_business_process/MaxCompute/ods_layer'),
        autoParsing?: boolean(name='AutoParsing', description='Specifies whether automatic parsing is enabled for the file. Valid values:

*   true: The file automatically parses code.
*   false: The file does not automatically parse code.

This parameter corresponds to Analyze Code when you set Dependencies to Same Cycle in the scheduling configuration of a Data Studio task in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='true'),
        bizId?: long(name='BizId', description='The ID of the workflow to which the file belongs. This parameter is deprecated. Use the BusinessId parameter instead.', example='300000'),
        businessId?: long(name='BusinessId', description='The ID of the workflow to which the file belongs.', example='300000'),
        commitStatus?: int32(name='CommitStatus', description='The current commit status of the file. Valid values: 0 (the latest code is not committed) and 1 (the latest code is committed).', example='1'),
        connectionName?: string(name='ConnectionName', description='The data source name used by the task.', example='odps_source'),
        content?: string(name='Content', description='This parameter is deprecated. You can call the [GetFile](https://help.aliyun.com/document_detail/173954.html) operation to query this information.', example='SHOW TABLES;'),
        createTime?: long(name='CreateTime', description='The timestamp (in milliseconds) when the file was created.', example='1593950832000'),
        createUser?: string(name='CreateUser', description='The Alibaba Cloud account ID of the file creator.', example='382762****'),
        currentVersion?: int32(name='CurrentVersion', description='The latest version of the file.', example='2'),
        fileDescription?: string(name='FileDescription', description='The description of the file.', example='my test datastudio file'),
        fileFolderId?: string(name='FileFolderId', description='The ID of the folder where the file is located.', example='2735c2****'),
        fileId?: long(name='FileId', description='The file ID.', example='10000001'),
        fileName?: string(name='FileName', description='The file name.', example='ods_user_info_d'),
        fileType?: int32(name='FileType', description='The file type. Different file types have different code. For more information, see [DataWorks node types](https://help.aliyun.com/document_detail/600169.html).', example='10'),
        isMaxCompute?: boolean(name='IsMaxCompute', description='If the current file is a MaxCompute resource file, this parameter specifies whether the resource file needs to be uploaded to MaxCompute.

You only need to configure this parameter when the file is a MaxCompute resource file.', example='false'),
        lastEditTime?: long(name='LastEditTime', description='The timestamp (in milliseconds) when the file was last modified.', example='1593950832000'),
        lastEditUser?: string(name='LastEditUser', description='The Alibaba Cloud account ID of the user who last updated the file.', example='382762****'),
        nodeId?: long(name='NodeId', description='The ID of the scheduling task generated in the scheduling system after the file is committed.', example='300001'),
        owner?: string(name='Owner', description='The Alibaba Cloud account ID of the file owner.', example='3872572****'),
        parentId?: long(name='ParentId', description='If the current file is an internal file of a combined node, this parameter specifies the ID of the corresponding combined node file.', example='-1'),
        useType?: string(name='UseType', description='The functional module to which the file belongs. Valid values:

*   NORMAL: Data Studio
*   MANUAL: Manually triggered node
*   MANUAL_BIZ: Manually triggered workflow
*   SKIP: Dry-run scheduling in Data Studio
*   ADHOCQUERY: Ad hoc query
*   COMPONENT: Component management', example='NORMAL'),
      }
    ](name='Files', description='The file details.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='13'),
  }(name='Data', description='The response details.'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID. Use this ID to troubleshoot issues.', example='0000-ABCD-****'),
  success?: boolean(name='Success', description='Indicates whether the call succeeded. Valid values:

*   true
*   false', example='true'),
}

model ListFilesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListFilesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListFiles  ListFilesRequest
  * @return ListFilesResponse
 */
async function listFiles(request: ListFilesRequest): ListFilesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListFiles', 'POST', '/', 'json', true, 'form', request);
}

model ListFoldersRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  pageNumber: int32(name='PageNumber', description='The page number of the request. Used for pagination.

This parameter is required.', example='1', minimum=1, position='Body'),
  pageSize: int32(name='PageSize', description='The number of records per page. Default value: 10. Maximum value: 100.

This parameter is required.', example='10', minimum=0, maximum=100, position='Body'),
  parentFolderPath: string(name='ParentFolderPath', description='The path of the parent folder.

This parameter is required.', example='Business_process/my_first_business_process/MaxCompute', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the DataWorks console and go to the Workspace page to query the ID. You must specify either this parameter or the ProjectIdentifier parameter to identify the DataWorks workspace when you call this operation.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can log on to the DataWorks console and go to the Workspace page to query the workspace name. You must specify either this parameter or the ProjectId parameter to identify the DataWorks workspace when you call this operation.', example='dw_project', position='Body'),
}

model ListFoldersResponseBody = {
  data?: {
    folders?: [ 
      {
        folderId?: string(name='FolderId', description='The folder ID.', example='2735c2****'),
        folderPath?: string(name='FolderPath', description='The folder path.', example='Business_process/my_first_business_process/MaxCompute/ods_layer'),
      }
    ](name='Folders', description='The list of folders.'),
    pageNumber?: int32(name='PageNumber', description='The current page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of records on the current page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of records that meet the query conditions.', example='13'),
  }(name='Data', description='The list of folders that meet the conditions.'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID. Used to troubleshoot errors.', example='0000-ABCD-****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true: success.
*   false: failure.', example='true'),
}

model ListFoldersResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListFoldersResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListFolders  ListFoldersRequest
  * @return ListFoldersResponse
 */
async function listFolders(request: ListFoldersRequest): ListFoldersResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListFolders', 'POST', '/', 'json', true, 'form', request);
}

model ListFunctionsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  name?: string(name='Name', position='Query'),
  owner?: string(name='Owner', description='The ID of the owner of the UDF. This parameter specifies a filter condition.', example='110755000425XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1. Minimum value: 1.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='12345', position='Query'),
  type?: string(name='Type', description='The user-defined function (UDF) type. This parameter specifies a filter condition.

Valid values:

*   Math: mathematical operation function
*   Aggregate: aggregate function
*   String: string processing function
*   Date: date function
*   Analytic: window function
*   Other: other functions', example='MATH', position='Query'),
}

model ListFunctionsResponseBody = {
  pagingInfo?: {
    functions?: [ 
      {
        armResource?: string(name='ArmResource', description='The file resources in an Advanced RISC Machines (ARM) cluster.', example='xxx.jar,yyy.jar'),
        className?: string(name='ClassName', description='The fully qualified class name of the UDF.', example='com.demo.Main'),
        commandDescription?: string(name='CommandDescription', description='The description of the command.', example='testUdf(xx,yy)'),
        createTime?: long(name='CreateTime', description='The time when the UDF was created. This value is a UNIX timestamp.', example='1655953028000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='odps_first'),
          type?: string(name='Type', description='The type of the data source.', example='odps'),
        }(name='DataSource', description='The data source information about the UDF.'),
        databaseName?: string(name='DatabaseName', description='The name of the database. This parameter is returned for E-MapReduce (EMR) functions.', example='odps_first'),
        description?: string(name='Description', description='The overall description of the UDF.', example='Description'),
        embeddedCode?: string(name='EmbeddedCode', description='The code of the embedded UDF.', example='print(\\"hello,world!\\")'),
        embeddedCodeType?: string(name='EmbeddedCodeType', description='The type of the nested code.

Valid values:

*   Python2
*   Python3
*   Java8
*   Java11
*   Java17', example='Python2'),
        embeddedResourceType?: string(name='EmbeddedResourceType', description='The type of the nested resource.

Valid values:

*   File: general resources
*   Embedded: embedded resources', example='File'),
        exampleDescription?: string(name='ExampleDescription', description='The description of the example.', example='Example description >>> select tsetUdf(xx,yy);
abc'),
        fileResource?: string(name='FileResource', description='The files resources.', example='xxx.jar,yyy.jar'),
        id?: long(name='Id', description='The ID of the UDF.', example='580667964888595XXXX'),
        modifyTime?: long(name='ModifyTime', description='The time when the UDF was last modified. This value is a UNIX timestamp.', example='1655953028000'),
        name?: string(name='Name', description='The name of the UDF.', example='Function name'),
        owner?: string(name='Owner', description='The owner of the UDF.', example='110755000425XXXX'),
        parameterDescription?: string(name='ParameterDescription', description='The description of the parameter.', example='xx: parameter information XXX
yy: parameter information YYY'),
        projectId?: long(name='ProjectId', description='The ID of the workspace to which the UDF belongs.', example='307XXX'),
        returnValueDescription?: string(name='ReturnValueDescription', description='The description of the return value.', example='The return value is a string.'),
        runtimeResource?: {
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group used when you run the UDF.', example='S_resgrop_xxx'),
        }(name='RuntimeResource', description='The information about the resource group used when you run the UDF.'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='652567824470354XXXX'),
          path?: string(name='Path', description='The script path.', example='XXX/OpenAPI/function/function_name'),
          runtime?: {
            command?: string(name='Command', description='The command.', example='ODPS_FUNCTION'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information about the UDF.'),
        type?: string(name='Type', description='The UDF type.

Valid values:

*   Math: mathematical operation function
*   Aggregate: aggregate function
*   String: string processing function
*   Date: date function
*   Analytic: window function
*   Other: other functions', example='MATH'),
      }
    ](name='Functions', description='The UDFs.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='294'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='89FB2BF0-EB00-5D03-9C34-05931001XXXX'),
}

model ListFunctionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListFunctionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListFunctions  ListFunctionsRequest
  * @return ListFunctionsResponse
 */
async function listFunctions(request: ListFunctionsRequest): ListFunctionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListFunctions', 'GET', '/', 'json', false, 'json', request);
}

model ListLineageRelationshipsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dstEntityId: string(name='DstEntityId', description='The destination entity ID. For more information, see the table ID or field ID in the response returned by the ListTables or ListColumns operation. You can also specify a custom entity ID.

This parameter is required.', example='maxcompute-table:123456XXX::test_project::test_tbl
dlf-table:123456XXX:test_catalog:test_db::test_tbl
hms-table:c-abc123xxx::test_db::test_tbl
holo-table:h-abc123xxx::test_db:test_schema:test_tbl
custom-api:api123
custom-table:table456', position='Query'),
  dstEntityName?: string(name='DstEntityName', description='The destination entity name. Supports fuzzy matching.', example='dstName', position='Query'),
  order?: string(name='Order', description='The order in which schemas are sorted. Default value: Asc. Valid values:

*   Asc: ascending.
*   Desc: descending.', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
  sortBy?: string(name='SortBy', description='The sort field. Default value: Name.', example='Name', position='Query'),
  srcEntityId: string(name='SrcEntityId', description='The source entity ID. For more information, see the table ID or field ID in the response returned by the ListTables or ListColumns operation. You can also specify a custom entity ID.

This parameter is required.', example='maxcompute-table:123456XXX::test_project::test_tbl
dlf-table:123456XXX:test_catalog:test_db::test_tbl
hms-table:c-abc123xxx::test_db::test_tbl
holo-table:h-abc123xxx::test_db:test_schema:test_tbl
custom-api:api123
custom-table:table456', position='Query'),
  srcEntityName?: string(name='SrcEntityName', description='The source entity name. Supports fuzzy matching.', example='srcName', position='Query'),
}

model ListLineageRelationshipsResponseBody = {
  pagingInfo?: {
    lineageRelationships?: [
      LineageRelationship
    ](name='LineageRelationships', description='The list of data tables.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The page size.', example='10'),
    totalCount?: long(name='TotalCount', description='The total count.', example='123'),
  }(name='PagingInfo', description='The pagination result.'),
  requestId?: string(name='RequestId', description='The request ID. Used for locating and troubleshooting issues.', example='SDFSDFSDF-SDFSDF-SDFDSF-SDFSDF'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListLineageRelationshipsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLineageRelationshipsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLineageRelationships  ListLineageRelationshipsRequest
  * @return ListLineageRelationshipsResponse
 */
async function listLineageRelationships(request: ListLineageRelationshipsRequest): ListLineageRelationshipsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLineageRelationships', 'GET', '/', 'json', false, 'json', request);
}

model ListLineagesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dstEntityId?: string(name='DstEntityId', description='The destination entity ID. You can refer to the table or column ID returned by the ListTables or ListColumns operation, or use a custom entity ID.', example='maxcompute-table:123456XXX::test_project::test_tbl
dlf-table:123456XXX:test_catalog:test_db::test_tbl
hms-table:c-abc123xxx::test_db::test_tbl
holo-table:h-abc123xxx::test_db:test_schema:test_tbl
custom-api:api123
custom-table:table456', position='Query'),
  dstEntityName?: string(name='DstEntityName', description='The destination entity name. Supports fuzzy matching.', example='dstName1', position='Query'),
  needAttachRelationship?: boolean(name='NeedAttachRelationship', description='Specifies whether to return lineage information.', example='false', position='Query'),
  order?: string(name='Order', description='The sort order. Default value: Asc. Valid values:

*   Asc
*   Desc', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of records per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
  sortBy?: string(name='SortBy', description='The sort field. Default value: Name.', example='Name', position='Query'),
  srcEntityId?: string(name='SrcEntityId', description='The source entity ID. You can refer to the table or column ID returned by the ListTables or ListColumns operation, or use a custom entity ID.', example='maxcompute-table:123456XXX::test_project::test_tbl
dlf-table:123456XXX:test_catalog:test_db::test_tbl
hms-table:c-abc123xxx::test_db::test_tbl
holo-table:h-abc123xxx::test_db:test_schema:test_tbl
custom-api:api123
custom-table:table456', position='Query'),
  srcEntityName?: string(name='SrcEntityName', description='The source entity name. Supports fuzzy matching.', example='srcName1', position='Query'),
}

model ListLineagesResponseBody = {
  pagingInfo?: {
    lineages?: [ 
      {
        dstEntity?: LineageEntity(name='DstEntity', description='The destination entity.'),
        relationships?: [
          LineageRelationship
        ](name='Relationships', description='The lineage details.'),
        srcEntity?: LineageEntity(name='SrcEntity', description='The source entity.'),
      }
    ](name='Lineages', description='The lineage information list.'),
    pageNumber?: int32(name='PageNumber', description='The requested page number for pagination.', example='1'),
    pageSize?: int32(name='PageSize', description='The page size. Default value: 10.', example='10'),
    totalCount?: long(name='TotalCount', description='Total record count.', example='12'),
  }(name='PagingInfo', description='The pagination result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListLineagesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListLineagesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListLineages  ListLineagesRequest
  * @return ListLineagesResponse
 */
async function listLineages(request: ListLineagesRequest): ListLineagesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListLineages', 'GET', '/', 'json', false, 'json', request);
}

model ListMetaCollectionsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  administrator?: string(name='Administrator', description='The administrator ID. Valid only for album types. Default: The current user ID.', example='12345', position='Query'),
  createUser?: string(name='CreateUser', description='The creator user ID. Valid only for album types. Default: The current user ID.', example='123456', position='Query'),
  description?: string(name='Description', description='The collection description. Supports fuzzy matching.', position='Query'),
  name?: string(name='Name', description='The collection name. Supports fuzzy matching.', example='test', position='Query'),
  order?: string(name='Order', description='The sort order. Valid values:

*   Asc (default): Ascending order
*   Desc', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default: 10. Maximum: 100.', example='10', position='Query'),
  parentId?: string(name='ParentId', description='The ID of the parent collection.', example='category.123', position='Query'),
  sortBy?: string(name='SortBy', description='The sort field. Valid values:

*   Id (default)
*   Name
*   CreateUser: Creator ID
*   CreateTime: Creation time
*   ModifyTime: Modification time', example='Name', position='Query'),
  type: string(name='Type', description='The collection type. Valid values:

*   Category
*   Album
*   AlbumCategory: Album subcategory

This parameter is required.', example='Category', position='Query'),
}

model ListMetaCollectionsResponseBody = {
  data?: {
    metaCollections?: [ 
      {
        administrators?: [ string ](name='Administrators', description='The list of administrator IDs. Supported only for album types. Administrators must be users within the same tenant. Multiple administrators can be specified.'),
        createTime?: long(name='CreateTime', description='The creation time in milliseconds (timestamp).', example='1668568601000'),
        createUser?: string(name='CreateUser', description='The creator user ID.', example='456789'),
        description?: string(name='Description', description='The collection description.'),
        id?: string(name='Id', description='The collection name.', example='category.123'),
        modifyTime?: long(name='ModifyTime', description='The modification time in milliseconds (timestamp).', example='1668568601000'),
        name?: string(name='Name', description='The collection name.', example='test_category'),
        parentId?: string(name='ParentId', description='The ID of the parent collection. Can be empty.', example='category.1'),
        type?: string(name='Type', description='The collection type. Valid values:

*   Category
*   Album
*   AlbumCategory: Album subcategory', example='Category'),
      }
    ](name='MetaCollections', description='The list of collections.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of records.', example='10'),
  }(name='Data', description='Pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='E25887B7-579C-54A5-9C4F-83A0DE367DDE'),
}

model ListMetaCollectionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListMetaCollectionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListMetaCollections  ListMetaCollectionsRequest
  * @return ListMetaCollectionsResponse
 */
async function listMetaCollections(request: ListMetaCollectionsRequest): ListMetaCollectionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListMetaCollections', 'GET', '/', 'json', false, 'json', request);
}

model ListNetworksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10', position='Query'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Query'),
  sortBy?: string(name='SortBy', description='The fields used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   Id (Desc/Asc): the network ID
*   Status (Desc/Asc): the network status
*   CreateUser (Desc/Asc): the user who created the network
*   CreateTime (Desc/Asc): the time when the network was created

Default value: CreateTime Asc.', example='CreateTime Asc', position='Query'),
}

model ListNetworksResponseBody = {
  pagingInfo?: {
    networkList?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the network resource was created. The value is a 64-bit timestamp.', example='1727055811000'),
        createUser?: string(name='CreateUser', description='The ID of the user who creates the network resource.', example='11075500042XXXXX'),
        id?: long(name='Id', description='The network ID.', example='1000'),
        resourceGroupId?: string(name='ResourceGroupId', description='The ID of the serverless resource group.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
        securityGroupId?: string(name='SecurityGroupId', description='The security group ID.', example='sg-2ze13vamugr7jenXXXXX'),
        status?: string(name='Status', description='The status of the network resource. Valid values: Pending, Creating, Running, Deleting, and Deleted.', example='Running'),
        vpcId?: string(name='VpcId', description='The ID of the virtual private cloud (VPC).', example='vpc-m2et4f3oc8msfbccXXXXX'),
        vswitchId?: string(name='VswitchId', description='The VSwitch ID.', example='vsw-uf8usrhs7hjd9amsXXXXX'),
      }
    ](name='NetworkList', description='The network resources of the serverless resource group.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListNetworksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListNetworksResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListNetworks  ListNetworksRequest
  * @return ListNetworksResponse
 */
async function listNetworks(request: ListNetworksRequest): ListNetworksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListNetworks', 'GET', '/', 'json', false, 'json', request);
}

model ListNodeDependenciesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number, starting from 1. Default value: 1.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10001', position='Query'),
}

model ListNodeDependenciesResponseBody = {
  pagingInfo?: {
    nodes?: [ 
      {
        createTime?: long(name='CreateTime', description='The timestamp when the node was created.', example='1724505917000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='odps_first'),
          type?: string(name='Type', description='The type of the data source.', example='odps'),
        }(name='DataSource', description='The data source.'),
        description?: string(name='Description', description='The description of the node.', example='Node description'),
        id?: long(name='Id', description='The ID of the node.', example='723932906364267XXXX'),
        inputs?: {
          nodeOutputs?: [ 
            {
              data?: string(name='Data', description='The node output.', example='860438872620113XXXX'),
            }
          ](name='NodeOutputs', description='The list of node outputs.'),
          tables?: [ 
            {
              guid?: string(name='Guid', description='The table ID.', example='odps.autotest.test_output_table_1'),
            }
          ](name='Tables', description='The table list.'),
          variables?: [ 
            {
              artifactType?: string(name='ArtifactType', description='The artifact type.', example='Variable'),
              id?: long(name='Id', description='The variable ID.', example='543218872620113XXXX'),
              name?: string(name='Name', description='The variable name.', example='input'),
              node?: {
                output?: string(name='Output', description='The output of the node.', example='860438872620113XXXX'),
              }(name='Node', description='The node to which the variable belongs.'),
              scope?: string(name='Scope', description='The scope of the variable. Valid values:

*   NodeParameter
*   NodeContext
*   Workflow
*   Workspace', example='NodeParameter'),
              type?: string(name='Type', description='The type of the variable. Valid values:

*   NoKvVariableExpression
*   Constant
*   PassThrough
*   System
*   NodeOutput', example='Constant'),
              value?: string(name='Value', description='The variable name.', example='111'),
            }
          ](name='Variables', description='The variable list.'),
        }(name='Inputs', description='The input of the node.'),
        modifyTime?: long(name='ModifyTime', description='The timestamp when the node was last modified.', example='1724505917000'),
        name?: string(name='Name', description='The name of the node.', example='Node name'),
        outputs?: {
          nodeOutputs?: [ 
            {
              data?: string(name='Data', description='The output of the node.', example='463497880880954XXXX'),
            }
          ](name='NodeOutputs', description='The list of node outputs.'),
          tables?: [ 
            {
              guid?: string(name='Guid', description='The table ID.', example='odps.autotest.test_output_table_1'),
            }
          ](name='Tables', description='The table list.'),
          variables?: [ 
            {
              artifactType?: string(name='ArtifactType', description='The artifact type.', example='Variable'),
              id?: long(name='Id', description='The variable ID.', example='543217824470354XXXX'),
              name?: string(name='Name', description='The variable name.', example='output'),
              node?: {
                output?: string(name='Output', description='The node output corresponding to the variable.', example='463497880880954XXXX'),
              }(name='Node', description='The node to which the variable belongs.'),
              scope?: string(name='Scope', description='The scope of the variable. Valid values:

*   NodeParameter
*   NodeContext
*   Workflow
*   Workspace', example='NodeParameter'),
              type?: string(name='Type', description='The type of the variable. Valid values:

*   NoKvVariableExpression
*   Constant
*   PassThrough
*   System
*   NodeOutput', example='Constant'),
              value?: string(name='Value', description='The value of the variable.', example='111'),
            }
          ](name='Variables', description='The variable list.'),
        }(name='Outputs', description='The output of the node.'),
        owner?: string(name='Owner', description='The owner of the node.', example='110755000425XXXX'),
        projectId?: long(name='ProjectId', description='The ID of the workspace to which the node belongs.', example='65133'),
        recurrence?: string(name='Recurrence', description='The scheduling type.

Valid values:

*   Normal: Nodes are scheduled as expected.
*   Pause: Nodes are paused, and the running of their descendant nodes is blocked.
*   Skip: Nodes are dry run. The system does not actually run the nodes but directly prompts that the nodes are successfully run. The running duration of the nodes is 0 seconds. In addition, the nodes do not occupy resources or block the running of their descendant nodes.', example='Normal'),
        runtimeResource?: {
          resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='S_res_group_XXXX_XXXX'),
        }(name='RuntimeResource', description='The information about the resource group.'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='853573334108680XXXX'),
          path?: string(name='Path', description='The script path.', example='root/demo'),
          runtime?: {
            command?: string(name='Command', description='The command used to distinguish node types.', example='ODPS_SQL'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information.'),
        strategy?: {
          instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
          rerunInterval?: int32(name='RerunInterval', description='The interval between retries after failure. Unit: milliseconds.', example='180000'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   Allowed
*   Denied
*   FailureAllowed', example='Allowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of retries after failure.', example='3'),
          timeout?: int32(name='Timeout', description='The timeout period. Unit: milliseconds.', example='0'),
        }(name='Strategy', description='The scheduling policy.'),
        tags?: [ 
          {
            key?: string(name='Key', description='The tag key.', example='null'),
            value?: string(name='Value', description='The tag value.', example='null'),
          }
        ](name='Tags', description='The tags. This parameter is not in use.'),
        taskId?: long(name='TaskId', description='The scheduling task ID.', example='580667964888595XXXX'),
        trigger?: {
          cron?: string(name='Cron', description='The cron expression for scheduling.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The effective end time of the schedule, in the format yyyy-MM-dd HH:mm:ss.', example='9999-01-01 00:00:00'),
          id?: long(name='Id', description='The unique identifier of the trigger.', example='543680677872062XXXX'),
          startTime?: string(name='StartTime', description='The effective start time of the schedule, in the format yyyy-MM-dd HH:mm:ss.', example='1970-01-01 00:00:00'),
          timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
          type?: string(name='Type', description='The trigger type.

Valid values:

*   Scheduler: periodic scheduling.
*   Manual: manual scheduling.
*   Streaming: streaming scheduler.', example='Scheduler'),
        }(name='Trigger', description='The trigger.'),
      }
    ](name='Nodes', description='The list of dependent nodes.'),
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='90'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='204EAF68-CCE3-5112-8DA0-E7A60F02XXXX'),
}

model ListNodeDependenciesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListNodeDependenciesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListNodeDependencies  ListNodeDependenciesRequest
  * @return ListNodeDependenciesResponse
 */
async function listNodeDependencies(request: ListNodeDependenciesRequest): ListNodeDependenciesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListNodeDependencies', 'GET', '/', 'json', false, 'json', request);
}

model ListNodesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  containerId?: long(name='ContainerId', description='The container ID, which is a filter condition. If you do not want to use this condition for filtering, you do not need to configure this parameter. The container ID that you specify is unrelated to the resource group ID indicated by the ResourceGroupId parameter.', example='860438872620113XXXX', position='Query'),
  name?: string(name='Name', description='The name of the node. Fuzzy search is supported.', example='test', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number of the data to retrieve, used for pagination.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default is 10, and the maximum is 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='12345', position='Query'),
  recurrence?: string(name='Recurrence', description='The scheduling type, which is a filter condition. Valid values:

*   Normal: The nodes are scheduled as expected.
*   Pause: The nodes are paused, and the running of their descendant nodes is blocked.
*   Skip: The nodes are dry run. The system does not actually run the nodes, but directly returns a success response. The running duration of the nodes is 0 seconds. In addition, the nodes do not occupy resources or block the running of their descendant nodes.', example='Normal', position='Query'),
  rerunMode?: string(name='RerunMode', description='The rerun property, which is a filter condition. If you do not want to use this condition for filtering, you do not need to configure this parameter. Valid values:

*   Allowed: The nodes can be rerun regardless of whether they are successfully run or fail to run.
*   FailureAllowed: The nodes can be rerun only after they fail to run.
*   Denied: The nodes cannot be rerun regardless of whether they are successfully run or fail to run.', example='Allowed', position='Query'),
  scene?: string(name='Scene', description='The location of the nodes in the left-side navigation pane of the Data Studio page, which is a filter condition. If you do not want to use this condition for filtering, you do not need to configure this parameter. Valid values:

*   DataworksProject
*   DataworksManualWorkflow
*   DataworksManualTask', example='DATAWORKS_PROJECT', position='Query'),
}

model ListNodesResponseBody = {
  pagingInfo?: {
    nodes?: [ 
      {
        createTime?: long(name='CreateTime', description='The timestamp when the node in DataStudio was created.', example='1722910655000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='odps_first'),
          type?: string(name='Type', description='The type of the data source.', example='odps'),
        }(name='DataSource', description='The data source.'),
        description?: string(name='Description', description='The description of the node.', example='Node description'),
        id?: long(name='Id', description='The ID of the node.', example='860438872620113XXXX'),
        inputs?: {
          nodeOutputs?: [ 
            {
              data?: string(name='Data', description='The node output.', example='623731286945488XXXX'),
            }
          ](name='NodeOutputs', description='The node output list.'),
          tables?: [ 
            {
              guid?: string(name='Guid', description='The table ID.', example='odps.autotest.test_output_table_1'),
            }
          ](name='Tables', description='The table list.'),
          variables?: [ 
            {
              artifactType?: string(name='ArtifactType', description='The artifact type.', example='Variable'),
              id?: long(name='Id', description='The variable ID.', example='543211286945488XXXX'),
              name?: string(name='Name', description='The name of the variable.', example='input'),
              node?: {
                output?: string(name='Output', description='The node output.', example='623731286945488XXXX'),
              }(name='Node', description='The node to which the variable belongs.'),
              scope?: string(name='Scope', description='The scope of the variable. Valid values:

*   WorkSpace
*   NodeParameter
*   NodeContext
*   Workflow', example='NodeParameter'),
              type?: string(name='Type', description='The type of the variable. Valid values:

*   NoKvVariableExpression
*   Constant
*   PassThrough
*   System
*   NodeOutput', example='Constant'),
              value?: string(name='Value', description='The variable value.', example='222'),
            }
          ](name='Variables', description='The variable list.'),
        }(name='Inputs', description='The node input.'),
        modifyTime?: long(name='ModifyTime', description='The timestamp when the node in DataStudio was last modified.', example='1722910655000'),
        name?: string(name='Name', description='The name of the node.', example='test'),
        outputs?: {
          nodeOutputs?: [ 
            {
              data?: string(name='Data', description='The node output.', example='860438872620113XXXX'),
            }
          ](name='NodeOutputs', description='The node output list.'),
          tables?: [ 
            {
              guid?: string(name='Guid', description='The table ID.', example='odps.autotest.test_output_table_1'),
            }
          ](name='Tables', description='The table list.'),
          variables?: [ 
            {
              artifactType?: string(name='ArtifactType', description='The artifact type.', example='Variable'),
              id?: long(name='Id', description='The variable ID.', example='623731286945488XXXX'),
              name?: string(name='Name', description='The name of the variable.', example='output'),
              node?: {
                output?: string(name='Output', description='The node output.', example='860438872620113XXXX'),
              }(name='Node', description='The node to which the variable belongs.'),
              scope?: string(name='Scope', description='The variable scope. Valid values:

*   NodeParameter
*   NodeContext
*   Workflow
*   Workspace', example='NodeParameter'),
              type?: string(name='Type', description='The variable type. Valid values:

*   NoKvVariableExpression
*   Constant
*   PassThrough
*   System
*   NodeOutput', example='Constant'),
              value?: string(name='Value', description='The variable value.', example='111'),
            }
          ](name='Variables', description='The variable list.'),
        }(name='Outputs', description='The node output.'),
        owner?: string(name='Owner', description='The owner of nodes in DataStudio.', example='110755000425XXXX'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.', example='33233'),
        recurrence?: string(name='Recurrence', description='The scheduling type.

Valid values:

*   Normal: The node is scheduled as expected.
*   Pause: The node is paused, and the running of its descendant nodes is blocked.
*   Skip: The node is dry run. The system does not actually run the node but directly prompts that the node is successfully run. The running duration of the node is 0 seconds. In addition, the node does not occupy resources or block the running of its descendant nodes.', example='Normal'),
        runtimeResource?: {
          resourceGroup?: string(name='ResourceGroup', description='The identifier of the resource group. You can call the [ListResourceGroups](https://help.aliyun.com/document_detail/173913.html) operation to query the identifier of the resource group.', example='S_res_group_XXXX'),
          resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='S_resgrop_xxx'),
        }(name='RuntimeResource', description='The information about the resource group.'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='853573334108680XXXX'),
          path?: string(name='Path', description='The script path.', example='root/demo'),
          runtime?: {
            command?: string(name='Command', description='The command used to distinguish node types.', example='ODPS_SQL'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information.'),
        strategy?: {
          instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: milliseconds.', example='180000'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   Allowed
*   Denied
*   FailureAllowed', example='Allowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of reruns.', example='3'),
          timeout?: int32(name='Timeout', description='Timeout.', example='0'),
        }(name='Strategy', description='The scheduling policy.'),
        tags?: [ 
          {
            key?: string(name='Key', description='The tag key.', example='null'),
            value?: string(name='Value', description='The tag value.', example='null'),
          }
        ](name='Tags', description='The tag information (not in use).'),
        taskId?: long(name='TaskId', description='The scheduling task ID.', example='88888888888'),
        trigger?: {
          cron?: string(name='Cron', description='The cron expression for scheduling', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the validity period of the trigger.', example='9999-01-01 00:00:00'),
          id?: long(name='Id', description='The trigger ID.', example='543680677872062XXXX'),
          startTime?: string(name='StartTime', description='The start time of the validity period of the trigger.', example='1970-01-01 00:00:00'),
          timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
          type?: string(name='Type', description='The trigger type.

Valid values:

*   Scheduler: periodic scheduling
*   Manual: manual trigger
*   Streaming: streaming task', example='Scheduler'),
        }(name='Trigger', description='The trigger.'),
      }
    ](name='Nodes', description='The list of nodes in DataStudio.'),
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='42'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='2197B9C4-39CE-55EA-8EEA-FDBAE52DXXXX'),
}

model ListNodesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListNodesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListNodes  ListNodesRequest
  * @return ListNodesResponse
 */
async function listNodes(request: ListNodesRequest): ListNodesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListNodes', 'GET', '/', 'json', false, 'json', request);
}

model ListPartitionsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  name?: string(name='Name', description='The partition name.', example='ds=20250101', position='Query'),
  order?: string(name='Order', description='The sort order. Default: Asc. Valid values:

*   Asc: Ascending order.
*   Desc: Descending order.', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default: 1.', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default: 10. Maximum: 100.', example='10', minimum=1, maximum=100, position='Query'),
  sortBy?: string(name='SortBy', description='The sort field. Default value: CreateTime. Valid values:

*   CreateTime: Creation time. Supported only for MaxCompute tables.
*   ModifyTime: Modification time. Supported only for MaxCompute tables.
*   Name: Name. Used for HMS-type tables.
*   RecordCount: Record count. Supported only for MaxCompute tables.
*   DataSize: Storage size. Supported only for MaxCompute tables.', example='CreateTime', position='Query'),
  tableId: string(name='TableId', description='The ID of the data table.You can refer to the ListTables API response and [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

This parameter is required.', example='maxcompute-column:11075xxxx::test_project:test_schema:test_table', position='Query'),
}

model ListPartitionsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    partitionList?: [
      Partition
    ](name='PartitionList', description='The list of table partitions.'),
    totalCount?: long(name='TotalCount', description='The total number of entries.', example='1'),
  }(name='PagingInfo', description='Pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='D1E2E5BC-xxxx-xxxx-xxxx-xxxxxx'),
  success?: boolean(name='Success', description='Indicates whether the request succeeded.', example='true'),
}

model ListPartitionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPartitionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListPartitions  ListPartitionsRequest
  * @return ListPartitionsResponse
 */
async function listPartitions(request: ListPartitionsRequest): ListPartitionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListPartitions', 'GET', '/', 'json', false, 'json', request);
}

model ListPipelineRunItemsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  pageNumber?: int32(name='PageNumber', description='The page number, for pagination.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. The number of entries per page. Default: 10. Maximum: 100.', example='10', minimum=10, maximum=100, position='Query'),
  pipelineRunId: string(name='PipelineRunId', description='The workflow task ID. To obtain the ID, see [ListPipelineRuns](https://help.aliyun.com/document_detail/438042.html).

This parameter is required.', example='097c73fe-ed6e-4fb1-b109-a5d59e46cd58', position='Query'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can obtain the workspace ID from the workspace configuration page in the DataWorks console.

This parameter is required.', example='10001', position='Query'),
}

model ListPipelineRunItemsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    pipelineRunItems?: [ 
      {
        createTime?: long(name='CreateTime', description='The deployment creation time.', example='1724984066000'),
        id?: long(name='Id', description='The unique identifier of the deployment.', example='860438872620113XXXX'),
        message?: string(name='Message', description='The error message if the deployment failed.', example='Error Message'),
        modifyTime?: long(name='ModifyTime', description='The time when the deployment was last modified.', example='1724984066000'),
        name?: string(name='Name', description='The deployment name.', example='test'),
        spec?: string(name='Spec', description='The FlowSpec information describing this deployment. For detailed specifications, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).', example='{ "version": "1.1.0", "kind": "Node", "spec": { "nodes": [ { "recurrence": "Normal", "id": "860438872620113XXXX", "timeout": 0, "instanceMode": "T+1", "rerunMode": "Allowed", "rerunTimes": 3, "rerunInterval": 180000, "datasource": { "name": "odps_test", "type": "odps" }, "script": { "language": "odps-sql", "path": "XX/OpenAPI_Test/ODPS_SQL_Test", "runtime": { "command": "ODPS_SQL", "commandTypeId": 10 }, "content": "select now();", "id": "853573334108680XXXX" }, "trigger": { "type": "Scheduler", "id": "543680677872062XXXX", "cron": "00 00 00 * * ?", "startTime": "1970-01-01 00:00:00", "endTime": "9999-01-01 00:00:00", "timezone": "Asia/Shanghai", "delaySeconds": 0 }, "runtimeResource": { "resourceGroup": "S_res_group_XXXX_XXXX", "id": "623731286945488XXXX", "resourceGroupId": "7201XXXX" }, "name": "ODPS_SQL_Test", "owner": "110755000425XXXX", "metadata": { "owner": "110755000425XXXX", "ownerName": "XXXXX@test.XXX.com", "projectId": "307XXX" }, "inputs": { "nodeOutputs": [ { "data": "lwttest_standard_root", "artifactType": "NodeOutput" } ] }, "outputs": { "nodeOutputs": [ { "data": "860438872620113XXXX", "artifactType": "NodeOutput", "refTableName": "ODPS_SQL_Test", "isDefault": true } ] } } ], "flow": [ { "nodeId": "860438872620113XXXX", "depends": [ { "type": "Normal", "output": "lwttest_standard_root" } ] } ] }, "metadata": { "uuid": "860438872620113XXXX" } }'),
        status?: string(name='Status', description='The deployment status. Valid values:

*   Init: Initializing
*   Running
*   Success
*   Fail
*   Termination', example='Running'),
        type?: string(name='Type', description='The deployment type. Valid values:

*   Node
*   WorkflowDefinition: Workflow definition.
*   Resource
*   Function: The object is a function.', example='Node'),
        version?: long(name='Version', description='The deployment version.', example='1'),
      }
    ](name='PipelineRunItems', description='The list of deployments.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries that match the conditions.', example='12'),
  }(name='PagingInfo', description='Pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use this ID to troubleshoot issues if errors occur.', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADE490'),
}

model ListPipelineRunItemsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPipelineRunItemsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListPipelineRunItems  ListPipelineRunItemsRequest
  * @return ListPipelineRunItemsResponse
 */
async function listPipelineRunItems(request: ListPipelineRunItemsRequest): ListPipelineRunItemsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListPipelineRunItems', 'GET', '/', 'json', false, 'json', request);
}

model ListPipelineRunsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  creator?: string(name='Creator', description='The ID of the user who creates the processes. This parameter specifies a filter condition.', example='110755000425****', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Query'),
  status?: string(name='Status', description='The status of the processes. This parameter specifies a filter condition.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='Running', position='Query'),
}

model ListPipelineRunsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    pipelineRuns?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the process was created. This value is a UNIX timestamp.', example='1702736654000'),
        creator?: string(name='Creator', description='The creator of the process.', example='110755000425XXXX'),
        id?: string(name='Id', description='The process ID.', example='097c73fe-ed6e-4fb1-b109-a5d59e46cd58'),
        message?: string(name='Message', description='The error message returned during the stage.', example='Error message'),
        modifyTime?: long(name='ModifyTime', description='The time when the process was modified. This value is a UNIX timestamp.', example='1702736654000'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='70199'),
        stages?: [ 
          {
            code?: string(name='Code', description='The code of the stage.', example='DEV_CHECK'),
            description?: string(name='Description', description='The description of the stage.', example='Check before going online to development'),
            detail?: map[string]any(name='Detail', description='The additional information about the stage.'),
            message?: string(name='Message', description='The error message returned during the stage.', example='Error message'),
            name?: string(name='Name', description='The name of the stage.', example='Check before going online to development'),
            status?: string(name='Status', description='The status of the stage.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='Running'),
            step?: int32(name='Step', description='The step number of the stage.', example='1'),
            type?: string(name='Type', description='The type of the stage. This parameter indicates the operation type in the stage.

Valid values:

*   Deploy
*   Check
*   Offline
*   Build
*   Delete', example='Check'),
          }
        ](name='Stages', description='The stages of the process.'),
        status?: string(name='Status', description='The status of the process.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='Running'),
      }
    ](name='PipelineRuns', description='The processes.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='2524'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7C352CB7-CD88-50CF-9D0D-E81BDF02XXXX'),
}

model ListPipelineRunsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListPipelineRunsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListPipelineRuns  ListPipelineRunsRequest
  * @return ListPipelineRunsResponse
 */
async function listPipelineRuns(request: ListPipelineRunsRequest): ListPipelineRunsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListPipelineRuns', 'GET', '/', 'json', false, 'json', request);
}

model ListProjectMembersRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='62136', position='Body'),
  roleCodes?: [ string ](name='RoleCodes', description='The codes of the roles in the workspace. You can call the [ListProjectRoles](https://help.aliyun.com/document_detail/2853930.html) operation to query the codes of all roles in the workspace.', shrink='json', position='Body'),
  userIds?: [ string ](name='UserIds', description='The IDs of the accounts used by the members in the workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the Tenant Members and Roles page, view the IDs of the accounts used by the members in the workspace.', shrink='json', position='Body'),
}

model ListProjectMembersResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    projectMembers?: [ 
      {
        projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace.', example='62136'),
        roles?: [ 
          {
            code?: string(name='Code', description='The code of the role.', example='role_project_guest'),
            name?: string(name='Name', description='The name of the role.', example='Visitors'),
            type?: string(name='Type', description='The type of the role. Valid values:

*   UserCustom: user-defined role
*   System: system role', example='System'),
          }
        ](name='Roles', description='The roles that are assigned to the member.'),
        status?: string(name='Status', description='The status of the member. Valid values:

*   Normal
*   Forbidden', example='Normal'),
        userId?: string(name='UserId', description='The ID of the account used by the member.', example='123422344899'),
        userName?: string(name='UserName'),
      }
    ](name='ProjectMembers', description='The members in the workspace.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='12'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='9FBBBB1F-DD5E-5D8E-8F50-37F77460F056'),
}

model ListProjectMembersResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListProjectMembersResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListProjectMembers  ListProjectMembersRequest
  * @return ListProjectMembersResponse
 */
async function listProjectMembers(request: ListProjectMembersRequest): ListProjectMembersResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListProjectMembers', 'POST', '/', 'json', true, 'form', request);
}

model ListProjectRolesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  codes?: [ string ](name='Codes', description='The codes of roles in the DataWorks workspace.', shrink='json', position='Body'),
  names?: [ string ](name='Names', description='The names of roles in the DataWorks workspace.', shrink='json', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='21229', position='Body'),
  type?: string(name='Type', description='The type of the role. Valid values:

*   UserCustom: user-defined role
*   System: system role', example='System', position='Body'),
}

model ListProjectRolesResponseBody = {
  pagingInfo?: {
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    projectRoles?: [ 
      {
        code?: string(name='Code', description='The code of the role in the DataWorks workspace.', example='role_project_guest'),
        name?: string(name='Name', description='The name of the role.', example='Visitors'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='21229'),
        type?: string(name='Type', description='The type of the role in the DataWorks workspace.', example='System'),
      }
    ](name='ProjectRoles', description='The roles in the DataWorks workspace.'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='42'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='61649187-0BCF-5E75-8D4B-64FDBEBBB447'),
}

model ListProjectRolesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListProjectRolesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListProjectRoles  ListProjectRolesRequest
  * @return ListProjectRolesResponse
 */
async function listProjectRoles(request: ListProjectRolesRequest): ListProjectRolesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListProjectRoles', 'POST', '/', 'json', true, 'form', request);
}

model ListProjectsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group to which the workspaces belong. You can log on to the [Resource Management console](https://resourcemanager.console.aliyun.com/resource-groups) and go to the Resource Group page to query the ID.

This parameter is used to query the information about workspaces that belong to a specific resource group.', example='rg-acfmzbn7pti3zff', position='Body'),
  aliyunResourceTags?: [ 
    {
      key?: string(name='Key', description='The tag key.', example='batch'),
      value?: string(name='Value', description='The tag value.', example='blue'),
    }
  ](name='AliyunResourceTags', description='The tags.', shrink='json', position='Body'),
  devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Specifies whether the development environment is enabled. Valid values:

*   true: The development environment is enabled. In this case, the development environment is isolated from the production environment in a workspace.
*   false: The development environment is disabled. In this case, only the production environment is used in a workspace.', example='true', position='Body'),
  devRoleDisabled?: boolean(name='DevRoleDisabled', description='Specifies whether the Develop role is disabled. Valid values:

*   false (default)
*   true', example='false', position='Body'),
  ids?: [ long ](name='Ids', description='The IDs of the DataWorks workspaces.', shrink='json', position='Body'),
  names?: [ string ](name='Names', description='The names of the DataWorks workspaces.', shrink='json', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Body'),
  paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Specifies whether scheduling of Platform for AI (PAI) tasks is enabled. Valid values:

*   true: Scheduling of PAI tasks is enabled. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: Scheduling of PAI tasks is disabled.', example='true', position='Body'),
  status?: string(name='Status', description='The status of the workspaces. Valid values:

*   Available
*   Initializing
*   InitFailed
*   Forbidden
*   Deleting
*   DeleteFailed
*   Frozen
*   Updating
*   UpdateFailed', example='Available', position='Body'),
}

model ListProjectsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='10'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='1'),
    projects?: [ 
      {
        aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group to which the workspace belongs.', example='rg-acfmzbn7pti3zfa'),
        aliyunResourceTags?: [ 
          {
            key?: string(name='Key', description='The tag key.', example='batch'),
            value?: string(name='Value', description='The tag value.', example='blue'),
          }
        ](name='AliyunResourceTags', description='The tags.'),
        description?: string(name='Description', description='The description of the workspace.', example='Financial analysis group project data development'),
        devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Indicates whether the development environment is enabled. Valid values:

*   true: The development environment is enabled. In this case, the development environment is isolated from the production environment in the workspace.
*   false: The development environment is disabled. In this case, only the production environment is used in the workspace.', example='true'),
        devRoleDisabled?: boolean(name='DevRoleDisabled', description='Indicates whether the Develop role is disabled. Valid values:

*   false (default)
*   true', example='false'),
        displayName?: string(name='DisplayName', description='The display name of the workspace.', example='Sora financial analysis'),
        id?: long(name='Id', description='The workspace ID.', example='123456'),
        name?: string(name='Name', description='The name of the workspace.', example='sora_finance'),
        owner?: string(name='Owner', description='The ID of the Alibaba Cloud account to which the workspace belongs.', example='123532153125'),
        paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Indicates whether scheduling of PAI tasks is enabled. Valid values:

*   true: Scheduling of PAI tasks is enabled. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: Scheduling of PAI tasks is disabled.', example='true'),
        status?: string(name='Status', description='The status of the workspace. Valid values:

*   Available
*   Initializing
*   InitFailed
*   Forbidden
*   Deleting
*   DeleteFailed
*   Frozen
*   Updating
*   UpdateFailed', example='Available'),
      }
    ](name='Projects', description='The workspaces.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='6D24AD9A-652F-59E2-AC1F-05029300F8A4'),
}

model ListProjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListProjectsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListProjects  ListProjectsRequest
  * @return ListProjectsResponse
 */
async function listProjects(request: ListProjectsRequest): ListProjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListProjects', 'POST', '/', 'json', true, 'form', request);
}

model ListResourceGroupAssociateProjectsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the serverless resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003****', position='Query'),
}

model ListResourceGroupAssociateProjectsResponseBody = {
  projectIdList?: [ long ](name='ProjectIdList', description='The list of workspace IDs.'),
  requestId?: string(name='RequestId', description='The request ID. You can use this ID to troubleshoot issues.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListResourceGroupAssociateProjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListResourceGroupAssociateProjectsResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  **Make sure that the AliyunServiceRoleForDataWorks service-linked role is created before you call this operation.
  * @param request  the request parameters of ListResourceGroupAssociateProjects  ListResourceGroupAssociateProjectsRequest
  * @return ListResourceGroupAssociateProjectsResponse
 */
async function listResourceGroupAssociateProjects(request: ListResourceGroupAssociateProjectsRequest): ListResourceGroupAssociateProjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListResourceGroupAssociateProjects', 'POST', '/', 'json', false, 'json', request);
}

model ListResourceGroupMetricDataRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  beginTime?: long(name='BeginTime', description='Start Time

Supported format:

*   Unix timestamp, representing the number of milliseconds that have elapsed since January 1, 1970.

The interval between BeginTime and EndTime must be 31 days or less.

Default: The current time minus 2 hours, expressed as a millisecond Unix timestamp.', example='1593950832000', minimum=0, position='Body'),
  endTime?: long(name='EndTime', description='End Time

Supported format:

*   Unix timestamp, representing the number of milliseconds that have elapsed since January 1, 1970.

The interval between BeginTime and EndTime must be 31 days or less.

Default: The current time, expressed as a millisecond Unix timestamp.', example='1750176000000', minimum=0, position='Body'),
  length?: int32(name='Length', example='100', minimum=0, maximum=1440, position='Body'),
  metricName: string(name='MetricName', description='The metric name. Available metrics include:

*   CUSpec: Maximum CU capacity of the resource group, in CUs.
*   CUUsage: CU usage of the resource group, in CUs.
*   CUUtilization: CU utilization of the resource group, in %.
*   SlotSpec: Maximum concurrency for resource group scheduling, in slots.
*   SlotUsage: Used concurrency for resource group scheduling, in slots.
*   SchedulerCUMaxSpec: Maximum CU quota for data computing, in CUs.
*   SchedulerCUUsage: CU usage for data computing, in CUs.
*   SchedulerCUMinSpec: Minimum guaranteed CUs for data computing, in CUs.
*   DataIntegrationCUMaxSpec: Maximum CU quota for Data Integration, in CUs.
*   DataIntegrationCUUsage: CU usage for Data Integration, in CUs.
*   DataIntegrationCUMinSpec: Minimum guaranteed CUs for Data Integration, in CUs.
*   DataServiceCUMaxSpec: Maximum CU quota for dataservice, in CUs.
*   DataServiceCUUsage: CU usage for DataService Studio, in CUs.
*   DataServiceCUMinSpec: Minimum guaranteed CUs for DataService Studio, in CUs.
*   ServerIdeCUMaxSpec: Maximum CU quota for personal development environment, in CUs.
*   ServerIdeCUUsage: CU usage for personal development environment, in CUs.
*   ServerIdeCUMinSpec: Minimum guaranteed CUs for personal development environment, in CUs.

This parameter is required.', example='CUSpec', position='Body'),
  nextToken?: string(name='NextToken', example='FFqBJBxE8I0PE0IUO6K69k7m2FfyWNNc2qQ9ReUkazhz9VA7dWZKlxBcjUwOV0imSM', position='Body'),
  period?: string(name='Period', description='The statistical period for monitoring data.

Value: A multiple of 60.

Unit: Seconds.

Default: 60', example='60', position='Body'),
  resourceGroupId: string(name='ResourceGroupId', description='This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
}

model ListResourceGroupMetricDataResponseBody = {
  metricData?: {
    id?: string(name='Id', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
    metricName?: string(name='MetricName', description='The metric name. Available metrics include:

*   CUSpec: Maximum CU capacity of the resource group, in CUs.
*   CUUsage: CU usage of the resource group, in CUs.
*   CUUtilization: CU utilization of the resource group, in %.
*   SlotSpec: Maximum concurrency for resource group scheduling, in slots.
*   SlotUsage: Used concurrency for resource group scheduling, in slots.
*   SchedulerCUMaxSpec: Maximum CU quota for data computing, in CUs.
*   SchedulerCUUsage: CU usage for data computing, in CUs.
*   SchedulerCUMinSpec: Minimum guaranteed CUs for data computing, in CUs.
*   DataIntegrationCUMaxSpec: Maximum CU quota for Data Integration, in CUs.
*   DataIntegrationCUUsage: CU usage for Data Integration, in CUs.
*   DataIntegrationCUMinSpec: Minimum guaranteed CUs for Data Integration, in CUs.
*   DataServiceCUMaxSpec: Maximum CU quota for DataService Studio, in CUs.
*   DataServiceCUUsage: CU usage for DataService Studio, in CUs.
*   DataServiceCUMinSpec: Minimum guaranteed CUs for DataService Studio, in CUs.
*   ServerIdeCUMaxSpec: Maximum CU quota for personal development environment, in CUs.
*   ServerIdeCUUsage: CU usage for personal development environment, in CUs.
*   ServerIdeCUMinSpec: Minimum guaranteed CUs for personal development environment, in CUs.', example='CUSpec'),
    metrics?: [ 
      {
        timestamp?: long(name='Timestamp', example='1761184929633'),
        value?: double(name='Value', example='1.0'),
      }
    ](name='Metrics'),
    nextToken?: string(name='NextToken', example='tSBOXZcAmk+akxRkwRuXnGQEsIDODyd5ulPqgytNTbLp4bhb7fuvz13FXtm87Kfl'),
  }(name='MetricData', description='Monitoring metric data.'),
  requestId?: string(name='RequestId', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', example='true'),
}

model ListResourceGroupMetricDataResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListResourceGroupMetricDataResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListResourceGroupMetricData  ListResourceGroupMetricDataRequest
  * @return ListResourceGroupMetricDataResponse
 */
async function listResourceGroupMetricData(request: ListResourceGroupMetricDataRequest): ListResourceGroupMetricDataResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListResourceGroupMetricData', 'POST', '/', 'json', true, 'form', request);
}

model ListResourceGroupsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='Alibaba Cloud Resource Group ID', example='rg-aek2kqofrgXXXXX', position='Query'),
  aliyunResourceTags?: [ 
    {
      key?: string(name='Key', description='Tag Key', example='key'),
      value?: string(name='Value', description='Tag Value', example='value'),
    }
  ](name='AliyunResourceTags', description='Alibaba Cloud tag list', shrink='json', position='Query'),
  name?: string(name='Name', description='The name of a resource group, which is used for fuzzy match.', example='Resource', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100', position='Query'),
  paymentType?: string(name='PaymentType', description='The billing method of resource groups. Valid values:

*   PrePaid
*   PostPaid', example='PrePaid', position='Query'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace.', example='1000', position='Query'),
  resourceGroupTypes?: [ string ](name='ResourceGroupTypes', description='The types of resource groups to query. If you do not configure this parameter, only serverless resource groups are returned by default.', shrink='json', position='Query'),
  sortBy?: string(name='SortBy', description='The list of fields used for sorting. Fields such as TriggerTime and StartedTime are supported. You must configure this parameter in the Sorting field + Sort by (Desc/Asc). By default, results are sorted in ascending order. Valid values:

*   Id (Desc/Asc): the resource group ID
*   Name (Desc/Asc): the name of the resource group
*   Remark (Desc/Asc): the remarks of the resource group
*   Type (Desc/Asc): the type of the resource group
*   Status (Desc/Asc): the status of the resource group
*   Spec (Desc/Asc): the specifications of the resource group
*   CreateUser (Desc/Asc): the creator of the resource group
*   CreateTime (Desc/Asc): the time when the resource group is created

Default value: CreateTime Asc', example='CreateTime Asc', position='Query'),
  statuses?: [ string ](name='Statuses', description='The statuses of resource groups.', shrink='json', position='Query'),
}

model ListResourceGroupsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100'),
    resourceGroupList?: [ 
      {
        aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='Alibaba Cloud Resource Group ID', example='rg-aek2kqofrgXXXXX'),
        aliyunResourceTags?: [ 
          {
            key?: string(name='Key', description='Tag Key', example='Key'),
            value?: string(name='Value', description='Tag Value', example='Value'),
          }
        ](name='AliyunResourceTags', description='Alibaba Cloud tag list'),
        createTime?: long(name='CreateTime', description='The creation time, which is a 64-bit timestamp.', example='1727055811000'),
        createUser?: string(name='CreateUser', description='The ID of the user who created the resource group.', example='11075500042XXXXX'),
        defaultVpcId?: string(name='DefaultVpcId', description='Default VPC ID bound to a common resource group', example='vpc-m2et4f3oc8msfbccXXXXX'),
        defaultVswicthId?: string(name='DefaultVswicthId', description='The default switch ID bound to the common resource group.', example='vsw-uf8usrhs7hjd9amsXXXXX'),
        id?: string(name='Id', description='Unique identifier of a resource group', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
        name?: string(name='Name', description='The name of the resource group.', example='common_resource_group'),
        orderInstanceId?: string(name='OrderInstanceId', description='The order instance ID of the resource group.', example='c442b330-3b10-4584-959e-736e4edXXXXX'),
        paymentType?: string(name='PaymentType', description='The billing method of the resource group. Valid values: PrePaid and PostPaid. The value PrePaid indicates the subscription billing method, and the value PostPaid indicates the pay-as-you-go billing method.', example='PrePaid'),
        remark?: string(name='Remark', description='Remarks for resource groups', example='Create a common resource group for common tasks'),
        resourceGroupType?: string(name='ResourceGroupType', description='Resource group types:

*   CommonV2: Serverless resource group
*   ExclusiveDataIntegration: Exclusive resource group for Data Integration
*   ExclusiveScheduler: Exclusive resource group for scheduling
*   ExclusiveDataService: Exclusive resource group for DataService Studio', example='CommonV2'),
        spec?: {
          amount?: int32(name='Amount', description='Quantity', example='1'),
          standard?: string(name='Standard', description='Specification details', example='2CU'),
        }(name='Spec', description='Resource Group specifications'),
        status?: string(name='Status', description='The status of the resource group. Valid values:

*   Normal: The resource group is running or in use.
*   Stop: The resource group is expired.
*   Deleted: The resource group is released or destroyed.
*   Creating: The resource group is being created.
*   CreateFailed: The resource group fails to be created.
*   Updating: The resource group is being scaled in or out, or the configurations of the resource group are being changed.
*   UpdateFailed: The resource group fails to be scaled out or upgraded.
*   Deleting: The resource group is being released or destroyed.
*   DeleteFailed: The resource group fails to be released or destroyed.
*   Timeout: The operations that are performed on the resource group time out.
*   Freezed: The resource group is frozen.
*   Starting: The resource group is being started.', example='Normal'),
      }
    ](name='ResourceGroupList', description='The resource groups returned.'),
    totalCount?: int32(name='TotalCount', description='All data entries', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true and false.', example='true'),
}

model ListResourceGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListResourceGroupsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListResourceGroups  ListResourceGroupsRequest
  * @return ListResourceGroupsResponse
 */
async function listResourceGroups(request: ListResourceGroupsRequest): ListResourceGroupsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListResourceGroups', 'GET', '/', 'json', false, 'json', request);
}

model ListResourcesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  name?: string(name='Name', position='Query'),
  owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the workspace administrator. You can log on to the Alibaba Cloud Management Console and view the ID on the Security Settings page.', example='110755000425XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Valid values: 1 to 100. Default value: 10.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10002', position='Query'),
  type?: string(name='Type', description='The resource type. This parameter specifies a filter condition.

Valid values:

*   Python
*   Jar
*   Archive
*   File', example='python', position='Query'),
}

model ListResourcesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    resources?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the file resource was created. This value is a UNIX timestamp.', example='1724505917000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='odps_first'),
          type?: string(name='Type', description='The type of the data source.', example='odps'),
        }(name='DataSource', description='The information about the data source.'),
        id?: long(name='Id', description='The ID of the file resource.', example='631478864897630XXXX'),
        modifyTime?: long(name='ModifyTime', description='The times when the file resource was last modified. This value is a UNIX timestamp.', example='1724505917000'),
        name?: string(name='Name', description='The name of the file resource.', example='math.py'),
        owner?: string(name='Owner', description='The owner of the file resource.', example='110755000425XXXX'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID.', example='344247'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='123348864897630XXXX'),
          path?: string(name='Path', description='The script path.', example='root/demo'),
          runtime?: {
            command?: string(name='Command', description='The command used to distinguish file resource types.', example='ODPS_PYTHON'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information.'),
        sourcePath?: string(name='SourcePath', description='The path of the source of the file resource. If the SourecType parameter is set to Local, this parameter is left empty.', example='XXX/unknown/ide/1/XXX/20240820200851_963a9da676de44ef8d06a6576a8c4d6a.py'),
        sourceType?: string(name='SourceType', description='The storage type of the source of the file resource.

Valid values:

*   Local
*   Oss', example='local'),
        targetPath?: string(name='TargetPath', description='The storage path of the destination of the file resource.', example='XXX/unknown/ide/1/XXX/20240820200851_963a9da676de44ef8d06a6576a8c4d6a.py'),
        targetType?: string(name='TargetType', description='The storage type of the destination of the file resource.

Valid values:

*   Gateway
*   Oss
*   Hdfs', example='oss'),
        type?: string(name='Type', description='The type of the file resource.

Valid values:

*   Python
*   Jar
*   Archive
*   File', example='jar'),
      }
    ](name='Resources', description='The queried file resources.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='131'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='99EBE7CF-69C0-5089-BE3E-79563C31XXXX'),
}

model ListResourcesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListResourcesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListResources  ListResourcesRequest
  * @return ListResourcesResponse
 */
async function listResources(request: ListResourcesRequest): ListResourcesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListResources', 'GET', '/', 'json', false, 'json', request);
}

model ListRoutesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  networkId?: long(name='NetworkId', description='The network ID.', example='1000', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100', position='Query'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Query'),
  sortBy?: string(name='SortBy', description='The fields used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   Id (Desc/Asc): the route ID
*   DestinationCidr (Desc/Asc): the destination CIDR block of the route
*   CreateTime (Desc/Asc): the time when the route is created

Default value: CreateTime Asc.', example='CreateTime Asc', position='Query'),
}

model ListRoutesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100'),
    routeList?: [ 
      {
        createTime?: long(name='CreateTime', description='The creation time, which is a 64-bit timestamp.', example='1727055811000'),
        destinationCidr?: string(name='DestinationCidr', description='Route destination CIDR', example='192.168.0.0/16'),
        id?: long(name='Id', description='Route ID', example='1000'),
        networkId?: long(name='NetworkId', description='Network Resource ID', example='1000'),
        resourceGroupId?: string(name='ResourceGroupId', description='Unique identifier of the resource group to which it belongs', example='Serverless_res_group_524257424564736_6831777003****'),
        resourceId?: string(name='ResourceId', description='Unique identifier of network resource', example='ns-679XXXXXX'),
      }
    ](name='RouteList', description='The list of network resource routing information obtained.'),
    totalCount?: int32(name='TotalCount', description='All data entries', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListRoutesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListRoutesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListRoutes  ListRoutesRequest
  * @return ListRoutesResponse
 */
async function listRoutes(request: ListRoutesRequest): ListRoutesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListRoutes', 'GET', '/', 'json', false, 'json', request);
}

model ListSchemasRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The comment. Fuzzy match is supported.', example='test comment', position='Query'),
  name?: string(name='Name', description='The name. Fuzzy match is supported.', example='abc', position='Query'),
  order?: string(name='Order', description='The order in which schemas are sorted. Default value: Asc. Valid values:

*   Asc: ascending order
*   Desc: descending order', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
  parentMetaEntityId: string(name='ParentMetaEntityId', description='The parent entity ID. For more information, see [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html). For the Hologres metadata crawler type, you can call the ListDatabases operation to query the settings of the `ParentMetaEntityId` parameter.

Configure the `ParentMetaEntityId` parameter in the `${EntityType}:${Instance ID or escaped URL}:${Catalog identifier}:${Database name}` format. If a level does not exist, leave the level empty.

>  If you want to query the information about a MaxCompute schema, specify an empty string at the Instance ID level as a placeholder and a MaxCompute project name at the Database name level. Make sure that the schema feature is enabled for the MaxCompute project.

This parameter is required.', example='maxcompute-project:123456XXX::test_project
holo-database:h-abc123xxx::test_db', position='Query'),
  sortBy?: string(name='SortBy', description='The field used for sorting. Default value: CreateTime. Valid values:

*   CreateTime
*   ModifyTime
*   Name
*   Type', example='CreateTime', position='Query'),
  types?: [ string ](name='Types', description='The types. Exact match is supported. If this parameter is left empty, all types are queried.', shrink='simple', position='Query'),
}

model ListSchemasResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    schemas?: [
      Schema
    ](name='Schemas', description='The schemas.'),
    totalCount?: long(name='TotalCount', example='1'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='235BBA5E-3428-XXXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListSchemasResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListSchemasResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListSchemas  ListSchemasRequest
  * @return ListSchemasResponse
 */
async function listSchemas(request: ListSchemasRequest): ListSchemasResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListSchemas', 'GET', '/', 'json', false, 'json', request);
}

model ListTablesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The comment. Supports fuzzy matching.', example='this is a comment', position='Query'),
  name?: string(name='Name', description='The name. Supports fuzzy matching.', example='abc', position='Query'),
  order?: string(name='Order', description='The order in which the tables are sorted. Default value: Asc. Valid values:

*   Asc
*   Desc', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of records per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
  parentMetaEntityId: string(name='ParentMetaEntityId', description='The parent metadata entity ID. You can refer to the responses of the ListDatabases or ListSchemas operation and [Description of concepts related to metadata entities.](https://help.aliyun.com/document_detail/2880092.html)

*   The parent metadata entity is a database: The format of `ParentMetaEntityId` is `${EntityType}:${Instance ID or encoded URL}:${Catalog Identifier}:${Database Name}`. Use an empty string (\\`""\\`) as a placeholder for any non-existent level.
*   The parent metadata entity is a database schema: The format of `ParentMetaEntityId` is `${EntityType}:${Instance ID or encoded URL}:${Catalog Identifier}:${Database Name}:${Schema Name}`. Use an empty string (\\`""\\`) as a placeholder for any non-existent level.

> 

*   The schema level in `ParentMetaEntityId` is supported only for database services, such as `MaxCompute (with schema enabled), Hologres, PostgreSQL, SQL Server, HybridDB for PostgreSQL, and Oracle`.

*   For the MaxCompute and DLF types, use an empty string as the placeholder for the instance ID. For MaxCompute, the database name is the same as the project name.

*   For StarRocks, the catalog identifier is the catalog name. For DLF, it is the catalog ID. Other types do not support the catalog level and you can use an empty string as a placeholder.

Examples of common ParentMetaEntityId formats

*   `maxcompute-project:::project_name`
*   `maxcompute-schema:::project_name:schema_name` (for MaxCompute projects with schema enabled)
*   `dlf-database::catalog_id:database_name`
*   `hms-database:instance_id::database_name`
*   `holo-schema:instance_id::database_name:schema_name`
*   `mysql-database:(instance_id|encoded_jdbc_url)::database_name`

> 

*   `instance_id`: The instance ID, which is required when the data source is registered in instance mode.

*   `encoded_jdbc_url`: The URLEncoded JDBC connection string, which is requiredwhen the data source is registered using a connection string.

*   `catalog_id`: The DLF catalog ID.

*   `project_name`: The MaxCompute project name.

*   `database_name`: The database name.

*   `schema_name`: The schema name.

This parameter is required.', example='maxcompute-schema:123456XXX::test_project_with_schema:default
maxcompute-project:123456XXX::test_project_without_schema
dlf-database:123456XXX:test_catalog:test_db
hms-database:c-abc123xxx::test_db
holo-schema:h-abc123xxx::test_db:test_schema
mysql-database:jdbc%3Amysql%3A%2F%2F127.0.0.1%3A3306%2Ftest_db::test_db', position='Query'),
  sortBy?: string(name='SortBy', description='The sort field. Default value: CreateTime. Valid values:

*   CreateTime
*   ModifyTime
*   Name
*   TableType', example='CreateTime', position='Query'),
  tableTypes?: [ string ](name='TableTypes', description='The list of table types to query. If it\\"s left empty, all types will be queried.', shrink='simple', position='Query'),
}

model ListTablesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of records per page.', example='10'),
    tables?: [
      Table
    ](name='Tables', description='The list of data tables.'),
    totalCount?: long(name='TotalCount', description='The total number of records returned.', example='100'),
  }(name='PagingInfo', description='The pagination result.'),
  requestId?: string(name='RequestId', description='The request ID.', example='E25887B7-579C-54A5-9C4F-83A****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListTablesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTablesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListTables  ListTablesRequest
  * @return ListTablesResponse
 */
async function listTables(request: ListTablesRequest): ListTablesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTables', 'GET', '/', 'json', false, 'json', request);
}

model ListTaskInstanceOperationLogsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  date?: long(name='Date', description='The operation date, accurate to the day. The default value is the current day. You can query only the operation logs generated within the previous 31 days. This value is a UNIX timestamp.', example='1710239005403', position='Query'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
}

model ListTaskInstanceOperationLogsResponseBody = {
  pagingInfo?: {
    operationLogs?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the operation log was generated.', example='1710239005403'),
        operationContent?: string(name='OperationContent', description='The operation content.', example='Freeze tasks'),
        operationSeq?: long(name='OperationSeq', description='The serial number of the operation.', example='1111'),
        taskInstanceId?: long(name='TaskInstanceId', description='The ID of the instance on which the operation was performed.', example='1234'),
        user?: string(name='User', description='The account ID of the operator.', example='1000'),
      }
    ](name='OperationLogs', description='The operation logs.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListTaskInstanceOperationLogsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTaskInstanceOperationLogsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * You can call this operation to query only the operation logs generated within the previous 31 days.
  * @param request  the request parameters of ListTaskInstanceOperationLogs  ListTaskInstanceOperationLogsRequest
  * @return ListTaskInstanceOperationLogsResponse
 */
async function listTaskInstanceOperationLogs(request: ListTaskInstanceOperationLogsRequest): ListTaskInstanceOperationLogsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTaskInstanceOperationLogs', 'GET', '/', 'json', false, 'json', request);
}

model ListTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  bizdate: long(name='Bizdate', description='The data timestamp. The value of this parameter is 00:00:00 of the day before the scheduling time of the instance. The value is a UNIX timestamp. Unit: milliseconds. Example: 1743350400000.

This parameter is required.', example='1710239005403', position='Body'),
  filter?: string(name='Filter', position='Body'),
  id?: long(name='Id', description='The ID of the instance. The instance may be rerun. If the instance is rerun and you configure this parameter, the system returns the historical information of the instance, including the rerun information. You can use the RunNumber parameter to distinguish each entry in the historical information.', example='1234', position='Body'),
  ids?: [ long ](name='Ids', description='The IDs of the instances. You can query multiple instances at a time by instance ID.', shrink='json', position='Body'),
  owner?: string(name='Owner', description='The account ID of the task owner.', example='1000', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='100', position='Body'),
  runtimeResource?: string(name='RuntimeResource', description='The information about the resource group. Set this parameter to the identifier of a resource group for scheduling.', example='S_res_group_524258031846018_1684XXXXXXXXX', position='Body'),
  sortBy?: string(name='SortBy', description='The field used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   `TriggerTime (Desc/Asc)`

*   `StartedTime (Desc/Asc)`

*   `FinishedTime (Desc/Asc)`

*   `CreateTime (Desc/Asc)`

*   `Id (Desc/Asc)`

    Default value: `Id Desc`.', example='Id Desc', position='Body'),
  status?: string(name='Status', description='The status of the task instance.

*   `NotRun`: Not started
*   `Running`
*   `Failure`
*   `Success`
*   `WaitTime`: Awaiting scheduled time
*   `WaitResource`: Awaiting resources', example='Success', position='Body'),
  taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234', position='Body'),
  taskIds?: [ long ](name='TaskIds', description='The IDs of the tasks. You can query multiple instances at a time by task ID.', shrink='json', position='Body'),
  taskName?: string(name='TaskName', description='The name of the task. Fuzzy match is supported.', example='SQL node', position='Body'),
  taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL', position='Body'),
  triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal', position='Body'),
  triggerType?: string(name='TriggerType', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Normal', position='Body'),
  unifiedWorkflowInstanceId?: long(name='UnifiedWorkflowInstanceId', position='Body'),
  workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234', position='Body'),
  workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234', position='Body'),
  workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   SmokeTest: Testing
*   Manual: Manually triggered node
*   SupplementData: Data backfill
*   ManualWorkflow: Manually triggered workflow
*   Normal: Scheduled execution', example='Normal', position='Body'),
}

model ListTaskInstancesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    taskInstances?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the user who creates the instance.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description.', example='test'),
        finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The instance ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the user who modifies the instance.', example='1000'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
        priority?: int32(name='Priority', description='The priority of the task. Minimum value: 1. Maximum value: 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100'),
        rerunMode?: string(name='RerunMode', description='The rerun mode

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.', example='AllAllowed'),
        runNumber?: int32(name='RunNumber', description='The number of times the task is run. By default, the value starts from 1.', example='1'),
        runtime?: {
          gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
          processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
        }(name='Runtime', description='The runtime information about the instance.'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of CUs configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The information about the resource group with which the instance is associated.'),
        scriptParameters?: string(name='ScriptParameters', description='The script parameter list.', example='para1=val1 para2=val2'),
        startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
        status?: string(name='Status', description='The status of the instance.

Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
        taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
        taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
        taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='1'),
        triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
        triggerType?: string(name='TriggerType', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        unifiedWorkflowInstanceId?: long(name='UnifiedWorkflowInstanceId'),
        waitingResourceTime?: long(name='WaitingResourceTime', description='The timestamp for when it started waiting for resources.', example='1710239005403'),
        waitingTriggerTime?: long(name='WaitingTriggerTime', description='The timestamp for when it started waiting for the scheduled time.', example='1710239005403'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
        workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
        workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance.

Valid values:

*   SmokeTest
*   SupplementData
*   Manual
*   ManualWorkflow
*   Normal
*   ManualFlow', example='Normal'),
        workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
      }
    ](name='TaskInstances', description='The list of task instances.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListTaskInstances  ListTaskInstancesRequest
  * @return ListTaskInstancesResponse
 */
async function listTaskInstances(request: ListTaskInstancesRequest): ListTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model ListTaskOperationLogsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  date?: long(name='Date', description='The operation date, accurate to the day. The default value is the current day. You can query only the operation logs generated within the previous 31 days.', example='1710239005403', position='Query'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model ListTaskOperationLogsResponseBody = {
  pagingInfo?: {
    operationLogs?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the operation log was generated.', example='1710239005403'),
        operationContent?: string(name='OperationContent', description='The operation content.', example='Freeze tasks'),
        operationSeq?: long(name='OperationSeq', description='The serial number of the operation.', example='1111'),
        taskId?: long(name='TaskId', description='The ID of the task on which the operation was performed.', example='1234'),
        user?: string(name='User', description='The account ID of the operator.', example='1000'),
      }
    ](name='OperationLogs', description='The operation logs.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListTaskOperationLogsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTaskOperationLogsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * You can call this operation to query only the operation logs generated within the previous 31 days.
  * @param request  the request parameters of ListTaskOperationLogs  ListTaskOperationLogsRequest
  * @return ListTaskOperationLogsResponse
 */
async function listTaskOperationLogs(request: ListTaskOperationLogsRequest): ListTaskOperationLogsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTaskOperationLogs', 'GET', '/', 'json', false, 'json', request);
}

model ListTasksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  ids?: [ long ](name='Ids', description='The ID of the task.', shrink='json', position='Body'),
  name?: string(name='Name', description='The name of the task. Fuzzy match is supported.', example='SQL node', position='Body'),
  owner?: string(name='Owner', description='The account ID of the task owner.', example='1000', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  projectId: long(name='ProjectId', description='The workspace ID.

This parameter is required.', example='100', position='Body'),
  runtimeResource?: string(name='RuntimeResource', description='The information about the resource group. Set this parameter to the ID of a resource group for scheduling.', example='S_res_group_524258031846018_1684XXXXXXXXX', position='Body'),
  sortBy?: string(name='SortBy', description='The field that is used to sort tasks. This parameter is configured in the format of "Sorting field Sorting order". You can set the sorting order to Desc or Asc. If you do not specify the sorting order, Asc is used by default. Valid values:

*   `ModifyTime (Desc/Asc)`

*   `CreateTime (Desc/Asc)`

*   `Id (Desc/Asc)`

    Default value: `Id Desc`.', example='Id Desc', position='Body'),
  taskType?: string(name='TaskType', description='The type of the task. Valid values:

*   ODPS_SQL
*   SPARK
*   PY_ODPS
*   PY_ODPS3
*   ODPS_SCRIPT
*   ODPS_MR
*   COMPONENT_SQL
*   EMR_HIVE
*   EMR_MR
*   EMR_SPARK_SQL
*   EMR_SPARK
*   EMR_SHELL
*   EMR_PRESTO
*   EMR_IMPALA
*   SPARK_STREAMING
*   EMR_KYUUBI
*   EMR_TRINO
*   HOLOGRES_SQL
*   HOLOGRES_SYNC_DDL
*   HOLOGRES_SYNC_DATA', example='ODPS_SQL', position='Body'),
  triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal', position='Body'),
  triggerType?: string(name='TriggerType', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler', position='Body'),
  workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234', position='Body'),
}

model ListTasksResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    tasks?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description of the task.', example='test'),
        id?: long(name='Id', description='The task ID.', example='1234'),
        instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name of the task.', example='SQL node'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
        rerunMode?: string(name='RerunMode', description='The rerun mode.

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
        rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        scriptParameters?: string(name='ScriptParameters', description='The list of script parameters.', example='para1=$bizdate para2=$[yyyymmdd]'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
          recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
          type?: string(name='Type', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        }(name='Trigger', description='The method to trigger task scheduling.'),
        type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
      }
    ](name='Tasks', description='The tasks.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTasksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListTasks  ListTasksRequest
  * @return ListTasksResponse
 */
async function listTasks(request: ListTasksRequest): ListTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTasks', 'POST', '/', 'json', true, 'form', request);
}

model ListUpstreamTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
}

model ListUpstreamTaskInstancesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    taskInstances?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description.', example='test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The instance ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        periodNumber?: int32(name='PeriodNumber', description='The sequence number of the period. Indicates which cycle of the day the task instance is in.', example='1'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', deprecated='true'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.', example='AllAllowed'),
        runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
        runtime?: {
          gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
          processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
        }(name='Runtime', description='The runtime information about the instance.'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
        status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
        stepType?: string(name='StepType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
        taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
        taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='1'),
        triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
        triggerType?: string(name='TriggerType', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
        workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
        workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   SmokeTest
*   SupplementData
*   Manual
*   ManualWorkflow
*   Normal
*   ManualFlow', example='Normal'),
        workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
      }
    ](name='TaskInstances', description='The instances. This parameter is deprecated and replaced by the UpstreamTaskInstances parameter.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
    upstreamTaskInstances?: [ 
      {
        dependencyType?: string(name='DependencyType', description='The scheduling dependency type. Valid values:

*   Normal
*   CrossCycle', example='Normal'),
        taskInstance?: {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
          bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description.', example='test'),
          envType?: string(name='EnvType', description='The environment in which the data source is used. Valid values:

*   Dev
*   Prod', example='Prod'),
          finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
          id?: long(name='Id', description='The instance ID.', example='1234'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
          priority?: int32(name='Priority', description='The priority of the task. Minimum value: 1. Maximum value: 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunMode?: string(name='RerunMode', description='The rerun mode.', example='AllAllowed'),
          runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
          runtime?: {
            gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
            processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
          }(name='Runtime', description='The runtime information about the instance.'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
          startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
          status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.
*   WaitTrigger: The instance is waiting to be triggered by external scheduling systems.', example='Success'),
          taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
          taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
          taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='3600'),
          triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
          triggerType?: string(name='TriggerType', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
          workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
          workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   Normal
*   Manual
*   SmokeTest
*   SupplementData
*   ManualWorkflow', example='Normal'),
          workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
        }(name='TaskInstance', description='The information about a task instance.'),
      }
    ](name='UpstreamTaskInstances', description='The ancestor instances.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListUpstreamTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListUpstreamTaskInstancesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListUpstreamTaskInstances  ListUpstreamTaskInstancesRequest
  * @return ListUpstreamTaskInstancesResponse
 */
async function listUpstreamTaskInstances(request: ListUpstreamTaskInstancesRequest): ListUpstreamTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListUpstreamTaskInstances', 'GET', '/', 'json', false, 'json', request);
}

model ListUpstreamTasksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model ListUpstreamTasksResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    tasks?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description of the task.', example='test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        id?: long(name='Id', description='The task ID.', example='1234'),
        instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name of the task.', example='SQL node'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter.

Valid values:

*   Prod
*   Dev', example='Prod', deprecated='true'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
        rerunMode?: string(name='RerunMode', description='The rerun mode.

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether it is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
        rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        stepType?: string(name='StepType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
          recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
          timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
          type?: string(name='Type', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        }(name='Trigger', description='The method to trigger task scheduling.'),
        type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
      }
    ](name='Tasks', description='The tasks. This parameter is deprecated and replaced by the UpstreamTasks parameter.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
    upstreamTasks?: [ 
      {
        dependencyType?: string(name='DependencyType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        task?: {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description of the task.', example='test'),
          envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
          id?: long(name='Id', description='The task ID.', example='1234'),
          instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          name?: string(name='Name', description='The name of the task.', example='SQL node'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8.', example='1'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.', example='AllAllowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
          trigger?: {
            cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
            endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
            recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
            startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
            timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
            type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
          }(name='Trigger', description='The trigger method.'),
          type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
        }(name='Task', description='The information about the task.'),
      }
    ](name='UpstreamTasks', description='The ancestor tasks.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListUpstreamTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListUpstreamTasksResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListUpstreamTasks  ListUpstreamTasksRequest
  * @return ListUpstreamTasksResponse
 */
async function listUpstreamTasks(request: ListUpstreamTasksRequest): ListUpstreamTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListUpstreamTasks', 'GET', '/', 'json', false, 'json', request);
}

model ListWorkflowDefinitionsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  name?: string(name='Name', position='Query'),
  owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the workspace administrator. You can log on to the Alibaba Cloud Management Console and view the ID on the Security Settings page.', example='110755000425XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Query'),
  type?: string(name='Type', description='The workflow type. This parameter specifies a filter condition.

Valid values:

*   CycleWorkflow
*   ManualWorkflow', example='CycleWorkflow', position='Query'),
}

model ListWorkflowDefinitionsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='227'),
    workflowDefinitions?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the workflow was created. This value is a UNIX timestamp.', example='1698057323000'),
        description?: string(name='Description', description='The description of the workflow.', example='Workflow description'),
        id?: long(name='Id', description='The ID of the workflow.', example='463497880880954XXXX'),
        modifyTime?: long(name='ModifyTime', description='The time when the workflow was last modified. This value is a UNIX timestamp.', example='1698057323000'),
        name?: string(name='Name', description='The name of the workflow.', example='OpenAPI test workflow Demo'),
        owner?: string(name='Owner', description='The owner.', example='110755000425XXXX'),
        projectId: long(name='ProjectId', description='The ID of the DataWorks workspace to which the workflow belongs.

This parameter is required.', example='4710'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='698002781368644XXXX'),
          path?: string(name='Path', description='The script path.', example='XX/OpenAPI_test/workflow_test/OpenAPI_test_workflow_Demo'),
          runtime?: {
            command?: string(name='Command', description='The command.', example='WORKFLOW'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information.'),
        type?: string(name='Type', description='The type of the workflow.

Valid values:

*   CycleWorkflow
*   ManualWorkflow', example='CycleWorkflow'),
      }
    ](name='WorkflowDefinitions', description='The workflows.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='8C3ED0C5-ABAB-55E1-854B-DAC02B11XXXX'),
}

model ListWorkflowDefinitionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListWorkflowDefinitionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListWorkflowDefinitions  ListWorkflowDefinitionsRequest
  * @return ListWorkflowDefinitionsResponse
 */
async function listWorkflowDefinitions(request: ListWorkflowDefinitionsRequest): ListWorkflowDefinitionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListWorkflowDefinitions', 'GET', '/', 'json', false, 'json', request);
}

model ListWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  bizDate: long(name='BizDate', description='The data timestamp. The value of this parameter is 00:00:00 of the day before the scheduling time of the instance. The value is a UNIX timestamp. Unit: milliseconds. Example: 1743350400000.

This parameter is required.', example='1710239005403', position='Body'),
  filter?: string(name='Filter', position='Body'),
  ids?: [ long ](name='Ids', description='The IDs of the workflow instances. You can query multiple instances at a time by instance ID.', shrink='json', position='Body'),
  name?: string(name='Name', description='The instance name. Fuzzy match is supported.', example='WorkflowInstance1', position='Body'),
  owner?: string(name='Owner', description='The account ID of the workflow instance owner.', example='1000', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  projectId: long(name='ProjectId', description='The workspace ID.

This parameter is required.', example='100', position='Body'),
  sortBy?: string(name='SortBy', description='The fields used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   TriggerTime (Desc/Asc)
*   StartedTime (Desc/Asc)
*   FinishedTime (Desc/Asc)
*   CreateTime (Desc/Asc)
*   Id (Desc/Asc)

Default value: Id Desc.', example='Id Desc', position='Body'),
  tags?: [ string ](name='Tags', shrink='json', position='Body'),
  type?: string(name='Type', description='The type of the workflow instance. Valid values:

*   Normal: Scheduled execution
*   Manual: Manually triggered node
*   SmokeTest: Smoke test
*   SupplementData: Data backfill
*   ManualWorkflow: Manually triggered workflow
*   TriggerWorkflow: Triggered Workflow', example='Normal', position='Body'),
  unifiedWorkflowInstanceId?: long(name='UnifiedWorkflowInstanceId', position='Body'),
  workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234', position='Body'),
}

model ListWorkflowInstancesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
    workflowInstances?: [ 
      {
        bizDate?: long(name='BizDate', example='1710239005403'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='100'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The workflow instance ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='100'),
        name?: string(name='Name', description='The name of the workflow instance.', example='WorkflowInstance1'),
        owner?: string(name='Owner', example='1000'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
        status?: string(name='Status', description='The status of the workflow instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
        tags?: [ 
          {
            key?: string(name='Key', description='The key of a tag.', example='key1'),
            value?: string(name='Value', description='The value of a tag.', example='value1'),
          }
        ](name='Tags', description='The task tag.'),
        type?: string(name='Type', description='The type of the workflow instance. Valid values:

*   Normal: Scheduled execution
*   Manual: Manually triggered node
*   SmokeTest: Smoke test
*   SupplementData: Data backfill
*   ManualWorkflow: Manually triggered workflow
*   TriggerWorkflow: Triggered Workflow', example='Normal'),
        unifiedWorkflowInstanceId?: long(name='UnifiedWorkflowInstanceId'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
        workflowParameters?: string(name='WorkflowParameters', description='The workflow parameters.'),
        workflowTaskInstanceId?: long(name='WorkflowTaskInstanceId', example='1234'),
      }
    ](name='WorkflowInstances', description='The workflow instances.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListWorkflowInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListWorkflowInstances  ListWorkflowInstancesRequest
  * @return ListWorkflowInstancesResponse
 */
async function listWorkflowInstances(request: ListWorkflowInstancesRequest): ListWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model ListWorkflowsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  ids?: [ long ](name='Ids', description='The IDs of the workflows. You can query multiple workflows at a time by workflow ID.', shrink='json', position='Body'),
  name?: string(name='Name', description='The name of the workflow. Fuzzy match is supported.', example='Workflow1', position='Body'),
  owner?: string(name='Owner', description='The account ID of the workflow owner.', example='1000', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  projectId: long(name='ProjectId', description='The workspace ID.

This parameter is required.', example='100', position='Body'),
  sortBy?: string(name='SortBy', description='The field used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   ModifyTime (Desc/Asc)
*   CreateTime (Desc/Asc)
*   Id (Desc/Asc)

Default value: Id Desc.', example='Id Desc', position='Body'),
  tags?: [ string ](name='Tags', shrink='json', position='Body'),
  triggerType?: string(name='TriggerType', description='The trigger type.

*   Scheduler
*   Manual', example='Scheduler', position='Body'),
}

model ListWorkflowsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
    workflows?: [ 
      {
        clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a workflow asynchronously and implement the idempotence of the workflow. If you do not specify this parameter when you create the workflow, the system automatically generates a unique code. The unique code is uniquely associated with the workflow ID. If you specify this parameter when you update or delete the workflow, the value of this parameter must be the unique code that is used to create the workflow.', example='Workflow_0bc5213917368545132902xxxxxxxx'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        description?: string(name='Description', description='The description.', example='test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        id?: long(name='Id', description='The workflow ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name.', example='Workflow1'),
        owner?: string(name='Owner', description='The account ID of the owner.', example='1000'),
        parameters?: string(name='Parameters', description='The parameters.', example='para1=$bizdate para2=$[yyyymmdd]'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        tags?: [ 
          {
            key?: string(name='Key', example='key1'),
            value?: string(name='Value', example='value1'),
          }
        ](name='Tags', description='The task tag.'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
          recurrence?: string(name='Recurrence', description='The running mode of the workflow after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          startTime?: string(name='StartTime', description='The start time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
          type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        }(name='Trigger', description='The trigger method.'),
      }
    ](name='Workflows', description='The workflows.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListWorkflowsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListWorkflowsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListWorkflows  ListWorkflowsRequest
  * @return ListWorkflowsResponse
 */
async function listWorkflows(request: ListWorkflowsRequest): ListWorkflowsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListWorkflows', 'POST', '/', 'json', true, 'form', request);
}

model MoveFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='543217824470354XXXX', position='Body'),
  path: string(name='Path', description='The path to which you want to move the UDF. You do not need to specify a UDF name in the path.

For example, if you want to move the test UDF to root/demo/test, you must set this parameter to root/demo.

This parameter is required.', example='root/demo', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID.

This parameter indicates the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='12345', position='Body'),
}

model MoveFunctionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='48C0E2F0-52BA-5888-BDFA-28F1B9AFXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model MoveFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: MoveFunctionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of MoveFunction  MoveFunctionRequest
  * @return MoveFunctionResponse
 */
async function moveFunction(request: MoveFunctionRequest): MoveFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'MoveFunction', 'POST', '/', 'json', true, 'form', request);
}

model MoveNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  path: string(name='Path', description='The path to which you want to move the node. You do not need to specify a node name in the path.

For example, if you want to move the test node to root/demo/test, you must set this parameter to root/demo.

This parameter is required.', example='root/demo', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You can use this parameter to specify the DataWorks workspace on which you want to perform the API operation.

This parameter is required.', example='10000', position='Body'),
}

model MoveNodeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model MoveNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: MoveNodeResponseBody(name='body'),
}

/**
  * @param request  the request parameters of MoveNode  MoveNodeRequest
  * @return MoveNodeResponse
 */
async function moveNode(request: MoveNodeRequest): MoveNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'MoveNode', 'POST', '/', 'json', true, 'form', request);
}

model MoveResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the file resource.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  path: string(name='Path', description='The path to which you want to move the file resource. You do not need to specify a file resource name in the path.

For example, if you want to move the test file resource to root/demo/test, you must set this parameter to root/demo.

This parameter is required.', example='root/demo', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID.

You can use this parameter to specify the DataWorks workspace on which you want to perform the API operation.

This parameter is required.', example='10000', position='Body'),
}

model MoveResourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='F332BED4-DD73-5972-A9C2-642BA6CFXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model MoveResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: MoveResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of MoveResource  MoveResourceRequest
  * @return MoveResourceResponse
 */
async function moveResource(request: MoveResourceRequest): MoveResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'MoveResource', 'POST', '/', 'json', true, 'form', request);
}

model MoveWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='543217824470354XXXX', position='Body'),
  path: string(name='Path', description='The path to which you want to move the workflow. You do not need to specify a workflow name in the path.

For example, if you want to move the test workflow to root/demo/test, you must set this parameter to root/demo.

This parameter is required.', example='root/demo', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the ID. This parameter indicates the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10001', position='Body'),
}

model MoveWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='05ADAF4F-7709-5FB1-B606-3513483FXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model MoveWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: MoveWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of MoveWorkflowDefinition  MoveWorkflowDefinitionRequest
  * @return MoveWorkflowDefinitionResponse
 */
async function moveWorkflowDefinition(request: MoveWorkflowDefinitionRequest): MoveWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'MoveWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model PreviewDatasetVersionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='This parameter is required.', example='dataworks-datasetVersion:3pXXXb8o0ngr07njhps1
:2', position='Query'),
}

model PreviewDatasetVersionResponseBody = {
  previewResult?: {
    content?: string(name='Content', example='this is content'),
    fileName?: string(name='FileName', example='parth/data.csv'),
    mimeType?: string(name='MimeType', example='text/plain'),
    supportPreview?: boolean(name='SupportPreview', example='true'),
  }(name='PreviewResult'),
  requestId?: string(name='RequestId', description='Id of the request', example='A6C6B486-E3A2-5D52-9E76-D9380485DXXX'),
  success?: boolean(name='Success', example='true'),
}

model PreviewDatasetVersionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: PreviewDatasetVersionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of PreviewDatasetVersion  PreviewDatasetVersionRequest
  * @return PreviewDatasetVersionResponse
 */
async function previewDatasetVersion(request: PreviewDatasetVersionRequest): PreviewDatasetVersionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'PreviewDatasetVersion', 'POST', '/', 'json', false, 'json', request);
}

model RemoveEntityFromMetaCollectionRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: string(name='Id', description='The entity ID. Currently, entities can only be tables. You can call the ListTables operation to query the ID.', example='dlf-table:123456789:test_catalog:test_database::test_table', position='Query'),
  metaCollectionId?: string(name='MetaCollectionId', description='The collection ID. You can call the ListMetaCollections operation to query the ID.', example='category.123', position='Query'),
}

model RemoveEntityFromMetaCollectionResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='6D6CD444-DFA0-5180-9763-4A8730F2B382'),
}

model RemoveEntityFromMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RemoveEntityFromMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RemoveEntityFromMetaCollection  RemoveEntityFromMetaCollectionRequest
  * @return RemoveEntityFromMetaCollectionResponse
 */
async function removeEntityFromMetaCollection(request: RemoveEntityFromMetaCollectionRequest): RemoveEntityFromMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RemoveEntityFromMetaCollection', 'POST', '/', 'json', false, 'json', request);
}

model RemoveTaskInstanceDependenciesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  upstreamTaskInstanceIds?: [ long ](name='UpstreamTaskInstanceIds', description='The IDs of ancestor instances of the instance', shrink='json', position='Body'),
}

model RemoveTaskInstanceDependenciesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model RemoveTaskInstanceDependenciesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RemoveTaskInstanceDependenciesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of RemoveTaskInstanceDependencies  RemoveTaskInstanceDependenciesRequest
  * @return RemoveTaskInstanceDependenciesResponse
 */
async function removeTaskInstanceDependencies(request: RemoveTaskInstanceDependenciesRequest): RemoveTaskInstanceDependenciesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RemoveTaskInstanceDependencies', 'POST', '/', 'json', true, 'form', request);
}

model RenameFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='543217824470354XXXX', position='Body'),
  name: string(name='Name', description='The new name.

This parameter is required.', example='Rename', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10002', position='Body'),
}

model RenameFunctionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1ED4C97F-BA2A-57C5-BA7C-8853627EXXXX'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model RenameFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RenameFunctionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RenameFunction  RenameFunctionRequest
  * @return RenameFunctionResponse
 */
async function renameFunction(request: RenameFunctionRequest): RenameFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameFunction', 'POST', '/', 'json', true, 'form', request);
}

model RenameNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  name: string(name='Name', description='The new name.

This parameter is required.', example='Rename', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='12345', position='Body'),
}

model RenameNodeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4CDF7B72-020B-542A-8465-21CFFA81XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model RenameNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RenameNodeResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RenameNode  RenameNodeRequest
  * @return RenameNodeResponse
 */
async function renameNode(request: RenameNodeRequest): RenameNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameNode', 'POST', '/', 'json', true, 'form', request);
}

model RenameResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the file resource.

This parameter is required.', example='543217824470354XXXX', position='Body'),
  name: string(name='Name', description='The new name.

This parameter is required.', example='Rename', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model RenameResourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4CDF7B72-020B-542A-8465-21CFFA8XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model RenameResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RenameResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RenameResource  RenameResourceRequest
  * @return RenameResourceResponse
 */
async function renameResource(request: RenameResourceRequest): RenameResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameResource', 'POST', '/', 'json', true, 'form', request);
}

model RenameWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='463497880880954XXXX', position='Query'),
  name: string(name='Name', description='The new name.

This parameter is required.', example='Rename', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID. You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Query'),
}

model RenameWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can troubleshoot issues based on the ID.', example='975BD43D-C421-595C-A29C-565A8AD5XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model RenameWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RenameWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RenameWorkflowDefinition  RenameWorkflowDefinitionRequest
  * @return RenameWorkflowDefinitionResponse
 */
async function renameWorkflowDefinition(request: RenameWorkflowDefinitionRequest): RenameWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameWorkflowDefinition', 'POST', '/', 'json', false, 'json', request);
}

model RerunTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model RerunTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model RerunTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RerunTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of RerunTaskInstances  RerunTaskInstancesRequest
  * @return RerunTaskInstancesResponse
 */
async function rerunTaskInstances(request: RerunTaskInstancesRequest): RerunTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RerunTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model RerunWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  bizdate?: long(name='Bizdate', description='The business date used for matching manual workflow instances.', example='1710239005403', position='Body'),
  endTriggerTime?: long(name='EndTriggerTime', description='The end trigger time of the manual workflow instance used for matching. This parameter must be used together with the StartTriggerTime.', example='1710239005403', position='Body'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

Prod Dev', example='Prod', position='Body'),
  filter?: {
    rerunDownstreamEnabled?: boolean(name='RerunDownstreamEnabled', description='Specifies whether to rerun the matched instances and all downstream instances.', example='false'),
    taskIds?: [ long ](name='TaskIds', description='The internal task IDs used for matching manual workflow instances.'),
    taskInstanceStatuses?: [ string ](name='TaskInstanceStatuses', description='The statuses of internal tasks used for matching manual workflow instances.'),
    taskName?: string(name='TaskName', description='The internal task name used for matching the manual workflow instance.', example='test'),
    taskTypes?: [ string ](name='TaskTypes', description='Match internal tasks within the manual workflow by type.'),
  }(name='Filter', description='The match conditions for internal instances of manual workflow instances.', shrink='json', position='Body'),
  ids?: [ long ](name='Ids', description='The instance IDs used for matching manual workflow instances.', shrink='json', position='Body'),
  name?: string(name='Name', description='The manual workflow name, used for fuzzy matching.', example='test', position='Body'),
  projectId: long(name='ProjectId', description='The project ID.

This parameter is required.', example='123', position='Body'),
  startTriggerTime?: long(name='StartTriggerTime', description='The start trigger time (creation time) of the manual workflow instance used for matching. This parameter must be used together with EndTriggerTime.', example='1710239005403', position='Body'),
  status?: string(name='Status', description='The status used for matching manual workflow instances.

Valid values:

*   Success
*   Failure', example='Failure', position='Body'),
  type: string(name='Type', description='The type of the workflow instance. Valid values:

ManualWorkflow.

This parameter is required.', example='ManualWorkflow', position='Body'),
  workflowId: long(name='WorkflowId', description='The workflow ID.

This parameter is required.', example='123', position='Body'),
}

model RerunWorkflowInstancesResponseBody = {
  operationId?: string(name='OperationId', description='The operation ID. You can use this value to query the creation result via the GetRerunWorkflowInstancesResult operation.', example='e15ad21c-b0e9-4792-8f55-b037xxxxxxxx'),
  requestId?: string(name='RequestId', description='The request ID. Used for troubleshooting and log tracking.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model RerunWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RerunWorkflowInstancesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RerunWorkflowInstances  RerunWorkflowInstancesRequest
  * @return RerunWorkflowInstancesResponse
 */
async function rerunWorkflowInstances(request: RerunWorkflowInstancesRequest): RerunWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RerunWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model ResumeTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model ResumeTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model ResumeTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ResumeTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ResumeTaskInstances  ResumeTaskInstancesRequest
  * @return ResumeTaskInstancesResponse
 */
async function resumeTaskInstances(request: ResumeTaskInstancesRequest): ResumeTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ResumeTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model RevokeMemberProjectRolesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to query the ID.

This parameter is required.', example='105149', position='Body'),
  roleCodes: [ string ](name='RoleCodes', description='The codes of the roles in the workspace. You can call the [ListProjectRoles](https://help.aliyun.com/document_detail/2853930.html) operation to query the codes of all roles in the workspace.

You must configure this parameter to specify the roles that you want to revoke from the member in the workspace.

This parameter is required.', shrink='json', position='Body'),
  userId: string(name='UserId', description='The ID of the account used by the member in the workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the Tenant Members and Roles page, view the ID of the account used by the member in the workspace.

This parameter is required.', example='123422344899', position='Body'),
}

model RevokeMemberProjectRolesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='676271D6-53B4-57BE-89FA-72F7AE1418DF'),
}

model RevokeMemberProjectRolesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RevokeMemberProjectRolesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of RevokeMemberProjectRoles  RevokeMemberProjectRolesRequest
  * @return RevokeMemberProjectRolesResponse
 */
async function revokeMemberProjectRoles(request: RevokeMemberProjectRolesRequest): RevokeMemberProjectRolesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RevokeMemberProjectRoles', 'POST', '/', 'json', true, 'form', request);
}

model SetSuccessTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model SetSuccessTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model SetSuccessTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetSuccessTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of SetSuccessTaskInstances  SetSuccessTaskInstancesRequest
  * @return SetSuccessTaskInstancesResponse
 */
async function setSuccessTaskInstances(request: SetSuccessTaskInstancesRequest): SetSuccessTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetSuccessTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model StartDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='10000', deprecated='true', position='Query'),
  forceToRerun?: boolean(name='ForceToRerun', description='Specifies whether to forcefully rerun all synchronization steps. If you do not configure this parameter, the system does not perform the forcible rerun operation.

*   If the system does not perform the forcible rerun operation, only the steps that are not run start to run.
*   If the system performs the forcible rerun operation, all steps start to rerun.', example='false', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='10000', position='Query'),
  realtimeStartSettings?: {
    failoverSettings?: {
      interval?: long(name='Interval', description='This parameter is deprecated. Use advanced parameters for failover settings when you create a task.', example='10', deprecated='true'),
      upperLimit?: long(name='UpperLimit', description='This parameter is deprecated. Use advanced parameters for failover settings when you create a task.', example='30', deprecated='true'),
    }(name='FailoverSettings', description='This parameter is deprecated. Use advanced parameters for failover settings when you create a task.', deprecated='true'),
    startTime?: long(name='StartTime', description='The start time.', example='1671516776'),
  }(name='RealtimeStartSettings', description='The settings for starting real-time synchronization.

    {
      "StartTime":1663765058
    }', shrink='json', position='Query'),
}

model StartDIJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='999431B2-6013-577F-B684-36F7433C753B'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model StartDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StartDIJob  StartDIJobRequest
  * @return StartDIJobResponse
 */
async function startDIJob(request: StartDIJobRequest): StartDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartDIJob', 'GET', '/', 'json', false, 'json', request);
}

model StartWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  ids: [ long ](name='Ids', description='The IDs of workflow instances.

This parameter is required.', shrink='json', position='Body'),
}

model StartWorkflowInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17****'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The workflow instance ID serves as a key, and the result serves as a value.'),
}

model StartWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartWorkflowInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StartWorkflowInstances  StartWorkflowInstancesRequest
  * @return StartWorkflowInstancesResponse
 */
async function startWorkflowInstances(request: StartWorkflowInstancesRequest): StartWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model StopDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated and is replaced by the Id parameter.', example='11668', deprecated='true', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11668', position='Query'),
  instanceId?: long(name='InstanceId', description='The instance ID.', example='1234', position='Query'),
}

model StopDIJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='92F778C7-8F00-53B1-AE1A-B3B17101247D'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model StopDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StopDIJob  StopDIJobRequest
  * @return StopDIJobResponse
 */
async function stopDIJob(request: StopDIJobRequest): StopDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopDIJob', 'GET', '/', 'json', false, 'json', request);
}

model StopTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model StopTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model StopTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StopTaskInstances  StopTaskInstancesRequest
  * @return StopTaskInstancesResponse
 */
async function stopTaskInstances(request: StopTaskInstancesRequest): StopTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model StopWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  ids: [ long ](name='Ids', description='The workflow instance IDs.

This parameter is required.', shrink='json', position='Body'),
}

model StopWorkflowInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17****'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The workflow instance ID serves as a key, and the result serves as a value.'),
}

model StopWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopWorkflowInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StopWorkflowInstances  StopWorkflowInstancesRequest
  * @return StopWorkflowInstancesResponse
 */
async function stopWorkflowInstances(request: StopWorkflowInstancesRequest): StopWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model SubmitFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The description of the submission.', example='Submit a task for the first time', position='Body'),
  fileId: long(name='FileId', description='The file ID. You can call the [ListFiles](https://help.aliyun.com/document_detail/173942.html) operation to obtain the ID.

This parameter is required.', example='1000000', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the DataWorks console and go to the Workspace page to query the ID. You must specify either this parameter or the ProjectIdentifier parameter to identify the DataWorks workspace when you call this operation.', example='100001', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can log on to the DataWorks console and go to the Workspace page to query the workspace name. You must specify either this parameter or the ProjectId parameter to identify the DataWorks workspace when you call this operation.', example='dw_project', position='Body'),
  skipAllDeployFileExtensions?: boolean(name='SkipAllDeployFileExtensions', description='Whether to skip the pre-deployment check after the file is submitted:

*   false: Do not skip. After the file is submitted, the system automatically triggers the pre-deployment check. The file becomes available for deployment only after the check is passed.
*   true: Skip. After the file is submitted, the system does not trigger the pre-deployment check. The file can proceed directly to deployment.', example='false', position='Body'),
}

model SubmitFileResponseBody = {
  data?: long(name='Data', description='The deployment package ID. You must specify this ID as a parameter when you call the [GetDeployment](https://help.aliyun.com/document_detail/173950.html) operation to query the details of the deployment.', example='3000001'),
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the call was successful.

*   true: success.
*   false: failure.', example='true'),
}

model SubmitFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SubmitFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of SubmitFile  SubmitFileRequest
  * @return SubmitFileResponse
 */
async function submitFile(request: SubmitFileRequest): SubmitFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SubmitFile', 'POST', '/', 'json', true, 'form', request);
}

model SuspendTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model SuspendTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model SuspendTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SuspendTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of SuspendTaskInstances  SuspendTaskInstancesRequest
  * @return SuspendTaskInstancesResponse
 */
async function suspendTaskInstances(request: SuspendTaskInstancesRequest): SuspendTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SuspendTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model TagDataAssetsRequest {
  regionId?: string(name='RegionId', position='Host'),
  autoTraceEnabled?: boolean(name='AutoTraceEnabled', description='Specifies whether to enable lineage-based automatic backtracking.', example='false', position='Query'),
  dataAssetIds: [ string ](name='DataAssetIds', description='The data asset IDs.

This parameter is required.', shrink='json', position='Query'),
  dataAssetType: string(name='DataAssetType', description='The type of the data asset. Valid values:

*   ACS::DataWorks::Table
*   ACS::DataWorks::Task

This parameter is required.', example='ACS::DataWorks::Task', position='Query'),
  envType?: string(name='EnvType', description='The environment of the workspace to which the data asset belongs. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10000', position='Query'),
  tags: [ 
    {
      key: string(name='Key', description='The tag key.

This parameter is required.', example='key', minLength=1, maxLength=128),
      value?: string(name='Value', description='The tag value.', example='value', maxLength=128),
    }
  ](name='Tags', description='The tags that you want to add to data assets.

This parameter is required.', shrink='json', position='Query'),
}

model TagDataAssetsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model TagDataAssetsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: TagDataAssetsResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of TagDataAssets  TagDataAssetsRequest
  * @return TagDataAssetsResponse
 */
async function tagDataAssets(request: TagDataAssetsRequest): TagDataAssetsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'TagDataAssets', 'POST', '/', 'json', false, 'json', request);
}

model TestDataSourceConnectivityRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dataSourceId: long(name='DataSourceId', description='The ID of the data source for which you want to test the network connectivity.

This parameter is required.', example='144544', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='10001', position='Query'),
  resourceGroupId: string(name='ResourceGroupId', description='The resource group ID.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Query'),
}

model TestDataSourceConnectivityResponseBody = {
  connectivity?: {
    connectMessage?: string(name='ConnectMessage', description='The error message returned if the connectivity test fails. No such a message is returned if the connectivity test is successful.'),
    connectState?: string(name='ConnectState', description='The result of the connectivity test. Valid values: Connectable: The network can be connected. ConfigError: The network can be connected, but the configurations are incorrect. Unreachable: The network cannot be connected. Unsupport: An error is reported due to other causes. For example, the desired resource group is being initialized.', example='Connectable'),
    detailLogs?: [ 
      {
        code?: string(name='Code', description='The code of the test item.', example='validate_input_parameters'),
        endTime?: long(name='EndTime', description='The end time of a step.', example='1730217604002'),
        message?: string(name='Message', description='The name of the step.'),
        startTime?: long(name='StartTime', description='The start time of a step.', example='1730217600001'),
      }
    ](name='DetailLogs', description='The detailed logs of each step in the connectivity test.'),
  }(name='Connectivity', description='The details of the connectivity test.'),
  requestId?: string(name='RequestId', description='The request ID.', example='4CDF7B72-020B-542A-8465-21CFFA81****'),
}

model TestDataSourceConnectivityResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: TestDataSourceConnectivityResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  Your account must be assigned one of the following roles of the desired workspace: Tenant Owner, Workspace Administrator, Deploy, Develop, Workspace Owner, and O\\&M
  * @param request  the request parameters of TestDataSourceConnectivity  TestDataSourceConnectivityRequest
  * @return TestDataSourceConnectivityResponse
 */
async function testDataSourceConnectivity(request: TestDataSourceConnectivityRequest): TestDataSourceConnectivityResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'TestDataSourceConnectivity', 'POST', '/', 'json', false, 'json', request);
}

model TriggerSchedulerTaskInstanceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
  taskId: long(name='TaskId', description='The task ID.

This parameter is required.', example='1234', position='Body'),
  triggerTime: long(name='TriggerTime', description='The time defined by the HTTP Trigger node. This value is a UNIX timestamp.

This parameter is required.', example='1710239005403', position='Body'),
}

model TriggerSchedulerTaskInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model TriggerSchedulerTaskInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: TriggerSchedulerTaskInstanceResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of TriggerSchedulerTaskInstance  TriggerSchedulerTaskInstanceRequest
  * @return TriggerSchedulerTaskInstanceResponse
 */
async function triggerSchedulerTaskInstance(request: TriggerSchedulerTaskInstanceRequest): TriggerSchedulerTaskInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'TriggerSchedulerTaskInstance', 'POST', '/', 'json', true, 'form', request);
}

model UnTagDataAssetsRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataAssetIds: [ string ](name='DataAssetIds', description='The data asset IDs.

This parameter is required.', shrink='json', position='Query'),
  dataAssetType: string(name='DataAssetType', description='The type of the data asset. Valid values:

*   ACS::DataWorks::Table
*   ACS::DataWorks::Task

This parameter is required.', example='ACS::DataWorks::Task', position='Query'),
  envType?: string(name='EnvType', description='The environment of the workspace to which the data asset belongs. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='123', position='Query'),
  tags: [ 
    {
      key: string(name='Key', description='The tag key.

This parameter is required.', example='key', minLength=1, maxLength=128),
      value?: string(name='Value', description='The tag value.', example='value', maxLength=128),
    }
  ](name='Tags', description='The tags that you want to remove.

This parameter is required.', shrink='json', position='Query'),
}

model UnTagDataAssetsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='8754EE08-4AA2-5F77-ADD7-754DBBDA9F75'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UnTagDataAssetsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UnTagDataAssetsResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of UnTagDataAssets  UnTagDataAssetsRequest
  * @return UnTagDataAssetsResponse
 */
async function unTagDataAssets(request: UnTagDataAssetsRequest): UnTagDataAssetsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UnTagDataAssets', 'POST', '/', 'json', false, 'json', request);
}

model UpdateAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the rule.', example='true', position='Query'),
  id?: long(name='Id', description='The rule ID.', example='105412', position='Query'),
  name?: string(name='Name', description='The name of the rule.', example='collection_name', position='Query'),
  notification?: {
    channels?: [ string ](name='Channels', description='The alert notification channels.'),
    intervalInMinutes?: int32(name='IntervalInMinutes', description='The interval at which an alert notification is sent. Unit: minutes. Valid values: [5,10000].', example='30'),
    maximum?: int32(name='Maximum', description='The maximum number of times an alert notification can be sent within a calendar day. Valid values: [1, 10000].', example='3'),
    receivers?: [ 
      {
        extension?: string(name='Extension', description='The additional configuration of the alert recipient. If the ReceiverType parameter is set to DingdingUrl, you can set this parameter to {"atAll":true} to remind all members in a DingTalk group.', example='{"atAll":true}'),
        receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid valves:

*   AliUid: Alibaba Cloud account ID.
*   Shift Schedules: the personnel in a shift schedule.
*   TaskOwner: the task owner. The task owner can receive custom alerts and event alerts.
*   Owner: the baseline owner. The baseline owner can receive baseline alerts.
*   WebhookUrl: URL of a custom webhook.
*   DingdingUrl: DingTalk webhook URL.
*   FeishuUrl: Lark webhook URL.
*   WeixinUrl: WeCom webhook URL.', example='TaskOwner'),
        receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
      }
    ](name='Receivers', description='The alert recipients.'),
    silenceEndTime?: string(name='SilenceEndTime', description='The end time for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
    silenceStartTime?: string(name='SilenceStartTime', description='The start time for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
  }(name='Notification', description='The configuration for the alert notification.', shrink='json', position='Query'),
  owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.', example='193379****', position='Query'),
  triggerCondition?: {
    extension?: {
      cycleUnfinished?: {
        cycleAndTime?: [ 
          {
            cycleId?: int32(name='CycleId', description='The ID of the scheduling cycle of the instance. Valid values: [1,288].', example='1'),
            time?: string(name='Time', description='The latest completion time of the instance within the scheduling cycle. The time is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='01:00'),
          }
        ](name='CycleAndTime', description='The configurations of the scheduling cycle and timeout period of the instance.'),
      }(name='CycleUnfinished', description='The configuration for an alert of the CycleUnfinished type.'),
      error?: {
        autoRerunAlertEnabled?: boolean(name='AutoRerunAlertEnabled', description='Specifies whether to trigger an alert if a batch synchronization task is automatically rerun upon a failure.', example='false'),
        streamTaskIds?: [ long ](name='StreamTaskIds', description='The IDs of the real-time computing tasks. This parameter is required when you monitor real-time computing tasks.'),
      }(name='Error', description='The configuration for an alert of the Error type.'),
      instanceErrorCount?: {
        count?: int32(name='Count', description='The maximum number of instances on which an error occurs. Valid values: [1,10000].', example='10'),
      }(name='InstanceErrorCount', description='The configuration for an alert of the InstanceErrorCount type.'),
      instanceErrorPercentage?: {
        percentage?: int32(name='Percentage', description='The maximum percentage of instances on which an error occurs in the workspace to the total number of instances. Valid values: [1-100].', example='10'),
      }(name='InstanceErrorPercentage', description='The configuration for an alert of the InstanceErrorPercentage type.'),
      instanceTransferFluctuate?: {
        percentage?: int32(name='Percentage', description='The maximum percentage of fluctuation in the number of auto triggered node instances that are generated in your workspace. Valid values: [1-100].', example='10'),
        trend?: string(name='Trend', description='The way in which the number of auto triggered node instances that are generated in your workspace fluctuates. Valid values:

*   abs: the absolute value. The number of instances increases or decreases.
*   increase: The number of instances increases.
*   decrease: The number of instances decreases.', example='abs'),
      }(name='InstanceTransferFluctuate', description='The configuration for an alert of the InstanceTransferFluctuate type.'),
      timeout?: {
        timeoutInMinutes?: int32(name='TimeoutInMinutes', description='The timeout period. Unit: minutes.', example='10'),
      }(name='Timeout', description='The configuration for an alert of the Timeout type.'),
      unFinished?: {
        unFinishedTime?: string(name='UnFinishedTime', description='The latest completion time of the instance. The period is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
      }(name='UnFinished', description='The configuration for an alert of the UnFinished type.'),
    }(name='Extension', description='The extended information about the rule. This parameter is required for specific types of alerts.'),
    target?: {
      allowTasks?: [ long ](name='AllowTasks', description='The nodes that are not to be monitored.'),
      ids?: [ long ](name='Ids', description='The IDs of monitored objects.'),
      type?: string(name='Type', description='The type of the monitored objects. Valid values:

*   Task: node
*   Baseline: baseline
*   project: workspace
*   BizProcess: workflow', example='Task'),
    }(name='Target', description='The monitored objects.'),
    type?: string(name='Type', description='The alert type. Valid values:

*   Finished: An instance is successfully run.
*   UnFinished: An instance does not finish running before a specified point in time.
*   Error: An error occurs on an instance.
*   CycleUnfinished: An instance does not finish running as expected within a specific cycle.
*   Timeout: An instance times out.
*   InstanceTransferComplete: An instance is generated by the auto triggered node.
*   InstanceTransferFluctuate: The number of generated instances fluctuates.
*   ExhaustedError: An error persists after an instance is automatically rerun.
*   InstanceKeyword: An instance with errors contains specified keywords.
*   InstanceErrorCount: The number of instances on which an error occurs reaches a specified threshold.
*   InstanceErrorPercentage: The proportion of instances on which an error occurs in the workspace to the total number of instances reaches a specified threshold.
*   ResourceGroupPercentage: The usage rate of the resource group reaches a specified threshold.
*   ResourceGroupWaitCount: The number of instances that are waiting for resources in the resource group reaches a specified threshold.', example='ERROR'),
  }(name='TriggerCondition', description='The alert triggering condition.', shrink='json', position='Query'),
}

model UpdateAlertRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='D85FEE2B-6174-5817-AF9E-FDD02FEDA5BC'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAlertRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateAlertRule  UpdateAlertRuleRequest
  * @return UpdateAlertRuleResponse
 */
async function updateAlertRule(request: UpdateAlertRuleRequest): UpdateAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateAlertRule', 'POST', '/', 'json', false, 'json', request);
}

model UpdateBusinessRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  businessId: long(name='BusinessId', description='The workflow ID.

You can call the [ListBusiness](https://help.aliyun.com/document_detail/173945.html) operation to query the ID.

This parameter is required.', example='300000', position='Body'),
  businessName?: string(name='BusinessName', description='The name of the workflow.

You can call the [ListBusiness](https://help.aliyun.com/document_detail/173945.html) operation to query the name.', example='MyBusiness', position='Body'),
  description?: string(name='Description', description='The description of the workflow.', example='modified from my first business', position='Body'),
  owner?: string(name='Owner', description='The owner of the workflow.

You can call the [ListBusiness](https://help.aliyun.com/document_detail/173945.html) operation to query the owner.', example='348428****', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to obtain the workspace ID. You must configure either this parameter or the `ProjectIdentifier` parameter to determine the DataWorks workspace to which the operation is applied.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to obtain the name. You must configure either this parameter or the `ProjectId` parameter to determine the DataWorks workspace to which the operation is applied.', example='dw_project', position='Body'),
}

model UpdateBusinessResponseBody = {
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateBusinessResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateBusinessResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateBusiness  UpdateBusinessRequest
  * @return UpdateBusinessResponse
 */
async function updateBusiness(request: UpdateBusinessRequest): UpdateBusinessResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateBusiness', 'POST', '/', 'json', true, 'form', request);
}

model UpdateColumnBusinessMetadataRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  description?: string(name='Description', description='The field business description.', example='test description', position='Body'),
  id: string(name='Id', description='The field ID. You can refer to the response from the ListColumns operation. You can also refer to the [Concepts related to metadata entities](https://help.aliyun.com/document_detail/2880092.html).

This parameter is required.', example='maxcompute-column:11075xxxx::test_project:test_schema:test_table:test_column', position='Body'),
}

model UpdateColumnBusinessMetadataResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='D1E2E5BC-xxxx-xxxx-xxxx-xxxxxx'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateColumnBusinessMetadataResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateColumnBusinessMetadataResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateColumnBusinessMetadata  UpdateColumnBusinessMetadataRequest
  * @return UpdateColumnBusinessMetadataResponse
 */
async function updateColumnBusinessMetadata(request: UpdateColumnBusinessMetadataRequest): UpdateColumnBusinessMetadataResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateColumnBusinessMetadata', 'POST', '/', 'json', true, 'form', request);
}

model UpdateComponentRequest {
  regionId?: string(name='RegionId', description='代表region的资源属性字段

This parameter is required.', position='Host'),
  componentId: string(name='ComponentId', description='The component ID.

This parameter is required.', example='568780096083*******', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Query'),
  spec: string(name='Spec', description='The FlowSpec information for this UDF function. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
    "kind": "Component",
    "version": "1.1.2",
    "spec": {
        "components": [
            {
                "id": "568780096083*******",
                "script": {
                    "content": "select \\"@@{para1}\\", \\"@@{para2}\\""
                }
            }
        ]
    }
}', position='Body'),
}

model UpdateComponentResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateComponentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateComponentResponseBody(name='body'),
}

/**
  * @description This operation is currently in beta. To join the beta testing, please submit a request. You can call this operation after we add you to the beta program.
  * @param request  the request parameters of UpdateComponent  UpdateComponentRequest
  * @return UpdateComponentResponse
 */
async function updateComponent(request: UpdateComponentRequest): UpdateComponentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateComponent', 'POST', '/', 'json', true, 'form', request);
}

model UpdateComputeResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  connectionProperties: string(name='ConnectionProperties', description='This parameter is required.', position='Query'),
  connectionPropertiesMode?: string(name='ConnectionPropertiesMode', position='Query'),
  description?: string(name='Description', position='Query'),
  id: long(name='Id', description='This parameter is required.', position='Query'),
  projectId: long(name='ProjectId', description='This parameter is required.', position='Query'),
}

model UpdateComputeResourceResponseBody = {
  requestId?: string(name='RequestId'),
  success?: boolean(name='Success', example='true'),
}

model UpdateComputeResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateComputeResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateComputeResource  UpdateComputeResourceRequest
  * @return UpdateComputeResourceResponse
 */
async function updateComputeResource(request: UpdateComputeResourceRequest): UpdateComputeResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateComputeResource', 'POST', '/', 'json', false, 'json', request);
}

model UpdateDIAlarmRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIAlarmRuleId?: long(name='DIAlarmRuleId', description='This parameter is deprecated. Use the Id parameter instead.', example='34982', deprecated='true', position='Query'),
  DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='1', position='Query'),
  description?: string(name='Description', description='The description of the alert rule.', example='The description of the alert rule.', position='Query'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the alert rule. By default, the alert rule is disabled.', example='true', position='Query'),
  id?: long(name='Id', description='The alert rule Id', example='34982', position='Query'),
  metricType?: string(name='MetricType', description='The metric type in the alert rule. Valid values:

*   Heartbeat
*   FailoverCount
*   Delay
*   DdlReport
*   ResourceUtilization', example='Heartbeat', position='Query'),
  name?: string(name='Name', description='The name of the alert rule.', example='alarm_rule_name', position='Query'),
  notificationSettings?: {
    inhibitionInterval?: long(name='InhibitionInterval', description='This parameter is deprecated and replaced by the MuteInterval parameter.', example='5', deprecated='true'),
    muteInterval?: long(name='MuteInterval', description='The duration of the alert suppression interval. Default value: 5. Unit: minutes.', example='5'),
    notificationChannels?: [ 
      {
        channels?: [ string ](name='Channels', description='The alert notification method. Valid values:

*   Mail
*   Phone
*   Sms
*   Ding'),
        severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Warning'),
      }
    ](name='NotificationChannels', description='The alert notification methods.'),
    notificationReceivers?: [ 
      {
        receiverType?: string(name='ReceiverType', description='The recipient type. Valid values: AliyunUid, DingToken, FeishuToken, and WebHookUrl.', example='DingToken'),
        receiverValues?: [ string ](name='ReceiverValues', description='The recipient.

*   If the ReceiverType parameter is set to AliyunUid, set this parameter to the Alibaba Cloud account ID of a user.
*   If the ReceiverType parameter is set to DingToken, set this parameter to the token of a DingTalk chatbot.'),
      }
    ](name='NotificationReceivers', description='The settings of alert notification recipients.'),
  }(name='NotificationSettings', description='The alert notification settings.', shrink='json', position='Query'),
  triggerConditions?: [ 
    {
      ddlReportTags?: [ string ](name='DdlReportTags', description='This parameter is deprecated and replaced by the DdlTypes parameter.', deprecated='true'),
      ddlTypes?: [ string ](name='DdlTypes', description='The types of DDL operations for which the alert rule takes effect.'),
      duration?: long(name='Duration', description='The time interval for alert calculation. Unit: minutes.', example='15'),
      severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Warning'),
      threshold?: long(name='Threshold', description='The alert threshold.

*   If the alert rule is for task status, you do not need to specify a threshold.
*   If the alert rule is for failovers, you must specify the number of failovers.
*   If the alert rule is for latency, you must specify the latency duration, in seconds.', example='5'),
    }
  ](name='TriggerConditions', description='The conditions that can trigger the alert rule.', shrink='json', position='Query'),
}

model UpdateDIAlarmRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='A6C6B486-E3A2-5D52-9E76-D9380485D946'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateDIAlarmRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDIAlarmRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateDIAlarmRule  UpdateDIAlarmRuleRequest
  * @return UpdateDIAlarmRuleResponse
 */
async function updateDIAlarmRule(request: UpdateDIAlarmRuleRequest): UpdateDIAlarmRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDIAlarmRule', 'GET', '/', 'json', false, 'json', request);
}

model UpdateDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='11588', deprecated='true', position='Query'),
  description?: string(name='Description', position='Body'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11588', position='Query'),
  jobSettings?: {
    channelSettings?: string(name='ChannelSettings'),
    columnDataTypeSettings?: [ 
      {
        destinationDataType?: string(name='DestinationDataType'),
        sourceDataType?: string(name='SourceDataType'),
      }
    ](name='ColumnDataTypeSettings'),
    cycleScheduleSettings?: {
      scheduleParameters?: string(name='ScheduleParameters'),
    }(name='CycleScheduleSettings'),
    ddlHandlingSettings?: [ 
      {
        action?: string(name='Action'),
        type?: string(name='Type'),
      }
    ](name='DdlHandlingSettings'),
    runtimeSettings?: [ 
      {
        name?: string(name='Name'),
        value?: string(name='Value'),
      }
    ](name='RuntimeSettings'),
  }(name='JobSettings', shrink='json', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can call the [ListProjects](https://help.aliyun.com/document_detail/178393.html) operation to obtain the ID.', example='10000', position='Query'),
  resourceSettings?: {
    offlineResourceSettings?: {
      requestedCu?: double(name='RequestedCu'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier'),
    }(name='OfflineResourceSettings'),
    realtimeResourceSettings?: {
      requestedCu?: double(name='RequestedCu'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier'),
    }(name='RealtimeResourceSettings'),
    scheduleResourceSettings?: {
      requestedCu?: double(name='RequestedCu'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier'),
    }(name='ScheduleResourceSettings'),
  }(name='ResourceSettings', shrink='json', position='Body'),
  tableMappings?: [ 
    {
      sourceObjectSelectionRules?: [ 
        {
          action?: string(name='Action'),
          expression?: string(name='Expression'),
          expressionType?: string(name='ExpressionType'),
          objectType?: string(name='ObjectType'),
        }
      ](name='SourceObjectSelectionRules'),
      transformationRules?: [ 
        {
          ruleActionType?: string(name='RuleActionType'),
          ruleName?: string(name='RuleName'),
          ruleTargetType?: string(name='RuleTargetType'),
        }
      ](name='TransformationRules'),
    }
  ](name='TableMappings', shrink='json', position='Body'),
  transformationRules?: [ 
    {
      ruleActionType?: string(name='RuleActionType'),
      ruleExpression?: string(name='RuleExpression'),
      ruleName?: string(name='RuleName'),
      ruleTargetType?: string(name='RuleTargetType'),
    }
  ](name='TransformationRules', shrink='json', position='Body'),
}

model UpdateDIJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='AAC30B35-820D-5F3E-A42C-E96BB6379325'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateDIJob  UpdateDIJobRequest
  * @return UpdateDIJobResponse
 */
async function updateDIJob(request: UpdateDIJobRequest): UpdateDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDIJob', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDataAssetTagRequest {
  regionId?: string(name='RegionId', position='Host'),
  description?: string(name='Description', description='The description of the tag.', example='This is a description.', maxLength=1024, position='Query'),
  key: string(name='Key', description='The tag key.

This parameter is required.', example='key1', minLength=1, maxLength=128, position='Query'),
  managers?: [ string ](name='Managers', description='The tag administrators.', shrink='json', position='Query'),
  values?: [ string ](name='Values', description='The tag values.', shrink='json', position='Query'),
}

model UpdateDataAssetTagResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateDataAssetTagResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataAssetTagResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of UpdateDataAssetTag  UpdateDataAssetTagRequest
  * @return UpdateDataAssetTagResponse
 */
async function updateDataAssetTag(request: UpdateDataAssetTagRequest): UpdateDataAssetTagResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataAssetTag', 'POST', '/', 'json', false, 'json', request);
}

model UpdateDataQualityAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  condition?: string(name='Condition', description='The alert condition of the data quality monitoring rule.', example='results.any { r -> r.status == \\"fail\\" && r.rule.severity == \\"High\\" }', position='Body'),
  id?: long(name='Id', description='The ID of the alert rule.', example='105412', position='Body'),
  notification?: {
    channels: [ string ](name='Channels', description='The list of alert channels. You can set both Email and Sms at the same time. In other cases, only one channel can be set.

This parameter is required.'),
    receivers?: [ 
      {
        extension?: string(name='Extension', description='Additional configurations required for the alert recipients. When ReceiverType is DingdingUrl, you can set `{"atAll":true}` to mention all members.', example='{"atAll":true}'),
        receiverType: string(name='ReceiverType', description='The type of alert recipients.

*   AliUid
*   WebhookUrl
*   DingdingUrl
*   WeixinUrl
*   FeishuUrl
*   TaskOwner
*   DataQualityScanOwner
*   ShiftSchedule

This parameter is required.', example='TaskOwner'),
        receiverValues?: [ string ](name='ReceiverValues', description='The value of alert recipients.'),
      }
    ](name='Receivers', description='The alert recipients.'),
  }(name='Notification', description='Alert notification configurations.', shrink='json', position='Body'),
  projectId?: long(name='ProjectId', description='The project ID.', example='1000', position='Body'),
  target?: {
    ids?: [ long ](name='Ids', description='The list of monitored target IDs. Currently, only one ID can be set.'),
    type?: string(name='Type', description='The type of the monitored target. Only DataQualityScan is supported.', example='DataQualityScan'),
  }(name='Target', description='The monitored target of the data quality monitoring rule.', shrink='json', position='Body'),
}

model UpdateDataQualityAlertRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc14115***159376359'),
  success?: boolean(name='Success', description='Indicates whether the alert rule was updated.', example='True'),
}

model UpdateDataQualityAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataQualityAlertRuleResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateDataQualityAlertRule  UpdateDataQualityAlertRuleRequest
  * @return UpdateDataQualityAlertRuleResponse
 */
async function updateDataQualityAlertRule(request: UpdateDataQualityAlertRuleRequest): UpdateDataQualityAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataQualityAlertRule', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDataQualityEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityRules?: [ 
    {
      checkingConfig?: {
        referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain specific types of thresholds, you must query reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{"bizdate": ["-1"]}'),
        thresholds?: {
          critical?: {
            expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
            value?: string(name='Value', description='The threshold value.', example='0.01'),
          }(name='Critical', description='The threshold settings for critical alerts.'),
          expected?: {
            expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='='),
            value?: string(name='Value', description='The threshold value.', example='0'),
          }(name='Expected', description='The expected threshold setting.'),
          warned?: {
            expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Examples:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
            value?: string(name='Value', description='The threshold value.', example='0.001'),
          }(name='Warned', description='The threshold settings for normal alerts.'),
        }(name='Thresholds', description='The threshold settings.'),
        type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fluctation
*   Auto
*   FluctationDiscreate
*   Average
*   Fixed', example='Fixed'),
      }(name='CheckingConfig', description='The check settings for sample data.'),
      description?: string(name='Description', description='The description of the rule.', example='OpenAPI test rules', maxLength=500),
      enabled?: boolean(name='Enabled', description='Specifies whether to enable the rule.', example='true'),
      errorHandlers?: [ 
        {
          errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If you define the rule by using custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM ods_d_openapi_log WHERE status = \\"Error\\"'),
          type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
        }
      ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
      id?: long(name='Id', description='The rule ID. You can call the [ListQualityRules](https://help.aliyun.com/document_detail/173995.html) operation to query the ID of the monitoring rule.', example='1022171560'),
      name?: string(name='Name', description='The name of the monitoring rule.', example='OpenAPI test rules', maxLength=255),
      samplingConfig?: {
        metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: specifies that data is sampled by executing custom SQL statements.', example='CountNotIn'),
        metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
        samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='status != \\"Succeeded\\"'),
        settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='odps.sql.type.system.odps2=True,odps.sql.hive.compatible=True', maxLength=1000),
      }(name='SamplingConfig', description='The parameters required for sampling.'),
      severity?: string(name='Severity', description='The strength of the rule. Valid values:

*   Normal
*   High', example='Normal'),
      templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='SYSTEM:field:null_value:fixed:0'),
    }
  ](name='DataQualityRules', description='The list of monitoring rules that are associated with the monitor.', shrink='json', position='Body'),
  dataSourceId?: long(name='DataSourceId', description='The data source ID. You can call the [ListDataSources](https://help.aliyun.com/document_detail/211431.html) operation to query the ID.', example='358750', position='Body'),
  description?: string(name='Description', description='The description of the monitor.', example='OpenAPI data quality monitoring test.', maxLength=65535, position='Body'),
  hooks?: [ 
    {
      condition?: string(name='Condition', description='The hook trigger condition. When this condition is met, the hook action is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='${severity} == "High" AND ${status} == "Critical"'),
      type?: string(name='Type', description='The hook type. Valid values:

*   BlockTaskInstance: Blocks the running of scheduling tasks.', example='ByScheduledTaskInstance'),
    }
  ](name='Hooks', description='The hook.', shrink='json', position='Body'),
  id: long(name='Id', description='The ID of the monitor.

This parameter is required.', example='7227061794', position='Body'),
  name?: string(name='Name', description='The name of the monitor.', example='OpenAPI data quality monitoring test.', maxLength=255, position='Body'),
  notifications?: {
    condition?: string(name='Condition', description='The notification trigger condition. When this condition is met, the alert notification is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='${severity} == "High" AND ${status} == "Critical"'),
    notifications?: [ 
      {
        notificationChannels?: [ 
          {
            channels?: [ string ](name='Channels', description='The alert notification methods.'),
          }
        ](name='NotificationChannels', description='The alert notification methods.'),
        notificationReceivers?: [ 
          {
            extension?: string(name='Extension', description='The additional parameters that are required when alerts are sent. The parameters are JSON-formatted strings. The following keys are supported:

*   atAll: specifies that all members in a group are mentioned when alerts are sent by using DingTalk. This parameter is valid only if you set ReceiverType to DingdingUrl.', example='{  "atAll": true }'),
            receiverType?: string(name='ReceiverType', description='The type of the alert recipient.

Valid values:

*   WebhookUrl
*   FeishuUrl
*   DingdingUrl
*   WeixinUrl
*   AliUid', example='DingdingUrl'),
            receiverValues?: [ string ](name='ReceiverValues', description='The alert recipient.'),
          }
        ](name='NotificationReceivers', description='The configurations of alert recipients.'),
      }
    ](name='Notifications', description='The configurations of the alert notification.'),
  }(name='Notifications', description='The configurations of alert notifications.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace.

This parameter is required.', example='10000', position='Body'),
  runtimeConf?: string(name='RuntimeConf', description='The extended configurations in JSON-formatted strings. You can use this parameter only for monitors that are used to monitor the quality of E-MapReduce (EMR) data.

*   queue: The Yarn queue used when a monitor checks the quality of EMR data. By default, the queue configured for the current workspace is used.

*   sqlEngine: The SQL engine used when a monitor checks the quality of EMR data.

    *   HIVE_SQL
    *   SPARK_SQL', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }', position='Body'),
  target?: {
    databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   hologres
*   cdh
*   analyticdb_for_mysql
*   starrocks
*   emr
*   analyticdb_for_postgresql', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='dt=$[yyyymmdd-1]', maxLength=255),
    tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odsp.openapi.ods_d_openapi_log'),
  }(name='Target', description='The monitored object of the data quality monitoring task.', shrink='json', position='Body'),
  trigger?: {
    taskIds?: [ long ](name='TaskIds', description='The IDs of scheduling tasks. This parameter is valid only if you set Type to ByScheduledTaskInstance.'),
    type?: string(name='Type', description='The trigger type of the monitor. Valid values:

*   ByScheduledTaskInstance: The monitor is triggered by the associated scheduling tasks.
*   ByManual: The monitor is manually triggered.', example='ByScheduledTaskInstance'),
  }(name='Trigger', description='The trigger configuration of the monitor.', shrink='json', position='Body'),
}

model UpdateDataQualityEvaluationTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateDataQualityEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataQualityEvaluationTaskResponseBody(name='body'),
}

/**
  * @description This API operation is supported in all DataWorks editions.
  * @param request  the request parameters of UpdateDataQualityEvaluationTask  UpdateDataQualityEvaluationTaskRequest
  * @return UpdateDataQualityEvaluationTaskResponse
 */
async function updateDataQualityEvaluationTask(request: UpdateDataQualityEvaluationTaskRequest): UpdateDataQualityEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataQualityEvaluationTask', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDataQualityRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    thresholds?: {
      critical?: {
        expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue > 0.05'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Critical', description='The threshold settings for critical alerts.'),
      expected?: {
        expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue <= 0.01'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Expected', description='The expected threshold setting.'),
      warned?: {
        expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue > 0.01'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Warned', description='The threshold settings for normal alerts.'),
    }(name='Thresholds', description='The threshold settings.'),
    type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
  }(name='CheckingConfig', description='The check settings for sample data.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description of the rule. The description can be up to 500 characters in length.', example='this is a odps _sql task', maxLength=500, position='Body'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the rule.', example='true', position='Body'),
  errorHandlers?: [ 
    {
      errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If the rule is defined by custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
      type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
    }
  ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.', shrink='json', position='Body'),
  id: long(name='Id', description='The rule ID.

This parameter is required.', example='100001', position='Body'),
  name?: string(name='Name', description='The name of the rule. The name can be up to 255 characters in length and can contain digits, letters, and punctuation marks.', example='The table cannot be empty.', maxLength=255, position='Body'),
  projectId: long(name='ProjectId', description='This parameter is required.', position='Query'),
  samplingConfig?: {
    metric?: string(name='Metric', description='The metrics used for sampling. You can leave this parameter empty if you use a rule template. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='Min'),
    metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
    samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='id IS NULL'),
    settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;', maxLength=1000),
  }(name='SamplingConfig', description='The sampling settings.', shrink='json', position='Body'),
  severity?: string(name='Severity', description='The strength of the rule. Valid values:

*   Normal
*   High', example='High', position='Body'),
  templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='system::user_defined', position='Body'),
}

model UpdateDataQualityRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateDataQualityRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataQualityRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateDataQualityRule  UpdateDataQualityRuleRequest
  * @return UpdateDataQualityRuleResponse
 */
async function updateDataQualityRule(request: UpdateDataQualityRuleRequest): UpdateDataQualityRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataQualityRule', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDataQualityRuleTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference samples and perform aggregate operations on the reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
  }(name='CheckingConfig', description='The check settings for sample data.', shrink='json', position='Body'),
  code: string(name='Code', description='The code for the template.

This parameter is required.', example='USER_DEFINED:123', position='Body'),
  directoryPath?: string(name='DirectoryPath', description='The directory in which the template is stored. Slashes (/) are used to separate directory levels. The name of each directory level can be up to 1,024 characters in length. It cannot contain whitespace characters or slashes (/).', example='/ods/order_data', position='Body'),
  name?: string(name='Name', description='The name of the template. The name can be up to 512 characters in length and can contain digits, letters, and punctuation marks.', example='Table row Count Verification', maxLength=128, position='Body'),
  projectId: long(name='ProjectId', description='This parameter is required.', position='Query'),
  samplingConfig?: {
    metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='Max'),
    metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{"SQL": "select count(1) from table;"}'),
    settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;', maxLength=1000),
  }(name='SamplingConfig', description='The sampling settings.', shrink='json', position='Body'),
}

model UpdateDataQualityRuleTemplateResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='691CA452-D37A-4ED0-9441'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateDataQualityRuleTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataQualityRuleTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateDataQualityRuleTemplate  UpdateDataQualityRuleTemplateRequest
  * @return UpdateDataQualityRuleTemplateResponse
 */
async function updateDataQualityRuleTemplate(request: UpdateDataQualityRuleTemplateRequest): UpdateDataQualityRuleTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataQualityRuleTemplate', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDataQualityScanRequest {
  regionId?: string(name='RegionId', position='Host'),
  computeResource?: {
    envType?: string(name='EnvType', description='Workspace environment of the compute engine. Valid values:

*   Prod
*   Dev', example='Prod'),
    name?: string(name='Name', description='The name of the compute engine, which is a unique identifier.', example='auto_createAlertRule_Finished_1kUTk6'),
    runtime?: {
      engine?: string(name='Engine', description='The engine type. These settings are only supported for the EMR compute engine.This setting? Valid values:

*   Hive: Hive SQL
*   Spark: Spark SQL
*   Kyuubi', example='Hive'),
      hiveConf?: map[string]any(name='HiveConf', description='Additional Hive engine parameters. Currently, only the mapreduce.job.queuename parameter is supported.', example='mapreduce.job.queuename=dq_queue'),
      sparkConf?: map[string]any(name='SparkConf', description='Additional Spark engine parameters. Currently, only the spark.yarn.queue parameter is supported.', example='spark.yarn.queue=dq_queue'),
    }(name='Runtime', description='Additional settings for the compute engine.'),
  }(name='ComputeResource', description='The compute engine used during execution. If it\\"s not specified, the data source connection defined in the Spec will be used.', shrink='json', position='Body'),
  description?: string(name='Description', description='Description of the data quality monitor.', example='Daily data quality scanning of ods tables.', position='Body'),
  hooks?: [ 
    {
      condition?: string(name='Condition', description='The hook trigger condition. When this condition is met, the hook is triggered. Valid expression format:

Specifies multiple combinations of rule severity levels and rule validation statuses, such as `results.any { r -> r.status == \\"Fail\\" && r.rule.severity == \\"Normal\\" || r.status == \\"Error\\" && r.rule.severity == \\"High\\" || r.status == \\"Warn\\" && r.rule.severity == \\"High\\" }`. This means the hook is triggered if any executed rule has Fail with Normal severity, Error with High severity, or Warn with High severity. The severity values must match those defined in the Spec. The status values must match those in DataQualityResult.', example='results.any { r -> r.status == \\"Fail\\" && r.rule.severity == \\"Normal\\" || r.status == \\"Error\\" && r.rule.severity == \\"High\\" || r.status == \\"Warn\\" && r.rule.severity == \\"High\\" }'),
      type?: string(name='Type', description='The type of the hook. Valid values:

*   BlockTaskInstance: Block the scheduling of the task instance.', example='BlockTaskInstance'),
    }
  ](name='Hooks', description='The hook configuration after the data quality monitor stops.', shrink='json', position='Body'),
  id?: long(name='Id', description='The ID of the data quality monitor.', example='10001', position='Body'),
  name?: string(name='Name', description='The name of the data quality monitor.', example='data_quality_scan_001', position='Body'),
  owner?: string(name='Owner', description='The user ID of the owner of the data quality monitor.', example='231263586109857423', position='Body'),
  parameters?: [ 
    {
      name?: string(name='Name', description='The parameter name.', example='temp_237669.zip_byBwm_1734661241752'),
      value?: string(name='Value', description='The parameter value.', example='smtp.qiye.aliyun.com'),
    }
  ](name='Parameters', description='The definition of execution parameters for the data quality monitor.', shrink='json', position='Body'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace where the data quality monitor resides. You can obtain the workspace ID by calling the [ListProjects](https://help.aliyun.com/document_detail/2852607.html) operation.', example='101', position='Body'),
  runtimeResource?: {
    cu?: float(name='Cu', description='The default number of CUs configured for task running.', example='0.25'),
    id?: string(name='Id', description='The ID of the resource group.', example='20315'),
    image?: string(name='Image', description='The image ID of the task runtime configuration.', example='i-xxxxxx'),
  }(name='RuntimeResource', description='The resource group used during the execution of the data quality monitor.', shrink='json', position='Body'),
  spec?: string(name='Spec', description='The Spec code of the data quality monitoring content. For more information, see [Data quality Spec configuration description](https://help.aliyun.com/document_detail/2963394.html).', example='{
    "datasets": [
        {
            "type": "Table",
            "dataSource": {
                "name": "odps_first",
                "envType": "Prod"
            },
            "tables": [
                "ods_d_user_info"
            ],
            "filter": "pt = $[yyyymmdd-1]"
        }
    ],
    "rules": [
        {
            "assertion": "row_count > 0"
        }, {
            "templateId": "SYSTEM:field:null_value:fixed",
            "pass": "when = 0",
            "name": "The id cannot be empty.",
            "severity": "High",
             "identity": "a-customized-data-quality-rule-uuid"
        }
    ]
}', position='Body'),
  trigger?: {
    taskIds?: [ long ](name='TaskIds', description='If the trigger mode is BySchedule, the ID of the scheduling task that triggers the monitor must be configured.'),
    type?: string(name='Type', description='The trigger mode of the data quality monitor. Valid values:

*   ByManual: Manually triggered. Default setting.
*   BySchedule: Triggered by a scheduled task instance.', example='BySchedule'),
  }(name='Trigger', description='Trigger settings for the data quality monitor.', shrink='json', position='Body'),
}

model UpdateDataQualityScanResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A1****'),
  success?: boolean(name='Success', description='Indicates whether the call was successful.', example='true'),
}

model UpdateDataQualityScanResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataQualityScanResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateDataQualityScan  UpdateDataQualityScanRequest
  * @return UpdateDataQualityScanResponse
 */
async function updateDataQualityScan(request: UpdateDataQualityScanRequest): UpdateDataQualityScanResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataQualityScan', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDataQualityTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: string(name='Id', description='The ID of the custom rule template.', example='USER_DEFINED:2001', position='Body'),
  owner?: string(name='Owner', description='The account ID of the owner.', example='95279527****', position='Query'),
  projectId?: long(name='ProjectId', description='The project ID.', example='100001', position='Body'),
  spec?: string(name='Spec', description='Detailed configuration Spec code of the rule template. For more information, see [Data quality Spec configuration description](~2963394~).', example='{
    "assertion": "anomaly detection fro id_not_null_cnt",
    "id_not_null_cnt": {
        "query": "SELECT COUNT(*) AS cnt FROM ${tableName} WHERE dt = \\"$[yyyymmdd-1]\\";"
    },
    "identity": "819cf1f8-29be-4f94-a9d0-c5c06c0c3d2a"
}', position='Body'),
}

model UpdateDataQualityTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The API request ID, which is generated as a UUID.', example='0bc14115***159376359'),
  success?: boolean(name='Success', description='Indicates whether the rule template is updated.', example='true'),
}

model UpdateDataQualityTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataQualityTemplateResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateDataQualityTemplate  UpdateDataQualityTemplateRequest
  * @return UpdateDataQualityTemplateResponse
 */
async function updateDataQualityTemplate(request: UpdateDataQualityTemplateRequest): UpdateDataQualityTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataQualityTemplate', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  connectionProperties: string(name='ConnectionProperties', description='The connection configurations of the data source, including the connection address, access identity, and environment information. The envType parameter specifies the environment in which the data source is used. Valid values of the envType parameter:

*   Dev: development environment
*   Prod: production environment

The parameters that you need to configure for the data source vary based on the mode in which the data source is added. For more information, see [Data source connection information (ConnectionProperties)](https://help.aliyun.com/document_detail/2852465.html).

This parameter is required.', example='{
	"envType": "Prod",
	"regionId": "cn-beijing",
    "instanceId": "hgprecn-cn-x0r3oun4k001",
    "database": "testdb",
    "securityProtocol": "authTypeNone",
    "authType": "Executor",
    "authIdentity": "1107550004253538"
}', position='Query'),
  connectionPropertiesMode?: string(name='ConnectionPropertiesMode', description='The mode in which the data source is added. The mode varies based on the data source type. Valid values:

*   InstanceMode: instance mode
*   UrlMode: connection string mode', example='UrlMode', position='Query'),
  description?: string(name='Description', description='The description of the data source. The description cannot exceed 3,000 characters in length.', example='test', position='Query'),
  id: long(name='Id', description='The data source ID.

This parameter is required.', example='16033', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='5678', position='Query'),
}

model UpdateDataSourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='102E8E24-0387-531D-8A75-1C0AE7DD03E5'),
  success?: boolean(name='Success', description='Whether the data source has been modified:

- true: Yes
- false: no', example='true'),
}

model UpdateDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Tenant Administrator, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of UpdateDataSource  UpdateDataSourceRequest
  * @return UpdateDataSourceResponse
 */
async function updateDataSource(request: UpdateDataSourceRequest): UpdateDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataSource', 'POST', '/', 'json', false, 'json', request);
}

model UpdateDatasetRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', example='new comment', position='Body'),
  id: string(name='Id', description='This parameter is required.', example='dataworks-dataset:3pXXXb8o0ngr07njhps1', position='Body'),
  name?: string(name='Name', example='test_oss_dataset_new', position='Body'),
  readme?: string(name='Readme', example='## introduction', position='Body'),
}

model UpdateDatasetResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', example='true'),
}

model UpdateDatasetResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDatasetResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateDataset  UpdateDatasetRequest
  * @return UpdateDatasetResponse
 */
async function updateDataset(request: UpdateDatasetRequest): UpdateDatasetResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataset', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDatasetVersionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', example='this is a comment', position='Body'),
  id: string(name='Id', description='This parameter is required.', example='dataworks-datasetVersion:3pXXXb8o0ngr07njhps1
:2', position='Body'),
}

model UpdateDatasetVersionResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='A090666C-74FB-5629-ABFC-2FE99DD55XXX'),
  success?: boolean(name='Success', example='true'),
}

model UpdateDatasetVersionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDatasetVersionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateDatasetVersion  UpdateDatasetVersionRequest
  * @return UpdateDatasetVersionResponse
 */
async function updateDatasetVersion(request: UpdateDatasetVersionRequest): UpdateDatasetVersionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDatasetVersion', 'POST', '/', 'json', true, 'form', request);
}

model UpdateFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  advancedSettings?: string(name='AdvancedSettings', description='The advanced settings for the task.

This parameter corresponds to the Advanced Settings in the right-side navigation pane on the editing page for EMR Spark Streaming and EMR Streaming SQL tasks in Data Studio in the [DataWorks console](https://workbench.data.aliyun.com/console).

Currently, only EMR Spark Streaming and EMR Streaming SQL tasks support this parameter, and the parameter must be in JSON format.', example='{"queue":"default","SPARK_CONF":"--conf spark.driver.memory=2g"}', position='Body'),
  applyScheduleImmediately?: boolean(name='ApplyScheduleImmediately', description='Specifies whether to apply the scheduling configuration immediately after the file is published.', example='true', position='Body'),
  autoParsing?: boolean(name='AutoParsing', description='Specifies whether to enable automatic parsing for the file. Valid values:

*   true
*   false

This parameter corresponds to the Analyze Code setting in Properties > Dependencies for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='true', position='Body'),
  autoRerunIntervalMillis?: int32(name='AutoRerunIntervalMillis', description='The interval at which the node is automatically rerun after a failure. Unit: milliseconds. Maximum value: 1800000 milliseconds (30 minutes).

This parameter corresponds to the Rerun interval parameter in Properties > Schedule > Auto Rerun upon Failure for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console). In the console, the unit of the rerun interval is minutes. Convert the time unit when you call this operation.', example='120000', position='Body'),
  autoRerunTimes?: int32(name='AutoRerunTimes', description='The number of automatic reruns after the file execution fails.', example='3', position='Body'),
  connectionName?: string(name='ConnectionName', description='The name of the data source that is used to run the node. You can call the [ListDataSources](https://help.aliyun.com/document_detail/211431.html) operation to query the available data sources.', example='odps_source', position='Body'),
  content?: string(name='Content', description='The file code content. Different code types (fileType) have different code formats. In Operation Center, you can right-click a task of the corresponding type and select View Code to view the specific code format.', example='SELECT "1";', position='Body'),
  cronExpress?: string(name='CronExpress', description='The cron expression for scheduled execution. This parameter corresponds to the Cron Expression setting in Scheduling > Scheduling Time for Data Studio tasks in the [DataWorks console](https://workbench.data.aliyun.com/console). After you configure Scheduling Cycle and Scheduled Time, DataWorks automatically generates a cron expression.

Examples:

*   Scheduled at 05:30 every day: `00 30 05 * * ?`
*   Scheduled at the 15th minute of every hour: `00 15 * * * ?`
*   Scheduled every 10 minutes: `00 00/10 * * * ?`
*   Scheduled every 10 minutes between 08:00 and 23:00 every day: `00 00-59/10 8-23 * * * ?`
*   Scheduled at 00:20 on the 1st day of every month: `00 20 00 1 * ?`
*   Scheduled every 3 months starting from 00:10 on January 1: `00 10 00 1 1-12/3 ?`
*   Scheduled at 00:05 on every Tuesday and Friday: `00 05 00 * * 2,5`

Due to the rules of the DataWorks scheduling system, cron expressions have the following restrictions:

*   The minimum scheduling interval is 5 minutes.
*   The earliest scheduling time each day is 00:05.', example='00 00-59/5 1-23 * * ?', position='Body'),
  cycleType?: string(name='CycleType', description='The type of scheduling cycle. Valid values: NOT_DAY (minute, hour) and DAY (day, week, month).

This parameter corresponds to the Scheduling Cycle setting in Scheduling > Scheduling Time for Data Studio tasks in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='NOT_DAY', position='Body'),
  dependentNodeIdList?: string(name='DependentNodeIdList', description='The IDs of the nodes on which the current node depends. This parameter takes effect only when the DependentType parameter is set to USER_DEFINE. Separate multiple node IDs with commas (,).

This parameter corresponds to the Other Nodes option in Properties > Dependencies > Cross-cycle Dependency (Original Previous-cycle Dependency) for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='5,10,15,20', position='Body'),
  dependentType?: string(name='DependentType', description='The dependency mode on the previous cycle. Valid values:

*   SELF: Depends on the current node.
*   CHILD: Depends on the child nodes.
*   USER_DEFINE: Depends on other nodes.
*   NONE: No dependencies. Does not depend on the previous cycle.', example='USER_DEFINE', position='Body'),
  endEffectDate?: long(name='EndEffectDate', description='The timestamp (in milliseconds) when automatic scheduling stops.

This parameter corresponds to the end time of Effective Period in Scheduling > Scheduling Time for Data Studio tasks in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='4155787800000', minimum=0, position='Body'),
  fileDescription?: string(name='FileDescription', description='The file description.', example='Here is the file description', position='Body'),
  fileFolderPath?: string(name='FileFolderPath', description='The path to the folder where the file is located.', example='Business_process/First_Business_Process/data_integration/Folder_1/Folder_2', position='Body'),
  fileId: long(name='FileId', description='The file ID. You can call the [ListFiles](https://help.aliyun.com/document_detail/173942.html) operation to obtain the file ID.

This parameter is required.', example='100000001', position='Body'),
  fileName?: string(name='FileName', description='The file name. You can modify the file name by setting a new value for FileName. For example, you can call the [ListFiles](https://help.aliyun.com/document_detail/173942.html) operation to query the file ID in the target directory, and then call the [UpdateFile](https://help.aliyun.com/document_detail/173951.html) operation with the file ID specified in the FileId parameter and a new value specified in the FileName parameter to modify the file name.', example='ods_user_info_d', position='Body'),
  ignoreParentSkipRunningProperty?: boolean(name='IgnoreParentSkipRunningProperty', description='This parameter corresponds to the Skip The Dry-Run Property Of The Ancestor Node option in Properties > Dependencies > Cross-cycle Dependency (Original Previous-cycle Dependency) when Instances of Current Node or Level-1 Child Node is selected for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='true', position='Body'),
  imageId?: string(name='ImageId', description='The custom image ID.', example='m-uf6d7npxk1hhek8ng0cb', position='Body'),
  inputList?: string(name='InputList', description='The output names of the ancestor nodes on which the current node depends. Separate multiple output names with commas (,).

This parameter corresponds to the Output Name of Ancestor Node setting in Properties > Dependencies for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).

> This parameter is required when you call the CreateDISyncTask or UpdateFile operation to create a batch synchronization node.', example='project_root,project.file1,project.001_out', position='Body'),
  inputParameters?: string(name='InputParameters', description='The input context parameters of the node. The value must be in the JSON format. For more information about the parameter structure, see the InputContextParameterList parameter in the response parameters of the [GetFile](https://help.aliyun.com/document_detail/173954.html) operation.

This parameter corresponds to the Input Parameters setting in Properties > Input and Output Parameters for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='[{"ValueSource": "project_001.first_node:bizdate_param","ParameterName": "bizdate_input"}]', position='Body'),
  outputList?: string(name='OutputList', description='The outputs of the node.

This parameter corresponds to the Output Name setting in Properties > Dependencies for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='dw_project.ods_user_info_d', position='Body'),
  outputParameters?: string(name='OutputParameters', description='The output context parameters of the node. The value must be in the JSON format. For more information about the parameter structure, see the OutputContextParameterList parameter in the response parameters of the [GetFile](https://help.aliyun.com/document_detail/173954.html) operation.

This parameter corresponds to the Output Parameters setting in Properties > Input and Output Parameters for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='[{"Type": 1,"Value": "${bizdate}","ParameterName": "bizdate_param"}]', position='Body'),
  owner?: string(name='Owner', description='The file owner ID.', example='18023848927592', position='Body'),
  paraValue?: string(name='ParaValue', description='The scheduling parameters of the node.

This parameter corresponds to the Scheduling Parameter setting in Properties for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console). For more information, see [Scheduling parameters](https://help.aliyun.com/document_detail/137548.html).', example='x=a y=b z=c', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. To obtain the ID, log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and navigate to the workspace management page.', example='100001', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The DataWorks workspace name. To obtain the workspace name, log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and navigate to the workspace configuration page.

You must specify either this parameter or ProjectId to identify the target DataWorks workspace for this API call.', example='dw_project', position='Body'),
  rerunMode?: string(name='RerunMode', description='The rerun policy. Valid values:

*   ALL_ALLOWED: Reruns are allowed regardless of whether the task succeeds or fails.
*   FAILURE_ALLOWED: Reruns are allowed only when the task fails.
*   ALL_DENIED: Reruns are not allowed regardless of whether the task succeeds or fails.

This parameter corresponds to the Support for Rerun setting in Scheduling > Scheduling Policies for Data Studio tasks in the [DataWorks console](https://workbench.data.aliyun.com/console).

Valid values:

*   ALL_ALLOWD
*   FAILURE_ALLOWED
*   ALL_DENIED
*   ALL_ALLOWED', example='ALL_ALLOWED', position='Body'),
  resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The resource group for the task published from the file. You can call the [ListResourceGroups](https://help.aliyun.com/document_detail/173913.html) operation to query the available resource groups in the workspace.', example='default_group', position='Body'),
  schedulerType?: string(name='SchedulerType', description='The scheduling type. Valid values:

*   NORMAL: Normal scheduled task.
*   MANUAL: Manually triggered node. Not scheduled for daily execution. Corresponds to nodes in manually triggered workflows.
*   PAUSE: Paused task.
*   SKIP: Dry-run task. Scheduled for daily execution but is directly marked as successful when scheduling starts.', example='NORMAL', position='Body'),
  startEffectDate?: long(name='StartEffectDate', description='The timestamp (in milliseconds) when automatic scheduling starts.

This parameter corresponds to the start time of Effective Period in Scheduling > Scheduling Time for Data Studio tasks in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='936923400000', minimum=0, position='Body'),
  startImmediately?: boolean(name='StartImmediately', description='Specifies whether to start the task immediately after it is published. Valid values:

*   true: Start the task immediately after it is published.
*   false: Do not start the task immediately after it is published.

This parameter corresponds to the Start Method setting in Configuration > Scheduling Policies in the right-side navigation pane on the editing page for EMR Spark Streaming and EMR Streaming SQL tasks in Data Studio in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='true', position='Body'),
  stop?: boolean(name='Stop', description='Specifies whether to skip execution. Valid values:

*   true
*   false

This parameter corresponds to the Skip Execution option in Properties > Schedule > Recurrence for data development nodes in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='false', position='Body'),
  timeout?: int32(name='Timeout', description='The timeout settings for scheduling configuration.', example='1', position='Body'),
}

model UpdateFileResponseBody = {
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID. Use this ID to troubleshoot issues.', example='0000-ABCD-EFGH-IJKLMNOPQ'),
  success?: boolean(name='Success', description='Indicates whether the call succeeded. Valid values:

*   true: The call succeeded.
*   false: The call failed.', example='true'),
}

model UpdateFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateFile  UpdateFileRequest
  * @return UpdateFileResponse
 */
async function updateFile(request: UpdateFileRequest): UpdateFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateFile', 'POST', '/', 'json', true, 'form', request);
}

model UpdateFolderRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  folderId: string(name='FolderId', description='The folder ID. You can call the [ListFolders](https://help.aliyun.com/document_detail/173955.html) operation to obtain the folder ID.

This parameter is required.', example='2735c2c19d58', position='Body'),
  folderName: string(name='FolderName', description='The folder name.

This parameter is required.', example='MySecondFolder', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the DataWorks console and go to the Workspace page to query the ID. You must specify either this parameter or the ProjectIdentifier parameter to identify the DataWorks workspace when you call this operation.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The name of the DataWorks workspace. You can log on to the DataWorks console and go to the Workspace page to query the workspace name. You must specify either this parameter or the ProjectId parameter to identify the DataWorks workspace when you call this operation.', example='dw_project', position='Body'),
}

model UpdateFolderResponseBody = {
  errorCode?: string(name='ErrorCode', description='The error code', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the call was successful', example='true'),
}

model UpdateFolderResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateFolderResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateFolder  UpdateFolderRequest
  * @return UpdateFolderResponse
 */
async function updateFolder(request: UpdateFolderRequest): UpdateFolderResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateFolder', 'POST', '/', 'json', true, 'form', request);
}

model UpdateFunctionRequest {
  regionId?: string(name='RegionId', description='代表region的资源属性字段

This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='463497880880954XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the UDF. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
    "version": "1.1.0",
    "kind": "Function",
    "spec": {
        "functions": [
            {
                "name": "FunctionName",
                "script": {
                    "content": "{\\"name\\": \\"FunctionName\\", \\"datasource\\": {\\"type\\": \\"odps\\", \\"name\\": \\"odps_first\\"}, \\"runtimeResource\\": {\\"resourceGroup\\": \\"S_res_group_XXXX_XXXX\\"}}",
                    "path": "XXX/OpenAPI/Function/FunctionName",
                    "runtime": {
                        "command": "ODPS_FUNCTION"
                    }
                },
                "datasource": {
                    "name": "odps_first",
                    "type": "odps"
                },
                "runtimeResource": {
                    "resourceGroup": "S_res_group_XXXX_XXXX"
                }
            }
        ]
    }
}', position='Body'),
}

model UpdateFunctionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can troubleshoot issues based on the ID.', example='12123960-CB2C-5086-868E-C6C1D024XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

true

false', example='true'),
}

model UpdateFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateFunctionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateFunction  UpdateFunctionRequest
  * @return UpdateFunctionResponse
 */
async function updateFunction(request: UpdateFunctionRequest): UpdateFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateFunction', 'POST', '/', 'json', true, 'form', request);
}

model UpdateIDEEventResultRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkResult?: string(name='CheckResult', description='The check status of the extension for this extension point event. Valid values:

*   OK: The extension passed the check for this event.
*   FAIL: The extension failed the check for this event. You need to review and resolve the error promptly to avoid affecting subsequent program execution.
*   WARN: The extension passed the check for this event, but with warnings.', example='OK', position='Body'),
  checkResultTip?: string(name='CheckResultTip', description='A summary of the check result for this extension point event. This message is displayed on your current development page. When the check fails or has warnings, you can use this summary to quickly identify the cause.', example='Succeeded', position='Body'),
  extensionCode?: string(name='ExtensionCode', description='The unique identifier of the extension. You can obtain the identifier from the Extensions tab on Open Platform in the [DataWorks console](https://workbench.data.aliyun.com/console).', example='8abcb91f-d266-4073-b907-2ed670378ed1', position='Body'),
  messageId?: string(name='MessageId', description='The OpenEvent message ID from DataWorks. When an extension point event is triggered, you can obtain the message ID from the event message.', example='8abcb91f-d266-4073-b907-2ed670378ed1', position='Body'),
}

model UpdateIDEEventResultResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. Used for troubleshooting errors.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
}

model UpdateIDEEventResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateIDEEventResultResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateIDEEventResult  UpdateIDEEventResultRequest
  * @return UpdateIDEEventResultResponse
 */
async function updateIDEEventResult(request: UpdateIDEEventResultRequest): UpdateIDEEventResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateIDEEventResult', 'POST', '/', 'json', true, 'form', request);
}

model UpdateMetaCollectionRequest {
  regionId?: string(name='RegionId', position='Host'),
  administrators?: [ string ](name='Administrators', description='The collection administrator IDs. This parameter is available only for data albums. The administrator must be an account within the same tenant.', shrink='simple', position='Query'),
  description?: string(name='Description', example='new comment', position='Query'),
  id: string(name='Id', description='The collection ID.

This parameter is required.', example='category.123', position='Query'),
  name?: string(name='Name', example='new_name', position='Query'),
}

model UpdateMetaCollectionResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='0E1C0122-F79F-5C26-B546-47A321691868'),
}

model UpdateMetaCollectionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateMetaCollectionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateMetaCollection  UpdateMetaCollectionRequest
  * @return UpdateMetaCollectionResponse
 */
async function updateMetaCollection(request: UpdateMetaCollectionRequest): UpdateMetaCollectionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateMetaCollection', 'POST', '/', 'json', false, 'json', request);
}

model UpdateNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Body'),
  spec: string(name='Spec', description='{ "title": "CycleWorkflow Schema", "description": "the JSON schema that is used to configure the auto triggered workflow and nodes in the workflow", "type": "object", "required": [ "version", "kind", "spec" ], "properties": { "version": { "type": "string", "const": "1.1.0", "description": "the schema version. The value is fixed to 1.1.0" }, "kind": { "type": "string", "enum": [ "Workflow", "Node" ], "description": "the resource type" }, "spec": { "type": "object", "description": "the key configurations of the workflow", "required": [ "nodes" ], "properties": { "nodes": { "type": "array", "description": "the nodes in the workflow", "items": { "type": "object", "required": [ "name", "script" ], "properties": { "recurrence": { "type": "string", "enum": [ "Normal", "Pause", "Skip", "NoneAuto" ], "description": "the running mode of the node. Valid values: Normal, Pause, Skip, and NoneAuto" }, "id": { "type": "string", "description": "the node ID" }, "timeout": { "type": "integer", "minimum": 0, "description": "the timeout period. Unit: seconds" }, "instanceMode": { "type": "string", "enum": [ "T+1", "Immediately" ], "description": "the instance generation mode. Valid values: T+1 and Immediately" }, "rerunMode": { "type": "string", "enum": [ "Allowed", "Denied", "FailureAllowed" ], "description": "the rerun mode. Valid values: AllAllowed, Denied, and FailureAllowed" }, "rerunTimes": { "type": "integer", "minimum": 0, "description": "the maximum number of reruns allowed after a failure" }, "rerunInterval": { "type": "integer", "minimum": 0, "description": "the rerun interval. Unit: seconds" }, "datasource": { "type": "object", "description": "the configurations of the data source", "required": [ "name", "type" ], "properties": { "name": { "type": "string", "description": "the name of the data source" }, "type": { "type": "string", "enum": [ "odps" ], "description": "the type of the data source. Only MaxCompute data sources are supported" } } }, "script": { "type": "object", "description": "the script configurations of the node", "required": [ "path", "runtime" ], "properties": { "language": { "type": "string", "description": "the programming language of the script" }, "path": { "type": "string", "description": "the storage path of the script file. The storage path ends with the node name and does not require a file extension" }, "runtime": { "type": "object", "description": "the configurations of the runtime environment", "required": [ "command" ], "properties": { "command": { "type": "string", "enum": [ "ODPS_SQL" ], "Description": "the command" }, "cu": { "type": "string", "description": "the unit of the computing resource" } } } } }, "trigger": { "type": "object", "description": "the configurations of the node trigger", "required": [ "type" ], "properties": { "type": { "type": "string", "enum": [ "Scheduler", "Manual", "Streaming", "None" ], "description": "the trigger type. Valid values: Scheduler, Manual, Streaming, and None" }, "cron": { "type": "string", "description": "the cron expression, which is suitable for only auto triggered nodes" }, "startTime": { "type": "string", "format": "yyyy-MM-dd hh:mm:ss", "description": "the start time for scheduling" }, "endTime": { "type": "string", "format": "yyyy-MM-dd hh:mm:ss", "description": "the end time for scheduling" } } }, "runtimeResource": { "type": "object", "description": "the resource configurations for running", "required": [ "resourceGroup" ], "properties": { "resourceGroup": { "type": "string", "description": "the name of the resource group" } } }, "name": { "type": "string", "description": "the name of the node" }, "owner": { "type": "string", "description": "the node owner" }, "inputs": { "type": "object", "description": "the node input parameters", "properties": { "nodeOutputs": { "type": "array", "description": "the node dependencies", "items": { "type": "object", "required": [ "data" ], "properties": { "data": { "type": "string", "description": "the identifier of the node dependency" }, "refTableName": { "type": "string", "description": "the name of the table that is associated with the node. You must configure this parameter if the artifactType parameter is set to Table" }, "isDefault": { "type": "boolean", "description": "specifies whether the table is the default input table“ } } } } } }, "outputs": { "type": "object", "description": "the node output parameters", "properties": { "nodeOutputs": { "type": "array", "description": "the node dependencies", "items": { "type": "object", "required": [ "data" ], "properties": { "data": { "type": "string", "description": "the identifier of the node dependency" }, "refTableName": { "type": "string", "description": "the name of the table that is associated with the node. You must configure this parameter if the artifactType parameter is set to Table" }, "isDefault": { "type": "boolean", "description": "specifies whether the table is the default output table“ } } } } } } } } } } } } }

This parameter is required.', example='{
    "version": "1.1.0",
    "kind": "Node",
    "spec": {
        "nodes": [
            {
                "id": "860438872620113XXXX",
                "recurrence": "Normal",
                "timeout": 0,
                "instanceMode": "T+1",
                "rerunMode": "Allowed",
                "rerunTimes": 3,
                "rerunInterval": 180000,
                "datasource": {
                    "name": "odps_test",
                    "type": "odps"
                },
                "script": {
                    "path": "XX/OpenAPI_Test/odpsSQL_Test",
                    "runtime": {
                        "command": "ODPS_SQL"
                    },
                    "content": "select now();"
                },
                "trigger": {
                    "type": "Scheduler",
                    "cron": "00 00 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "runtimeResource": {
                    "resourceGroup": "S_res_group_XXXX_XXXX"
                },
                "name": "odpsSQL_Test",
                "inputs": {
                    "nodeOutputs": [
                        {
                            "data": "lwttest_standard_root",
                            "artifactType": "NodeOutput"
                        }
                    ]
                },
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "output_data",
                            "artifactType": "NodeOutput",
                            "refTableName": "odpsSQL_Test"
                        }
                    ]
                }
            }
        ],
        "flow": [
            {
                "nodeId": "860438872620113XXXX",
                "depends": [
                    {
                        "type": "Normal",
                        "output": "project_root"
                    }
                ]
            }
        ]
    }
}', position='Body'),
}

model UpdateNodeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can troubleshoot issues based on the ID.', example='99EBE7CF-69C0-5089-BE3E-79563C31XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateNodeResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateNode  UpdateNodeRequest
  * @return UpdateNodeResponse
 */
async function updateNode(request: UpdateNodeRequest): UpdateNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateNode', 'POST', '/', 'json', true, 'form', request);
}

model UpdateProjectRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  description?: string(name='Description', description='The description of the workspace.', example='Financial analysis group project data development', position='Body'),
  devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Specifies whether to enable the development environment. Valid values:

*   true: enables the development environment. In this case, the development environment is isolated from the production environment in the workspace.
*   false: disables the development environment. In this case, only the production environment is used in the workspace.', example='true', position='Body'),
  devRoleDisabled?: boolean(name='DevRoleDisabled', description='Specifies whether to disable the Develop role. Valid values:

*   false (default)
*   true

Note: If you disable the Develop role, you cannot assume the Develop role to develop nodes in workflows and edit node code. The Develop role cannot be enabled again after it is disabled.', example='true', position='Body'),
  displayName?: string(name='DisplayName', description='The display name of the workspace.', example='Sora financial analysis Space', position='Body'),
  id: long(name='Id', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the workspace management page to obtain the ID.

This parameter is used to determine the DataWorks workspaces used for this API call.

This parameter is required.', example='123456', position='Body'),
  paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Specifies whether to enable scheduling of Platform for AI (PAI) tasks. Valid values:

*   true: enables scheduling of PAI tasks. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: disables scheduling of PAI tasks.', example='true', position='Body'),
  status?: string(name='Status', description='Specifies whether to disable or enable the workspace. Valid values:

*   Available: enables the workspace.
*   Forbidden: disables the workspace.', example='Forbidden', position='Body'),
}

model UpdateProjectResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
}

model UpdateProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateProject  UpdateProjectRequest
  * @return UpdateProjectResponse
 */
async function updateProject(request: UpdateProjectRequest): UpdateProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateProject', 'POST', '/', 'json', true, 'form', request);
}

model UpdateResourceGroupRequest {
  regionId?: string(name='RegionId', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the new Alibaba Cloud resource group.', example='rg-aek2kqofrgXXXXX', position='Body'),
  id: string(name='Id', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
  name?: string(name='Name', description='The new name that you want to change for the resource group.', example='common_resource_group', position='Body'),
  remark?: string(name='Remark', description='The new remarks that you want to modify for the resource group.', example='Create a common resource group for common tasks', position='Body'),
}

model UpdateResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateResourceGroupResponseBody(name='body'),
}

/**
  * @description You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * @param request  the request parameters of UpdateResourceGroup  UpdateResourceGroupRequest
  * @return UpdateResourceGroupResponse
 */
async function updateResourceGroup(request: UpdateResourceGroupRequest): UpdateResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model UpdateRouteRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  destinationCidr: string(name='DestinationCidr', description='The destination CIDR block of the route that you want to update.

This parameter is required.', example='192.168.0.0/16', position='Body'),
  id: long(name='Id', description='The route ID of the network resource.

This parameter is required.', example='1000', position='Body'),
}

model UpdateRouteResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateRouteResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateRouteResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateRoute  UpdateRouteRequest
  * @return UpdateRouteResponse
 */
async function updateRoute(request: UpdateRouteRequest): UpdateRouteResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateRoute', 'POST', '/', 'json', true, 'form', request);
}

model UpdateTableBusinessMetadataRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The table ID. You can refer to the format of the table ID returned by the ListTables operation.

This parameter is required.', example='maxcompute-table:123456XXX::test_project::test_tbl
dlf-table:123456XXX:test_catalog:test_db::test_tbl
hms-table:c-abc123xxx::test_db::test_tbl
holo-table:h-abc123xxx::test_db:test_schema:test_tbl', position='Body'),
  readme?: string(name='Readme', description='The usage notes. The rich text format is supported.', example='## introduction', position='Body'),
}

model UpdateTableBusinessMetadataResponseBody = {
  requestId?: string(name='RequestId', description='Request ID.', example='7C352CB7-CD88-XXXXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateTableBusinessMetadataResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateTableBusinessMetadataResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateTableBusinessMetadata  UpdateTableBusinessMetadataRequest
  * @return UpdateTableBusinessMetadataResponse
 */
async function updateTableBusinessMetadata(request: UpdateTableBusinessMetadataRequest): UpdateTableBusinessMetadataResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateTableBusinessMetadata', 'POST', '/', 'json', true, 'form', request);
}

model UpdateTaskRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This code uniquely identifies a task. This parameter is used to create a task asynchronously and implement the idempotence of the task. If you do not specify this parameter when you create the task, the system automatically generates a unique code. The unique code is uniquely associated with the task ID. If you specify this parameter when you update or delete the task, the value of this parameter must be the unique code that is used to create the task.', example='Task_0bc5213917368545132902xxxxxxxx', position='Body'),
  dataSource?: {
    name?: string(name='Name', description='The name of the data source.', example='odps_test'),
  }(name='DataSource', description='The information about the associated data source.', shrink='json', position='Body'),
  dependencies?: [ 
    {
      type: string(name='Type', description='The dependency type. Valid values:

*   CrossCycleDependsOnChildren: Depends on level-1 downstream nodes across cycles
*   CrossCycleDependsOnSelf: Depends on itself across cycles.
*   CrossCycleDependsOnOtherNode: Depends on other nodes across cycles.
*   Normal: Depends on nodes in the same cycle.

This parameter is required.', example='Normal'),
      upstreamOutput?: string(name='UpstreamOutput', description='The output identifier of the upstream task. (This parameter is returned only if `Normal` is set and the node input is configured.)', example='pre.odps_sql_demo_0'),
      upstreamTaskId?: long(name='UpstreamTaskId', description='The ID of the upstream task. (This parameter is returned only if `Normal` or `CrossCycleDependsOnOtherNode` is set and the node input is not configured.)', example='1234'),
    }
  ](name='Dependencies', description='The dependency information.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description of the task.', example='test', position='Body'),
  envType?: string(name='EnvType', description='The project environment.

*   Prod
*   Dev', example='Prod', position='Body'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Body'),
  inputs?: {
    variables?: [ 
      {
        name?: string(name='Name', description='The name of the variable.', example='key1'),
        type: string(name='Type', description='The type. Valid values:

*   Constant: constant value.
*   PassThrough: node output.
*   System: variable.
*   NodeOutput: script output.

This parameter is required.', example='Constant'),
        value?: string(name='Value', description='The value of the variable.', example='value1'),
      }
    ](name='Variables', description='The variables.'),
  }(name='Inputs', description='The input information.', shrink='json', position='Body'),
  instanceMode?: string(name='InstanceMode', description='The instance generation mode.

*   T+1: the next day
*   Immediately', example='T+1', position='Body'),
  name?: string(name='Name', description='Name.', example='SQL node', position='Body'),
  outputs?: {
    taskOutputs?: [ 
      {
        output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
      }
    ](name='TaskOutputs', description='The task outputs.'),
    variables?: [ 
      {
        name?: string(name='Name', description='The name of the variable.', example='key1'),
        type: string(name='Type', description='The type. Valid values:

*   Constant: constant value.
*   PassThrough: node output.
*   System: variable.
*   NodeOutput: script output.

This parameter is required.', example='Constant'),
        value?: string(name='Value', description='The value of the variable.', example='value1'),
      }
    ](name='Variables', description='The variables.'),
  }(name='Outputs', description='The output information.', shrink='json', position='Body'),
  owner?: string(name='Owner', description='The account ID of the task owner.', example='1000', position='Body'),
  rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: milliseconds. Must not exceed 1800000.', example='60', position='Body'),
  rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun.
*   FailureAllowed: The task can be rerun only after it fails.
*   AllAllowed: The task can always be rerun.', example='AllAllowed', position='Body'),
  rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3', position='Body'),
  runtimeResource?: {
    cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
    image?: string(name='Image', description='The image ID used in the task runtime configuration.', example='i-xxxxxx'),
    resourceGroupId?: string(name='ResourceGroupId', description='The identifier of the scheduling resource group used in the task runtime configuration.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
  }(name='RuntimeResource', description='Runtime environment configurations, such as resource group information.', shrink='json', position='Body'),
  script?: {
    content?: string(name='Content', description='The script content.', example='echo "helloWorld"', deprecated='true'),
    parameters?: string(name='Parameters', description='The script parameter list.', example='para1=$bizdate'),
  }(name='Script', description='The run script information.', shrink='json', position='Body'),
  tags?: [ 
    {
      key: string(name='Key', description='The key of a tag.

This parameter is required.', example='key1'),
      value?: string(name='Value', description='The value of a tag.', example='value1'),
    }
  ](name='Tags', description='The tags.', shrink='json', position='Body'),
  timeout?: int32(name='Timeout', description='Task execution timeout in seconds. Must be greater than 3600.', example='3600', position='Body'),
  trigger?: {
    cron?: string(name='Cron', description='The Cron expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
    cycleType?: string(name='CycleType', description='Cycle type. This parameter takes effect only when Type is set to Scheduler and the cron expression specifies hourly scheduling. Default value: Daily

*   Daily: Schedules jobs on a daily basis.
*   NotDaily: Schedules jobs on an hourly basis.', example='Daily'),
    endTime?: string(name='EndTime', description='The expiration time of periodic triggering. Takes effect only when type is set to Scheduler. The value of this parameter is in the`yyyy-mm-dd hh:mm:ss` format.', example='9999-01-01 00:00:00'),
    recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
    startTime?: string(name='StartTime', description='The time when periodic triggering takes effect. This parameter takes effect only if the Type parameter is set to Scheduler. The value of this parameter is in the`yyyy-mm-dd hh:mm:ss` format.', example='1970-01-01 00:00:00'),
    type?: string(name='Type', description='The triggering type. Valid values:

*   Scheduler: periodically triggered
*   Manual', example='Scheduler'),
  }(name='Trigger', description='The triggering method.', shrink='json', position='Body'),
}

model UpdateTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateTask  UpdateTaskRequest
  * @return UpdateTaskResponse
 */
async function updateTask(request: UpdateTaskRequest): UpdateTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateTask', 'POST', '/', 'json', true, 'form', request);
}

model UpdateTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  taskInstances?: [ 
    {
      dataSource?: {
        name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
      }(name='DataSource', description='The information about the associated data source.'),
      id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234'),
      priority?: int32(name='Priority', description='The priority of the instance. Valid values: 1, 3, 5, 7, and 8.

A larger value indicates a higher priority. Default value: 1.', example='1'),
      runtimeResource?: string(name='RuntimeResource', description='The resource group information. Set this parameter to the ID of a resource group for scheduling.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
    }
  ](name='TaskInstances', description='The instances.', shrink='json', position='Body'),
}

model UpdateTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model UpdateTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateTaskInstances  UpdateTaskInstancesRequest
  * @return UpdateTaskInstancesResponse
 */
async function updateTaskInstances(request: UpdateTaskInstancesRequest): UpdateTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model UpdateUdfFileRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  className: string(name='ClassName', description='The class name where the function is defined, corresponding to the class name field in the Create Function form.

This parameter is required.', example='com.alibaba.DataWorks.api.udf.StringConcat', position='Body'),
  cmdDescription?: string(name='CmdDescription', description='The command format for invoking the function, corresponding to the command format field in the Create Function form.', example='StringConcat(String... substrs)', position='Body'),
  example?: string(name='Example', description='An example demonstrating how to call the function, corresponding to the example field in the Create Function form.', example='StringConcat(\\"a\\", \\"b\\", \\"c\\")', position='Body'),
  fileFolderPath?: string(name='FileFolderPath', description='The path to the folder containing the function file.', example='Business_process/First_Business_Process/function/string_processing_function', position='Body'),
  fileId: string(name='FileId', description='The file ID.

This parameter is required.', example='10000001', position='Body'),
  functionType: string(name='FunctionType', description='The function category, corresponding to the function type field in the Create Function form. Valid values: MATH (mathematical functions), AGGREGATE (aggregate functions), STRING (string processing functions), DATE (date processing functions), ANALYTIC (window functions), and OTHER (other functions).

This parameter is required.', example='STRING', position='Body'),
  parameterDescription?: string(name='ParameterDescription', description='The function parameter description, corresponding to the parameter description field in the Create Function form.

Valid values:

*   ALL_ALLOWD
*   FAILURE_ALLOWED
*   ALL_DENIED', example='List of strings to be connected', position='Body'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. To find this, click the wrench icon in the upper-right corner and navigate to the workspace management page.', example='10000', position='Body'),
  projectIdentifier?: string(name='ProjectIdentifier', description='The unique identifier of the DataWorks workspace, which is the identifier at the top of the Data Studio page where you switch workspaces.

Either this parameter or ProjectId must be specified to identify the target DataWorks workspace for this API call.', example='dw_project', position='Body'),
  resources: string(name='Resources', description='A comma-separated list of resource names referenced by the function, corresponding to the resource list field in the Create Function form.

This parameter is required.', example='string-concat-1.0.0.jar,commons-lang-2.6.jar', position='Body'),
  returnValue?: string(name='ReturnValue', description='The return value description, corresponding to the return value field in the Create Function form.', example='New strings generated by concatenating all strings before and after the input order', position='Body'),
  udfDescription?: string(name='UdfDescription', description='The function purpose description, corresponding to the description field in the Create Function form.', example='Concatenate several strings to generate a new string', position='Body'),
}

model UpdateUdfFileResponseBody = {
  errorCode?: string(name='ErrorCode', description='The error code.', example='Invalid.Tenant.ConnectionNotExists'),
  errorMessage?: string(name='ErrorMessage', description='The error message.', example='The connection does not exist.'),
  httpStatusCode?: int32(name='HttpStatusCode', description='The HTTP status code.', example='200'),
  requestId?: string(name='RequestId', description='The unique ID for this request. Use this ID for troubleshooting if an error occurs.', example='0000-ABCD-EFG****'),
  success?: boolean(name='Success', description='Indicates whether the request succeeded. Valid values:

*   true
*   false', example='true'),
}

model UpdateUdfFileResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateUdfFileResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateUdfFile  UpdateUdfFileRequest
  * @return UpdateUdfFileResponse
 */
async function updateUdfFile(request: UpdateUdfFileRequest): UpdateUdfFileResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateUdfFile', 'POST', '/', 'json', true, 'form', request);
}

model UpdateWorkflowRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a workflow asynchronously and implement the idempotence of the workflow. If you do not specify this parameter when you create the workflow, the system automatically generates a unique code. The unique code is uniquely associated with the workflow ID. If you specify this parameter when you update or delete the workflow, the value of this parameter must be the unique code that is used to create the workflow.', example='Workflow_0bc5213917368545132902xxxxxxxx', position='Body'),
  dependencies?: [ 
    {
      type: string(name='Type', description='The dependency type. Valid values:

*   CrossCycleDependsOnChildren: cross-cycle dependency on level-1 descendant nodes
*   CrossCycleDependsOnSelf: cross-cycle dependency on the current node
*   CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
*   Normal: same-cycle scheduling dependency

This parameter is required.', example='Normal'),
      upstreamOutput?: string(name='UpstreamOutput', description='The identifier of the output of the ancestor task. This parameter is returned only if `same-cycle scheduling dependencies` and the node input are configured.', example='pre.odps_sql_demo_0'),
      upstreamTaskId?: long(name='UpstreamTaskId', description='The ancestor task ID. This parameter is returned only if `cross-cycle scheduling dependencies` or `same-cycle scheduling dependencies` and the node input are not configured.', example='1234'),
    }
  ](name='Dependencies', description='The dependency information.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description.', example='test', position='Body'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  id: long(name='Id', description='The workflow ID.

This parameter is required.', example='1234', position='Body'),
  instanceMode?: string(name='InstanceMode', position='Body'),
  name: string(name='Name', description='The name of the workflow.

This parameter is required.', example='My Workflow', position='Body'),
  outputs?: {
    taskOutputs?: [ 
      {
        output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
      }
    ](name='TaskOutputs', description='The task outputs.'),
  }(name='Outputs', description='The output information.', shrink='json', position='Body'),
  owner: string(name='Owner', description='The account ID of the owner.

This parameter is required.', example='1000', position='Body'),
  parameters?: string(name='Parameters', description='The parameters.', example='para1=$bizdate para2=$[yyyymmdd]', position='Body'),
  tags?: [ 
    {
      key: string(name='Key', description='The tag key.

This parameter is required.', example='key1'),
      value?: string(name='Value', description='The tag value.', example='value1'),
    }
  ](name='Tags', description='The tags.', shrink='json', position='Body'),
  tasks?: [ 
    {
      baseLineId?: long(name='BaseLineId', description='The baseline ID.', example='1234'),
      clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a task asynchronously and implement the idempotence of the task. If you do not specify this parameter when you create the workflow, the system automatically generates a unique code. The unique code is uniquely associated with the workflow ID. If you specify this parameter when you update or delete the workflow, the value of this parameter must be the unique code that is used to create the workflow.', example='Task_0bc5213917368545132902xxxxxxxx'),
      dataSource?: {
        name?: string(name='Name', description='The name of the data source.', example='odps_test'),
      }(name='DataSource', description='The information about the associated data source.'),
      dependencies?: [ 
        {
          type: string(name='Type', description='The dependency type. Valid values:

*   CrossCycleDependsOnChildren: cross-cycle dependency on level-1 descendant nodes
*   CrossCycleDependsOnSelf: cross-cycle dependency on the current node
*   CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
*   Normal: same-cycle scheduling dependency

This parameter is required.', example='Normal'),
          upstreamOutput?: string(name='UpstreamOutput', description='The identifier of the output of the ancestor task. This parameter is returned only if `same-cycle scheduling dependencies` and the node input are configured.', example='pre.odps_sql_demo_0'),
          upstreamTaskId?: long(name='UpstreamTaskId', description='The ancestor task ID. This parameter is returned only if `cross-cycle scheduling dependencies` or `same-cycle scheduling dependencies` and the node input are not configured.', example='1234'),
        }
      ](name='Dependencies', description='The dependency information.'),
      description?: string(name='Description', description='The description.', example='Test'),
      envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
      id?: long(name='Id', description='The task ID. If you configure this parameter, full update is performed on the task. If you do not configure this parameter, another task is created.', example='1234'),
      inputs?: {
        variables?: [ 
          {
            name?: string(name='Name', description='The name of the variable.', example='key1'),
            type: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output

This parameter is required.', example='Constant'),
            value?: string(name='Value', description='The value of the variable.', example='value1'),
          }
        ](name='Variables', description='The variables.'),
      }(name='Inputs', description='The input information.'),
      name: string(name='Name', description='The name of the task.

This parameter is required.', example='SQL node'),
      outputs?: {
        taskOutputs?: [ 
          {
            output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
          }
        ](name='TaskOutputs', description='The task outputs.'),
        variables?: [ 
          {
            name?: string(name='Name', description='The name of the variable.', example='key1'),
            type: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output

This parameter is required.', example='Constant'),
            value?: string(name='Value', description='The value of the variable.', example='value1'),
          }
        ](name='Variables', description='The variables.'),
      }(name='Outputs', description='The output information.'),
      owner: string(name='Owner', description='The account ID of the owner.

This parameter is required.', example='1000'),
      rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
      rerunMode: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.

This parameter is required.', example='AllAllowed'),
      rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
      runtimeResource: {
        cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
        image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
        resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.

This parameter is required.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
      }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.

This parameter is required.'),
      script?: {
        content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
        parameters?: string(name='Parameters', description='The script parameters.', example='para1=$bizdate'),
      }(name='Script', description='The script information.'),
      tags?: [ 
        {
          key: string(name='Key', description='The tag key.

This parameter is required.', example='key1'),
          value?: string(name='Value', description='The tag value.', example='value1'),
        }
      ](name='Tags', description='The tags.'),
      timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
      trigger: {
        recurrence: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal

This parameter is required.', example='Normal'),
        type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
      }(name='Trigger', description='The trigger method.

This parameter is required.'),
      type: string(name='Type', description='The type of the task.

This parameter is required.', example='ODPS_SQL'),
    }
  ](name='Tasks', description='The tasks.', shrink='json', position='Body'),
  trigger: {
    cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
    endTime?: string(name='EndTime', description='The end time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler. The value of this parameter is in the `yyyy-mm-dd hh:mm:ss` format.', example='9999-01-01 00:00:00'),
    startTime?: string(name='StartTime', description='The start time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler. The value of this parameter is in the `yyyy-mm-dd hh:mm:ss` format.', example='1970-01-01 00:00:00'),
    type: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger

This parameter is required.', example='Scheduler'),
  }(name='Trigger', description='The trigger method.

This parameter is required.', shrink='json', position='Body'),
}

model UpdateWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateWorkflowResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateWorkflow  UpdateWorkflowRequest
  * @return UpdateWorkflowResponse
 */
async function updateWorkflow(request: UpdateWorkflowRequest): UpdateWorkflowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateWorkflow', 'POST', '/', 'json', true, 'form', request);
}

model UpdateWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='代表region的资源属性字段

This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10001', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the workflow. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
    "kind": "CycleWorkflow",
    "version": "1.1.0",
    "spec": {
        "name": "OpenAPI Test Workflow Demo",
        "type": "CycleWorkflow",
        "id": "652567824470354XXXX",
        "workflows": [
            {
                "id": "652567824470354XXXX",
                "script": {
                    "path": "XX/OpenAPI_Test/Workflow_Test/OpenAPI_Test_Workflow_Demo",
                    "runtime": {
                        "command": "WORKFLOW"
                    }
                },
                "trigger": {
                    "type": "Scheduler",
                    "cron": "00 02 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "strategy": {
                    "timeout": 0,
                    "instanceMode": "T+1",
                    "rerunMode": "Allowed",
                    "rerunTimes": 3,
                    "rerunInterval": 180000,
                    "failureStrategy": "Break"
                },
                "name": "OpenAPI Test Workflow Demo",
                "inputs": {},
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "workflow_output",
                            "artifactType": "NodeOutput",
                            "refTableName": "OpenAPI_Test_Workflow_Demo"
                        }
                    ]
                },
                "nodes": [],
                "dependencies": []
            }
        ]
    }
}', position='Body'),
}

model UpdateWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='20BF7E80-668A-5620-8AD8-879B8FEAXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @description >  You cannot use this API operation to create multiple workflows at a time. If you specify multiple workflows in the FlowSpec filed, only the first workflow is created. Other specified workflows and the nodes in the workflows are ignored. You can call the UpdateNode operation to update a node.
  * @param request  the request parameters of UpdateWorkflowDefinition  UpdateWorkflowDefinitionRequest
  * @return UpdateWorkflowDefinitionResponse
 */
async function updateWorkflowDefinition(request: UpdateWorkflowDefinitionRequest): UpdateWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model SuccessInfoValue = {
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
  message?: string(name='Message', description='The error message.', example='The task does not exist.'),
}

