/**
  *
  */
import BaseClientBuilder;
import TeaAsyncHandler;
import TeaRequest;
import AsyncRequestBody;
import RequestBody;
import AsyncResponseHandler;
import ClientConfiguration;
import ClientExecutionParams;
extends BaseClientBuilder;
type @product = string
type @version = string
type @endpointRule = string
type @endpointMap = map[string]string
type @REQUEST = TeaRequest
type @handler = TeaAsyncHandler

init(configuration: ClientConfiguration){
  @handler = new TeaAsyncHandler(configuration);
  @product = 'dataworks-public';
  @version = '2024-05-18';
  @endpointRule = 'regional';
  @endpointMap = {
    'ap-northeast-1' = 'dataworks.ap-northeast-1.aliyuncs.com',
    'ap-south-1' = 'dataworks.ap-south-1.aliyuncs.com',
    'ap-southeast-1' = 'dataworks.ap-southeast-1.aliyuncs.com',
    'ap-southeast-2' = 'dataworks.ap-southeast-2.aliyuncs.com',
    'ap-southeast-3' = 'dataworks.ap-southeast-3.aliyuncs.com',
    'ap-southeast-5' = 'dataworks.ap-southeast-5.aliyuncs.com',
    'cn-beijing' = 'dataworks.cn-beijing.aliyuncs.com',
    'cn-chengdu' = 'dataworks.cn-chengdu.aliyuncs.com',
    'cn-hangzhou' = 'dataworks.cn-hangzhou.aliyuncs.com',
    'cn-hongkong' = 'dataworks.cn-hongkong.aliyuncs.com',
    'cn-huhehaote' = 'dataworks.aliyuncs.com',
    'cn-qingdao' = 'dataworks.aliyuncs.com',
    'cn-shanghai' = 'dataworks.cn-shanghai.aliyuncs.com',
    'cn-shenzhen' = 'dataworks.cn-shenzhen.aliyuncs.com',
    'cn-zhangjiakou' = 'dataworks.aliyuncs.com',
    'eu-central-1' = 'dataworks.eu-central-1.aliyuncs.com',
    'eu-west-1' = 'dataworks.eu-west-1.aliyuncs.com',
    'me-east-1' = 'dataworks.me-east-1.aliyuncs.com',
    'us-east-1' = 'dataworks.us-east-1.aliyuncs.com',
    'us-west-1' = 'dataworks.us-west-1.aliyuncs.com',
    'cn-hangzhou-finance' = 'dataworks.aliyuncs.com',
    'cn-shenzhen-finance-1' = 'dataworks.aliyuncs.com',
    'cn-shanghai-finance-1' = 'dataworks.aliyuncs.com',
    'cn-north-2-gov-1' = 'dataworks.aliyuncs.com',
  };
}

function close(): void {
  @handler.close();
}

model DataQualityEvaluationTask {
  dataSourceId?: long(name='DataSourceId', example='201'),
  description?: string(name='Description', example='This is a daily run data quality evaluation plan.'),
  hooks?: [ 
    {
      condition?: string(name='Condition', example='${severity} == "High" AND ${status} == "Critical"'),
      type?: string(name='Type', example='BlockTaskInstance'),
    }
  ](name='Hooks'),
  id?: long(name='Id', example='10001'),
  name?: string(name='Name', example='质量校验任务'),
  notifications?: [ 
    {
      condition?: string(name='Condition', example='${blockType} == "Strong"'),
      notifications?: [ 
        {
          notificationChannels?: [ 
            {
              channels?: [ string ](name='Channels'),
            }
          ](name='NotificationChannels'),
          notificationReceivers?: [ 
            {
              extension?: string(name='Extension', example='{"atAll":"true"}'),
              receiverType?: string(name='ReceiverType', example='AliUid'),
              receiverValues?: [ string ](name='ReceiverValues'),
            }
          ](name='NotificationReceivers'),
        }
      ](name='Notifications'),
    }
  ](name='Notifications'),
  projectId?: long(name='ProjectId', example='100'),
  runtimeConf?: string(name='RuntimeConf', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }'),
  target?: {
    databaseType?: string(name='DatabaseType', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', example='ds=$[yyyymmdd-1]'),
    tableGuid?: string(name='TableGuid', example='odps.unit_test.tb_unit_test'),
    type?: string(name='Type', example='Table'),
  }(name='Target'),
  tenantId?: long(name='TenantId', example='10'),
  trigger?: {
    taskIds?: [ long ](name='TaskIds'),
    type?: string(name='Type', example='ByScheduledTaskInstance'),
  }(name='Trigger'),
}

model DataQualityEvaluationTaskInstance {
  createTime?: long(name='CreateTime', example='1710239005403'),
  finishTime?: long(name='FinishTime', example='1710239005403'),
  id?: long(name='Id', example='10001'),
  status?: string(name='Status', example='Passed'),
  task?: {
    dataSourceId?: long(name='DataSourceId', example='201'),
    hooks?: [ 
      {
        condition?: string(name='Condition', example='${severity} == "High" AND ${status} == "Critical"'),
        type?: string(name='Type', example='BlockTaskInstance'),
      }
    ](name='Hooks'),
    id?: long(name='Id', example='10001'),
    name?: string(name='Name', example='质量校验任务'),
    notifications?: [ 
      {
        condition?: string(name='Condition', example='${blockType} == "Strong"'),
        notifications?: [ 
          {
            notificationChannels?: [ 
              {
                channels?: [ string ](name='Channels'),
              }
            ](name='NotificationChannels'),
            notificationReceivers?: [ 
              {
                extension?: string(name='Extension', example='{"atAll":"true"}'),
                receiverType?: string(name='ReceiverType', example='AliUid'),
                receiverValues?: [ string ](name='ReceiverValues'),
              }
            ](name='NotificationReceivers'),
          }
        ](name='Notifications'),
      }
    ](name='Notifications'),
    projectId?: long(name='ProjectId'),
    runtimeConf?: string(name='RuntimeConf', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }'),
    target?: {
      databaseType?: string(name='DatabaseType', example='maxcompute'),
      partitionSpec?: string(name='PartitionSpec', example='ds=$[yyyymmdd-1]'),
      tableGuid?: string(name='TableGuid', example='odps.unit_test.tb_unit_test'),
      type?: string(name='Type', example='Table'),
    }(name='Target'),
    tenantId?: long(name='TenantId'),
    trigger?: {
      taskIds?: [ long ](name='TaskIds'),
      type?: string(name='Type', example='ByScheduledTaskInstance'),
    }(name='Trigger'),
  }(name='Task'),
}

model DataQualityResult {
  details?: [ 
    {
      checkedValue?: string(name='CheckedValue', example='100.0'),
      referencedValue?: string(name='ReferencedValue', example='0.0'),
      status?: string(name='Status', example='Passed'),
    }
  ](name='Details'),
  id?: long(name='Id', example='10001'),
  rule?: {
    checkingConfig?: {
      referencedSamplesFilter?: string(name='ReferencedSamplesFilter', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
      thresholds?: {
        critical?: {
          operator?: string(name='Operator', example='>'),
          value?: string(name='Value', example='100.0'),
        }(name='Critical'),
        expected?: {
          operator?: string(name='Operator', example='>'),
          value?: string(name='Value', example='100.0'),
        }(name='Expected'),
        warned?: {
          operator?: string(name='Operator', example='>'),
          value?: string(name='Value', example='100.0'),
        }(name='Warned'),
      }(name='Thresholds'),
      type?: string(name='Type', example='Fixed'),
    }(name='CheckingConfig'),
    description?: string(name='Description', example='this is a odps _sql task'),
    enabled?: boolean(name='Enabled', example='true'),
    errorHandlers?: [ 
      {
        errorDataFilter?: string(name='ErrorDataFilter', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
        type?: string(name='Type', example='SaveErrorData'),
      }
    ](name='ErrorHandlers'),
    id?: long(name='Id', example='100001'),
    name?: string(name='Name', example='表不能为空'),
    projectId?: long(name='ProjectId', example='100'),
    samplingConfig?: {
      metric?: string(name='Metric', example='Min'),
      metricParameters?: string(name='MetricParameters', example='{ "Columns": [ "id", "name" ] }'),
      samplingFilter?: string(name='SamplingFilter', example='id IS NULL'),
      settingConfig?: string(name='SettingConfig', example='SET odps.sql.udf.timeout=600s;'),
    }(name='SamplingConfig'),
    severity?: string(name='Severity', example='High'),
    target?: {
      databaseType?: string(name='DatabaseType', example='maxcompute'),
      partitionSpec?: string(name='PartitionSpec', example='ds=$[yyyymmdd-1]'),
      tableGuid?: string(name='TableGuid', example='odps.unit_test.tb_unit_test'),
      type?: string(name='Type', example='Table'),
    }(name='Target'),
    templateCode?: string(name='TemplateCode', example='SYSTEM:user_defined_sql'),
    tenantId?: long(name='TenantId', example='1'),
  }(name='Rule'),
  sample?: string(name='Sample', example='[   {     "gender": "male",     "_count": 100   }, {     "gender": "female",     "_count": 100   } ]'),
  status?: string(name='Status', example='Passed'),
  taskInstanceId?: long(name='TaskInstanceId', example='20001'),
}

model DataQualityRule {
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    thresholds?: {
      critical?: {
        expression?: string(name='Expression', example='波动率类型规则使用，通过表达式来表示波动阈值。如：波动上升大于0.01： $checkValue > 0.01  波动下降大于0.01：$checkValue < -0.01   波动率绝对值：abs($checkValue) > 0.01'),
        operator?: string(name='Operator', example='>'),
        value?: string(name='Value', example='100.0'),
      }(name='Critical'),
      expected?: {
        expression?: string(name='Expression', example='波动率类型规则使用，通过表达式来表示波动阈值。如：波动上升大于0.01： $checkValue > 0.01  波动下降大于0.01：$checkValue < -0.01   波动率绝对值：abs($checkValue) > 0.01'),
        operator?: string(name='Operator', example='>'),
        value?: string(name='Value', example='100.0'),
      }(name='Expected'),
      warned?: {
        expression?: string(name='Expression', example='波动率类型规则使用，通过表达式来表示波动阈值。如：波动上升大于0.01： $checkValue > 0.01  波动下降大于0.01：$checkValue < -0.01   波动率绝对值：abs($checkValue) > 0.01'),
        operator?: string(name='Operator', example='>'),
        value?: string(name='Value', example='100.0'),
      }(name='Warned'),
    }(name='Thresholds'),
    type?: string(name='Type', example='Fixed'),
  }(name='CheckingConfig'),
  description?: string(name='Description', example='this is a odps _sql task'),
  enabled?: boolean(name='Enabled', example='true'),
  errorHandlers?: [ 
    {
      errorDataFilter?: string(name='ErrorDataFilter', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
      type?: string(name='Type', example='SaveErrorData'),
    }
  ](name='ErrorHandlers'),
  id?: long(name='Id', example='1'),
  name?: string(name='Name', example='表不能为空'),
  projectId?: long(name='ProjectId', example='100'),
  samplingConfig?: {
    metric?: string(name='Metric', example='Min'),
    metricParameters?: string(name='MetricParameters', example='{ "Columns": [ "id", "name" ] }'),
    samplingFilter?: string(name='SamplingFilter', example='id IS NULL'),
    settingConfig?: string(name='SettingConfig', example='SET odps.sql.udf.timeout=600s;'),
  }(name='SamplingConfig'),
  severity?: string(name='Severity', example='High'),
  target?: {
    databaseType?: string(name='DatabaseType', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', example='ds=$[yyyymmdd-1]'),
    tableGuid?: string(name='TableGuid', example='odps.unit_test.tb_unit_test'),
    type?: string(name='Type', example='Table'),
  }(name='Target'),
  templateCode?: string(name='TemplateCode', example='SYSTEM:user_defined_sql'),
  tenantId?: long(name='TenantId', example='1'),
}

model DataQualityRuleTemplate {
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    type?: string(name='Type', example='Fixed'),
  }(name='CheckingConfig'),
  code?: string(name='Code'),
  directoryPath?: string(name='DirectoryPath', example='/ods/订单数据'),
  name?: string(name='Name'),
  projectId?: long(name='ProjectId'),
  samplingConfig?: {
    metric?: string(name='Metric', example='Min'),
    metricParameters?: string(name='MetricParameters', example='{ "SQL": "SELECT min(id) from table;" }'),
    settingConfig?: string(name='SettingConfig', example='SET odps.sql.udf.timeout=600s;'),
  }(name='SamplingConfig'),
  tenantId?: long(name='TenantId'),
  visibleScope?: string(name='VisibleScope', example='Project'),
}

model AbolishDeploymentRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID of the process.

This parameter is required.', example='1606087c-9ac4-43f0-83a8-0b5ced21XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model AbolishDeploymentResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='55D786C9-DD57-524D-884C-C5239278XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model AbolishDeploymentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AbolishDeploymentResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AbolishDeployment  AbolishDeploymentRequest
  * @return AbolishDeploymentResponse
 */
async function abolishDeployment(request: AbolishDeploymentRequest): AbolishDeploymentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AbolishDeployment', 'POST', '/', 'json', true, 'form', request);
}

model AssociateProjectToResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace with which you want to associate the resource group.

This parameter is required.', example='1000', position='Body'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
}

model AssociateProjectToResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to locate logs and troubleshoot issues.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model AssociateProjectToResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AssociateProjectToResourceGroupResponseBody(name='body'),
}

/**
  * @description 1.  You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * 2.  Your account must be assigned one of the following roles of the desired workspace:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of AssociateProjectToResourceGroup  AssociateProjectToResourceGroupRequest
  * @return AssociateProjectToResourceGroupResponse
 */
async function associateProjectToResourceGroup(request: AssociateProjectToResourceGroupRequest): AssociateProjectToResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AssociateProjectToResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model AttachDataQualityRulesToEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityEvaluationTaskId: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task that is associated with the rule.

This parameter is required.', example='200001', position='Body'),
  dataQualityRuleIds: [ long ](name='DataQualityRuleIds', description='The IDs of the monitoring rules.

This parameter is required.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID. You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model AttachDataQualityRulesToEvaluationTaskResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='E6F0DBDD-5AD8-4870-A6A0'),
  success?: boolean(name='Success', description='The value of the association is as follows:
- true: The call is successful.
- false: the call failed.', example='true'),
}

model AttachDataQualityRulesToEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AttachDataQualityRulesToEvaluationTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of AttachDataQualityRulesToEvaluationTask  AttachDataQualityRulesToEvaluationTaskRequest
  * @return AttachDataQualityRulesToEvaluationTaskResponse
 */
async function attachDataQualityRulesToEvaluationTask(request: AttachDataQualityRulesToEvaluationTaskRequest): AttachDataQualityRulesToEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AttachDataQualityRulesToEvaluationTask', 'POST', '/', 'json', true, 'form', request);
}

model BatchUpdateTasksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  tasks?: [ 
    {
      dataSource?: {
        name?: string(name='Name', description='The name of the data source.', example='odps_test'),
      }(name='DataSource', description='The information about the associated data source.'),
      description?: string(name='Description', description='The description of the task.', example='test'),
      envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
      id: long(name='Id', description='The task ID.

This parameter is required.', example='1234'),
      name?: string(name='Name', description='The name of the task.', example='SQL node'),
      owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
      rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
      rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.', example='AllAllowed'),
      rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
      runtimeResource?: {
        cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
        image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
        resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
      }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
      tags?: [ 
        {
          key: string(name='Key', description='The tag key.

This parameter is required.', example='key1'),
          value?: string(name='Value', description='The tag value.', example='value1'),
        }
      ](name='Tags', description='The tags.'),
      timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
      trigger?: {
        cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
        endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
        recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
        type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: periodic scheduling
*   Manual: manual scheduling', example='Scheduler'),
      }(name='Trigger', description='The trigger method.'),
    }
  ](name='Tasks', description='The tasks.', shrink='json', position='Body'),
}

model BatchUpdateTasksResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The task ID serves as a key, and the result serves as a value.'),
}

model BatchUpdateTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: BatchUpdateTasksResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of BatchUpdateTasks  BatchUpdateTasksRequest
  * @return BatchUpdateTasksResponse
 */
async function batchUpdateTasks(request: BatchUpdateTasksRequest): BatchUpdateTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'BatchUpdateTasks', 'POST', '/', 'json', true, 'form', request);
}

model CloneDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  cloneDataSourceName: string(name='CloneDataSourceName', description='The name of the destination data source The name can contain letters, digits, and underscores (_), and must start with a letter. It cannot exceed 60 characters in length.

This parameter is required.', example='demo_holo_datasource', position='Query'),
  id: long(name='Id', description='The data source ID.

This parameter is required.', example='16036', position='Query'),
}

model CloneDataSourceResponseBody = {
  id?: long(name='Id', description='The ID of the cloned data source.', example='19715'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='FCD583B9-346B-5E75-82C1-4A7C192C48DB'),
}

model CloneDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CloneDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of CloneDataSource  CloneDataSourceRequest
  * @return CloneDataSourceResponse
 */
async function cloneDataSource(request: CloneDataSourceRequest): CloneDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CloneDataSource', 'POST', '/', 'json', false, 'json', request);
}

model CreateAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  enabled: boolean(name='Enabled', description='Indicates whether the rule is enabled.

This parameter is required.', example='true', position='Query'),
  name: string(name='Name', description='The name of the rule.

This parameter is required.', example='xm_create_test', position='Query'),
  notification?: {
    channels: [ string ](name='Channels', description='The alert channels.

This parameter is required.'),
    intervalInMinutes?: int32(name='IntervalInMinutes', description='The interval at which an alert notification is sent. Unit: minutes. Valid values: 5 to 10,000.', example='30'),
    maximum?: int32(name='Maximum', description='The maximum number of times an alert notification is sent within one calendar day. Valid values: 1 to 10,000.', example='3'),
    receivers: [ 
      {
        extension?: string(name='Extension', description='The additional configuration of the alert recipient. If the ReceiverType parameter is set to DingdingUrl, you can set this parameter to {"atAll":true} to remind all members in a DingTalk group.', example='{"atAll":true}'),
        receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid valves:

*   AliUid: Alibaba Cloud account ID.
*   Shift Schedules: The personnel in a shift schedule.
*   TaskOwner: The node owner. This parameter is available for custom alerts and event alerts.
*   Owner: The baseline owner. This parameter is available for baseline alerts.
*   WebhookUrl: URL of a custom webhook.
*   DingdingUrl: DingTalk chatbot URL.
*   FeishuUrl: Lark chatbot URL.
*   WeixinUrl: WeCom chatbot URL.', example='TaskOwner'),
        receiverValues?: [ string ](name='ReceiverValues', description='The IDs of the alert recipients.'),
      }
    ](name='Receivers', description='The alert recipient.

This parameter is required.'),
    silenceEndTime?: string(name='SilenceEndTime', description='The end of the time range for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
    silenceStartTime?: string(name='SilenceStartTime', description='The beginning of the time range for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
  }(name='Notification', description='The configuration for the alert notification.', shrink='json', position='Query'),
  owner: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.

This parameter is required.', example='279114181716147735', position='Query'),
  triggerCondition: {
    extension?: {
      cycleUnfinished?: {
        cycleAndTime?: [ 
          {
            cycleId?: int32(name='CycleId', description='The ID of the scheduling cycle of the instance. Valid values: [1,288].', example='1'),
            time?: string(name='Time', description='The latest completion time of the instance within the scheduling cycle. The time is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
          }
        ](name='CycleAndTime', description='The configurations of the scheduling cycle and timeout period of the instance.'),
      }(name='CycleUnfinished', description='The configuration for an alert of the CycleUnfinished type.'),
      error?: {
        autoRerunAlertEnabled?: boolean(name='AutoRerunAlertEnabled', description='Specifies whether to trigger an alert if a batch synchronization task is automatically rerun upon a failure.', example='false'),
        streamTaskIds?: [ long ](name='StreamTaskIds', description='The IDs of the real-time computing tasks. This parameter is required when you monitor real-time computing tasks.'),
      }(name='Error', description='The configuration for an alert of the Error type.'),
      instanceErrorCount?: {
        count?: int32(name='Count', description='The maximum number of instances on which an error occurs. Valid values: [1,10000].', example='5'),
      }(name='InstanceErrorCount', description='The configuration for an alert of the InstanceErrorCount type.'),
      instanceErrorPercentage?: {
        percentage?: int32(name='Percentage', description='The maximum percentage of instances on which an error occurs in the workspace to the total number of instances. Valid values: [1-100].', example='5'),
      }(name='InstanceErrorPercentage', description='The configuration for an alert of the InstanceErrorPercentage type.'),
      instanceTransferFluctuate?: {
        percentage?: int32(name='Percentage', description='The maximum percentage of fluctuation in the number of auto triggered node instances that are generated in your workspace. Valid values: [1-100].', example='10'),
        trend?: string(name='Trend', description='The way in which the number of auto triggered node instances that are generated in your workspace fluctuates. Valid values:

*   abs: the absolute value. The number of instances increases or decreases.
*   increase: The number of instances increases.
*   decrease: The number of instances decreases.', example='abs'),
      }(name='InstanceTransferFluctuate', description='The configuration for an alert of the InstanceTransferFluctuate type.'),
      timeout?: {
        timeoutInMinutes?: int32(name='TimeoutInMinutes', description='The timeout period. Unit: minutes. Valid values: [1, 21600].', example='10'),
      }(name='Timeout', description='The configuration for an alert of the Timeout type.'),
      unFinished?: {
        unFinishedTime?: string(name='UnFinishedTime', description='The latest completion time of the instance. The period is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='30:00'),
      }(name='UnFinished', description='The configuration for an alert of the UnFinished type.'),
    }(name='Extension', description='The extended information about the rule. This parameter is required for specific types of alerts.'),
    target?: {
      allowTasks?: [ long ](name='AllowTasks', description='The nodes that are not to be monitored.'),
      ids?: [ long ](name='Ids', description='The IDs of monitored objects.'),
      type?: string(name='Type', description='The type of the monitored objects. Valid values:

*   Task: node
*   Baseline: baseline
*   Project: workspace
*   BizProcess: workflow', example='Task'),
    }(name='Target', description='The monitored objects.'),
    type?: string(name='Type', description='The alert type. Valid values:

*   Finished: An instance is successfully run.
*   UnFinished: An instance does not finish running before a specified point in time.
*   Error: An error occurs on an instance.
*   CycleUnfinished: An instance does not finish running as expected within a specific cycle.
*   Timeout: An instance times out.
*   InstanceTransferComplete: An instance is generated by the auto triggered node.
*   InstanceTransferFluctuate: The number of generated instances fluctuates.
*   ExhaustedError: An error persists after an instance is automatically rerun.
*   InstanceKeyword: An instance with errors contains specified keywords.
*   InstanceErrorCount: The number of instances on which an error occurs reaches a specified threshold.
*   InstanceErrorPercentage: The proportion of instances on which an error occurs in the workspace to the total number of instances reaches a specified threshold.
*   ResourceGroupPercentage: The usage rate of the resource group reaches a specified threshold.
*   ResourceGroupWaitCount: The number of instances that are waiting for resources in the resource group reaches a specified threshold.', example='Error'),
  }(name='TriggerCondition', description='The alert triggering condition.

This parameter is required.', shrink='json', position='Query'),
}

model CreateAlertRuleResponseBody = {
  id?: long(name='Id', description='The rule ID.', example='123123'),
  requestId?: string(name='RequestId', description='The request ID.', example='A6C6B486-E3A2-5D52-9E76-D9380485D946'),
}

model CreateAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateAlertRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateAlertRule  CreateAlertRuleRequest
  * @return CreateAlertRuleResponse
 */
async function createAlertRule(request: CreateAlertRuleRequest): CreateAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateAlertRule', 'POST', '/', 'json', false, 'json', request);
}

model CreateDIAlarmRuleRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientToken?: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.', example='ABFUOEUOTRTRJKE', position='Query'),
  DIJobId: long(name='DIJobId', description='The ID of the synchronization task with which the alert rule is associated.

This parameter is required.', example='1', position='Query'),
  description?: string(name='Description', description='The description of the alert rule.', example='The description of the alert rule.', position='Query'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the alert rule. By default, the alert rule is disabled.', example='true', position='Query'),
  metricType: string(name='MetricType', description='The metric type in the alert rule. Valid values:

*   Heartbeat
*   FailoverCount
*   Delay
*   DdlReport
*   ResourceUtilization

This parameter is required.', example='Heartbeat', position='Query'),
  name: string(name='Name', description='The name of the alert rule.

This parameter is required.', example='alartRule', position='Query'),
  notificationSettings: {
    inhibitionInterval?: int32(name='InhibitionInterval', description='The duration of the alert suppression interval. Default value: 5. Unit: minutes.', example='5', deprecated='true'),
    muteInterval?: int32(name='MuteInterval', description='告警抑制间隔时长，单位分钟，默认5分钟。', example='5'),
    notificationChannels?: [ 
      {
        channels?: [ string ](name='Channels', description='The alert notification methods. Valid values:

*   Mail
*   Phone
*   Sms
*   Ding'),
        severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Warning'),
      }
    ](name='NotificationChannels', description='The alert notification methods.'),
    notificationReceivers?: [ 
      {
        receiverType?: string(name='ReceiverType', description='The recipient type. Valid values: AliyunUid, DingToken, FeishuToken, and WebHookUrl.', example='DingToken'),
        receiverValues?: [ string ](name='ReceiverValues', description='The recipient.

*   If the ReceiverType parameter is set to AliyunUid, set this parameter to the Alibaba Cloud account ID of a user.
*   If the ReceiverType parameter is set to DingToken, set this parameter to the token of a DingTalk chatbot.'),
      }
    ](name='NotificationReceivers', description='The settings of alert notification recipients.'),
  }(name='NotificationSettings', description='The alert notification settings.

This parameter is required.', shrink='json', position='Query'),
  triggerConditions: [ 
    {
      ddlReportTags?: [ string ](name='DdlReportTags', description='The types of DDL operations for which the alert rule takes effect.', deprecated='true'),
      ddlTypes?: [ string ](name='DdlTypes', description='在DDL通知的时候才生效，需要生效的DDL列表。'),
      duration?: long(name='Duration', description='The time interval for alert calculation. Unit: minutes.', example='10'),
      severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Warning'),
      threshold?: long(name='Threshold', description='The alert threshold.

*   If the alert rule is for task status, you do not need to specify a threshold.
*   If the alert rule is for failovers, you must specify the number of failovers.
*   If the alert rule is for latency, you must specify the latency duration, in seconds.', example='10'),
    }
  ](name='TriggerConditions', description='The conditions that can trigger the alert rule.

This parameter is required.', shrink='json', position='Query'),
}

model CreateDIAlarmRuleResponseBody = {
  DIAlarmRuleId?: string(name='DIAlarmRuleId', description='This parameter is deprecated and is replaced by the Id parameter.', example='1', deprecated='true'),
  id?: long(name='Id', description='The ID of the alert rule.', example='1'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='C636A747-7E4E-594D-94CD-2B4F8A9A9A63'),
}

model CreateDIAlarmRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDIAlarmRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDIAlarmRule  CreateDIAlarmRuleRequest
  * @return CreateDIAlarmRuleResponse
 */
async function createDIAlarmRule(request: CreateDIAlarmRuleRequest): CreateDIAlarmRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDIAlarmRule', 'GET', '/', 'json', false, 'json', request);
}

model CreateDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  description?: string(name='Description', description='The description of the synchronization task.', example='The description of the synchronization task.', position='Query'),
  destinationDataSourceSettings: [ 
    {
      dataSourceName?: string(name='DataSourceName', description='The name of the data source.', example='holo_datasource_1'),
    }
  ](name='DestinationDataSourceSettings', description='The settings of the destination. Only a single destination is supported.

This parameter is required.', shrink='json', position='Query'),
  destinationDataSourceType: string(name='DestinationDataSourceType', description='The destination type. Valid values: Hologres, OSS-HDFS, OSS, MaxCompute, LogHub, StarRocks, DataHub, AnalyticDB for MySQL, Kafka, and Hive.

This parameter is required.', example='Hologres', position='Query'),
  jobName?: string(name='JobName', description='This parameter is deprecated and is replaced by the Name parameter.', example='mysql_to_holo_sync_8772', deprecated='true', position='Query'),
  jobSettings?: {
    channelSettings?: string(name='ChannelSettings', description='The channel control settings for the synchronization task. You can configure special channel control settings for the following synchronization links: data synchronization between Hologres data sources and data synchronization from Hologres to Kafka.

1.  Data synchronization from Hologres to Kafka

*   Example: {"destinationChannelSettings":{"kafkaClientProperties":[{"key":"linger.ms","value":"100"}],"keyColumns":["col3"],"writeMode":"canal"}}
*   kafkaClientProperties: the parameters related to a Kafka producer, which are used when you write data to a Kafka data source.
*   keyColumns: the names of Kafka columns to which you want to write data.
*   writeMode: the writing format. Valid values: json and canal.

2.  Data synchronization between Hologres data sources

*   Example: {"destinationChannelSettings":{"conflictMode":"replace","dynamicColumnAction":"replay","writeMode":"replay"}}
*   conflictMode: the policy used to handle a conflict that occurs during data writing to Hologres. Valid values: replace and ignore.
*   writeMode: the mode in which you want to write data to Hologres. Valid values: replay and insert.
*   dynamicColumnAction: the method used to write data to dynamic columns in a Hologres table. Valid values: replay, insert, and ignore.', example='{"structInfo":"MANAGED","storageType":"TEXTFILE","writeMode":"APPEND","partitionColumns":[{"columnName":"pt","columnType":"STRING","comment":""}],"fieldDelimiter":""}'),
    columnDataTypeSettings?: [ 
      {
        destinationDataType?: string(name='DestinationDataType', description='The data type of the destination field. Valid values: bigint, boolean, string, text, datetime, timestamp, decimal, and binary. Different types of data sources support different data types.', example='text'),
        sourceDataType?: string(name='SourceDataType', description='The data type of the source field. Valid values: Valid values: bigint, boolean, string, text, datetime, timestamp, decimal, and binary. Different types of data sources support different data types.', example='bigint'),
      }
    ](name='ColumnDataTypeSettings', description='The data type mappings between source fields and destination fields.

>  "ColumnDataTypeSettings":[ { "SourceDataType":"Bigint", "DestinationDataType":"Text" } ]'),
    cycleScheduleSettings?: {
      cycleMigrationType?: string(name='CycleMigrationType', description='The synchronization type that requires periodic scheduling. Valid values:

*   Full: full synchronization
*   OfflineIncremental: batch incremental synchronization', example='Full'),
      scheduleParameters?: string(name='ScheduleParameters', description='The scheduling parameters.', example='bizdate=$bizdate'),
    }(name='CycleScheduleSettings', description='The settings for periodic scheduling.'),
    ddlHandlingSettings?: [ 
      {
        action?: string(name='Action', description='The processing policy. Valid values:

*   Ignore: ignores a DDL message.
*   Critical: reports an error for a DDL message.
*   Normal: normally processes a DDL message.', example='Critical'),
        type?: string(name='Type', description='The type of the DDL operation. Valid values:

*   RenameColumn
*   ModifyColumn
*   CreateTable
*   TruncateTable
*   DropTable
*   DropColumn
*   AddColumn', example='AddColumn'),
      }
    ](name='DdlHandlingSettings', description='The processing settings for DDL messages.

>  "DDLHandlingSettings":[ { "Type":"Insert", "Action":"Normal" } ]'),
    runtimeSettings?: [ 
      {
        name?: string(name='Name', description='The name of the configuration item. Valid values:

*   src.offline.datasource.max.connection: specifies the maximum number of connections that are allowed for reading data from the source of a batch synchronization task.
*   dst.offline.truncate: specifies whether to clear the destination table before data writing.
*   runtime.offline.speed.limit.enable: specifies whether throttling is enabled for a batch synchronization task.
*   runtime.offline.concurrent: specifies the maximum number of parallel threads that are allowed for a batch synchronization task.
*   runtime.enable.auto.create.schema: specifies whether schemas are automatically created in the destination of a synchronization task.
*   runtime.realtime.concurrent: specifies the maximum number of parallel threads that are allowed for a real-time synchronization task.
*   runtime.realtime.failover.minute.dataxcdc: The maximum waiting duration before a synchronization task retries the next restart if the previous restart fails after failover occurs. Unit: minutes.
*   runtime.realtime.failover.times.dataxcdc: The maximum number of failures that are allowed for restarting a synchronization task after failovers occur.', example='runtime.offline.concurrent'),
        value?: string(name='Value', description='The value of the configuration item.', example='1'),
      }
    ](name='RuntimeSettings', description='The runtime settings.'),
  }(name='JobSettings', description='The settings for the dimension of the synchronization task. The settings include processing policies for DDL messages, policies for data type mappings between source fields and destination fields, and runtime parameters of the synchronization task.', shrink='json', position='Query'),
  migrationType: string(name='MigrationType', description='The synchronization type. Valid values:

*   FullAndRealtimeIncremental: one-time full synchronization and real-time incremental synchronization
*   RealtimeIncremental: real-time incremental synchronization
*   Full: full synchronization
*   OfflineIncremental: batch incremental synchronization
*   FullAndOfflineIncremental: one-time full synchronization and batch incremental synchronization

This parameter is required.', example='FullAndRealtimeIncremental', position='Query'),
  name?: string(name='Name', description='The name of the synchronization task.', example='mysql_to_holo_sync_8772', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
  resourceSettings: {
    offlineResourceSettings?: {
      requestedCu?: double(name='RequestedCu', description='The number of compute units (CUs) in the resource group for Data Integration that are used for batch synchronization.', example='2.0'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for Data Integration used for batch synchronization.', example='S_res_group_111_222'),
    }(name='OfflineResourceSettings', description='The resource used for batch synchronization.'),
    realtimeResourceSettings?: {
      requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for Data Integration that are used for real-time synchronization.', example='2.0'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for Data Integration used for real-time synchronization.', example='S_res_group_111_222'),
    }(name='RealtimeResourceSettings', description='The resource used for real-time synchronization.'),
    scheduleResourceSettings?: {
      requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for scheduling that are used for batch synchronization.', example='2.0'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for scheduling used for batch synchronization.', example='S_res_group_235454102432001_1579085295030'),
    }(name='ScheduleResourceSettings', description='The resource used for scheduling.'),
  }(name='ResourceSettings', description='The resource settings.

This parameter is required.', shrink='json', position='Query'),
  sourceDataSourceSettings: [ 
    {
      dataSourceName?: string(name='DataSourceName', description='The name of the data source.', example='mysql_datasource_1'),
      dataSourceProperties?: {
        encoding?: string(name='Encoding', description='The encoding format of the database.', example='UTF-8'),
        timezone?: string(name='Timezone', description='The time zone.', example='GMT+8'),
      }(name='DataSourceProperties', description='The properties of the data source.'),
    }
  ](name='SourceDataSourceSettings', description='The settings of the source. Only a single source is supported.

This parameter is required.', shrink='json', position='Query'),
  sourceDataSourceType: string(name='SourceDataSourceType', description='The source type. Valid values: PolarDB, MySQL, Kafka, LogHub, Hologres, Oracle, OceanBase, MongoDB, Redshift, Hive, SQL Server, Doris, and ClickHouse.

This parameter is required.', example='MySQL', position='Query'),
  tableMappings: [ 
    {
      sourceObjectSelectionRules?: [ 
        {
          action?: string(name='Action', description='The operation that is performed to select objects. Valid values: Include and Exclude.', example='Include'),
          expression?: string(name='Expression', description='The expression.', example='mysql_table_1'),
          expressionType?: string(name='ExpressionType', description='The expression type. Valid values: Exact and Regex.', example='Exact'),
          objectType?: string(name='ObjectType', description='The object type. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
        }
      ](name='SourceObjectSelectionRules', description='The list of rules used to select synchronization objects in the source.'),
      transformationRules?: [ 
        {
          ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml
*   DefineIncrementalCondition
*   DefineCycleScheduleSettings
*   DefineRuntimeSettings
*   DefinePartitionKey', example='Rename'),
          ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
          ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which you want to perform the action. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
        }
      ](name='TransformationRules', description='The list of transformation rules that you want to apply to the synchronization objects selected from the source. Each entry in the list defines a transformation rule.'),
    }
  ](name='TableMappings', description='The list of mappings between rules used to select synchronization objects in the source and transformation rules applied to the selected synchronization objects. Each entry in the list displays a mapping between a rule used to select synchronization objects and a transformation rule applied to the selected synchronization objects.

>  [ { "SourceObjectSelectionRules":[ { "ObjectType":"Database", "Action":"Include", "ExpressionType":"Exact", "Expression":"biz_db" }, { "ObjectType":"Schema", "Action":"Include", "ExpressionType":"Exact", "Expression":"s1" }, { "ObjectType":"Table", "Action":"Include", "ExpressionType":"Exact", "Expression":"table1" } ], "TransformationRuleNames":[ { "RuleName":"my_database_rename_rule", "RuleActionType":"Rename", "RuleTargetType":"Schema" } ] } ]

This parameter is required.', shrink='json', position='Query'),
  transformationRules?: [ 
    {
      ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml
*   DefineIncrementalCondition
*   DefineCycleScheduleSettings
*   DefinePartitionKey', example='Rename'),
      ruleExpression?: string(name='RuleExpression', description='The expression of the rule. The expression must be a JSON string.

1.  Example of a renaming rule

*   Example: {"expression":"${srcDatasourceName}_${srcDatabaseName}_0922" }
*   expression: the expression of the renaming rule. You can use the following variables in an expression: ${srcDatasourceName}, ${srcDatabaseName}, and ${srcTableName}. ${srcDatasourceName} specifies the name of the source. ${srcDatabaseName} specifies the name of a source database. ${srcTableName} specifies the name of a source table.

2.  Example of a column addition rule

*   Example: {"columns":[{"columnName":"my_add_column","columnValueType":"Constant","columnValue":"123"}]}
*   If you do not configure such a rule, no fields are added to the destination and no values are assigned by default.
*   columnName: the name of the field that is added.
*   columnValueType: the value type of the field. Valid values: Constant and Variable.
*   columnValue: the value of the field. If the columnValueType parameter is set to Constant, set the columnValue parameter to a constant of the STRING data type. If the columnValueType parameter is set to Variable, set the columnValue parameter to a built-in variable. The following built-in variables are supported: EXECUTE_TIME (LONG data type), DB_NAME_SRC (STRING data type), DATASOURCE_NAME_SRC (STRING data type), TABLE_NAME_SRC (STRING data type), DB_NAME_DEST (STRING data type), DATASOURCE_NAME_DEST (STRING data type), TABLE_NAME_DEST (STRING data type), and DB_NAME_SRC_TRANSED (STRING data type). EXECUTE_TIME specifies the execution time. DB_NAME_SRC specifies the name of a source database. DATASOURCE_NAME_SRC specifies the name of the source. TABLE_NAME_SRC specifies the name of a source table. DB_NAME_DEST specifies the name of a destination database. DATASOURCE_NAME_DEST specifies the name of the destination. TABLE_NAME_DEST specifies the name of a destination table. DB_NAME_SRC_TRANSED specifies the database name obtained after a transformation.

3.  Example of a rule used to specify primary key fields for a destination table

*   Example: {"columns":["ukcolumn1","ukcolumn2"]}
*   If you do not configure such a rule, the primary key fields in the mapped source table are used for the destination table by default.
*   If the destination table is an existing table, Data Integration does not modify the schema of the destination table. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run.
*   If the destination table is automatically created by the system, Data Integration automatically creates the schema of the destination table. The schema contains the primary key fields that you specify. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run.

4.  Example of a rule used to process DML messages

*   Example: {"dmlPolicies":[{"dmlType":"Delete","dmlAction":"Filter","filterCondition":"id > 1"}]}
*   If you do not configure such a rule, the default processing policy for messages generated for insert, update, and delete operations is Normal.
*   dmlType: the DML operation. Valid values: Insert, Update, and Delete.
*   dmlAction: the processing policy for DML messages. Valid values: Normal, Ignore, Filter, and LogicalDelete. Filter indicates conditional processing. You can set the dmlAction parameter to Filter only when the dmlType parameter is set to Update or Delete.
*   filterCondition: the condition used to filter DML messages. This parameter is required only when the dmlAction parameter is set to Filter.

5.  Example of a rule used to perform incremental synchronization

*   Example: {"where":"id > 0"}
*   You can configure such a rule to perform incremental synchronization.

6.  Example of a rule used to configure scheduling parameters for an auto triggered task

*   Example: {"cronExpress":" \\* \\* \\* \\* \\* \\*", "cycleType":"1"}
*   You can configure such a rule to configure scheduling parameters for an auto triggered task.

7.  Example of a rule used to specify a partition key

*   Example: {"columns":["id"]}
*   You can configure such a rule to specify a partition key.', example='{"expression":"${srcDatasoureName}_${srcDatabaseName}"}'),
      ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
      ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which you want to perform the action. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
    }
  ](name='TransformationRules', description='The list of transformation rules for objects involved in the synchronization task.

>  [ { "RuleName":"my_database_rename_rule", "RuleActionType":"Rename", "RuleTargetType":"Schema", "RuleExpression":"{"expression":"${srcDatasoureName}_${srcDatabaseName}"}" } ]', shrink='json', position='Query'),
}

model CreateDIJobResponseBody = {
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated and is replaced by the Id parameter.', example='11792', deprecated='true'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11792'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='4F6AB6B3-41FB-5EBB-AFB2-0C98D49DA2BB'),
}

model CreateDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDIJobResponseBody(name='body'),
}

/**
  * @description *   This API operation is available for all DataWorks editions.
  * *   You can call this API operation to create a synchronization task. When you call this API operation, you must configure parameters such as SourceDataSourceSettings, DestinationDataSourceSettings, MigrationType, TransformationRules, TableMappings, and JobSettings. The SourceDataSourceSettings parameter defines the settings related to the source. The DestinationDataSourceSettings parameter defines the settings related to the destination. The MigrationType parameter defines the synchronization task type. The TransformationRules parameter defines the transformation rules for objects involved in the synchronization task. The TableMappings parameter defines the mappings between rules used to select synchronization objects in the source and transformation rules applied to the selected synchronization objects. The JobSettings parameter defines the settings for the dimension of the synchronization task, including policies for data type mappings between source fields and destination fields and settings for periodic scheduling.
  * @param request  the request parameters of CreateDIJob  CreateDIJobRequest
  * @return CreateDIJobResponse
 */
async function createDIJob(request: CreateDIJobRequest): CreateDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDIJob', 'GET', '/', 'json', false, 'json', request);
}

model CreateDataAssetTagRequest {
  regionId?: string(name='RegionId', position='Host'),
  description?: string(name='Description', description='The description of the tag.', example='This is a description', maxLength=1024, position='Query'),
  key: string(name='Key', description='The tag key.

This parameter is required.', example='key1', minLength=1, maxLength=128, position='Query'),
  managers?: [ string ](name='Managers', description='The tag administrators.', shrink='json', position='Query'),
  valueType?: string(name='ValueType', description='The type of the tag value. Valid values:

*   Boolean
*   Int
*   String
*   Double', example='String', position='Query'),
  values?: [ string ](name='Values', description='The tag values.', shrink='json', position='Query'),
}

model CreateDataAssetTagResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateDataAssetTagResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataAssetTagResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of CreateDataAssetTag  CreateDataAssetTagRequest
  * @return CreateDataAssetTagResponse
 */
async function createDataAssetTag(request: CreateDataAssetTagRequest): CreateDataAssetTagResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataAssetTag', 'POST', '/', 'json', false, 'json', request);
}

model CreateDataQualityEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityRules?: [ 
    {
      checkingConfig?: {
        referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain specific types of thresholds, you must query reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{"bizdate": ["-1"]}'),
        thresholds?: {
          critical?: {
            expression?: string(name='Expression', description='阈值表达式。

波动率类型规则必须使用表达式方式表示波动阈值。如：

- 波动上升大于0.01： $checkValue > 0.01 
- 波动下降大于0.01：$checkValue < -0.01 
- 波动率绝对值：abs($checkValue) > 0.01

固定值类型规则也可以使用表达式方式配置阈值，如果同时配置，表达式优先级高于Operator和Value', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
            value?: string(name='Value', description='The threshold value.', example='0.01'),
          }(name='Critical', description='The threshold settings for critical alerts.'),
          expected?: {
            expression?: string(name='Expression', description='阈值表达式。

波动率类型规则必须使用表达式方式表示波动阈值。如：

- 波动上升大于0.01： $checkValue > 0.01 
- 波动下降大于0.01：$checkValue < -0.01 
- 波动率绝对值：abs($checkValue) > 0.01

固定值类型规则也可以使用表达式方式配置阈值，如果同时配置，表达式优先级高于Operator和Value', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='='),
            value?: string(name='Value', description='The threshold value.', example='0'),
          }(name='Expected', description='The expected threshold setting.'),
          warned?: {
            expression?: string(name='Expression', description='阈值表达式。

波动率类型规则必须使用表达式方式表示波动阈值。如：

- 波动上升大于0.01： $checkValue > 0.01 
- 波动下降大于0.01：$checkValue < -0.01 
- 波动率绝对值：abs($checkValue) > 0.01

固定值类型规则也可以使用表达式方式配置阈值，如果同时配置，表达式优先级高于Operator和Value', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
            value?: string(name='Value', description='The threshold value.', example='0.001'),
          }(name='Warned', description='The threshold settings for normal alerts.'),
        }(name='Thresholds', description='The threshold settings.'),
        type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average', example='Fixed'),
      }(name='CheckingConfig', description='The check settings for sample data.'),
      description?: string(name='Description', description='The description of the monitoring rule.', example='OpenAPI test rules', maxLength=500),
      enabled?: boolean(name='Enabled', description='Specifies whether to enable the monitoring rule.', example='true'),
      errorHandlers?: [ 
        {
          errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If you define the rule by using custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM ods_api_log WHERE status = \\"Error\\";'),
          type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
        }
      ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
      id?: long(name='Id', description='The rule ID.', example='2176'),
      name?: string(name='Name', description='The name of the monitoring rule.', example='OpenAPI test rules'),
      samplingConfig?: {
        metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: specifies that data is sampled by executing custom SQL statements.', example='NullValueCount'),
        metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
        samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='status != \\"Succeeded\\"'),
        settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='odps.sql.type.system.odps2=True,odps.sql.hive.compatible=True', maxLength=1000),
      }(name='SamplingConfig', description='The parameters required for sampling.'),
      severity?: string(name='Severity', description='The strength of the monitoring rule. Valid values:

*   Normal
*   High', example='High'),
      templateCode?: string(name='TemplateCode', description='The ID of the template used by the monitoring rule.', example='SYSTEM:field:null_value:fixed:0'),
    }
  ](name='DataQualityRules', description='The list of monitoring rules that are associated with the monitor. If you configure the ID of a monitoring rule by using the DataQualityRule.Id parameter, the system associates the rule with a created monitor. If you do not configure the ID of a monitoring rule, the system creates a new monitoring rule by using other fields and associates the rule with a created monitor.', shrink='json', position='Body'),
  dataSourceId?: long(name='DataSourceId', description='The data source ID. You can call the [ListDataSources](https://help.aliyun.com/document_detail/211431.html) operation to query the ID.', example='1', position='Body'),
  description?: string(name='Description', description='The description of the monitor.', example='OpenAPI create a data quality monitoring test', maxLength=65535, position='Body'),
  hooks?: [ 
    {
      condition?: string(name='Condition', description='The hook trigger condition. When this condition is met, the hook action is triggered. Only two conditional expressions are supported:

1.  Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical.
2.  Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
      type?: string(name='Type', description='The hook type. Only one hook type is supported.

*   BlockTaskInstance: Blocks the running of scheduling tasks. A monitor is triggered by scheduling tasks. After a monitor finishes running, the monitor determines whether to block the running of scheduling tasks based on the hook condition.', example='BlockTaskInstance'),
    }
  ](name='Hooks', description='The hook.', shrink='json', position='Body'),
  name: string(name='Name', description='The name of the monitor.

This parameter is required.', example='OpenAPI create a data quality monitoring test', maxLength=255, position='Body'),
  notifications?: {
    condition?: string(name='Condition', description='The notification trigger condition. When this condition is met, the alert notification is triggered. Only two conditional expressions are supported:

Specify only one group of rule strength type and rule check status, such as `${severity} == "High" AND ${status} == "Critical"`. In this expression, the hook trigger condition is met if severity is High and status is Critical. Specify multiple groups of rule strength types and rule check status, such as `(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")`. In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
    notifications?: [ 
      {
        notificationChannels?: [ 
          {
            channels?: [ string ](name='Channels', description='The alert notification methods.'),
          }
        ](name='NotificationChannels', description='The alert notification methods.'),
        notificationReceivers?: [ 
          {
            extension?: string(name='Extension', description='The additional parameters that are required when alerts are sent. The parameters are JSON-formatted strings. The following keys are supported:

*   atAll: specifies that all members in a group are mentioned when alerts are sent by using DingTalk. This parameter is valid only if you set ReceiverType to DingdingUrl.', example='{  "atAll": true }'),
            receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid values:

*   WebhookUrl
*   FeishuUrl
*   DingdingUrl
*   WeixinUrl
*   AliUid', example='DingdingUrl'),
            receiverValues?: [ string ](name='ReceiverValues', description='The alert recipient.'),
          }
        ](name='NotificationReceivers', description='The configurations of alert recipients.'),
      }
    ](name='Notifications', description='The configurations of the alert notification.'),
  }(name='Notifications', description='The configurations of alert notifications.', shrink='json', position='Body'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You can use this parameter to specify the DataWorks workspace on which you want to perform the API operation.', example='10000', position='Body'),
  runtimeConf?: string(name='RuntimeConf', description='The extended configurations in JSON-formatted strings. You can use this parameter only for monitors that are used to monitor the quality of E-MapReduce (EMR) data.

*   queue: The Yarn queue used when a monitor checks the quality of EMR data. By default, the queue configured for the current workspace is used.

*   sqlEngine: The SQL engine used when a monitor checks the quality of EMR data.

    *   HIVE_SQL
    *   SPARK_SQL', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }', position='Body'),
  target?: {
    databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   hologres
*   cdh
*   analyticdb_for_mysql
*   starrocks
*   emr
*   analyticdb_for_postgresql', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='pt=$[yyyymmdd-1]', maxLength=255),
    tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.api_test.ods_openapi_log_d'),
  }(name='Target', description='The monitored object of the monitor.', shrink='json', position='Body'),
  trigger?: {
    taskIds?: [ long ](name='TaskIds', description='The IDs of scheduling tasks. This parameter is valid only if you set Type to ByScheduledTaskInstance.'),
    type?: string(name='Type', description='The trigger type of the monitor. Valid values:

*   ByManual (default): The monitor is manually triggered.
*   ByScheduledTaskInstance: The monitor is triggered by the associated scheduling tasks.', example='ByScheduledTaskInstance'),
  }(name='Trigger', description='The trigger configuration of the monitor.', shrink='json', position='Body'),
}

model CreateDataQualityEvaluationTaskResponseBody = {
  id?: long(name='Id', description='The ID of the new monitor.', example='10001'),
  requestId?: string(name='RequestId', description='Id of the request', example='2d9ce-38ef-4923-baf6-391a7e656'),
}

model CreateDataQualityEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityEvaluationTaskResponseBody(name='body'),
}

/**
  * @description This API operation is supported in all DataWorks editions.
  * @param request  the request parameters of CreateDataQualityEvaluationTask  CreateDataQualityEvaluationTaskRequest
  * @return CreateDataQualityEvaluationTaskResponse
 */
async function createDataQualityEvaluationTask(request: CreateDataQualityEvaluationTaskRequest): CreateDataQualityEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityEvaluationTask', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataQualityEvaluationTaskInstanceRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityEvaluationTaskId: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task.

This parameter is required.', example='200001', position='Body'),
  parameters: string(name='Parameters', description='Data quality verification execution parameters in JSON format. The available keys are as follows:
- triggerTime: the millisecond timestamp of the trigger time. The baseline time of the $[yyyymmdd] expression in the data range of data quality monitoring. Required.

This parameter is required.', example='{ "triggerTime": 1733284062000 }', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the workspace management page to obtain the ID.

This parameter is used to determine the DataWorks workspaces used for this API call.

This parameter is required.', example='10000', position='Body'),
  runtimeResource?: {
    cu?: double(name='Cu', description='The task runs to configure CU consumption. If Serverless resource groups are used, you must specify this parameter.', example='0.25'),
    resourceGroupId?: string(name='ResourceGroupId', description='The identifier of the scheduling resource group configured for running the task.', example='63900680'),
  }(name='RuntimeResource', description='Resource Group information, which must be filled in when running non-MaxCompute data quality verification.', shrink='json', position='Body'),
}

model CreateDataQualityEvaluationTaskInstanceResponseBody = {
  id?: long(name='Id', description='The ID of the data quality monitoring instance.', example='22130'),
  requestId?: string(name='RequestId', description='Id of the request', example='ecb967ec-c137-48****'),
}

model CreateDataQualityEvaluationTaskInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityEvaluationTaskInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDataQualityEvaluationTaskInstance  CreateDataQualityEvaluationTaskInstanceRequest
  * @return CreateDataQualityEvaluationTaskInstanceResponse
 */
async function createDataQualityEvaluationTaskInstance(request: CreateDataQualityEvaluationTaskInstanceRequest): CreateDataQualityEvaluationTaskInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityEvaluationTaskInstance', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataQualityRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference samples and perform aggregate operations on the reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    thresholds?: {
      critical?: {
        expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Example:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.05'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Critical', description='The threshold settings for critical alerts.'),
      expected?: {
        expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Example:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue <= 0.01'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Expected', description='The expected threshold setting.'),
      warned?: {
        expression?: string(name='Expression', description='The threshold expression.

If the template specified by the TemplateCode parameter is about fluctuation, you must use an expression to represent the threshold for fluctuation. Example:

*   $checkValue > 0.01
*   $checkValue < -0.01
*   abs($checkValue) > 0.01

If the template specified by the TemplateCode parameter is about fixed value, you can also use an expression to represent the threshold. If you configure the Expression, Operator, and Value parameters for the threshold at the same time, the Expression parameter takes precedence over the Operator and Value parameters.', example='$checkValue > 0.01'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Warned', description='The threshold settings for normal alerts.'),
    }(name='Thresholds', description='The threshold settings.'),
    type?: string(name='Type', description='The method that is used to calculate a threshold. You can leave this parameter empty if you use a rule template. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
  }(name='CheckingConfig', description='The check settings for sample data.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description of the rule. The description can be up to 500 characters in length.', example='this is a odps _sql task', maxLength=500, position='Body'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the monitoring rule.', example='true', position='Body'),
  errorHandlers?: [ 
    {
      errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If you define the rule by using custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
      type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
    }
  ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.', shrink='json', position='Body'),
  name: string(name='Name', description='The name of the rule.

This parameter is required.', example='The table cannot be empty.', maxLength=255, position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='10726', position='Body'),
  samplingConfig?: {
    metric?: string(name='Metric', description='The metrics used for sampling. You can leave this parameter empty if you use a rule template. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: specifies that data is sampled by executing custom SQL statements.', example='Count'),
    metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
    samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='id IS NULL'),
    settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;', maxLength=1000),
  }(name='SamplingConfig', description='The sampling settings.', shrink='json', position='Body'),
  severity?: string(name='Severity', description='The strength of the monitoring rule. Valid values:

*   Normal
*   High', example='Normal', position='Body'),
  target?: {
    databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='ds=$[yyyymmdd-1]'),
    tableGuid: string(name='TableGuid', description='The ID of the table that is limited by the rule in Data Map.

This parameter is required.', example='odps.unit_test.tb_unit_test'),
    type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
  }(name='Target', description='The monitored object of the rule.', shrink='json', position='Body'),
  templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='system::user_defined', position='Body'),
}

model CreateDataQualityRuleResponseBody = {
  id?: long(name='Id', description='The ID of the rule.', example='19715'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model CreateDataQualityRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDataQualityRule  CreateDataQualityRuleRequest
  * @return CreateDataQualityRuleResponse
 */
async function createDataQualityRule(request: CreateDataQualityRuleRequest): CreateDataQualityRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityRule', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataQualityRuleTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference samples and perform aggregate operations on the reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
  }(name='CheckingConfig', description='The check settings for sample data.', shrink='json', position='Body'),
  directoryPath?: string(name='DirectoryPath', description='The directory in which the template is stored. Slashes (/) are used to separate directory levels. The name of each directory level can be up to 1,024 characters in length. It cannot contain whitespace characters or slashes (/).', example='/ods/order_data', position='Body'),
  name: string(name='Name', description='The name of the template. The name can be up to 512 characters in length and can contain digits, letters, and punctuation marks.

This parameter is required.', example='Table row Count Verification', maxLength=128, position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='12345', position='Body'),
  samplingConfig?: {
    metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='Count'),
    metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{"SQL": "select count(1) from table;"}'),
    settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;', maxLength=1000),
  }(name='SamplingConfig', description='The sampling settings.', shrink='json', position='Body'),
  visibleScope?: string(name='VisibleScope', description='The applicable scope of the template. Valid values:

*   Tenant: The template is available in all workspaces in the current tenant.
*   Project: The template is available only in the current workspace.', example='Project', position='Body'),
}

model CreateDataQualityRuleTemplateResponseBody = {
  code?: string(name='Code', description='The Code of the rule template.', example='UserDefined:3001'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model CreateDataQualityRuleTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataQualityRuleTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDataQualityRuleTemplate  CreateDataQualityRuleTemplateRequest
  * @return CreateDataQualityRuleTemplateResponse
 */
async function createDataQualityRuleTemplate(request: CreateDataQualityRuleTemplateRequest): CreateDataQualityRuleTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataQualityRuleTemplate', 'POST', '/', 'json', true, 'form', request);
}

model CreateDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  connectionProperties: string(name='ConnectionProperties', description='The connection configurations of the data source, including the connection address, access identity, and environment information. The envType parameter specifies the environment in which the data source is used. Valid values of the envType parameter:

*   Dev: development environment
*   Prod: production environment

The parameters that you need to configure to the data source vary based on the mode in which the data source is added. For more information, see [Data source connection information (ConnectionProperties)](https://help.aliyun.com/document_detail/2852465.html).

This parameter is required.', example='{
	"envType": "Prod",
	"regionId": "cn-beijing",
    "instanceId": "hgprecn-cn-x0r3oun4k001",
    "database": "testdb",
    "securityProtocol": "authTypeNone",
    "authType": "Executor",
    "authIdentity": "1107550004253538"
}', position='Query'),
  connectionPropertiesMode: string(name='ConnectionPropertiesMode', description='The mode in which you want to add the data source. The mode varies based on the data source type. Valid values for MySQL data sources:

*   InstanceMode: instance mode
*   UrlMode: connection string mode

This parameter is required.', example='UrlMode', position='Query'),
  description?: string(name='Description', description='The description of the data source. The description cannot exceed 3,000 characters in length.', example='this is a holo datasource', position='Query'),
  name: string(name='Name', description='The name of the data source. The name can be up to 255 characters in length and can contain letters, digits, and underscores (_). The name must start with a letter.

This parameter is required.', example='demo_holo_datasource', position='Query'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/overview) and go to the workspace management page to obtain the ID.

This parameter is used to determine the DataWorks workspaces used for this API call.

This parameter is required.', example='2', minimum=0, position='Query'),
  type: string(name='Type', description='The type of the data source. More than 70 types of data sources are supported in DataWorks.

This parameter is required.', example='hologres', position='Query'),
}

model CreateDataSourceResponseBody = {
  id?: long(name='Id', description='The data source ID.', example='22130'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='B62EC203-B39E-5DC1-B5B8-EB3C61707009'),
}

model CreateDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of CreateDataSource  CreateDataSourceRequest
  * @return CreateDataSourceResponse
 */
async function createDataSource(request: CreateDataSourceRequest): CreateDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataSource', 'POST', '/', 'json', false, 'json', request);
}

model CreateDataSourceSharedRuleRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dataSourceId: long(name='DataSourceId', description='The data source ID.

This parameter is required.', example='144544', position='Query'),
  envType: string(name='EnvType', description='Share data sources to the target project environment, including
- Dev (Development Environment)
- Prod (production environment)

This parameter is required.', example='Dev', position='Query'),
  sharedUser?: string(name='SharedUser', description='The user with which you want to share the data source. If you do not configure this parameter, the data source is shared to an entire workspace.', example='1107550004253538', position='Query'),
  targetProjectId: long(name='TargetProjectId', description='The ID of the workspace to which you want to share the data source. You cannot share the data source to the workspace with which the data source is associated.

This parameter is required.', example='106560', position='Query'),
}

model CreateDataSourceSharedRuleResponseBody = {
  id?: long(name='Id', description='The sharing rule ID.', example='105412'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='46F594E6-84AB-5FA5-8144-6F3D149961E1'),
}

model CreateDataSourceSharedRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDataSourceSharedRuleResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  If you want to share a data source from Workspace A to Workspace B, you must have the permissions to share the data source in both workspaces. You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Tenant Administrator, Workspace Administrator, and Workspace Owner
  * @param request  the request parameters of CreateDataSourceSharedRule  CreateDataSourceSharedRuleRequest
  * @return CreateDataSourceSharedRuleResponse
 */
async function createDataSourceSharedRule(request: CreateDataSourceSharedRuleRequest): CreateDataSourceSharedRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDataSourceSharedRule', 'POST', '/', 'json', false, 'json', request);
}

model CreateDeploymentRequest {
  regionId?: string(name='RegionId', description='区域id

This parameter is required.', position='Host'),
  description?: string(name='Description', description='The description of the process.', example='This is a OdpsSQL-node publishing process. The function is XXXX.', position='Body'),
  objectIds: [ string ](name='ObjectIds', description='The IDs of entities to which you want to apply the process.

>  A process can be applied to only a single entity and its child entities. If you specify multiple entities in the array, the process is applied only to the first entity in the array and its child entities. Make sure that the array in your request contains only one element. Extra elements will be ignored.

This parameter is required.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
  type: string(name='Type', description='Specifies whether to deploy or undeploy the entity. Valid values:

*   Online: deploys the entity.
*   Offline: undeploys the entity.

This parameter is required.', example='Online', position='Body'),
}

model CreateDeploymentResponseBody = {
  id?: string(name='Id', description='The ID of the process.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX'),
  requestId?: string(name='RequestId', description='The request ID.', example='7C352CB7-CD88-50CF-9D0D-E81BDF02XXXX'),
}

model CreateDeploymentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDeploymentResponseBody(name='body'),
}

/**
  * @description >  You cannot use this API operation to create a process for multiple entities at a time. If you specify multiple entities in a request, the system creates a process only for the first entity.
  * @param request  the request parameters of CreateDeployment  CreateDeploymentRequest
  * @return CreateDeploymentResponse
 */
async function createDeployment(request: CreateDeploymentRequest): CreateDeploymentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDeployment', 'POST', '/', 'json', true, 'form', request);
}

model CreateFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='12345', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the UDF. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
  "version": "1.1.0",
  "kind": "Function",
  "spec": {
    "functions": [
      {
        "name": "function name",
        "script": {
          "content": "{\\"name\\": \\"function name\\", \\"datasource\\": {\\"type\\": \\"ODPS\\", \\"name\\": \\"ODPS_first\\"}, \\"runtimeResource\\": {\\"resourceGroup\\": \\"s_res_group_xx_xxxx\\"}}",
          "path": "XXX/OpenAPI/function/function name",
          "runtime": {
            "command": "ODPS_FUNCTION"
          }
        },
        "datasource": {
          "name": "ODPS_first",
          "type": "ODPS"
        },
        "runtimeResource": {
          "resourceGroup": "S_res_group_XXXX_XXXX"
        }
      }
    ]
  }
}', position='Body'),
}

model CreateFunctionResponseBody = {
  id?: long(name='Id', description='The ID of the UDF.', example='580667964888595XXXX'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='AE49C88D-5BEE-5ADD-8B8C-C4BBC0D7XXXX'),
}

model CreateFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateFunctionResponseBody(name='body'),
}

/**
  * @description >  You cannot use this API operation to create multiple UDFs at a time. If you specify multiple UDFs by using FlowSpec, the system creates only the first specified UDF.
  * @param request  the request parameters of CreateFunction  CreateFunctionRequest
  * @return CreateFunctionResponse
 */
async function createFunction(request: CreateFunctionRequest): CreateFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateFunction', 'POST', '/', 'json', true, 'form', request);
}

model CreateNetworkRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientToken: string(name='ClientToken', description='The client token that is used to ensure the idempotence of the request.

This parameter is required.', example='eb870033-74c8-4b1b-9664-04c4e7cc3465', position='Body'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the serverless resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
  vpcId: string(name='VpcId', description='The ID of the virtual private cloud (VPC).

This parameter is required.', example='vpc-m2et4f3oc8msfbccXXXXX', position='Body'),
  vswitchId: string(name='VswitchId', description='The VSwitch ID.

This parameter is required.', example='vsw-uf8usrhs7hjd9amsXXXXX', position='Body'),
}

model CreateNetworkResponseBody = {
  id?: long(name='Id', description='The network ID.', example='1000'),
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateNetworkResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateNetworkResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of CreateNetwork  CreateNetworkRequest
  * @return CreateNetworkResponse
 */
async function createNetwork(request: CreateNetworkRequest): CreateNetworkResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateNetwork', 'POST', '/', 'json', true, 'form', request);
}

model CreateNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  containerId?: long(name='ContainerId', description='The container ID. If you want to create a node in a container, you must configure this parameter to specify the container. The container can be a workflow or a node in a container.

>  If you configure this parameter, the path field defined in FlowSpec becomes invalid.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='123456', position='Body'),
  scene: string(name='Scene', description='The scene of the node. This parameter determines the location (the DataStudio pane or the Manual pane) of the node. You can set this parameter to DataworksManualWorkflow only if the ContainerId parameter is configured and the container specified by ContainerId is a manually triggered workflow.

Valid values:

*   DataworksProject
*   DataworksManualWorkflow
*   DataworksManualTask

This parameter is required.', example='DATAWORKS_PROJECT', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the node. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
  "version": "1.1.0",
  "kind": "Node",
  "spec": {
    "nodes": [
      {
        "id": "860438872620113XXXX",
        "recurrence": "Normal",
        "timeout": 0,
        "instanceMode": "T+1",
        "rerunMode": "Allowed",
        "rerunTimes": 3,
        "rerunInterval": 180000,
        "datasource": {
          "name": "ODPS_test",
          "type": "ODPS"
        },
        "script": {
          "path": "XX/OpenAPI test/odpsSQL test",
          "runtime": {
            "command": "ODPS_SQL"
          },
          "content": "select now();"
        },
        "trigger": {
          "type": "Scheduler",
          "cron": "00 00 00 * * ?",
          "startTime": "1970-01-01 00:00:00",
          "endTime": "9999-01-01 00:00:00",
          "timezone": "Asia/Shanghai",
          "delaySeconds": 0
        },
        "runtimeResource": {
          "resourceGroup": "S_res_group_XXXX_XXXX"
        },
        "name": "odpsSQL test",
        "inputs": {
          "nodeOutputs": [
            {
              "data": "lwttest_standard_root",
              "artifactType": "NodeOutput"
            }
          ]
        },
        "outputs": {
          "nodeOutputs": [
            {
              "data": "output_data",
              "artifactType": "NodeOutput",
              "refTableName": "odpsSQL test"
            }
          ]
        }
      }
    ],
    "flow": [
      {
        "nodeId": "860438872620113XXXX",
        "depends": [
          {
            "type": "Normal",
            "output": "project_root"
          }
        ]
      }
    ]
  }
}', position='Body'),
}

model CreateNodeResponseBody = {
  id?: long(name='Id', description='The ID of the node.', example='860438872620113XXXX'),
  requestId?: string(name='RequestId', description='The request ID.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
}

model CreateNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateNodeResponseBody(name='body'),
}

/**
  * @description >  You cannot use this API operation to create multiple nodes at a time. If you specify multiple nodes by using FlowSpec, the system creates only the first specified node.
  * @param request  the request parameters of CreateNode  CreateNodeRequest
  * @return CreateNodeResponse
 */
async function createNode(request: CreateNodeRequest): CreateNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateNode', 'POST', '/', 'json', true, 'form', request);
}

model CreateProjectRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group to which the workspace belongs. You can log on to the [Resource Management console](https://resourcemanager.console.aliyun.com/resource-groups) and go to the Resource Group page to query the ID.

You must configure this parameter to specify an Alibaba Cloud resource group for the workspace that you want to create.', example='rg-acfmzbn7pti3zff', position='Body'),
  aliyunResourceTags?: [ 
    {
      key?: string(name='Key', description='The tag key.', example='batch'),
      value?: string(name='Value', description='The tag value.', example='blue'),
    }
  ](name='AliyunResourceTags', description='The tags.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description of the workspace.', example='Financial analysis group project data development', position='Body'),
  devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Specifies whether to enable the development environment. Valid values:

*   true : enables the development environment. In this case, the development environment is isolated from the production environment in the workspace.
*   false: disables the development environment. In this case, only the production environment is used in the workspace.', example='false', position='Body'),
  devRoleDisabled?: boolean(name='DevRoleDisabled', description='Specifies whether to disable the Develop role. Valid values:

*   false (default)
*   true', example='true', position='Body'),
  displayName: string(name='DisplayName', description='The display name of the workspace.

This parameter is required.', example='Sora financial analysis', position='Body'),
  name: string(name='Name', description='The name of the workspace.

Limits:

*   The workspace name must be unqiue in a region.
*   The workspace name can contain letters, digits, and underscores (_), and must start with a letter.
*   The workspace name must be 3 to 28 characters in length.

This parameter is required.', example='sora_finance', position='Body'),
  paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Specifies whether to enable scheduling of Platform for AI (PAI) tasks. Valid values:

*   true: enables scheduling of PAI tasks. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: disables scheduling of PAI tasks.', example='true', position='Body'),
}

model CreateProjectResponseBody = {
  id?: long(name='Id', description='The workspace ID.', example='123456'),
  projectId?: long(name='ProjectId', description='The workspace ID. Note: This parameter is deprecated and is replaced by the Id parameter.', example='123456', deprecated='true'),
  requestId?: string(name='RequestId', description='The request ID.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
}

model CreateProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateProject  CreateProjectRequest
  * @return CreateProjectResponse
 */
async function createProject(request: CreateProjectRequest): CreateProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateProject', 'POST', '/', 'json', true, 'form', request);
}

model CreateProjectMemberRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='24054', position='Body'),
  roleCodes: [ string ](name='RoleCodes', description='The codes of the roles in the workspace. You can call the [ListProjectRoles](https://help.aliyun.com/document_detail/2853930.html) operation to query the codes of all roles in the workspace.

This parameter specifies the roles that you can assign to a member when you add the member.

This parameter is required.', shrink='json', position='Body'),
  userId: string(name='UserId', description='The ID of the account that you want to add to the workspace as a member. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click **Tenant Members and Roles**. On the Tenant Members and Roles page, view the ID of the account that you want to add to the workspace as a member.

This parameter is required.', example='123422344899', position='Body'),
}

model CreateProjectMemberResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='2B2F0B26-9253-5780-B6DB-F1A886D44D6F'),
}

model CreateProjectMemberResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateProjectMemberResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of CreateProjectMember  CreateProjectMemberRequest
  * @return CreateProjectMemberResponse
 */
async function createProjectMember(request: CreateProjectMemberRequest): CreateProjectMemberResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateProjectMember', 'POST', '/', 'json', true, 'form', request);
}

model CreateResourceRequest {
  regionId?: string(name='RegionId', description='代表region的资源属性字段

This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='123456', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the file resource. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
    "version": "1.1.0",
    "kind": "Resource",
    "spec": {
        "fileResources": [
            {
                "name": "OpenAPITestResource.py",
                "script": {
                    "content": "",
                    "path": "XX/OpenAPITest/ResourcesTest/OpenAPITestResource.py",
                    "runtime": {
                        "command": "ODPS_PYTHON"
                    }
                },
                "type": "python",
                "file": {
                    "storage": {}
                },
                "datasource": {
                    "name": "odps_first",
                    "type": "odps"
                }
            }
        ]
    }
}', position='Body'),
}

model CreateResourceResponseBody = {
  id?: long(name='Id', description='The ID of the file resource.', example='631478864897630XXXX'),
  requestId?: string(name='RequestId', description='A5B97987-66EA-5563-9599-A2752292XXXX', example='The ID of the file resource.'),
}

model CreateResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateResourceResponseBody(name='body'),
}

/**
  * @description Private
  * @param request  the request parameters of CreateResource  CreateResourceRequest
  * @return CreateResourceResponse
 */
async function createResource(request: CreateResourceRequest): CreateResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateResource', 'POST', '/', 'json', true, 'form', request);
}

model CreateResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the resource group.', example='rg-aek2kqofrgXXXXX', position='Body'),
  aliyunResourceTags?: [ 
    {
      key?: string(name='Key', description='The tag key.', example='key'),
      value?: string(name='Value', description='The tag value.', example='value'),
    }
  ](name='AliyunResourceTags', description='The tags.', shrink='json', position='Body'),
  autoRenewEnabled?: boolean(name='AutoRenewEnabled', description='Specifies whether to enable auto-renewal.', position='Body'),
  clientToken: string(name='ClientToken', description='The idempotent identifier of the client is used to ensure idempotent operation of creating a common resource group.

This parameter is required.', example='eb870033-74c8-4b1b-9664-04c4e7cc3465', position='Body'),
  name: string(name='Name', description='The name of a common resource group. It must start with a letter and can contain letters, numbers, and underscores (_). It can be up to 128 characters in length.

This parameter is required.', example='common_resource_group', position='Body'),
  paymentDuration?: int32(name='PaymentDuration', description='The duration of the payment.', example='1', position='Body'),
  paymentDurationUnit?: string(name='PaymentDurationUnit', description='The unit of the subscription duration. Valid values: Month and Year.', example='Month', position='Body'),
  paymentType: string(name='PaymentType', description='The billing method of the serverless resource group. Valid values: PrePaid and PostPaid. The value PrePaid indicates the subscription billing method, and the value PostPaid indicates the pay-as-you-go billing method.

This parameter is required.', example='PrePaid', position='Body'),
  remark?: string(name='Remark', description='Note for creating a common resource group, which can contain letters, Chinese characters, numbers, underscores (_), and a maximum of 128 characters.', example='Create a serverless resource group for common tasks', position='Body'),
  spec?: int32(name='Spec', description='The specifications of the resource group. Unit: compute unit (CU). This parameter is required only when you set the PaymentType parameter to PrePaid.', example='2', position='Body'),
  vpcId: string(name='VpcId', description='The ID of the virtual private cloud (VPC) with which the serverless resource group is associated by default.

This parameter is required.', example='vpc-m2et4f3oc8msfbccXXXXX', position='Body'),
  vswitchId: string(name='VswitchId', description='The ID of the vSwitch with which the serverless resource group is associated by default.

This parameter is required.', example='vsw-uf8usrhs7hjd9amsXXXXX', position='Body'),
}

model CreateResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  resourceGroupOrder?: {
    id?: string(name='Id', description='The unique identifier of the serverless resource group.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
    orderId?: long(name='OrderId', description='The ID of the order to create a serverless resource group.', example='2391982058XXXXX'),
    orderInstanceId?: string(name='OrderInstanceId', description='The ID of the order instance that created the serverless resource group.', example='c442b330-3b10-4584-959e-736e4edXXXXX'),
  }(name='ResourceGroupOrder', description='The order information for creating a serverless resource group.'),
  success?: boolean(name='Success', description='Whether the request is successful.', example='true'),
}

model CreateResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateResourceGroupResponseBody(name='body'),
}

/**
  * @description 1.  You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * 2.  **Before you call this API operation, you must make sure that you have a good command of the billing details and [pricing](https://help.aliyun.com/document_detail/2680173.html) of serverless resource groups.
  * @param request  the request parameters of CreateResourceGroup  CreateResourceGroupRequest
  * @return CreateResourceGroupResponse
 */
async function createResourceGroup(request: CreateResourceGroupRequest): CreateResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model CreateRouteRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  destinationCidr: string(name='DestinationCidr', description='The CIDR blocks of the destination-based route.

This parameter is required.', example='192.168.0.0/16', position='Body'),
  networkId: long(name='NetworkId', description='The network ID.

This parameter is required.', example='1000', position='Body'),
}

model CreateRouteResponseBody = {
  id?: long(name='Id', description='The route ID.', example='1000'),
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model CreateRouteResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateRouteResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of CreateRoute  CreateRouteRequest
  * @return CreateRouteResponse
 */
async function createRoute(request: CreateRouteRequest): CreateRouteResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateRoute', 'POST', '/', 'json', true, 'form', request);
}

model CreateWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the workflow. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow/).

This parameter is required.', example='{
    "kind": "CycleWorkflow",
    "version": "1.1.0",
    "spec": {
        "name": "OpenAPITestWorkflowDemo",
        "type": "CycleWorkflow",
        "workflows": [
            {
                "script": {
                    "path": "XX/OpenAPITest/WorkflowTest/OpenAPITestWorkflowDemo",
                    "runtime": {
                        "command": "WORKFLOW"
                    }
                },
                "trigger": {
                    "type": "Scheduler",
                    "cron": "00 02 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "strategy": {
                    "timeout": 0,
                    "instanceMode": "T+1",
                    "rerunMode": "Allowed",
                    "rerunTimes": 3,
                    "rerunInterval": 180000,
                    "failureStrategy": "Break"
                },
                "name": "OpenAPITestWorkflowDemo",
                "inputs": {},
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "workflow_output",
                            "artifactType": "NodeOutput",
                            "refTableName": "OpenAPITestWorkflowDemo"
                        }
                    ]
                },
                "nodes": [],
                "dependencies": []
            }
        ]
    }
}', position='Body'),
}

model CreateWorkflowDefinitionResponseBody = {
  id?: long(name='Id', description='The ID of the workflow.', example='463497880880954XXXX'),
  requestId?: string(name='RequestId', description='The request ID.', example='0EF298E5-0940-5AC7-9CB0-65025070XXXX'),
}

model CreateWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @description > You cannot use this API operation to create multiple workflows at a time. If you specify multiple workflows by using FlowSpec, the system creates only the first specified workflow. Other specified workflows and the nodes in the workflows are ignored. You can call the CreateNode operation to create a node.
  * @param request  the request parameters of CreateWorkflowDefinition  CreateWorkflowDefinitionRequest
  * @return CreateWorkflowDefinitionResponse
 */
async function createWorkflowDefinition(request: CreateWorkflowDefinitionRequest): CreateWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model CreateWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  autoStartEnabled?: boolean(name='AutoStartEnabled', description='The default value is true.', example='true', position='Body'),
  comment?: string(name='Comment', description='The reason for the creation.', example='create for test', position='Body'),
  defaultRunProperties?: {
    alert?: {
      noticeType?: string(name='NoticeType', description='The notification method.
- Sms: Sms only
- Mail: Mail only
- SmsMail: SMS and email.', example='Sms'),
      type?: string(name='Type', description='The alert policy.
- Success: successful alert
- Failure: failed alarm
- SuccessFailure: alerts for both success and failure', example='Succes'),
    }(name='Alert', description='Alarm configuration.'),
    analysis: {
      blocked: boolean(name='Blocked', description='Whether to block the operation if the analysis fails.

This parameter is required.', example='true'),
      enabled: boolean(name='Enabled', description='Whether to enable analysis.

This parameter is required.', example='true'),
    }(name='Analysis', description='Analyze the configuration.

This parameter is required.'),
    excludeProjectIds?: [ long ](name='ExcludeProjectIds', description='The list of project IDs that do not need to be run.'),
    excludeTaskIds?: [ long ](name='ExcludeTaskIds', description='The list of task IDs that you do not want to run.'),
    includeProjectIds?: [ long ](name='IncludeProjectIds', description='The list of project IDs to be run.'),
    includeTaskIds?: [ long ](name='IncludeTaskIds', description='The list of task IDs to be run.'),
    mode?: string(name='Mode', description='The data replenishment mode. The default value is ManualSelection.
- General: In normal mode, only one \\"roottaskkids\\" can be filled in, and \\"IncludeTaskIds\\" is optional. If not, the content in \\"roottaskkids\\" will be included by default.
- ManualSelection: manually select, \\"roottaskkids\\" can be filled in multiple, \\"IncludeTaskIds\\" optional, if not, the content in \\"roottaskkids\\" will be included by default.
- Chain: the link, \\"roottaskkids\\" is empty, and \\"IncludeTaskIds\\" is filled with two IDs, which are the start and end tasks respectively.
- AllDownstream: all downstream, \\"roottaskkids\\" can only be filled in one', example='ManualSelection'),
    order?: string(name='Order', description='The running sequence. Default value: Asc.
- Asc: ascending order by business date.
- Desc: descending order by business date.', example='Asc'),
    parallelism: int32(name='Parallelism', description='The number of rows that the task has. Values from 2 to 10 are parallelism and 1 is serial.

This parameter is required.', example='2'),
    rootTaskIds?: [ long ](name='RootTaskIds', description='The ID list of the root task.'),
    runPolicy?: {
      endTime?: string(name='EndTime', description='The end runtime. This field is required if the policy is set.', example='23:59:59'),
      immediately?: boolean(name='Immediately', description='The default value is false.', example='false'),
      startTime?: string(name='StartTime', description='The start time. This field is required if the policy is set.', example='00:00:00'),
      type?: string(name='Type', description='The type of the time period. This field is required if the policy is set.
- Daily: every day
- Weekend: Weekends only', example='Daily'),
    }(name='RunPolicy', description='Run the policy. If this field is empty, the task configuration is followed.'),
    runtimeResource?: string(name='RuntimeResource', description='The identifier of the custom scheduling Resource Group. If this field is empty, the task configuration is followed.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
  }(name='DefaultRunProperties', description='Runtime configuration.', shrink='json', position='Body'),
  envType?: string(name='EnvType', description='The project environment.
- Prod (production)
- Dev', example='Prod', position='Body'),
  name: string(name='Name', description='The name.

This parameter is required.', example='WorkflowInstance1', position='Body'),
  periods?: {
    bizDates: [ 
      {
        endBizDate: string(name='EndBizDate', description='The end date of the business.

This parameter is required.', example='2024-11-24'),
        startBizDate: string(name='StartBizDate', description='The start business date.

This parameter is required.', example='2024-11-20'),
      }
    ](name='BizDates', description='The list of business dates. You can specify a multi-segment business date (up to 7 segments).

This parameter is required.'),
    endTime?: string(name='EndTime', description='Specifies the end cycle time. Default value: 23:59:59.

If you enter this field, StartTime and EndTime must be filled in at the same time.', example='23:59:59'),
    startTime?: string(name='StartTime', description='Specifies the start cycle time. Default value: 00:00:00.

If you enter this field, StartTime and EndTime must be filled in at the same time.', example='00:00:00'),
  }(name='Periods', description='Make up the data cycle settings.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The project ID.

This parameter is required.', example='100', position='Body'),
  taskParameters?: string(name='TaskParameters', description='Task parameters. Set parameters for a specific task. In JSON format, the key is the Task ID. For more information about the value format, see Task Script parameters (Task.Script. GetTask of the Parameter interface).', example='{
  "1001": "key1=val2 key2=val2", 
  "1002": "key1=val2 key2=val2"
}', position='Body'),
  type: string(name='Type', description='The type of the workflow instance.

- SupplementData: Retroactive data
- ManualWorkflow: manual workflow

This parameter is required.', example='SupplementData', position='Body'),
  workflowId: long(name='WorkflowId', description='The ID of the workflow to which the workflow belongs. The default value of WorkflowId for retroactive data is 1.

This parameter is required.', example='1', position='Body'),
  workflowParameters?: string(name='WorkflowParameters', description='Workflow parameters. The priority is higher than the task parameters. JSON format.', example='{ 
  "key1": "value1", 
  "key2": "value2" 
}', position='Body'),
}

model CreateWorkflowInstancesResponseBody = {
  operationId?: string(name='OperationId', description='The ID of the operation. You can use this field to query the results of the creation operation through the GetCreateWorkflowInstancesResult interface.', example='e15ad21c-b0e9-4792-8f55-b037xxxxxxxx'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model CreateWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateWorkflowInstancesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateWorkflowInstances  CreateWorkflowInstancesRequest
  * @return CreateWorkflowInstancesResponse
 */
async function createWorkflowInstances(request: CreateWorkflowInstancesRequest): CreateWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model DeleteAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The rule ID.', example='105412', position='Body'),
}

model DeleteAlertRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='8754EE08-4AA2-5F77-ADD7-754DBBDA9F75'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteAlertRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteAlertRule  DeleteAlertRuleRequest
  * @return DeleteAlertRuleResponse
 */
async function deleteAlertRule(request: DeleteAlertRuleRequest): DeleteAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteAlertRule', 'POST', '/', 'json', true, 'form', request);
}

model DeleteDIAlarmRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIAlarmRuleId?: long(name='DIAlarmRuleId', description='This parameter is deprecated. Use the Id parameter instead.', example='2', deprecated='true', position='Query'),
  DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='1', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='2', position='Query'),
}

model DeleteDIAlarmRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADE490'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteDIAlarmRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDIAlarmRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDIAlarmRule  DeleteDIAlarmRuleRequest
  * @return DeleteDIAlarmRuleResponse
 */
async function deleteDIAlarmRule(request: DeleteDIAlarmRuleRequest): DeleteDIAlarmRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDIAlarmRule', 'GET', '/', 'json', false, 'json', request);
}

model DeleteDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='11126', deprecated='true', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11126', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='108864', position='Query'),
}

model DeleteDIJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can troubleshoot issues based on the ID.', example='D33D4A51-5845-579A-B4BA-FAADD0F83D53'),
  success?: boolean(name='Success', description='true', example='true'),
}

model DeleteDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteDIJob  DeleteDIJobRequest
  * @return DeleteDIJobResponse
 */
async function deleteDIJob(request: DeleteDIJobRequest): DeleteDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDIJob', 'GET', '/', 'json', false, 'json', request);
}

model DeleteDataAssetTagRequest {
  regionId?: string(name='RegionId', position='Host'),
  key: string(name='Key', description='The tag key.

This parameter is required.', example='key1', minLength=1, maxLength=128, position='Query'),
  values?: [ string ](name='Values', description='The tag values.', shrink='json', position='Query'),
}

model DeleteDataAssetTagResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1411515937635973****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteDataAssetTagResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataAssetTagResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of DeleteDataAssetTag  DeleteDataAssetTagRequest
  * @return DeleteDataAssetTagResponse
 */
async function deleteDataAssetTag(request: DeleteDataAssetTagRequest): DeleteDataAssetTagResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataAssetTag', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDataQualityEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The ID of the data quality monitor.', example='123123', position='Query'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the workspace management page to obtain the ID.

This parameter is used to determine the DataWorks workspaces used for this API call.', example='10000', position='Query'),
}

model DeleteDataQualityEvaluationTaskResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='0bc1ec92159376****'),
  success?: boolean(name='Success', description='Whether the deletion is successful.
- true: Successful
- false: Failed', example='true'),
}

model DeleteDataQualityEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataQualityEvaluationTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDataQualityEvaluationTask  DeleteDataQualityEvaluationTaskRequest
  * @return DeleteDataQualityEvaluationTaskResponse
 */
async function deleteDataQualityEvaluationTask(request: DeleteDataQualityEvaluationTaskRequest): DeleteDataQualityEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataQualityEvaluationTask', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDataQualityRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id: long(name='Id', description='The rule ID.

This parameter is required.', example='19715', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='17302', position='Query'),
}

model DeleteDataQualityRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteDataQualityRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataQualityRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDataQualityRule  DeleteDataQualityRuleRequest
  * @return DeleteDataQualityRuleResponse
 */
async function deleteDataQualityRule(request: DeleteDataQualityRuleRequest): DeleteDataQualityRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataQualityRule', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDataQualityRuleTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  code: string(name='Code', description='The code for the template.

This parameter is required.', example='USER_DEFINED:123', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10001', position='Query'),
}

model DeleteDataQualityRuleTemplateResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteDataQualityRuleTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataQualityRuleTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DeleteDataQualityRuleTemplate  DeleteDataQualityRuleTemplateRequest
  * @return DeleteDataQualityRuleTemplateResponse
 */
async function deleteDataQualityRuleTemplate(request: DeleteDataQualityRuleTemplateRequest): DeleteDataQualityRuleTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataQualityRuleTemplate', 'POST', '/', 'json', false, 'json', request);
}

model DeleteDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The data source ID.

This parameter is required.', example='1234', position='Query'),
}

model DeleteDataSourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='B56432E0-2112-5C97-88D0-AA0AE5C75C74'),
  success?: boolean(name='Success', description='Whether the call is successful.
- true: Successful
- false: Failed', example='true'),
}

model DeleteDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all Dataworks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of DeleteDataSource  DeleteDataSourceRequest
  * @return DeleteDataSourceResponse
 */
async function deleteDataSource(request: DeleteDataSourceRequest): DeleteDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataSource', 'GET', '/', 'json', false, 'json', request);
}

model DeleteDataSourceSharedRuleRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The sharing rule ID.

This parameter is required.', example='22127', position='Query'),
}

model DeleteDataSourceSharedRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='64B-587A-8CED-969E1973887FXXX-TT'),
  success?: boolean(name='Success', description='Whether the data source sharing rule is deleted successfully. The value is as follows:
-true: The request is successful.
-false: The request failed.', example='true'),
}

model DeleteDataSourceSharedRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteDataSourceSharedRuleResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  If you want to delete a sharing rule of a data source from Workspace A to Workspace B, you must have the permissions to share the data source in Workspace A or Workspace B. You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Tenant Administrator, Workspace Administrator, and Workspace Owner
  * @param request  the request parameters of DeleteDataSourceSharedRule  DeleteDataSourceSharedRuleRequest
  * @return DeleteDataSourceSharedRuleResponse
 */
async function deleteDataSourceSharedRule(request: DeleteDataSourceSharedRuleRequest): DeleteDataSourceSharedRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteDataSourceSharedRule', 'POST', '/', 'json', false, 'json', request);
}

model DeleteFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='860438872620113XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID. You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model DeleteFunctionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='88198F19-A36B-52A9-AE44-4518A688XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteFunctionResponseBody(name='body'),
}

/**
  * @description >  A UDF that is deployed cannot be deleted. If you want to delete such a UDF, you must first undeploy the UDF.
  * @param request  the request parameters of DeleteFunction  DeleteFunctionRequest
  * @return DeleteFunctionResponse
 */
async function deleteFunction(request: DeleteFunctionRequest): DeleteFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteFunction', 'POST', '/', 'json', true, 'form', request);
}

model DeleteNetworkRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the network that you want to delete.

This parameter is required.', example='1000', position='Body'),
}

model DeleteNetworkResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteNetworkResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteNetworkResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteNetwork  DeleteNetworkRequest
  * @return DeleteNetworkResponse
 */
async function deleteNetwork(request: DeleteNetworkRequest): DeleteNetworkResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteNetwork', 'POST', '/', 'json', true, 'form', request);
}

model DeleteNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='860438872620113XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model DeleteNodeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='A1E54497-5122-505E-91C6-BAC14980XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

true\\
false', example='true'),
}

model DeleteNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteNodeResponseBody(name='body'),
}

/**
  * @description >  A node that is deployed cannot be deleted. If you want to delete such a node, you must first undeploy the node.
  * @param request  the request parameters of DeleteNode  DeleteNodeRequest
  * @return DeleteNodeResponse
 */
async function deleteNode(request: DeleteNodeRequest): DeleteNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteNode', 'POST', '/', 'json', true, 'form', request);
}

model DeleteProjectRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='123456', position='Body'),
}

model DeleteProjectResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
}

model DeleteProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteProjectResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteProject  DeleteProjectRequest
  * @return DeleteProjectResponse
 */
async function deleteProject(request: DeleteProjectRequest): DeleteProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteProject', 'POST', '/', 'json', true, 'form', request);
}

model DeleteProjectMemberRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='534752', position='Body'),
  userId: string(name='UserId', description='The ID of the account used by the member in the workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the Tenant Members and Roles page, view the ID of the account used by the member in the workspace.

This parameter is required.', example='123422344899', position='Body'),
}

model DeleteProjectMemberResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='1FF0465F-209C-5964-8F30-FAF21B677CC6'),
}

model DeleteProjectMemberResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteProjectMemberResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteProjectMember  DeleteProjectMemberRequest
  * @return DeleteProjectMemberResponse
 */
async function deleteProjectMember(request: DeleteProjectMemberRequest): DeleteProjectMemberResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteProjectMember', 'POST', '/', 'json', true, 'form', request);
}

model DeleteResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the file resource.

This parameter is required.', example='860438872620113XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID. You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model DeleteResourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='88198F19-A36B-52A9-AE44-4518A688XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteResourceResponseBody(name='body'),
}

/**
  * @description >  A file resource that is deployed cannot be deleted. If you want to delete such a file resource, you must first undeploy the file resource.
  * @param request  the request parameters of DeleteResource  DeleteResourceRequest
  * @return DeleteResourceResponse
 */
async function deleteResource(request: DeleteResourceRequest): DeleteResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteResource', 'POST', '/', 'json', true, 'form', request);
}

model DeleteResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
}

model DeleteResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to locate logs and troubleshoot issues.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteResourceGroupResponseBody(name='body'),
}

/**
  * @description 1.  You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * 2.  **Before you call this API operation, you must make sure that you have a good command of the billing details and [pricing](https://help.aliyun.com/document_detail/2680173.html) of serverless resource groups.
  * @param request  the request parameters of DeleteResourceGroup  DeleteResourceGroupRequest
  * @return DeleteResourceGroupResponse
 */
async function deleteResourceGroup(request: DeleteResourceGroupRequest): DeleteResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model DeleteRouteRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The route ID.

This parameter is required.', example='1000', position='Body'),
}

model DeleteRouteResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteRouteResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteRouteResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteRoute  DeleteRouteRequest
  * @return DeleteRouteResponse
 */
async function deleteRoute(request: DeleteRouteRequest): DeleteRouteResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteRoute', 'POST', '/', 'json', true, 'form', request);
}

model DeleteTaskRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model DeleteTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteTaskResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteTask  DeleteTaskRequest
  * @return DeleteTaskResponse
 */
async function deleteTask(request: DeleteTaskRequest): DeleteTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteTask', 'POST', '/', 'json', false, 'json', request);
}

model DeleteWorkflowRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a workflow asynchronously and implement the idempotence of the workflow. If you do not specify this parameter when you create the workflow, the system automatically generates a unique code. The unique code is uniquely associated with the workflow ID. If you specify this parameter when you update or delete the workflow, the value of this parameter must be the unique code that is used to create the workflow.', example='Workflow_0bc5213917368545132902xxxxxxxx', position='Body'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  id: long(name='Id', description='The workflow ID.

This parameter is required.', example='1234', position='Query'),
}

model DeleteWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DeleteWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteWorkflowResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of DeleteWorkflow  DeleteWorkflowRequest
  * @return DeleteWorkflowResponse
 */
async function deleteWorkflow(request: DeleteWorkflowRequest): DeleteWorkflowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteWorkflow', 'POST', '/', 'json', true, 'form', request);
}

model DeleteWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='860438872620113XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Body'),
}

model DeleteWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='B17730C0-D959-548A-AE23-E754177CXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DeleteWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @description >  A workflow that is deployed cannot be deleted. If you want to delete such a workflow, you must first undeploy the workflow.
  * @param request  the request parameters of DeleteWorkflowDefinition  DeleteWorkflowDefinitionRequest
  * @return DeleteWorkflowDefinitionResponse
 */
async function deleteWorkflowDefinition(request: DeleteWorkflowDefinitionRequest): DeleteWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model DetachDataQualityRulesFromEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityEvaluationTaskId: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task that is associated with the rule.

This parameter is required.', example='10000', position='Body'),
  dataQualityRuleIds: [ long ](name='DataQualityRuleIds', description='The IDs of the monitoring rules.

This parameter is required.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the workspace configuration page to obtain the workspace ID.

This parameter is required.', example='10002', position='Body'),
}

model DetachDataQualityRulesFromEvaluationTaskResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
  success?: boolean(name='Success', description='Whether the call is successful. The values are as follows:
- true: The call is successful.
- false: the call failed.', example='true'),
}

model DetachDataQualityRulesFromEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DetachDataQualityRulesFromEvaluationTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of DetachDataQualityRulesFromEvaluationTask  DetachDataQualityRulesFromEvaluationTaskRequest
  * @return DetachDataQualityRulesFromEvaluationTaskResponse
 */
async function detachDataQualityRulesFromEvaluationTask(request: DetachDataQualityRulesFromEvaluationTaskRequest): DetachDataQualityRulesFromEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DetachDataQualityRulesFromEvaluationTask', 'POST', '/', 'json', true, 'form', request);
}

model DissociateProjectFromResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The ID of the workspace from which you want to disassociate the resource group.

This parameter is required.', example='1000', position='Body'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
}

model DissociateProjectFromResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to locate logs and troubleshoot issues.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model DissociateProjectFromResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DissociateProjectFromResourceGroupResponseBody(name='body'),
}

/**
  * @description 1.  You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * 2.  Your account must be assigned one of the following roles of the desired workspace:
  * *   Tenant Owner, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of DissociateProjectFromResourceGroup  DissociateProjectFromResourceGroupRequest
  * @return DissociateProjectFromResourceGroupResponse
 */
async function dissociateProjectFromResourceGroup(request: DissociateProjectFromResourceGroupRequest): DissociateProjectFromResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DissociateProjectFromResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model ExecDeploymentStageRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  code: string(name='Code', description='The code of the stage in the process. You can call the GetDeployment operation to query the code.

This parameter is required.', example='DEV_CHECK', position='Body'),
  id: string(name='Id', description='The ID of the process.

This parameter is required.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Query'),
}

model ExecDeploymentStageResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true

*   false

    **

    **Note:** The value of this parameter indicates only whether the stage is triggered but does not indicate whether the execution of the stage is successful.', example='true'),
}

model ExecDeploymentStageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ExecDeploymentStageResponseBody(name='body'),
}

/**
  * @description >  The stages in a process are sequential. For more information, see the GetDeployment operation. Skipping or repeating a stage is not allowed.
  * >  The execution of a stage is asynchronous. The response of this operation indicates only whether a stage is triggered but does not indicate whether the execution of the stage is successful. You can call the GetDeployment operation to check whether the execution is successful.
  * @param request  the request parameters of ExecDeploymentStage  ExecDeploymentStageRequest
  * @return ExecDeploymentStageResponse
 */
async function execDeploymentStage(request: ExecDeploymentStageRequest): ExecDeploymentStageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ExecDeploymentStage', 'POST', '/', 'json', true, 'form', request);
}

model ExecuteAdhocWorkflowInstanceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  bizDate: long(name='BizDate', description='业务日期。

This parameter is required.', example='1710239005403', position='Body'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  name: string(name='Name', description='The name of the workflow instance.

This parameter is required.', example='WorkflowInstance1', position='Body'),
  owner: string(name='Owner', description='The account ID of the owner.

This parameter is required.', example='1000', position='Body'),
  projectId: long(name='ProjectId', description='The workspace ID.

This parameter is required.', example='100', position='Body'),
  tasks: [ 
    {
      clientUniqueCode: string(name='ClientUniqueCode', description='The unique code of the client. This code uniquely identifies a task.

This parameter is required.', example='Task_0bc5213917368545132902xxxxxxxx'),
      dataSource?: {
        name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
      }(name='DataSource', description='The information about the associated data source.'),
      dependencies?: [ 
        {
          upstreamOutput?: string(name='UpstreamOutput', description='The identifier of the output of the ancestor task.', example='pre.odps_sql_demo_0'),
        }
      ](name='Dependencies', description='The dependency information.'),
      inputs?: {
        variables?: [ 
          {
            name?: string(name='Name', description='The name of the variable.', example='key1'),
            value?: string(name='Value', description='The value of the variable.', example='Value1'),
          }
        ](name='Variables', description='The variables.'),
      }(name='Inputs', description='The input information.'),
      name: string(name='Name', description='The name of the task.

This parameter is required.', example='SQL node.'),
      outputs?: {
        taskOutputs?: [ 
          {
            output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
          }
        ](name='TaskOutputs', description='The task outputs.'),
        variables?: [ 
          {
            name?: string(name='Name', description='The name of the variable.', example='key1'),
            type?: string(name='Type', description='The type of the variable. Valid values:

*   System
*   Constant
*   NodeOutput
*   PassThrough', example='Constant'),
            value?: string(name='Value', description='The value of the variable.', example='value1'),
          }
        ](name='Variables', description='The variables.'),
      }(name='Outputs', description='The output information.'),
      owner: string(name='Owner', description='The account ID of the owner.

This parameter is required.', example='1000'),
      runtimeResource: {
        cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
        image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
        resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.

This parameter is required.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
      }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.

This parameter is required.'),
      script?: {
        content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
        parameters?: string(name='Parameters', description='The script parameters.', example='para1=$bizdate'),
      }(name='Script', description='The script information.'),
      timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
      type: string(name='Type', description='The type of the task.

This parameter is required.', example='ODPS_SQL'),
    }
  ](name='Tasks', description='The tasks.

This parameter is required.', shrink='json', position='Body'),
}

model ExecuteAdhocWorkflowInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
}

model ExecuteAdhocWorkflowInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ExecuteAdhocWorkflowInstanceResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ExecuteAdhocWorkflowInstance  ExecuteAdhocWorkflowInstanceRequest
  * @return ExecuteAdhocWorkflowInstanceResponse
 */
async function executeAdhocWorkflowInstance(request: ExecuteAdhocWorkflowInstanceRequest): ExecuteAdhocWorkflowInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ExecuteAdhocWorkflowInstance', 'POST', '/', 'json', true, 'form', request);
}

model GetAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: string(name='Id', description='The rule ID.', example='28547072', position='Query'),
}

model GetAlertRuleResponseBody = {
  alertRule?: {
    enabled?: boolean(name='Enabled', description='Indicates whether the rule is enabled.', example='true'),
    id?: long(name='Id', description='The rule ID.', example='16035'),
    name?: string(name='Name', description='The name of the rule.', example='error_rule'),
    notification?: {
      channels?: [ string ](name='Channels', description='The alert notification channels.'),
      intervalInMinutes?: int32(name='IntervalInMinutes', description='The interval at which an alert notification is sent. Unit: minutes. Valid values: [5,10000].', example='30'),
      maximum?: int32(name='Maximum', description='The maximum number of times an alert notification can be sent within a calendar day. Valid values: [1, 10000].', example='3'),
      receivers?: [ 
        {
          extension?: string(name='Extension', description='The additional configuration of the alert recipient. If the ReceiverType parameter is set to DingdingUrl, you can set this parameter to {"atAll":true} to remind all members in a DingTalk group.', example='{"atAll":true}'),
          receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid valves:

*   AliUid: Alibaba Cloud account ID.
*   Shift Schedules: the personnel in a shift schedule.
*   TaskOwner: the task owner. The task owner can receive custom alerts and event alerts.
*   Owner: the baseline owner. The baseline owner can receive baseline alerts.
*   WebhookUrl: URL of a custom webhook.
*   DingdingUrl: DingTalk webhook URL.
*   FeishuUrl: Lark webhook URL.
*   WeixinUrl: WeCom webhook URL.', example='WebhookUrl'),
          receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
        }
      ](name='Receivers', description='The alert recipients.'),
      silenceEndTime?: string(name='SilenceEndTime', description='The end time for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
      silenceStartTime?: string(name='SilenceStartTime', description='The start time for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
    }(name='Notification', description='The configuration for the alert notification.'),
    owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.', example='279961421580845157'),
    triggerCondition?: {
      extension?: {
        cycleUnfinished?: {
          cycleAndTime?: [ 
            {
              cycleId?: int32(name='CycleId', description='The ID of the scheduling cycle of the instance. Valid values: [1,288].', example='1'),
              time?: string(name='Time', description='The latest completion time of the instance within the scheduling cycle. The time is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
            }
          ](name='CycleAndTime', description='The configurations of the scheduling cycle and timeout period of the instance.'),
        }(name='CycleUnfinished', description='The configuration for an alert of the CycleUnfinished type.'),
        error?: {
          autoRerunAlertEnabled?: boolean(name='AutoRerunAlertEnabled', description='Indicates whether an alert is triggered if a batch synchronization task is automatically rerun upon a failure.', example='false'),
          streamTaskIds?: [ long ](name='StreamTaskIds', description='The IDs of the real-time computing tasks. This parameter is required when you monitor real-time computing tasks.'),
        }(name='Error', description='The configuration for an alert of the Error type.'),
        instanceErrorCount?: {
          count?: int32(name='Count', description='The maximum number of instances on which an error occurs. Valid values: [1,10000].', example='10'),
        }(name='InstanceErrorCount', description='The configuration for an alert of the InstanceErrorCount type.'),
        instanceErrorPercentage?: {
          percentage?: int32(name='Percentage', description='The maximum percentage of instances on which an error occurs in the workspace to the total number of instances. Valid values: [1-100].', example='10'),
        }(name='InstanceErrorPercentage', description='The configuration for an alert of the InstanceErrorPercentage type.'),
        instanceTransferFluctuate?: {
          percentage?: int32(name='Percentage', description='The maximum percentage of fluctuation in the number of auto triggered node instances that are generated in your workspace. Valid values: [1-100].', example='10'),
          trend?: string(name='Trend', description='The way in which the number of auto triggered node instances that are generated in your workspace fluctuates. Valid values:

*   abs: the absolute value. The number of instances increases or decreases.
*   increase: The number of instances increases.
*   decrease: The number of instances decreases.', example='10'),
        }(name='InstanceTransferFluctuate', description='The configuration for an alert of the InstanceTransferFluctuate type.'),
        timeout?: {
          timeoutInMinutes?: int32(name='TimeoutInMinutes', description='The timeout period. Unit: minutes. Valid values: [1, 21600].', example='10'),
        }(name='Timeout', description='The configuration for an alert of the Timeout type.'),
        unFinished?: {
          unFinishedTime?: string(name='UnFinishedTime', description='The latest completion time of the instance. The period is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
        }(name='UnFinished', description='The configuration for an alert of the UnFinished type.'),
      }(name='Extension', description='The extended information about the rule. This parameter is required for specific types of alerts.'),
      target?: {
        allowTasks?: [ long ](name='AllowTasks', description='The nodes that are not to be monitored.'),
        ids?: [ long ](name='Ids', description='The IDs of monitored objects.'),
        type?: string(name='Type', description='The type of the monitored objects. Valid values:

*   Task: node
*   Baseline: baseline
*   project: workspace
*   BizProcess: workflow', example='Task'),
      }(name='Target', description='The monitored objects.'),
      type?: string(name='Type', description='The alert type. Valid values:

*   Finished: An instance is successfully run.
*   UnFinished: An instance does not finish running before a specified point in time.
*   Error: An error occurs on an instance.
*   CycleUnfinished: An instance does not finish running as expected within a specific cycle.
*   Timeout: An instance times out.
*   InstanceTransferComplete: An instance is generated by the auto triggered node.
*   InstanceTransferFluctuate: The number of generated instances fluctuates.
*   ExhaustedError: An error persists after an instance is automatically rerun.
*   InstanceKeyword: An instance with errors contains specified keywords.
*   InstanceErrorCount: The number of instances on which an error occurs reaches a specified threshold.
*   InstanceErrorPercentage: The proportion of instances on which an error occurs in the workspace to the total number of instances reaches a specified threshold.
*   ResourceGroupPercentage: The usage rate of the resource group reaches a specified threshold.
*   ResourceGroupWaitCount: The number of instances that are waiting for resources in the resource group reaches a specified threshold.', example='Error'),
    }(name='TriggerCondition', description='The alert triggering condition.'),
  }(name='AlertRule', description='The information about the rule.'),
  requestId?: string(name='RequestId', description='The request ID.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
}

model GetAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAlertRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetAlertRule  GetAlertRuleRequest
  * @return GetAlertRuleResponse
 */
async function getAlertRule(request: GetAlertRuleRequest): GetAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAlertRule', 'GET', '/', 'json', false, 'json', request);
}

model GetCreateWorkflowInstancesResultRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  operationId: string(name='OperationId', description='The operation ID. This parameter is used to query the result of asynchronously creating a workflow instance. You can call the CreateWorkflowInstances operation to query the ID.

This parameter is required.', example='e15ad21c-b0e9-4792-8f55-b037xxxxxxxx', position='Query'),
}

model GetCreateWorkflowInstancesResultResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  result?: {
    failureMessage?: string(name='FailureMessage', description='The error message. This parameter is returned only if the creation fails.', example='Invalid Param xxx'),
    status?: string(name='Status', description='The creation status. Valid values:

*   Creating
*   Created
*   CreateFailure', example='Created'),
    workflowInstanceIds?: [ long ](name='WorkflowInstanceIds', description='The workflow instance IDs. This parameter is returned only if the creation is successful.'),
  }(name='Result', description='The result of asynchronously creating a workflow instance.'),
}

model GetCreateWorkflowInstancesResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetCreateWorkflowInstancesResultResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetCreateWorkflowInstancesResult  GetCreateWorkflowInstancesResultRequest
  * @return GetCreateWorkflowInstancesResultResponse
 */
async function getCreateWorkflowInstancesResult(request: GetCreateWorkflowInstancesResultRequest): GetCreateWorkflowInstancesResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetCreateWorkflowInstancesResult', 'GET', '/', 'json', false, 'json', request);
}

model GetDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='11588', deprecated='true', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11588', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
  withDetails?: boolean(name='WithDetails', description='Specifies whether to return detailed configuration information, including TransformationRules, TableMappings, and JobSettings. Valid values: true and false. Default value: true.', example='true', position='Query'),
}

model GetDIJobResponseBody = {
  pagingInfo?: {
    DIJobId?: string(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='32601', deprecated='true'),
    description?: string(name='Description', description='The description of the synchronization task.', example='description'),
    destinationDataSourceSettings?: [ 
      {
        dataSourceName?: string(name='DataSourceName', description='The name of the data source.', example='dw_mysql'),
      }
    ](name='DestinationDataSourceSettings', description='The properties of the destination.'),
    destinationDataSourceType?: string(name='DestinationDataSourceType', description='The destination type. Valid values: Hologres, OSS-HDFS, OSS, MaxCompute, Loghub, STARROCKS, Datahub, ANALYTICDB_FOR_MYSQL, Kafka, and Hive.', example='Hologres'),
    id?: long(name='Id', description='The ID of the synchronization task.', example='32601'),
    jobName?: string(name='JobName', description='The name of the synchronization task.', example='imp_ods_dms_det_dealer_info_df'),
    jobSettings?: {
      channelSettings?: string(name='ChannelSettings', description='The channel control settings for the synchronization task. You can configure special channel control settings for the following synchronization links: data synchronization between Hologres data sources and data synchronization from Hologres to Kafka.

1.  Holo2Kafka

*   Example: {"destinationChannelSettings":{"kafkaClientProperties":[{"key":"linger.ms","value":"100"}],"keyColumns":["col3"],"writeMode":"canal"}}
*   kafkaClientProperties: the parameters related to a Kafka producer, which are used when you write data to a Kafka data source.
*   keyColumns: the names of Kafka columns to which data is written.
*   writeMode: the writing format. Valid values: json and canal.

2.  Holo2Holo

*   Example: {"destinationChannelSettings":{"conflictMode":"replace","dynamicColumnAction":"replay","writeMode":"replay"}}
*   conflictMode: the policy used to handle a conflict that occurs during data writing to Hologres. Valid values: replace and ignore.
*   writeMode: the mode in which data is written to Hologres. Valid values: replay and insert.
*   dynamicColumnAction: the mode in which data is written to dynamic columns in a Hologres table. Valid values: replay, insert, and ignore.', example='{"structInfo":"MANAGED","storageType":"TEXTFILE","writeMode":"APPEND","partitionColumns":[{"columnName":"pt","columnType":"STRING","comment":""}],"fieldDelimiter":""}'),
      columnDataTypeSettings?: [ 
        {
          destinationDataType?: string(name='DestinationDataType', description='The data type of the destination field. Valid values: bigint, boolean, string, text, datetime, timestamp, decimal, and binary. Different types of data sources support different data types.', example='text'),
          sourceDataType?: string(name='SourceDataType', description='The data type of the source field. Valid values: bigint, boolean, string, text, datetime, timestamp, decimal, and binary. Different types of data sources support different data types.', example='bigint'),
        }
      ](name='ColumnDataTypeSettings', description='The data type mappings between source fields and destination fields.'),
      cycleScheduleSettings?: {
        cycleMigrationType?: string(name='CycleMigrationType', description='The synchronization type that requires periodic scheduling. Valid values:

*   Full: full synchronization
*   OfflineIncremental: batch incremental synchronization', example='Full'),
        scheduleParameters?: string(name='ScheduleParameters', description='The scheduling parameters.', example='bizdate=$bizdate'),
      }(name='CycleScheduleSettings', description='The settings for periodic scheduling.'),
      ddlHandlingSettings?: [ 
        {
          action?: string(name='Action', description='The processing policy for a specific type of DDL message. Valid values:

*   Ignore: ignores a DDL message.
*   Critical: reports an error for a DDL message.
*   Normal: normally processes a DDL message.', example='Ignore'),
          type?: string(name='Type', description='The DDL operation type. Valid values:

*   RenameColumn
*   ModifyColumn
*   CreateTable
*   TruncateTable
*   DropTable', example='CreateTable'),
        }
      ](name='DdlHandlingSettings', description='The DDL operation types. Valid values:

*   RenameColumn
*   ModifyColumn
*   CreateTable
*   TruncateTable
*   DropTable
*   DropColumn
*   AddColumn'),
      runtimeSettings?: [ 
        {
          name?: string(name='Name', description='The name of the configuration item. Valid values:

*   src.offline.datasource.max.connection: indicates the maximum number of connections that are allowed for reading data from the source of a batch synchronization task.
*   dst.offline.truncate: indicates whether to clear the destination table before data writing.
*   runtime.offline.speed.limit.enable: indicates whether throttling is enabled for a batch synchronization task.
*   runtime.offline.concurrent: indicates the maximum number of parallel threads that are allowed for a batch synchronization task.
*   runtime.enable.auto.create.schema: indicates whether schemas are automatically created in the destination of a synchronization task.
*   runtime.realtime.concurrent: indicates the maximum number of parallel threads that are allowed for a real-time synchronization task.
*   runtime.realtime.failover.minute.dataxcdc: indicates the maximum waiting duration before a synchronization task retries the next restart if the previous restart fails after failover occurs. Unit: minutes.
*   runtime.realtime.failover.times.dataxcdc: indicates the maximum number of failures that are allowed for restarting a synchronization task after failovers occur.', example='runtime.offline.concurrent'),
          value?: string(name='Value', description='The value of the configuration item.', example='1'),
        }
      ](name='RuntimeSettings', description='The runtime settings.'),
    }(name='JobSettings', description='The runtime settings.'),
    jobStatus?: string(name='JobStatus', description='The status of the job.', example='Running'),
    migrationType?: string(name='MigrationType', description='The synchronization type. Valid values:

*   FullAndRealtimeIncremental: one-time full synchronization and real-time incremental synchronization
*   RealtimeIncremental: real-time incremental synchronization
*   Full: full synchronization
*   OfflineIncremental: batch incremental synchronization
*   FullAndOfflineIncremental: one-time full synchronization and batch incremental synchronization', example='FullAndRealtimeIncremental'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter indicates the DataWorks workspace to which the API operation is applied.', example='98330'),
    resourceSettings?: {
      offlineResourceSettings?: {
        requestedCu?: double(name='RequestedCu', description='The number of compute units (CUs) in the resource group for scheduling that are used for batch synchronization.', example='2.0'),
        resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for Data Integration used for batch synchronization.', example='S_res_group_7708_1667792816832'),
      }(name='OfflineResourceSettings', description='The resource used for batch synchronization.'),
      realtimeResourceSettings?: {
        requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for Data Integration that are used for real-time synchronization.', example='2.0'),
        resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for Data Integration used for real-time synchronization.', example='S_res_group_235454102432001_1579085295030'),
      }(name='RealtimeResourceSettings', description='The resource used for real-time synchronization.'),
      scheduleResourceSettings?: {
        requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for Data Integration that are used for scheduling.', example='2.0'),
        resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for scheduling used by the synchronization task.', example='S_res_group_235454102432001_1718359176885'),
      }(name='ScheduleResourceSettings', description='The resource used for scheduling.'),
    }(name='ResourceSettings', description='The resource settings.'),
    sourceDataSourceSettings?: [ 
      {
        dataSourceName?: string(name='DataSourceName', description='The name of the data source.', example='dw_mysql'),
        dataSourceProperties?: {
          encoding?: string(name='Encoding', description='The encoding format of the database.', example='UTF-8'),
          timezone?: string(name='Timezone', description='The time zone.', example='GMT+8'),
        }(name='DataSourceProperties', description='The properties of the data source.'),
      }
    ](name='SourceDataSourceSettings', description='The settings of the source. Only a single source is supported.'),
    sourceDataSourceType?: string(name='SourceDataSourceType', description='The source type. Valid values: PolarDB, MySQL, Kafka, Loghub, Hologres, Oracle, OceanBase, MongoDB, RedShift, Hive, SqlServer, Doris, and ClickHouse.', example='Mysql'),
    tableMappings?: [ 
      {
        sourceObjectSelectionRules?: [ 
          {
            action?: string(name='Action', description='The operation that is performed to select objects. Valid values: Include and Exclude.', example='Include'),
            expression?: string(name='Expression', description='The expression.', example='mysql_table_1'),
            expressionType?: string(name='ExpressionType', description='The expression type. Valid values: Exact and Regex.', example='Exact'),
            objectType?: string(name='ObjectType', description='The object type. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
          }
        ](name='SourceObjectSelectionRules', description='The list of rules used to select synchronization objects in the source.'),
        transformationRules?: [ 
          {
            ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml', example='AddColumn'),
            ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
            ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which the action is performed. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
          }
        ](name='TransformationRules', description='The list of transformation rules that are applied to the synchronization objects selected from the source. Each entry in the list defines a transformation rule.'),
      }
    ](name='TableMappings', description='The list of mappings between rules used to select synchronization objects in the source and transformation rules applied to the selected synchronization objects. Each entry in the list displays a mapping between a rule used to select synchronization objects and a transformation rule applied to the selected synchronization objects.

>  [ { "SourceObjectSelectionRules":[ { "ObjectType":"Database", "Action":"Include", "ExpressionType":"Exact", "Expression":"biz_db" }, { "ObjectType":"Schema", "Action":"Include", "ExpressionType":"Exact", "Expression":"s1" }, { "ObjectType":"Table", "Action":"Include", "ExpressionType":"Exact", "Expression":"table1" } ], "TransformationRuleNames":[ { "RuleName":"my_database_rename_rule", "RuleActionType":"Rename", "RuleTargetType":"Schema" } ] } ]'),
    transformationRules?: [ 
      {
        ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml
*   DefineIncrementalCondition
*   DefineCycleScheduleSettings
*   DefinePartitionKey', example='Rename'),
        ruleExpression?: string(name='RuleExpression', description='The expression of the rule. The expression is a JSON string.

1.  Example of a renaming rule

*   Example: {"expression":"${srcDatasourceName}_${srcDatabaseName}_0922" }
*   expression: the expression of the renaming rule. You can use the following variables in an expression: ${srcDatasourceName}, ${srcDatabaseName}, and ${srcTableName}. ${srcDatasourceName} indicates the name of the source. ${srcDatabaseName} indicates the name of a source database. ${srcTableName} indicates the name of a source table.

2.  Example of a column addition rule

*   Example: {"columns":[{"columnName":"my_add_column","columnValueType":"Constant","columnValue":"123"}]}
*   If no rule of this type is configured, no fields are added to the destination and no values are assigned by default.
*   columnName: the name of the field that is added.
*   columnValueType: the value type of the field. Valid values: Constant and Variable.
*   columnValue: the value of the field. If the columnValueType parameter is set to Constant, the value of the columnValue parameter is a constant of the STRING data type. If the columnValueType parameter is set to Variable, the value of the columnValue parameter is a built-in variable. The following built-in variables are supported: EXECUTE_TIME (LONG data type), DB_NAME_SRC (STRING data type), DATASOURCE_NAME_SRC (STRING data type), TABLE_NAME_SRC (STRING data type), DB_NAME_DEST (STRING data type), DATASOURCE_NAME_DEST (STRING data type), TABLE_NAME_DEST (STRING data type), and DB_NAME_SRC_TRANSED (STRING data type). EXECUTE_TIME indicates the execution time. DB_NAME_SRC indicates the name of a source database. DATASOURCE_NAME_SRC indicates the name of the source. TABLE_NAME_SRC indicates the name of a source table. DB_NAME_DEST indicates the name of a destination database. DATASOURCE_NAME_DEST indicates the name of the destination. TABLE_NAME_DEST indicates the name of a destination table. DB_NAME_SRC_TRANSED indicates the database name obtained after a transformation.

3.  Example of a rule used to specify primary key fields for a destination table

*   Example: {"columns":["ukcolumn1","ukcolumn2"]}
*   If no rule of this type is configured, the primary key fields in the mapped source table are used for the destination table by default.
*   If the destination table is an existing table, Data Integration does not modify the schema of the destination table. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run.
*   If the destination table is automatically created by the system, Data Integration automatically creates the schema of the destination table. The schema contains the primary key fields that you specify. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run.

4.  Example of a rule used to process DML messages

*   Example: {"dmlPolicies":[{"dmlType":"Delete","dmlAction":"Filter","filterCondition":"id > 1"}]}
*   If no rule of this type is configured, the default processing policy for messages generated for insert, update, and delete operations is Normal.
*   dmlType: the DML operation. Valid values: Insert, Update, and Delete.
*   dmlAction: the processing policy for DML messages. Valid values: Normal, Ignore, Filter, and LogicalDelete. Filter indicates conditional processing. The value Filter is returned for the dmlAction parameter only when the value of the dmlType parameter is Update or Delete.
*   filterCondition: the condition used to filter DML messages. This parameter is returned only when the value of the dmlAction parameter is Filter.

5.  Example of a rule used to perform incremental synchronization

*   Example: {"where":"id > 0"}
*   The rule used to perform incremental synchronization is returned.

6.  Example of a rule used to configure scheduling parameters for an auto triggered task

*   Example: {"cronExpress":" \\* \\* \\* \\* \\* \\*", "cycleType":"1"}
*   The rule used to configure scheduling parameters for an auto triggered task is returned.

7.  Example of a rule used to specify a partition key

*   Example: {"columns":["id"]}
*   The rule used to specify a partition key is returned.', example='{"expression":"${srcDatasoureName}_${srcDatabaseName}"}'),
        ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
        ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which the action is performed. Valid values:

*   Table
*   Schema
*   Database', example='Table'),
      }
    ](name='TransformationRules', description='The list of transformation rules that are applied to the synchronization objects selected from the source.

>  [ { "RuleName":"my_database_rename_rule", "RuleActionType":"Rename", "RuleTargetType":"Schema", "RuleExpression":"{"expression":"${srcDatasoureName}_${srcDatabaseName}"}" } ]'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADE490'),
}

model GetDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDIJob  GetDIJobRequest
  * @return GetDIJobResponse
 */
async function getDIJob(request: GetDIJobRequest): GetDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDIJob', 'GET', '/', 'json', false, 'json', request);
}

model GetDIJobLogRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='10000', deprecated='true', position='Query'),
  failoverId?: long(name='FailoverId', description='The failover ID.', example='10', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='10000', position='Query'),
  instanceId?: long(name='InstanceId', description='The instance ID.', example='6153616438', position='Query'),
  nodeType?: string(name='NodeType', position='Query'),
  pageNumber?: int32(name='PageNumber', position='Query'),
}

model GetDIJobLogResponseBody = {
  log?: string(name='Log', description='The log.', example='>>>>>>>> stdout:n++++++++++++++++++executing sql: create database if not exists jindo_test location \\"oss://pangbei-hdfs/tmp/hive\\" n++n'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='1AFAE64E-D1BE-432B-A9****'),
}

model GetDIJobLogResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDIJobLogResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDIJobLog  GetDIJobLogRequest
  * @return GetDIJobLogResponse
 */
async function getDIJobLog(request: GetDIJobLogRequest): GetDIJobLogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDIJobLog', 'GET', '/', 'json', false, 'json', request);
}

model GetDataQualityEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  id?: long(name='Id', description='The ID of the data quality monitor.', example='1006455182', position='Query'),
}

model GetDataQualityEvaluationTaskResponseBody = {
  dataQualityEvaluationTask?: {
    dataSourceId?: long(name='DataSourceId', description='The ID of the data source used by the quality monitoring task.', example='45238'),
    description?: string(name='Description', description='The description of the monitor.', example='The description of the quality monitoring task.'),
    hooks?: [ 
      {
        condition?: string(name='Condition', description='Hook trigger condition. When this condition is met, hook action is triggered. Currently, only two conditional expressions are supported:

- Specify only one set of rule severity types AND rule verification status, such as `${severity} = = "High" AND ${status} = = "Critical"`, which indicates that in the executed rule, if the rule verification result of severity High is Critical, the condition is met.
- Specify multiple sets of rule severity types AND rule verification status, such as `(${severity} = = "High" AND ${status} = "Critical") OR (${severity} = "Normal" AND ${status} = "Critical") OR (${severity} = "Normal" AND ${status} = "Error")`, if the rule verification result of severity High is Critical, the rule verification result of severity Normal is Critical, or the rule verification result of severity Normal is Error, the enumeration that satisfies the condition expression severity is consistent with the enumeration DataQualityRule in severity, and the enumeration of status is consistent with the status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
        type?: string(name='Type', description='The hook type. Only one hook type is supported.

*   BlockTaskInstance: Blocks the running of scheduling tasks. A monitor is triggered by scheduling tasks. After a monitor finishes running, the monitor determines whether to block the running of scheduling tasks based on the hook condition.', example='BlockTaskInstance'),
      }
    ](name='Hooks', description='The hook.'),
    id?: long(name='Id', description='The ID of the data quality monitor.', example='2178'),
    name: string(name='Name', description='The name of the monitor.

This parameter is required.', example='OpenAPI create a data quality monitoring test'),
    notifications?: {
      condition?: string(name='Condition', description='The notification trigger condition. When this condition is met, a message notification is triggered. Currently, only two conditional expressions are supported:

- Specify only one set of rule severity types AND rule verification status, such as `${severity} = = "High" AND ${status} = = "Critical"`, which indicates that in the executed rule, if the rule verification result of severity High is Critical, the condition is met.
- Specify multiple sets of rule severity types AND rule verification status, such as `(${severity} = = "High" AND ${status} = "Critical") OR (${severity} = "Normal" AND ${status} = "Critical") OR (${severity} = "Normal" AND ${status} = "Error")`, if the rule verification result of severity High is Critical, the rule verification result of severity Normal is Critical, or the rule verification result of severity Normal is Error, the enumeration that satisfies the condition expression severity is consistent with the enumeration DataQualityRule in severity, and the enumeration of status is consistent with the status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
      notifications?: [ 
        {
          notificationChannels?: [ 
            {
              channels?: [ string ](name='Channels', description='The alert notification methods.'),
            }
          ](name='NotificationChannels', description='The alert notification methods.'),
          notificationReceivers?: [ 
            {
              extension?: string(name='Extension', description='The extended information.', example='{  "atAll": true }'),
              receiverType?: string(name='ReceiverType', description='The additional parameters that are required when alerts are sent. The parameters are JSON-formatted strings. The following keys are supported:

*   atAll: specifies that all members in a group are mentioned when alerts are sent by using DingTalk. This parameter is valid only if you set ReceiverType to DingdingUrl.

Valid values:

*   WebhookUrl
*   FeishuUrl
*   DingdingUrl
*   WeixinUrl
*   AliUid', example='DingdingUrl'),
              receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
            }
          ](name='NotificationReceivers', description='The configurations of alert recipients.'),
        }
      ](name='Notifications', description='The configurations of alert notifications.'),
    }(name='Notifications', description='The configurations of alert notifications.'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='2626'),
    runtimeConf?: string(name='RuntimeConf', description='Extended configuration, JSON-formatted string, takes effect only for EMR-type data quality monitoring.

- queue: the yarn queue used when performing EMR data quality verification. The default queue is the queue configured for this project.
- sqlEngine: SQL engine used when performing EMR data verification
    - HIVE_ SQL
    - SPARK_ SQL', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }'),
    target?: {
      databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   hologres
*   cdh
*   analyticdb_for_mysql
*   starrocks
*   emr
*   analyticdb_for_postgresql', example='maxcompute'),
      partitionSpec?: string(name='PartitionSpec', description='Data quality monitoring partition range settings.', example='pt=$[yyyymmdd-1]'),
      tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.meta_open_api_test_sz.test_partition_tbl'),
      type?: string(name='Type', description='The type of the monitoring object.

- Table: Table.', example='Table'),
    }(name='Target', description='The monitored object of the monitor.'),
    trigger?: {
      taskIds?: [ long ](name='TaskIds', description='The IDs of scheduling tasks. This parameter is valid only if you set Type to ByScheduledTaskInstance.'),
      type?: string(name='Type', description='The trigger type of the monitor. Valid values:

*   ByManual: The monitor is manually triggered.
*   ByScheduledTaskInstance: The monitor is triggered by associated scheduling tasks.
*   ByQualityNode: The monitor is triggered by created data quality monitoring nodes.', example='ByScheduledTaskInstance'),
    }(name='Trigger', description='The trigger configuration of the monitor.'),
  }(name='DataQualityEvaluationTask', description='The details of the monitor.'),
  requestId?: string(name='RequestId', description='Id of the request', example='SDFSDFSDF-SDFSDF-SDFDSF-SDFSDF'),
}

model GetDataQualityEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityEvaluationTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDataQualityEvaluationTask  GetDataQualityEvaluationTaskRequest
  * @return GetDataQualityEvaluationTaskResponse
 */
async function getDataQualityEvaluationTask(request: GetDataQualityEvaluationTaskRequest): GetDataQualityEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityEvaluationTask', 'GET', '/', 'json', false, 'json', request);
}

model GetDataQualityEvaluationTaskInstanceRequest {
  regionId?: string(name='RegionId', position='Host'),
  id: long(name='Id', description='The ID of the data quality monitoring instance.

This parameter is required.', example='7227550902', position='Query'),
}

model GetDataQualityEvaluationTaskInstanceResponseBody = {
  dataQualityEvaluationTaskInstance?: {
    createTime?: long(name='CreateTime', description='The creation time.', example='1716344665000'),
    finishTime?: long(name='FinishTime', description='The end time of the instance.', example='1716344665000'),
    id?: long(name='Id', description='The ID of the data quality monitoring instance.', example='7234231689'),
    parameters?: string(name='Parameters', description='Data quality verification execution parameters in JSON format. The available keys are as follows:
- triggerTime: the millisecond timestamp of the trigger time. The baseline time of the $[yyyymmdd] expression in the data range of data quality monitoring. Required.', example='{ "triggerTime": 1733284062000 }'),
    projectId?: long(name='ProjectId', description='The ID of the workspace.', example='98330'),
    status?: string(name='Status', description='The status of the data quality monitoring instance.
- Running: Verifying
- Error: A rule verification Error occurred.
- Passed: all rules are verified
- Warned: normal alarm threshold triggered by rules
- Critical: Threshold for serious alerts triggered by rules', example='Passed'),
    task?: {
      description?: string(name='Description', description='The description of the monitor.', example='OpenAPI quality monitoring test'),
      hooks?: [ 
        {
          condition?: string(name='Condition', description='Hook trigger condition. When this condition is met, hook action is triggered. Currently, only two conditional expressions are supported:

- Specify only one set of rule severity types AND rule verification status, such as `${severity} = = "High" AND ${status} = = "Critical"`, which indicates that in the executed rule, if the rule verification result of severity High is Critical, the condition is met.
- Specify multiple sets of rule severity types AND rule verification status, such as `(${severity} = = "High" AND ${status} = "Critical") OR (${severity} = "Normal" AND ${status} = "Critical") OR (${severity} = "Normal" AND ${status} = "Error")`, if the rule verification result of severity High is Critical, the rule verification result of severity Normal is Critical, or the rule verification result of severity Normal is Error, the enumeration that satisfies the condition expression severity is consistent with the enumeration DataQualityRule in severity, and the enumeration of status is consistent with the status in DataQualityResult.', example='(${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error")'),
          type?: string(name='Type', description='Hook type. Currently, only one type is supported:

- BlockTaskInstance: the blocking scheduling task continues to run. Data quality monitoring is triggered by the scheduling task. After the data quality monitoring is completed, the Hook.Condition is used to determine whether the blocking scheduling task continues to run.', example='BlockTaskInstance'),
        }
      ](name='Hooks', description='Callback settings.'),
      id?: long(name='Id', description='The ID of the data quality monitor.', example='28544990'),
      name?: string(name='Name', description='The name of the monitor.', example='Data quality OpenAPI monitoring test'),
      notifications?: {
        condition?: string(name='Condition', description='The notification trigger condition. When this condition is met, a message notification is triggered. Currently, only two conditional expressions are supported:

- Specify only one set of rule severity types AND rule verification status, such as `${severity} = = "High" AND ${status} = = "Critical"`, which indicates that in the executed rule, if the rule verification result of severity High is Critical, the condition is met.
- Specify multiple sets of rule severity types AND rule verification status, such as `(${severity} = = "High" AND ${status} = "Critical") OR (${severity} = "Normal" AND ${status} = "Critical") OR (${severity} = "Normal" AND ${status} = "Error")`, if the rule verification result of severity High is Critical, the rule verification result of severity Normal is Critical, or the rule verification result of severity Normal is Error, the enumeration that satisfies the condition expression severity is consistent with the enumeration DataQualityRule in severity, and the enumeration of status is consistent with the status in DataQualityResult.', example='${severity} == "High" AND ${status} == "Critical"'),
        notifications?: [ 
          {
            notificationChannels?: [ 
              {
                channels?: [ string ](name='Channels', description='The notification method.'),
              }
            ](name='NotificationChannels', description='The notification method.'),
            notificationReceivers?: [ 
              {
                extension?: string(name='Extension', description='Additional parameter settings for sending alerts in json format. The supported keys are as follows:

- atAll: when sending DingTalk alerts, do you need to @ everyone in the group. It takes effect when ReceiverType is DingdingUrl.', example='{ "atAll": true }'),
                receiverType?: string(name='ReceiverType', description='The type of alert recipient.', example='DingdingUrl'),
                receiverValues?: [ string ](name='ReceiverValues', description='The recipient of the alert.'),
              }
            ](name='NotificationReceivers', description='The value of the receiver.'),
          }
        ](name='Notifications', description='The alert notification methods.'),
      }(name='Notifications', description='The configurations of alert notifications.'),
      projectId?: long(name='ProjectId', description='The ID of the workspace.', example='20629'),
      runtimeConf?: string(name='RuntimeConf', description='Extended configuration, JSON-formatted string, takes effect only for EMR-type data quality monitoring.

- queue: the yarn queue used when performing EMR data quality verification. The default queue is the queue configured for this project.
- sqlEngine: SQL engine used when performing EMR data verification
  - HIVE_ SQL
  - SPARK_ SQL', example='{ "queue": "default" }'),
      target?: {
        databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs.', example='maxcompute'),
        partitionSpec?: string(name='PartitionSpec', description='The partition range monitored.', example='pt=$[yyyymmdd-1]'),
        tableGuid?: string(name='TableGuid', description='The unique ID of the table in the data map.', example='odps.api_trace.ods_d_api_log'),
        type?: string(name='Type', description='The type of the monitoring object.
- Table: Table', example='Table'),
      }(name='Target', description='For more information, see DataQualityTarget monitoring objects for the sample data quality verification task. For more information, see DataQualityTarget.'),
      trigger?: {
        taskIds?: [ long ](name='TaskIds', description='The Id list of the scheduled task, which is valid when the Type is ByScheduledTaskInstance.'),
        type?: string(name='Type', description='Quality Monitoring trigger type:

- ByManual: manually triggered. Default value
- ByScheduledTaskInstance: triggered by associated scheduling tasks', example='ByScheduledTaskInstance'),
      }(name='Trigger', description='The trigger configuration of the data quality verification task.'),
    }(name='Task', description='The monitor.'),
    triggerContext?: string(name='TriggerContext', description='The context information when the instance is triggered, in JSON format. The possible keys are as follows:
- TriggerClient: the trigger source of the data quality monitoring instance, such as CWF2 (scheduling system), may be added later.
- TriggerClientId: associated with a specific business resource in the source system. For example, if TriggerClient is CWF2, the ID of the scheduling task is recorded here.', example='{ "triggerClient": "CWF2", "triggerClientId": 70001238945 }'),
  }(name='DataQualityEvaluationTaskInstance', description='The details of the monitor instance.'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
}

model GetDataQualityEvaluationTaskInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityEvaluationTaskInstanceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDataQualityEvaluationTaskInstance  GetDataQualityEvaluationTaskInstanceRequest
  * @return GetDataQualityEvaluationTaskInstanceResponse
 */
async function getDataQualityEvaluationTaskInstance(request: GetDataQualityEvaluationTaskInstanceRequest): GetDataQualityEvaluationTaskInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityEvaluationTaskInstance', 'GET', '/', 'json', false, 'json', request);
}

model GetDataQualityRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  id: long(name='Id', description='The rule ID.

This parameter is required.', example='19715', position='Query'),
}

model GetDataQualityRuleResponseBody = {
  dataQualityRule?: {
    checkingConfig?: {
      referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='Some types of thresholds need to query some reference samples, and then summarize the values of the reference samples to obtain the threshold for comparison. Here, an expression is used to represent the query method of the reference samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
      thresholds?: {
        critical?: {
          expression?: string(name='Expression', description='The threshold expression.', example='$checkValue > 0.05'),
          operator?: string(name='Operator', description='Comparison character:
- \\>
- % =
- <
- <=
- ! =
- =', example='>'),
          value?: string(name='Value', description='The threshold value.', example='100.0'),
        }(name='Critical', description='The threshold settings for critical alerts.'),
        expected?: {
          expression?: string(name='Expression', description='The threshold expression.', example='$checkValue <= 0.01'),
          operator?: string(name='Operator', description='Comparison character:
- \\>
- % =
- <
- <=
- ! =
- =', example='>'),
          value?: string(name='Value', description='The threshold value.', example='100.0'),
        }(name='Expected', description='The expected threshold setting.'),
        warned?: {
          expression?: string(name='Expression', description='The threshold expression.', example='$checkValue > 0.01'),
          operator?: string(name='Operator', description='Comparison character:
- \\>
- % =
- <
- <=
- ! =
- =', example='>'),
          value?: string(name='Value', description='The threshold value.', example='100.0'),
        }(name='Warned', description='The threshold settings for normal alerts.'),
      }(name='Thresholds', description='The threshold settings.'),
      type?: string(name='Type', description='Threshold Calculation method:
- Fixed
- Fluctation
- FluctationDiscreate
- Auto
- Average
- Variance', example='Fixed'),
    }(name='CheckingConfig', description='The check settings for sample data.'),
    description?: string(name='Description', description='The description of the rule. It can be up to 500 characters in length.', example='this is a odps _sql task'),
    enabled?: boolean(name='Enabled', description='Whether the rule is enabled.', example='true'),
    errorHandlers?: [ 
      {
        errorDataFilter?: string(name='ErrorDataFilter', description='For custom SQL rules, you must specify SQL to filter problem data.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
        type?: string(name='Type', description='Processor type:
- SaveErrorData', example='SaveErrorData'),
      }
    ](name='ErrorHandlers', description='The list of quality rule verification problem processors.'),
    id?: long(name='Id', description='The ID of the rule.', example='16033'),
    name?: string(name='Name', description='The name of the rule.', example='The table cannot be empty.'),
    projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace.', example='1948'),
    samplingConfig?: {
      metric?: string(name='Metric', description='The name of the sampled metric:
- Count: number of table rows
- Min: minimum value of the field
- Max: The maximum value of the field.
- Avg: field mean
- DistinctCount: number of unique field values
- DistinctPercent: the ratio of the number of unique field values to the number of data rows.
- DuplicatedCount: number of duplicate field values
- DuplicatedPercent: the ratio of the number of duplicate field values to the number of data rows.
- TableSize: table size
- NullValueCount: number of rows with empty fields
- NullValuePercent: the proportion of fields that are empty.
- GroupCount: aggregate each value by field value and the corresponding number of data rows
- CountNotIn: the enumerated value does not match the number of rows.
- CountDistinctNotIn: the number of unique values that the enumerated values do not match.
- UserDefinedSql: use custom SQL to collect samples', example='Max'),
      metricParameters?: string(name='MetricParameters', description='Parameters required for sample collection.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
      samplingFilter?: string(name='SamplingFilter', description='The condition for secondary filtering of data that is not concerned during sampling, which can be up to 16777215 characters in length.', example='id IS NULL'),
      settingConfig?: string(name='SettingConfig', description='Before executing the sample statement, insert some runtime parameter setting statements, which can be up to 1000 characters in length. Currently, only MaxCompute is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;'),
    }(name='SamplingConfig', description='The settings required for sample collection.'),
    severity?: string(name='Severity', description='Rule for the business level (corresponding to the strong and weak rules on the page), optional enumeration value:
- Normal
- High', example='High'),
    target?: {
      databaseType?: string(name='DatabaseType', description='The dataset of the table type. The database type to which the table belongs.
- maxcompute
- emr
- cdh
- hologres
- analyticdb_for_postgresql
- analyticdb_for_mysql
- starrocks', example='maxcompute'),
      partitionSpec?: string(name='PartitionSpec', description='Partition settings for partitioned tables.', example='ds=$[yyyymmdd-1]'),
      tableGuid?: string(name='TableGuid', description='The unique ID of the table used by the rule in the data map.', example='odps.unit_test.tb_unit_test'),
      type?: string(name='Type', description='Monitoring object type

- Table', example='Table'),
    }(name='Target', description='The object monitored by the rule.'),
    templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='system::user_defined'),
  }(name='DataQualityRule', description='The information about the rule.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model GetDataQualityRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityRuleResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDataQualityRule  GetDataQualityRuleRequest
  * @return GetDataQualityRuleResponse
 */
async function getDataQualityRule(request: GetDataQualityRuleRequest): GetDataQualityRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityRule', 'GET', '/', 'json', false, 'json', request);
}

model GetDataQualityRuleTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  code: string(name='Code', description='The code for the template.

This parameter is required.', example='USER_DEFINED:123', position='Query'),
}

model GetDataQualityRuleTemplateResponseBody = {
  dataQualityRuleTemplate?: {
    checkingConfig?: {
      referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='Some types of thresholds need to query some reference samples, and then summarize the values of the reference samples to obtain the threshold for comparison. Here, an expression is used to represent the query method of the reference samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
      type?: string(name='Type', description='Threshold Calculation method:
- Fixed
- Fluctation
- FluctationDiscreate
- Auto
- Average
- Variance', example='Fixed'),
    }(name='CheckingConfig', description='Sample verification settings.'),
    code?: string(name='Code', description='The Code of the rule template.', example='USER_DEFINED:123'),
    directoryPath?: string(name='DirectoryPath', description='The category directory where the custom template is stored, separated by slashes. Each level name can be up to 1024 characters in length and cannot contain white space characters or slashes.', example='/ods/order_data'),
    name?: string(name='Name', description='The name of the rule template. It can contain up to 512 characters in length, including numbers, letters, Chinese characters, and half-width punctuation marks.', example='Table row Count Verification'),
    projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace.', example='4020'),
    samplingConfig?: {
      metric?: string(name='Metric', description='The name of the sampled metric.
- Count: number of table rows
- Min: minimum value of the field
- Max: The maximum value of the field.
- Avg: field mean
- DistinctCount: number of unique field values
- DistinctPercent: the ratio of the number of unique field values to the number of data rows.
- DuplicatedCount: number of duplicate field values
- DuplicatedPercent: the ratio of the number of duplicate field values to the number of data rows.
- TableSize: table size
- NullValueCount: number of rows with empty fields
- NullValuePercent: the proportion of fields that are empty.
- GroupCount: aggregate each value by field value and the corresponding number of data rows
- CountNotIn: the enumerated value does not match the number of rows.
- CountDistinctNotIn: the number of unique values that the enumerated values do not match.
- UserDefinedSql: use custom SQL to collect samples.', example='Max'),
      metricParameters?: string(name='MetricParameters', description='Parameters required for sample collection.', example='{"SQL": "select count(1) from table;"}'),
      settingConfig?: string(name='SettingConfig', description='Before executing the sample statement, insert some runtime parameter setting statements, which can be up to 1000 characters in length. Currently, only MaxCompute is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;'),
    }(name='SamplingConfig', description='The settings required for sample collection.'),
    visibleScope?: string(name='VisibleScope', description='Available range of templates:
- Tenant: all tenants are available
- Project: only available in the current Project', example='Project'),
  }(name='DataQualityRuleTemplate', description='The information about the template.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model GetDataQualityRuleTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataQualityRuleTemplateResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetDataQualityRuleTemplate  GetDataQualityRuleTemplateRequest
  * @return GetDataQualityRuleTemplateResponse
 */
async function getDataQualityRuleTemplate(request: GetDataQualityRuleTemplateRequest): GetDataQualityRuleTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataQualityRuleTemplate', 'GET', '/', 'json', false, 'json', request);
}

model GetDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The data source ID.

This parameter is required.', example='16035', position='Query'),
}

model GetDataSourceResponseBody = {
  dataSource?: {
    connectionProperties?: any(name='ConnectionProperties', description='The connection configurations of the data source, including the connection address, access identity, and environment information. The envType parameter specifies the environment in which the data source is used. Valid values of the envType parameter:

*   Dev: development environment
*   Prod: production environment

The parameters that you need to configure for the data source vary based on the mode in which the data source is added. For more information, see [Data source connection information (ConnectionProperties)](https://help.aliyun.com/document_detail/2852465.html).', example='{
	"envType": "Prod",
	"regionId": "cn-beijing",
    "instanceId": "hgprecn-cn-x0r3oun4k001",
    "database": "testdb",
    "securityProtocol": "authTypeNone",
    "authType": "Executor",
    "authIdentity": "1107550004253538"
}'),
    connectionPropertiesMode?: string(name='ConnectionPropertiesMode', description='The mode in which the data source is added. The mode varies based on the data source type. Valid values:

*   InstanceMode: instance mode
*   UrlMode: connection string mode
*   CdhMode: CDH cluster mode', example='UrlMode'),
    createTime?: long(name='CreateTime', description='The time when the data source was added. This value is a UNIX timestamp.', example='1698286929333'),
    createUser?: string(name='CreateUser', description='The ID of the user who adds the data source.', example='1107550004253538'),
    description?: string(name='Description', description='The description of the data source.', example='test'),
    id?: long(name='Id', description='The data source ID.', example='16738'),
    modifyTime?: long(name='ModifyTime', description='The time when the data source was last modified. This value is a UNIX timestamp.', example='1698286929333'),
    modifyUser?: string(name='ModifyUser', description='The ID of the user who modifies the data source.', example='1107550004253538'),
    name?: string(name='Name', description='The name of the data source.', example='test'),
    projectId?: long(name='ProjectId', description='The ID of the workspace with which the data source is associated.', example='52660'),
    qualifiedName?: string(name='QualifiedName', description='The unique business key of the data source. For example, the unique business key of a Hologres data source is in the `${tenantOwnerId}:${regionId}:${type}:${instanceId}:${database}` format.', example='1107550004253538:cn-beijing:holo:hgprecn-cn-x0r3oun4k001:testdb'),
    type?: string(name='Type', description='The type of the data source.', example='hologres'),
  }(name='DataSource', description='The information about the data source.'),
  requestId?: string(name='RequestId', description='The request ID.', example='9252F32F-D855-549E-8898-61CF5A733050'),
}

model GetDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Deployment, Development, Project Owner, and O\\&M
  * @param request  the request parameters of GetDataSource  GetDataSourceRequest
  * @return GetDataSourceResponse
 */
async function getDataSource(request: GetDataSourceRequest): GetDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDataSource', 'GET', '/', 'json', false, 'json', request);
}

model GetDeploymentRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='The ID of the process.

This parameter is required.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Query'),
}

model GetDeploymentResponseBody = {
  pipeline?: {
    createTime?: long(name='CreateTime', description='The time when the process was created. This value is a UNIX timestamp.', example='1724984066000'),
    creator?: string(name='Creator', description='The creator of the process.', example='137946317766XXXX'),
    id?: string(name='Id', description='The ID of the process.', example='a7ef0634-20ec-4a7c-a214-54020f91XXXX'),
    message?: string(name='Message', description='The error message returned when the process fails.', example='Error message'),
    modifyTime?: long(name='ModifyTime', description='The time when the process was modified. This value is a UNIX timestamp.', example='1724984066000'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='56160'),
    stages?: [ 
      {
        code?: string(name='Code', description='The code of the stage.', example='DEV_CHECK'),
        description?: string(name='Description', description='The description of the stage.', example='Phase description'),
        detail?: map[string]any(name='Detail', description='The details of the stage.'),
        message?: string(name='Message', description='The error message returned for the stage.', example='Exception information XXX'),
        name?: string(name='Name', description='The name of the stage.', example='Publish package build'),
        status?: string(name='Status', description='The status of the stage.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='INIT'),
        step?: int32(name='Step', description='The step number of the stage.', example='1'),
        type?: string(name='Type', description='The type of the stage.

Valid values:

*   Deploy
*   Check
*   Offline
*   Build
*   Delete', example='BUILD'),
      }
    ](name='Stages', description='The information about stages in the process.'),
    status?: string(name='Status', description='The status of the process.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='RUNNING'),
  }(name='Pipeline', description='The information about the process.'),
  requestId?: string(name='RequestId', description='The request ID.', example='08468352-032C-5262-AEDC-68C9FA05XXXX'),
}

model GetDeploymentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDeploymentResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDeployment  GetDeploymentRequest
  * @return GetDeploymentResponse
 */
async function getDeployment(request: GetDeploymentRequest): GetDeploymentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDeployment', 'GET', '/', 'json', false, 'json', request);
}

model GetFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
}

model GetFunctionResponseBody = {
  function?: {
    createTime?: long(name='CreateTime', description='The time when the UDF was created. This value is a UNIX timestamp.', example='1724505917000'),
    id?: long(name='Id', description='The ID of the UDF.', example='860438872620113XXXX'),
    modifyTime?: long(name='ModifyTime', description='The time when the UDF was last modified. This value is a UNIX timestamp.', example='1724506661000'),
    name?: string(name='Name', description='The name of the UDF.', example='Function name'),
    owner?: string(name='Owner', description='The owner of the UDF.', example='110755000425XXXX'),
    projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace to which the UDF belongs.', example='10000'),
    spec?: string(name='Spec', description='The FlowSpec field information about the UDF. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).', example='{
    "version": "1.1.0",
    "kind": "Function",
    "spec": {
        "functions": [
            {
                "name": "Function_Name",
                "id": "580667964888595XXXX",
                "script": {
                    "content": "{  \\"uuid\\": \\"580667964888595XXXX\\",  \\"name\\": \\"Function_Name\\",  \\"datasource\\": {    \\"type\\": \\"odps\\",    \\"name\\": \\"odps_first\\"  },  \\"runtimeResource\\": {    \\"resourceGroup\\": \\"S_res_group_XXXX_XXXX\\",    \\"resourceGroupId\\": 6591XXXX  }}",
                    "path": "XXX/OpenAPI/Function/Function_Name",
                    "runtime": {
                        "command": "ODPS_FUNCTION"
                    }
                },
                "datasource": {
                    "name": "odps_first",
                    "type": "odps"
                },
                "runtimeResource": {
                    "resourceGroup": "S_res_group_XXXX_XXXX",
                    "id": "723932906364267XXXX",
                    "resourceGroupId": "6591XXXX"
                },
                "metadata": {
                    "owner": "110755000425XXXX"
                }
            }
        ]
    }
}'),
  }(name='Function', description='The information about the UDF.'),
  requestId?: string(name='RequestId', description='The request ID.', example='6CF95929-6D12-5A88-8CC3-4B2F4C2EXXXX'),
}

model GetFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetFunctionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetFunction  GetFunctionRequest
  * @return GetFunctionResponse
 */
async function getFunction(request: GetFunctionRequest): GetFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetFunction', 'GET', '/', 'json', false, 'json', request);
}

model GetJobStatusRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  jobId: string(name='JobId', description='The ID of the asynchronous task that is generated after you call an asynchronous operation.

This parameter is required.', example='70ecdaec-bf21-4c11-8ecb-4f77453ceea8', position='Query'),
}

model GetJobStatusResponseBody = {
  jobStatus?: {
    completed?: string(name='Completed', description='Indicates whether the asynchronous task is complete. Valid values: True False', example='False'),
    createTime?: string(name='CreateTime', description='The time when the asynchronous task was created.', example='1729063449802'),
    error?: string(name='Error', description='The error message returned if the asynchronous task fails.', example='Not Found'),
    jobId?: string(name='JobId', description='The ID of the asynchronous task.', example='C664CDE3-9C0B-5792-B17F-6C543783BBBC'),
    jobType?: string(name='JobType', description='The type of the asynchronous task. Valid values:

*   **Create**: The asynchronous task is used to create an object.
*   **Update**: The asynchronous task is used to update an object.
*   **Cancel**: The asynchronous task is used to cancel an operation.', example='Create'),
    status?: string(name='Status', description='The status of the asynchronous task. Valid values:

*   **Success**
*   **Fail**
*   **Cancel**
*   **Running**', example='Success'),
  }(name='JobStatus', description='The real-time status information of the asynchronous task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='5E2BFE96-C0E0-5A98-85C8-633EC803198D'),
}

model GetJobStatusResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetJobStatusResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetJobStatus  GetJobStatusRequest
  * @return GetJobStatusResponse
 */
async function getJobStatus(request: GetJobStatusRequest): GetJobStatusResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetJobStatus', 'GET', '/', 'json', false, 'json', request);
}

model GetNetworkRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the network resource.

This parameter is required.', example='1000', position='Query'),
}

model GetNetworkResponseBody = {
  network?: {
    createTime?: long(name='CreateTime', description='The creation time, which is a 64-bit timestamp.', example='1727055811000'),
    createUser?: string(name='CreateUser', description='The ID of the user who created the network resource.', example='11075500042XXXXX'),
    id?: long(name='Id', description='The ID of the network resource.', example='1000'),
    resourceGroupId?: string(name='ResourceGroupId', description='The unique identifier of the common resource group to which it belongs.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
    securityGroupId?: string(name='SecurityGroupId', description='The ID of the security group for the network resource.', example='sg-2ze13vamugr7jenXXXXX'),
    status?: string(name='Status', description='The status of the network resource. Valid values:

*   Pending: The network resource is waiting to be created.
*   Creating: The network resource is being created.
*   Running: The network resource is running as expected.
*   Deleting: The network resource is being deleted.
*   Deleted: The network resource is deleted.', example='Running'),
    vpcId?: string(name='VpcId', description='The VPC ID of the network resource.', example='vpc-m2et4f3oc8msfbccXXXXX'),
    vswitchId?: string(name='VswitchId', description='The switch ID of the network resource.', example='vsw-uf8usrhs7hjd9amsXXXXX'),
  }(name='Network', description='The information about the network resource.'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetNetworkResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetNetworkResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetNetwork  GetNetworkRequest
  * @return GetNetworkResponse
 */
async function getNetwork(request: GetNetworkRequest): GetNetworkResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetNetwork', 'GET', '/', 'json', false, 'json', request);
}

model GetNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the workspace ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
}

model GetNodeResponseBody = {
  node?: {
    createTime?: long(name='CreateTime', description='The time when the node was created. This value is a UNIX timestamp.', example='1700539206000'),
    id?: long(name='Id', description='The ID of the node.', example='860438872620113XXXX'),
    modifyTime?: long(name='ModifyTime', description='The time when the node was last modified. This value is a UNIX timestamp.', example='1700539206000'),
    name?: string(name='Name', description='The name of the node.', example='Node name'),
    owner?: string(name='Owner', description='The owner of the node.', example='196596664824XXXX'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10000'),
    spec?: string(name='Spec', description='The FlowSpec field information about this node. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow).', example='{
    "version": "1.1.0",
    "kind": "Node",
    "spec": {
        "nodes": [
            {
                "recurrence": "Normal",
                "id": "860438872620113XXXX",
                "timeout": 0,
                "instanceMode": "T+1",
                "rerunMode": "Allowed",
                "rerunTimes": 3,
                "rerunInterval": 180000,
                "datasource": {
                    "name": "odps_test",
                    "type": "odps"
                },
                "script": {
                    "language": "odps-sql",
                    "path": "XX/OpenAPI_Test/ODPS_SQL_Test",
                    "runtime": {
                        "command": "ODPS_SQL",
                        "commandTypeId": 10
                    },
                    "content": "select now();",
                    "id": "853573334108680XXXX"
                },
                "trigger": {
                    "type": "Scheduler",
                    "id": "543680677872062XXXX",
                    "cron": "00 00 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "runtimeResource": {
                    "resourceGroup": "S_res_group_XXXX_XXXX",
                    "id": "623731286945488XXXX",
                    "resourceGroupId": "7201XXXX"
                },
                "name": "ODPS_SQL_Test",
                "owner": "110755000425XXXX",
                "metadata": {
                    "owner": "110755000425XXXX",
                    "ownerName": "XXXXX@test.XXX.com",
                    "projectId": "307XXX"
                },
                "inputs": {
                    "nodeOutputs": [
                        {
                            "data": "lwttest_standard_root",
                            "artifactType": "NodeOutput"
                        }
                    ]
                },
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "860438872620113XXXX",
                            "artifactType": "NodeOutput",
                            "refTableName": "ODPS_SQL_Test",
                            "isDefault": true
                        }
                    ]
                }
            }
        ],
        "flow": [
            {
                "nodeId": "860438872620113XXXX",
                "depends": [
                    {
                        "type": "Normal",
                        "output": "lwttest_standard_root"
                    }
                ]
            }
        ]
    },
    "metadata": {
        "uuid": "860438872620113XXXX"
    }
}'),
  }(name='Node', description='The information about the node.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model GetNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetNodeResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetNode  GetNodeRequest
  * @return GetNodeResponse
 */
async function getNode(request: GetNodeRequest): GetNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetNode', 'GET', '/', 'json', false, 'json', request);
}

model GetProjectRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='123456', position='Query'),
}

model GetProjectResponseBody = {
  project?: {
    aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group to which the workspace belongs.', example='rg-acfmzbn7pti3zfa'),
    aliyunResourceTags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='batch'),
        value?: string(name='Value', description='The tag value.', example='blue'),
      }
    ](name='AliyunResourceTags', description='The tags.'),
    description?: string(name='Description', description='The description of the workspace.', example='Financial analysis group project data development'),
    devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Indicates whether the development environment is enabled. Valid values:

*   true: The development environment is enabled. In this case, the development environment is isolated from the production environment in the workspace.
*   false: The development environment is disabled. In this case, only the production environment is used in the workspace.', example='true'),
    devRoleDisabled?: boolean(name='DevRoleDisabled', description='Indicates whether the Develop role is disabled. Valid values:

*   false
*   true', example='false'),
    displayName?: string(name='DisplayName', description='The display name of the workspace.', example='Sora financial analysis'),
    id?: long(name='Id', description='The workspace ID.', example='28477242'),
    name?: string(name='Name', description='The name of the workspace.', example='sora_finance'),
    owner?: string(name='Owner', description='The ID of the Alibaba Cloud account to which the workspace belongs.', example='207947397706614299'),
    paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Indicates whether scheduling of PAI tasks is enabled. Valid values:

*   true: Scheduling of PAI tasks is enabled. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: Scheduling of PAI tasks is disabled.', example='true'),
    status?: string(name='Status', description='The status of the workspace. Valid values:

*   Available
*   Initializing
*   InitFailed
*   Forbidden
*   Deleting
*   DeleteFailed
*   Frozen
*   Updating
*   UpdateFailed', example='Available'),
  }(name='Project', description='The information about the workspace.'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model GetProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetProjectResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetProject  GetProjectRequest
  * @return GetProjectResponse
 */
async function getProject(request: GetProjectRequest): GetProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetProject', 'GET', '/', 'json', false, 'json', request);
}

model GetProjectMemberRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='88757', position='Body'),
  userId: string(name='UserId', description='The ID of the account used by the member. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the Tenant Members and Roles page, view the IDs of the accounts used by the members in the workspace.

This parameter is required.', example='123422344899', position='Body'),
}

model GetProjectMemberResponseBody = {
  projectMember?: {
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='88757'),
    roles?: [ 
      {
        code?: string(name='Code', description='The code of the role. Valid values:

*   role_project_admin: Workspace Administrator
*   role_project_dev: Develop
*   role_project_dg_admin: Data Governance Administrator
*   role_project_guest: Visitor
*   role_project_security: Security Administrator
*   role_project_deploy: Deploy
*   role_project_owner: Workspace Owner
*   role_project_data_analyst: Data Analyst
*   role_project_pe: O\\&M
*   role_project_erd: Model Designer', example='role_project_guest'),
        name?: string(name='Name', description='The name of the role.', example='Visitors'),
        type?: string(name='Type', description='The type of the role. Valid values:

*   UserCustom: custom role
*   System: built-in role', example='System'),
      }
    ](name='Roles', description='The roles that are assigned to the member in the workspace.'),
    status?: string(name='Status', description='The status of the member.

*   Normal
*   Forbidden', example='Normal'),
    userId?: string(name='UserId', description='The ID of the account used by the member in the workspace.', example='123422344899'),
  }(name='ProjectMember', description='The details about the member in the workspace.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
}

model GetProjectMemberResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetProjectMemberResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetProjectMember  GetProjectMemberRequest
  * @return GetProjectMemberResponse
 */
async function getProjectMember(request: GetProjectMemberRequest): GetProjectMemberResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetProjectMember', 'POST', '/', 'json', true, 'form', request);
}

model GetProjectRoleRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  code: string(name='Code', description='The code of the role in the DataWorks workspace. Valid values:

*   role_project_admin: workspace administrator
*   role_project_dev: developer
*   role_project_dg_admin: data governance administrator
*   role_project_guest: visitor
*   role_project_security: security administrator
*   role_project_deploy: deployer
*   role_project_owner: workspace owner
*   role_project_data_analyst: data analyst
*   role_project_pe: O\\&M engineer
*   role_project_erd: model designer

This parameter is required.', example='role_project_guest', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10002', position='Query'),
}

model GetProjectRoleResponseBody = {
  projectRole?: {
    code?: string(name='Code', description='The code of the role in the DataWorks workspace.', example='role_project_guest'),
    name?: string(name='Name', description='The name of the role in the DataWorks workspace.', example='Visitors'),
    projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10002'),
    type?: string(name='Type', description='The type of the role in the DataWorks workspace.

*   UserCustom: user-defined role
*   System: system role', example='System'),
  }(name='ProjectRole', description='The role in the DataWorks workspace.'),
  requestId?: string(name='RequestId', description='The request ID.', example='82F28E60-CF48-5EDF-AB25-D806847B97D1'),
}

model GetProjectRoleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetProjectRoleResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetProjectRole  GetProjectRoleRequest
  * @return GetProjectRoleResponse
 */
async function getProjectRole(request: GetProjectRoleRequest): GetProjectRoleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetProjectRole', 'POST', '/', 'json', false, 'json', request);
}

model GetResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the file resource.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
}

model GetResourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='E871F6C0-2EFF-5790-A00D-C57543EEXXXX'),
  resource?: {
    createTime?: long(name='CreateTime', description='The time when the file resource was created. This value is a UNIX timestamp.', example='1700539206000'),
    id?: long(name='Id', description='The ID of the file resource.', example='860438872620113XXXX'),
    modifyTime?: long(name='ModifyTime', description='The time when the file resource was last modified. This value is a UNIX timestamp.', example='1700539206000'),
    name?: string(name='Name', description='The name of the file resource.', example='OpenAPI_Test_Resource. py'),
    owner?: string(name='Owner', description='The owner of the file resource.', example='110755000425XXXX'),
    projectId?: long(name='ProjectId', description='The ID of the workspace to which the file resource belongs.', example='10000'),
    spec?: string(name='Spec', description='The FlowSpec field information about the file resource. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow).', example='{
    "version": "1.1.0",
    "kind": "Resource",
    "spec": {
        "fileResources": [
            {
                "name": "OpenAPI_Test_Resource.py",
                "id": "631478864897630XXXX",
                "script": {
                    "content": "",
                    "path": "XX/OpenAPI_Test/Resource_Test/OpenAPI_Test_Resource.py",
                    "runtime": {
                        "command": "ODPS_PYTHON"
                    }
                },
                "type": "python",
                "file": {
                    "storage": {}
                },
                "datasource": {
                    "name": "odps_first",
                    "type": "odps"
                },
                "metadata": {
                    "owner": "110755000425XXXX"
                }
            }
        ]
    }
}'),
  }(name='Resource', description='The information about the file resource.'),
}

model GetResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetResource  GetResourceRequest
  * @return GetResourceResponse
 */
async function getResource(request: GetResourceRequest): GetResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetResource', 'GET', '/', 'json', false, 'json', request);
}

model GetResourceGroupRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: string(name='Id', description='Unique identifier of a common resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Query'),
}

model GetResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  resourceGroup?: {
    aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group.', example='rg-aek2kqofrgXXXXX'),
    aliyunResourceTags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='key'),
        value?: string(name='Value', description='The tag value.', example='value'),
      }
    ](name='AliyunResourceTags', description='The tags.'),
    createTime?: long(name='CreateTime', description='The creation time, which is a 64-bit timestamp.', example='1727055811000'),
    createUser?: string(name='CreateUser', description='The ID of the user who created the resource group.', example='11075500042XXXXX'),
    defaultVpcId?: string(name='DefaultVpcId', description='The default VPC ID bound to the common resource group.', example='vpc-m2et4f3oc8msfbccXXXXX'),
    defaultVswitchId?: string(name='DefaultVswitchId', description='The default switch ID bound to the common resource group.', example='vsw-uf8usrhs7hjd9amsXXXXX'),
    id?: string(name='Id', description='The unique identifier of the resource group.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
    name?: string(name='Name', description='The name of the resource group.', example='common_resource_group'),
    orderInstanceId?: string(name='OrderInstanceId', description='The ID of the order instance of the resource group.', example='c442b330-3b10-4584-959e-736e4edXXXXX'),
    paymentType?: string(name='PaymentType', description='The billing method of the resource group. Valid values: PrePaid and PostPaid. The value PrePaid indicates the subscription billing method, and the value PostPaid indicates the pay-as-you-go billing method.', example='PrePaid'),
    remark?: string(name='Remark', description='The description of the resource group.', example='Create a common resource group for common tasks'),
    resourceGroupType?: string(name='ResourceGroupType', description='The type of the resource group. Valid values:

*   CommonV2: serverless resource group
*   ExclusiveDataIntegration: exclusive resource group for Data Integration
*   ExclusiveScheduler: exclusive resource group for scheduling
*   ExclusiveDataService: exclusive resource group for DataService Studio', example='CommonV2'),
    spec?: {
      amount?: int32(name='Amount', description='The number of resources in the resource group.', example='1'),
      standard?: string(name='Standard', description='Specification details.', example='2CU'),
    }(name='Spec', description='The specifications of the resource group.'),
    status?: string(name='Status', description='The status of the resource group. Valid values:

*   Normal: The resource group is running or in use.
*   Stop: The resource group is expired.
*   Deleted: The resource group is released or destroyed.
*   Creating: The resource group is being started.
*   CreateFailed: The resource group fails to be started.
*   Updating: The resource group is being scaled in or out, or the configurations of the resource group are being changed.
*   UpdateFailed: The resource group fails to be scaled out or upgraded.
*   Deleting: The resource group is being released or destroyed.
*   DeleteFailed: The resource group fails to be released or destroyed.
*   Timeout: The operations that are performed on the resource group time out.', example='Normal'),
  }(name='ResourceGroup', description='The details about the resource group.'),
  success?: boolean(name='Success', description='Whether the request is successful.', example='true'),
}

model GetResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetResourceGroupResponseBody(name='body'),
}

/**
  * @description You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * @param request  the request parameters of GetResourceGroup  GetResourceGroupRequest
  * @return GetResourceGroupResponse
 */
async function getResourceGroup(request: GetResourceGroupRequest): GetResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetResourceGroup', 'GET', '/', 'json', false, 'json', request);
}

model GetRouteRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the route.

This parameter is required.', example='1000', position='Query'),
}

model GetRouteResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  route?: {
    createTime?: long(name='CreateTime', description='The creation time, which is a 64-bit timestamp.', example='1727055811000'),
    destinationCidr?: string(name='DestinationCidr', description='The destination route CIDR.', example='192.168.0.0/16'),
    id?: long(name='Id', description='The ID of the route.', example='1000'),
    networkId?: long(name='NetworkId', description='The network ID.', example='1000'),
    resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
    resourceId?: string(name='ResourceId', description='The unique identifier of the network resource to which it belongs.', example='ns-679XXXXX'),
  }(name='Route', description='The information about the route.'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model GetRouteResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetRouteResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetRoute  GetRouteRequest
  * @return GetRouteResponse
 */
async function getRoute(request: GetRouteRequest): GetRouteResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetRoute', 'GET', '/', 'json', false, 'json', request);
}

model GetTaskRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model GetTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  task?: {
    baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
    createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
    createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
    dataSource?: {
      name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
    }(name='DataSource', description='The information about the associated data source.'),
    dependencies?: [ 
      {
        type?: string(name='Type', description='The dependency type. Valid values:

*   CrossCycleDependsOnChildren: cross-cycle dependency on level-1 descendant nodes
*   CrossCycleDependsOnSelf: cross-cycle dependency on the current node
*   CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
*   Normal: same-cycle scheduling dependency', example='Normal'),
        upstreamOutput?: string(name='UpstreamOutput', description='The output identifier of the upstream task. (This field is returned when `same cycle dependence` and input content is set).', example='pre.odps_sql_demo_0'),
        upstreamTaskId?: string(name='UpstreamTaskId', description='The Id of the upstream task. (This field is returned when the input content is not set for `cross-cycle dependency other nodes` and `same-cycle dependency`, otherwise it is not returned).', example='1234'),
      }
    ](name='Dependencies', description='The dependency information.'),
    description?: string(name='Description', description='The description of the task.', example='test'),
    envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
    id?: long(name='Id', description='The instance ID.', example='1234'),
    inputs?: {
      variables?: [ 
        {
          name?: string(name='Name', description='The name of the variable.', example='key1'),
          type?: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output', example='Constant'),
          value?: string(name='Value', description='The value of the variable.', example='Value1'),
        }
      ](name='Variables', description='The variables.'),
    }(name='Inputs', description='The input information.'),
    instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
    modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
    modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
    name?: string(name='Name', description='The name of the task.', example='SQL node'),
    outputs?: {
      taskOutputs?: [ 
        {
          output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
        }
      ](name='TaskOutputs', description='The task outputs.'),
      variables?: [ 
        {
          name?: string(name='Name', description='The name of the variable.', example='key1'),
          type?: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output', example='Constant'),
          value?: string(name='Value', description='The value of the variable.', example='value1'),
        }
      ](name='Variables', description='The variables.'),
    }(name='Outputs', description='The output information.'),
    owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
    priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
    projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', deprecated='true'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
    rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
    rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to be run.
*   FailureAllowed: The task can be rerun only after it fails to be run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to be run.', example='AllAllowed'),
    rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
    runtimeResource?: {
      cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
      image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
      resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
    }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
    script?: {
      content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
      parameters?: string(name='Parameters', description='The script parameters.', example='para1=$bizdate'),
    }(name='Script', description='The script information.'),
    subTasks?: {
      subTasks?: [ 
        {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='The baseline ID.'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description of the task.', example='test'),
          envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
          id?: long(name='Id', description='The task ID.', example='1234'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          name?: string(name='Name', description='The name of the task.', example='SQL node'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
          projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', deprecated='true'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='180'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to be run.
*   FailureAllowed: The task can be rerun only after it fails to be run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to be run.', example='AllAllowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of CUs configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The runtime environment configuration of the task, such as the resource group.'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
          trigger?: {
            cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
            endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
            recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
            startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
            type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: periodic scheduling
*   Manual: manual scheduling', example='Scheduler'),
          }(name='Trigger', description='The method to trigger task scheduling.'),
          type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
        }
      ](name='SubTasks', description='The subtasks.'),
      type?: string(name='Type', description='The type of the subtask. Valid values:

*   DoWhile: do-while node
*   Combined: node group
*   ForEach: for-each node', example='Combined'),
    }(name='SubTasks', description='The configurations of the subtasks, such as a do-while node.'),
    tags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='key1'),
        value?: string(name='Value', description='The tag value.', example='value1'),
      }
    ](name='Tags', description='The tags.'),
    timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
    trigger?: {
      cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
      endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
      recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
      startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
      type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: periodic scheduling
*   Manual: manual scheduling', example='Scheduler'),
    }(name='Trigger', description='The method to trigger task scheduling.'),
    type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
    workflowId?: long(name='WorkflowId', description='The workflow ID.', example='1234'),
  }(name='Task', description='The details of the task.'),
}

model GetTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTask  GetTaskRequest
  * @return GetTaskResponse
 */
async function getTask(request: GetTaskRequest): GetTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTask', 'GET', '/', 'json', false, 'json', request);
}

model GetTaskInstanceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
}

model GetTaskInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  taskInstance?: {
    baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
    bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
    createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
    createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
    dataSource?: {
      name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
    }(name='DataSource', description='The information about the associated data source.'),
    description?: string(name='Description', description='The description.', example='test'),
    finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
    id?: long(name='Id', description='The instance ID.', example='1234'),
    inputs?: {
      variables?: [ 
        {
          name?: string(name='Name', description='The name of the variable.', example='Key1'),
          type?: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output', example='Constant'),
          value?: string(name='Value', description='The value of the variable.', example='Value1'),
        }
      ](name='Variables', description='The variables.'),
    }(name='Inputs', description='The input information.'),
    modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
    modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
    outputs?: {
      taskOutputs?: [ 
        {
          output?: string(name='Output', description='The output identifier.', example='pre.odps_sql_demo_0'),
        }
      ](name='TaskOutputs', description='The task outputs.'),
      variables?: [ 
        {
          name?: string(name='Name', description='The name of the variable.', example='key1'),
          type?: string(name='Type', description='The type. Valid values:

*   Constant: constant
*   PassThrough: node output
*   System: variable
*   NodeOutput: script output', example='Constant'),
          value?: string(name='Value', description='The value of the variable.', example='value1'),
        }
      ](name='Variables', description='The variables.'),
    }(name='Outputs', description='The output information.'),
    owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
    periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
    priority?: int32(name='Priority', description='The task priority. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
    projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
    rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.', example='AllAllowed'),
    runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
    runtime?: {
      gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
      processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
    }(name='Runtime', description='The runtime information about the instance.'),
    runtimeResource?: {
      cu?: string(name='Cu', description='The default number of CUs configured for task running.', example='0.25'),
      image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
      resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
    }(name='RuntimeResource', description='The information about the resource group with which the instance is associated.'),
    script?: {
      content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
      parameters?: string(name='Parameters', description='The script parameters.', example='para1=$bizdate'),
    }(name='Script', description='The script information.'),
    startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
    status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
    tags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='key1'),
        value?: string(name='Value', description='The tag value.', example='value1'),
      }
    ](name='Tags', description='The tags of the task.'),
    taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
    taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
    taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
    timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='1'),
    triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
    triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
    triggerType?: string(name='TriggerType', description='The method to trigger instance scheduling. The value of the Trigger.Type parameter in the response of the GetTask operation is used. Valid values:

*   Scheduler
*   Manual', example='Scheduler'),
    workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
    workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
    workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   SmokeTest
*   SupplementData
*   Manual
*   ManualWorkflow
*   Normal
*   ManualFlow', example='Normal'),
    workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
  }(name='TaskInstance', description='The details of the instance.'),
}

model GetTaskInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTaskInstanceResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetTaskInstance  GetTaskInstanceRequest
  * @return GetTaskInstanceResponse
 */
async function getTaskInstance(request: GetTaskInstanceRequest): GetTaskInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTaskInstance', 'GET', '/', 'json', false, 'json', request);
}

model GetTaskInstanceLogRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  runNumber?: int32(name='RunNumber', description='The sequence number of an instance run. Minimum value: 1. By default, the latest run is used.', example='1', position='Query'),
}

model GetTaskInstanceLogResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  taskInstanceLog?: string(name='TaskInstanceLog', description='The run log of the instance.', example='This is running log'),
}

model GetTaskInstanceLogResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTaskInstanceLogResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetTaskInstanceLog  GetTaskInstanceLogRequest
  * @return GetTaskInstanceLogResponse
 */
async function getTaskInstanceLog(request: GetTaskInstanceLogRequest): GetTaskInstanceLogResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetTaskInstanceLog', 'GET', '/', 'json', false, 'json', request);
}

model GetWorkflowRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
  id: long(name='Id', description='The workflow ID.

This parameter is required.', example='1234', position='Query'),
}

model GetWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  workflow?: {
    clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a workflow asynchronously and implement the idempotence of the workflow. If you do not specify this parameter when you create the workflow, the system automatically generates a unique code. The unique code is uniquely associated with the workflow ID. If you specify this parameter when you update or delete the workflow, the value of this parameter must be the unique code that is used to create the workflow.', example='Workflow_0bc5213917368545132902xxxxxxxx'),
    createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
    createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
    dependencies?: [ 
      {
        type?: string(name='Type', description='The scheduling dependency type. Valid values:

*   CrossCycleDependsOnChildren: cross-cycle dependency on the level-1 descendant nodes of a node
*   CrossCycleDependsOnSelf: cross-cycle dependency on the current node
*   CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
*   Normal: same-cycle scheduling dependency', example='Normal'),
        upstreamOutput?: string(name='UpstreamOutput', description='The identifier of the output of the ancestor task. This parameter is returned only if `same-cycle scheduling dependencies` and the node input are configured.', example='pre.odps_sql_demo_0'),
        upstreamTaskId?: long(name='UpstreamTaskId', description='The ancestor task ID. This parameter is returned only if `cross-cycle scheduling dependencies` or `same-cycle scheduling dependencies` and the node input are not configured.', example='1234'),
      }
    ](name='Dependencies', description='The dependency information.'),
    description?: string(name='Description', description='The description of the workflow.', example='Test workflow'),
    envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
    id?: long(name='Id', description='The workflow ID.', example='1234'),
    modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
    modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
    name?: string(name='Name', description='The name of the workflow.', example='Workflow'),
    outputs?: {
      taskOutputs?: [ 
        {
          output?: string(name='Output', description='The identifier of the output.', example='pre.odps_sql_demo_0'),
        }
      ](name='TaskOutputs', description='The task outputs.'),
    }(name='Outputs', description='The output information.'),
    owner?: string(name='Owner', description='The account ID of the workflow owner.', example='1000'),
    parameters?: string(name='Parameters', description='The parameters.', example='para1=$bizdate para2=$[yyyymmdd]'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
    tags?: [ 
      {
        key?: string(name='Key', description='The tag key.', example='key1'),
        value?: string(name='Value', description='The tag value.', example='value1'),
      }
    ](name='Tags', description='The tags.'),
    tasks?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a task asynchronously and implement the idempotence of the task. If you do not specify this parameter when you create the task, the system automatically generates a unique code. The unique code is uniquely associated with the task ID. If you specify this parameter when you update or delete the task, the value of this parameter must be the unique code that is used to create the task.', example='Task_0bc5213917368545132902xxxxxxxx'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description of the task.', example='Test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
        id?: long(name='Id', description='The task ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name of the task.', example='SQL node'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
        rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.', example='AllAllowed'),
        rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
        triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the task after it is triggered. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
      }
    ](name='Tasks', description='The tasks.'),
    trigger?: {
      cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
      endTime?: string(name='EndTime', description='The end time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
      recurrence?: string(name='Recurrence', description='The running mode of the workflow after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
      startTime?: string(name='StartTime', description='The start time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
      type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
    }(name='Trigger', description='The trigger method.'),
  }(name='Workflow', description='The infromation about the workflow.'),
}

model GetWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkflowResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetWorkflow  GetWorkflowRequest
  * @return GetWorkflowResponse
 */
async function getWorkflow(request: GetWorkflowRequest): GetWorkflowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetWorkflow', 'GET', '/', 'json', false, 'json', request);
}

model GetWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.', example='10000', position='Query'),
}

model GetWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='F2BDD628-8A21-5BD1-B930-1A2D5989XXXX'),
  workflowDefinition?: {
    createTime?: long(name='CreateTime', description='The time when the workflow was created. This value is a UNIX timestamp.', example='1708481905000'),
    id?: long(name='Id', description='The ID of the workflow.', example='463497880880954XXXX'),
    modifyTime?: long(name='ModifyTime', description='The time when the workflow was last modified. This value is a UNIX timestamp.', example='1708481905000'),
    name?: string(name='Name', description='The name of the workflow.', example='OpenAPI test workflow Demo'),
    owner?: string(name='Owner', description='The owner of the workflow.', example='110755000425XXXX'),
    projectId?: long(name='ProjectId', description='The ID of the workspace to which the workflow belongs.', example='307XXX'),
    spec?: string(name='Spec', description='The FlowSpec field information about the workflow. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow/).', example='{
    "metadata": {
        "tenantId": "52425742456XXXX",
        "projectId": "307XXXX",
        "uuid": "463497880880954XXXX"
    },
    "kind": "CycleWorkflow",
    "version": "1.1.0",
    "spec": {
        "name": "OpenAPI_Test_Workflow_Demo",
        "id": "463497880880954XXXX",
        "type": "CycleWorkflow",
        "owner": "110755000425XXXX",
        "workflows": [
            {
                "script": {
                    "path": "XX/OpenAPI_Test/Workflow_Test/OpenAPI_Test_Workflow_Demo",
                    "runtime": {
                        "command": "WORKFLOW"
                    },
                    "id": "698002781368644XXXX"
                },
                "id": "463497880880954XXXX",
                "trigger": {
                    "type": "Scheduler",
                    "id": "652567824470354XXXX",
                    "cron": "00 02 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "strategy": {
                    "timeout": 0,
                    "instanceMode": "T+1",
                    "rerunMode": "Allowed",
                    "rerunTimes": 3,
                    "rerunInterval": 180000,
                    "failureStrategy": "Break"
                },
                "name": "OpenAPI_Test_Workflow_Demo",
                "owner": "110755000425XXXX",
                "metadata": {
                    "owner": "110755000425XXXX",
                    "ownerName": "XXXX@test.XXXX.com",
                    "tenantId": "52425742456XXXX",
                    "project": {
                        "mode": "STANDARD",
                        "projectId": "307303",
                        "projectIdentifier": "lwttest_standard",
                        "projectName": "XXXX",
                        "projectOwnerId": "110755000425XXXX",
                        "simple": false,
                        "tenantId": "52425742456XXXX"
                    },
                    "projectId": "307XXXX"
                },
                "inputs": {},
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "463497880880954XXXX",
                            "artifactType": "NodeOutput",
                            "refTableName": "OpenAPI_Test_Workflow_Demo",
                            "isDefault": true
                        }
                    ]
                },
                "nodes": [],
                "dependencies": []
            }
        ]
    }
}'),
  }(name='WorkflowDefinition', description='The information about the workflow.'),
}

model GetWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetWorkflowDefinition  GetWorkflowDefinitionRequest
  * @return GetWorkflowDefinitionResponse
 */
async function getWorkflowDefinition(request: GetWorkflowDefinitionRequest): GetWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetWorkflowDefinition', 'GET', '/', 'json', false, 'json', request);
}

model GetWorkflowInstanceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow instance.

This parameter is required.', example='1234', position='Query'),
}

model GetWorkflowInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  workflowInstance?: {
    bizDate?: long(name='BizDate', description='The business date.', example='1710239005403'),
    createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
    createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
    envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
    finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
    id?: long(name='Id', description='The ID of the workflow instance.', example='1234'),
    modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
    modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
    name?: string(name='Name', description='The name of the workflow instance.', example='WorkInstance1'),
    projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
    startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
    status?: string(name='Status', description='The status of the workflow instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
    type?: string(name='Type', description='The type of the workflow instance.', example='Normal'),
    workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
  }(name='WorkflowInstance', description='The information about the workflow instance.'),
}

model GetWorkflowInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWorkflowInstanceResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GetWorkflowInstance  GetWorkflowInstanceRequest
  * @return GetWorkflowInstanceResponse
 */
async function getWorkflowInstance(request: GetWorkflowInstanceRequest): GetWorkflowInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetWorkflowInstance', 'GET', '/', 'json', false, 'json', request);
}

model GrantMemberProjectRolesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='105149', position='Body'),
  roleCodes: [ string ](name='RoleCodes', description='The codes of the roles in the workspace. You can call the [ListProjectRoles](https://help.aliyun.com/document_detail/2853930.html) operation to query the codes of all roles in the workspace.

You must configure this parameter to specify the roles that you want to assign to members in the workspace.

This parameter is required.', shrink='json', position='Body'),
  userId: string(name='UserId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the Tenant Members and Roles page, view the IDs of the accounts used by the members in the workspace.

This parameter is required.', example='123422344899', position='Body'),
}

model GrantMemberProjectRolesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='2d9ced66-38ef-4923-baf6-391dd3a7e656'),
}

model GrantMemberProjectRolesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GrantMemberProjectRolesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of GrantMemberProjectRoles  GrantMemberProjectRolesRequest
  * @return GrantMemberProjectRolesResponse
 */
async function grantMemberProjectRoles(request: GrantMemberProjectRolesRequest): GrantMemberProjectRolesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GrantMemberProjectRoles', 'POST', '/', 'json', true, 'form', request);
}

model ImportWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='123456', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the workflow. For more information, see [FlowSpec](https://github.com/aliyun/alibabacloud-dataworks-tool-dflow/).

This parameter is required.', example='{
    "version": "1.1.0",
    "kind": "CycleWorkflow",
    "spec": {
        "name": "Asynchronous_Workflow_Creation_Test",
        "id": "632647691239009XXXX",
        "type": "CycleWorkflow",
        "workflows": [
            {
                "script": {
                    "path": "XX/OpenAPI_Test/Workflow_Test/Asynchronous_Workflow_Creation_Test",
                    "runtime": {
                        "command": "WORKFLOW"
                    }
                },
                "id": "632647691239009XXXX",
                "trigger": {
                    "type": "Scheduler",
                    "cron": "00 03 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "strategy": {
                    "timeout": 0,
                    "instanceMode": "T+1",
                    "rerunMode": "Allowed",
                    "rerunTimes": 3,
                    "rerunInterval": 180000,
                    "failureStrategy": "Break"
                },
                "name": "Asynchronous_Workflow_Creation_Test",
                "inputs": {},
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "632647691239009XXXX",
                            "artifactType": "NodeOutput",
                            "refTableName": "Asynchronous_Workflow_Creation_Test"
                        }
                    ]
                },
                "nodes": [
                    {
                        "recurrence": "Normal",
                        "id": "742981001612325XXXX",
                        "timeout": 0,
                        "instanceMode": "T+1",
                        "rerunMode": "Allowed",
                        "rerunTimes": 3,
                        "rerunInterval": 180000,
                        "script": {
                            "path": "XX/OpenAPI_Test/Workflow_Test/Asynchronous_Workflow_Creation_Test/111",
                            "runtime": {
                                "command": "ODPS_SQL"
                            },
                            "content": "select now();\\n"
                        },
                        "trigger": {
                            "type": "Scheduler",
                            "cron": "00 24 00 * * ?",
                            "startTime": "1970-01-01 00:00:00",
                            "endTime": "9999-01-01 00:00:00",
                            "timezone": "Asia/Shanghai",
                            "delaySeconds": 0
                        },
                        "name": "111",
                        "inputs": {},
                        "outputs": {
                            "nodeOutputs": [
                                {
                                    "data": "742981001612325XXXX",
                                    "artifactType": "NodeOutput",
                                    "refTableName": "111"
                                }
                            ]
                        }
                    },
                    {
                        "recurrence": "Normal",
                        "id": "595182137303408XXXX",
                        "timeout": 0,
                        "instanceMode": "T+1",
                        "rerunMode": "Allowed",
                        "rerunTimes": 3,
                        "rerunInterval": 180000,
                        "script": {
                            "path": "XX/OpenAPI_Test/Workflow_Test/Asynchronous_Workflow_Creation_Test/222",
                            "runtime": {
                                "command": "ODPS_SQL"
                            },
                            "content": "select now();\\n select 1;"
                        },
                        "trigger": {
                            "type": "Scheduler",
                            "cron": "00 00 00 * * ?",
                            "startTime": "1970-01-01 00:00:00",
                            "endTime": "9999-01-01 00:00:00",
                            "timezone": "Asia/Shanghai",
                            "delaySeconds": 0
                        },
                        "name": "222",
                        "inputs": {},
                        "outputs": {
                            "nodeOutputs": [
                                {
                                    "data": "595182137303408XXXX",
                                    "artifactType": "NodeOutput",
                                    "refTableName": "222"                                
                                }
                            ]
                        }
                    }
                ],
                "dependencies": [
                    {
                        "nodeId": "595182137303408XXXX",
                        "depends": [
                            {
                                "type": "Normal",
                                "output": "742981001612325XXXX",
                                "refTableName": "111"
                            }
                        ]
                    }
                ]
            }
        ]
    }
}', position='Body'),
}

model ImportWorkflowDefinitionResponseBody = {
  asyncJob?: {
    completed?: boolean(name='Completed', description='Indicates whether the asynchronous task is complete.', example='false'),
    createTime?: long(name='CreateTime', description='The time when the asynchronous task was created. This value is a UNIX timestamp.', example='1706581425000'),
    error?: string(name='Error', description='The error message returned if the asynchronous task fails.', example='target folder already exists: XXXX'),
    id?: string(name='Id', description='The ID of the asynchronous task.', example='1234567691239009XXXX'),
    progress?: int32(name='Progress', description='The progress of the asynchronous task. Valid values: 0 to 100.', example='0'),
    response?: string(name='Response', description='The response.

>  The workflow ID is returned.', example='632647691239009XXXX'),
    status?: string(name='Status', description='The status of the asynchronous task.

Valid values:

*   Running: The asynchronous task is running.
*   Success: The asynchronous task is complete.
*   Fail: The asynchronous task fails.
*   Cancel: The asynchronous task is canceled.', example='Running'),
    type?: string(name='Type', description='The type of the asynchronous task.

Valid values:

*   Create: The asynchronous task is used to create an object.
*   Cancel: The asynchronous task is used to cancel an operation.', example='Create'),
  }(name='AsyncJob', description='The status information of the asynchronous task.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7C352CB7-CD88-50CF-9D0D-E81BDF020E7F'),
}

model ImportWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ImportWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @description > 
  * *   You cannot use this API operation to import multiple workflows at a time. If you specify multiple workflows by using FlowSpec, the system imports only the first specified workflow.
  * *   ImportWorkflowDefinition is an asynchronous operation. After you send a request, an asynchronous task is generated, and the system returns the ID of the asynchronous task. You can call the GetJobStatus operation to query the status of the asynchronous task.
  * @param request  the request parameters of ImportWorkflowDefinition  ImportWorkflowDefinitionRequest
  * @return ImportWorkflowDefinitionResponse
 */
async function importWorkflowDefinition(request: ImportWorkflowDefinitionRequest): ImportWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ImportWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model ListAlertRulesRequest {
  regionId?: string(name='RegionId', position='Host'),
  name?: string(name='Name', description='The name of the rule.', example='error_rule', position='Query'),
  owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.', example='1933790683****', position='Query'),
  pageNumber: int32(name='PageNumber', description='The page number. Pages start from page 1.

This parameter is required.', example='1', minimum=1, position='Query'),
  pageSize: long(name='PageSize', description='The number of entries per page. Maximum value: 100.

This parameter is required.', example='10', maximum=100, position='Query'),
  receiver?: string(name='Receiver', description='The ID of the Alibaba Cloud account used by the alert recipient.', example='1933790683****', position='Query'),
  taskIds?: [ long ](name='TaskIds', description='The IDs of the scheduling tasks.', shrink='json', position='Query'),
  types?: [ string ](name='Types', description='The alert triggering condition.', shrink='json', position='Query'),
}

model ListAlertRulesResponseBody = {
  pagingInfo?: {
    alertRules?: [ 
      {
        enabled?: boolean(name='Enabled', description='Indicates whether the rule is enabled.', example='true'),
        id?: long(name='Id', description='The rule ID.', example='22125'),
        name?: string(name='Name', description='The name of the rule.', example='error_test'),
        owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.', example='1933790683****'),
        triggerCondition?: {
          extension?: {
            cycleUnfinished?: {
              cycleAndTime?: [ 
                {
                  cycleId?: int32(name='CycleId', description='The ID of the scheduling cycle of the instance. Valid values: [1,288].', example='1'),
                  time?: string(name='Time', description='The latest completion time of the instance within the scheduling cycle. The time is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='01:00'),
                }
              ](name='CycleAndTime', description='The configurations of the scheduling cycle and timeout period of the instance.'),
            }(name='CycleUnfinished', description='The configuration for an alert of the CycleUnfinished type.'),
            error?: {
              autoRerunAlertEnabled?: boolean(name='AutoRerunAlertEnabled', description='Indicates whether an alert is triggered if a batch synchronization task is automatically rerun upon a failure.', example='false'),
              streamTaskIds?: [ long ](name='StreamTaskIds', description='The IDs of the real-time computing tasks. This parameter is required when you monitor real-time computing tasks.'),
            }(name='Error', description='The configuration for an alert of the Error type.'),
            instanceErrorCount?: {
              count?: int32(name='Count', description='The maximum number of instances on which an error occurs. Valid values: [1,10000].', example='10'),
            }(name='InstanceErrorCount', description='The configuration for an alert of the InstanceErrorCount type.'),
            instanceErrorPercentage?: {
              percentage?: int32(name='Percentage', description='The maximum percentage of instances on which an error occurs in the workspace to the total number of instances. Valid values: [1-100].', example='10'),
            }(name='InstanceErrorPercentage', description='The configuration for an alert of the InstanceErrorPercentage type.'),
            instanceTransferFluctuate?: {
              percentage?: int32(name='Percentage', description='The maximum percentage of fluctuation in the number of auto triggered node instances that are generated in your workspace. Valid values: [1-100].', example='10'),
              trend?: string(name='Trend', description='The way in which the number of auto triggered node instances that are generated in your workspace fluctuates. Valid values:

*   abs: the absolute value. The number of instances increases or decreases.
*   increase: The number of instances increases.
*   decrease: The number of instances decreases.', example='abs'),
            }(name='InstanceTransferFluctuate', description='The configuration for an alert of the InstanceTransferFluctuate type.'),
            timeout?: {
              timeoutInMinutes?: int32(name='TimeoutInMinutes', description='The timeout period. Unit: minutes.', example='10'),
            }(name='Timeout', description='The configuration for an alert of the Timeout type.'),
            unFinished?: {
              unFinishedTime?: string(name='UnFinishedTime', description='The latest completion time of the instance. The period is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
            }(name='UnFinished', description='The configuration for an alert of the UnFinished type.'),
          }(name='Extension', description='The extended information about the rule. This parameter is required for specific types of alerts.'),
          target?: {
            allowTasks?: [ long ](name='AllowTasks', description='The nodes that are not to be monitored.'),
            ids?: [ long ](name='Ids', description='The IDs of monitored objects.'),
            type?: string(name='Type', description='The type of the monitored objects. Valid values:

*   Task: node
*   Baseline: baseline
*   Project: workspace
*   BizProcess: workflow', example='Task'),
          }(name='Target', description='The monitored objects.'),
          type?: string(name='Type', description='The alert type. Valid values:

*   Finished: An instance is successfully run.
*   UnFinished: An instance does not finish running before a specified point in time.
*   Error: An error occurs on an instance.
*   CycleUnfinished: An instance does not finish running as expected within a specific cycle.
*   Timeout: An instance times out.
*   InstanceTransferComplete: An instance is generated by the auto triggered node.
*   InstanceTransferFluctuate: The number of generated instances fluctuates.
*   ExhaustedError: An error persists after an instance is automatically rerun.
*   InstanceKeyword: An instance with errors contains specified keywords.
*   InstanceErrorCount: The number of instances on which an error occurs reaches a specified threshold.
*   InstanceErrorPercentage: The proportion of instances on which an error occurs in the workspace to the total number of instances reaches a specified threshold.
*   ResourceGroupPercentage: The usage rate of the resource group reaches a specified threshold.
*   ResourceGroupWaitCount: The number of instances that are waiting for resources in the resource group reaches a specified threshold.', example='Error'),
        }(name='TriggerCondition', description='The alert triggering condition.'),
      }
    ](name='AlertRules', description='The rules.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='5'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='A6C6B486-E3A2-5D52-9E76-D9380485D946'),
}

model ListAlertRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListAlertRulesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListAlertRules  ListAlertRulesRequest
  * @return ListAlertRulesResponse
 */
async function listAlertRules(request: ListAlertRulesRequest): ListAlertRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListAlertRules', 'POST', '/', 'json', false, 'json', request);
}

model ListDIAlarmRulesRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIAlarmRuleId?: long(name='DIAlarmRuleId', description='The ID of the alert rule. If you leave this parameter empty, all alert rules of the task are queried.', example='34988', position='Query'),
  jobId?: long(name='JobId', description='The ID of the task for which alert rules are configured.', example='1000001', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
}

model ListDIAlarmRulesResponseBody = {
  pagingInfo?: {
    DIJobAlarmRules?: [ 
      {
        DIAlarmRuleId?: long(name='DIAlarmRuleId', description='This parameter is deprecated. Use the Id parameter instead.', example='72402', deprecated='true'),
        DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='32594'),
        description?: string(name='Description', description='The description of the alert rule.', example='rule descrition'),
        enabled?: boolean(name='Enabled', description='Indicates whether the alert rule is enabled. Valid values: True and False.', example='True'),
        id?: long(name='Id', description='The ID of the alert rule.', example='72402'),
        metricType?: string(name='MetricType', description='The metric type in the alert rule. Valid values:

*   Heartbeat
*   FailoverCount
*   Delay
*   DdlReport
*   ResourceUtilization', example='Heartbeat'),
        name?: string(name='Name', description='The name of the alert rule.', example='rule_name'),
        notificationSettings?: {
          inhibitionInterval?: long(name='InhibitionInterval', description='This parameter is deprecated and replaced by the MuteInterval parameter.', example='5', deprecated='true'),
          muteInterval?: long(name='MuteInterval', description='The duration of the alert suppression interval. Unit: minutes.', example='5'),
          notificationChannels?: [ 
            {
              channels?: [ string ](name='Channels', description='The alert notification methods.'),
              severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Critical'),
            }
          ](name='NotificationChannels', description='The alert notification methods.'),
          notificationReceivers?: [ 
            {
              receiverType?: string(name='ReceiverType', description='The recipient type. Valid values: AliyunUid, DingToken, FeishuToken, and WebHookUrl.', example='DingToken'),
              receiverValues?: [ string ](name='ReceiverValues', description='The recipient.

*   If the value of the ReceiverType parameter is AliyunUid, the value of this parameter is the Alibaba Cloud account ID of a user.
*   If the value of the ReceiverType parameter is DingToken, the value of this parameter is the token of a DingTalk chatbot.'),
            }
          ](name='NotificationReceivers', description='The settings of alert notification recipients.'),
        }(name='NotificationSettings', description='The alert notification method and recipient settings.'),
        triggerConditions?: [ 
          {
            ddlReportTags?: [ string ](name='DdlReportTags', description='This parameter is deprecated and replaced by the DdlTypes parameter.', deprecated='true'),
            ddlTypes?: [ string ](name='DdlTypes', description='The types of DDL operations for which the alert rule takes effect. This parameter is returned only if the MetricType parameter is set to DdlReport.'),
            duration?: long(name='Duration', description='The time interval for alert calculation. Unit: minutes.', example='1'),
            severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Critical'),
            threshold?: long(name='Threshold', description='The alert threshold.

*   If the alert rule is for task status, no threshold is used.
*   If the alert rule is for failovers, the threshold is the number of failovers.
*   If the alert rule is for latency, the threshold is the latency duration, in seconds.', example='5'),
          }
        ](name='TriggerConditions', description='The conditions that are used to trigger the alert rule.'),
      }
    ](name='DIJobAlarmRules', description='The alert rules.'),
    pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='90'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='74C2FECD-5B3A-554A-BCF5-351A36DE9815'),
}

model ListDIAlarmRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIAlarmRulesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDIAlarmRules  ListDIAlarmRulesRequest
  * @return ListDIAlarmRulesResponse
 */
async function listDIAlarmRules(request: ListDIAlarmRulesRequest): ListDIAlarmRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIAlarmRules', 'GET', '/', 'json', false, 'json', request);
}

model ListDIJobEventsRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='11588', position='Query'),
  endTime: long(name='EndTime', description='The end of the time range to query.

This parameter is required.', example='1717971005', position='Query'),
  eventType: string(name='EventType', description='The type of event that you want to query. Valid values: Failover, Alarm, and DDL.

This parameter is required.', example='Alarm', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  startTime: long(name='StartTime', description='The beginning of the time range to query.

This parameter is required.', example='1716971005', position='Query'),
}

model ListDIJobEventsResponseBody = {
  pagingInfo?: {
    DIJobEvent?: [ 
      {
        action?: string(name='Action', description='The processing result of the DDL event. Valid values: Critical, Ignore, Normal, and Warning.', example='Ignore'),
        channels?: string(name='Channels', description='The alert notification method. Valid values: Phone, Mail, Sms, Ding, and Webhook.', example='Phone'),
        createTime?: string(name='CreateTime', description='The time when the event was created.', example='1663573162'),
        detail?: string(name='Detail', description='The alert details.', example='aggregator:avg [**] for 5 minutes, service maybe abnormal'),
        dstSql?: string(name='DstSql', description='The DDL statement of the destination table.', example='alter table table2 ***'),
        dstTable?: string(name='DstTable', description='The name of the destination table.', example='table2'),
        failoverMessage?: string(name='FailoverMessage', description='The error logs for failovers.', example='2024-05-29 15:11:31,377 [main] INFO com.*.**.di.core.metrics.:21 []  {****} 
2024-05-29 15:11:31,384 [main] INFO *.aliyun.*.di.*.*.metrics.*:27 [] - Open MarioDiReporter 
2024-05-29 15:11:33,248 [flink-akka.*.*-dispatcher-17] INFO'),
        id?: string(name='Id', description='The event ID.', example='1'),
        severity?: string(name='Severity', description='The severity level of the alert. Valid values: Warning and Critical.', example='Warning'),
        srcSql?: string(name='SrcSql', description='The DDL statement of the source table.', example='alter table table1 ***'),
        srcTable?: string(name='SrcTable', description='The name of the source table.', example='table1'),
        status?: string(name='Status', description='The sending status of an alert notification. Valid values: Success, Fail, and Silence.', example='Success'),
        type?: string(name='Type', description='The type of the alert event.

*   Heartbeat
*   Delay
*   FailoverCount
*   DdlReport
*   ResourceUtilization', example='Delay'),
      }
    ](name='DIJobEvent', description='The events returned. The value of this parameter is an array.'),
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='2524'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='645F6D68-9C29-5961-80B1-BDD4B794C22D'),
}

model ListDIJobEventsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIJobEventsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDIJobEvents  ListDIJobEventsRequest
  * @return ListDIJobEventsResponse
 */
async function listDIJobEvents(request: ListDIJobEventsRequest): ListDIJobEventsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIJobEvents', 'GET', '/', 'json', false, 'json', request);
}

model ListDIJobMetricsRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='11265', position='Query'),
  endTime: long(name='EndTime', description='The end of the time range to query.

This parameter is required.', example='1712205941', position='Query'),
  metricName: [ string ](name='MetricName', description='The metrics that you want to query.

This parameter is required.', shrink='json', position='Query'),
  startTime: long(name='StartTime', description='The beginning of the time range to query.

This parameter is required.', example='1586509407', position='Query'),
}

model ListDIJobMetricsResponseBody = {
  pagingInfo?: {
    jobMetrics?: [ 
      {
        name?: string(name='Name', description='The name of the metric.', example='JobDelay'),
        seriesList?: [ 
          {
            time?: long(name='Time', description='The point in time at which data is sampled based on the metric.', example='1716881141'),
            value?: double(name='Value', description='The sample value.', example='10'),
          }
        ](name='SeriesList', description='The metric data.'),
      }
    ](name='JobMetrics', description='The metrics returned.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='691CA452-D37A-4ED0-9441'),
}

model ListDIJobMetricsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIJobMetricsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDIJobMetrics  ListDIJobMetricsRequest
  * @return ListDIJobMetricsResponse
 */
async function listDIJobMetrics(request: ListDIJobMetricsRequest): ListDIJobMetricsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIJobMetrics', 'GET', '/', 'json', false, 'json', request);
}

model ListDIJobRunDetailsRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId: long(name='DIJobId', description='The ID of the synchronization task.

This parameter is required.', example='11265', position='Query'),
  instanceId?: long(name='InstanceId', description='The instance ID.', example='1234', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  sourceDataSourceName?: string(name='SourceDataSourceName', description='The name of the source.', example='ds_name', position='Query'),
  sourceDatabaseName?: string(name='SourceDatabaseName', description='The name of the database in the source.', example='db_name', position='Query'),
  sourceSchemaName?: string(name='SourceSchemaName', description='The name of the schema of the source.', example='schema_name', position='Query'),
  sourceTableName?: string(name='SourceTableName', description='The name of the table in the source.', example='table_name', position='Query'),
}

model ListDIJobRunDetailsResponseBody = {
  pagingInfo?: {
    jobRunInfos?: [ 
      {
        destinationDatabaseName?: string(name='DestinationDatabaseName', description='The name of the database in the destination.', example='dst_db'),
        destinationDatasourceName?: string(name='DestinationDatasourceName', description='The name of the destination.', example='dst_name'),
        destinationSchemaName?: string(name='DestinationSchemaName', description='The name of the schema of the destination.', example='dst_schema'),
        destinationTableName?: string(name='DestinationTableName', description='The name of the table in the destination.', example='dst_name'),
        fullMigrationErrorMessage?: string(name='FullMigrationErrorMessage', description='The error message that is returned if an error occurs during full batch synchronization. If no error occurs, no value is returned for this parameter.', example='sync table t1 fail.'),
        fullMigrationStatus?: string(name='FullMigrationStatus', description='The status of full batch synchronization.', example='Finished'),
        offlineErrorRecords?: long(name='OfflineErrorRecords', description='The total number of errors that occur during full synchronization.', example='0'),
        offlineTotalBytes?: long(name='OfflineTotalBytes', description='The total number of bytes that are synchronized during full synchronization.', example='100'),
        offlineTotalRecords?: long(name='OfflineTotalRecords', description='The total number of data records that are synchronized during full synchronization.', example='10'),
        realtimeMigrationErrorMessage?: string(name='RealtimeMigrationErrorMessage', description='The error message that is returned if an error occurs during real-time synchronization. If no error occurs, no value is returned for this parameter.', example='sync table t1 fail.'),
        realtimeMigrationStatus?: string(name='RealtimeMigrationStatus', description='The status of real-time synchronization.', example='Running'),
        sourceDatabaseName?: string(name='SourceDatabaseName', description='The name of the database in the source.', example='db_name'),
        sourceDatasourceName?: string(name='SourceDatasourceName', description='The name of the source.', example='ds_name'),
        sourceSchemaName?: string(name='SourceSchemaName', description='The name of the schema of the source.', example='schema_name'),
        sourceTableName?: string(name='SourceTableName', description='The name of the table in the source.', example='table_name'),
        structureMigrationErrorMessage?: string(name='StructureMigrationErrorMessage', description='The error message that is returned if an error occurs during schema synchronization. If no error occurs, no value is returned for this parameter.', example='create table t1 fail.'),
        structureMigrationStatus?: string(name='StructureMigrationStatus', description='The synchronization status of the schema.', example='Finished'),
      }
    ](name='JobRunInfos', description='The running information about the synchronization task.'),
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='131'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='691CA452-D37A-4ED0-9441'),
}

model ListDIJobRunDetailsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIJobRunDetailsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDIJobRunDetails  ListDIJobRunDetailsRequest
  * @return ListDIJobRunDetailsResponse
 */
async function listDIJobRunDetails(request: ListDIJobRunDetailsRequest): ListDIJobRunDetailsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIJobRunDetails', 'GET', '/', 'json', false, 'json', request);
}

model ListDIJobsRequest {
  regionId?: string(name='RegionId', position='Host'),
  destinationDataSourceType?: string(name='DestinationDataSourceType', description='The destination type. Valid values: Hologres, OSS-HDFS, OSS, MaxCompute, Loghub, STARROCKS, Datahub, ANALYTICDB_FOR_MYSQL, Kafka, and Hive. If you do not configure this parameter, the API operation queries synchronization tasks that use all type of destinations.', example='Hologres', position='Query'),
  migrationType?: string(name='MigrationType', description='The synchronization type. Valid values:

*   FullAndRealtimeIncremental: one-time full synchronization and real-time incremental synchronization
*   RealtimeIncremental: real-time incremental synchronization
*   Full: full synchronization
*   OfflineIncremental: batch incremental synchronization
*   FullAndOfflineIncremental: one-time full synchronization and batch incremental synchronization', example='FullAndRealtimeIncremental', position='Query'),
  name?: string(name='Name', description='The name of the export task.

The name of each export task must be unique. You must make sure that the names of the export tasks in the current workspace are unique.', example='test_export_01', position='Query'),
  pageNumber?: long(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='1967', position='Query'),
  sourceDataSourceType?: string(name='SourceDataSourceType', description='The source type. Valid values: PolarDB, MySQL, Kafka, Loghub, Hologres, Oracle, OceanBase, MongoDB, RedShift, Hive, SqlServer, Doris, and ClickHouse. If you do not configure this parameter, the API operation queries synchronization tasks that use all types of sources.', example='MySQL', position='Query'),
}

model ListDIJobsResponseBody = {
  pagingInfo?: {
    DIJobs?: [ 
      {
        DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='32599', deprecated='true'),
        destinationDataSourceType?: string(name='DestinationDataSourceType', description='The destination type. Valid values: Hologres, OSS-HDFS, OSS, MaxCompute, Loghub, STARROCKS, Datahub, ANALYTICDB_FOR_MYSQL, Kafka, and Hive. If you do not configure this parameter, the API operation returns synchronization tasks that use all type of destinations.', example='Hologres'),
        id?: long(name='Id', description='The ID of the synchronization task.', example='32599'),
        jobName?: string(name='JobName', description='The name of the synchronization task.', example='mysql_to_holo_sync_35197'),
        jobStatus?: string(name='JobStatus', description='The status of the synchronization task. Valid values:

*   Finished
*   Initialized
*   Stopped
*   Failed
*   Running
*   Stopping', example='Running'),
        migrationType?: string(name='MigrationType', description='The synchronization type. Valid values:

*   FullAndRealtimeIncremental: one-time full synchronization and real-time incremental synchronization
*   RealtimeIncremental: real-time incremental synchronization
*   Full: full synchronization
*   OfflineIncremental: batch incremental synchronization
*   FullAndOfflineIncremental: one-time full synchronization and batch incremental synchronization', example='FullAndRealtimeIncremental'),
        projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace to which the synchronization task belongs.', example='26442'),
        sourceDataSourceType?: string(name='SourceDataSourceType', description='The source type. Valid values: PolarDB, MySQL, Kafka, Loghub, Hologres, Oracle, OceanBase, MongoDB, RedShift, Hive, SqlServer, Doris, and ClickHouse. If you do not configure this parameter, the API operation returns synchronization tasks that use all types of sources.', example='Mysql'),
      }
    ](name='DIJobs', description='The synchronization tasks returned.'),
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='12'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7263E4AC-9D2E-5B29-B8AF-7C5012E92A41'),
}

model ListDIJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDIJobsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDIJobs  ListDIJobsRequest
  * @return ListDIJobsResponse
 */
async function listDIJobs(request: ListDIJobsRequest): ListDIJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDIJobs', 'GET', '/', 'json', false, 'json', request);
}

model ListDataAssetTagsRequest {
  regionId?: string(name='RegionId', position='Host'),
  category?: string(name='Category', description='The type of the tag.

Valid values:

*   Normal
*   System', example='Normal', position='Query'),
  key?: string(name='Key', description='The tag key.', example='key1', minLength=1, maxLength=128, position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', minimum=1, maximum=200, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
}

model ListDataAssetTagsResponseBody = {
  pagingInfo?: {
    dataAssetTags?: [ 
      {
        category?: string(name='Category', description='The type of the tag.

Valid values:

*   Normal
*   System', example='Normal'),
        createTime?: long(name='CreateTime', description='The time when the tag was created.', example='1735890003000'),
        createUser?: string(name='CreateUser', description='The creator of the tag.', example='12345'),
        description?: string(name='Description', description='The description of the tag.', example='This is a description'),
        key?: string(name='Key', description='The tag key.', example='key1'),
        managers?: [ string ](name='Managers', description='The tag administrators.'),
        modifyTime?: long(name='ModifyTime', description='The time when the tag was last modified.', example='1735890003000'),
        modifyUser?: string(name='ModifyUser', description='The user who last modified the tag.', example='1234'),
        valueType?: string(name='ValueType', description='The type of the tag value.', example='String'),
        values?: [ string ](name='Values', description='The tag values.'),
      }
    ](name='DataAssetTags', description='The tags.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='2524'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376****'),
}

model ListDataAssetTagsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataAssetTagsResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of ListDataAssetTags  ListDataAssetTagsRequest
  * @return ListDataAssetTagsResponse
 */
async function listDataAssetTags(request: ListDataAssetTagsRequest): ListDataAssetTagsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataAssetTags', 'GET', '/', 'json', false, 'json', request);
}

model ListDataAssetsRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataAssetIds?: [ string ](name='DataAssetIds', description='The data asset IDs.', shrink='json', position='Query'),
  dataAssetType?: string(name='DataAssetType', description='The type of the data asset. Valid values:

*   ACS::DataWorks::Table
*   ACS::DataWorks::Task', example='ACS::DataWorks::Task', position='Query'),
  envType?: string(name='EnvType', description='The environment of the workspace to which the data asset belongs. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=1, maximum=100, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10000', position='Query'),
  tags: [ 
    {
      key: string(name='Key', description='The tag key.

The tag key can be up to 64 characters in length and can contain letters, digits, and the following characters: `-@#*<>|[]()+=&%$!~`. It cannot start with `dw:`.

This parameter is required.', example='key'),
      value?: string(name='Value', description='The tag value.', example='value'),
    }
  ](name='Tags', description='The tags that are added to data assets. This parameter specifies a filter condition.

*   You can specify multiple tags, which are in the logical OR relation. For example, you can query the data assets that contain one of the following tags: `["key1:v1", "key2:v1", "key3:v1"]`.
*   If you do not configure this parameter, tag-based filtering is not performed.

This parameter is required.', shrink='json', position='Query'),
}

model ListDataAssetsResponseBody = {
  pagingInfo?: {
    dataAssets?: [ 
      {
        dataAssetTagMappings?: [ 
          {
            autoTraceEnabled?: boolean(name='AutoTraceEnabled', description='Indicates whether the lineage-based automatic backtrack feature is enabled for the mapping.', example='false'),
            creator?: string(name='Creator', description='The creator of the mapping between the data asset and the tag.', example='12345'),
            dataAssetId?: string(name='DataAssetId', description='The data asset ID.', example='7259557313'),
            key?: string(name='Key', description='The tag key.', example='key'),
            tagSource?: string(name='TagSource', description='The way in which the mapping between the data asset and the tag is created. Valid values:

*   System
*   UserDefined', example='UserDefined'),
            value?: string(name='Value', description='The tag value.', example='value'),
          }
        ](name='DataAssetTagMappings', description='The mappings between data assets and tags.'),
        envType?: string(name='EnvType', description='The environment of the workspace to which the data asset belongs. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod'),
        id?: string(name='Id', description='The data asset ID.', example='7259557313'),
        name?: string(name='Name', description='The name of the data asset.', example='ali_cn_es_gfn'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='54275'),
        type?: string(name='Type', description='The type of the data asset. Valid values:

*   ACS::DataWorks::Table
*   ACS::DataWorks::Task', example='ACS::DataWorks::Task'),
      }
    ](name='DataAssets', description='The data assets.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376'),
}

model ListDataAssetsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataAssetsResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of ListDataAssets  ListDataAssetsRequest
  * @return ListDataAssetsResponse
 */
async function listDataAssets(request: ListDataAssetsRequest): ListDataAssetsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataAssets', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityEvaluationTaskInstancesRequest {
  regionId?: string(name='RegionId', position='Host'),
  bizdateFrom?: string(name='BizdateFrom', description='The start time of the data quality monitoring task.', example='2024-04-01', position='Query'),
  bizdateTo?: string(name='BizdateTo', description='The end time of the data quality monitoring task.', example='2024-05-01', position='Query'),
  createTimeFrom?: long(name='CreateTimeFrom', description='The earliest start time at which the instances are generated.', example='1710239005403', position='Query'),
  createTimeTo?: long(name='CreateTimeTo', description='The latest start time at which the instances are generated.', example='1710239005403', position='Query'),
  dataQualityEvaluationTaskId?: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task.', example='10000', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', minimum=1, maximum=200, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100', position='Query'),
  tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test', position='Query'),
  triggerClient?: string(name='TriggerClient', description='The name of the trigger module of the instance.', example='CWF2', position='Query'),
  triggerClientId?: string(name='TriggerClientId', description='The ID of the instance that is generated by the task.', example='1001', position='Query'),
}

model ListDataQualityEvaluationTaskInstancesResponseBody = {
  pagingInfo?: {
    dataQualityEvaluationTaskInstances?: [ 
      {
        createTime?: long(name='CreateTime', description='The time at which the instance was generated.', example='1710239005403'),
        finishTime?: long(name='FinishTime', description='The time at which the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The ID of the instance.', example='10001'),
        parameters?: string(name='Parameters', description='The parameters configured for the instance.', example='{
  "bizdate": "20240517",
  "triggerTime": "1710239005403"
}'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100'),
        status?: string(name='Status', description='The status of the instance. Valid values:

*   Running
*   Error
*   Passed
*   Warned
*   Critical', example='Critical'),
        task?: {
          description?: string(name='Description', description='The description of the task.', example='This is a daily run data quality evaluation plan.'),
          hooks?: [ 
            {
              condition?: string(name='Condition', description='The trigger configuration of the callback event.', example='${severity} == "High" AND ${status} == "Critical"'),
              type?: string(name='Type', description='The type of the callback event. Valid values:

*   BlockTaskInstance. The value indicates that an auto triggered node is blocked.', example='BlockTaskInstance'),
            }
          ](name='Hooks', description='The callback configurations of the task during the instance lifecycle. Blocking an auto triggered node is a type of callback event. Only this type is supported.'),
          id?: long(name='Id', description='The task ID.', example='10001'),
          name: string(name='Name', description='The name of the task.

This parameter is required.', example='Quality verification task'),
          notifications?: {
            condition?: string(name='Condition', description='The trigger condition of the alert notification.', example='${severity} == "High"'),
            notifications?: [ 
              {
                nofiticationReceivers?: [ 
                  {
                    extension?: string(name='Extension', description='The extended information in the JSON format. For example, the DingTalk chatbot can remind all members in a DingTalk group by using the at sign (@).', example='{"atAll":"true"}'),
                    receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid values:

*   AliUid: Alibaba Cloud account ID
*   WebhookUrl: URL of a custom webhook
*   DingdingUrl: DingTalk chatbot URL
*   FeishuUrl: Lark chatbot URL
*   WeixinUrl: WeCom chatbot URL', example='AliUid'),
                    receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
                  }
                ](name='NofiticationReceivers', description='The alert recipients.'),
                notificationChannels?: [ 
                  {
                    channels?: [ string ](name='Channels', description='The alert notification methods.'),
                  }
                ](name='NotificationChannels', description='The alert notification methods.'),
              }
            ](name='Notifications', description='The configurations for the alert notification.'),
          }(name='Notifications', description='The configurations for alert notifications.'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          runtimeConf?: string(name='RuntimeConf', description='The configuration of the data source. The value of the queue field is default, and that of the sqlEngine field can be set to SPARK_SQL, KYUUBI, PRESTO_SQL, or HIVE_SQL. The value default indicates the YARN queue for E-MapReduce (EMR) tasks.', example='{ "queue": "default", "sqlEngine": "SPARK-SQL" }'),
          target?: {
            databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='maxcompute'),
            partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='ds=$[yyyymmdd-1]'),
            tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test'),
            type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
          }(name='Target', description='The monitored object of the task.'),
          trigger?: {
            taskIds?: [ long ](name='TaskIds', description='The IDs of the auto triggered nodes of which the instances are successfully run.'),
            type?: string(name='Type', description='The trigger condition of the task. Valid values:

*   ByScheduledTaskInstance. The value indicates that the task is triggered when the instance of an auto triggered node is successfully run.', example='ByScheduledTaskInstance'),
          }(name='Trigger', description='The trigger configuration of the task.'),
        }(name='Task', description='The snapshot of the configurations for the task when the task starts.'),
        triggerContext?: string(name='TriggerContext', description='The information about the trigger module of the instance.', example='{
  "TriggerClientId": 10001,
  "TriggerClient": "CWF2"
}'),
      }
    ](name='DataQualityEvaluationTaskInstances', description='The instances generated by the task.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='294'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityEvaluationTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityEvaluationTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityEvaluationTaskInstances  ListDataQualityEvaluationTaskInstancesRequest
  * @return ListDataQualityEvaluationTaskInstancesResponse
 */
async function listDataQualityEvaluationTaskInstances(request: ListDataQualityEvaluationTaskInstancesRequest): ListDataQualityEvaluationTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityEvaluationTaskInstances', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityEvaluationTasksRequest {
  regionId?: string(name='RegionId', position='Host'),
  name?: string(name='Name', description='The name of the data quality monitoring task. Fuzzy match is supported.', example='Test', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', minimum=1, maximum=200, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100', position='Query'),
  tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test', position='Query'),
}

model ListDataQualityEvaluationTasksResponseBody = {
  pagingInfo?: {
    dataQualityEvaluationTasks?: [ 
      {
        description?: string(name='Description', description='The description of the data quality monitoring task. The description can be up to 65,535 characters in length.', example='This is a daily run data quality evaluation plan'),
        hooks?: [ 
          {
            condition?: string(name='Condition', description='The trigger configuration of the callback event.', example='${severity} == "High" AND ${status} == "Critical"'),
            type?: string(name='Type', description='The type of the callback event. Valid values:

*   BlockTaskInstance. The value indicates that an auto triggered node is blocked.', example='BlockTaskInstance'),
          }
        ](name='Hooks', description='The callback configurations of the task during the instance lifecycle. Blocking an auto triggered node is a type of callback event. Only this type is supported.'),
        id?: long(name='Id', description='The ID of the data quality monitoring task.', example='10001'),
        name?: string(name='Name', description='The name of the data quality monitoring task. The name can be up to 255 characters in length and can contain digits, letters, and punctuation marks.', example='Data quality verification task'),
        notifications?: {
          condition?: string(name='Condition', description='The trigger condition of the alert notification.', example='${severity} == "High"'),
          notifications?: [ 
            {
              notificationChannels?: [ 
                {
                  channels?: [ string ](name='Channels', description='The alert notification methods.'),
                }
              ](name='NotificationChannels', description='The alert notification methods.'),
              notificationReceivers?: [ 
                {
                  extension?: string(name='Extension', description='The extended information in the JSON format. For example, the DingTalk chatbot can remind all members in a DingTalk group by using the at sign (@).', example='{"atAll":"true"}'),
                  receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid values:

*   AliUid: Alibaba Cloud account ID
*   WebhookUrl: URL of a custom webhook
*   DingdingUrl: DingTalk chatbot URL
*   FeishuUrl: Lark chatbot URL
*   WeixinUrl: WeCom chatbot URL', example='AliUid'),
                  receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
                }
              ](name='NotificationReceivers', description='The alert recipients.'),
            }
          ](name='Notifications', description='The configurations for the alert notification.'),
        }(name='Notifications', description='The configurations for alert notifications.'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100'),
        runtimeConf?: string(name='RuntimeConf', description='The configuration of the data source. The value of the queue field is default, and that of the sqlEngine field can be set to SPARK_SQL, KYUUBI, PRESTO_SQL, or HIVE_SQL. The value default indicates the YARN queue for E-MapReduce (EMR) tasks.', example='{ "queue": "default", "sqlEngine": "SPARK-SQL" }'),
        target?: {
          databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='maxcompute'),
          partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='ds=$[yyyymmdd-1]'),
          tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odps.unit_test.tb_unit_test'),
          type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
        }(name='Target', description='The monitored object of the task.'),
        trigger?: {
          taskIds?: [ long ](name='TaskIds', description='The IDs of the auto triggered nodes of which the instances are successfully run. This parameter takes effect only if the Type parameter is set to ByScheduledTaskInstance.'),
          type?: string(name='Type', description='The trigger condition of the task. Valid values:

*   ByScheduledTaskInstance. The value indicates that the task is triggered when the instance of an auto triggered node is successfully run.', example='ByScheduledTaskInstance'),
        }(name='Trigger', description='The trigger configuration of the task.'),
      }
    ](name='DataQualityEvaluationTasks', description='The data quality monitoring tasks.'),
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='131'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityEvaluationTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityEvaluationTasksResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityEvaluationTasks  ListDataQualityEvaluationTasksRequest
  * @return ListDataQualityEvaluationTasksResponse
 */
async function listDataQualityEvaluationTasks(request: ListDataQualityEvaluationTasksRequest): ListDataQualityEvaluationTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityEvaluationTasks', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityResultsRequest {
  regionId?: string(name='RegionId', position='Host'),
  bizdateFrom?: string(name='BizdateFrom', description='The beginning of the time range to query.', example='2024-05-01', position='Query'),
  bizdateTo?: string(name='BizdateTo', description='The end of the time range to query.', example='2024-05-04', position='Query'),
  createTimeFrom?: long(name='CreateTimeFrom', description='The earliest time when data quality verification results are generated.', example='1710239005403', position='Query'),
  createTimeTo?: long(name='CreateTimeTo', description='The latest generation time of data quality verification results.', example='1710239005403', position='Query'),
  dataQualityEvaluationTaskId?: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality verification task.', example='200001', position='Query'),
  dataQualityEvaluationTaskInstanceId?: long(name='DataQualityEvaluationTaskInstanceId', description='The ID of the data quality verification task instance.', example='10001', position='Query'),
  dataQualityRuleId?: long(name='DataQualityRuleId', description='The ID of the data quality rule.', example='100001', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', minimum=1, maximum=200, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100', position='Query'),
}

model ListDataQualityResultsResponseBody = {
  pagingInfo?: {
    dataQualityResults?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the verification result was generated.', example='1708284916414'),
        details?: [ 
          {
            checkedValue?: string(name='CheckedValue', description='The value used to compare with the threshold.', example='100.0'),
            referencedValue?: string(name='ReferencedValue', description='Use the referenced sample to participate in the CheckedValue calculation of the benchmark value.', example='0.0'),
            status?: string(name='Status', description='The comparison result between the value of CheckedValue and the threshold. Valid values:

*   Error
*   Passed
*   Warned
*   Critical', example='PASSED'),
          }
        ](name='Details', description='The check details.'),
        id?: long(name='Id', description='The ID of the verification result.', example='16033'),
        rule?: {
          checkingConfig?: {
            referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='Some types of thresholds need to query some reference samples, and then summarize the values of the reference samples to obtain the threshold for comparison. Here, an expression is used to represent the query method of the reference samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
            thresholds?: {
              critical?: {
                expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue > 0.01'),
                operator?: string(name='Operator', description='*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
                value?: string(name='Value', description='The threshold value.', example='100.0'),
              }(name='Critical', description='The threshold settings for critical alerts.'),
              expected?: {
                expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue > 0.01'),
                operator?: string(name='Operator', description='*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
                value?: string(name='Value', description='The threshold value.', example='100.0'),
              }(name='Expected', description='The expected threshold setting.'),
              warned?: {
                expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue > 0.01'),
                operator?: string(name='Operator', description='*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
                value?: string(name='Value', description='The threshold value.', example='100.0'),
              }(name='Warned', description='The threshold settings for normal alerts.'),
            }(name='Thresholds', description='The threshold settings.'),
            type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='FIXED'),
          }(name='CheckingConfig', description='The check settings for sample data.'),
          description?: string(name='Description', description='The description of the rule. It can be up to 500 characters in length.', example='this is a odps _sql task'),
          enabled?: boolean(name='Enabled', description='Whether the rule is enabled.', example='true'),
          errorHandlers?: [ 
            {
              errorDataFilter?: string(name='ErrorDataFilter', description='For custom SQL rules, you must specify SQL to filter problem data.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
              type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SAVE_ERROR_DATA'),
            }
          ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
          id?: long(name='Id', description='The ID of the rule.', example='100001'),
          name?: string(name='Name', description='The rule name, a combination of numbers, English letters, Chinese characters, and half-width punctuation marks, can be up to 255 characters in length.', example='The table cannot be empty.'),
          projectId?: long(name='ProjectId', description='DataWorks the ID of the project.', example='100'),
          samplingConfig?: {
            metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='COUNT'),
            metricParameters?: string(name='MetricParameters', description='Parameters required for sample collection.', example='{ "columns": [ "id", "name" ] }'),
            samplingFilter?: string(name='SamplingFilter', description='The condition for secondary filtering of data that is not concerned during sampling, which can be up to 16777215 characters in length.', example='id IS NULL'),
            settingConfig?: string(name='SettingConfig', description='Before executing the sample statement, insert some runtime parameter setting statements, which can be up to 1000 characters in length. Currently, only MaxCompute is supported.', example='SET odps.sql.udf.timeout=600s;'),
          }(name='SamplingConfig', description='The sampling settings.'),
          severity?: string(name='Severity', description='The strength of the rule. Valid values:

*   High
*   Normal', example='NORMAL'),
          target?: {
            databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='MAX_COMPUTE'),
            tableGuid?: string(name='TableGuid', description='The unique ID of the table in the data map.', example='odps.unit_test.tb_unit_test'),
            type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='TABLE'),
          }(name='Target', description='The monitored object of the rule.'),
          templateCode?: string(name='TemplateCode', description='The code of the template that is referenced when you create a rule.', example='system::user_defined'),
        }(name='Rule', description='The snapshot of the rule configuration when the check starts.'),
        sample?: string(name='Sample', description='The sample value used for this verification.', example='[
  {
    "gender": "male",
    "_count": 100
  }, {
    "gender": "female",
    "_count": 100
  }
]'),
        status?: string(name='Status', description='The status of the check result. Valid values:

*   Running
*   Error
*   Passed
*   Warned
*   Critical', example='PASSED'),
        taskInstanceId?: long(name='TaskInstanceId', description='The ID of the verification task instance.', example='200001'),
      }
    ](name='DataQualityResults', description='The data quality check results.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The page size.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries.', example='219'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityResultsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityResultsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityResults  ListDataQualityResultsRequest
  * @return ListDataQualityResultsResponse
 */
async function listDataQualityResults(request: ListDataQualityResultsRequest): ListDataQualityResultsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityResults', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityRuleTemplatesRequest {
  regionId?: string(name='RegionId', position='Host'),
  creationSource?: string(name='CreationSource', description='The source of the rule template. Required.
- System: System Template
- UserDefined: user-defined Template', example='System', position='Query'),
  directoryPath?: string(name='DirectoryPath', description='The category directory where the custom template is stored, slash/divider level. Each level name can be up to 1024 characters in length and cannot contain white space characters or backslashes.', example='/ods/order_data', position='Query'),
  name?: string(name='Name', description='Fuzzy matching of template rule names. If it is a system template, the internationalized name of the system template will be fuzzy matching based on the language.', example='Table rows', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The number of entries per page. Default value: 10.', example='10', minimum=1, position='Query'),
  pageSize?: int32(name='PageSize', description='The page number. Default value: 1.', example='1', minimum=1, maximum=200, position='Query'),
  projectId: long(name='ProjectId', description='DataWorks workspace ID.

This parameter is required.', example='10000', position='Query'),
}

model ListDataQualityRuleTemplatesResponseBody = {
  pagingInfo?: {
    dataQualityRuleTemplates?: [ 
      {
        checkingConfig?: {
          referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='Some types of thresholds need to query some reference samples, and then summarize the values of the reference samples to obtain the threshold for comparison. Here, an expression is used to represent the query method of the reference samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
          type?: string(name='Type', description='Threshold Calculation method
- Fixed
- Fluctation
- FluctationDiscreate
- Auto
- Average
- Variance', example='Fixed'),
        }(name='CheckingConfig', description='Sample verification settings'),
        code?: string(name='Code', description='Rule template Code', example='USER_DEFINED:123'),
        directoryPath?: string(name='DirectoryPath', description='The category directory where the custom template is stored, separated by slashes. Each level name can be up to 1024 characters in length and cannot contain white space characters or slashes.', example='/ods/order_data'),
        name?: string(name='Name', description='Rule template name, a combination of numbers, English letters, Chinese characters, and half-width punctuation marks, up to 512 characters in length', example='Table row Count Verification'),
        projectId?: long(name='ProjectId', description='DataWorks workspace ID', example='2043'),
        samplingConfig?: {
          metric?: string(name='Metric', description='The name of the sampled metric.
- Count: number of table rows
- Min: minimum value of the field
- Max: The maximum value of the field.
- Avg: field mean
- DistinctCount: number of unique field values
- DistinctPercent: the ratio of the number of unique field values to the number of data rows.
- DuplicatedCount: number of duplicate field values
- DuplicatedPercent: the ratio of the number of duplicate field values to the number of data rows.
- TableSize: table size
- NullValueCount: number of rows with empty fields
- NullValuePercent: the proportion of fields that are empty.
- GroupCount: aggregate each value by field value and the corresponding number of data rows
- CountNotIn: the enumerated value does not match the number of rows.
- CountDistinctNotIn: the number of unique values that the enumerated values do not match.
- UserDefinedSql: use custom SQL to collect samples', example='Max'),
          metricParameters?: string(name='MetricParameters', description='Parameters required for sample collection', example='{"Sql": "select count(1) from table;"}'),
          settingConfig?: string(name='SettingConfig', description='Before executing the sample statement, insert some runtime parameter setting statements, which can be up to 1000 characters in length. Currently, only MaxCompute are supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;'),
        }(name='SamplingConfig', description='Settings required for sample collection'),
        visibleScope?: string(name='VisibleScope', description='Available range of templates:
- Tenant: all tenants are available
- Project: only available in the current Project', example='Project'),
      }
    ](name='DataQualityRuleTemplates', description='Rule template list'),
    pageNumber?: int32(name='PageNumber', description='Page number', example='1'),
    pageSize?: int32(name='PageSize', description='Page size', example='10'),
    totalCount?: int32(name='TotalCount', description='Total number of entries', example='42'),
  }(name='PagingInfo', description='Quality Rule template pagination query results'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityRuleTemplatesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityRuleTemplatesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDataQualityRuleTemplates  ListDataQualityRuleTemplatesRequest
  * @return ListDataQualityRuleTemplatesResponse
 */
async function listDataQualityRuleTemplates(request: ListDataQualityRuleTemplatesRequest): ListDataQualityRuleTemplatesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityRuleTemplates', 'GET', '/', 'json', false, 'json', request);
}

model ListDataQualityRulesRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityEvaluationTaskId?: long(name='DataQualityEvaluationTaskId', description='The ID of the data quality monitoring task that is associated with the rule.', example='10000', position='Query'),
  name?: string(name='Name', description='The name of the rule. Fuzzy match is supported.', example='unit_test', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 200.', example='10', minimum=1, maximum=200, position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10002', position='Query'),
  tableGuid?: string(name='TableGuid', description='The ID of the table that is limited by the rule in Data Map.', example='odps.unit_test.tb_unit_test', position='Query'),
}

model ListDataQualityRulesResponseBody = {
  pagingInfo?: {
    dataQualityRules?: [ 
      {
        checkingConfig?: {
          referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference values. In this example, an expression is used to indicate the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
          thresholds?: {
            critical?: {
              expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue > 0.01'),
              operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
              value?: string(name='Value', description='The threshold value.', example='100.0'),
            }(name='Critical', description='The threshold settings for critical alerts.'),
            expected?: {
              expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue > 0.01'),
              operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
              value?: string(name='Value', description='The threshold value.', example='100.0'),
            }(name='Expected', description='The expected threshold setting.'),
            warned?: {
              expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue > 0.01'),
              operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
              value?: string(name='Value', description='The threshold value.', example='100.0'),
            }(name='Warned', description='The threshold settings for normal alerts.'),
          }(name='Thresholds', description='The threshold settings.'),
          type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
        }(name='CheckingConfig', description='The check settings for sample data.'),
        description?: string(name='Description', description='The description of the rule. The description can be up to 500 characters in length.', example='this is a odps _sql task'),
        enabled?: boolean(name='Enabled', description='Indicates whether the rule is enabled.', example='true'),
        errorHandlers?: [ 
          {
            errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If the rule is defined by custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
            type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
          }
        ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
        id?: long(name='Id', description='The rule ID.', example='22130'),
        name?: string(name='Name', description='The rule name.', example='The table cannot be empty.'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100001'),
        samplingConfig?: {
          metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the percentage of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values in the field.
*   DuplicatedPercent: the percentage of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field is set to null.
*   NullValuePercent: the percentage of the number of rows in which the field is set to null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that the data is sampled by executing custom SQL statements.', example='Max'),
          metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
          samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='id IS NULL'),
          settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;'),
        }(name='SamplingConfig', description='The settings for sampling.'),
        severity?: string(name='Severity', description='The strength of the rule. Valid values:

*   Normal
*   High', example='High'),
        target?: {
          databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   emr
*   cdh
*   hologres
*   analyticdb_for_postgresql
*   analyticdb_for_mysql
*   starrocks', example='maxcompute'),
          tableGuid?: string(name='TableGuid', description='The ID of the table that is limited by the rule in Data Map.', example='odps.unit_test.tb_unit_test'),
          type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
        }(name='Target', description='The monitored object of the rule.'),
        templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='system::user_defined'),
      }
    ](name='DataQualityRules', description='The rules.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='294'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
}

model ListDataQualityRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataQualityRulesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDataQualityRules  ListDataQualityRulesRequest
  * @return ListDataQualityRulesResponse
 */
async function listDataQualityRules(request: ListDataQualityRulesRequest): ListDataQualityRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataQualityRules', 'GET', '/', 'json', false, 'json', request);
}

model ListDataSourceSharedRulesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  dataSourceId: long(name='DataSourceId', description='The data source ID.

This parameter is required.', example='1', position='Query'),
  targetProjectId?: long(name='TargetProjectId', description='The ID of the workspace to which the data source is shared. You cannot share the data source to the workspace with which the data source is associated.', example='1', position='Query'),
}

model ListDataSourceSharedRulesResponseBody = {
  dataSourceSharedRules?: [ 
    {
      createTime?: long(name='CreateTime', description='The time when the rule was created. This value is a UNIX timestamp.', example='1724379762000'),
      createUser?: string(name='CreateUser', description='The ID of the user who creates the rule.', example='1'),
      dataSourceId?: long(name='DataSourceId', description='The data source ID. You can call the [ListDataSources](https://help.aliyun.com/document_detail/211431.html) operation to query the ID.', example='1'),
      envType?: string(name='EnvType', description='The environment to which the target data source belongs. The values are as follows:
- Dev: the development environment.
- Prod: the production environment.', example='Dev'),
      id?: long(name='Id', description='The rule ID.', example='1'),
      sharedDataSourceName?: string(name='SharedDataSourceName', description='The name of the data source in the destination workspace.', example='targetProject.datasource'),
      sharedUser?: string(name='SharedUser', description='The user in the workspace to which the data source is shared. If the data source is shared to the entire workspace, this parameter is left empty.', example='1'),
      sourceProjectId?: long(name='SourceProjectId', description='The ID of the workspace with which the data source is associated.', example='1'),
      targetProjectId?: long(name='TargetProjectId', description='The ID of the workspace to which the data source is shared.', example='1'),
    }
  ](name='DataSourceSharedRules', description='The sharing rules of the data source.'),
  requestId?: string(name='RequestId', description='The request ID.', example='0000-ABCD-EFG****'),
}

model ListDataSourceSharedRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataSourceSharedRulesResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  If you want to query the sharing rules of a data source that is associated with Workspace A, you must have the permissions to share the data source in Workspace A. You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Tenant Administrator, Workspace Administrator, and Workspace Owner
  * @param request  the request parameters of ListDataSourceSharedRules  ListDataSourceSharedRulesRequest
  * @return ListDataSourceSharedRulesResponse
 */
async function listDataSourceSharedRules(request: ListDataSourceSharedRulesRequest): ListDataSourceSharedRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataSourceSharedRules', 'GET', '/', 'json', false, 'json', request);
}

model ListDataSourcesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  envType?: string(name='EnvType', description='The environment in which the data sources are used. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod', position='Query'),
  name?: string(name='Name', description='The name of the data source. Fuzzy match by data source name is supported.', example='test', position='Query'),
  order?: string(name='Order', description='The order in which you want to sort the data sources. Valid values:

*   Desc: descending order
*   Asc: ascending order

Default value: Asc', example='Asc', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='17820', position='Query'),
  sortBy?: string(name='SortBy', description='The field that you want to use to sort the data sources. Valid values:

*   CreateTime
*   Id
*   Name

Default value: Id', example='Id', position='Query'),
  tags?: string(name='Tags', description='The tag of the data source. This parameter specifies a filter condition.

*   You can specify multiple tags, which are in the logical AND relation. For example, you can query the data sources that contain the following tags: `["tag1", "tag2", "tag3"]`.
*   If you do not configure this parameter, tag-based filtering is not performed.', example='["tag1", "tag2", "tag3"]', position='Query'),
  types?: [ string ](name='Types', description='The data source types. This parameter specifies a filter condition. You can specify multiple data source types.', shrink='simple', position='Query'),
}

model ListDataSourcesResponseBody = {
  pagingInfo?: {
    dataSources?: [ 
      {
        dataSource?: [ 
          {
            connectionProperties?: any(name='ConnectionProperties', description='The connection configurations of the data source, including the connection address, access identity, and environment information. The envType parameter specifies the environment in which the data source is used. Valid values of the envType parameter:

*   Dev: development environment
*   Prod: production environment

The parameters that you need to configure for the data source vary based on the mode in which the data source is added. For more information, see [Data source connection information (ConnectionProperties)](https://help.aliyun.com/document_detail/2852465.html).', example='{
	"envType": "Prod",
	"regionId": "cn-beijing",
    "instanceId": "hgprecn-cn-x0r3oun4k001",
    "database": "testdb",
    "securityProtocol": "authTypeNone",
    "authType": "Executor",
    "authIdentity": "1107550004253538"
}'),
            connectionPropertiesMode?: string(name='ConnectionPropertiesMode', description='The mode in which the data source is added. The mode varies based on the data source type. Valid values: InstanceMode, UrlMode, and CdhMode. The value InstanceMode indicates the instance mode. The value UrlMode indicates the connection string mode. The value CdhMode indicates the CDH cluster mode.', example='UrlMode'),
            createTime?: long(name='CreateTime', description='The time when the data source was added. This value is a UNIX timestamp.', example='1648711113000'),
            createUser?: string(name='CreateUser', description='The ID of the user who adds the data source.', example='1624387842781448'),
            description?: string(name='Description', description='The description of the data source.', example='test'),
            id?: long(name='Id', description='The ID of the data source.', example='16035'),
            modifyTime?: long(name='ModifyTime', description='The time when the data source was last modified. This value is a UNIX timestamp.', example='1648711113000'),
            modifyUser?: string(name='ModifyUser', description='The ID of the user who modifies the data source.', example='1624387842781448'),
            qualifiedName?: string(name='QualifiedName', description='The unique business key of the data source. For example, the unique business key of a Hologres data source is in the `${tenantOwnerId}:${regionId}:${type}:${instanceId}:${database}` format.', example='1648711121000:cn-beijing:odps:yongxunQA_beijing_standard'),
          }
        ](name='DataSource', description='The data sources. Each element is the information of a single data source with a unique data source ID.'),
        name?: string(name='Name', description='The name of the data source.', example='test'),
        type?: string(name='Type', description='The type of the data source.', example='mysql'),
      }
    ](name='DataSources', description='The data source groups. Each element in the array indicates a data source group. Each data source group contains data sources in the development environment (if any) and the production environment.'),
    pageNumber?: long(name='PageNumber', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: long(name='TotalCount', description='The total number of entries returned.', example='131'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7BE1433F-6D55-5D86-9344-CA6F7DD19B13'),
}

model ListDataSourcesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDataSourcesResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Workspace Administrator, Deploy, Develop, Visitor, Workspace Owner, O\\&M, Model Designer, Security Administrator, Data Analyst, OpenPlatform Administrator, and Data Governance Administrator
  * @param request  the request parameters of ListDataSources  ListDataSourcesRequest
  * @return ListDataSourcesResponse
 */
async function listDataSources(request: ListDataSourcesRequest): ListDataSourcesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDataSources', 'GET', '/', 'json', false, 'json', request);
}

model ListDeploymentsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  creator?: string(name='Creator', description='The ID of the user who creates the processes. This parameter specifies a filter condition.', example='110755000425XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Query'),
  status?: string(name='Status', description='The status of the processes. This parameter specifies a filter condition.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='RUNNING', position='Query'),
}

model ListDeploymentsResponseBody = {
  pagingInfo?: {
    deployments?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the process was created. This value is a UNIX timestamp.', example='1702736654000'),
        creator?: string(name='Creator', description='The ID of the user who creates the process.', example='110755000425XXXX'),
        id?: string(name='Id', description='The process ID.', example='ddf354a5-03df-48fc-94c1-cc973f79XXXX'),
        message?: string(name='Message', description='The error message returned if the process fails.', example='Error message'),
        modifyTime?: long(name='ModifyTime', description='The time when the process was last modified. This value is a UNIX timestamp.', example='1702736654000'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='44683'),
        stages?: [ 
          {
            code?: string(name='Code', description='The code of the stage.', example='DEV_CHECK'),
            description?: string(name='Description', description='The description of the stage.', example='Check before going online to development'),
            detail?: map[string]any(name='Detail', description='The additional information about the stage.'),
            message?: string(name='Message', description='The error message returned during the stage.', example='Error message'),
            name?: string(name='Name', description='The name of the stage.', example='Check before going online to development'),
            status?: string(name='Status', description='The status of the stage.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='RUNNING'),
            step?: int32(name='Step', description='The step number of the stage.', example='1'),
            type?: string(name='Type', description='The type of the stage. This parameter indicates the operation type in the stage.

Valid values:

*   Deploy
*   Check
*   Offline
*   Build
*   Delete', example='CHECK'),
          }
        ](name='Stages', description='The stages of the process.'),
        status?: string(name='Status', description='The status of the process.

Valid values:

*   Init
*   Running
*   Success
*   Fail
*   Termination
*   Cancel', example='RUNNING'),
      }
    ](name='Deployments', description='The processes.'),
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='2524'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='7C352CB7-CD88-50CF-9D0D-E81BDF02XXXX'),
}

model ListDeploymentsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDeploymentsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDeployments  ListDeploymentsRequest
  * @return ListDeploymentsResponse
 */
async function listDeployments(request: ListDeploymentsRequest): ListDeploymentsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDeployments', 'GET', '/', 'json', false, 'json', request);
}

model ListDownstreamTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
}

model ListDownstreamTaskInstancesResponseBody = {
  pagingInfo?: {
    downstreamTaskInstances?: [ 
      {
        dependencyType?: string(name='DependencyType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        taskInstance?: {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
          bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description.', example='test'),
          envType?: string(name='EnvType', description='The environment in which the data source is used. Valid values:

*   Dev
*   Prod', example='Prod'),
          finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
          id?: long(name='Id', description='The instance ID.', example='1234'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
          priority?: int32(name='Priority', description='The priority of the task. Minimum value: 1. Maximum value: 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunMode?: string(name='RerunMode', description='The rerun mode.', example='AllAllowed'),
          runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
          runtime?: {
            gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
            processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
          }(name='Runtime', description='The runtime information about the instance.'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
          startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
          status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.
*   WaitTrigger: The instance is waiting to be triggered by external scheduling systems.', example='Success'),
          taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
          taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
          taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='3600'),
          triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
          triggerType?: string(name='TriggerType', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
          workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
          workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   Normal
*   Manual
*   SmokeTest
*   SupplementData
*   ManualWorkflow', example='Normal'),
          workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
        }(name='TaskInstance', description='The information about a task instance.'),
      }
    ](name='DownstreamTaskInstances', description='The descendant instances.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    taskInstances?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description.', example='test'),
        envType?: string(name='EnvType', description='The environment in which the data source is used. Valid values:

*   Dev
*   Prod', example='Prod'),
        finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The instance ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='100'),
        periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', deprecated='true'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunMode?: string(name='RerunMode', description='The rerun mode.

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether it is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
        runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
        runtime?: {
          gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
          processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
        }(name='Runtime', description='The runtime information about the instance.'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The information about the resource group with which the instance is associated.'),
        startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
        status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.
*   WaitTrigger: The instance is waiting to be triggered by external scheduling systems.', example='Success'),
        stepType?: string(name='StepType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
        taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
        taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='1'),
        triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
        triggerType?: string(name='TriggerType', description='The method to trigger instance scheduling.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
        workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
        workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance.

Valid values:

*   SmokeTest
*   SupplementData
*   Manual
*   ManualWorkflow
*   Normal
*   ManualFlow', example='Normal'),
        workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
      }
    ](name='TaskInstances', description='The instances. This parameter is deprecated and replaced by the DownstreamTaskInstances parameter.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListDownstreamTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDownstreamTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListDownstreamTaskInstances  ListDownstreamTaskInstancesRequest
  * @return ListDownstreamTaskInstancesResponse
 */
async function listDownstreamTaskInstances(request: ListDownstreamTaskInstancesRequest): ListDownstreamTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDownstreamTaskInstances', 'GET', '/', 'json', false, 'json', request);
}

model ListDownstreamTasksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model ListDownstreamTasksResponseBody = {
  pagingInfo?: {
    downstreamTasks?: [ 
      {
        dependencyType?: string(name='DependencyType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        task?: {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description.', example='test'),
          envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
          id?: long(name='Id', description='The task ID.', example='1234'),
          instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          name?: string(name='Name', description='The name of the task.', example='SQL node'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8.', example='1'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
          trigger?: {
            cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
            endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
            recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
            startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
            timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
            type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
          }(name='Trigger', description='The trigger method.'),
          type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
        }(name='Task', description='The information about the task.'),
      }
    ](name='DownstreamTasks', description='The descendant tasks.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    tasks?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description of the task.', example='test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        id?: long(name='Id', description='The task ID.', example='1234'),
        instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name of the task.', example='SQL node'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter.

Valid values:

*   Prod
*   Dev', example='Prod', deprecated='true'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
        rerunMode?: string(name='RerunMode', description='The rerun mode.

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether it is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
        rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        stepType?: string(name='StepType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
          recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
          timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
          type?: string(name='Type', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        }(name='Trigger', description='The method to trigger task scheduling.'),
        type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
      }
    ](name='Tasks', description='The tasks. This parameter is deprecated and replaced by the DownstreamTasks parameter.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListDownstreamTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListDownstreamTasksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListDownstreamTasks  ListDownstreamTasksRequest
  * @return ListDownstreamTasksResponse
 */
async function listDownstreamTasks(request: ListDownstreamTasksRequest): ListDownstreamTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListDownstreamTasks', 'GET', '/', 'json', false, 'json', request);
}

model ListFunctionsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  owner?: string(name='Owner', description='The ID of the owner of the UDF. This parameter specifies a filter condition.', example='110755000425XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Default value: 1. Minimum value: 1.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='12345', position='Query'),
  type?: string(name='Type', description='The user-defined function (UDF) type. This parameter specifies a filter condition.

Valid values:

*   Math: mathematical operation function
*   Aggregate: aggregate function
*   String: string processing function
*   Date: date function
*   Analytic: window function
*   Other: other functions', example='MATH', position='Query'),
}

model ListFunctionsResponseBody = {
  pagingInfo?: {
    functions?: [ 
      {
        armResource?: string(name='ArmResource', description='The file resources in an Advanced RISC Machines (ARM) cluster.', example='xxx.jar,yyy.jar'),
        className?: string(name='ClassName', description='The fully qualified class name of the UDF.', example='com.demo.Main'),
        commandDescription?: string(name='CommandDescription', description='The description of the command.', example='testUdf(xx,yy)'),
        createTime?: long(name='CreateTime', description='The time when the UDF was created. This value is a UNIX timestamp.', example='1655953028000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='odps_first'),
          type?: string(name='Type', description='The type of the data source.', example='odps'),
        }(name='DataSource', description='The data source information about the UDF.'),
        databaseName?: string(name='DatabaseName', description='The name of the database. This parameter is returned for E-MapReduce (EMR) functions.', example='odps_first'),
        description?: string(name='Description', description='The overall description of the UDF.', example='Description'),
        embeddedCode?: string(name='EmbeddedCode', description='The code of the embedded UDF.', example='print(\\"hello,world!\\")'),
        embeddedCodeType?: string(name='EmbeddedCodeType', description='The type of the nested code.

Valid values:

*   Python2
*   Python3
*   Java8
*   Java11
*   Java17', example='Python2'),
        embeddedResourceType?: string(name='EmbeddedResourceType', description='The type of the nested resource.

Valid values:

*   File: general resources
*   Embedded: embedded resources', example='File'),
        exampleDescription?: string(name='ExampleDescription', description='The description of the example.', example='Example description >>> select tsetUdf(xx,yy);
abc'),
        fileResource?: string(name='FileResource', description='The files resources.', example='xxx.jar,yyy.jar'),
        id?: long(name='Id', description='The ID of the UDF.', example='580667964888595XXXX'),
        modifyTime?: long(name='ModifyTime', description='The time when the UDF was last modified. This value is a UNIX timestamp.', example='1655953028000'),
        name?: string(name='Name', description='The name of the UDF.', example='Function name'),
        owner?: string(name='Owner', description='The owner of the UDF.', example='110755000425XXXX'),
        parameterDescription?: string(name='ParameterDescription', description='The description of the parameter.', example='xx: parameter information XXX
yy: parameter information YYY'),
        projectId?: long(name='ProjectId', description='The ID of the workspace to which the UDF belongs.', example='307XXX'),
        returnValueDescription?: string(name='ReturnValueDescription', description='The description of the return value.', example='The return value is a string.'),
        runtimeResource?: {
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group used when you run the UDF.', example='S_resgrop_xxx'),
        }(name='RuntimeResource', description='The information about the resource group used when you run the UDF.'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='652567824470354XXXX'),
          path?: string(name='Path', description='The script path.', example='XXX/OpenAPI/function/function_name'),
          runtime?: {
            command?: string(name='Command', description='The command.', example='ODPS_FUNCTION'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information about the UDF.'),
        type?: string(name='Type', description='The UDF type.

Valid values:

*   Math: mathematical operation function
*   Aggregate: aggregate function
*   String: string processing function
*   Date: date function
*   Analytic: window function
*   Other: other functions', example='MATH'),
      }
    ](name='Functions', description='The UDFs.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='294'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='89FB2BF0-EB00-5D03-9C34-05931001XXXX'),
}

model ListFunctionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListFunctionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListFunctions  ListFunctionsRequest
  * @return ListFunctionsResponse
 */
async function listFunctions(request: ListFunctionsRequest): ListFunctionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListFunctions', 'GET', '/', 'json', false, 'json', request);
}

model ListNetworksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10', position='Query'),
  resourceGroupId: string(name='ResourceGroupId', description='Unique identifier of a Serverless resource group

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Query'),
  sortBy?: string(name='SortBy', description='The fields used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   Id (Desc/Asc): the network ID
*   Status (Desc/Asc): the network status
*   CreateUser (Desc/Asc): the user who created the network
*   CreateTime (Desc/Asc): the time when the network was created

Default value: CreateTime Asc.', example='CreateTime Asc', position='Query'),
}

model ListNetworksResponseBody = {
  pagingInfo?: {
    networkList?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the network resource was created. The value is a 64-bit timestamp.', example='1727055811000'),
        createUser?: string(name='CreateUser', description='The ID of the user who creates the network resource.', example='11075500042XXXXX'),
        id?: long(name='Id', description='The network ID.', example='1000'),
        resourceGroupId?: string(name='ResourceGroupId', description='The ID of the serverless resource group.', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
        securityGroupId?: string(name='SecurityGroupId', description='The security group ID.', example='sg-2ze13vamugr7jenXXXXX'),
        status?: string(name='Status', description='The status of the network resource. Valid values: Pending, Creating, Running, Deleting, and Deleted.', example='Running'),
        vpcId?: string(name='VpcId', description='The ID of the virtual private cloud (VPC).', example='vpc-m2et4f3oc8msfbccXXXXX'),
        vswitchId?: string(name='VswitchId', description='The VSwitch ID.', example='vsw-uf8usrhs7hjd9amsXXXXX'),
      }
    ](name='NetworkList', description='The network resources of the serverless resource group.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Whether the request is successful', example='true'),
}

model ListNetworksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListNetworksResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListNetworks  ListNetworksRequest
  * @return ListNetworksResponse
 */
async function listNetworks(request: ListNetworksRequest): ListNetworksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListNetworks', 'GET', '/', 'json', false, 'json', request);
}

model ListNodeDependenciesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='860438872620113XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10001', position='Query'),
}

model ListNodeDependenciesResponseBody = {
  pagingInfo?: {
    nodes?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the node was created. This value is a UNIX timestamp.', example='1724505917000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='odps_first'),
          type?: string(name='Type', description='The type of the data source.', example='odps'),
        }(name='DataSource', description='The information about the data source.'),
        description?: string(name='Description', description='The description of the node.', example='Node description'),
        id?: long(name='Id', description='The ID of the node.', example='723932906364267XXXX'),
        inputs?: {
          nodeOutputs?: [ 
            {
              data?: string(name='Data', description='The node output.', example='860438872620113XXXX'),
            }
          ](name='NodeOutputs', description='The node outputs.'),
          tables?: [ 
            {
              guid?: string(name='Guid', description='The table ID.', example='odps.autotest.test_output_table_1'),
            }
          ](name='Tables', description='The tables.'),
          variables?: [ 
            {
              artifactType?: string(name='ArtifactType', description='The artifact type.', example='Variable'),
              id?: long(name='Id', description='The variable ID.', example='543218872620113XXXX'),
              name?: string(name='Name', description='The name of the variable.', example='input'),
              node?: {
                output?: string(name='Output', description='The output of the node.', example='860438872620113XXXX'),
              }(name='Node', description='The node to which the variable belongs.'),
              scope?: string(name='Scope', description='The scope of the variable. Valid values:

*   NodeParameter
*   NodeContext
*   Workflow
*   Workspace', example='NodeParameter'),
              type?: string(name='Type', description='The type of the variable. Valid values:

*   NoKvVariableExpression
*   Constant
*   PassThrough
*   System
*   NodeOutput', example='Constant'),
              value?: string(name='Value', description='The value of the variable.', example='111'),
            }
          ](name='Variables', description='The variables.'),
        }(name='Inputs', description='The input of the node.'),
        modifyTime?: long(name='ModifyTime', description='The time when the node was last modified. This value is a UNIX timestamp.', example='1724505917000'),
        name?: string(name='Name', description='The name of the node.', example='Node name'),
        outputs?: {
          nodeOutputs?: [ 
            {
              data?: string(name='Data', description='The node output.', example='463497880880954XXXX'),
            }
          ](name='NodeOutputs', description='The node outputs.'),
          tables?: [ 
            {
              guid?: string(name='Guid', description='The table ID.', example='odps.autotest.test_output_table_1'),
            }
          ](name='Tables', description='The tables.'),
          variables?: [ 
            {
              artifactType?: string(name='ArtifactType', description='The artifact type.', example='Variable'),
              id?: long(name='Id', description='The variable ID.', example='543217824470354XXXX'),
              name?: string(name='Name', description='The name of the variable.', example='output'),
              node?: {
                output?: string(name='Output', description='The output of the node to which the variable belongs.', example='463497880880954XXXX'),
              }(name='Node', description='The node to which the variable belongs.'),
              scope?: string(name='Scope', description='The scope of the variable. Valid values:

*   NodeParameter
*   NodeContext
*   Workflow
*   Workspace', example='NodeParameter'),
              type?: string(name='Type', description='The type of the variable. Valid values:

*   NoKvVariableExpression
*   Constant
*   PassThrough
*   System
*   NodeOutput', example='Constant'),
              value?: string(name='Value', description='The value of the variable.', example='111'),
            }
          ](name='Variables', description='The variables.'),
        }(name='Outputs', description='The output of the node.'),
        owner?: string(name='Owner', description='The owner of the node.', example='110755000425XXXX'),
        projectId?: long(name='ProjectId', description='The ID of the workspace to which the node belongs.', example='65133'),
        recurrence?: string(name='Recurrence', description='The scheduling type.

Valid values:

*   Normal: Nodes are scheduled as expected.
*   Pause: Nodes are paused, and the running of their descendant nodes is blocked.
*   Skip: Nodes are dry run. The system does not actually run the nodes but directly prompts that the nodes are successfully run. The running duration of the nodes is 0 seconds. In addition, the nodes do not occupy resources or block the running of their descendant nodes.', example='Normal'),
        runtimeResource?: {
          resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='S_res_group_XXXX_XXXX'),
        }(name='RuntimeResource', description='The information about the resource group.'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='853573334108680XXXX'),
          path?: string(name='Path', description='The script path.', example='root/demo'),
          runtime?: {
            command?: string(name='Command', description='The command used to distinguish node types.', example='ODPS_SQL'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information.'),
        strategy?: {
          instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval after a failure. Unit: milliseconds.', example='180000'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   Allowed
*   Denied
*   FailureAllowed', example='Allowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of reruns after a failure.', example='3'),
          timeout?: int32(name='Timeout', description='The timeout period. Unit: milliseconds.', example='0'),
        }(name='Strategy', description='The scheduling policy.'),
        tags?: [ 
          {
            key?: string(name='Key', description='The tag key.', example='null'),
            value?: string(name='Value', description='The tag value.', example='null'),
          }
        ](name='Tags', description='The tags. This parameter is not in use.'),
        taskId?: long(name='TaskId', description='The scheduling task ID.', example='580667964888595XXXX'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression for scheduling.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the validity period of the scheduling. The time is in the yyyy-MM-dd HH:mm:ss format.', example='9999-01-01 00:00:00'),
          id?: long(name='Id', description='The trigger ID.', example='543680677872062XXXX'),
          startTime?: string(name='StartTime', description='The start time of the validity period of the scheduling. The time is in the yyyy-MM-dd HH:mm:ss format.', example='1970-01-01 00:00:00'),
          timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
          type?: string(name='Type', description='The type of the trigger.

Valid values:

*   Scheduler
*   Manual
*   Streaming', example='Scheduler'),
        }(name='Trigger', description='The trigger.'),
      }
    ](name='Nodes', description='The descendant nodes.'),
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='90'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='204EAF68-CCE3-5112-8DA0-E7A60F02XXXX'),
}

model ListNodeDependenciesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListNodeDependenciesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListNodeDependencies  ListNodeDependenciesRequest
  * @return ListNodeDependenciesResponse
 */
async function listNodeDependencies(request: ListNodeDependenciesRequest): ListNodeDependenciesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListNodeDependencies', 'GET', '/', 'json', false, 'json', request);
}

model ListNodesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  containerId?: long(name='ContainerId', description='The container ID. This parameter specifies a filter condition.', example='860438872620113XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='12345', position='Query'),
  recurrence?: string(name='Recurrence', description='The scheduling type. This parameter specifies a filter condition.

Valid values:

*   Normal: Nodes are scheduled as expected.
*   Pause: Nodes are paused, and the running of their descendant nodes is blocked.
*   Skip: Nodes are dry run. The system does not actually run the nodes but directly prompts that the nodes are successfully run. The running duration of the nodes is 0 seconds. In addition, the nodes do not occupy resources or block the running of their descendant nodes.', example='Normal', position='Query'),
  rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   Allowed: The nodes can be rerun regardless of whether they are successfully run or fail to run.
*   FailureAllowed: The nodes can be rerun only after they fail to run.
*   Denied: The nodes cannot be rerun regardless of whether they are successfully run or fail to run.', example='Allowed', position='Query'),
  scene?: string(name='Scene', description='The scene of the node. This parameter determines the location of the node.

Valid values:

*   DataworksProject
*   DataworksManualWorkflow
*   DataworksManualTask', example='DATAWORKS_PROJECT', position='Query'),
}

model ListNodesResponseBody = {
  pagingInfo?: {
    nodes?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the node was created. This value is a UNIX timestamp.', example='1722910655000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='odps_first'),
          type?: string(name='Type', description='The type of the data source.', example='odps'),
        }(name='DataSource', description='The information about the data source.'),
        description?: string(name='Description', description='The description of the node.', example='Node description'),
        id?: long(name='Id', description='The ID of the node.', example='860438872620113XXXX'),
        inputs?: {
          nodeOutputs?: [ 
            {
              data?: string(name='Data', description='The node output.', example='623731286945488XXXX'),
            }
          ](name='NodeOutputs', description='The node outputs.'),
          tables?: [ 
            {
              guid?: string(name='Guid', description='The table ID.', example='odps.autotest.test_output_table_1'),
            }
          ](name='Tables', description='The tables.'),
          variables?: [ 
            {
              artifactType?: string(name='ArtifactType', description='The artifact type.', example='Variable'),
              id?: long(name='Id', description='The variable ID.', example='543211286945488XXXX'),
              name?: string(name='Name', description='The name of the variable.', example='input'),
              node?: {
                output?: string(name='Output', description='The output of the node.', example='623731286945488XXXX'),
              }(name='Node', description='The node to which the variable belongs.'),
              scope?: string(name='Scope', description='The scope of the variable. Valid values:

*   WorkSpace
*   NodeParameter
*   NodeContext
*   Workflow', example='NodeParameter'),
              type?: string(name='Type', description='The type of the variable. Valid values:

*   NoKvVariableExpression
*   Constant
*   PassThrough
*   System
*   NodeOutput', example='Constant'),
              value?: string(name='Value', description='The value of the variable.', example='222'),
            }
          ](name='Variables', description='The variables.'),
        }(name='Inputs', description='The input of the node.'),
        modifyTime?: long(name='ModifyTime', description='The time when the node was last modified. This value is a UNIX timestamp.', example='1722910655000'),
        name?: string(name='Name', description='The name of the node.', example='test'),
        outputs?: {
          nodeOutputs?: [ 
            {
              data?: string(name='Data', description='The node output.', example='860438872620113XXXX'),
            }
          ](name='NodeOutputs', description='The node outputs.'),
          tables?: [ 
            {
              guid?: string(name='Guid', description='The table ID.', example='odps.autotest.test_output_table_1'),
            }
          ](name='Tables', description='The tables.'),
          variables?: [ 
            {
              artifactType?: string(name='ArtifactType', description='The artifact type.', example='Variable'),
              id?: long(name='Id', description='The variable ID.', example='623731286945488XXXX'),
              name?: string(name='Name', description='The name of the variable.', example='output'),
              node?: {
                output?: string(name='Output', description='The output of the node.', example='860438872620113XXXX'),
              }(name='Node', description='The node to which the variable belongs.'),
              scope?: string(name='Scope', description='The scope of the variable. Valid value:

*   NodeParameter
*   NodeContext
*   Workflow
*   Workspace', example='NodeParameter'),
              type?: string(name='Type', description='The type of the variable. Valid value:

*   NoKvVariableExpression
*   Constant
*   PassThrough
*   System
*   NodeOutput', example='Constant'),
              value?: string(name='Value', description='The value of the variable.', example='111'),
            }
          ](name='Variables', description='The variables.'),
        }(name='Outputs', description='The output of the node.'),
        owner?: string(name='Owner', description='The owner of the node.', example='110755000425XXXX'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.', example='33233'),
        recurrence?: string(name='Recurrence', description='The scheduling type.

Valid values:

*   Normal: The node is scheduled as expected.
*   Pause: The node is paused, and the running of its descendant nodes is blocked.
*   Skip: The node is dry run. The system does not actually run the node but directly prompts that the node is successfully run. The running duration of the node is 0 seconds. In addition, the node does not occupy resources or block the running of its descendant nodes.', example='Normal'),
        runtimeResource?: {
          resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='S_resgrop_xxx'),
        }(name='RuntimeResource', description='The information about the resource group.'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='853573334108680XXXX'),
          path?: string(name='Path', description='The script path.', example='root/demo'),
          runtime?: {
            command?: string(name='Command', description='The command used to distinguish node types.', example='ODPS_SQL'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information.'),
        strategy?: {
          instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: milliseconds.', example='180000'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   Allowed
*   Denied
*   FailureAllowed', example='Allowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of reruns.', example='3'),
          timeout?: int32(name='Timeout', description='The timeout period.', example='0'),
        }(name='Strategy', description='The scheduling policy.'),
        tags?: [ 
          {
            key?: string(name='Key', description='The tag key.', example='null'),
            value?: string(name='Value', description='The tag value.', example='null'),
          }
        ](name='Tags', description='The tags. This parameter is not in use.'),
        taskId?: long(name='TaskId', description='The scheduling task ID.', example='88888888888'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression for scheduling.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the validity period of the trigger.', example='9999-01-01 00:00:00'),
          id?: long(name='Id', description='The trigger ID.', example='543680677872062XXXX'),
          startTime?: string(name='StartTime', description='The start time of the validity period of the trigger.', example='1970-01-01 00:00:00'),
          timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
          type?: string(name='Type', description='The type of the trigger.

Valid values:

*   Scheduler
*   Manual
*   Steaming', example='Scheduler'),
        }(name='Trigger', description='The trigger.'),
      }
    ](name='Nodes', description='The nodes.'),
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='42'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='2197B9C4-39CE-55EA-8EEA-FDBAE52DXXXX'),
}

model ListNodesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListNodesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListNodes  ListNodesRequest
  * @return ListNodesResponse
 */
async function listNodes(request: ListNodesRequest): ListNodesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListNodes', 'GET', '/', 'json', false, 'json', request);
}

model ListProjectMembersRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='62136', position='Body'),
  roleCodes?: [ string ](name='RoleCodes', description='The codes of the roles in the workspace. You can call the [ListProjectRoles](https://help.aliyun.com/document_detail/2853930.html) operation to query the codes of all roles in the workspace.', shrink='json', position='Body'),
  userIds?: [ string ](name='UserIds', description='The IDs of the accounts used by the members in the workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the Tenant Members and Roles page, view the IDs of the accounts used by the members in the workspace.', shrink='json', position='Body'),
}

model ListProjectMembersResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    projectMembers?: [ 
      {
        projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace.', example='62136'),
        roles?: [ 
          {
            code?: string(name='Code', description='The code of the role.', example='role_project_guest'),
            name?: string(name='Name', description='The name of the role.', example='Visitors'),
            type?: string(name='Type', description='The type of the role. Valid values:

*   UserCustom: custom role
*   System: built-in role', example='System'),
          }
        ](name='Roles', description='The roles that are assigned to the member.'),
        status?: string(name='Status', description='The status of the member. Valid values:

*   Normal
*   Forbidden', example='Normal'),
        userId?: string(name='UserId', description='The ID of the account used by the member.', example='123422344899'),
      }
    ](name='ProjectMembers', description='The members in the workspace.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='12'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='9FBBBB1F-DD5E-5D8E-8F50-37F77460F056'),
}

model ListProjectMembersResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListProjectMembersResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListProjectMembers  ListProjectMembersRequest
  * @return ListProjectMembersResponse
 */
async function listProjectMembers(request: ListProjectMembersRequest): ListProjectMembersResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListProjectMembers', 'POST', '/', 'json', true, 'form', request);
}

model ListProjectRolesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  codes?: [ string ](name='Codes', description='The codes of roles in the DataWorks workspace.', shrink='json', position='Body'),
  names?: [ string ](name='Names', description='The names of roles in the DataWorks workspace.', shrink='json', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='21229', position='Body'),
  type?: string(name='Type', description='The type of the role. Valid values:

*   UserCustom: user-defined role
*   System: system role', example='System', position='Body'),
}

model ListProjectRolesResponseBody = {
  pagingInfo?: {
    pageNumber?: string(name='PageNumber', description='The page number.', example='1'),
    pageSize?: string(name='PageSize', description='The number of entries per page.', example='10'),
    projectRoles?: [ 
      {
        code?: string(name='Code', description='The code of the role in the DataWorks workspace.', example='role_project_guest'),
        name?: string(name='Name', description='The name of the role.', example='Visitors'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='21229'),
        type?: string(name='Type', description='The type of the role in the DataWorks workspace.', example='System'),
      }
    ](name='ProjectRoles', description='The roles in the DataWorks workspace.'),
    totalCount?: string(name='TotalCount', description='The total number of entries returned.', example='42'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='61649187-0BCF-5E75-8D4B-64FDBEBBB447'),
}

model ListProjectRolesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListProjectRolesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListProjectRoles  ListProjectRolesRequest
  * @return ListProjectRolesResponse
 */
async function listProjectRoles(request: ListProjectRolesRequest): ListProjectRolesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListProjectRoles', 'POST', '/', 'json', true, 'form', request);
}

model ListProjectsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group to which the workspaces belong. You can log on to the [Resource Management console](https://resourcemanager.console.aliyun.com/resource-groups) and go to the Resource Group page to query the ID.

This parameter is used to query the information about workspaces that belong to a specific resource group.', example='rg-acfmzbn7pti3zff', position='Body'),
  aliyunResourceTags?: [ 
    {
      key?: string(name='Key', description='The tag key.', example='batch'),
      value?: string(name='Value', description='The tag value.', example='blue'),
    }
  ](name='AliyunResourceTags', description='The tags.', shrink='json', position='Body'),
  devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Specifies whether the development environment is enabled. Valid values:

*   true: The development environment is enabled. In this case, the development environment is isolated from the production environment in a workspace.
*   false: The development environment is disabled. In this case, only the production environment is used in a workspace.', example='true', position='Body'),
  devRoleDisabled?: boolean(name='DevRoleDisabled', description='Specifies whether the Develop role is disabled. Valid values:

*   false (default)
*   true', example='false', position='Body'),
  ids?: [ long ](name='Ids', description='The IDs of the DataWorks workspaces.', shrink='json', position='Body'),
  names?: [ string ](name='Names', description='The names of the DataWorks workspaces.', shrink='json', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', position='Body'),
  paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Specifies whether scheduling of Platform for AI (PAI) tasks is enabled. Valid values:

*   true: Scheduling of PAI tasks is enabled. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: Scheduling of PAI tasks is disabled.', example='true', position='Body'),
  status?: string(name='Status', description='The status of the workspaces. Valid values:

*   Available
*   Initializing
*   InitFailed
*   Forbidden
*   Deleting
*   DeleteFailed
*   Frozen
*   Updating
*   UpdateFailed

<!---->

*
*
*
*
*
*
*
*
*', example='Available', position='Body'),
}

model ListProjectsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='10'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='1'),
    projects?: [ 
      {
        aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the Alibaba Cloud resource group to which the workspace belongs.', example='rg-acfmzbn7pti3zfa'),
        aliyunResourceTags?: [ 
          {
            key?: string(name='Key', description='The tag key.', example='batch'),
            value?: string(name='Value', description='The tag value.', example='blue'),
          }
        ](name='AliyunResourceTags', description='The tags.'),
        description?: string(name='Description', description='The description of the workspace.', example='Financial analysis group project data development'),
        devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Indicates whether the development environment is enabled. Valid values:

*   true: The development environment is enabled. In this case, the development environment is isolated from the production environment in the workspace.
*   false: The development environment is disabled. In this case, only the production environment is used in the workspace.', example='true'),
        devRoleDisabled?: boolean(name='DevRoleDisabled', description='Indicates whether the Develop role is disabled. Valid values:

*   false (default)
*   true', example='false'),
        displayName?: string(name='DisplayName', description='The display name of the workspace.', example='Sora financial analysis'),
        id?: long(name='Id', description='The workspace ID.', example='123456'),
        name?: string(name='Name', description='The name of the workspace.', example='sora_finance'),
        owner?: string(name='Owner', description='The ID of the Alibaba Cloud account to which the workspace belongs.', example='123532153125'),
        paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Indicates whether scheduling of PAI tasks is enabled. Valid values:

*   true: Scheduling of PAI tasks is enabled. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: Scheduling of PAI tasks is disabled.', example='true'),
        status?: string(name='Status', description='The status of the workspace. Valid values:

*   Available
*   Initializing
*   InitFailed
*   Forbidden
*   Deleting
*   DeleteFailed
*   Frozen
*   Updating
*   UpdateFailed', example='Available'),
      }
    ](name='Projects', description='The workspaces.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='6D24AD9A-652F-59E2-AC1F-05029300F8A4'),
}

model ListProjectsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListProjectsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListProjects  ListProjectsRequest
  * @return ListProjectsResponse
 */
async function listProjects(request: ListProjectsRequest): ListProjectsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListProjects', 'POST', '/', 'json', true, 'form', request);
}

model ListResourceGroupsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='Alibaba Cloud Resource Group ID', example='rg-aek2kqofrgXXXXX', position='Query'),
  aliyunResourceTags?: [ 
    {
      key?: string(name='Key', description='Tag Key', example='key'),
      value?: string(name='Value', description='Tag Value', example='value'),
    }
  ](name='AliyunResourceTags', description='Alibaba Cloud tag list', shrink='json', position='Query'),
  name?: string(name='Name', description='The name of a resource group, which is used for fuzzy match.', example='Resource', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100', position='Query'),
  paymentType?: string(name='PaymentType', description='The billing method of resource groups. Valid values:

*   PrePaid
*   PostPaid', example='PrePaid', position='Query'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace.', example='1000', position='Query'),
  resourceGroupTypes?: [ string ](name='ResourceGroupTypes', description='The types of resource groups to query. If you do not configure this parameter, only serverless resource groups are returned by default.', shrink='json', position='Query'),
  sortBy?: string(name='SortBy', description='The list of fields used for sorting. Fields such as TriggerTime and StartedTime are supported. You must configure this parameter in the Sorting field + Sort by (Desc/Asc). By default, results are sorted in ascending order. Valid values:

*   Id (Desc/Asc): resource group ID
*   Name (Desc/Asc): resource group name
*   Remark (Desc/Asc): resource group remarks
*   Type (Desc/Asc): resource group type
*   Status (Desc/Asc): status of resources in a resource group
*   Spec (Desc/Asc): resource group specifications
*   CreateUser (Desc/Asc): creator
*   CreateTime (Desc/Asc): creation time

Default value: CreateTime Asc', example='CreateTime Asc', position='Query'),
  statuses?: [ string ](name='Statuses', description='The statuses of resource groups.', shrink='json', position='Query'),
}

model ListResourceGroupsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100'),
    resourceGroupList?: [ 
      {
        aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='Alibaba Cloud Resource Group ID', example='rg-aek2kqofrgXXXXX'),
        createTime?: long(name='CreateTime', description='The creation time, which is a 64-bit timestamp.', example='1727055811000'),
        createUser?: string(name='CreateUser', description='The ID of the user who created the resource group.', example='11075500042XXXXX'),
        defaultVpcId?: string(name='DefaultVpcId', description='Default VPC ID bound to a common resource group', example='vpc-m2et4f3oc8msfbccXXXXX'),
        defaultVswicthId?: string(name='DefaultVswicthId', description='The default switch ID bound to the common resource group.', example='vsw-uf8usrhs7hjd9amsXXXXX'),
        id?: string(name='Id', description='Unique identifier of a resource group', example='Serverless_res_group_524257424564736_6831777003XXXXX'),
        name?: string(name='Name', description='The name of the resource group.', example='common_resource_group'),
        orderInstanceId?: string(name='OrderInstanceId', description='The order instance ID of the resource group.', example='c442b330-3b10-4584-959e-736e4edXXXXX'),
        paymentType?: string(name='PaymentType', description='The billing method of the resource group. Valid values: PrePaid and PostPaid. The value PrePaid indicates the subscription billing method, and the value PostPaid indicates the pay-as-you-go billing method.', example='PrePaid'),
        remark?: string(name='Remark', description='Remarks for resource groups', example='Create a common resource group for common tasks'),
        resourceGroupType?: string(name='ResourceGroupType', description='The type of resource group. Valid values:

*   CommonV2: serverless resource group
*   ExclusiveDataIntegration: exclusive resource group for Data Integration
*   ExclusiveScheduler: exclusive resource group for scheduling
*   ExclusiveDataService: exclusive resource group for DataService Studio', example='CommonV2'),
        spec?: {
          amount?: int32(name='Amount', description='Quantity', example='1'),
          standard?: string(name='Standard', description='Specification details', example='2CU'),
        }(name='Spec', description='Resource Group specifications'),
        status?: string(name='Status', description='The status of the resource group. Valid values:

*   Normal: The resource group is running or in use.
*   Stop: The resource group is expired.
*   Deleted: The resource group is released or destroyed.
*   Creating: The resource group is being started.
*   CreateFailed: The resource group fails to be started.
*   Updating: The resource group is being scaled in or out, or the configurations of the resource group are being changed.
*   UpdateFailed: The resource group fails to be scaled out or upgraded.
*   Deleting: The resource group is being released or destroyed.
*   DeleteFailed: The resource group fails to be released or destroyed.
*   Timeout: The operations that are performed on the resource group time out.', example='Normal'),
      }
    ](name='ResourceGroupList', description='The resource groups returned.'),
    totalCount?: int32(name='TotalCount', description='All data entries', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values: true and false.', example='true'),
}

model ListResourceGroupsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListResourceGroupsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListResourceGroups  ListResourceGroupsRequest
  * @return ListResourceGroupsResponse
 */
async function listResourceGroups(request: ListResourceGroupsRequest): ListResourceGroupsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListResourceGroups', 'GET', '/', 'json', false, 'json', request);
}

model ListResourcesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the workspace administrator. You can log on to the Alibaba Cloud Management Console and view the ID on the Security Settings page.', example='110755000425XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10002', position='Query'),
  type?: string(name='Type', description='The resource type. This parameter specifies a filter condition.

Valid values:

*   Python
*   Jar
*   Archive
*   File', example='python', position='Query'),
}

model ListResourcesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    resources?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the file resource was created. This value is a UNIX timestamp.', example='1724505917000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='odps_first'),
          type?: string(name='Type', description='The type of the data source.', example='odps'),
        }(name='DataSource', description='The information about the data source.'),
        id?: long(name='Id', description='The ID of the file resource.', example='631478864897630XXXX'),
        modifyTime?: long(name='ModifyTime', description='The times when the file resource was last modified. This value is a UNIX timestamp.', example='1724505917000'),
        name?: string(name='Name', description='The name of the file resource.', example='math.py'),
        owner?: string(name='Owner', description='The owner of the file resource.', example='110755000425XXXX'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.', example='344247'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='123348864897630XXXX'),
          path?: string(name='Path', description='The script path.', example='root/demo'),
          runtime?: {
            command?: string(name='Command', description='The command used to distinguish file resource types.', example='ODPS_PYTHON'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information.'),
        sourcePath?: string(name='SourcePath', description='The path of the source of the file resource. If the SourecType parameter is set to Local, this parameter is left empty.', example='XXX/unknown/ide/1/XXX/20240820200851_963a9da676de44ef8d06a6576a8c4d6a.py'),
        sourceType?: string(name='SourceType', description='The storage type of the source of the file resource.

Valid values:

*   Local
*   Oss', example='local'),
        targetPath?: string(name='TargetPath', description='The storage path of the destination of the file resource.', example='XXX/unknown/ide/1/XXX/20240820200851_963a9da676de44ef8d06a6576a8c4d6a.py'),
        targetType?: string(name='TargetType', description='The storage type of the destination of the file resource.

Valid values:

*   Gateway
*   Oss
*   Hdfs', example='oss'),
        type?: string(name='Type', description='The type of the file resource.

Valid values:

*   Python
*   Jar
*   Archive
*   File', example='jar'),
      }
    ](name='Resources', description='The file resources.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='131'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='99EBE7CF-69C0-5089-BE3E-79563C31XXXX'),
}

model ListResourcesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListResourcesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListResources  ListResourcesRequest
  * @return ListResourcesResponse
 */
async function listResources(request: ListResourcesRequest): ListResourcesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListResources', 'GET', '/', 'json', false, 'json', request);
}

model ListRoutesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  networkId?: long(name='NetworkId', description='The network ID.', example='1000', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100', position='Query'),
  resourceGroupId: string(name='ResourceGroupId', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Query'),
  sortBy?: string(name='SortBy', description='The fields used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   Id (Desc/Asc): the route ID
*   DestinationCidr (Desc/Asc): the destination CIDR block of the route
*   CreateTime (Desc/Asc): the time when the route is created

Default value: CreateTime Asc.', example='CreateTime Asc', position='Query'),
}

model ListRoutesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='100'),
    routeList?: [ 
      {
        createTime?: long(name='CreateTime', description='The creation time, which is a 64-bit timestamp.', example='1727055811000'),
        destinationCidr?: string(name='DestinationCidr', description='Route destination CIDR', example='192.168.0.0/16'),
        id?: long(name='Id', description='Route ID', example='1000'),
        networkId?: long(name='NetworkId', description='Network Resource ID', example='1000'),
        resourceGroupId?: string(name='ResourceGroupId', description='Unique identifier of the resource group to which it belongs', example='Serverless_res_group_524257424564736_6831777003****'),
        resourceId?: string(name='ResourceId', description='Unique identifier of network resource', example='ns-679XXXXXX'),
      }
    ](name='RouteList', description='The list of network resource routing information obtained.'),
    totalCount?: int32(name='TotalCount', description='All data entries', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model ListRoutesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListRoutesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListRoutes  ListRoutesRequest
  * @return ListRoutesResponse
 */
async function listRoutes(request: ListRoutesRequest): ListRoutesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListRoutes', 'GET', '/', 'json', false, 'json', request);
}

model ListTaskInstanceOperationLogsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  date?: long(name='Date', description='The operation date, accurate to the day. The default value is the current day. You can query only the operation logs generated within the previous 31 days.', example='1710239005403', position='Query'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
}

model ListTaskInstanceOperationLogsResponseBody = {
  pagingInfo?: {
    operationLogs?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the operation log was generated.', example='1710239005403'),
        operationContent?: string(name='OperationContent', description='The operation content.', example='Freeze tasks'),
        operationSeq?: long(name='OperationSeq', description='The serial number of the operation.', example='1111'),
        taskInstanceId?: long(name='TaskInstanceId', description='The ID of the instance on which the operation was performed.', example='1234'),
        user?: string(name='User', description='The account ID of the operator.', example='1000'),
      }
    ](name='OperationLogs', description='The operation logs.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListTaskInstanceOperationLogsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTaskInstanceOperationLogsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * You can call this operation to query only the operation logs generated within the previous 31 days.
  * @param request  the request parameters of ListTaskInstanceOperationLogs  ListTaskInstanceOperationLogsRequest
  * @return ListTaskInstanceOperationLogsResponse
 */
async function listTaskInstanceOperationLogs(request: ListTaskInstanceOperationLogsRequest): ListTaskInstanceOperationLogsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTaskInstanceOperationLogs', 'GET', '/', 'json', false, 'json', request);
}

model ListTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  bizdate: long(name='Bizdate', description='The data timestamp.

This parameter is required.', example='1710239005403', position='Body'),
  id?: long(name='Id', description='The ID of the instance. The instance may be rerun. If the instance is rerun and you configure this parameter, the system returns the historical information of the instance, including the rerun information. You can use the RunNumber parameter to distinguish each entry in the historical information.', example='1234', position='Body'),
  ids?: [ long ](name='Ids', description='The IDs of the instances. You can query multiple instances at a time by instance ID.', shrink='json', position='Body'),
  owner?: string(name='Owner', description='The account ID of the task owner.', example='1000', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='100', position='Body'),
  runtimeResource?: string(name='RuntimeResource', description='The information about the resource group. Set this parameter to the identifier of a resource group for scheduling.', example='S_res_group_524258031846018_1684XXXXXXXXX', position='Body'),
  sortBy?: string(name='SortBy', description='The field used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   `TriggerTime (Desc/Asc)`

*   `StartedTime (Desc/Asc)`

*   `FinishedTime (Desc/Asc)`

*   `CreateTime (Desc/Asc)`

*   `Id (Desc/Asc)`

    Default value: `Id Desc`.', example='Id Desc', position='Body'),
  taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234', position='Body'),
  taskIds?: [ long ](name='TaskIds', description='The IDs of the tasks. You can query multiple instances at a time by task ID.', shrink='json', position='Body'),
  taskName?: string(name='TaskName', description='The name of the task. Fuzzy match is supported.', example='SQL node', position='Body'),
  taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL', position='Body'),
  triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal', position='Body'),
  triggerType?: string(name='TriggerType', description='The trigger type.

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Normal', position='Body'),
  workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234', position='Body'),
  workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234', position='Body'),
  workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   SmokeTest
*   Manual
*   SupplementData
*   ManualWorkflow
*   Normal', example='Normal', position='Body'),
}

model ListTaskInstancesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    taskInstances?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the user who creates the instance.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description.', example='test'),
        finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The instance ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the user who modifies the instance.', example='1000'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
        priority?: int32(name='Priority', description='The priority of the task. Minimum value: 1. Maximum value: 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
        projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='100'),
        rerunMode?: string(name='RerunMode', description='The rerun mode

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.', example='AllAllowed'),
        runNumber?: int32(name='RunNumber', description='The number of times the task is run. By default, the value starts from 1.', example='1'),
        runtime?: {
          gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
          processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
        }(name='Runtime', description='The runtime information about the instance.'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of CUs configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The information about the resource group with which the instance is associated.'),
        startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
        status?: string(name='Status', description='The status of the instance.

Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
        taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
        taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
        taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='1'),
        triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
        triggerType?: string(name='TriggerType', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
        workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
        workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance.

Valid values:

*   SmokeTest
*   SupplementData
*   Manual
*   ManualWorkflow
*   Normal
*   ManualFlow', example='Normal'),
        workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
      }
    ](name='TaskInstances', description='The instances.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListTaskInstances  ListTaskInstancesRequest
  * @return ListTaskInstancesResponse
 */
async function listTaskInstances(request: ListTaskInstancesRequest): ListTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model ListTaskOperationLogsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  date?: long(name='Date', description='The operation date, accurate to the day. The default value is the current day. You can query only the operation logs generated within the previous 31 days.', example='1710239005403', position='Query'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model ListTaskOperationLogsResponseBody = {
  pagingInfo?: {
    operationLogs?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the operation log was generated.', example='1710239005403'),
        operationContent?: string(name='OperationContent', description='The operation content.', example='Freeze tasks'),
        operationSeq?: long(name='OperationSeq', description='The serial number of the operation.', example='1111'),
        taskId?: long(name='TaskId', description='The ID of the task on which the operation was performed.', example='1234'),
        user?: string(name='User', description='The account ID of the operator.', example='1000'),
      }
    ](name='OperationLogs', description='The operation logs.'),
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListTaskOperationLogsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTaskOperationLogsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * You can call this operation to query only the operation logs generated within the previous 31 days.
  * @param request  the request parameters of ListTaskOperationLogs  ListTaskOperationLogsRequest
  * @return ListTaskOperationLogsResponse
 */
async function listTaskOperationLogs(request: ListTaskOperationLogsRequest): ListTaskOperationLogsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTaskOperationLogs', 'GET', '/', 'json', false, 'json', request);
}

model ListTasksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  ids?: [ long ](name='Ids', description='The ID of the task.', shrink='json', position='Body'),
  name?: string(name='Name', description='The name of the task. Fuzzy match is supported.', example='SQL node', position='Body'),
  owner?: string(name='Owner', description='The account ID of the task owner.', example='1000', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  projectId: long(name='ProjectId', description='The workspace ID.

This parameter is required.', example='100', position='Body'),
  runtimeResource?: string(name='RuntimeResource', description='The information about the resource group. Set this parameter to the ID of a resource group for scheduling.', example='S_res_group_524258031846018_1684XXXXXXXXX', position='Body'),
  sortBy?: string(name='SortBy', description='The field that is used to sort tasks. This parameter is configured in the format of "Sorting field Sorting order". You can set the sorting order to Desc or Asc. If you do not specify the sorting order, Asc is used by default. Valid values:

*   `ModifyTime (Desc/Asc)`

*   `CreateTime (Desc/Asc)`

*   `Id (Desc/Asc)`

    Default value: `Id Desc`.', example='Id Desc', position='Body'),
  taskType?: string(name='TaskType', description='The type of the task.', example='ODPS_SQL', position='Body'),
  triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal', position='Body'),
  triggerType?: string(name='TriggerType', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler', position='Body'),
  workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234', position='Body'),
}

model ListTasksResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    tasks?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description of the task.', example='test'),
        id?: long(name='Id', description='The task ID.', example='1234'),
        instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name of the task.', example='SQL node'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
        rerunMode?: string(name='RerunMode', description='The rerun mode.

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
        rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        scriptParameters?: string(name='ScriptParameters', description='The list of script parameters.', example='para1=$bizdate para2=$[yyyymmdd]'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
          recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
          type?: string(name='Type', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        }(name='Trigger', description='The method to trigger task scheduling.'),
        type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
      }
    ](name='Tasks', description='The tasks.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListTasksResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListTasks  ListTasksRequest
  * @return ListTasksResponse
 */
async function listTasks(request: ListTasksRequest): ListTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListTasks', 'POST', '/', 'json', true, 'form', request);
}

model ListUpstreamTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
}

model ListUpstreamTaskInstancesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    taskInstances?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description.', example='test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod'),
        finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The instance ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        periodNumber?: int32(name='PeriodNumber', description='The sequence number of the period. Indicates which cycle of the day the task instance is in.', example='1'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', deprecated='true'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunMode?: string(name='RerunMode', description='The rerun mode.

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether it is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
        runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
        runtime?: {
          gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
          processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
        }(name='Runtime', description='The runtime information about the instance.'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
        status?: string(name='Status', description='The status of the instance.

Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
        stepType?: string(name='StepType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
        taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
        taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='1'),
        triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
        triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
        triggerType?: string(name='TriggerType', description='The method to trigger instance scheduling.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
        workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
        workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance.

Valid values:

*   SmokeTest
*   SupplementData
*   Manual
*   ManualWorkflow
*   Normal
*   ManualFlow', example='Normal'),
        workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
      }
    ](name='TaskInstances', description='The instances. This parameter is deprecated and replaced by the UpstreamTaskInstances parameter.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
    upstreamTaskInstances?: [ 
      {
        dependencyType?: string(name='DependencyType', description='The scheduling dependency type. Valid values:

*   Normal
*   CrossCycle', example='Normal'),
        taskInstance?: {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
          bizdate?: long(name='Bizdate', description='The data timestamp.', example='1710239005403'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description.', example='test'),
          envType?: string(name='EnvType', description='The environment in which the data source is used. Valid values:

*   Dev
*   Prod', example='Prod'),
          finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
          id?: long(name='Id', description='The instance ID.', example='1234'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          periodNumber?: int32(name='PeriodNumber', description='The sequence number of the cycle. This parameter indicates the cycle of the task instance on the current day.', example='1'),
          priority?: int32(name='Priority', description='The priority of the task. Minimum value: 1. Maximum value: 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunMode?: string(name='RerunMode', description='The rerun mode.', example='AllAllowed'),
          runNumber?: int32(name='RunNumber', description='The number of times the instance is run. By default, the value starts from 1.', example='1'),
          runtime?: {
            gateway?: string(name='Gateway', description='The host for running.', example='cn-shanghai.1.2'),
            processId?: string(name='ProcessId', description='The instance run ID.', example='T3_123'),
          }(name='Runtime', description='The runtime information about the instance.'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
          startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
          status?: string(name='Status', description='The status of the instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.
*   WaitTrigger: The instance is waiting to be triggered by external scheduling systems.', example='Success'),
          taskId?: long(name='TaskId', description='The ID of the task for which the instance is generated.', example='1234'),
          taskName?: string(name='TaskName', description='The name of the task for which the instance is generated.', example='SQL node'),
          taskType?: string(name='TaskType', description='The type of the task for which the instance is generated.', example='ODPS_SQL'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.

Note: The value of this parameter is rounded up by hour.', example='3600'),
          triggerRecurrence?: string(name='TriggerRecurrence', description='The running mode of the instance after it is triggered. This parameter takes effect only if the TriggerType parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          triggerTime?: long(name='TriggerTime', description='The scheduling time.', example='1710239005403'),
          triggerType?: string(name='TriggerType', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
          workflowInstanceId?: long(name='WorkflowInstanceId', description='The workflow instance ID.', example='1234'),
          workflowInstanceType?: string(name='WorkflowInstanceType', description='The type of the workflow instance. Valid values:

*   Normal
*   Manual
*   SmokeTest
*   SupplementData
*   ManualWorkflow', example='Normal'),
          workflowName?: string(name='WorkflowName', description='The name of the workflow to which the instance belongs.', example='Test workflow'),
        }(name='TaskInstance', description='The information about a task instance.'),
      }
    ](name='UpstreamTaskInstances', description='The ancestor instances.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListUpstreamTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListUpstreamTaskInstancesResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListUpstreamTaskInstances  ListUpstreamTaskInstancesRequest
  * @return ListUpstreamTaskInstancesResponse
 */
async function listUpstreamTaskInstances(request: ListUpstreamTaskInstancesRequest): ListUpstreamTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListUpstreamTaskInstances', 'GET', '/', 'json', false, 'json', request);
}

model ListUpstreamTasksRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The task ID.

This parameter is required.', example='1234', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  projectEnv?: string(name='ProjectEnv', description='The environment of the workspace.

Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
}

model ListUpstreamTasksResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    tasks?: [ 
      {
        baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        dataSource?: {
          name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
        }(name='DataSource', description='The information about the associated data source.'),
        description?: string(name='Description', description='The description of the task.', example='test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        id?: long(name='Id', description='The task ID.', example='1234'),
        instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

T+1

Immediately', example='T+1'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name of the task.', example='SQL node'),
        owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
        priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8. A larger value indicates a higher priority. Default value: 1.', example='1'),
        projectEnv?: string(name='ProjectEnv', description='The environment of the workspace. This parameter is deprecated and replaced by the EnvType parameter.

Valid values:

*   Prod
*   Dev', example='Prod', deprecated='true'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
        rerunMode?: string(name='RerunMode', description='The rerun mode.

Valid values:

*   AllDenied: The task cannot be rerun regardless of whether it is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether it is successfully run or fails to run.', example='AllAllowed'),
        rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
        runtimeResource?: {
          cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
          image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
          resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
        }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
        stepType?: string(name='StepType', description='The scheduling dependency type. Valid values:

Normal: same-cycle scheduling dependency

CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression of the task. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
          recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler.

Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
          timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
          type?: string(name='Type', description='The trigger type.

Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        }(name='Trigger', description='The method to trigger task scheduling.'),
        type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
      }
    ](name='Tasks', description='The tasks. This parameter is deprecated and replaced by the UpstreamTasks parameter.'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
    upstreamTasks?: [ 
      {
        dependencyType?: string(name='DependencyType', description='The scheduling dependency type. Valid values:

*   Normal: same-cycle scheduling dependency
*   CrossCycle: cross-cycle scheduling dependency', example='Normal'),
        task?: {
          baselineId?: long(name='BaselineId', description='The baseline ID.', example='1234'),
          createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
          createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
          dataSource?: {
            name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
          }(name='DataSource', description='The information about the associated data source.'),
          description?: string(name='Description', description='The description of the task.', example='test'),
          envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
          id?: long(name='Id', description='The task ID.', example='1234'),
          instanceMode?: string(name='InstanceMode', description='The instance generation mode. Valid values:

*   T+1
*   Immediately', example='T+1'),
          modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
          modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
          name?: string(name='Name', description='The name of the task.', example='SQL node'),
          owner?: string(name='Owner', description='The account ID of the task owner.', example='1000'),
          priority?: int32(name='Priority', description='The priority of the task. Valid values: 1 to 8.', example='1'),
          projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
          rerunInterval?: int32(name='RerunInterval', description='The rerun interval. Unit: seconds.', example='60'),
          rerunMode?: string(name='RerunMode', description='The rerun mode. Valid values:

*   AllDenied: The task cannot be rerun regardless of whether the task is successfully run or fails to run.
*   FailureAllowed: The task can be rerun only after it fails to run.
*   AllAllowed: The task can be rerun regardless of whether the task is successfully run or fails to run.', example='AllAllowed'),
          rerunTimes?: int32(name='RerunTimes', description='The number of times that the task is rerun. This parameter takes effect only if the RerunMode parameter is set to AllAllowed or FailureAllowed.', example='3'),
          runtimeResource?: {
            cu?: string(name='Cu', description='The default number of compute units (CUs) configured for task running.', example='0.25'),
            image?: string(name='Image', description='The ID of the image configured for task running.', example='i-xxxxxx'),
            resourceGroupId?: string(name='ResourceGroupId', description='The ID of the resource group for scheduling configured for task running.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
          }(name='RuntimeResource', description='The configurations of the runtime environment, such as the resource group information.'),
          timeout?: int32(name='Timeout', description='The timeout period of task running. Unit: seconds.', example='3600'),
          trigger?: {
            cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
            endTime?: string(name='EndTime', description='The end time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
            recurrence?: string(name='Recurrence', description='The running mode of the task after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
            startTime?: string(name='StartTime', description='The start time of the time range during which the task is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
            timezone?: string(name='Timezone', description='The time zone.', example='Asia/Shanghai'),
            type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
          }(name='Trigger', description='The trigger method.'),
          type?: string(name='Type', description='The type of the task.', example='ODPS_SQL'),
          workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the task belongs.', example='1234'),
        }(name='Task', description='The information about the task.'),
      }
    ](name='UpstreamTasks', description='The ancestor tasks.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListUpstreamTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListUpstreamTasksResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListUpstreamTasks  ListUpstreamTasksRequest
  * @return ListUpstreamTasksResponse
 */
async function listUpstreamTasks(request: ListUpstreamTasksRequest): ListUpstreamTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListUpstreamTasks', 'GET', '/', 'json', false, 'json', request);
}

model ListWorkflowDefinitionsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the workspace administrator. You can log on to the Alibaba Cloud Management Console and view the ID on the Security Settings page.', example='110755000425XXXX', position='Query'),
  pageNumber?: int32(name='PageNumber', description='The page number.', example='1', minimum=1, maximum=2147483647, position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Maximum value: 100.', example='10', minimum=10, maximum=100, position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Query'),
  type?: string(name='Type', description='The workflow type. This parameter specifies a filter condition.

Valid values:

*   CycleWorkflow
*   ManualWorkflow', example='CycleWorkflow', position='Query'),
}

model ListWorkflowDefinitionsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='227'),
    workflowDefinitions?: [ 
      {
        createTime?: long(name='CreateTime', description='The time when the workflow was created. This value is a UNIX timestamp.', example='1698057323000'),
        description?: string(name='Description', description='The description of the workflow.', example='Workflow description'),
        id?: long(name='Id', description='The ID of the workflow.', example='463497880880954XXXX'),
        modifyTime?: long(name='ModifyTime', description='The times when the workflow was last modified. This value is a UNIX timestamp.', example='1698057323000'),
        name?: string(name='Name', description='The name of the workflow.', example='OpenAPI test workflow Demo'),
        owner?: string(name='Owner', description='The owner.', example='110755000425XXXX'),
        projectId: long(name='ProjectId', description='The ID of the DataWorks workspace to which the workflow belongs.

This parameter is required.', example='4710'),
        script?: {
          id?: long(name='Id', description='The script ID.', example='698002781368644XXXX'),
          path?: string(name='Path', description='The script path.', example='XX/OpenAPI_test/workflow_test/OpenAPI_test_workflow_Demo'),
          runtime?: {
            command?: string(name='Command', description='The command.', example='WORKFLOW'),
          }(name='Runtime', description='The runtime.'),
        }(name='Script', description='The script information.'),
        type?: string(name='Type', description='The type of the workflow.

Valid values:

*   CycleWorkflow
*   ManualWorkflow', example='CycleWorkflow'),
      }
    ](name='WorkflowDefinitions', description='The workflows.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='8C3ED0C5-ABAB-55E1-854B-DAC02B11XXXX'),
}

model ListWorkflowDefinitionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListWorkflowDefinitionsResponseBody(name='body'),
}

/**
  * @param request  the request parameters of ListWorkflowDefinitions  ListWorkflowDefinitionsRequest
  * @return ListWorkflowDefinitionsResponse
 */
async function listWorkflowDefinitions(request: ListWorkflowDefinitionsRequest): ListWorkflowDefinitionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListWorkflowDefinitions', 'GET', '/', 'json', false, 'json', request);
}

model ListWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  bizDate: long(name='BizDate', description='业务日期。

This parameter is required.', example='1710239005403', position='Body'),
  ids?: [ long ](name='Ids', description='The IDs of the workflow instances. You can query multiple instances at a time by instance ID.', shrink='json', position='Body'),
  name?: string(name='Name', description='The instance name. Fuzzy match is supported.', example='WorkflowInstance1', position='Body'),
  owner?: string(name='Owner', description='The account ID of the workflow instance owner.', example='1000', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  projectId: long(name='ProjectId', description='The workspace ID.

This parameter is required.', example='100', position='Body'),
  sortBy?: string(name='SortBy', description='The fields used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   TriggerTime (Desc/Asc)
*   StartedTime (Desc/Asc)
*   FinishedTime (Desc/Asc)
*   CreateTime (Desc/Asc)
*   Id (Desc/Asc)

Default value: Id Desc.', example='Id Desc', position='Body'),
  type?: string(name='Type', description='工作流实例的类型。
- Normal：周期调度
- Manual：手动任务
- SmokeTest：测试
- SupplementData：补数据
- ManualWorkflow：手动工作流', example='Normal', position='Body'),
  workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234', position='Body'),
}

model ListWorkflowInstancesResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
    workflowInstances?: [ 
      {
        bizDate?: long(name='BizDate', description='业务日期。', example='1710239005403'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='100'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        finishedTime?: long(name='FinishedTime', description='The time when the instance finished running.', example='1710239005403'),
        id?: long(name='Id', description='The workflow instance ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='100'),
        name?: string(name='Name', description='The name of the workflow instance.', example='WorkflowInstance1'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        startedTime?: long(name='StartedTime', description='The time when the instance started to run.', example='1710239005403'),
        status?: string(name='Status', description='The status of the workflow instance. Valid values:

*   NotRun: The instance is not run.
*   Running: The instance is running.
*   WaitTime: The instance is waiting for the scheduling time to arrive.
*   CheckingCondition: Branch conditions are being checked for the instance.
*   WaitResource: The instance is waiting for resources.
*   Failure: The instance fails to be run.
*   Success: The instance is successfully run.
*   Checking: Data quality is being checked for the instance.', example='Success'),
        type?: string(name='Type', description='工作流实例的类型。
- Normal：周期调度
- Manual：手动任务
- SmokeTest：测试
- SupplementData：补数据
- ManualWorkflow：手动工作流', example='Normal'),
        workflowId?: long(name='WorkflowId', description='The ID of the workflow to which the instance belongs.', example='1234'),
      }
    ](name='WorkflowInstances', description='The workflow instances.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListWorkflowInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListWorkflowInstances  ListWorkflowInstancesRequest
  * @return ListWorkflowInstancesResponse
 */
async function listWorkflowInstances(request: ListWorkflowInstancesRequest): ListWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model ListWorkflowsRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Body'),
  ids?: [ long ](name='Ids', description='The IDs of the workflows. You can query multiple workflows at a time by workflow ID.', shrink='json', position='Body'),
  name?: string(name='Name', description='The name of the workflow. Fuzzy match is supported.', example='Workflow1', position='Body'),
  owner?: string(name='Owner', description='The account ID of the workflow owner.', example='1000', position='Body'),
  pageNumber?: int32(name='PageNumber', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  projectId: long(name='ProjectId', description='The workspace ID.

This parameter is required.', example='100', position='Body'),
  sortBy?: string(name='SortBy', description='The field used for sorting. Fields such as TriggerTime and StartedTime are supported. The value of this parameter is in the Sort field + Sort by (Desc/Asc) format. By default, results are sorted in ascending order. Valid values:

*   ModifyTime (Desc/Asc)
*   CreateTime (Desc/Asc)
*   Id (Desc/Asc)

Default value: Id Desc.', example='Id Desc', position='Body'),
  triggerType?: string(name='TriggerType', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler', position='Body'),
}

model ListWorkflowsResponseBody = {
  pagingInfo?: {
    pageNumber?: int32(name='PageNumber', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    totalCount?: int32(name='TotalCount', description='The total number of entries returned.', example='100'),
    workflows?: [ 
      {
        clientUniqueCode?: string(name='ClientUniqueCode', description='The unique code of the client. This parameter is used to create a workflow asynchronously and implement the idempotence of the workflow. If you do not specify this parameter when you create the workflow, the system automatically generates a unique code. The unique code is uniquely associated with the workflow ID. If you specify this parameter when you update or delete the workflow, the value of this parameter must be the unique code that is used to create the workflow.', example='Workflow_0bc5213917368545132902xxxxxxxx'),
        createTime?: long(name='CreateTime', description='The creation time.', example='1710239005403'),
        createUser?: string(name='CreateUser', description='The account ID of the creator.', example='1000'),
        description?: string(name='Description', description='The description.', example='test'),
        envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod
*   Dev', example='Prod'),
        id?: long(name='Id', description='The workflow ID.', example='1234'),
        modifyTime?: long(name='ModifyTime', description='The modification time.', example='1710239005403'),
        modifyUser?: string(name='ModifyUser', description='The account ID of the modifier.', example='1000'),
        name?: string(name='Name', description='The name.', example='Workflow1'),
        owner?: string(name='Owner', description='The account ID of the owner.', example='1000'),
        parameters?: string(name='Parameters', description='The parameters.', example='para1=$bizdate para2=$[yyyymmdd]'),
        projectId?: long(name='ProjectId', description='The workspace ID.', example='100'),
        trigger?: {
          cron?: string(name='Cron', description='The CRON expression. This parameter takes effect only if the Type parameter is set to Scheduler.', example='00 00 00 * * ?'),
          endTime?: string(name='EndTime', description='The end time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='9999-01-01 00:00:00'),
          recurrence?: string(name='Recurrence', description='The running mode of the workflow after it is triggered. This parameter takes effect only if the Type parameter is set to Scheduler. Valid values:

*   Pause
*   Skip
*   Normal', example='Normal'),
          startTime?: string(name='StartTime', description='The start time of the time range during which the workflow is periodically scheduled. This parameter takes effect only if the Type parameter is set to Scheduler.', example='1970-01-01 00:00:00'),
          type?: string(name='Type', description='The trigger type. Valid values:

*   Scheduler: scheduling cycle-based trigger
*   Manual: manual trigger', example='Scheduler'),
        }(name='Trigger', description='The trigger method.'),
      }
    ](name='Workflows', description='The workflows.'),
  }(name='PagingInfo', description='The pagination information.'),
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
}

model ListWorkflowsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ListWorkflowsResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ListWorkflows  ListWorkflowsRequest
  * @return ListWorkflowsResponse
 */
async function listWorkflows(request: ListWorkflowsRequest): ListWorkflowsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ListWorkflows', 'POST', '/', 'json', true, 'form', request);
}

model MoveFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='543217824470354XXXX', position='Body'),
  path: string(name='Path', description='The path to which you want to move the UDF. You do not need to specify a UDF name in the path.

For example, if you want to move the test UDF to root/demo/test, you must set this parameter to root/demo.

This parameter is required.', example='root/demo', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='12345', position='Body'),
}

model MoveFunctionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='48C0E2F0-52BA-5888-BDFA-28F1B9AFXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model MoveFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: MoveFunctionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of MoveFunction  MoveFunctionRequest
  * @return MoveFunctionResponse
 */
async function moveFunction(request: MoveFunctionRequest): MoveFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'MoveFunction', 'POST', '/', 'json', true, 'form', request);
}

model MoveNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  path: string(name='Path', description='The path to which you want to move the node. You do not need to specify a node name in the path.

For example, if you want to move the test node to root/demo/test, you must set this parameter to root/demo.

This parameter is required.', example='root/demo', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model MoveNodeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='C99E2BE6-9DEA-5C2E-8F51-1DDCFEADXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model MoveNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: MoveNodeResponseBody(name='body'),
}

/**
  * @param request  the request parameters of MoveNode  MoveNodeRequest
  * @return MoveNodeResponse
 */
async function moveNode(request: MoveNodeRequest): MoveNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'MoveNode', 'POST', '/', 'json', true, 'form', request);
}

model MoveResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the file resource.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  path: string(name='Path', description='The path to which you want to move the file resource. You do not need to specify a file resource name in the path.

For example, if you want to move the test file resource to root/demo/test, you must set this parameter to root/demo.

This parameter is required.', example='root/demo', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model MoveResourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='F332BED4-DD73-5972-A9C2-642BA6CFXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model MoveResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: MoveResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of MoveResource  MoveResourceRequest
  * @return MoveResourceResponse
 */
async function moveResource(request: MoveResourceRequest): MoveResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'MoveResource', 'POST', '/', 'json', true, 'form', request);
}

model MoveWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='543217824470354XXXX', position='Body'),
  path: string(name='Path', description='The path to which you want to move the workflow. You do not need to specify a workflow name in the path.

For example, if you want to move the test workflow to root/demo/test, you must set this parameter to root/demo.

This parameter is required.', example='root/demo', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID. You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10001', position='Body'),
}

model MoveWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='05ADAF4F-7709-5FB1-B606-3513483FXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model MoveWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: MoveWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of MoveWorkflowDefinition  MoveWorkflowDefinitionRequest
  * @return MoveWorkflowDefinitionResponse
 */
async function moveWorkflowDefinition(request: MoveWorkflowDefinitionRequest): MoveWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'MoveWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model RemoveTaskInstanceDependenciesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234', position='Query'),
  upstreamTaskInstanceIds?: [ long ](name='UpstreamTaskInstanceIds', description='The IDs of ancestor instances of the instance', shrink='json', position='Body'),
}

model RemoveTaskInstanceDependenciesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model RemoveTaskInstanceDependenciesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RemoveTaskInstanceDependenciesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of RemoveTaskInstanceDependencies  RemoveTaskInstanceDependenciesRequest
  * @return RemoveTaskInstanceDependenciesResponse
 */
async function removeTaskInstanceDependencies(request: RemoveTaskInstanceDependenciesRequest): RemoveTaskInstanceDependenciesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RemoveTaskInstanceDependencies', 'POST', '/', 'json', true, 'form', request);
}

model RenameFunctionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='543217824470354XXXX', position='Body'),
  name: string(name='Name', description='The new name.

This parameter is required.', example='Rename', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10002', position='Body'),
}

model RenameFunctionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='1ED4C97F-BA2A-57C5-BA7C-8853627EXXXX'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model RenameFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RenameFunctionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RenameFunction  RenameFunctionRequest
  * @return RenameFunctionResponse
 */
async function renameFunction(request: RenameFunctionRequest): RenameFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameFunction', 'POST', '/', 'json', true, 'form', request);
}

model RenameNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  name: string(name='Name', description='The new name.

This parameter is required.', example='Rename', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='12345', position='Body'),
}

model RenameNodeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4CDF7B72-020B-542A-8465-21CFFA81XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model RenameNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RenameNodeResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RenameNode  RenameNodeRequest
  * @return RenameNodeResponse
 */
async function renameNode(request: RenameNodeRequest): RenameNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameNode', 'POST', '/', 'json', true, 'form', request);
}

model RenameResourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the file resource.

This parameter is required.', example='543217824470354XXXX', position='Body'),
  name: string(name='Name', description='The new name.

This parameter is required.', example='Rename', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Body'),
}

model RenameResourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='4CDF7B72-020B-542A-8465-21CFFA8XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model RenameResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RenameResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RenameResource  RenameResourceRequest
  * @return RenameResourceResponse
 */
async function renameResource(request: RenameResourceRequest): RenameResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameResource', 'POST', '/', 'json', true, 'form', request);
}

model RenameWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='463497880880954XXXX', position='Query'),
  name: string(name='Name', description='The new name.

This parameter is required.', example='Rename', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID. You must configure this parameter to specify the DataWorks workspace to which the API operation is applied.

This parameter is required.', example='10000', position='Query'),
}

model RenameWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can troubleshoot issues based on the ID.', example='975BD43D-C421-595C-A29C-565A8AD5XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model RenameWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RenameWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of RenameWorkflowDefinition  RenameWorkflowDefinitionRequest
  * @return RenameWorkflowDefinitionResponse
 */
async function renameWorkflowDefinition(request: RenameWorkflowDefinitionRequest): RenameWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RenameWorkflowDefinition', 'POST', '/', 'json', false, 'json', request);
}

model RerunTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model RerunTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model RerunTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RerunTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of RerunTaskInstances  RerunTaskInstancesRequest
  * @return RerunTaskInstancesResponse
 */
async function rerunTaskInstances(request: RerunTaskInstancesRequest): RerunTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RerunTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model ResumeTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model ResumeTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model ResumeTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ResumeTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of ResumeTaskInstances  ResumeTaskInstancesRequest
  * @return ResumeTaskInstancesResponse
 */
async function resumeTaskInstances(request: ResumeTaskInstancesRequest): ResumeTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ResumeTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model RevokeMemberProjectRolesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the Workspace page to query the ID.

This parameter is required.', example='105149', position='Body'),
  roleCodes: [ string ](name='RoleCodes', description='The codes of the roles in the workspace. You can call the [ListProjectRoles](https://help.aliyun.com/document_detail/2853930.html) operation to query the codes of all roles in the workspace.

You must configure this parameter to specify the roles that you want to revoke from the member in the workspace.

This parameter is required.', shrink='json', position='Body'),
  userId: string(name='UserId', description='The ID of the account used by the member in the workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/product/ms_menu), choose More > Management Center in the left-side navigation pane, select the desired workspace on the Management Center page, and then click Go to Management Center. In the left-side navigation pane of the SettingCenter page, click Tenant Members and Roles. On the Tenant Members and Roles page, view the ID of the account used by the member in the workspace.

This parameter is required.', example='123422344899', position='Body'),
}

model RevokeMemberProjectRolesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='676271D6-53B4-57BE-89FA-72F7AE1418DF'),
}

model RevokeMemberProjectRolesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RevokeMemberProjectRolesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of RevokeMemberProjectRoles  RevokeMemberProjectRolesRequest
  * @return RevokeMemberProjectRolesResponse
 */
async function revokeMemberProjectRoles(request: RevokeMemberProjectRolesRequest): RevokeMemberProjectRolesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RevokeMemberProjectRoles', 'POST', '/', 'json', true, 'form', request);
}

model SetSuccessTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model SetSuccessTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model SetSuccessTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetSuccessTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of SetSuccessTaskInstances  SetSuccessTaskInstancesRequest
  * @return SetSuccessTaskInstancesResponse
 */
async function setSuccessTaskInstances(request: SetSuccessTaskInstancesRequest): SetSuccessTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetSuccessTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model StartDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='10000', deprecated='true', position='Query'),
  forceToRerun?: boolean(name='ForceToRerun', description='Deprecated', example='false', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='10000', position='Query'),
  realtimeStartSettings?: {
    failoverSettings?: {
      interval?: long(name='Interval', description='The failover interval. Unit: minutes.', example='10', deprecated='true'),
      upperLimit?: long(name='UpperLimit', description='The maximum number of failovers allowed.', example='30', deprecated='true'),
    }(name='FailoverSettings', description='The failover settings.', deprecated='true'),
    startTime?: long(name='StartTime', description='The start time.', example='1671516776'),
  }(name='RealtimeStartSettings', description='The settings for starting real-time synchronization.', shrink='json', position='Query'),
}

model StartDIJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='999431B2-6013-577F-B684-36F7433C753B'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model StartDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StartDIJob  StartDIJobRequest
  * @return StartDIJobResponse
 */
async function startDIJob(request: StartDIJobRequest): StartDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartDIJob', 'GET', '/', 'json', false, 'json', request);
}

model StartWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  ids: [ long ](name='Ids', description='The IDs of workflow instances.

This parameter is required.', shrink='json', position='Body'),
}

model StartWorkflowInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17****'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The workflow instance ID serves as a key, and the result serves as a value.'),
}

model StartWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StartWorkflowInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StartWorkflowInstances  StartWorkflowInstancesRequest
  * @return StartWorkflowInstancesResponse
 */
async function startWorkflowInstances(request: StartWorkflowInstancesRequest): StartWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StartWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model StopDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated and is replaced by the Id parameter.', example='11668', deprecated='true', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11668', position='Query'),
  instanceId?: long(name='InstanceId', description='The instance ID.', example='1234', position='Query'),
}

model StopDIJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='92F778C7-8F00-53B1-AE1A-B3B17101247D'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model StopDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StopDIJob  StopDIJobRequest
  * @return StopDIJobResponse
 */
async function stopDIJob(request: StopDIJobRequest): StopDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopDIJob', 'GET', '/', 'json', false, 'json', request);
}

model StopTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model StopTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model StopTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StopTaskInstances  StopTaskInstancesRequest
  * @return StopTaskInstancesResponse
 */
async function stopTaskInstances(request: StopTaskInstancesRequest): StopTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model StopWorkflowInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  ids: [ long ](name='Ids', description='The workflow instance IDs.

This parameter is required.', shrink='json', position='Body'),
}

model StopWorkflowInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17****'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The workflow instance ID serves as a key, and the result serves as a value.'),
}

model StopWorkflowInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopWorkflowInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of StopWorkflowInstances  StopWorkflowInstancesRequest
  * @return StopWorkflowInstancesResponse
 */
async function stopWorkflowInstances(request: StopWorkflowInstancesRequest): StopWorkflowInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopWorkflowInstances', 'POST', '/', 'json', true, 'form', request);
}

model SuspendTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='Remarks.', example='this is a comment', position='Body'),
  ids?: [ long ](name='Ids', description='The ID list of the task instance.', shrink='json', position='Body'),
}

model SuspendTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model SuspendTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SuspendTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of SuspendTaskInstances  SuspendTaskInstancesRequest
  * @return SuspendTaskInstancesResponse
 */
async function suspendTaskInstances(request: SuspendTaskInstancesRequest): SuspendTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SuspendTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model TagDataAssetsRequest {
  regionId?: string(name='RegionId', position='Host'),
  autoTraceEnabled?: boolean(name='AutoTraceEnabled', description='Specifies whether to enable lineage-based automatic backtracking.', example='false', position='Query'),
  dataAssetIds: [ string ](name='DataAssetIds', description='The data asset IDs.

This parameter is required.', shrink='json', position='Query'),
  dataAssetType: string(name='DataAssetType', description='The type of the data asset. Valid values:

*   ACS::DataWorks::Table
*   ACS::DataWorks::Task

This parameter is required.', example='ACS::DataWorks::Task', position='Query'),
  envType?: string(name='EnvType', description='The environment of the workspace to which the data asset belongs. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='10000', position='Query'),
  tags: [ 
    {
      key: string(name='Key', description='The tag key.

This parameter is required.', example='key', minLength=1, maxLength=128),
      value?: string(name='Value', description='The tag value.', example='value', maxLength=128),
    }
  ](name='Tags', description='The tags that you want to add to data assets.

This parameter is required.', shrink='json', position='Query'),
}

model TagDataAssetsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model TagDataAssetsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: TagDataAssetsResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of TagDataAssets  TagDataAssetsRequest
  * @return TagDataAssetsResponse
 */
async function tagDataAssets(request: TagDataAssetsRequest): TagDataAssetsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'TagDataAssets', 'POST', '/', 'json', false, 'json', request);
}

model TriggerSchedulerTaskInstanceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  envType?: string(name='EnvType', description='The environment of the workspace. Valid values:

*   Prod: production environment
*   Dev: development environment', example='Prod', position='Query'),
  taskId: long(name='TaskId', description='The task ID.

This parameter is required.', example='1234', position='Body'),
  triggerTime: long(name='TriggerTime', description='The time defined by the HTTP Trigger node.

This parameter is required.', example='1710239005403', position='Body'),
}

model TriggerSchedulerTaskInstanceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model TriggerSchedulerTaskInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: TriggerSchedulerTaskInstanceResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of TriggerSchedulerTaskInstance  TriggerSchedulerTaskInstanceRequest
  * @return TriggerSchedulerTaskInstanceResponse
 */
async function triggerSchedulerTaskInstance(request: TriggerSchedulerTaskInstanceRequest): TriggerSchedulerTaskInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'TriggerSchedulerTaskInstance', 'POST', '/', 'json', true, 'form', request);
}

model UnTagDataAssetsRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataAssetIds: [ string ](name='DataAssetIds', description='The data asset IDs.

This parameter is required.', shrink='json', position='Query'),
  dataAssetType: string(name='DataAssetType', description='The type of the data asset. Valid values:

*   ACS::DataWorks::Table
*   ACS::DataWorks::Task

This parameter is required.', example='ACS::DataWorks::Task', position='Query'),
  envType?: string(name='EnvType', description='The environment of the workspace to which the data asset belongs. Valid values:

*   Dev: development environment
*   Prod: production environment', example='Prod', position='Query'),
  projectId?: long(name='ProjectId', description='The DataWorks workspace ID.', example='123', position='Query'),
  tags: [ 
    {
      key: string(name='Key', description='The tag key.

This parameter is required.', example='key', minLength=1, maxLength=128),
      value?: string(name='Value', description='The tag value.', example='value', maxLength=128),
    }
  ](name='Tags', description='The tags that you want to remove.

This parameter is required.', shrink='json', position='Query'),
}

model UnTagDataAssetsResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='8754EE08-4AA2-5F77-ADD7-754DBBDA9F75'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UnTagDataAssetsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UnTagDataAssetsResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of UnTagDataAssets  UnTagDataAssetsRequest
  * @return UnTagDataAssetsResponse
 */
async function unTagDataAssets(request: UnTagDataAssetsRequest): UnTagDataAssetsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UnTagDataAssets', 'POST', '/', 'json', false, 'json', request);
}

model UpdateAlertRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the rule.', example='true', position='Query'),
  id?: long(name='Id', description='The rule ID.', example='105412', position='Query'),
  name?: string(name='Name', description='The name of the rule.', example='collection_name', position='Query'),
  notification?: {
    channels?: [ string ](name='Channels', description='The alert notification channels.'),
    intervalInMinutes?: int32(name='IntervalInMinutes', description='The interval at which an alert notification is sent. Unit: minutes. Valid values: [5,10000].', example='30'),
    maximum?: int32(name='Maximum', description='The maximum number of times an alert notification can be sent within a calendar day. Valid values: [1, 10000].', example='3'),
    receivers?: [ 
      {
        extension?: string(name='Extension', description='The additional configuration of the alert recipient. If the ReceiverType parameter is set to DingdingUrl, you can set this parameter to {"atAll":true} to remind all members in a DingTalk group.', example='{"atAll":true}'),
        receiverType?: string(name='ReceiverType', description='The type of the alert recipient. Valid valves:

*   AliUid: Alibaba Cloud account ID.
*   Shift Schedules: the personnel in a shift schedule.
*   TaskOwner: the task owner. The task owner can receive custom alerts and event alerts.
*   Owner: the baseline owner. The baseline owner can receive baseline alerts.
*   WebhookUrl: URL of a custom webhook.
*   DingdingUrl: DingTalk webhook URL.
*   FeishuUrl: Lark webhook URL.
*   WeixinUrl: WeCom webhook URL.', example='TaskOwner'),
        receiverValues?: [ string ](name='ReceiverValues', description='The alert recipients.'),
      }
    ](name='Receivers', description='The alert recipients.'),
    silenceEndTime?: string(name='SilenceEndTime', description='The end time for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
    silenceStartTime?: string(name='SilenceStartTime', description='The start time for silence. The time is in the HH:mm:ss format.', example='00:00:00'),
  }(name='Notification', description='The configuration for the alert notification.', shrink='json', position='Query'),
  owner?: string(name='Owner', description='The ID of the Alibaba Cloud account used by the owner of the rule.', example='193379****', position='Query'),
  triggerCondition?: {
    extension?: {
      cycleUnfinished?: {
        cycleAndTime?: [ 
          {
            cycleId?: int32(name='CycleId', description='The ID of the scheduling cycle of the instance. Valid values: [1,288].', example='1'),
            time?: string(name='Time', description='The latest completion time of the instance within the scheduling cycle. The time is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='01:00'),
          }
        ](name='CycleAndTime', description='The configurations of the scheduling cycle and timeout period of the instance.'),
      }(name='CycleUnfinished', description='The configuration for an alert of the CycleUnfinished type.'),
      error?: {
        autoRerunAlertEnabled?: boolean(name='AutoRerunAlertEnabled', description='Specifies whether to trigger an alert if a batch synchronization task is automatically rerun upon a failure.', example='false'),
        streamTaskIds?: [ long ](name='StreamTaskIds', description='The IDs of the real-time computing tasks. This parameter is required when you monitor real-time computing tasks.'),
      }(name='Error', description='The configuration for an alert of the Error type.'),
      instanceErrorCount?: {
        count?: int32(name='Count', description='The maximum number of instances on which an error occurs. Valid values: [1,10000].', example='10'),
      }(name='InstanceErrorCount', description='The configuration for an alert of the InstanceErrorCount type.'),
      instanceErrorPercentage?: {
        percentage?: int32(name='Percentage', description='The maximum percentage of instances on which an error occurs in the workspace to the total number of instances. Valid values: [1-100].', example='10'),
      }(name='InstanceErrorPercentage', description='The configuration for an alert of the InstanceErrorPercentage type.'),
      instanceTransferFluctuate?: {
        percentage?: int32(name='Percentage', description='The maximum percentage of fluctuation in the number of auto triggered node instances that are generated in your workspace. Valid values: [1-100].', example='10'),
        trend?: string(name='Trend', description='The way in which the number of auto triggered node instances that are generated in your workspace fluctuates. Valid values:

*   abs: the absolute value. The number of instances increases or decreases.
*   increase: The number of instances increases.
*   decrease: The number of instances decreases.', example='abs'),
      }(name='InstanceTransferFluctuate', description='The configuration for an alert of the InstanceTransferFluctuate type.'),
      timeout?: {
        timeoutInMinutes?: int32(name='TimeoutInMinutes', description='The timeout period. Unit: minutes.', example='10'),
      }(name='Timeout', description='The configuration for an alert of the Timeout type.'),
      unFinished?: {
        unFinishedTime?: string(name='UnFinishedTime', description='The latest completion time of the instance. The period is in the hh:mm format. Valid values of hh: [0,47]. Valid values of mm: [0,59].', example='12:00'),
      }(name='UnFinished', description='The configuration for an alert of the UnFinished type.'),
    }(name='Extension', description='The extended information about the rule. This parameter is required for specific types of alerts.'),
    target?: {
      allowTasks?: [ long ](name='AllowTasks', description='The nodes that are not to be monitored.'),
      ids?: [ long ](name='Ids', description='The IDs of monitored objects.'),
      type?: string(name='Type', description='The type of the monitored objects. Valid values:

*   Task: node
*   Baseline: baseline
*   project: workspace
*   BizProcess: workflow', example='Task'),
    }(name='Target', description='The monitored objects.'),
    type?: string(name='Type', description='The alert type. Valid values:

*   Finished: An instance is successfully run.
*   UnFinished: An instance does not finish running before a specified point in time.
*   Error: An error occurs on an instance.
*   CycleUnfinished: An instance does not finish running as expected within a specific cycle.
*   Timeout: An instance times out.
*   InstanceTransferComplete: An instance is generated by the auto triggered node.
*   InstanceTransferFluctuate: The number of generated instances fluctuates.
*   ExhaustedError: An error persists after an instance is automatically rerun.
*   InstanceKeyword: An instance with errors contains specified keywords.
*   InstanceErrorCount: The number of instances on which an error occurs reaches a specified threshold.
*   InstanceErrorPercentage: The proportion of instances on which an error occurs in the workspace to the total number of instances reaches a specified threshold.
*   ResourceGroupPercentage: The usage rate of the resource group reaches a specified threshold.
*   ResourceGroupWaitCount: The number of instances that are waiting for resources in the resource group reaches a specified threshold.', example='ERROR'),
  }(name='TriggerCondition', description='The alert triggering condition.', shrink='json', position='Query'),
}

model UpdateAlertRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='D85FEE2B-6174-5817-AF9E-FDD02FEDA5BC'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateAlertRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAlertRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateAlertRule  UpdateAlertRuleRequest
  * @return UpdateAlertRuleResponse
 */
async function updateAlertRule(request: UpdateAlertRuleRequest): UpdateAlertRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateAlertRule', 'POST', '/', 'json', false, 'json', request);
}

model UpdateDIAlarmRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIAlarmRuleId?: long(name='DIAlarmRuleId', description='This parameter is deprecated. Use the Id parameter instead.', example='34982', deprecated='true', position='Query'),
  DIJobId?: long(name='DIJobId', description='The ID of the synchronization task.', example='1', position='Query'),
  description?: string(name='Description', description='The description of the alert rule.', example='The description of the alert rule.', position='Query'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the alert rule. By default, the alert rule is disabled.', example='true', position='Query'),
  id?: long(name='Id', description='The alert rule Id', example='34982', position='Query'),
  metricType?: string(name='MetricType', description='The metric type in the alert rule. Valid values:

*   Heartbeat
*   FailoverCount
*   Delay
*   DdlReport
*   ResourceUtilization', example='Heartbeat', position='Query'),
  name?: string(name='Name', description='The name of the alert rule.', example='alarm_rule_name', position='Query'),
  notificationSettings?: {
    inhibitionInterval?: long(name='InhibitionInterval', description='The duration of the alert suppression interval. Default value: 5. Unit: minutes.', example='5', deprecated='true'),
    muteInterval?: long(name='MuteInterval', description='The duration of the alert suppression interval. Default value: 5. Unit: minutes.', example='5'),
    notificationChannels?: [ 
      {
        channels?: [ string ](name='Channels', description='The alert notification method. Valid values:

*   Mail
*   Phone
*   Sms
*   Ding'),
        severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Warning'),
      }
    ](name='NotificationChannels', description='The alert notification methods.'),
    notificationReceivers?: [ 
      {
        receiverType?: string(name='ReceiverType', description='The recipient type. Valid values: AliyunUid, DingToken, FeishuToken, and WebHookUrl.', example='DingToken'),
        receiverValues?: [ string ](name='ReceiverValues', description='The recipient.

*   If the ReceiverType parameter is set to AliyunUid, set this parameter to the Alibaba Cloud account ID of a user.
*   If the ReceiverType parameter is set to DingToken, set this parameter to the token of a DingTalk chatbot.'),
      }
    ](name='NotificationReceivers', description='The settings of alert notification recipients.'),
  }(name='NotificationSettings', description='The alert notification settings.', shrink='json', position='Query'),
  triggerConditions?: [ 
    {
      ddlReportTags?: [ string ](name='DdlReportTags', description='The types of DDL operations for which the alert rule takes effect.', deprecated='true'),
      ddlTypes?: [ string ](name='DdlTypes', description='The types of DDL operations for which the alert rule takes effect.'),
      duration?: long(name='Duration', description='The time interval for alert calculation. Unit: minutes.', example='15'),
      severity?: string(name='Severity', description='The severity level. Valid values:

*   Warning
*   Critical', example='Warning'),
      threshold?: long(name='Threshold', description='The alert threshold.

*   If the alert rule is for task status, you do not need to specify a threshold.
*   If the alert rule is for failovers, you must specify the number of failovers.
*   If the alert rule is for latency, you must specify the latency duration, in seconds.', example='5'),
    }
  ](name='TriggerConditions', description='The conditions that can trigger the alert rule.', shrink='json', position='Query'),
}

model UpdateDIAlarmRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='A6C6B486-E3A2-5D52-9E76-D9380485D946'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateDIAlarmRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDIAlarmRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateDIAlarmRule  UpdateDIAlarmRuleRequest
  * @return UpdateDIAlarmRuleResponse
 */
async function updateDIAlarmRule(request: UpdateDIAlarmRuleRequest): UpdateDIAlarmRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDIAlarmRule', 'GET', '/', 'json', false, 'json', request);
}

model UpdateDIJobRequest {
  regionId?: string(name='RegionId', position='Host'),
  DIJobId?: long(name='DIJobId', description='This parameter is deprecated. Use the Id parameter instead.', example='11588', deprecated='true', position='Query'),
  description?: string(name='Description', description='The description of the synchronization task.', example='The description of the synchronization task.', position='Query'),
  id?: long(name='Id', description='The ID of the synchronization task.', example='11588', position='Query'),
  jobSettings?: {
    channelSettings?: string(name='ChannelSettings', description='The channel control settings for the synchronization task. The value of this parameter must be a JSON string.', example='{"structInfo":"MANAGED","storageType":"TEXTFILE","writeMode":"APPEND","partitionColumns":[{"columnName":"pt","columnType":"STRING","comment":""}],"fieldDelimiter":""}'),
    columnDataTypeSettings?: [ 
      {
        destinationDataType?: string(name='DestinationDataType', description='The data type of the destination field.', example='text'),
        sourceDataType?: string(name='SourceDataType', description='The data type of the source field.', example='bigint'),
      }
    ](name='ColumnDataTypeSettings', description='The data type mappings between source fields and destination fields.'),
    cycleScheduleSettings?: {
      scheduleParameters?: string(name='ScheduleParameters', description='The scheduling parameters.', example='bizdate=$bizdate'),
    }(name='CycleScheduleSettings', description='The settings for periodic scheduling.'),
    ddlHandlingSettings?: [ 
      {
        action?: string(name='Action', description='The processing policy. Valid values:

*   Ignore: ignores a DDL message.
*   Critical: reports an error for a DDL message.
*   Normal: normally processes a DDL message.', example='Critical'),
        type?: string(name='Type', description='The type of the DDL operation. Valid values:

*   RenameColumn
*   ModifyColumn
*   CreateTable
*   TruncateTable
*   DropTable
*   DropColumn
*   AddColumn', example='AddColumn'),
      }
    ](name='DdlHandlingSettings', description='The processing settings for DDL messages.'),
    runtimeSettings?: [ 
      {
        name?: string(name='Name', description='The name of the configuration item. Valid values:

*   runtime.offline.speed.limit.mb: indicates the maximum transmission rate that is allowed for a batch synchronization task. This configuration item takes effect only when runtime.offline.speed.limit.enable is set to true.
*   runtime.offline.speed.limit.enable: indicates whether throttling is enabled for a batch synchronization task.
*   dst.offline.connection.max: indicates the maximum number of connections that are allowed for writing data to the destination of a batch synchronization task.
*   runtime.offline.concurrent: indicates the maximum number of parallel threads that are allowed for a batch synchronization task.
*   dst.realtime.connection.max: indicates the maximum number of connections that are allowed for writing data to the destination of a real-time synchronization task.
*   runtime.enable.auto.create.schema: indicates whether schemas are automatically created in the destination of a synchronization task.
*   src.offline.datasource.max.connection: indicates the maximum number of connections that are allowed for reading data from the source of a batch synchronization task.
*   runtime.realtime.concurrent: indicates the maximum number of parallel threads that are allowed for a real-time synchronization task.', example='runtime.offline.concurrent'),
        value?: string(name='Value', description='The value of the configuration item.', example='1'),
      }
    ](name='RuntimeSettings', description='The runtime settings.'),
  }(name='JobSettings', description='The settings for the dimension of the synchronization task. The settings include processing policies for DDL messages, policies for data type mappings between source fields and destination fields, and runtime parameters of the synchronization task.', shrink='json', position='Query'),
  projectId?: long(name='ProjectId', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to obtain the workspace ID.

You must configure this parameter to specify the DataWorks workspace to which the operation is applied.', example='10000', position='Query'),
  resourceSettings?: {
    offlineResourceSettings?: {
      requestedCu?: double(name='RequestedCu', description='The number of compute units (CUs) in the resource group for Data Integration that are used for batch synchronization.', example='2.0'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for Data Integration used for batch synchronization.', example='S_res_group_111_222'),
    }(name='OfflineResourceSettings', description='The resource used for batch synchronization.'),
    realtimeResourceSettings?: {
      requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for Data Integration that are used for real-time synchronization.', example='2.0'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for Data Integration used for real-time synchronization.', example='S_res_group_111_222'),
    }(name='RealtimeResourceSettings', description='The resource used for real-time synchronization.'),
    scheduleResourceSettings?: {
      requestedCu?: double(name='RequestedCu', description='The number of CUs in the resource group for scheduling that are used for batch synchronization.', example='2.0'),
      resourceGroupIdentifier?: string(name='ResourceGroupIdentifier', description='The identifier of the resource group for scheduling used for batch synchronization.', example='S_res_group_235454102432001_1721021993437'),
    }(name='ScheduleResourceSettings', description='The resource used for scheduling.'),
  }(name='ResourceSettings', description='The resource settings.', shrink='json', position='Query'),
  tableMappings?: [ 
    {
      sourceObjectSelectionRules?: [ 
        {
          action?: string(name='Action', description='The operation that is performed to select objects. Valid values: Include and Exclude.', example='Include'),
          expression?: string(name='Expression', description='The expression.', example='mysql_table_1'),
          expressionType?: string(name='ExpressionType', description='The expression type. Valid values: Exact and Regex.', example='Exact'),
          objectType?: string(name='ObjectType', description='The object type. Valid values:

*   Table
*   Database', example='Table'),
        }
      ](name='SourceObjectSelectionRules', description='The list of rules used to select synchronization objects in the source. The objects can be databases or tables.'),
      transformationRules?: [ 
        {
          ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml', example='Rename'),
          ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
          ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which you want to perform the action. Valid values:

*   Table
*   Schema', example='Table'),
        }
      ](name='TransformationRules', description='The list of transformation rules that you want to apply to the synchronization objects selected from the source. Each entry in the list defines a transformation rule.'),
    }
  ](name='TableMappings', description='The list of mappings between rules used to select synchronization objects in the source and transformation rules applied to the selected synchronization objects. Each entry in the list displays a mapping between a rule used to select synchronization objects and a transformation rule applied to the selected synchronization objects.', shrink='json', position='Query'),
  transformationRules?: [ 
    {
      ruleActionType?: string(name='RuleActionType', description='The action type. Valid values:

*   DefinePrimaryKey
*   Rename
*   AddColumn
*   HandleDml', example='Rename'),
      ruleExpression?: string(name='RuleExpression', description='The expression of the rule. The expression must be a JSON string.

Example of a renaming rule: {"expression":"${srcDatasourceName}_${srcDatabaseName}_0922","variables":[{"variableName":"srcDatabaseName","variableRules":[{"from":"fromdb","to":"todb"}]}]}.

expression: the expression of the renaming rule. The expression may contain the following variables: ${srcDatasourceName}, ${srcDatabaseName}, and ${srcTableName}. ${srcDatasourceName} indicates the name of the source. ${srcDatabaseName} indicates the name of a source database. ${srcTableName} indicates the name of a source table. variables: the generation rule for a variable used in the expression of the renaming rule. The default value of the specified variable is the original value of the object indicated by the variable. You can define a group of string replacement rules to change the original values based on your business requirements. variableName: the name of the variable. The variable name cannot be enclosed in ${}. variableRules: the string replacement rules for variables. The system runs the string replacement rules in sequence. from specifies the original string. to specifies the new string. Example of a rule used to add a specific field to the destination and assign a value to the field: {"columns":[{"columnName":"my_add_column","columnValueType":"Constant","columnValue":"123"}]}.

If you do not configure such a rule, no fields are added to the destination and no values are assigned by default. columnName: the name of the field that you want to add. columnValueType: the value type of the field. Valid values: Constant and Variable. columnValue: the value of the field. If you set the valueType parameter to Constant, set the columnValue parameter to a custom constant of the STRING type. If you set the valueType parameter to Variable, set the columnValue to a built-in variable. The following built-in variables are supported: EXECUTE_TIME (LONG data type), DB_NAME_SRC (STRING data type), DATASOURCE_NAME_SRC (STRING data type), TABLE_NAME_SRC (STRING data type), DB_NAME_DEST (STRING data type), DATASOURCE_NAME_DEST (STRING data type), TABLE_NAME_DEST (STRING data type), and DB_NAME_SRC_TRANSED (STRING data type). EXECUTE_TIME specifies the execution time. DB_NAME_SRC indicates the name of a source database. DATASOURCE_NAME_SRC specifies the name of the source. TABLE_NAME_SRC specifies the name of a source table. DB_NAME_DEST specifies the name of a destination database. DATASOURCE_NAME_DEST specifies the name of the destination. TABLE_NAME_DEST specifies the name of a destination table. DB_NAME_SRC_TRANSED specifies the database name obtained after a transformation. Example of a rule used to specify primary key fields for a destination table: {"columns":["ukcolumn1","ukcolumn2"]}.

If you do not configure such a rule, the primary key fields in the mapped source table are used for the destination table by default. If the destination table is an existing table, Data Integration does not modify the schema of the destination table. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run. If the destination table is automatically created by the system, Data Integration automatically creates the schema of the destination table. The schema contains the primary key fields that you specify. If the specified primary key fields do not exist in the destination table, an error is reported when the synchronization task starts to run. Example of a rule used to process DML messages: {"dmlPolicies":[{"dmlType":"Delete","dmlAction":"Filter","filterCondition":"id > 1"}]}.

If you do not configure such a rule, the default processing policy for messages generated for insert, update, and delete operations is Normal. dmlType: the DML operation. Valid values: Insert, Update, and Delete. dmlAction: the processing policy for DML messages. Valid values: Normal, Ignore, Filter, and LogicalDelete. Filter indicates conditional processing. You can set the dmlAction parameter to Filter only when the dmlType parameter is set to Update or Delete. filterCondition: the condition used to filter DML messages. This parameter is required only when the dmlAction parameter is set to Filter.', example='{"expression":"${srcDatasoureName}_${srcDatabaseName}"}'),
      ruleName?: string(name='RuleName', description='The name of the rule. If the values of the RuleActionType parameter and the RuleTargetType parameter are the same for multiple transformation rules, you must make sure that the transformation rule names are unique.', example='rename_rule_1'),
      ruleTargetType?: string(name='RuleTargetType', description='The type of the object on which you want to perform the action. Valid values:

*   Table
*   Schema', example='Table'),
    }
  ](name='TransformationRules', description='The list of transformation rules for objects involved in the synchronization task. Each entry in the list defines a transformation rule.', shrink='json', position='Query'),
}

model UpdateDIJobResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='AAC30B35-820D-5F3E-A42C-E96BB6379325'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateDIJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDIJobResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateDIJob  UpdateDIJobRequest
  * @return UpdateDIJobResponse
 */
async function updateDIJob(request: UpdateDIJobRequest): UpdateDIJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDIJob', 'GET', '/', 'json', false, 'json', request);
}

model UpdateDataAssetTagRequest {
  regionId?: string(name='RegionId', position='Host'),
  description?: string(name='Description', description='The description of the tag.', example='This is a description.', maxLength=1024, position='Query'),
  key: string(name='Key', description='The tag key.

This parameter is required.', example='key1', minLength=1, maxLength=128, position='Query'),
  managers?: [ string ](name='Managers', description='The tag administrators.', shrink='json', position='Query'),
  values?: [ string ](name='Values', description='The tag values.', shrink='json', position='Query'),
}

model UpdateDataAssetTagResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='0bc1ec92159376'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateDataAssetTagResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataAssetTagResponseBody(name='body'),
}

/**
  * @description This API operation is available only for DataWorks Enterprise Edition or a more advanced edition.
  * @param request  the request parameters of UpdateDataAssetTag  UpdateDataAssetTagRequest
  * @return UpdateDataAssetTagResponse
 */
async function updateDataAssetTag(request: UpdateDataAssetTagRequest): UpdateDataAssetTagResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataAssetTag', 'POST', '/', 'json', false, 'json', request);
}

model UpdateDataQualityEvaluationTaskRequest {
  regionId?: string(name='RegionId', position='Host'),
  dataQualityRules?: [ 
    {
      checkingConfig?: {
        referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain specific types of thresholds, you must query reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{"bizdate": ["-1"]}'),
        thresholds?: {
          critical?: {
            expression?: string(name='Expression', description='阈值表达式。

波动率类型规则必须使用表达式方式表示波动阈值。如：

- 波动上升大于0.01： $checkValue > 0.01 
- 波动下降大于0.01：$checkValue < -0.01 
- 波动率绝对值：abs($checkValue) > 0.01

固定值类型规则也可以使用表达式方式配置阈值，如果同时配置，表达式优先级高于Operator和Value', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
            value?: string(name='Value', description='The threshold value.', example='0.01'),
          }(name='Critical', description='The threshold settings for critical alerts.'),
          expected?: {
            expression?: string(name='Expression', description='阈值表达式。

波动率类型规则必须使用表达式方式表示波动阈值。如：

- 波动上升大于0.01： $checkValue > 0.01 
- 波动下降大于0.01：$checkValue < -0.01 
- 波动率绝对值：abs($checkValue) > 0.01

固定值类型规则也可以使用表达式方式配置阈值，如果同时配置，表达式优先级高于Operator和Value', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='='),
            value?: string(name='Value', description='The threshold value.', example='0'),
          }(name='Expected', description='The expected threshold setting.'),
          warned?: {
            expression?: string(name='Expression', description='阈值表达式。

波动率类型规则必须使用表达式方式表示波动阈值。如：

- 波动上升大于0.01： $checkValue > 0.01 
- 波动下降大于0.01：$checkValue < -0.01 
- 波动率绝对值：abs($checkValue) > 0.01

固定值类型规则也可以使用表达式方式配置阈值，如果同时配置，表达式优先级高于Operator和Value', example='$checkValue > 0.01'),
            operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
            value?: string(name='Value', description='The threshold value.', example='0.001'),
          }(name='Warned', description='The threshold settings for normal alerts.'),
        }(name='Thresholds', description='The threshold settings.'),
        type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fluctuation
*   Auto
*   FluctationDiscreate
*   Average
*   Fixed', example='Fixed'),
      }(name='CheckingConfig', description='The check settings for sample data.'),
      description?: string(name='Description', description='The description of the rule.', example='OpenAPI test rules', maxLength=500),
      enabled?: boolean(name='Enabled', description='Specifies whether to enable the rule.', example='true'),
      errorHandlers?: [ 
        {
          errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If you define the rule by using custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM ods_d_openapi_log WHERE status = \\"Error\\"'),
          type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
        }
      ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.'),
      id?: long(name='Id', description='The rule ID. You can call the [ListQualityRules](https://help.aliyun.com/document_detail/173995.html) operation to query the ID of the monitoring rule.', example='1022171560'),
      name?: string(name='Name', description='The name of the monitoring rule.', example='OpenAPI test rules', maxLength=255),
      samplingConfig?: {
        metric?: string(name='Metric', description='The metrics used for sampling.
Valid values:

*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   TableSize: the table size.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   Max: the maximum value of the field.
*   GroupCount: the field value and the number of rows for each field value.
*   Count: the number of rows in the table.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   Min: the minimum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   NullValueCount: the number of rows in which the field value is null.
*   UserDefinedSql: specifies that data is sampled by executing custom SQL statements.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.', example='CountNotIn'),
        metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
        samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='status != \\"Succeeded\\"'),
        settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='odps.sql.type.system.odps2=True,odps.sql.hive.compatible=True', maxLength=1000),
      }(name='SamplingConfig', description='The parameters required for sampling.'),
      severity?: string(name='Severity', description='The strength of the rule. Valid values:

*   Normal
*   High', example='Normal'),
      templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='SYSTEM:field:null_value:fixed:0'),
    }
  ](name='DataQualityRules', description='The list of monitoring rules that are associated with the monitor.', shrink='json', position='Body'),
  dataSourceId?: long(name='DataSourceId', description='The data source ID. You can call the [ListDataSources](https://help.aliyun.com/document_detail/211431.html) operation to query the ID.', example='358750', position='Body'),
  description?: string(name='Description', description='The description of the monitor.', example='OpenAPI data quality monitoring test.', maxLength=65535, position='Body'),
  hooks?: [ 
    {
      condition?: string(name='Condition', description='The hook trigger condition. When this condition is met, the hook action is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as ${severity} == "High" AND ${status} == "Critical". In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as (${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error"). In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='${severity} == "High" AND ${status} == "Critical"'),
      type?: string(name='Type', description='The hook type. Valid values:

*   BlockTaskInstance: Blocks the running of scheduling tasks.', example='ByScheduledTaskInstance'),
    }
  ](name='Hooks', description='The hook.', shrink='json', position='Body'),
  id: long(name='Id', description='The ID of the monitor.

This parameter is required.', example='7227061794', position='Body'),
  name?: string(name='Name', description='The name of the monitor.', example='OpenAPI data quality monitoring test.', maxLength=255, position='Body'),
  notifications?: {
    condition?: string(name='Condition', description='The notification trigger condition. When this condition is met, the alert notification is triggered. Only two conditional expressions are supported:

*   Specify only one group of rule strength type and rule check status, such as ${severity} == "High" AND ${status} == "Critical". In this expression, the hook trigger condition is met if severity is High and status is Critical.
*   Specify multiple groups of rule strength types and rule check status, such as (${severity} == "High" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Critical") OR (${severity} == "Normal" AND ${status} == "Error"). In this expression, the hook trigger condition is met if severity is High and status is Critical, severity is Normal and status is Critical, or severity is Normal and status is Error. The enumeration of severity in a conditional expression is the same as the enumeration of severity in DataQualityRule. The enumeration of status in a conditional expression is the same as the enumeration of status in DataQualityResult.', example='${severity} == "High" AND ${status} == "Critical"'),
    notifications?: [ 
      {
        notificationChannels?: [ 
          {
            channels?: [ string ](name='Channels', description='The alert notification methods.'),
          }
        ](name='NotificationChannels', description='The alert notification methods.'),
        notificationReceivers?: [ 
          {
            extension?: string(name='Extension', description='The additional parameters that are required when alerts are sent. The parameters are JSON-formatted strings. The following keys are supported:

*   atAll: specifies that all members in a group are mentioned when alerts are sent by using DingTalk. This parameter is valid only if you set ReceiverType to DingdingUrl.

Valid values:

*   WebhookUrl
*   FeishuUrl
*   DingdingUrl
*   WeixinUrl
*   AliUid', example='{  "atAll": true }'),
            receiverType?: string(name='ReceiverType', description='The type of the alert recipient.', example='DingdingUrl'),
            receiverValues?: [ string ](name='ReceiverValues', description='The alert recipient.'),
          }
        ](name='NotificationReceivers', description='The configurations of alert recipients.'),
      }
    ](name='Notifications', description='The configurations of the alert notification.'),
  }(name='Notifications', description='The configurations of alert notifications.', shrink='json', position='Body'),
  projectId: long(name='ProjectId', description='The ID of the DataWorks workspace.

This parameter is required.', example='10000', position='Body'),
  runtimeConf?: string(name='RuntimeConf', description='The extended configurations in JSON-formatted strings. You can use this parameter only for monitors that are used to monitor the quality of E-MapReduce (EMR) data.

*   queue: The Yarn queue used when a monitor checks the quality of EMR data. By default, the queue configured for the current workspace is used.

*   sqlEngine: The SQL engine used when a monitor checks the quality of EMR data.

    *   HIVE_SQL
    *   SPARK_SQL', example='{ "queue": "default", "sqlEngine": "SPARK_SQL" }', position='Body'),
  target?: {
    databaseType?: string(name='DatabaseType', description='The type of the database to which the table belongs. Valid values:

*   maxcompute
*   hologres
*   cdh
*   analyticdb_for_mysql
*   starrocks
*   emr
*   analyticdb_for_postgresql', example='maxcompute'),
    partitionSpec?: string(name='PartitionSpec', description='The configuration of the partitioned table.', example='dt=$[yyyymmdd-1]', maxLength=255),
    tableGuid?: string(name='TableGuid', description='The ID of the table in Data Map.', example='odsp.openapi.ods_d_openapi_log'),
  }(name='Target', description='The monitored object of the data quality monitoring task.', shrink='json', position='Body'),
  trigger?: {
    taskIds?: [ long ](name='TaskIds', description='The IDs of scheduling tasks. This parameter is valid only if you set Type to ByScheduledTaskInstance.'),
    type?: string(name='Type', description='The trigger type of the monitor. Valid values:

*   ByScheduledTaskInstance: The monitor is triggered by the associated scheduling tasks.
*   ByManual: The monitor is manually triggered.', example='ByScheduledTaskInstance'),
  }(name='Trigger', description='The trigger configuration of the monitor.', shrink='json', position='Body'),
}

model UpdateDataQualityEvaluationTaskResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can use the ID to query logs and troubleshoot issues.', example='8abcb91f-d266-4073-b907-2ed670378ed1'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateDataQualityEvaluationTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataQualityEvaluationTaskResponseBody(name='body'),
}

/**
  * @description This API operation is supported in all DataWorks editions.
  * @param request  the request parameters of UpdateDataQualityEvaluationTask  UpdateDataQualityEvaluationTaskRequest
  * @return UpdateDataQualityEvaluationTaskResponse
 */
async function updateDataQualityEvaluationTask(request: UpdateDataQualityEvaluationTaskRequest): UpdateDataQualityEvaluationTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataQualityEvaluationTask', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDataQualityRuleRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    thresholds?: {
      critical?: {
        expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue > 0.05'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Critical', description='The threshold settings for critical alerts.'),
      expected?: {
        expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue <= 0.01'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Expected', description='The expected threshold setting.'),
      warned?: {
        expression?: string(name='Expression', description='The threshold expression.

The volatility type rule must use an expression to represent the volatility threshold. For example:

- Fluctuation rise greater than 0.01: $checkValue > 0.01
- Fluctuation drop greater than 0.01:$checkValue < -0.01
- Absolute volatility: abs($checkValue) > 0.01

You can also use expressions to configure thresholds for fixed-Value rules. If you configure them at the same time, the expression priority is higher than Operator and Value.', example='$checkValue > 0.01'),
        operator?: string(name='Operator', description='The comparison operator. Valid values:

*   \\>
*   \\>=
*   <
*   <=
*   !=
*   \\=', example='>'),
        value?: string(name='Value', description='The threshold value.', example='100.0'),
      }(name='Warned', description='The threshold settings for normal alerts.'),
    }(name='Thresholds', description='The threshold settings.'),
    type?: string(name='Type', description='The threshold calculation method. Valid values:

*   Fixed
*   Fluctation
*   FluctationDiscreate
*   Auto
*   Average
*   Variance', example='Fixed'),
  }(name='CheckingConfig', description='The check settings for sample data.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description of the rule. The description can be up to 500 characters in length.', example='this is a odps _sql task', maxLength=500, position='Body'),
  enabled?: boolean(name='Enabled', description='Specifies whether to enable the rule.', example='true', position='Body'),
  errorHandlers?: [ 
    {
      errorDataFilter?: string(name='ErrorDataFilter', description='The SQL statement that is used to filter failed tasks. If the rule is defined by custom SQL statements, you must specify an SQL statement to filter failed tasks.', example='SELECT * FROM tb_api_log WHERE id IS NULL'),
      type?: string(name='Type', description='The type of the operation. Valid values:

*   SaveErrorData', example='SaveErrorData'),
    }
  ](name='ErrorHandlers', description='The operations that you can perform after the rule-based check fails.', shrink='json', position='Body'),
  id: long(name='Id', description='The rule ID.

This parameter is required.', example='100001', position='Body'),
  name?: string(name='Name', description='The name of the rule. The name can be up to 255 characters in length and can contain digits, letters, and punctuation marks.', example='The table cannot be empty.', maxLength=255, position='Body'),
  projectId: long(name='ProjectId', description='This parameter is required.', position='Query'),
  samplingConfig?: {
    metric?: string(name='Metric', description='The metrics used for sampling. You can leave this parameter empty if you use a rule template. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='Min'),
    metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{ "Columns": [ "id", "name" ] , "SQL": "select count(1) from table;"}'),
    samplingFilter?: string(name='SamplingFilter', description='The statements that are used to filter unnecessary data during sampling. The statements can be up to 16,777,215 characters in length.', example='id IS NULL'),
    settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;', maxLength=1000),
  }(name='SamplingConfig', description='The sampling settings.', shrink='json', position='Body'),
  severity?: string(name='Severity', description='The strength of the rule.

*   Normal
*   High', example='High', position='Body'),
  templateCode?: string(name='TemplateCode', description='The ID of the template used by the rule.', example='system::user_defined', position='Body'),
}

model UpdateDataQualityRuleResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='691CA452-D37A-4ED0-9441'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateDataQualityRuleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataQualityRuleResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateDataQualityRule  UpdateDataQualityRuleRequest
  * @return UpdateDataQualityRuleResponse
 */
async function updateDataQualityRule(request: UpdateDataQualityRuleRequest): UpdateDataQualityRuleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataQualityRule', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDataQualityRuleTemplateRequest {
  regionId?: string(name='RegionId', position='Host'),
  checkingConfig?: {
    referencedSamplesFilter?: string(name='ReferencedSamplesFilter', description='The method that is used to query the referenced samples. To obtain some types of thresholds, you need to query reference samples and perform aggregate operations on the reference values. In this example, an expression is used to specify the query method of referenced samples.', example='{ "bizdate": [ "-1", "-7", "-1m" ] }'),
    type?: string(name='Type', description='The type of the monitored object. Valid values:

*   Table', example='Table'),
  }(name='CheckingConfig', description='The check settings for sample data.', shrink='json', position='Body'),
  code: string(name='Code', description='The code for the template.

This parameter is required.', example='USER_DEFINED:123', position='Body'),
  directoryPath?: string(name='DirectoryPath', description='The directory in which the template is stored. Slashes (/) are used to separate directory levels. The name of each directory level can be up to 1,024 characters in length. It cannot contain whitespace characters or slashes (/).', example='/ods/order_data', position='Body'),
  name?: string(name='Name', description='The name of the template. The name can be up to 512 characters in length and can contain digits, letters, and punctuation marks.', example='Table row Count Verification', maxLength=128, position='Body'),
  projectId: long(name='ProjectId', description='This parameter is required.', position='Query'),
  samplingConfig?: {
    metric?: string(name='Metric', description='The metrics used for sampling. Valid values:

*   Count: the number of rows in the table.
*   Min: the minimum value of the field.
*   Max: the maximum value of the field.
*   Avg: the average value of the field.
*   DistinctCount: the number of unique values of the field after deduplication.
*   DistinctPercent: the proportion of the number of unique values of the field after deduplication to the number of rows in the table.
*   DuplicatedCount: the number of duplicated values of the field.
*   DuplicatedPercent: the proportion of the number of duplicated values of the field to the number of rows in the table.
*   TableSize: the table size.
*   NullValueCount: the number of rows in which the field value is null.
*   NullValuePercent: the proportion of the number of rows in which the field value is null to the number of rows in the table.
*   GroupCount: the field value and the number of rows for each field value.
*   CountNotIn: the number of rows in which the field values are different from the referenced values that you specified in the rule.
*   CountDistinctNotIn: the number of unique values that are different from the referenced values that you specified in the rule after deduplication.
*   UserDefinedSql: indicates that data is sampled by executing custom SQL statements.', example='Max'),
    metricParameters?: string(name='MetricParameters', description='The parameters required for sampling.', example='{"SQL": "select count(1) from table;"}'),
    settingConfig?: string(name='SettingConfig', description='The statements that are used to configure the parameters required for sampling before you execute the sampling statements. The statements can be up to 1,000 characters in length. Only the MaxCompute database is supported.', example='SET odps.sql.udf.timeout=600s; 
SET odps.sql.python.version=cp27;', maxLength=1000),
  }(name='SamplingConfig', description='The sampling settings.', shrink='json', position='Body'),
}

model UpdateDataQualityRuleTemplateResponseBody = {
  requestId?: string(name='RequestId', description='Id of the request', example='691CA452-D37A-4ED0-9441'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateDataQualityRuleTemplateResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataQualityRuleTemplateResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateDataQualityRuleTemplate  UpdateDataQualityRuleTemplateRequest
  * @return UpdateDataQualityRuleTemplateResponse
 */
async function updateDataQualityRuleTemplate(request: UpdateDataQualityRuleTemplateRequest): UpdateDataQualityRuleTemplateResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataQualityRuleTemplate', 'POST', '/', 'json', true, 'form', request);
}

model UpdateDataSourceRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  connectionProperties: string(name='ConnectionProperties', description='The connection configurations of the data source, including the connection address, access identity, and environment information. The envType parameter specifies the environment in which the data source is used. Valid values of the envType parameter:

*   Dev: development environment
*   Prod: production environment

The parameters that you need to configure to the data source vary based on the mode in which the data source is added. For more information, see [Data source connection information (ConnectionProperties)](https://help.aliyun.com/document_detail/2852465.html).

This parameter is required.', example='{
	"envType": "Prod",
	"regionId": "cn-beijing",
    "instanceId": "hgprecn-cn-x0r3oun4k001",
    "database": "testdb",
    "securityProtocol": "authTypeNone",
    "authType": "Executor",
    "authIdentity": "1107550004253538"
}', position='Query'),
  connectionPropertiesMode?: string(name='ConnectionPropertiesMode', description='The mode in which the data source is added. The mode varies based on the data source type. Valid values:

*   InstanceMode: instance mode
*   UrlMode: connection string mode
*   CdhMode: CDH cluster mode', example='UrlMode', position='Query'),
  description?: string(name='Description', description='The description of the data source. The description cannot exceed 3,000 characters in length.', example='test', position='Query'),
  id: long(name='Id', description='The data source ID.

This parameter is required.', example='16033', position='Query'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID.

This parameter is required.', example='5678', position='Query'),
}

model UpdateDataSourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='102E8E24-0387-531D-8A75-1C0AE7DD03E5'),
  success?: boolean(name='Success', description='Whether the data source has been modified:

- true: Yes
- false: no', example='true'),
}

model UpdateDataSourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateDataSourceResponseBody(name='body'),
}

/**
  * @description 1.  This API operation is available for all DataWorks editions.
  * 2.  You can call this operation only if you are assigned one of the following roles in DataWorks:
  * *   Tenant Owner, Tenant Administrator, Workspace Administrator, Workspace Owner, and O\\&M
  * @param request  the request parameters of UpdateDataSource  UpdateDataSourceRequest
  * @return UpdateDataSourceResponse
 */
async function updateDataSource(request: UpdateDataSourceRequest): UpdateDataSourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateDataSource', 'POST', '/', 'json', false, 'json', request);
}

model UpdateFunctionRequest {
  regionId?: string(name='RegionId', description='代表region的资源属性字段

This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the UDF.

This parameter is required.', example='463497880880954XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the UDF. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
    "version": "1.1.0",
    "kind": "Function",
    "spec": {
        "functions": [
            {
                "name": "FunctionName",
                "script": {
                    "content": "{\\"name\\": \\"FunctionName\\", \\"datasource\\": {\\"type\\": \\"odps\\", \\"name\\": \\"odps_first\\"}, \\"runtimeResource\\": {\\"resourceGroup\\": \\"S_res_group_XXXX_XXXX\\"}}",
                    "path": "XXX/OpenAPI/Function/FunctionName",
                    "runtime": {
                        "command": "ODPS_FUNCTION"
                    }
                },
                "datasource": {
                    "name": "odps_first",
                    "type": "odps"
                },
                "runtimeResource": {
                    "resourceGroup": "S_res_group_XXXX_XXXX"
                }
            }
        ]
    }
}', position='Body'),
}

model UpdateFunctionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can troubleshoot issues based on the ID.', example='12123960-CB2C-5086-868E-C6C1D024XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

true

false', example='true'),
}

model UpdateFunctionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateFunctionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateFunction  UpdateFunctionRequest
  * @return UpdateFunctionResponse
 */
async function updateFunction(request: UpdateFunctionRequest): UpdateFunctionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateFunction', 'POST', '/', 'json', true, 'form', request);
}

model UpdateNodeRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the node.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the node. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
    "version": "1.1.0",
    "kind": "Node",
    "spec": {
        "nodes": [
            {
                "id": "860438872620113XXXX",
                "recurrence": "Normal",
                "timeout": 0,
                "instanceMode": "T+1",
                "rerunMode": "Allowed",
                "rerunTimes": 3,
                "rerunInterval": 180000,
                "datasource": {
                    "name": "odps_test",
                    "type": "odps"
                },
                "script": {
                    "path": "XX/OpenAPI_Test/odpsSQL_Test",
                    "runtime": {
                        "command": "ODPS_SQL"
                    },
                    "content": "select now();"
                },
                "trigger": {
                    "type": "Scheduler",
                    "cron": "00 00 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "runtimeResource": {
                    "resourceGroup": "S_res_group_XXXX_XXXX"
                },
                "name": "odpsSQL_Test",
                "inputs": {
                    "nodeOutputs": [
                        {
                            "data": "lwttest_standard_root",
                            "artifactType": "NodeOutput"
                        }
                    ]
                },
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "output_data",
                            "artifactType": "NodeOutput",
                            "refTableName": "odpsSQL_Test"
                        }
                    ]
                }
            }
        ],
        "flow": [
            {
                "nodeId": "860438872620113XXXX",
                "depends": [
                    {
                        "type": "Normal",
                        "output": "project_root"
                    }
                ]
            }
        ]
    }
}', position='Body'),
}

model UpdateNodeResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can troubleshoot issues based on the ID.', example='99EBE7CF-69C0-5089-BE3E-79563C31XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateNodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateNodeResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateNode  UpdateNodeRequest
  * @return UpdateNodeResponse
 */
async function updateNode(request: UpdateNodeRequest): UpdateNodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateNode', 'POST', '/', 'json', true, 'form', request);
}

model UpdateProjectRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  description?: string(name='Description', description='The description of the workspace.', example='Financial analysis group project data development', position='Body'),
  devEnvironmentEnabled?: boolean(name='DevEnvironmentEnabled', description='Specifies whether to enable the development environment. Valid values:

*   true: enables the development environment. In this case, the development environment is isolated from the production environment in the workspace.
*   false: disables the development environment. In this case, only the production environment is used in the workspace.', example='true', position='Body'),
  devRoleDisabled?: boolean(name='DevRoleDisabled', description='Specifies whether to disable the Develop role. Valid values:

*   false (default)
*   true

Note: If you disable the Develop role, you cannot assume the Develop role to develop nodes in workflows and edit node code. The Develop role cannot be enabled again after it is disabled.', example='true', position='Body'),
  displayName?: string(name='DisplayName', description='The display name of the workspace.', example='Sora financial analysis Space', position='Body'),
  id: long(name='Id', description='The ID of the DataWorks workspace. You can log on to the [DataWorks console](https://dataworks.console.aliyun.com/workspace/list) and go to the workspace management page to obtain the ID.

This parameter is used to determine the DataWorks workspaces used for this API call.

This parameter is required.', example='123456', position='Body'),
  paiTaskEnabled?: boolean(name='PaiTaskEnabled', description='Specifies whether to enable scheduling of Platform for AI (PAI) tasks. Valid values:

*   true: enables scheduling of PAI tasks. In this case, you can create a PAI node in a DataWorks workspace and configure scheduling properties for the node to implement periodic scheduling of PAI tasks.
*   false: disables scheduling of PAI tasks.', example='true', position='Body'),
  status?: string(name='Status', description='Specifies whether to disable or enable the workspace. Valid values:

*   Available: enables the workspace.
*   Forbidden: disables the workspace.', example='Forbidden', position='Body'),
}

model UpdateProjectResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='AFBB799F-8578-51C5-A766-E922EDB8XXXX'),
}

model UpdateProjectResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateProjectResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateProject  UpdateProjectRequest
  * @return UpdateProjectResponse
 */
async function updateProject(request: UpdateProjectRequest): UpdateProjectResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateProject', 'POST', '/', 'json', true, 'form', request);
}

model UpdateResourceRequest {
  regionId?: string(name='RegionId', description='代表region的资源属性字段

This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the file resource.

This parameter is required.', example='543217824470354XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10000', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the file resource. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
    "version": "1.1.0",
    "kind": "Resource",
    "spec": {
        "fileResources": [
            {
                "name": "OpenAPI_Test_Resource.py",
                "script": {
                    "content": "",
                    "path": "XX/OpenAPI_Test/Resources_Test/OpenAPI_Test_Resource.py",
                    "runtime": {
                        "command": "ODPS_PYTHON"
                    }
                },
                "type": "python",
                "file": {
                    "storage": {}
                },
                "datasource": {
                    "name": "odps_first",
                    "type": "odps"
                }
            }
        ]
    }
}', position='Body'),
}

model UpdateResourceResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can troubleshoot issues based on the ID.', example='4CDF7B72-020B-542A-8465-21CFFA81XXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateResourceResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateResource  UpdateResourceRequest
  * @return UpdateResourceResponse
 */
async function updateResource(request: UpdateResourceRequest): UpdateResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateResource', 'POST', '/', 'json', true, 'form', request);
}

model UpdateResourceGroupRequest {
  regionId?: string(name='RegionId', position='Host'),
  aliyunResourceGroupId?: string(name='AliyunResourceGroupId', description='The ID of the new Alibaba Cloud resource group.', example='rg-aek2kqofrgXXXXX', position='Body'),
  id: string(name='Id', description='The ID of the resource group.

This parameter is required.', example='Serverless_res_group_524257424564736_6831777003XXXXX', position='Body'),
  name?: string(name='Name', description='The new name that you want to change for the resource group.', example='common_resource_group', position='Body'),
  remark?: string(name='Remark', description='The new remarks that you want to modify for the resource group.', example='Create a common resource group for common tasks', position='Body'),
}

model UpdateResourceGroupResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateResourceGroupResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateResourceGroupResponseBody(name='body'),
}

/**
  * @description You can use this API operation only in DataWorks Basic Edition or an advanced edition.
  * @param request  the request parameters of UpdateResourceGroup  UpdateResourceGroupRequest
  * @return UpdateResourceGroupResponse
 */
async function updateResourceGroup(request: UpdateResourceGroupRequest): UpdateResourceGroupResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateResourceGroup', 'POST', '/', 'json', true, 'form', request);
}

model UpdateRouteRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  destinationCidr: string(name='DestinationCidr', description='The destination CIDR block of the route that you want to update.

This parameter is required.', example='192.168.0.0/16', position='Body'),
  id: long(name='Id', description='The route ID of the network resource.

This parameter is required.', example='1000', position='Body'),
}

model UpdateRouteResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='6A6CBE87-9F91-1323-B680-E7A7065XXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
}

model UpdateRouteResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateRouteResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateRoute  UpdateRouteRequest
  * @return UpdateRouteResponse
 */
async function updateRoute(request: UpdateRouteRequest): UpdateRouteResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateRoute', 'POST', '/', 'json', true, 'form', request);
}

model UpdateTaskRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientUniqueCode?: string(name='ClientUniqueCode', description='The client unique code of the task, which uniquely identifies a task. It is used to implement asynchronous and idempotent functions. If it is not specified during creation, the system will automatically generate the code, which will be uniquely bound to the resource ID. If you specify this parameter when updating and deleting resources, it should be consistent with the client unique code when creating resources.', example='Task_0bc5213917368545132902xxxxxxxx', position='Body'),
  dataSource?: {
    name?: string(name='Name', description='The name of the data source.', example='odps_test'),
  }(name='DataSource', description='The associated data source information.', shrink='json', position='Body'),
  dependencies?: [ 
    {
      type: string(name='Type', description='The type of the dependency.
- CrossCycleDependsOnChildren: cross-cycle dependency level-1 child nodes
- CrossCycleDependsOnSelf: cross-cycle dependency
- CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
- Normal: same-cycle dependency

This parameter is required.', example='Normal'),
      upstreamOutput?: string(name='UpstreamOutput', description='The output identifier of the upstream task. (This field is returned when the input content is set depending on the same cycle)', example='pre.odps_sql_demo_0'),
      upstreamTaskId?: long(name='UpstreamTaskId', description='The Id of the upstream task. (This field is returned when the input content is not set for cross-cycle dependencies on other nodes and same-cycle dependencies.', example='1234'),
    }
  ](name='Dependencies', description='Dependency information.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description.', example='test', position='Body'),
  envType?: string(name='EnvType', description='The project environment.
- Prod: Production
- Dev: Development', example='Prod', position='Body'),
  id: long(name='Id', description='The ID of the task.

This parameter is required.', example='1234', position='Body'),
  inputs?: {
    variables?: [ 
      {
        name?: string(name='Name', description='The name of the variable.', example='key1'),
        type: string(name='Type', description='Type.
- Constant: Constant
- PassThrough: parameter node output
- System: variable
- NodeOutput: script output

This parameter is required.', example='Constant'),
        value?: string(name='Value', description='The value of the variable.', example='value1'),
      }
    ](name='Variables', description='The list of variable definitions.'),
  }(name='Inputs', description='Enter information.', shrink='json', position='Body'),
  instanceMode?: string(name='InstanceMode', description='The instance generation mode.
- T +1 (second born)
- Immediately (generate now)', example='T+1', position='Body'),
  name: string(name='Name', description='The name.

This parameter is required.', example='SQL node', position='Body'),
  outputs?: {
    taskOutputs?: [ 
      {
        output?: string(name='Output', description='The output identifier.', example='pre.odps_sql_demo_0'),
      }
    ](name='TaskOutputs', description='The list of task output definitions.'),
    variables?: [ 
      {
        name?: string(name='Name', description='The name of the variable.', example='key1'),
        type: string(name='Type', description='Type.
- Constant: Constant
- PassThrough: parameter node output
- System: variable
- NodeOutput: script output

This parameter is required.', example='Constant'),
        value?: string(name='Value', description='The value of the variable.', example='value1'),
      }
    ](name='Variables', description='The list of variable definitions.'),
  }(name='Outputs', description='The output information.', shrink='json', position='Body'),
  owner: string(name='Owner', description='The account ID of the owner of the task.

This parameter is required.', example='1000', position='Body'),
  rerunInterval?: int32(name='RerunInterval', description='The retry interval, in seconds.', example='60', position='Body'),
  rerunMode: string(name='RerunMode', description='The configuration of whether the task is allowed to rerun.
- AllDenied: failure or success cannot be rerun.
- FailureAllowed: only failures can be rerun
- AllAllowed: you can run again if you fail or succeed.

This parameter is required.', example='AllAllowed', position='Body'),
  rerunTimes?: int32(name='RerunTimes', description='The number of retries that take effect when the task is set to rerun.', example='3', position='Body'),
  runtimeResource: {
    cu?: string(name='Cu', description='Configure CU consumption for task running.', example='0.25'),
    image?: string(name='Image', description='The ID of the image configured for the task.', example='i-xxxxxx'),
    resourceGroupId: string(name='ResourceGroupId', description='The identifier of the scheduling resource group configured for running the task.

This parameter is required.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
  }(name='RuntimeResource', description='Configuration of the runtime environment, such as resource group information.

This parameter is required.', shrink='json', position='Body'),
  script?: {
    content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
    parameters?: string(name='Parameters', description='The list of script parameters.', example='para1=$bizdate'),
  }(name='Script', description='Run the script information.', shrink='json', position='Body'),
  tags?: [ 
    {
      key: string(name='Key', description='The tag key.

This parameter is required.', example='key1'),
      value?: string(name='Value', description='The value of the tag.', example='value1'),
    }
  ](name='Tags', description='The list of task tags.', shrink='json', position='Body'),
  timeout?: int32(name='Timeout', description='The timeout period of the task execution, in seconds.', example='3600', position='Body'),
  trigger: {
    cron?: string(name='Cron', description='Cron expression, which takes effect when type = Scheduler.', example='00 00 00 * * ?'),
    endTime?: string(name='EndTime', description='The expiration time of the periodic trigger, which takes effect when type = Scheduler.', example='9999-01-01 00:00:00'),
    recurrence?: string(name='Recurrence', description='The operation mode when the trigger is triggered. It takes effect when type = Scheduler.
- Pause: Pause
- Skip: empty run
- Normal: Normal operation', example='Normal'),
    startTime?: string(name='StartTime', description='The time when the cycle trigger takes effect. It takes effect when type = Scheduler.', example='1970-01-01 00:00:00'),
    type: string(name='Type', description='The type of the trigger method.
- Scheduler: the scheduling cycle is triggered.
- Manual: manually triggered

This parameter is required.', example='Scheduler'),
  }(name='Trigger', description='The trigger method of the task.

This parameter is required.', shrink='json', position='Body'),
}

model UpdateTaskResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Whether the operation is successful.', example='true'),
}

model UpdateTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateTask  UpdateTaskRequest
  * @return UpdateTaskResponse
 */
async function updateTask(request: UpdateTaskRequest): UpdateTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateTask', 'POST', '/', 'json', true, 'form', request);
}

model UpdateTaskInstancesRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  comment?: string(name='Comment', description='The remarks.', example='this is a comment', position='Body'),
  taskInstances?: [ 
    {
      dataSource?: {
        name?: string(name='Name', description='The name of the data source.', example='mysql_test'),
      }(name='DataSource', description='The information about the associated data source.'),
      id: long(name='Id', description='The instance ID.

This parameter is required.', example='1234'),
      priority?: int32(name='Priority', description='The priority of the instance. Valid values: 1, 3, 5, 7, and 8.

A larger value indicates a higher priority. Default value: 1.', example='1'),
      runtimeResource?: string(name='RuntimeResource', description='The resource group information. Set this parameter to the ID of a resource group for scheduling.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
    }
  ](name='TaskInstances', description='The instances.', shrink='json', position='Body'),
}

model UpdateTaskInstancesResponseBody = {
  requestId?: string(name='RequestId', description='The request ID.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  successInfo?: map[string]SuccessInfoValue(name='SuccessInfo', description='The result of the batch operation, which is in the MAP structure. The instance ID serves as a key, and the result serves as a value.'),
}

model UpdateTaskInstancesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateTaskInstancesResponseBody(name='body'),
}

/**
  * @description This API operation is available for all DataWorks editions.
  * @param request  the request parameters of UpdateTaskInstances  UpdateTaskInstancesRequest
  * @return UpdateTaskInstancesResponse
 */
async function updateTaskInstances(request: UpdateTaskInstancesRequest): UpdateTaskInstancesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateTaskInstances', 'POST', '/', 'json', true, 'form', request);
}

model UpdateWorkflowRequest {
  regionId?: string(name='RegionId', description='This parameter is required.', position='Host'),
  clientUniqueCode?: string(name='ClientUniqueCode', description='The client-side unique code of the workflow for asynchronous and idempotent implementation. If not specified during creation, the system will automatically generate the code, which will be uniquely bound to the resource ID. If you specify this parameter when updating and deleting resources, it should be consistent with the client unique code when creating resources.', example='Workflow_0bc5213917368545132902xxxxxxxx', position='Body'),
  dependencies?: [ 
    {
      type: string(name='Type', description='The type of the dependency.
- CrossCycleDependsOnChildren: cross-cycle dependency level-1 child nodes
- CrossCycleDependsOnSelf: cross-cycle dependency
- CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
- Normal: same-cycle dependency

This parameter is required.', example='Normal'),
      upstreamOutput?: string(name='UpstreamOutput', description='The output identifier of the upstream task. (This field is returned when `same cycle dependence` and input content is set)', example='pre.odps_sql_demo_0'),
      upstreamTaskId?: long(name='UpstreamTaskId', description='The Id of the upstream task. (This field is returned when the input content is not set for `cross-cycle dependency other nodes` and `same-cycle dependency `, otherwise it is not returned)', example='1234'),
    }
  ](name='Dependencies', description='Dependency information.', shrink='json', position='Body'),
  description?: string(name='Description', description='The description.', example='test', position='Body'),
  envType?: string(name='EnvType', description='The project environment.

- Prod: Production
- Dev: Development', example='Prod', position='Body'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='1234', position='Body'),
  name: string(name='Name', description='The name.

This parameter is required.', example='My Workflow', position='Body'),
  outputs?: {
    taskOutputs?: [ 
      {
        output?: string(name='Output', description='The output identifier.', example='pre.odps_sql_demo_0'),
      }
    ](name='TaskOutputs', description='The list of workflow task output definitions.'),
  }(name='Outputs', description='The output information.', shrink='json', position='Body'),
  owner: string(name='Owner', description='The account ID of the owner.

This parameter is required.', example='1000', position='Body'),
  parameters?: string(name='Parameters', description='The list of parameters.', example='para1=$bizdate para2=$[yyyymmdd]', position='Body'),
  tags?: [ 
    {
      key: string(name='Key', description='The tag key.

This parameter is required.', example='key1'),
      value?: string(name='Value', description='The value of the tag.', example='value1'),
    }
  ](name='Tags', description='The list of workflow tags.', shrink='json', position='Body'),
  tasks?: [ 
    {
      baseLineId?: long(name='BaseLineId', description='The baseline ID.', example='1234'),
      clientUniqueCode?: string(name='ClientUniqueCode', description='The client-side unique code of the task, which is used to implement asynchronous and idempotent functions. If not specified during creation, the system will automatically generate the code, which will be uniquely bound to the resource ID. If you specify this parameter when updating and deleting resources, it should be consistent with the client unique code when creating resources.', example='Task_0bc5213917368545132902xxxxxxxx'),
      dataSource?: {
        name?: string(name='Name', description='The name of the data source.', example='odps_test'),
      }(name='DataSource', description='The associated data source information.'),
      dependencies?: [ 
        {
          type: string(name='Type', description='The type of the dependency.
- CrossCycleDependsOnChildren: cross-cycle dependency level-1 child nodes
- CrossCycleDependsOnSelf: cross-cycle dependency
- CrossCycleDependsOnOtherNode: cross-cycle dependency on other nodes
- Normal: same-cycle dependency

This parameter is required.', example='Normal'),
          upstreamOutput?: string(name='UpstreamOutput', description='The output identifier of the upstream task. (This field is returned when the input content is set depending on the same cycle)', example='pre.odps_sql_demo_0'),
          upstreamTaskId?: long(name='UpstreamTaskId', description='The Id of the upstream task. (This field is returned when the input content is not set for cross-cycle dependencies on other nodes and same-cycle dependencies.', example='1234'),
        }
      ](name='Dependencies', description='Dependency information.'),
      description?: string(name='Description', description='The description.', example='Test'),
      envType?: string(name='EnvType', description='The project environment.
- Prod: Production
- Dev: Development', example='Prod'),
      id: long(name='Id', description='The ID of the task. If you enter this field, a full update is performed on the corresponding task. If you do not enter this field, a new task is created.

This parameter is required.', example='1234'),
      inputs?: {
        variables?: [ 
          {
            name?: string(name='Name', description='The name of the variable.', example='key1'),
            type: string(name='Type', description='Type.
- Constant: Constant
- PassThrough: parameter node output
- System: variable
- NodeOutput: script output

This parameter is required.', example='Constant'),
            value?: string(name='Value', description='The value of the variable.', example='value1'),
          }
        ](name='Variables', description='The list of variable definitions.'),
      }(name='Inputs', description='Enter information.'),
      name: string(name='Name', description='The name of the task.

This parameter is required.', example='SQL node'),
      outputs?: {
        taskOutputs?: [ 
          {
            output?: string(name='Output', description='The output identifier.', example='pre.odps_sql_demo_0'),
          }
        ](name='TaskOutputs', description='The list of task output definitions.'),
        variables?: [ 
          {
            name?: string(name='Name', description='The name of the variable.', example='key1'),
            type: string(name='Type', description='Type.
- Constant: Constant
- PassThrough: parameter node output
- System: variable
- NodeOutput: script output

This parameter is required.', example='Constant'),
            value?: string(name='Value', description='The value of the variable.', example='value1'),
          }
        ](name='Variables', description='The list of variable definitions.'),
      }(name='Outputs', description='The output information.'),
      owner: string(name='Owner', description='The account ID of the owner.

This parameter is required.', example='1000'),
      rerunInterval?: int32(name='RerunInterval', description='The retry interval, in seconds.', example='60'),
      rerunMode: string(name='RerunMode', description='The configuration of whether the task is allowed to rerun.
- AllDenied (failure or success cannot be rerun)
- FailureAllowed (only failures can be rerun)
- AllAllowed (run again if failed or successful)

This parameter is required.', example='AllAllowed'),
      rerunTimes?: int32(name='RerunTimes', description='The number of retries that take effect when the task is set to rerun.', example='3'),
      runtimeResource: {
        cu?: string(name='Cu', description='Configure CU consumption for task running.', example='0.25'),
        image?: string(name='Image', description='The ID of the image configured for the task.', example='i-xxxxxx'),
        resourceGroupId: string(name='ResourceGroupId', description='The identifier of the scheduling resource group configured for running the task.

This parameter is required.', example='S_res_group_524258031846018_1684XXXXXXXXX'),
      }(name='RuntimeResource', description='Configuration of the runtime environment, such as resource group information.

This parameter is required.'),
      script?: {
        content?: string(name='Content', description='The script content.', example='echo "helloWorld"'),
        parameters?: string(name='Parameters', description='The list of script parameters.', example='para1=$bizdate'),
      }(name='Script', description='Run the script information.'),
      tags?: [ 
        {
          key: string(name='Key', description='The tag key.

This parameter is required.', example='key1'),
          value?: string(name='Value', description='The value of the tag.', example='value1'),
        }
      ](name='Tags', description='The list of task tags.'),
      timeout?: int32(name='Timeout', description='The timeout period of the task execution, in seconds.', example='3600'),
      trigger: {
        recurrence: string(name='Recurrence', description='The operation mode when the trigger is triggered. It takes effect when type = Scheduler.
- Pause: Pause
- Skip: empty run
- Normal: Normal operation

This parameter is required.', example='Normal'),
        type?: string(name='Type', description='The type of the trigger method.
- Scheduler: the scheduling cycle is triggered.
- Manual: manually triggered', example='Scheduler'),
      }(name='Trigger', description='The trigger method of the task.

This parameter is required.'),
      type: string(name='Type', description='The type of the task.

This parameter is required.', example='ODPS_SQL'),
    }
  ](name='Tasks', description='The list of tasks.', shrink='json', position='Body'),
  trigger: {
    cron?: string(name='Cron', description='Cron expression, which takes effect when type = Scheduler.', example='00 00 00 * * ?'),
    endTime?: string(name='EndTime', description='The expiration time of the periodic trigger, which takes effect when type = Scheduler.', example='9999-01-01 00:00:00'),
    startTime?: string(name='StartTime', description='The time when the cycle trigger takes effect. It takes effect when type = Scheduler.', example='1970-01-01 00:00:00'),
    type: string(name='Type', description='The type of the trigger method.
- Scheduler: the scheduling cycle is triggered.
- Manual: manually triggered

This parameter is required.', example='Scheduler'),
  }(name='Trigger', description='The trigger method.

This parameter is required.', shrink='json', position='Body'),
}

model UpdateWorkflowResponseBody = {
  requestId?: string(name='RequestId', description='The ID of the request. It is used to locate logs and troubleshoot problems.', example='22C97E95-F023-56B5-8852-B1A77A17XXXX'),
  success?: boolean(name='Success', description='Whether the operation is successful.', example='true'),
}

model UpdateWorkflowResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateWorkflowResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateWorkflow  UpdateWorkflowRequest
  * @return UpdateWorkflowResponse
 */
async function updateWorkflow(request: UpdateWorkflowRequest): UpdateWorkflowResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateWorkflow', 'POST', '/', 'json', true, 'form', request);
}

model UpdateWorkflowDefinitionRequest {
  regionId?: string(name='RegionId', description='代表region的资源属性字段

This parameter is required.', position='Host'),
  id: long(name='Id', description='The ID of the workflow.

This parameter is required.', example='652567824470354XXXX', position='Body'),
  projectId: long(name='ProjectId', description='The DataWorks workspace ID. You can log on to the [DataWorks console](https://workbench.data.aliyun.com/console) and go to the Workspace page to query the ID.

This parameter is required.', example='10001', position='Body'),
  spec: string(name='Spec', description='The FlowSpec field information about the workflow. For more information, see [FlowSpec](https://github.com/aliyun/dataworks-spec/blob/master/README_zh_CN.md).

This parameter is required.', example='{
    "kind": "CycleWorkflow",
    "version": "1.1.0",
    "spec": {
        "name": "OpenAPI Test Workflow Demo",
        "type": "CycleWorkflow",
        "id": "652567824470354XXXX",
        "workflows": [
            {
                "id": "652567824470354XXXX",
                "script": {
                    "path": "XX/OpenAPI_Test/Workflow_Test/OpenAPI_Test_Workflow_Demo",
                    "runtime": {
                        "command": "WORKFLOW"
                    }
                },
                "trigger": {
                    "type": "Scheduler",
                    "cron": "00 02 00 * * ?",
                    "startTime": "1970-01-01 00:00:00",
                    "endTime": "9999-01-01 00:00:00",
                    "timezone": "Asia/Shanghai",
                    "delaySeconds": 0
                },
                "strategy": {
                    "timeout": 0,
                    "instanceMode": "T+1",
                    "rerunMode": "Allowed",
                    "rerunTimes": 3,
                    "rerunInterval": 180000,
                    "failureStrategy": "Break"
                },
                "name": "OpenAPI Test Workflow Demo",
                "inputs": {},
                "outputs": {
                    "nodeOutputs": [
                        {
                            "data": "workflow_output",
                            "artifactType": "NodeOutput",
                            "refTableName": "OpenAPI_Test_Workflow_Demo"
                        }
                    ]
                },
                "nodes": [],
                "dependencies": []
            }
        ]
    }
}', position='Body'),
}

model UpdateWorkflowDefinitionResponseBody = {
  requestId?: string(name='RequestId', description='The request ID. You can locate logs and troubleshoot issues based on the ID.', example='20BF7E80-668A-5620-8AD8-879B8FEAXXXX'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model UpdateWorkflowDefinitionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateWorkflowDefinitionResponseBody(name='body'),
}

/**
  * @param request  the request parameters of UpdateWorkflowDefinition  UpdateWorkflowDefinitionRequest
  * @return UpdateWorkflowDefinitionResponse
 */
async function updateWorkflowDefinition(request: UpdateWorkflowDefinitionRequest): UpdateWorkflowDefinitionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateWorkflowDefinition', 'POST', '/', 'json', true, 'form', request);
}

model SuccessInfoValue = {
  success?: boolean(name='Success', description='Indicates whether the request was successful.', example='true'),
  message?: string(name='Message', description='The error message.', example='The task does not exist.'),
}

