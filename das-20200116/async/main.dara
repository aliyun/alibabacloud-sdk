/**
 *
 */
import BaseClientBuilder;
import TeaAsyncHandler;
import TeaRequest;
import AsyncRequestBody;
import RequestBody;
import AsyncResponseHandler;
import ClientConfiguration;
import ClientExecutionParams;
extends BaseClientBuilder;
type @product = string
type @version = string
type @endpointRule = string
type @endpointMap = map[string]string
type @REQUEST = TeaRequest
type @handler = TeaAsyncHandler

init(configuration: ClientConfiguration){
  @handler = new TeaAsyncHandler(configuration);
  @product = 'DAS';
  @version = '2020-01-16';
  @endpointRule = 'central';
  @endpointMap = {
    'cn-shanghai' = 'das.cn-shanghai.aliyuncs.com',
  };
}

function close(): void {
  @handler.close();
}

model AddHDMInstanceRequest {
  engine?: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**
*   **PostgreSQL**
*   **SQLServer**
*   **PolarDBMySQL**
*   **PolarDBPostgreSQL**
*   **Redis**
*   **MongoDB**
*   **PolarDBOracle**
*   **PolarDBX**', example='MySQL', position='Query'),
  flushAccount?: string(name='FlushAccount', description='The reserved parameter.', example='None', position='Query'),
  instanceAlias?: string(name='InstanceAlias', description='The name of the instance.', example='yuecq--test****', position='Query'),
  instanceArea: string(name='InstanceArea', description='The type of the instance on which the database is deployed. Valid values:

*   **RDS**: an Alibaba Cloud database instance.
*   **ECS**: an Elastic Compute Service (ECS) instance on which a self-managed database is deployed.
*   **IDC**: a self-managed database instance that is not deployed on Alibaba Cloud.

>  IDC refers to your data center.', example='ECS', position='Query'),
  instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-2ze1jdv45i7l6****', position='Query'),
  ip?: string(name='Ip', description='The endpoint that is used to access the instance over internal networks.', example='rm-2ze1jdv45i7l6****.mysql.rds.aliyuncs.com', position='Query'),
  networkType?: string(name='NetworkType', description='The network type of the instance.', example='VPC', position='Query'),
  password?: string(name='Password', description='The password for the username.', example='122****', position='Query'),
  port?: string(name='Port', description='The port that is used to access the instance over internal networks.', example='3306', position='Query'),
  region?: string(name='Region', description='The ID of the region in which the instance resides.', example='cn-hangzhou', position='Query'),
  username?: string(name='Username', description='The username that is used to log on to the database.', example='test****', position='Query'),
  vpcId?: string(name='VpcId', description='The virtual private cloud (VPC) ID.', example='vpc-m5e666n89m2bx8jar****', position='Query'),
  context?: string(name='__context', description='The reserved parameter.', example='None', position='Query'),
}

model AddHDMInstanceResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    callerUid?: string(name='CallerUid', description='The user ID of the caller.', example='31063db679****'),
    code?: int32(name='Code', description='The HTTP status code returned.', example='200'),
    error?: string(name='Error', description='The error message returned if the request failed.', example='InvalidRequestURL'),
    instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-2ze1jdv45i7l6****'),
    ip?: string(name='Ip', description='The endpoint of the instance.', example='rm-de21209****.mysql.rds.aliyuncs.com'),
    ownerId?: string(name='OwnerId', description='The ID of the instance owner.', example='325352345'),
    port?: int32(name='Port', description='The port number of the instance that you want to access.', example='3306'),
    role?: string(name='Role', description='The role of the current API caller.', example='master'),
    tenantId?: string(name='TenantId', description='The tenant ID.', example='L0EPfLS****=SCE00000*****'),
    token?: string(name='Token', description='The client token that is used to ensure the idempotence of the request.', example='tokenID'),
    uuid?: string(name='Uuid', description='The unique identifier of the instance.', example='hdm_3063db6792965c080a4bcb6e6304****'),
    vpcId?: string(name='VpcId', description='The VPC ID.', example='vpc-m5e666n89m2bx8jar****'),
  }(name='Data', description='The detailed information, including the error codes and the number of entries that are returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
  synchro?: string(name='Synchro', description='The reserved parameter.', example='None'),
}

model AddHDMInstanceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: AddHDMInstanceResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a DAS SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call DAS, you must set the region to cn-shanghai.
  *
 */
async function addHDMInstance(request: AddHDMInstanceRequest): AddHDMInstanceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'AddHDMInstance', 'POST', '/', 'json', false, 'json', request);
}

model CreateAdamBenchTaskRequest {
  description: string(name='Description', description='The description of the stress testing task.', example='test-das-bench-0501', position='Query'),
  dstInstanceId: string(name='DstInstanceId', description='The ID of the destination instance. The instance must be an ApsaraDB RDS for MySQL instance or a PolarDB for MySQL instance. You can call the [GetInstanceInspections](~~202857~~) operation to query the ID.', example='rm-2ze1jdv45i7l6****', position='Query'),
  dstSuperAccount: string(name='DstSuperAccount', description='The name of the privileged account for the destination instance.', example='root***', position='Query'),
  dstSuperPassword: string(name='DstSuperPassword', description='The password of the privileged account for the destination instance.', example='root***1234', position='Query'),
  rate?: int32(name='Rate', description='The rate at which the traffic captured from the source database instance is replayed on the destination database instance. Valid values: 1 to 30. Default value: 1.', example='1', position='Query'),
  requestDuration: long(name='RequestDuration', description='The duration of the stress testing task for which the traffic is captured from the source instance. Unit: milliseconds.', example='86400000', position='Query'),
  requestStartTime: long(name='RequestStartTime', description='The start time of the stress testing task. Specify the time in the UNIX timestamp format. Unit: milliseconds.', example='1588819800000', position='Query'),
  srcEngine?: string(name='SrcEngine', description='The database engine that the source database instance runs.', example='MySQL', position='Query'),
  srcEngineVersion?: string(name='SrcEngineVersion', description='The version of the database engine that the source database instance runs.', example='9i', position='Query'),
  srcMaxQps: double(name='SrcMaxQps', description='The maximum number of queries per second (QPS) within the time period during which traffic on the source database instance is captured. The value must be accurate to two decimal places.', example='2013.22', position='Query'),
  srcMeanQps: double(name='SrcMeanQps', description='The average QPS within the time period in which traffic on the source database instance is captured. The value must be accurate to two decimal places.', example='312.22', position='Query'),
  srcSqlOssAddr: string(name='SrcSqlOssAddr', description='The URL of the Object Storage Service (OSS) folder in which the archived objects for SQL statements that run on the source database instance are stored. You can obtain the URL after you upload the archived files to OSS.', example='http://rdslog-hz-v3.oss-cn-hangzhou.aliyuncs.com/custins4131****', position='Query'),
}

model CreateAdamBenchTaskResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The detailed information, including the error codes and the number of entries that are returned.', example='"Data": { "total": 1, "list":[...] }, "Code": 200, "Success": true }'),
  message?: string(name='Message', description='The returned message.

> If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model CreateAdamBenchTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateAdamBenchTaskResponseBody(name='body'),
}

/**
  * Database Autonomy Service (DAS) provides the intelligent stress testing feature. You can create an Advanced Database & Application Migration (ADAM) stress testing task to check whether you need to scale up your database instance to handle workloads during peak hours. For more information, see [Intelligent stress testing](~~155068~~).
  * Make sure that your database instances meet the following requirements:
  * *   The source database instance is an ApsaraDB RDS for MySQL High-availability Edition or Enterprise Edition instance, or a PolarDB for MySQL Cluster Edition or X-Engine Edition cluster.
  * *   The destination instance is an ApsaraDB RDS for MySQL instance or a PolarDB for MySQL cluster.
  * *   The source and destination database instances are connected to DAS. For information about how to connect database instances to DAS, see [Connect an Alibaba Cloud database instance to DAS](~~65405~~).
  * *   DAS Enterprise Edition is enabled for the source and destination database instances. For more information, see [Overview](~~190912~~).
  *
 */
async function createAdamBenchTask(request: CreateAdamBenchTaskRequest): CreateAdamBenchTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateAdamBenchTask', 'POST', '/', 'json', false, 'json', request);
}

model CreateCacheAnalysisJobRequest {
  backupSetId?: string(name='BackupSetId', description='The ID of the backup file. You can call the [DescribeBackups](~~61081~~) operation to query the ID.

*   If you need to specify multiple backup file IDs, separate them with commas (,). For example, you can set this parameter to `12345,67890`.
*   If you do not specify this parameter, the system automatically backs up the task and performs cache analysis on the backup file.', example='12345', position='Query'),
  instanceId: string(name='InstanceId', description='The ID of the ApsaraDB for Redis instance.', example='r-bp18ff4a195d****', position='Query'),
  nodeId?: string(name='NodeId', description='The ID of the data node on the instance. You can specify this parameter to query the monitoring information about the specified node.

>  If you specify the BackupSetId parameter, the system ignores the NodeId parameter. You can call the [DescribeLogicInstanceTopology](~~94665~~) operation to query the node ID.', example='r-x****-db-0', position='Query'),
  separators?: string(name='Separators', description='The delimiters used to identify the prefixes of keys. You do not need to specify this parameter if one or more of the following default delimiters are used: `: ; , _ - + @ = | #`', example='&', position='Query'),
}

model CreateCacheAnalysisJobResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    bigKeys?: {
      keyInfo?: [ 
      {
        bytes?: long(name='Bytes', description='The number of bytes that are occupied by the key.', example='12345'),
        count?: long(name='Count', description='The number of elements in the key.', example='127'),
        db?: int32(name='Db', description='The name of the database.', example='0'),
        encoding?: string(name='Encoding', description='The data type of the key.', example='hashtable'),
        expirationTimeMillis?: long(name='ExpirationTimeMillis', description='The expiration period of the key. Unit: milliseconds. A value of 0 indicates that the key does not expire.', example='1596256542547'),
        key?: string(name='Key', description='The name of the key.', example='task_x****'),
        nodeId?: string(name='NodeId', description='The ID of the data node on the instance.', example='r-x****-db-0'),
        type?: string(name='Type', description='The data type of the ApsaraDB for Redis instance.', example='hash'),
      }
    ](name='KeyInfo')
    }(name='BigKeys', description='The number of elements in the key.'),
    instanceId?: string(name='InstanceId', description='The instance ID.', example='r-bp18ff4a195d****'),
    jobId?: string(name='JobId', description='The ID of the cache analysis task.

>  This parameter can be used to query a specific cache analysis task. When you call the CreateCacheAnalysisJob operation, it takes some time to create a cache analysis task. As a result, the analysis results cannot be immediately returned. You can call the [DescribeCacheAnalysisJob](~~180983~~) operation to query the analysis results of the specified cache analysis task.', example='sf79-sd99-sa37-****'),
    message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
    nodeId?: string(name='NodeId', description='The ID of the data node on the instance.', example='r-x****-db-0'),
    taskState?: string(name='TaskState', description='The state of the cache analysis task. Valid values:

*   **BACKUP**: The data is being backed up.
*   **ANALYZING**: The data is being analyzed.
*   **FINISHED**: The data is analyzed.
*   **FAILED**: An error occurred.', example='BACKUP'),
  }(name='Data', description='The detailed information.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model CreateCacheAnalysisJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateCacheAnalysisJobResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call DAS, you must set the region to cn-shanghai.
  * *   This operation is applicable only to ApsaraDB for Redis Community Edition instances and performance-enhanced instances of the ApsaraDB for Redis Enhanced Edition (Tair).
  * >  Redis 7.0 is not supported. You are not allowed to use custom modules.
  *
 */
async function createCacheAnalysisJob(request: CreateCacheAnalysisJobRequest): CreateCacheAnalysisJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateCacheAnalysisJob', 'POST', '/', 'json', false, 'json', request);
}

model CreateCloudBenchTasksRequest {
  amount?: string(name='Amount', description='The total number of stress testing tasks that you want to create. Valid values: **0** to **30**. Default value: **1**.', example='1', position='Query'),
  backupId?: string(name='BackupId', description='The ID of the backup set. You can call the [DescribeBackups](~~26273~~) operation to query the ID of the backup set.', example='229132', position='Query'),
  backupTime?: string(name='BackupTime', description='The time when the backup starts. Specify the time in the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time must be in UTC.', example='2021-04-23T13:22:14Z', position='Query'),
  clientType: string(name='ClientType', description='The type of the stress testing client. Valid values:

*   **ECS**: indicates that you must create the [DBGateway](~~64905~~).
*   **DAS_ECS**: indicates that DAS automatically purchases and deploys an Elastic Compute Service (ECS) instance for stress testing.', example='ECS', position='Query'),
  description: string(name='Description', description='The description of the stress testing task.', example='test-das-bench-0501', position='Query'),
  dstConnectionString?: string(name='DstConnectionString', description='The endpoint of the destination instance. The specified endpoint must be the endpoint of an ApsaraDB RDS for MySQL instance or a PolarDB for MySQL instance.

>  This parameter takes effect only if you set **DstType** to **ConnectionString**.', example='rm-de21209****.mysql.rds.aliyuncs.com', position='Query'),
  dstInstanceId?: string(name='DstInstanceId', description='The ID of the destination instance. The instance must be an ApsaraDB RDS for MySQL instance or a PolarDB for MySQL instance. You can call the [GetInstanceInspections](~~202857~~) operation to query the ID.

>  This parameter must be specified if you set **DstType** to **Instance**.', example='rm-2ze1jdv45i7l6****', position='Query'),
  dstPort?: string(name='DstPort', description='The port number of the instance that you want to access.

>  This parameter takes effect only if you set **DstType** to **ConnectionString**.', example='3306', position='Query'),
  dstSuperAccount?: string(name='DstSuperAccount', description='The name of the privileged account for the destination instance.', example='root', position='Query'),
  dstSuperPassword?: string(name='DstSuperPassword', description='The password of the privileged account for the destination instance.', example='test123', position='Query'),
  dstType?: string(name='DstType', description='The type of the identifier that is used to indicate the destination instance. Valid values:

*   **Instance**: the instance ID. This is the default value.
*   **ConnectionString**: the endpoint of the instance.', example='Instance', position='Query'),
  dtsJobClass?: string(name='DtsJobClass', description='The specification of the Data Transmission Service (DTS) migration task. You can call the [DescribeCloudbenchTask](~~230669~~) operation to query the specification.

>  You must migrate the basic data in the source instance to the destination instance before you start a stress testing task. When you create a DTS migration task, you must specify this parameter.', example='medium', position='Query'),
  dtsJobId?: string(name='DtsJobId', description='The ID of the DTS migration task. You can call the [ConfigureDtsJob](~~208399~~) operation to query the ID.

>  After a DTS migration task is created in the DTS console, you must specify this parameter.', example='23127', position='Query'),
  endState?: string(name='EndState', description='The state that specifies the last operation that is performed for the stress testing task. Valid values:

*   **WAIT_TARGET**: prepares the destination instance
*   **WAIT_DBGATEWAY**: prepares the DBGateway
*   **WAIT_SQL**: prepares the full SQL statistics
*   **WAIT_LOGIC**: prepares to replay the traffic

>  When the state of a stress testing task changes to the state that is specified by the EndState parameter, the stress testing task becomes completed.', example='WAIT_TARGET', position='Query'),
  gatewayVpcId?: string(name='GatewayVpcId', description='The ID of the virtual private cloud (VPC) in which the database gateway (DBGateway) is deployed.

>  This parameter must be specified if you set **ClientType** to **ECS**.', example='vpc-t4nsnwvpbc1h76ja4****', position='Query'),
  gatewayVpcIp?: string(name='GatewayVpcIp', description='The IP address or domain name of the DBGateway.

>  This parameter must be specified if you set **ClientType** to **ECS**.', example='172.30.XX.XX', position='Query'),
  rate?: string(name='Rate', description='The rate at which the traffic captured from the source instance is replayed on the destination instance. The value must be a positive integer. Valid values: **1** to **30**. Default value: **1**.', example='1', position='Query'),
  requestDuration?: string(name='RequestDuration', description='The duration of the stress testing task for which the traffic is captured from the source instance. Unit: milliseconds.', example='86400000', position='Query'),
  requestEndTime?: string(name='RequestEndTime', description='The time when the stress testing task ends. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1608888296001', position='Query'),
  requestStartTime?: string(name='RequestStartTime', description='The time when the stress testing task starts. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1608888296000', position='Query'),
  smartPressureTime?: string(name='SmartPressureTime', description='The duration within which the traffic generation stressing test takes effect. Unit: milliseconds.

>  This parameter must be specified if you set **TaskType** to **smart pressure test**.', example='86400000', position='Query'),
  srcInstanceId: string(name='SrcInstanceId', description='The ID of the source instance. The instance must be an ApsaraDB RDS for MySQL instance or a PolarDB for MySQL instance. You can call the [GetInstanceInspections](~~202857~~) operation to query the ID.

>  This parameter must be specified if you set **DstType** to **Instance**.', example='rm-2ze1jdv45i7l6****', position='Query'),
  srcPublicIp?: string(name='SrcPublicIp', description='The reserved parameter.', example='None', position='Query'),
  srcSuperAccount?: string(name='SrcSuperAccount', description='The name of the privileged account for the source instance. Set the value to **admin**.

>  This parameter must be specified if you set **DstType** to **Instance**.', example='admin', position='Query'),
  srcSuperPassword?: string(name='SrcSuperPassword', description='The password of the privileged account for the source instance.

>  This parameter must be specified if you set **DstType** to **Instance**.', example='test123', position='Query'),
  taskType: string(name='TaskType', description='The type of the stress testing task. Valid values:

*   **pressure test** (default): A task of this type replays the traffic that is captured from the source instance on the destination instance at the maximum playback rate that is supported by the destination instance.
*   **smart pressure test**: A task of this type analyzes the traffic that is captured from the source instance over a short period of time and generates traffic on the destination instance for continuous stress testing. The business model based on which the traffic is generated on the destination instance and the traffic distribution are consistent with those on the source instance. Stress testing tasks of this type can help you reduce the amount of time that is consumed to collect data from the source instance and reduce storage costs and performance overheads.', example='pressure test', position='Query'),
  workDir?: string(name='WorkDir', description='The temporary directory generated for stress testing.', example='/tmp/bench/', position='Query'),
}

model CreateCloudBenchTasksResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    taskIds?: [ string ](name='taskIds')
  }(name='Data', description='The detailed information.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model CreateCloudBenchTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateCloudBenchTasksResponseBody(name='body'),
}

/**
  * Database Autonomy Service (DAS) provides the intelligent stress testing feature. This feature helps you check whether your instance needs to be scaled up to effectively handle traffic spikes. For more information, see [Intelligent stress testing](~~155068~~). Before you call this API operation, make sure that your database instances meet the following requirements:
  * *   The source database instance is an ApsaraDB RDS for MySQL High-availability Edition or Enterprise Edition instance, or a PolarDB for MySQL Cluster Edition or X-Engine Edition cluster.
  * *   The destination database instance is an ApsaraDB RDS for MySQL instance or a PolarDB for MySQL instance.
  * *   The source and destination database instances are connected to DAS. For information about how to connect database instances to DAS, see [Connect an Alibaba Cloud database instance to DAS](~~65405~~).
  * *   DAS Enterprise Edition is enabled for the source and destination database instances. For more information, see [Overview](~~190912~~).
  *
 */
async function createCloudBenchTasks(request: CreateCloudBenchTasksRequest): CreateCloudBenchTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateCloudBenchTasks', 'POST', '/', 'json', false, 'json', request);
}

model CreateDiagnosticReportRequest {
  DBInstanceId: string(name='DBInstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to create the diagnostic report. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The start time must be later than the end time.', example='1596177993001', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to create the diagnostic report. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1596177993000', position='Query'),
}

model CreateDiagnosticReportResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The data returned.', example='70af71852fcdf2c5dc7b90596e2cf05b'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='ac544623-f6ad-45fd-9a74-9be3db65****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model CreateDiagnosticReportResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDiagnosticReportResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK, make sure that the aliyun-sdk-core version is later than 4.3.3. We recommend that you use the latest version.
  * *   The version of Database Autonomy Service (DAS) SDK must be 1.0.3 or later.
  * *   If you use an SDK to call DAS, you must set the region to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   RDS MySQL
  *     *   PolarDB for MySQL
  *     *   Redis
  *
 */
async function createDiagnosticReport(request: CreateDiagnosticReportRequest): CreateDiagnosticReportResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateDiagnosticReport', 'POST', '/', 'json', false, 'json', request);
}

model CreateKillInstanceSessionTaskRequest {
  dbUser: string(name='DbUser', description='The database account that has the permissions to terminate sessions.', example='testUser', position='Query'),
  dbUserPassword: string(name='DbUserPassword', description='The password of the database account.', example='testPassword', position='Query'),
  ignoredUsers?: string(name='IgnoredUsers', description='The account whose sessions do not need to be terminated.

>  Set this parameter to a JSON array. Separate database accounts with commas (,). Example: \\[\\"Database account 1\\",\\"Database account 2\\"].', example='[\\"db_user1\\",\\"db_user2\\"]', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  killAllSessions: boolean(name='KillAllSessions', description='Specifies whether to terminate all sessions.

*   **true**
*   **false**

>  If you set this parameter to **true**, sessions of the accounts that are specified by **IgnoredUsers**, sessions of internal O\\&M accounts of Alibaba Cloud, and **Binlog Dump** sessions are not terminated.', example='true', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  This parameter must be specified if the database instance is a PolarDB for MySQL cluster. If you do not specify a node ID and set **KillAllSessions** to **true**, the system traverses all nodes in the PolarDB for MySQL cluster and terminates the active sessions on each node.', example='pi-bp1v203xzzh0a****', position='Query'),
  sessionIds?: string(name='SessionIds', description='The IDs of sessions that need to be terminated.

>  Set this parameter to a JSON array. Separate session IDs with commas (,). Example: \\[\\"Session ID1\\",\\"Session ID2\\"]. If **KillAllSessions** is set to **true**, this parameter does not take effect.', example='[10805639,10805623,10805645,10805553,10805566,10805616]', position='Query'),
}

model CreateKillInstanceSessionTaskResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The ID of the task that terminated the sessions.

>  If the sessions of a PolarDB for MySQL cluster were terminated, **NodeId** is left empty, and **KillAllSessions** is set to **true**, the task IDs are returned based on the number of nodes. Example: \\["f77d535b45405bd462b21caa3ee8\\*\\*\\*\\*", "e93ab549abb081eb5dcd5396a29b\\*\\*\\*\\*"].', example='f77d535b45405bd462b21caa3ee8****'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model CreateKillInstanceSessionTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateKillInstanceSessionTaskResponseBody(name='body'),
}

/**
  * *   This operation is applicable only to ApsaraDB RDS for MySQL instances and PolarDB for MySQL clusters.
  * *   If you use an Alibaba Cloud SDK or a Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function createKillInstanceSessionTask(request: CreateKillInstanceSessionTaskRequest): CreateKillInstanceSessionTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateKillInstanceSessionTask', 'POST', '/', 'json', false, 'json', request);
}

model CreateKillInstanceSessionTaskWithMaintainUserRequest {
  ignoredUsers?: string(name='IgnoredUsers', position='Query'),
  instanceId: string(name='InstanceId', position='Query'),
  killAllSessions: boolean(name='KillAllSessions', position='Query'),
  nodeId?: string(name='NodeId', position='Query'),
  sessionIds?: string(name='SessionIds', position='Query'),
}

model CreateKillInstanceSessionTaskWithMaintainUserResponseBody = {
  code?: long(name='Code'),
  data?: string(name='Data'),
  message?: string(name='Message'),
  requestId?: string(name='RequestId'),
  success?: boolean(name='Success'),
}

model CreateKillInstanceSessionTaskWithMaintainUserResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateKillInstanceSessionTaskWithMaintainUserResponseBody(name='body'),
}

async function createKillInstanceSessionTaskWithMaintainUser(request: CreateKillInstanceSessionTaskWithMaintainUserRequest): CreateKillInstanceSessionTaskWithMaintainUserResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateKillInstanceSessionTaskWithMaintainUser', 'POST', '/', 'json', false, 'json', request);
}

model CreateQueryOptimizeTagRequest {
  comments?: string(name='Comments', description='The remarks.

The remarks can be 1 to 300 characters in length.', example='Slow SQL queries of offline synchronization. No optimization is required.', position='Query'),
  engine: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**: ApsaraDB RDS for MySQL
*   **PolarDBMySQL**: PolarDB for MySQL
*   **PostgreSQL**: ApsaraDB RDS for PostgreSQL', example='MySQL', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze1jdv45i7l6****', position='Query'),
  sqlIds: string(name='SqlIds', description='The SQL template IDs. You can call the [GetQueryOptimizeExecErrorStats](~~405261~~) operation to obtain the SQL template ID. Separate multiple SQL template IDs with commas (,).', example='6068ce044e3dc9b903979672fb0b69df,d12515c015fc9f41a0778a9e1de0e941', position='Query'),
  status: int32(name='Status', description='The status of **Tags**. Valid values:

*   **0**: removes all tags added to the SQL templates that are specified by **SqlIds** and leaves **Tags** empty.
*   **1**: adds the tags specified by **Tags** to the SQL templates that are specified by **SqlIds**.', example='1', position='Query'),
  tags: string(name='Tags', description='The SQL tags. Separate multiple SQL tags with commas (,). Valid values:

*   **DAS_IMPORTANT**: The SQL template is important.
*   **DAS_NOT_IMPORTANT**: The SQL template is unimportant.
*   **USER_IGNORE**: The scheduling of the SQL template does not need to be optimized.
*   **DAS_IN_PLAN**: The scheduling of the SQL template needs to be optimized.', example='DAS_IN_PLAN,DAS_NOT_IMPORTANT', position='Query'),
}

model CreateQueryOptimizeTagResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: boolean(name='Data', description='Indicates whether the tags were added to the SQL templates.

*   **true**
*   **false**', example='true'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model CreateQueryOptimizeTagResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateQueryOptimizeTagResponseBody(name='body'),
}

/**
  * *   If you use Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   PolarDB for MySQL
  *     *   ApsaraDB RDS for PostgreSQL
  *
 */
async function createQueryOptimizeTag(request: CreateQueryOptimizeTagRequest): CreateQueryOptimizeTagResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateQueryOptimizeTag', 'POST', '/', 'json', false, 'json', request);
}

model CreateRequestDiagnosisRequest {
  database: string(name='Database', description='The name of the database.', example='das', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-0iwhhl8gx0ld6****', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  This parameter must be specified for PolarDB for MySQL, PolarDB for PostgreSQL (Compatible with Oracle), and ApsaraDB for MongoDB instances.', example='202****', position='Query'),
  sql: string(name='Sql', description='The SQL statement that you want to diagnose.', example='select * from test where name = \\"mockUser\\"', position='Query'),
}

model CreateRequestDiagnosisResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The diagnostics ID, which is the unique identifier of the diagnosis. This parameter can be used to query the result of the diagnosis.', example='61820b594664275c4429****'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='800FBAF5-A539-5B97-A09E-C63AB2F7****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model CreateRequestDiagnosisResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateRequestDiagnosisResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an SDK to call Database Autonomy Service (DAS), you must set the region to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   ApsaraDB RDS for PostgreSQL
  *     *   ApsaraDB RDS for SQL Server
  *     *   PolarDB for MySQL
  *     *   PolarDB for PostgreSQL (compatible with Oracle)
  *     *   ApsaraDB for MongoDB
  * >  The minor engine version of ApsaraDB RDS for PostgreSQL instances must be 20221230 or later. For more information about how to check and update the minor engine version of an ApsaraDB RDS for PostgreSQL instance, see [Update the minor engine version of an ApsaraDB RDS for PostgreSQL instance](~~146895~~).
  *
 */
async function createRequestDiagnosis(request: CreateRequestDiagnosisRequest): CreateRequestDiagnosisResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateRequestDiagnosis', 'POST', '/', 'json', false, 'json', request);
}

model CreateSqlLogTaskRequest {
  endTime?: long(name='EndTime', description='The end of the time range to query. Specify the time in the UNIX timestamp format. Unit: milliseconds.', example='1608888296000', position='Body'),
  filters?: [ 
    {
      key?: string(name='Key', description='The name of the filter parameter.

>  For more information about the supported filter parameters and their valid values, see the following **supplement about the Key parameter**.', example='KeyWords'),
      value?: string(name='Value', description='The value of the filter parameter.', example='select'),
    }
  ](name='Filters', description='The filter conditions.', position='Query'),
  instanceId?: string(name='InstanceId', description='The ID of the database instance.', example='pc-2ze8g2am97624****', position='Body'),
  name?: string(name='Name', description='The name of the task.', example='test01', position='Body'),
  nodeId?: string(name='NodeId', description='The node ID.

>  This parameter is available only for instances that run in a cluster architecture. You can specify this parameter to query the offline tasks of a specific node. By default, if this parameter is not specified, the information about the offline tasks of the primary node is returned.', example='pi-uf6k5f6g3912i0dqz', position='Body'),
  role?: string(name='Role', description='The role of the node of the PolarDB-X 2.0 database instance. Valid values:

*   **polarx_cn**: compute node
*   **polarx_dn**: data node', example='polarx_cn', position='Query'),
  startTime?: long(name='StartTime', description='The beginning of the time range to query. Specify the time in the UNIX timestamp format. Unit: milliseconds.', example='1596177993000', position='Body'),
  type?: string(name='Type', description='The type of the task. Valid values:

*   **Export**
*   **Query**
*   **Insight**', example='Export', position='Body'),
}

model CreateSqlLogTaskResponseBody = {
  code?: string(name='Code', description='The response code.', example='200'),
  data?: {
    createTime?: long(name='CreateTime', description='The time when the task was created. This value is a UNIX timestamp. Unit: milliseconds.', example='1681363254423'),
    end?: long(name='End', description='The end of the time range to query. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1608888296000'),
    instanceId?: string(name='InstanceId', description='The ID of the database instance.', example='pc-2ze8g2am97624****'),
    name?: string(name='Name', description='The name of the task.', example='Export_test'),
    start?: long(name='Start', description='The beginning of the time range to query. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1596177993000'),
    status?: string(name='Status', description='The state of the task. Valid values:

*   **INIT**: The task is to be scheduled.
*   **RUNNING**: The task is running.
*   **FAILED**: The task failed.
*   **CANCELED**: The task is canceled.
*   **COMPLETED**: The task is complete.

>  You can view the result of a task that is in the **COMPLETED** state.', example='COMPLETED'),
    taskId?: string(name='TaskId', description='The task ID.', example='54f8041743ca3a9ac5cb9342d050527c'),
  }(name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, error information such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='83D9D59B-057A-54A9-BFF9-CF2B42F05645'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model CreateSqlLogTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateSqlLogTaskResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or DAS SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  * *   You can create an offline task only for database instances for which DAS Enterprise Edition V2 or V3 is enabled. For more information about the databases and regions that are supported by various versions of DAS Enterprise Edition, see [Editions and supported features](~~156204~~).
  *
 */
async function createSqlLogTask(request: CreateSqlLogTaskRequest): CreateSqlLogTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateSqlLogTask', 'POST', '/', 'json', true, 'form', request);
}

model CreateStorageAnalysisTaskRequest {
  dbName?: string(name='DbName', description='The database name. If you specify a database, the operation analyzes the storage usage of the specified database.', example='testdb01', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze1jdv45i7l6****', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID. For ApsaraDB for MongoDB instances, you can use this parameter to specify a node for storage analysis. You can call the [DescribeRoleZoneInfo](~~123802~~) operation to query the information about nodes of an ApsaraDB for MongoDB instance.

*   If you set this parameter to a value in the **InsName** format, such as `d-bp1872fa24d5****`, you can call this operation to analyze the hidden node that corresponds to the node ID.
*   If you set this parameter to a value in the `InsName#RoleId` format, such as `d-bp1872fa24d5****#299****5`, you can call this operation to analyze the specified node.

>  If you run a storage analysis task on an ApsaraDB for MongoDB replica set instances and you do not specify this parameter, only the hidden node of the instance is analyzed by default. If you run a storage analysis task on an ApsaraDB for MongoDB sharded cluster instance, we recommend that you set this parameter to specify a node.', example='23302528', position='Query'),
  tableName?: string(name='TableName', description='The table name. If you specify a table in the specified database, the operation analyzes the storage usage of the specified table. If you specify a table, you must also specify the database to which the table belongs by using **DbName**.', example='test_table', position='Query'),
}

model CreateStorageAnalysisTaskResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    createTaskSuccess?: boolean(name='CreateTaskSuccess', description='Indicates whether the task is created. Valid values:

*   **true**
*   **false**', example='false'),
    errorMessage?: string(name='ErrorMessage', description='The error message returned.', example='unknown error'),
    taskId?: string(name='TaskId', description='The task ID.', example='910f83f4b96df0524ddc5749f61539f8'),
  }(name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request is successful, **Successful** is returned. Otherwise, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: boolean(name='Success', description='Indicates whether the request is successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model CreateStorageAnalysisTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateStorageAnalysisTaskResponseBody(name='body'),
}

/**
  * *   This operation is applicable only to ApsaraDB RDS for MySQL instances, PolarDB for MySQL clusters, and ApsaraDB for MongoDB instances.
  * *   If you use an Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function createStorageAnalysisTask(request: CreateStorageAnalysisTaskRequest): CreateStorageAnalysisTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'CreateStorageAnalysisTask', 'POST', '/', 'json', false, 'json', request);
}

model DeleteCloudBenchTaskRequest {
  taskId: string(name='TaskId', description='The ID of the stress testing task. You can call the [DescribeCloudBenchTasks](~~230670~~) operation to query the ID.', example='e5cec704-0518-430f-8263-76f4dcds****', position='Query'),
}

model DeleteCloudBenchTaskResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The reserved parameter.', example='None'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model DeleteCloudBenchTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteCloudBenchTaskResponseBody(name='body'),
}

/**
  * Database Autonomy Service (DAS) provides the intelligent stress testing feature. This feature helps you check whether your instance needs to be scaled up to handle traffic spikes in an effective manner. For more information, see [Intelligent stress testing](~~155068~~).
  *
 */
async function deleteCloudBenchTask(request: DeleteCloudBenchTaskRequest): DeleteCloudBenchTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteCloudBenchTask', 'POST', '/', 'json', false, 'json', request);
}

model DeleteStopGatewayRequest {
  gatewayId: string(name='GatewayId', description='The ID that can uniquely identify the DBGateway. You can obtain the DBGateway ID by calling the [DescribeCloudbenchTask](~~230669~~) operation. The DBGateway ID is the value of the **ClientGatewayId** field in the response.', example='22938c83fcfbced4b4869b9695e3****', position='Query'),
}

model DeleteStopGatewayResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The result of the DeleteStopGateway operation. Valid values:

*   **0**: The metadata of the DBGateway is deleted.
*   **-1**: A system error occurs.
*   **-2**: The DBGateway does not exist.
*   **-3**: The DBGateway is not stopped and the metadata cannot be deleted.
*   **-4**: The metadata of the DBGateway fails to be deleted.', example='0'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='FC6C0929-29E1-59FD-8DFE-70D9D41E****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model DeleteStopGatewayResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DeleteStopGatewayResponseBody(name='body'),
}

/**
  * *   This operation is used to delete the metadata of a DBGateway that is released in a stress testing task created by calling the [CreateCloudBenchTasks](~~230665~~) operation.
  * *   If you use an SDK to call API operations of Database Autonomy Service (DAS), you must set the region ID to cn-shanghai.
  * >  If the heartbeat is lost between a DBGateway and the access point for more than 20 seconds, the DBGateway is considered stopped.
  *
 */
async function deleteStopGateway(request: DeleteStopGatewayRequest): DeleteStopGatewayResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DeleteStopGateway', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAutoScalingConfigRequest {
  instanceId: string(name='InstanceId', description='The instance ID.', example='pc-2ze1prap1k46r****', position='Query'),
}

model DescribeAutoScalingConfigResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    bandwidth?: {
      bandwidthUsageLowerThreshold?: int32(name='BandwidthUsageLowerThreshold', description='The average bandwidth usage threshold that triggers automatic bandwidth downgrade. Unit: %.', example='30'),
      bandwidthUsageUpperThreshold?: int32(name='BandwidthUsageUpperThreshold', description='The average bandwidth usage threshold that triggers automatic bandwidth adjustment. Unit: %.', example='70'),
      downgrade?: boolean(name='Downgrade', description='Indicates whether the automatic bandwidth downgrade feature is enabled. Valid values:

*   **true**
*   **false**', example='true'),
      observationWindowSize?: string(name='ObservationWindowSize', description='The observation window of the automatic bandwidth adjustment feature. The return value consists of a numeric value and a time unit suffix. Valid values of the time unit suffix:

*   **s**: seconds.
*   **m**: minutes.
*   **h**: hours.
*   **d**: days.

>  A value of **5m** indicates 5 minutes.', example='5m'),
      upgrade?: boolean(name='Upgrade', description='Indicates whether the automatic bandwidth adjustment feature is enabled. Valid values:

*   **true**
*   **false**', example='true'),
    }(name='Bandwidth', description='The configurations of the automatic bandwidth adjustment feature.'),
    resource?: {
      cpuStep?: int32(name='CpuStep', description='The scale-out step size of CPU.', example='2'),
      cpuUsageUpperThreshold?: int32(name='CpuUsageUpperThreshold', description='The average CPU utilization threshold that triggers automatic scale-out of local resources. Unit: %.', example='70'),
      downgradeObservationWindowSize?: string(name='DowngradeObservationWindowSize', description='The observation window of the automatic scale-in feature for local resources. The return value consists of a numeric value and a time unit suffix. Valid values of the time unit suffix:

*   **s**: seconds.
*   **m**: minutes.
*   **h**: hours.
*   **d**: days.

>  A value of **5m** indicates 5 minutes.', example='5m'),
      enable?: boolean(name='Enable', description='Indicates whether the auto scaling feature is enabled for local resources. Valid values:

*   **true**
*   **false**', example='true'),
      upgradeObservationWindowSize?: string(name='UpgradeObservationWindowSize', description='The observation window of the automatic scale-out feature for local resources. The return value consists of a numeric value and a time unit suffix. Valid values of the time unit suffix:

*   **s**: seconds.
*   **m**: minutes.
*   **h**: hours.
*   **d**: days.

>  A value of **5m** indicates 5 minutes.', example='5m'),
    }(name='Resource', description='The configurations of the auto scaling feature for local resources.'),
    shard?: {
      downgrade?: boolean(name='Downgrade', description='Indicates whether the feature of automatically removing shards is enabled. Valid values:

*   **true**
*   **false**', example='true'),
      downgradeObservationWindowSize?: string(name='DowngradeObservationWindowSize', description='The observation window of the feature of automatically removing shards. The return value consists of a numeric value and a time unit suffix. Valid values of the time unit suffix:

*   **s**: seconds.
*   **m**: minutes.
*   **h**: hours.
*   **d**: days.

>  A value of **1d** indicates one day.', example='1d'),
      maxShards?: int32(name='MaxShards', description='The maximum number of shards in the instance.', example='16'),
      memUsageLowerThreshold?: int32(name='MemUsageLowerThreshold', description='The average memory usage threshold that triggers automatic removal of shards. Unit: %.', example='30'),
      memUsageUpperThreshold?: int32(name='MemUsageUpperThreshold', description='The average memory usage threshold that triggers automatic adding of shards. Unit: %.', example='70'),
      minShards?: int32(name='MinShards', description='The minimum number of shards in the instance.', example='4'),
      upgrade?: boolean(name='Upgrade', description='Indicates whether the feature of automatically adding shards is enabled. Valid values:

*   **true**
*   **false**', example='true'),
      upgradeObservationWindowSize?: string(name='UpgradeObservationWindowSize', description='The observation window of the feature of automatically adding shards. The return value consists of a numeric value and a time unit suffix. Valid values of the time unit suffix:

*   **s**: seconds.
*   **m**: minutes.
*   **h**: hours.
*   **d**: days.

>  A value of **5m** indicates 5 minutes.', example='5m'),
    }(name='Shard', description='The configurations of the auto scaling feature for shards.'),
    spec?: {
      coolDownTime?: string(name='CoolDownTime', description='The quiescent period. The return value consists of a numeric value and a time unit suffix. Valid values of the time unit suffix:

*   **s**: seconds.
*   **m**: minutes.
*   **h**: hours.
*   **d**: days.

>  A value of **5m** indicates 5 minutes.', example='5m'),
      cpuUsageUpperThreshold?: int32(name='CpuUsageUpperThreshold', description='The average CPU utilization threshold that triggers automatic specification scale-up. Unit: %.', example='70'),
      downgrade?: boolean(name='Downgrade', description='Indicates whether the automatic specification scale-down feature is enabled. Valid values:

*   **true**
*   **false**', example='true'),
      maxReadOnlyNodes?: int32(name='MaxReadOnlyNodes', description='The maximum number of read-only nodes of the instance.', example='10'),
      maxSpec?: string(name='MaxSpec', description='The maximum specifications to which the database instance can be upgraded. For more information about the specifications of each type of supported database instances, see the following topics:

*   PolarDB for MySQL Cluster Edition instances: [Specifications of compute nodes](~~102542~~).
*   ApsaraDB RDS for MySQL High-availability Edition instances that use standard SSDs or enhanced SSDs (ESSDs): [Specifications](~~276974~~).', example='polar.mysql.x8.12xlarge'),
      memUsageUpperThreshold?: int32(name='MemUsageUpperThreshold', description='The average memory usage threshold that triggers automatic specification scale-up. Unit: %.', example='70'),
      observationWindowSize?: string(name='ObservationWindowSize', description='The observation window. The return value consists of a numeric value and a time unit suffix. Valid values of the time unit suffix:

*   **s**: seconds.
*   **m**: minutes.
*   **h**: hours.
*   **d**: days.

>  A value of **5m** indicates 5 minutes.', example='5m'),
      upgrade?: boolean(name='Upgrade', description='Indicates whether the automatic specification scale-up feature is enabled. Valid values:

*   **true**
*   **false**', example='true'),
    }(name='Spec', description='The configurations of the auto scaling feature for specifications.'),
    storage?: {
      diskUsageUpperThreshold?: int32(name='DiskUsageUpperThreshold', description='The average storage usage threshold that triggers automatic storage expansion. Unit: %.', example='70'),
      maxStorage?: int32(name='MaxStorage', description='The maximum storage size. Unit: GB.', example='32000'),
      upgrade?: boolean(name='Upgrade', description='Indicates whether the automatic storage expansion feature is enabled. Valid values:

*   **true**
*   **false**', example='true'),
    }(name='Storage', description='The configurations of the automatic storage expansion feature.'),
  }(name='Data', description='The configurations of the auto scaling feature.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeAutoScalingConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAutoScalingConfigResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function describeAutoScalingConfig(request: DescribeAutoScalingConfigRequest): DescribeAutoScalingConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAutoScalingConfig', 'POST', '/', 'json', false, 'json', request);
}

model DescribeAutoScalingHistoryRequest {
  autoScalingTaskType: string(name='AutoScalingTaskType', description='The type of the auto scaling task that you want to query. Set the value to **SPEC**, which indicates that you can query the history of only automatic performance scaling tasks.', example='SPEC', position='Query'),
  endTime: long(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

> The end time must be later than the start time.', example='1676605305796', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.

> Only ApsaraDB RDS for MySQL instances are supported.', example='rm-2ze8g2am97624****', position='Query'),
  startTime: long(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

> The maximum time range that can be specified is 45 days.', example='1675833788056', position='Query'),
}

model DescribeAutoScalingHistoryResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned. The status code 200 indicates that the request was successful.', example='200'),
  data?: {
    bandwidth?: [  map[string]any ](name='Bandwidth', description='The history of automatic bandwidth scaling of ApsaraDB for Redis instances. This feature is not supported.'),
    instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-2ze1jdv45i7l6****'),
    resource?: [  map[string]any ](name='Resource', description='The history of resource scale-out of ApsaraDB for Redis instances. This feature is not supported.'),
    shard?: [  map[string]any ](name='Shard', description='The history of automatic shard scale-out of ApsaraDB for Redis instances. This feature is not supported.'),
    specHistory?: [ 
      {
        errorCode?: string(name='ErrorCode', description='The error code returned by the scaling task. Valid values:

*   **Insufficient_Balance**: The account has insufficient balance or an unpaid order.
*   **REACH_SPEC_UPPERBOUND**: The instance type reaches the upper limit.
*   **Control_Error_Timeout_Msg**: The management task timed out.
*   **Invoke_Rds_Api_Error_Msg**: Failed to call the ApsaraDB RDS API.', example='Insufficient_Balance'),
        originCore?: int32(name='OriginCore', description='The original number of CPU cores of the instance.', example='4'),
        originInstanceClass?: string(name='OriginInstanceClass', description='The original instance type.', example='mysql.n2.large.2c'),
        originMemory?: double(name='OriginMemory', description='The original memory size of the instance. Unit: GB.', example='8'),
        scaleType?: string(name='ScaleType', description='The type of the automatic performance scaling task. Valid values:

*   **SCALE_UP**: automatic instance type scale-up task.
*   **SCALE_DOWN**: automatic instance type scale-down task.', example='SCALE_UP'),
        targetCore?: int32(name='TargetCore', description='The destination number of CPU cores of the instance.', example='8'),
        targetInstanceClass?: string(name='TargetInstanceClass', description='The destination instance type.', example='mysql.n2.xlarge.2c'),
        targetMemory?: double(name='TargetMemory', description='The destination memory size of the instance. Unit: GB.', example='16'),
        taskExcuteStatus?: boolean(name='TaskExcuteStatus', description='The status of the task. Valid values:

*   **true**: The task was successful.
*   **false**: The task failed.', example='true'),
        taskTime?: long(name='TaskTime', description='The time when the task was run. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1684830763000'),
      }
    ](name='SpecHistory', description='The history of automatic performance scaling.'),
    storage?: [  map[string]any ](name='Storage', description='The history of storage expansion. This feature is not supported.'),
  }(name='Data', description='The history of auto scaling.'),
  message?: string(name='Message', description='The returned message.

> If the request was successful, **Successful** is returned. Otherwise, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeAutoScalingHistoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeAutoScalingHistoryResponseBody(name='body'),
}

/**
  * *   You can call this operation to query the history information about the automatic performance scaling only of ApsaraDB RDS for MySQL High-availability Edition instances.
  * *   If you use an Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function describeAutoScalingHistory(request: DescribeAutoScalingHistoryRequest): DescribeAutoScalingHistoryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeAutoScalingHistory', 'GET', '/', 'json', false, 'json', request);
}

model DescribeCacheAnalysisJobRequest {
  instanceId: string(name='InstanceId', description='The ID of the instance.', example='r-bp18ff4a195d****', position='Query'),
  jobId: string(name='JobId', description='The ID of the cache analysis task. You can obtain the task ID from the response parameters of the [CreateCacheAnalysisJob](~~180982~~) operation.', example='sf79-sd99-sa37-****', position='Query'),
}

model DescribeCacheAnalysisJobResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    bigKeys?: {
      keyInfo?: [ 
      {
        bytes?: long(name='Bytes', description='The number of bytes that are occupied by the key.', example='12345'),
        count?: long(name='Count', description='The number of elements in the key.', example='127'),
        db?: int32(name='Db', description='The name of the database.', example='0'),
        encoding?: string(name='Encoding', description='The data type of the key.', example='hashtable'),
        expirationTimeMillis?: long(name='ExpirationTimeMillis', description='The expiration period of the key. Unit: milliseconds. A value of 0 indicates that the key does not expire.', example='1596256542547'),
        key?: string(name='Key', description='The name of the key.', example='task_x****'),
        nodeId?: string(name='NodeId', description='The ID of the data node on the instance.', example='r-x****-db-0'),
        type?: string(name='Type', description='The data type of the instance.', example='hash'),
      }
    ](name='KeyInfo')
    }(name='BigKeys', description='The details of the large keys. The returned large keys are sorted in descending order based on the number of bytes occupied by the keys.'),
    bigKeysOfNum?: {
      keyInfo?: [ 
      {
        bytes?: long(name='Bytes', description='The number of bytes that are occupied by the key.', example='12345'),
        count?: long(name='Count', description='The number of elements in the key.', example='127'),
        db?: int32(name='Db', description='The name of the database.', example='0'),
        encoding?: string(name='Encoding', description='The data type of the key.', example='hashtable'),
        expirationTimeMillis?: long(name='ExpirationTimeMillis', description='The expiration period of the key. Unit: milliseconds. A value of 0 indicates that the key does not expire.', example='1596256542547'),
        key?: string(name='Key', description='The name of the key.', example='task_x****'),
        nodeId?: string(name='NodeId', description='The ID of the data node on the instance.', example='r-x****-db-0'),
        type?: string(name='Type', description='The data type of the instance.', example='hash'),
      }
    ](name='KeyInfo')
    }(name='BigKeysOfNum', description='The details of the large keys. The returned large keys are sorted in descending order based on the number of keys.'),
    expiryKeysLevelCount?: {
      expiryLevel?: [ 
      {
        analysisTs?: long(name='AnalysisTs'),
        level?: int32(name='Level'),
        totalBytes?: long(name='TotalBytes'),
        totalKeys?: long(name='TotalKeys'),
      }
    ](name='ExpiryLevel')
    }(name='ExpiryKeysLevelCount'),
    instanceId?: string(name='InstanceId', description='The instance ID.', example='r-bp18ff4a195d****'),
    jobId?: string(name='JobId', description='The ID of the cache analysis task.', example='sf79-sd99-sa37-****'),
    keyPrefixes?: {
      prefix?: [ 
      {
        bytes?: long(name='Bytes', description='The number of bytes that are occupied by the key.', example='12345'),
        count?: long(name='Count', description='The number of elements in the key.', example='127'),
        keyNum?: long(name='KeyNum', description='The number of keys that contain the prefix.', example='123'),
        prefix?: string(name='Prefix', description='The prefix of the key.', example='task_'),
        type?: string(name='Type', description='The data type of the instance.', example='hash'),
      }
    ](name='Prefix')
    }(name='KeyPrefixes', description='The prefixes of the keys.'),
    message?: string(name='Message', description='The message that is returned for the request.

>  If the request is successful, **Successful** is returned. If the request fails, an error message that contains information such as an error code is returned.', example='Successful'),
    nodeId?: string(name='NodeId', description='The ID of the data node on the instance.', example='r-x****-db-0'),
    taskState?: string(name='TaskState', description='The state of the cache analysis task. Valid values:

*   **BACKUP**: The data is being backed up.
*   **ANALYZING**: The data is being analyzed.
*   **FINISHED**: The data is analyzed.
*   **FAILED**: An error occurred.', example='BACKUP'),
    unexBigKeysOfBytes?: {
      keyInfo?: [ 
      {
        bytes?: long(name='Bytes', description='The number of bytes that are occupied by the key.', example='12345'),
        count?: long(name='Count', description='The number of elements in the key.', example='127'),
        db?: int32(name='Db', description='The name of the database.', example='0'),
        encoding?: string(name='Encoding', description='The data type of the key.', example='hashtable'),
        expirationTimeMillis?: long(name='ExpirationTimeMillis', description='The expiration period of the key. Unit: milliseconds. A value of 0 indicates that the key does not expire.', example='1596256542547'),
        key?: string(name='Key', description='The name of the key.', example='task_x****'),
        nodeId?: string(name='NodeId', description='The ID of the data node on the instance.', example='r-x****-db-0'),
        type?: string(name='Type', description='The data type of the instance.', example='hash'),
      }
    ](name='KeyInfo')
    }(name='UnexBigKeysOfBytes', description='The details of permanent keys. The returned keys are sorted in descending order based on the number of bytes occupied by the keys.'),
    unexBigKeysOfNum?: {
      keyInfo?: [ 
      {
        bytes?: long(name='Bytes', description='The number of bytes that are occupied by the key.', example='12345'),
        count?: long(name='Count', description='The number of elements in the key.', example='127'),
        db?: int32(name='Db', description='The name of the database.', example='0'),
        encoding?: string(name='Encoding', description='The data type of the key.', example='hashtable'),
        expirationTimeMillis?: long(name='ExpirationTimeMillis', description='The expiration period of the key. Unit: milliseconds. A value of 0 indicates that the key does not expire.', example='1596256542547'),
        key?: string(name='Key', description='The name of the key.', example='task_x****'),
        nodeId?: string(name='NodeId', description='The ID of the data node on the instance.', example='r-x****-db-0'),
        type?: string(name='Type', description='The data type of the instance.', example='hash'),
      }
    ](name='KeyInfo')
    }(name='UnexBigKeysOfNum', description='The details of permanent keys. The returned keys are sorted in descending order based on the number of keys.'),
  }(name='Data', description='The details of the task.'),
  message?: string(name='Message', description='The message that is returned for the request.

>  If the request is successful, **Successful** is returned. If the request fails, an error message that contains information such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The ID of the request.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeCacheAnalysisJobResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeCacheAnalysisJobResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region to cn-shanghai.
  * *   This operation is applicable only to ApsaraDB for Redis.
  *
 */
async function describeCacheAnalysisJob(request: DescribeCacheAnalysisJobRequest): DescribeCacheAnalysisJobResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeCacheAnalysisJob', 'POST', '/', 'json', false, 'json', request);
}

model DescribeCacheAnalysisJobsRequest {
  endTime: string(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time.', example='1596177993001', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='r-bp18ff4a195d****', position='Query'),
  pageNo?: string(name='PageNo', description='The page number. The value must be an integer that is greater than 0. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1596177993000', position='Query'),
}

model DescribeCacheAnalysisJobsResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    extra?: string(name='Extra', description='The reserved parameter.', example='None'),
    list?: {
      cacheAnalysisJob?: [ 
      {
        bigKeys?: {
          keyInfo?: [ 
          {
            bytes?: long(name='Bytes', description='The number of bytes that are occupied by the key.', example='12345'),
            count?: long(name='Count', description='The number of elements in the key.', example='127'),
            db?: int32(name='Db', description='The name of the database.', example='0'),
            encoding?: string(name='Encoding', description='The data type of the key.', example='hashtable'),
            expirationTimeMillis?: long(name='ExpirationTimeMillis', description='The expiration period of the key. Unit: milliseconds. A value of 0 indicates that the key does not expire.', example='1596256542547'),
            key?: string(name='Key', description='The name of the key.', example='task_*****'),
            nodeId?: string(name='NodeId', description='The ID of the data node on the instance.', example='r-****-db-0'),
            type?: string(name='Type', description='The data type of the instance.', example='hash'),
          }
        ](name='KeyInfo')
        }(name='BigKeys', description='The details about the large keys.

> The sub-parameters of this parameter and the content of the sub-parameters are not returned. To query the detailed information about the cache analysis tasks, call the [DescribeCacheAnalysisJob](~~443012~~) operation.'),
        instanceId?: string(name='InstanceId', description='The instance ID.', example='r-bp18ff4a195d****'),
        jobId?: string(name='JobId', description='The ID of the cache analysis task.', example='sf79-sd99-sa37-****'),
        message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
        nodeId?: string(name='NodeId', description='The ID of the data node on the instance.', example='r-x****-db-0'),
        taskState?: string(name='TaskState', description='The state of the cache analysis task. Valid values:

* **BACKUP**: The data is being backed up.
* **ANALYZING**: The data is being analyzed.
* **FINISHED**: The data is analyzed.
* **FAILED**: An error occurred.', example='BACKUP'),
      }
    ](name='CacheAnalysisJob')
    }(name='List', description='The ID of the data node on the instance.'),
    pageNo?: long(name='PageNo', description='The page number. The value must be an integer that is greater than 0. Default value: 1.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
    total?: long(name='Total', description='The total number of entries returned.', example='4'),
  }(name='Data', description='The list of cache analysis tasks.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model DescribeCacheAnalysisJobsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeCacheAnalysisJobsResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation is applicable only to ApsaraDB for Redis.
  *
 */
async function describeCacheAnalysisJobs(request: DescribeCacheAnalysisJobsRequest): DescribeCacheAnalysisJobsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeCacheAnalysisJobs', 'POST', '/', 'json', false, 'json', request);
}

model DescribeCloudBenchTasksRequest {
  endTime?: string(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time.', example='1596177993001', position='Query'),
  pageNo?: string(name='PageNo', description='The page number. The value must be a positive integer. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries per page. The value must be a positive integer. Default value: 10.', example='10', position='Query'),
  startTime?: string(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1596177993000', position='Query'),
  status?: string(name='Status', description='The status of the stress testing task. Valid values:

*   **SUCCESS**: The task is successful.
*   **IGNORED**: The task is ignored.
*   **RUNNING**: The task is running.
*   **EXCEPTION**: The task is abnormal.', example='SUCCESS', position='Query'),
  taskType?: string(name='TaskType', description='The type of the stress testing task. Valid values:

*   **pressure test** (default): A task of this type replays the traffic that is captured from the source instance on the destination instance at the maximum playback rate that is supported by the destination instance.
*   **smart pressure test**: A task of this type analyzes the traffic that is captured from the source instance over a short period of time and generates traffic on the destination instance for continuous stress testing. The business model based on which the traffic is generated on the destination instance and the traffic distribution are consistent with those on the source instance. Stress testing tasks of this type can help you reduce the amount of time that is consumed to collect data from the source instance and reduce storage costs and performance overheads.', example='pressure test', position='Query'),
}

model DescribeCloudBenchTasksResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    extra?: string(name='Extra', description='The reserved parameter.', example='None'),
    list?: {
      cloudbenchTasks?: [ 
      {
        archiveJobId?: string(name='ArchiveJobId', description='The archiving task ID.', example='\\"202105211430070112231480820340758****'),
        archiveOssTableName?: string(name='ArchiveOssTableName', description='The name of the table that was archived to Object Storage Service (OSS).', example='custins15546355_161604665****'),
        archiveState?: int32(name='ArchiveState', description='The archiving status of the file that stores the analysis result of full SQL statistics. Valid values:

* **0**: The file archiving is not started.
* **1**: The file is archived.
* **2**: An error occurred.
* **3**: The file is being archived.
* **4**: The archived file does not need to be downloaded.', example='1'),
        backupId?: string(name='BackupId', description='The ID of the backup set. You can call the [DescribeBackups](~~26273~~) operation to query the ID of the backup set.', example='229132'),
        backupType?: string(name='BackupType', description='The backup type. Valid values:

* **TIMESTAMP**: Data is restored to the state at a specific point in time.
* **BACKUPID**: Data is restored from a backup set that is identified by an ID.', example='TIMESTAMP'),
        benchStep?: string(name='BenchStep', description='The substep in the stress testing task. Valid values:

* **NEW**: Initialize the stress testing task.
* **WAIT_BUY_ECS**: Purchase an ECS instance.
* **WAIT_START_ECS**: Start the ECS instance.
* **WAIT_INSTALL_JDK**: Install the Java Development Kit (JDK).
* **WAIT_INSTALL_DBGATEWAY**: Install the database gateway (DBGateway).
* **ADD_SECURITY_IPS_STEP**: Configure the whitelist of the security group.
* **ARCHIVE**: Archive the file that stores the analysis results of full SQL statistics.
* **DOWNLOAD**: Download the file that stores the analysis result of full SQL statistics.
* **PROCEED**: Preprocess the file that stores the analysis result of full SQL statistics.
* **PRE_LOAD**: Preload the file that stores the analysis result of full SQL statistics.
* **VALIDATE**: Verify the functionality of stress testing.
* **PRESSURE**: Start the stress testing task.', example='PROCEED'),
        benchStepStatus?: string(name='BenchStepStatus', description='The status that indicates the substep performed for the stress testing task. Valid values:

* **NEW**: The task is being initialized.
* **RUNNING**: The task is running.
* **FAILED**: The task failed.
* **FINISHED**: The task is complete.
* **Terminated**: The task is terminated.
* **Deleted**: The task is deleted.', example='FINISHED'),
        clientGatewayId?: string(name='ClientGatewayId', description='The DBGateway ID of the stress testing client.', example='58598b2af48a0193dfc16fc6964ef****'),
        clientType?: string(name='ClientType', description='The type of the stress testing client. Valid values:

* **ECS**: indicates that you must prepare the DBGateway.
* **DAS_ECS**: indicates that DAS automatically purchases and deploys an ECS instance for stress testing.', example='ECS'),
        description?: string(name='Description', description='The description of the stress testing task.', example='test-das-bench-0501'),
        dstInstanceUuid?: string(name='DstInstanceUuid', description='The UUID of the destination instance.', example='hdm_d887b5ccf99fa0dc9a1e5aaac368****'),
        dstIp?: string(name='DstIp', description='The reserved parameter.', example='None'),
        dstPort?: int32(name='DstPort', description='The port number of the destination instance.', example='3306'),
        dstType?: string(name='DstType', description='The type of the identifier that is used to indicate the destination instance. Valid values:

* **Instance** (default): the instance ID.
* **ConnectionString**: the endpoint of the instance.', example='Instance'),
        dtsJobClass?: string(name='DtsJobClass', description='The specification of the DTS instance.

> For more information about the specifications of DTS instances and the test performance of each instance, see [Specifications of data migration instances](~~26606~~).', example='medium'),
        dtsJobId?: string(name='DtsJobId', description='The ID of the DTS migration task.', example='i03e3zty16i****'),
        dtsJobName?: string(name='DtsJobName', description='The name of the Data Transmission Service (DTS) migration task.', example='RDS_TO_RDS_MIGRATION'),
        dtsJobState?: int32(name='DtsJobState', description='The status of the DTS migration task. Valid values:

* **NOT_STARTED**: The task is not started.
* **PRE_CHECKING**: The task is in precheck.
* **PRE_CHECK_FAILED**: The precheck failed.
* **CHECKING**: The task is being checked.
* **MIGRATING**: The data is being migrated.
* **CATCHED**: The data is migrated from the source instance to the destination instance.
* **SUSPENDING**: The task is suspended.
* **MIGRATION_FAILED**: The data failed to be migrated.
* **FINISHED**: The task is complete.
* **INITIALIZING**: The synchronization is being initialized.
* **INITIALIZE_FAILED**: The synchronization failed to be initialized.
* **SYNCHRONIZING**: The data is being synchronized.
* **MODIFYING**: The roles of the instances are being changed.
* **SWITCHING**: The roles of the instances are being switched.
* **FAILED**: The task failed.', example='CHECKING'),
        dtsJobStatus?: string(name='DtsJobStatus', description='The status of the DTS migration task. Valid values:

* **NOT_STARTED**: The task is not started.
* **PRE_CHECKING**: The task is in precheck.
* **PRE_CHECK_FAILED**: The precheck failed.
* **CHECKING**: The task is being checked.
* **MIGRATING**: The data is being migrated.
* **CATCHED**: The data is migrated from the source instance to the destination instance.
* **SUSPENDING**: The task is suspended.
* **MIGRATION_FAILED**: The data failed to be migrated.
* **FINISHED**: The task is complete.
* **INITIALIZING**: The synchronization is being initialized.
* **INITIALIZE_FAILED**: The synchronization failed to be initialized.
* **SYNCHRONIZING**: The data is being synchronized.
* **MODIFYING**: The roles of the instances are being changed.
* **SWITCHING**: The roles of the instances are being switched.
* **FAILED**: The task failed.', example='PRE_CHECK_FAILED'),
        ecsInstanceId?: string(name='EcsInstanceId', description='The ID of the Elastic Compute Service (ECS) instance.', example='i-bp1ecr5go2go1****'),
        endState?: string(name='EndState', description='The state that indicates the last operation performed for the stress testing task. Valid values:

* **WAIT_TARGET**: prepares the destination instance.
* **WAIT_DBGATEWAY**: prepares the DBGateway.
* **WAIT_SQL**: prepares the full SQL statistics.
* **WAIT_LOGIC**: prepares to replay the traffic.

> When the state of a stress testing task changes to the state that is specified by the EndState parameter, the stress testing task is complete.', example='WAIT_TARGET'),
        errorCode?: string(name='ErrorCode', description='The error code returned for the substep of the stress testing task.', example='10109'),
        errorMessage?: string(name='ErrorMessage', description='The error message returned if the task failed.', example='DTS-070211: Connect Source DB failed. cause by [com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException:Could not create connection to database server. Attempted reconnect 3 times. Giving up.][com.mysql.jdbc.exceptions.jdbc4.CommunicationsException:Communications link failure\\n\\nThe last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.][java.net.ConnectException:Connection timed out (Connection timed out)] About more information in [https://yq.aliyun.com/articles/499178].'),
        external?: string(name='External', description='The additional information.', example='Null'),
        rate?: int32(name='Rate', description='The rate at which the stress testing task replayed the traffic. This value is a positive integer. Valid values: **0** to **30**. Default value: **1**.', example='1'),
        requestDuration?: long(name='RequestDuration', description='The duration of the stress testing task. Unit: millisecond.', example='86400000'),
        smartPressureTime?: int32(name='SmartPressureTime', description='The duration of the stress testing task of the smart pressure test type. Unit: millisecond.', example='86400000'),
        source?: string(name='Source', description='The source of the task. Valid values:

* **DAS**
* **OPEN_API**', example='DAS'),
        sqlCompleteReuse?: string(name='SqlCompleteReuse', description='The reused information about the analysis result of full SQL statistics.', example='{"sqlUuid":"task_a37d2f07-45cb-4413-a2a6-c66c68****","metaUuid":"task_211e2561-5c0c-486b-864c-56b511****","sqlFile":"cl-1620057600000-1800626.sc","metaFile":"cl-1620057600000-1800626.meta"}'),
        srcInstanceArea?: string(name='SrcInstanceArea', description='The database engine of the source instance. Valid values:', example='RDS'),
        srcInstanceUuid?: string(name='SrcInstanceUuid', description='The UUID of the source instance.', example='hdm_3063db6792965c080a4bcb6e6304****'),
        srcPublicIp?: string(name='SrcPublicIp', description='The reserved parameter.', example='None'),
        state?: string(name='State', description='The state that indicates the operation performed for the stress testing task. Valid values:

* **WAIT_TARGET**: prepares the destination instance.
* **WAIT_DBGATEWAY**: prepares the DBGateway.
* **WAIT_SQL**: prepares the full SQL statistics.
* **WAIT_LOGIC**: prepares to replay the traffic.', example='WAIT_TARGET'),
        status?: string(name='Status', description='The status of the stress testing task. Valid values:

* **SUCCESS**: The task was successful.
* **IGNORED**: The task was ignored.
* **RUNNING**: The task is running.
* **EXCEPTION**: The task is abnormal.', example='RUNNING'),
        tableSchema?: string(name='TableSchema', description='The name of the table that is used for stress testing.', example='[{"TABLE_NAME":"customer1","TABLE_SCHEMA":"tpcc"}]'),
        taskId?: string(name='TaskId', description='The task ID.', example='e5cec704-0518-430f-8263-76f4dcds****'),
        taskType?: string(name='TaskType', description='The type of the stress testing task. Valid values:

* **pressure test** (default): A task of this type replays the traffic that is captured from the source instance on the destination instance at the maximum playback rate that is supported by the destination instance.
* **smart pressure test**: A task of this type analyzes the traffic that is captured from the source instance over a short period of time and generates traffic on the destination instance for continuous stress testing. The business model based on which the traffic is generated on the destination instance and the traffic distribution are consistent with those on the source instance. Stress testing tasks of this type can help you reduce the amount of time that is consumed to collect data from the source instance and reduce storage costs and performance overheads.', example='pressure test'),
        topic?: string(name='Topic', description='The topic that contains the consumed data. This topic is a topic in Message Queue for Apache Kafka.', example='das'),
        userId?: string(name='UserId', description='The Alibaba Cloud account ID.', example='1091411816252****'),
        version?: string(name='Version', description='The version of the stress testing task. Valid values:

* **V2.0**
* **V3.0**', example='V3.0'),
        workDir?: string(name='WorkDir', description='The path of the temporary directory that is generated for stress testing.', example='/tmp/bench/'),
      }
    ](name='cloudbenchTasks')
    }(name='List', description='The detailed information of the stress testing task.'),
    pageNo?: int32(name='PageNo', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    total?: long(name='Total', description='The total number of entries returned.', example='2'),
  }(name='Data', description='The detailed information, including the error codes and the number of entries that are returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeCloudBenchTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeCloudBenchTasksResponseBody(name='body'),
}

/**
  * Database Autonomy Service (DAS) provides the intelligent stress testing feature. This feature helps you check whether your instance needs to be scaled up to effectively handle traffic spikes. For more information, see [Intelligent stress testing](~~155068~~).
  *
 */
async function describeCloudBenchTasks(request: DescribeCloudBenchTasksRequest): DescribeCloudBenchTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeCloudBenchTasks', 'POST', '/', 'json', false, 'json', request);
}

model DescribeCloudbenchTaskRequest {
  taskId: string(name='TaskId', description='The ID of the stress testing task. You can call the [DescribeCloudBenchTasks](~~230670~~) operation to query the ID.', example='e5cec704-0518-430f-8263-76f4dcds****', position='Query'),
}

model DescribeCloudbenchTaskResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    archiveJobId?: string(name='ArchiveJobId', description='The ID of the archiving task.', example='\\"202105211430070112231480820340758****'),
    archiveOssTableName?: string(name='ArchiveOssTableName', description='The name of the table that was archived to Object Storage Service (OSS).', example='custins15546355_161604665****'),
    archiveState?: int32(name='ArchiveState', description='The archiving state of the file that stores the analysis result of full SQL statistics. Valid values:

*   **0**: The file archiving is not started.
*   **1**: The file is archived.
*   **2**: An error occurred.
*   **3**: The file is being archived.
*   **4**: The archived file does not need to be downloaded.', example='1'),
    backupId?: string(name='BackupId', description='The ID of the backup set. You can call the [DescribeBackups](~~26273~~) operation to query the ID of the backup set.', example='229132'),
    backupType?: string(name='BackupType', description='The backup type. Valid values:

*   **TIMESTAMP**
*   **BACKUPID**', example='TIMESTAMP'),
    benchStep?: string(name='BenchStep', description='The substep in the stress testing task. Valid values:

*   **NEW**: initializes the stress testing task.
*   **WAIT_BUY_ECS**: purchases an ECS instance.
*   **WAIT_START_ECS**: starts an ECS instance.
*   **WAIT_INSTALL_JDK**: installs the Java Development Kit (JDK).
*   **WAIT_INSTALL_DBGATEWAY**: installs the database gateway (DBGateway).
*   **ADD_SECURITY_IPS_STEP**: configure a security group whitelist.
*   **ARCHIVE**: archives the full SQL statistics.
*   **DOWNLOAD**: downloads the file that stores the analysis result of full SQL statistics.
*   **PROCEED**: preprocesses the file that stores the analysis result of full SQL statistics.
*   **PRE_LOAD**: preloads the file that stores the analysis result of full SQL statistics.
*   **VALIDATE**: verifies the functionality of stress testing.
*   **PRESSURE**: starts the stress testing task.', example='PROCEED'),
    benchStepStatus?: string(name='BenchStepStatus', description='The status that indicates the substep performed on the stress testing task. Valid values:

*   **NEW**: The task is being initialized.
*   **RUNNING**: The task is running.
*   **FAILED**: The task failed.
*   **FINISHED**: The task is complete.
*   **Terminated**: The task is terminated.
*   **Deleted**: The task is deleted.', example='FINISHED'),
    clientGatewayId?: string(name='ClientGatewayId', description='The DBGateway ID of the stress testing client.', example='58598b2af48a0193dfc16fc6964ef****'),
    clientType?: string(name='ClientType', description='The type of the stress testing client. Valid values:

*   **ECS**: indicates that you must create the [DBGateway](~~64905~~).
*   **DAS_ECS**: indicates that DAS automatically purchases and deploys an ECS instance for stress testing.', example='ECS'),
    description?: string(name='Description', description='The description of the stress testing task.', example='test-das-bench-0501'),
    dstInstanceUuid?: string(name='DstInstanceUuid', description='The UUID of the destination instance.', example='hdm_d887b5ccf99fa0dc9a1e5aaac368****'),
    dstIp?: string(name='DstIp', description='The reserved parameter.', example='None'),
    dstPort?: int32(name='DstPort', description='The port number of the destination instance.', example='3306'),
    dstType?: string(name='DstType', description='The type of the identifier that is used to indicate the destination instance. Valid values:

*   **Instance** (default): the instance ID.
*   **ConnectionString**: the endpoint of the instance.', example='Instance'),
    dtsJobClass?: string(name='DtsJobClass', description='The specification of the DTS task.', example='medium'),
    dtsJobId?: string(name='DtsJobId', description='The ID of the DTS migration task.', example='i03e3zty16i****'),
    dtsJobName?: string(name='DtsJobName', description='The name of the Data Transmission Service (DTS) task.', example='RDS_TO_RDS_MIGRATION'),
    dtsJobState?: int32(name='DtsJobState', description='The state of the DTS task. Valid values:

*   **NOT_STARTED**: The task is not started.
*   **PRE_CHECKING**: The task is in precheck.
*   **PRE_CHECK_FAILED**: The precheck failed.
*   **CHECKING**: The task is being checked.
*   **MIGRATING**: The data is being migrated.
*   **CATCHED**: The data is migrated from the source instance to the destination instance.
*   **SUSPENDING**: The task is suspended.
*   **MIGRATION_FAILED**: The data failed to be migrated.
*   **FINISHED**: The task is complete.
*   **INITIALIZING**: The synchronization is being initialized.
*   **INITIALIZE_FAILED**: The synchronization failed to be initialized.
*   **SYNCHRONIZING**: The data is being synchronized.
*   **MODIFYING**: The objects to be synchronized are being changed.
*   **SWITCHING**: The roles of the instances are being switched.
*   **FAILED**: The task failed.', example='CHECKING'),
    dtsJobStatus?: string(name='DtsJobStatus', description='The state of the DTS task. Valid values:

*   **NOT_STARTED**: The task is not started.
*   **PRE_CHECKING**: The task is in precheck.
*   **PRE_CHECK_FAILED**: The precheck failed.
*   **CHECKING**: The task is being checked.
*   **MIGRATING**: The data is being migrated.
*   **CATCHED**: The data is migrated from the source instance to the destination instance.
*   **SUSPENDING**: The task is suspended.
*   **MIGRATION_FAILED**: The data failed to be migrated.
*   **FINISHED**: The task is complete.
*   **INITIALIZING**: The synchronization is being initialized.
*   **INITIALIZE_FAILED**: The synchronization failed to be initialized.
*   **SYNCHRONIZING**: The data is being synchronized.
*   **MODIFYING**: The objects to be synchronized are being changed.
*   **SWITCHING**: The roles of the instances are being switched.
*   **FAILED**: The task failed.', example='PRE_CHECKING'),
    ecsInstanceId?: string(name='EcsInstanceId', description='The ID of the Elastic Compute Service (ECS) instance.', example='i-bp1ecr5go2go1****'),
    endState?: string(name='EndState', description='The state that specifies the last operation that is performed for the stress testing task. Valid values:

*   **WAIT_TARGET**: prepares the destination instance.
*   **WAIT_DBGATEWAY**: prepares the DBGateway.
*   **WAIT_SQL**: prepares the full SQL statistics.
*   **WAIT_LOGIC**: prepares to replay the traffic.

>  When the state of a stress testing task changes to the state that is specified by the EndState parameter, the stress testing task becomes completed.', example='WAIT_LOGIC'),
    errorCode?: string(name='ErrorCode', description='The error code returned for the substep of the stress testing task.', example='10910'),
    errorMessage?: string(name='ErrorMessage', description='The error message returned if the request failed.', example='DTS-070211: Connect Source DB failed. cause by [com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException:Could not create connection to database server. Attempted reconnect 3 times. Giving up.][com.mysql.jdbc.exceptions.jdbc4.CommunicationsException:Communications link failure\\n\\nThe last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.][java.net.ConnectException:Connection timed out (Connection timed out)] About more information in [https://yq.aliyun.com/articles/499178].'),
    external?: string(name='External', description='The additional information.', example='Null'),
    rate?: long(name='Rate', description='The rate at which the stress testing task replayed the traffic. The value is a positive integer. Valid values:**1** to **30**. Default value: **1**.', example='1'),
    requestDuration?: long(name='RequestDuration', description='The duration of the stress testing task for which traffic was captured from the source instance.', example='864000'),
    smartPressureTime?: int32(name='SmartPressureTime', description='The duration of the stress testing task for which the traffic was generated on the destination instance. Unit: milliseconds.', example='86400000'),
    source?: string(name='Source', description='The source of the task. Valid values:

*   **DAS**
*   **OPEN_API**', example='DAS'),
    sqlCompleteReuse?: string(name='SqlCompleteReuse', description='The reuse information about the analysis result of full SQL statistics.', example='{"sqlUuid":"task_a37d2f07-45cb-****-a2a6-c66c62****","metaUuid":"task_211e2561-5c0c-486b-864c-56b511****","sqlFile":"cl-1620057600000-1800626.sc","metaFile":"cl-1620057600000-180****.meta"}'),
    srcInstanceArea?: string(name='SrcInstanceArea', description='The database type of the source instance. Valid values:', example='RDS'),
    srcInstanceUuid?: string(name='SrcInstanceUuid', description='The UUID of the source instance.', example='a364e414-e68b-4e5c-9166-65b3a153****'),
    srcPublicIp?: string(name='SrcPublicIp', description='The reserved parameter.', example='None'),
    state?: string(name='State', description='The state that indicates the operation performed for the stress testing task. Valid values:

*   **WAIT_TARGET**: prepares the destination instance.
*   **WAIT_DBGATEWAY**: prepares the DBGateway.
*   **WAIT_SQL**: prepares the full SQL statistics.
*   **WAIT_LOGIC**: prepares to replay the traffic.', example='WAIT_TARGET'),
    status?: string(name='Status', description='The state of the stress testing task. Valid values:

*   **SUCCESS**: The task is successful.
*   **IGNORED**: The task is ignored.
*   **RUNNING**: The task is running.
*   **EXCEPTION**: An error occurred.', example='RUNNING'),
    tableSchema?: string(name='TableSchema', description='The name of the table that is used for stress testing.', example='[{"TABLE_NAME":"customer1","TABLE_SCHEMA":"tpcc"}]'),
    taskId?: string(name='TaskId', description='The task ID.', example='e5cec704-0518-430f-8263-76f4dcds****'),
    taskType?: string(name='TaskType', description='The type of the stress testing task. Valid values:

*   **pressure test** (default): A task of this type replays the traffic that is captured from the source instance on the destination instance at the maximum playback rate that is supported by the destination instance.
*   **smart pressure test**: A task of this type analyzes the traffic that is captured from the source instance over a short period of time and generates traffic on the destination instance for continuous stress testing. The business model based on which the traffic is generated on the destination instance and the traffic distribution are consistent with those on the source instance. Stress testing tasks of this type can help you reduce the amount of time that is consumed to collect data from the source instance and reduce storage costs and performance overheads.', example='pressure test'),
    topic?: string(name='Topic', description='The topic that contains the consumed data. This topic is a topic in Message Queue for Apache Kafka.', example='das'),
    userId?: string(name='UserId', description='The ID of the Alibaba Cloud account.', example='109141182625****'),
    version?: string(name='Version', description='The version of the stress testing task. Valid values:

*   **V2.0**
*   **V3.0**', example='V3.0'),
    workDir?: string(name='WorkDir', description='The temporary directory generated for stress testing.', example='/tmp/bench/'),
  }(name='Data', description='The detailed information, including the error codes and the number of entries that are returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model DescribeCloudbenchTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeCloudbenchTaskResponseBody(name='body'),
}

/**
  * Database Autonomy Service (DAS) provides the intelligent stress testing feature. This feature helps you check whether you need to scale up your database instance to handle workloads during peak hours. For more information, see [Intelligent stress testing](~~155068~~).
  *
 */
async function describeCloudbenchTask(request: DescribeCloudbenchTaskRequest): DescribeCloudbenchTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeCloudbenchTask', 'POST', '/', 'json', false, 'json', request);
}

model DescribeCloudbenchTaskConfigRequest {
  taskId: string(name='TaskId', description='The task ID. You can call the [DescribeCloudBenchTasks](~~230670~~) operation to query the task ID.', example='e5cec704-0518-430f-8263-76f4dcds****', position='Query'),
}

model DescribeCloudbenchTaskConfigResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    archiveFolder?: string(name='ArchiveFolder', description='The path in which the files are archived.', example='/tmp/das/cloudbench/archive-sqls/'),
    benchCmd?: string(name='BenchCmd', description='The command that was run to start the stress testing task.', example='java -jar /tmp/das/cloudbench/CloudBenchClient.jar --bench --rocksdb /tmp/das/cloudbench/rocksdb --meta /tmp/das/cloudbench/cl-1621353601000-360****.meta --task_name 2777bba9-a836-49e6-9f70-1c3822fc9239 --result_file /tmp/das/cloudbench/null.result --user cloudb**** --pwd \\"cloudbench@****\\" --host rm-bp1j5f8s5x26kq79216****.mysql.rds.aliyuncs.com --port 3306 --charset utf8mb4 --interval 1 --bench_time 3600 --rate_factor 1.0 --start_time 1621353601 --rt > /tmp/das/cloudbench/null.log'),
    clientJarPath?: string(name='ClientJarPath', description='The path to the JAR file that is used for stress testing.', example='/tmp/das/cloudbench/CloudBenchClient.jar'),
    jarOnOss?: string(name='JarOnOss', description='The path to the JAR file that is stored in OSS. The JAR file is used for stress testing.', example='https://cloudbench-cn-hangzhou.oss-cn-hangzhou.aliyuncs.com/CloudBenchClient.jar?OSSAccessKeyId=LTAI5tKj8B4wikkVtupK****&Expires=1622441372&Signature=28p%2BCe4tNHpr9VPOcHc3Si9iOb****'),
    loadCmd?: string(name='LoadCmd', description='The command that was run to preload the file that stores the analysis result of full SQL statistics.', example='java -jar /tmp/das/cloudbench/CloudBenchClient.jar --load --out /tmp/das/cloudbench/cl-1621353601000-360****.sc --meta /tmp/das/cloudbench/cl-1621353601000-360****.meta --task_name 2777bba9-****-49e6-9f70-1c3822fc**** --rocksdb /tmp/das/cloudbench/rocksdb'),
    metaFileName?: string(name='MetaFileName', description='The name of the metadata file.', example='cl-1621353601000-360****.meta'),
    metaFileOnOss?: string(name='MetaFileOnOss', description='The name of the metadata file stored in Object Storage Service (OSS).', example='"https://cb-rm-bp1w9g06h560l****.oss-cn-hangzhou.aliyuncs.com/cl-1621353601000-360****.meta?OSSAccessKeyId=LTAI5tKj8B4wikkVtupK****&Expires=1622441372&Signature=Qsehg3tzeA57M%2BIixAbWPWAtvl****'),
    metaFilePath?: string(name='MetaFilePath', description='The path to the metadata file.', example='/tmp/das/cloudbench/cl-1621353601000-360****.meta'),
    parseCmd?: string(name='ParseCmd', description='The command that was run to parse the file that stores the analysis result of full SQL statistics.', example='cd /tmp/das/cloudbench && java -jar CloudBenchClient.jar --parse --threads 32 --file /tmp/das/cloudbench/2777bba9-a836-49e6-9f70-1c3822fc9239.archiveSql --meta /tmp/das/cloudbench/cl-1621353601000-360****.meta --out /tmp/das/cloudbench/cl-1621353601000-360****.sc --parent_patmp/das/cloudbench --source RDS --h /thost rm-bp1j5f8s5x266****.mysql.rds.aliyuncs.com --port 3306 --user cloudb**** --pwd \\"cloudbench@****\\" --cutSqlLen 8192 --db_black_list=information_schema,test,unknow,null'),
    parseFilePath?: string(name='ParseFilePath', description='The path to the file that is parsed. The file stores the analysis result of full SQL statistics.', example='/tmp/das/cloudbench/2777bba9-a836-49e6-9f70-1c3822fc****.archiveSql'),
    rocksDbPath?: string(name='RocksDbPath', description='The location where the RocksDB storage system is deployed in the stress testing client.', example='/tmp/das/cloudbench/rocksdb'),
    sqlFileName?: string(name='SqlFileName', description='The name of the file that stores the analysis result of full SQL statistics.', example='cl-1621353601000-360****.sc'),
    sqlFileOnOss?: string(name='SqlFileOnOss', description='The name of the file that stores the analysis result of full SQL statistics and that is stored in OSS.', example='https://cb-rm-bp1w9g06h560l****.oss-cn-hangzhou.aliyuncs.com/cl-1621353601000-360****.sc?OSSAccessKeyId=LTAI5tKj8B4wikkVtupK****&Expires=1622441372&Signature=LYMADwo%2BRrJeqR3e4d8OlIkVmw****'),
    sqlFilePath?: string(name='SqlFilePath', description='The path to the file that stores the analysis result of full SQL statistics.', example='/tmp/das/cloudbench/cl-1621353601000-360****.sc'),
    taskId?: string(name='TaskId', description='The task ID.', example='e5cec704-0518-430f-8263-76f4dcds****'),
    userId?: string(name='UserId', description='The Alibaba Cloud account ID.', example='1091411816252****'),
    workDir?: string(name='WorkDir', description='The path of the temporary directory that is generated for stress testing.', example='/tmp/bench/'),
  }(name='Data', description='The detailed information, including the error codes and the number of entries that are returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeCloudbenchTaskConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeCloudbenchTaskConfigResponseBody(name='body'),
}

/**
  * Database Autonomy Service (DAS) provides the intelligent stress testing feature. This feature helps you check whether your instance needs to be scaled up to effectively handle traffic spikes. For more information, see [Intelligent stress testing](~~155068~~).
  *
 */
async function describeCloudbenchTaskConfig(request: DescribeCloudbenchTaskConfigRequest): DescribeCloudbenchTaskConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeCloudbenchTaskConfig', 'POST', '/', 'json', false, 'json', request);
}

model DescribeDiagnosticReportListRequest {
  DBInstanceId: string(name='DBInstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time.', example='1668420492000', position='Query'),
  pageNo?: string(name='PageNo', description='The page number. The value must be a positive integer. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1668398892000', position='Query'),
}

model DescribeDiagnosticReportListResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The information of the diagnostics reports. Valid values:

*   **total**: the number of diagnostics reports.
*   **score**: the health score.
*   **diagnosticTime**: the time when the diagnostics report was generated. The time is displayed in UTC.
*   **startTime**: the start time of the query. The time is displayed in UTC.
*   **endTime**: the end time of the query. The time is displayed in UTC.', example='{     "total": 1,     "list": [       {         "score": 100,         "diagnosticTime": "2022-11-14T08:17:00Z",         "startTime": "2022-11-14T07:16:59Z",         "endTime": "2022-11-14T08:16:59Z"       }     ]   }'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='D00DB161-FEF6-5428-B37A-8D29A4C2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
  synchro?: string(name='Synchro', description='The reserved parameter.', example='None'),
}

model DescribeDiagnosticReportListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeDiagnosticReportListResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation is applicable to the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   PolarDB for MySQL
  *     *   ApsaraDB for Redis
  *
 */
async function describeDiagnosticReportList(request: DescribeDiagnosticReportListRequest): DescribeDiagnosticReportListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeDiagnosticReportList', 'POST', '/', 'json', false, 'json', request);
}

model DescribeHotBigKeysRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceId: string(name='InstanceId', description='The ID of the ApsaraDB for Redis instance. You can call the [DescribeInstances](~~60933~~) operation to query the ID.', example='r-bp18ff4a195d****', position='Query'),
  nodeId?: string(name='NodeId', description='The ID of the data shard on the ApsaraDB for Redis instance. You can call the [DescribeRoleZoneInfo](~~190794~~) operation to query the ID.', example='r-****-db-0', position='Query'),
}

model DescribeHotBigKeysResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    bigKeyMsg?: string(name='BigKeyMsg', description='The reason why the large key failed to be queried.', example='current version doesn\\"t support'),
    bigKeys?: {
      bigKey?: [ 
      {
        db?: int32(name='Db', description='The database in which the key is stored.', example='0'),
        key?: string(name='Key', description='The key.', example='abc:def:eng'),
        keyType?: string(name='KeyType', description='The type of the key.', example='zset'),
        nodeId?: string(name='NodeId', description='The ID of the data shard on the ApsaraDB for Redis instance.', example='r-x****-db-0'),
        size?: long(name='Size', description='The number of elements in the key.', example='2'),
      }
    ](name='BigKey')
    }(name='BigKeys', description='The list of large keys.'),
    hotKeyMsg?: string(name='HotKeyMsg', description='The reason why the hot key failed to be queried.', example='current version doesn\\"t support'),
    hotKeys?: {
      hotKey?: [ 
      {
        db?: int32(name='Db', description='The database in which the key is stored.', example='0'),
        hot?: string(name='Hot', description='The frequency at which the key is accessed, which indicates the queries per second (QPS) of the key.', example='5500~6000'),
        key?: string(name='Key', description='The key.', example='abc:def:eng'),
        keyType?: string(name='KeyType', description='The type of the key.', example='zset'),
        lfu?: int32(name='Lfu', description='The statistical value that is calculated based on the least frequently used (LFU) caching algorithm.', example='253'),
        nodeId?: string(name='NodeId', description='The ID of the data shard on the ApsaraDB for Redis instance.', example='r-x****-db-0'),
      }
    ](name='HotKey')
    }(name='HotKeys', description='The list of hot keys.'),
  }(name='Data', description='The list of hot keys and large keys.'),
  message?: string(name='Message', description='The returned message.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model DescribeHotBigKeysResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeHotBigKeysResponseBody(name='body'),
}

/**
  * This operation sorts list, hash, set, and zset keys based on the number of elements contained in these keys. The top three keys that contain the most elements are considered large keys. If the number of queries per second (QPS) of a key is greater than 3,000, the key is considered a hot key.
  * *   If you use an Alibaba Cloud SDK, make sure that the aliyun-sdk-core version is later than 4.3.3. We recommend that you use the latest version.
  * *   The version of Database Autonomy Service (DAS) SDK must be 1.0.2 or later.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation is available only for ApsaraDB for Redis instances that meet the following requirements:
  *     *   The instance is a Community Edition instance that uses a major version of 5.0 or later or a performance-enhanced instance of the Enhanced Edition (Tair).
  *     *   The ApsaraDB for Redis instance is updated to the latest minor version.
  * >  For information about how to query and update the minor version of an instance, see [ModifyInstanceMinorVersion](~~129381~~) and [DescribeEngineVersion](~~95268~~).
  *
 */
async function describeHotBigKeys(request: DescribeHotBigKeysRequest): DescribeHotBigKeysResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeHotBigKeys', 'POST', '/', 'json', false, 'json', request);
}

model DescribeHotKeysRequest {
  instanceId: string(name='InstanceId', description='The ID of the ApsaraDB for Redis instance. You can call the [DescribeInstances](~~60933~~) operation to query the instance ID.', example='r-bp18ff4a195d****', position='Query'),
  nodeId?: string(name='NodeId', description='The ID of the data shard on the ApsaraDB for Redis instance. You can call the [DescribeRoleZoneInfo](~~190794~~) operation to query the data shard ID.', example='r-x****-db-0', position='Query'),
}

model DescribeHotKeysResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    hotKey?: [ 
    {
      db?: int32(name='Db', description='The database in which the key is stored.', example='0'),
      hot?: string(name='Hot', description='The frequency at which the key is accessed, which indicates the queries per second (QPS) of the key.', example='5500~6000'),
      key?: string(name='Key', description='The name of the key.', example='abc:def:eng'),
      keyType?: string(name='KeyType', description='The type of the key.', example='zset'),
      size?: long(name='Size', description='The number of elements in the key.', example='2'),
    }
  ](name='HotKey')
  }(name='Data', description='The details of the hot keys.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeHotKeysResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeHotKeysResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK, make sure that the aliyun-sdk-core version is later than V4.3.3. We recommend that you use the latest version.
  * *   The version of your Database Autonomy Service (DAS) SDK must be V1.0.2 or later.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation is applicable only to ApsaraDB for Redis instances that meet the following requirements:
  *     *   The ApsaraDB for Redis instance is a Community Edition instance that uses a major version of 4.0 or later or a performance-enhanced instance of the Enhanced Edition (Tair).
  *     *   The ApsaraDB for Redis instance is updated to the latest minor version.
  * >  For more information about how to query and update the minor version of an instance, see [ModifyInstanceMinorVersion](~~129381~~) and [DescribeEngineVersion](~~95268~~).
  *
 */
async function describeHotKeys(request: DescribeHotKeysRequest): DescribeHotKeysResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeHotKeys', 'POST', '/', 'json', false, 'json', request);
}

model DescribeInstanceDasProRequest {
  instanceId: string(name='InstanceId', description='The database instance ID.', example='rm-2ze8g2am97624****', position='Query'),
}

model DescribeInstanceDasProResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: boolean(name='Data', description='Indicates whether DAS Enterprise Edition is enabled for the database instance. Valid values:

*   **true**
*   **false**', example='true'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='9CB97BC4-6479-55D0-B9D0-EA925AFE****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeInstanceDasProResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeInstanceDasProResponseBody(name='body'),
}

/**
  * *   For more information about database instances that support DAS Enterprise Edition, see [Overview of DAS Enterprise Edition](~~190912~~).
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation is applicable only to DAS Enterprise Edition V1 and V2.
  *
 */
async function describeInstanceDasPro(request: DescribeInstanceDasProRequest): DescribeInstanceDasProResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeInstanceDasPro', 'POST', '/', 'json', false, 'json', request);
}

model DescribeSqlLogConfigRequest {
  instanceId: string(name='InstanceId', description='The ID of the database instance.', example='rm-2ze8g2am97624****', position='Body'),
}

model DescribeSqlLogConfigResponseBody = {
  code?: string(name='Code', description='The response code.', example='200'),
  data?: {
    coldEnable?: boolean(name='ColdEnable', description='Indicates whether the cold data storage is enabled. Valid values:

*   **true**
*   **false**', example='true'),
    coldRetention?: int32(name='ColdRetention', description='The number of days for which the SQL Explorer and Audit data is stored in cold storage.', example='23'),
    coldStartTime?: long(name='ColdStartTime', description='The time when the cold data storage was enabled. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1683712800000'),
    collectorVersion?: string(name='CollectorVersion', description='The collector version. Valid values:

*   **MYSQL_V0**
*   **MYSQL_V1**
*   **MYSQL_V2**
*   **MYSQL_V3**
*   **PG_V1**
*   **rdspg_v1**
*   **polarpg_v1**', example='MYSQL_V3'),
    hotEnable?: boolean(name='HotEnable', description='Indicates whether the hot data storage is enabled. Valid values:

*   **true**
*   **false**', example='true'),
    hotRetention?: int32(name='HotRetention', description='The number of days for which the SQL Explorer and Audit data is stored in hot storage.', example='7'),
    hotStartTime?: long(name='HotStartTime', description='The time when the hot data storage was enabled. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1683712800000'),
    logFilter?: string(name='LogFilter', description='A reserved parameter.', example='None'),
    requestEnable?: boolean(name='RequestEnable', description='Indicates whether the SQL Explorer feature is enabled. Valid values:

*   **true**
*   **false**', example='true'),
    requestStartTime?: long(name='RequestStartTime', description='The time when the SQL Explorer feature was enabled. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1683712800000'),
    requestStopTime?: long(name='RequestStopTime', description='The time when DAS Enterprise Edition V1 expired. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1715335200000'),
    retention?: int32(name='Retention', description='The total storage duration of the SQL Explorer and Audit data. The value of this parameter is the sum of the values of **HotRetention** and **ColdRetention**. Unit: day.', example='30'),
    sqlLogEnable?: boolean(name='SqlLogEnable', description='Indicates whether DAS Enterprise Edition is enabled. Valid values:

*   **true**
*   **false**', example='true'),
    sqlLogState?: string(name='SqlLogState', description='The state of data migration. Valid values:

*   **FINISH**: The historical data is migrated.
*   **RUNNING**: The historical data is being migrated.
*   **FAILURE**: The historical data fails to be migrated.', example='FINISH'),
    sqlLogVisibleTime?: long(name='SqlLogVisibleTime', description='The time when DAS Enterprise Edition was enabled. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1683712800000'),
    supportVersion?: string(name='SupportVersion', description='The latest version of DAS Enterprise Edition that supports the database instance. Valid values:

*   **SQL_LOG_V0**: DAS Enterprise Edition V0.
*   **SQL_LOG_V1**: DAS Enterprise version V1.
*   **SQL_LOG_V2**: DAS Enterprise Edition V2.
*   **SQL_LOG_V3**: DAS Enterprise Edition V3.
*   **SQL_LOG_NOT_ENABLE**: DAS Enterprise Edition is not enabled.
*   **SQL_LOG_NOT_SUPPORT**: DAS Enterprise Edition is not supported.', example='SQL_LOG_V3'),
    version?: string(name='Version', description='The version of DAS Enterprise Edition that is enabled for the database instance. Valid values:

*   **SQL_LOG_V0**: DAS Enterprise Edition V0.
*   **SQL_LOG_V1**: DAS Enterprise version V1.
*   **SQL_LOG_V2**: DAS Enterprise Edition V2.
*   **SQL_LOG_V3**: DAS Enterprise Edition V3.
*   **SQL_LOG_NOT_ENABLE**: DAS Enterprise Edition is not enabled.
*   **SQL_LOG_NOT_SUPPORT**: DAS Enterprise Edition is not supported.', example='SQL_LOG_V3'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='0A74B755-98B7-59DB-8724-1321B394****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeSqlLogConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeSqlLogConfigResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a DAS SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function describeSqlLogConfig(request: DescribeSqlLogConfigRequest): DescribeSqlLogConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSqlLogConfig', 'POST', '/', 'json', true, 'form', request);
}

model DescribeSqlLogRecordsRequest {
  endTime?: long(name='EndTime', description='The end of the time range to query. Specify the time in the UNIX timestamp format. Unit: milliseconds.', example='1608888296000', position='Body'),
  filters?: [ 
    {
      key?: string(name='Key', description='The name of the filter parameter.

>  For more information about the supported filter parameters and their valid values, see the following **supplement about the Key parameter**.', example='keyWords'),
      value?: string(name='Value', description='The value of the filter parameter.', example='select'),
    }
  ](name='Filters', description='The filter conditions.', position='Query'),
  instanceId: string(name='InstanceId', description='The ID of the database instance.', example='pc-2ze8g2am97624****', position='Body'),
  nodeId?: string(name='NodeId', description='The node ID.

*   For ApsaraDB RDS for MySQL and PolarDB for MySQL, this parameter is available only for Cluster Edition instances. By default, if this parameter is not specified, the information about the logs of the primary node is returned.
*   Set this parameter to **polarx_cn** or **polarx_dn** if the node that you want to query belongs to a PolarDB-X 2.0 database instance. A value of polarx_cn indicates a compute node. A value of polarx_dn indicates a data node.', example='pi-uf6k5f6g3912i****', position='Body'),
  pageNo?: int32(name='PageNo', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  role?: string(name='Role', description='The role of the node of the PolarDB-X 2.0 database instance. Valid values:

*   \\*\\*polarx_cn\\*\\*: compute node
*   \\*\\*polarx_dn\\*\\*: data node', example='polarx_cn', position='Query'),
  startTime?: long(name='StartTime', description='The beginning of the time range to query. Specify the time in the UNIX timestamp format. Unit: milliseconds.', example='1596177993000', position='Body'),
}

model DescribeSqlLogRecordsResponseBody = {
  code?: string(name='Code', description='The response code.', example='200'),
  data?: {
    endTime?: long(name='EndTime', description='The end of the time range to query. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1608888296000'),
    finish?: string(name='Finish', description='Indicates whether the task was complete. Valid values:

*   **0**: The task failed.
*   **1**: The task was complete.

>  If the value of **Finish** is 0 and the value of **JobId** is returned, the request is an asynchronous request and the return result cannot be directly obtained. You must query the return result by using the value of **JobId**. Specify JobId as the key of **Filters** and the value of **JobId** as the value of Filters. Example: `Filters=[{"Key": "JobId", "Value": "******"}]`.', example='1'),
    items?: {
      SQLLogRecord?: [ 
        {
          accountName?: string(name='AccountName', description='The account of the database.', example='testname'),
          collection?: string(name='Collection', description='This is a reserved parameter.', example='None'),
          consume?: long(name='Consume', description='The duration of the query. Unit: milliseconds.', example='58'),
          cpuTime?: long(name='CpuTime', description='The CPU execution duration. Unit: microseconds.', example='100'),
          DBName?: string(name='DBName', description='The name of the database.', example='testdb'),
          executeTime?: string(name='ExecuteTime', description='The time when the query was performed. The time follows the ISO 8601 standard in the `yyyy-MM-ddTHH:mm:ssZ` format. The time is displayed in UTC.', example='2023-12-07T02:15:32Z'),
          ext?: string(name='Ext', description='The extended information. This parameter is a reserved parameter.', example='None'),
          frows?: long(name='Frows', description='The number of rows that are pulled by the compute nodes of the PolarDB-X 2.0 database instance.', example='10'),
          hostAddress?: string(name='HostAddress', description='The IP address of the client.', example='11.197.XX.XX'),
          lockTime?: long(name='LockTime', description='The lock wait duration. Unit: milliseconds.', example='0'),
          logicRead?: long(name='LogicRead', description='The number of logical reads.', example='0'),
          nodeId?: string(name='NodeId', description='The node ID.', example='pi-uf6k5f6g3912i****'),
          originTime?: long(name='OriginTime', description='The time when the query was performed. The value of this parameter is a UNIX timestamp. Unit: milliseconds.', example='1701886532000'),
          parallelDegree?: string(name='ParallelDegree', description='The parallel queue time of the PolarDB for MySQL instance. Unit: milliseconds.', example='10'),
          parallelQueueTime?: string(name='ParallelQueueTime', description='The parallelism of the PolarDB for MySQL instance.', example='2'),
          physicAsyncRead?: long(name='PhysicAsyncRead', description='The number of physical asynchronous reads.', example='0'),
          physicRead?: long(name='PhysicRead', description='The number of physical reads.', example='0'),
          physicSyncRead?: long(name='PhysicSyncRead', description='The number of physical synchronous reads.', example='0'),
          returnRows?: long(name='ReturnRows', description='The number of rows that are returned.', example='0'),
          rows?: long(name='Rows', description='The total number of rows that are updated or returned by the compute nodes of the PolarDB-X 2.0 database instance.', example='10'),
          scanRows?: long(name='ScanRows', description='The number of rows that are scanned.', example='0'),
          scnt?: long(name='Scnt', description='The number of requests that are sent to the data nodes by the compute nodes of the PolarDB-X 2.0 database instance.', example='10'),
          sqlId?: string(name='SqlId', description='The SQL statement ID.', example='c67649d4a7fb62c4f8c7a447c52b5b17'),
          sqlText?: string(name='SqlText', description='The SQL statement.', example='select resource_id as cluster_id, tpl_name \\n\\tfrom dbfree_alert_resource_tpl_ref\\n\\twhere user_id=? and type=\\"cluster\\" group by resource_id, tpl_name'),
          sqlType?: string(name='SqlType', description='The type of the SQL statement.', example='select'),
          state?: string(name='State', description='The state of the query. Valid values:

*   **0**: The query was successful.
*   **1**: The query failed to be performed.', example='0'),
          threadId?: long(name='ThreadId', description='The thread ID.', example='None'),
          traceId?: string(name='TraceId', description='The trace ID of the PolarDB-X 2.0 database instance. The value is the execution ID of the SQL statement on the data nodes.', example='14c93b7c7bf00000'),
          trxId?: string(name='TrxId', description='The transaction ID.', example='200000'),
          updateRows?: long(name='UpdateRows', description='The number of rows that are updated.', example='0'),
          useImciEngine?: string(name='UseImciEngine', description='Indicates whether the In-Memory Column Index (IMCI) feature is enabled for the PolarDB for MySQL instance. Valid values:

*   **true**
*   **false**', example='true'),
          vip?: string(name='Vip', description='The IP address that is resolved from the endpoint of the query link.', example='100.115.XX.XX'),
          writes?: long(name='Writes', description='The number of writes that are performed by the ApsaraDB RDS for SQL Server engine.', example='10'),
        }
      ](name='SQLLogRecord', description='The SQL log data.'),
    }(name='Items', description='The data.'),
    jobId?: string(name='JobId', description='The ID of the asynchronous task.', example='MzI4NTZfUUlOR0RBT19DTTlfTlUyMF9NWVNRTF9PREJTX0xWU18zMjg1Nl9teXNxbF9XZWQgTWFyIDA2IDE0OjUwOjQ3IENTVCAyMDI0XzBfMzBfRXhlY3V0ZVRpbWVfREVTQ19XZWQgTWFyIDA2IDE0OjM1OjQ3IENTVCAyMDI0Xw==_1709708406465'),
    startTime?: long(name='StartTime', description='The beginning of the time range to query. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1596177993000'),
    totalRecords?: long(name='TotalRecords', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, error information such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='F43E7FB3-CE67-5FFD-A59C-EFD278BCD7BE'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeSqlLogRecordsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeSqlLogRecordsResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or DAS SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function describeSqlLogRecords(request: DescribeSqlLogRecordsRequest): DescribeSqlLogRecordsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSqlLogRecords', 'POST', '/', 'json', true, 'form', request);
}

model DescribeSqlLogStatisticRequest {
  instanceId: string(name='InstanceId', description='The ID of the database instance.', example='rm-2ze1jdv45i7l6****', position='Body'),
}

model DescribeSqlLogStatisticResponseBody = {
  code?: string(name='Code', description='The response code.', example='200'),
  data?: {
    coldSqlSize?: long(name='ColdSqlSize', description='The size of the SQL Explorer and Audit data that is stored in cold storage. Unit: bytes.', example='8585901'),
    freeColdSqlSize?: long(name='FreeColdSqlSize', description='The free quota for cold data storage. Unit: bytes.', example='5041450'),
    freeHotSqlSize?: long(name='FreeHotSqlSize', description='The free quota for hot data storage. Unit: bytes.', example='297245'),
    hotSqlSize?: long(name='HotSqlSize', description='The size of the SQL Explorer and Audit data that is stored in hot storage. Unit: bytes.', example='1118042'),
    importSqlSize?: long(name='ImportSqlSize', description='The size of the SQL Explorer and Audit data that was generated in the most recent day. Unit: bytes.', example='23'),
    timestamp?: long(name='Timestamp', description='The timestamp. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1712568564928'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   true
*   false', example='true'),
}

model DescribeSqlLogStatisticResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeSqlLogStatisticResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a DAS SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function describeSqlLogStatistic(request: DescribeSqlLogStatisticRequest): DescribeSqlLogStatisticResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSqlLogStatistic', 'POST', '/', 'json', true, 'form', request);
}

model DescribeSqlLogTaskRequest {
  instanceId?: string(name='InstanceId', description='The ID of the database instance.', example='r-bp1nti25tc7bq5****', position='Body'),
  pageNo?: int32(name='PageNo', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  taskId?: string(name='TaskId', description='The task ID.', example='a4f5c4494dbd6713185d87a97aa53e8', position='Body'),
}

model DescribeSqlLogTaskResponseBody = {
  code?: string(name='Code', description='The response code.', example='200'),
  data?: {
    createTime?: long(name='CreateTime', description='The time when the task was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1681363254423'),
    end?: long(name='End', description='The end of the time range to query. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1608888296000'),
    expire?: boolean(name='Expire', description='Indicates whether the task has expired. Valid values:

*   **true**
*   **false**', example='false'),
    export?: string(name='Export', description='The download URL of the export task.', example='"https://das-sqllog-download-cn-hongkong.oss-cn-hongkong.aliyuncs.com/****"'),
    filters?: [ 
      {
        key?: string(name='Key', description='The name of the filter parameter.

>  For more information about the filter parameters, see the **Valid values of Key** section of this topic.', example='keyWords'),
        value?: any(name='Value', description='The value of the filter parameter.', example='select'),
      }
    ](name='Filters', description='The filter parameters.'),
    name?: string(name='Name', description='The task name.'),
    queries?: [ 
      {
        accountName?: string(name='AccountName', description='The database account.', example='testname'),
        consume?: long(name='Consume', description='The execution duration. Unit: millisecond.', example='58'),
        cpuTime?: long(name='CpuTime', description='The CPU execution time. Unit: microsecond.', example='100'),
        DBName?: string(name='DBName', description='The database name.', example='testdb01'),
        executeTime?: string(name='ExecuteTime', description='The execution time. The time follows the ISO 8601 standard in the `yyyy-MM-ddTHH:mm:ssZ` format. The time is displayed in UTC.', example='2023-12-07T02:15:32Z'),
        ext?: string(name='Ext', description='The extended information. This parameter is a reserved parameter.', example='None'),
        frows?: long(name='Frows', description='The number of rows pulled by the CNs of the PolarDB-X 2.0 instance.', example='10'),
        hostAddress?: string(name='HostAddress', description='The IP address of the client.', example='11.197.XX.XX'),
        lockTime?: long(name='LockTime', description='The lock wait time. Unit: millisecond.', example='0'),
        logicRead?: long(name='LogicRead', description='The number of logical reads.', example='0'),
        nodeId?: string(name='NodeId', description='The ID of the child node.', example='pi-bp1o58x3ib7e6****'),
        originTime?: long(name='OriginTime', description='The execution timestamp. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1701886532000'),
        parallelDegree?: string(name='ParallelDegree', description='The wait time of parallel queries in the queue in the PolarDB for MySQL instance. Unit: millisecond.', example='10'),
        parallelQueueTime?: string(name='ParallelQueueTime', description='The degree of parallelism (DOP) value of the PolarDB for MySQL instance.', example='2'),
        physicAsyncRead?: long(name='PhysicAsyncRead', description='The number of physical asynchronous reads.', example='0'),
        physicRead?: long(name='PhysicRead', description='The total number of physical reads.', example='0'),
        physicSyncRead?: long(name='PhysicSyncRead', description='The number of physical synchronous reads.', example='0'),
        returnRows?: long(name='ReturnRows', description='The number of rows returned.', example='0'),
        rows?: long(name='Rows', description='The total number of rows updated or returned by the CNs of the PolarDB-X 2.0 instance.', example='10'),
        scanRows?: long(name='ScanRows', description='The number of rows scanned.', example='0'),
        scnt?: long(name='Scnt', description='The number of requests from the compute nodes (CNs) to the data nodes (DNs) in the PolarDB-X 2.0 instance.', example='10'),
        sqlId?: string(name='SqlId', description='The ID of the SQL statement.', example='a4111670e80596c5bf42cf5154438a91'),
        sqlText?: string(name='SqlText', description='The queried SQL statement.', example='SELECT @@session.transaction_read_only'),
        sqlType?: string(name='SqlType', description='The type of the SQL statement. Valid values:

*   **SELECT**
*   **UPDATE**
*   **DELETE**', example='SELECT'),
        state?: string(name='State', description='The execution result of the SQL statement. Valid values:

*   **0**: The execution was successful.
*   **1**: The execution failed.', example='0'),
        threadId?: long(name='ThreadId', description='The thread ID.', example='None'),
        traceId?: string(name='TraceId', description='The trace ID of the PolarDB-X 2.0 instance, which is the execution ID of the SQL statement on the DN.', example='14c93b7c7bf00000'),
        trxId?: string(name='TrxId', description='The transaction ID.', example='200000'),
        updateRows?: long(name='UpdateRows', description='The number of rows updated.', example='0'),
        useImciEngine?: string(name='UseImciEngine', description='Indicates whether the PolarDB for MySQL instance uses In-Memory Column Indexes (IMCIs). Valid values:

*   **true**
*   **false**', example='true'),
        vip?: string(name='Vip', description='The IP address to which the endpoint used for query is resolved.', example='10.146.XX.XX'),
        writes?: long(name='Writes', description='The number of writes to the ApsaraDB RDS for SQL Server instance.', example='10'),
      }
    ](name='Queries', description='The results of the offline querying task.'),
    start?: long(name='Start', description='The beginning of the time range to query. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1596177993000'),
    status?: string(name='Status', description='The task state. Valid values:

*   **INIT**: The task is to be scheduled.
*   **RUNNING**: The task is running.
*   **FAILED**: The task failed.
*   **CANCELED**: The task is canceled.
*   **COMPLETED**: The task is complete.

>  If a task is in the **COMPLETED** state, you can view the results of the task.', example='COMPLETED'),
    taskId?: string(name='TaskId', description='The task ID.', example='9a4f5c4494dbd6713185d87a97aa53e8'),
    taskType?: string(name='TaskType', description='The task type. Valid values:

*   **Export**
*   **Query**', example='Query'),
    total?: long(name='Total', description='The total number of tasks.', example='1'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeSqlLogTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeSqlLogTaskResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a DAS SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call the API operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function describeSqlLogTask(request: DescribeSqlLogTaskRequest): DescribeSqlLogTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSqlLogTask', 'POST', '/', 'json', true, 'form', request);
}

model DescribeSqlLogTasksRequest {
  endTime?: long(name='EndTime', description='The end of the time range to query. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1608888296000', position='Body'),
  filters?: [ 
    {
      key?: string(name='Key', description='The name of the filter parameter.

>  For more information about the filter parameters, see the **Valid values of Key** section of this topic.', example='delimiter'),
      value?: string(name='Value', description='The value of the filter parameter.', example=','),
    }
  ](name='Filters', description='The filter parameters.', position='Body'),
  instanceId?: string(name='InstanceId', description='The ID of the database instance.', example='r-bp1nti25tc7bq5****', position='Body'),
  nodeId?: string(name='NodeId', description='The node ID.

>  This parameter is available only for instances that are deployed in the cluster architecture. You can specify this parameter to query the tasks of a specific node. If this parameter is not specified, the tasks of the primary node are returned by default.', example='pi-bp1o58x3ib7e6z496', position='Body'),
  pageNo?: int32(name='PageNo', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Body'),
  startTime?: long(name='StartTime', description='The beginning of the time range to query. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1596177993000', position='Body'),
}

model DescribeSqlLogTasksResponseBody = {
  code?: string(name='Code', description='The response code.', example='200'),
  data?: {
    list?: [ 
      {
        analysisTaskFinishTime?: long(name='AnalysisTaskFinishTime', description='The time when the analysis task was complete. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1712751923000'),
        analysisTaskStatus?: string(name='AnalysisTaskStatus', description='The state of the analysis task.

>  This parameter is a system parameter. You do not need to pay attention to the parameter.', example='SCAN_ANALYZE_COMPLETED'),
        createTime?: long(name='CreateTime', description='The time when the task was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1681363254423'),
        end?: long(name='End', description='The time when the task ended. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1705975320000'),
        expire?: boolean(name='Expire', description='Indicates whether the task expired. Valid values:

*   **true**
*   **false**', example='false'),
        filters?: [ 
          {
            key?: string(name='Key', description='The name of the filter parameter.

>  For more information about the filter parameters, see the **Valid values of Key** section of this topic.', example='delimiter'),
            value?: string(name='Value', description='The value of the filter parameter.', example=','),
          }
        ](name='Filters', description='The filter parameters.'),
        instanceId?: string(name='InstanceId', description='The ID of the database instance.', example='rm-2zew761kf7ho18752'),
        logCount?: long(name='LogCount', description='The number of log records.', example='99999'),
        name?: string(name='Name', description='The task name.', example='test01'),
        progress?: int32(name='Progress', description='The task progress.', example='100'),
        result?: string(name='Result', description='The URL that is returned if the value of TaskType is **Export**.', example='https://das-sqllog-download-cn-shanghai.oss-cn-shanghai.aliyuncs.com/la'),
        scanFileSize?: long(name='ScanFileSize', description='The number of files that are scanned.', example='3000'),
        start?: long(name='Start', description='The time when the task started. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1683859555482'),
        status?: string(name='Status', description='The task state. Valid values:

*   **INIT**: The task is to be scheduled.
*   **RUNNING**: The task is running.
*   **FAILED**: The task failed.
*   **CANCELED**: The task is canceled.
*   **COMPLETED**: The task is complete.

>  If a task is in the **COMPLETED** state, you can view the results of the task.', example='RUNNING'),
        taskId?: string(name='TaskId', description='The task ID.', example='9a4f5c4494dbd6713185d87a97aa53e8'),
        taskType?: string(name='TaskType', description='The task type. Valid values:

*   **Export**
*   **Query**', example='Export'),
      }
    ](name='List', description='The details of the data returned.'),
    pageNo?: long(name='PageNo', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    total?: long(name='Total', description='The number of tasks.', example='40'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DescribeSqlLogTasksResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeSqlLogTasksResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a DAS SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function describeSqlLogTasks(request: DescribeSqlLogTasksRequest): DescribeSqlLogTasksResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeSqlLogTasks', 'POST', '/', 'json', true, 'form', request);
}

model DescribeTopBigKeysRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

> 

*   The end time must be later than the start time.

*   Only data within the last four days can be queried.

*   The maximum interval between the **start time** and the** end time** is 3 hours.', example='1596177993001', position='Query'),
  instanceId: string(name='InstanceId', description='The ID of the ApsaraDB for Redis instance. You can call the [DescribeInstances](~~60933~~) operation to query the ID.', example='r-bp18ff4a195d****', position='Query'),
  nodeId?: string(name='NodeId', description='The ID of the data shard on the ApsaraDB for Redis instance. You can call the [DescribeRoleZoneInfo](~~190794~~) operation to query the ID.', example='r-x****-db-0', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1596177993000', position='Query'),
}

model DescribeTopBigKeysResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    bigKey?: [ 
    {
      db?: int32(name='Db', description='The database in which the key is stored.', example='0'),
      key?: string(name='Key', description='The key.', example='abc:def:eng'),
      keyType?: string(name='KeyType', description='The type of the key.', example='zset'),
      nodeId?: string(name='NodeId', description='The ID of the data shard on the ApsaraDB for Redis instance.', example='r-x****-db-0'),
      size?: long(name='Size', description='The number of elements in the key.', example='2'),
    }
  ](name='BigKey')
  }(name='Data', description='The detailed information about the large keys.

> This parameter is left empty If no large keys exist within the specified time range.'),
  message?: string(name='Message', description='The returned message.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model DescribeTopBigKeysResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeTopBigKeysResponseBody(name='body'),
}

/**
  * The list, hash, set, and zset keys are sorted based on the number of elements in these keys. The top three keys that have the most elements are considered large keys.
  * *   If you use an Alibaba Cloud SDK, make sure that the aliyun-sdk-core version is later than 4.3.3. We recommend that you use the latest version.
  * *   The version of Database Autonomy Service (DAS) SDK must be 1.0.2 or later.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation is available only for an ApsaraDB for Redis instance of one of the following versions:
  *     *   The instance is ApsaraDB for Redis Community Edition instances that use a major version of 5.0 or later or a performance-enhanced instance of the ApsaraDB for Redis Enhanced Edition (Tair).
  *     *   The ApsaraDB for Redis instance is updated to the latest minor version.
  * >  For information about how to query and update the minor version of an instance, see [ModifyInstanceMinorVersion](~~129381~~) and [DescribeEngineVersion](~~95268~~).
  *
 */
async function describeTopBigKeys(request: DescribeTopBigKeysRequest): DescribeTopBigKeysResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeTopBigKeys', 'POST', '/', 'json', false, 'json', request);
}

model DescribeTopHotKeysRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

> 

*   The end time must be later than the start time.

*   Only data within the last four days can be queried.

*   The maximum interval between the **start time** and the** end time** is 3 hours.', example='1596177993001', position='Query'),
  instanceId: string(name='InstanceId', description='The ID of the ApsaraDB for Redis instance. You can call the [DescribeInstances](~~60933~~) operation to query the ID.', example='r-bp18ff4a195d****', position='Query'),
  nodeId?: string(name='NodeId', description='The ID of the data shard on the ApsaraDB for Redis instance. You can call the [DescribeRoleZoneInfo](~~190794~~) operation to query the ID.', example='r-****-db-0', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1596177993000', position='Query'),
}

model DescribeTopHotKeysResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    hotKey?: [ 
    {
      db?: int32(name='Db', description='The database in which the key is stored.', example='0'),
      hot?: string(name='Hot', description='The frequency at which the key is accessed, which indicates the QPS of the key.', example='5500~6000'),
      key?: string(name='Key', description='The key.', example='abc:def:eng'),
      keyType?: string(name='KeyType', description='The type of the key.', example='zset'),
      lfu?: int32(name='Lfu', description='The statistical value that is calculated based on the least frequently used (LFU) caching algorithm.', example='253'),
      nodeId?: string(name='NodeId', description='The ID of the data shard on the ApsaraDB for Redis instance.', example='r-x****-db-0'),
    }
  ](name='HotKey')
  }(name='Data', description='The detailed information about the hot keys.'),
  message?: string(name='Message', description='The returned message.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model DescribeTopHotKeysResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DescribeTopHotKeysResponseBody(name='body'),
}

/**
  * If the number of queries per second (QPS) of a key is greater than 3,000, the key is considered a hot key.
  * *   If you use an Alibaba Cloud SDK, make sure that the aliyun-sdk-core version is later than 4.3.3. We recommend that you use the latest version.
  * *   The version of Database Autonomy Service (DAS) SDK must be 1.0.2 or later.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation is available only for an ApsaraDB for Redis instance of one of the following versions:
  *     *   The instance is a Community Edition instance that uses a major version of 4.0 or later or a performance-enhanced instance of the Enhanced Edition (Tair).
  *     *   The ApsaraDB for Redis instance is updated to the latest minor version.
  * >  For information about how to query and update the minor version of an instance, see [DescribeEngineVersion](~~95268~~) and [ModifyInstanceMinorVersion](~~129381~~).
  *
 */
async function describeTopHotKeys(request: DescribeTopHotKeysRequest): DescribeTopHotKeysResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DescribeTopHotKeys', 'POST', '/', 'json', false, 'json', request);
}

model DisableAllSqlConcurrencyControlRulesRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.

>  You must specify this parameter only if your database instance is an ApsaraDB RDS for MySQL instance or a PolarDB for MySQL cluster.', example='rm-2ze1jdv45i7l6****', position='Query'),
}

model DisableAllSqlConcurrencyControlRulesResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The reserved parameter.', example='None'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message that contains information such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DisableAllSqlConcurrencyControlRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DisableAllSqlConcurrencyControlRulesResponseBody(name='body'),
}

/**
  * This operation supports the following database engines:
  * *   ApsaraDB RDS for MySQL
  * *   PolarDB for MySQL
  *
 */
async function disableAllSqlConcurrencyControlRules(request: DisableAllSqlConcurrencyControlRulesRequest): DisableAllSqlConcurrencyControlRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DisableAllSqlConcurrencyControlRules', 'POST', '/', 'json', false, 'json', request);
}

model DisableAutoResourceOptimizeRulesRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceIds: string(name='InstanceIds', description='The database instance ID.

>  Set this parameter to a JSON array that consists of multiple instance IDs. Separate instance IDs with commas (,). Example: `[\\"Instance ID1\\", \\"Instance ID2\\"]`.', example='[\\"rm-2ze8g2am97624****\\",\\"rm-2ze9xrhze0709****\\"]', position='Query'),
}

model DisableAutoResourceOptimizeRulesResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    configFailInstanceCount?: long(name='ConfigFailInstanceCount', description='The number of database instances for which the automatic tablespace fragment recycling feature failed to be disabled.', example='1'),
    configFailInstanceList?: [ 
      {
        configSuccess?: boolean(name='ConfigSuccess', description='Indicates whether the automatic tablespace fragment recycling feature is disabled. Valid values:

* **true**

* **false**', example='false'),
        errorMessage?: string(name='ErrorMessage', description='The error message returned if the request failed.', example='cannot found instance by rm-2ze9xrhze0709****'),
        instanceId?: string(name='InstanceId', description='The database instance ID.', example='rm-2ze9xrhze0709****'),
      }
    ](name='ConfigFailInstanceList', description='The list of database instances for which the automatic tablespace fragment recycling feature failed to be disabled.'),
    configSuccessInstanceCount?: long(name='ConfigSuccessInstanceCount', description='The number of database instances for which the automatic tablespace fragment recycling feature is disabled.', example='1'),
    configSuccessInstanceList?: [ 
      {
        configSuccess?: boolean(name='ConfigSuccess', description='Indicates whether the automatic tablespace fragment recycling feature is disabled. Valid values:

* **true**

* **false**', example='true'),
        instanceId?: string(name='InstanceId', description='The database instance ID.', example='rm-2ze8g2am97624****'),
      }
    ](name='ConfigSuccessInstanceList', description='The list of database instances for which the automatic tablespace fragment recycling feature is disabled.'),
    totalInstanceCount?: long(name='TotalInstanceCount', description='The total number of database instances.', example='2'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DisableAutoResourceOptimizeRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DisableAutoResourceOptimizeRulesResponseBody(name='body'),
}

/**
  * If you use an SDK to call API operations of Database Autonomy Service (DAS), you must set the region ID to cn-shanghai.
  *
 */
async function disableAutoResourceOptimizeRules(request: DisableAutoResourceOptimizeRulesRequest): DisableAutoResourceOptimizeRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DisableAutoResourceOptimizeRules', 'POST', '/', 'json', false, 'json', request);
}

model DisableAutoThrottleRulesRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceIds: string(name='InstanceIds', description='The database instance IDs.

>  Set this parameter to a JSON array that consists of multiple instance IDs. Separate instance IDs with commas (,). Example: `[\\"Instance ID1\\",\\"Instance ID2\\"]`.', example='[\\"rm-2ze8g2am97624****\\",\\"rm-2ze9xrhze0709****\\"]', position='Query'),
}

model DisableAutoThrottleRulesResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    configFailInstanceCount?: long(name='ConfigFailInstanceCount', description='The number of database instances for which the automatic SQL throttling feature failed to be disabled.', example='1'),
    configFailInstanceList?: [ 
      {
        configSuccess?: boolean(name='ConfigSuccess', description='Indicates whether the automatic SQL throttling feature is disabled. Valid values:

* **true**

* **false**', example='false'),
        errorMessage?: string(name='ErrorMessage', description='The error message returned.', example='cannot found instance by rm-2ze9xrhze0709****'),
        instanceId?: string(name='InstanceId', description='The database instance ID.', example='rm-2ze9xrhze0709****'),
      }
    ](name='ConfigFailInstanceList', description='The database instances for which the automatic SQL throttling feature failed to be disabled.'),
    configSuccessInstanceCount?: long(name='ConfigSuccessInstanceCount', description='The number of database instances for which the automatic SQL throttling feature is disabled.', example='1'),
    configSuccessInstanceList?: [ 
      {
        configSuccess?: boolean(name='ConfigSuccess', description='Indicates whether the automatic SQL throttling feature is disabled. Valid values:

* **true**

* **false**', example='true'),
        instanceId?: string(name='InstanceId', description='The database instance ID.', example='rm-2ze8g2am97624****'),
      }
    ](name='ConfigSuccessInstanceList', description='The database instances for which the automatic SQL throttling feature is disabled.'),
    totalInstanceCount?: long(name='TotalInstanceCount', description='The total number of database instances.', example='2'),
  }(name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DisableAutoThrottleRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DisableAutoThrottleRulesResponseBody(name='body'),
}

/**
  * If you use an SDK to call operations of Database Autonomy Service (DAS), you must set the region ID to cn-shanghai.
  *
 */
async function disableAutoThrottleRules(request: DisableAutoThrottleRulesRequest): DisableAutoThrottleRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DisableAutoThrottleRules', 'POST', '/', 'json', false, 'json', request);
}

model DisableDasProRequest {
  instanceId: string(name='InstanceId', description='The database instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  userId?: string(name='UserId', description='The ID of the Alibaba Cloud account that is used to create the database instance.

>  This parameter is optional. The system can automatically obtain the account ID based on the value of InstanceId that you set when you call this operation.', example='196278346919****', position='Query'),
}

model DisableDasProResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The reserved parameter.', example='None'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='7172BECE-588A-5961-8126-C216E16B****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
  synchro?: string(name='Synchro', description='The reserved parameter.', example='None'),
}

model DisableDasProResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DisableDasProResponseBody(name='body'),
}

/**
  * *   For more information about database instances that support DAS Enterprise Edition, see [Overview of DAS Enterprise Edition](~~190912~~).
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation is applicable only to DAS Enterprise Edition V1.
  *
 */
async function disableDasPro(request: DisableDasProRequest): DisableDasProResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DisableDasPro', 'POST', '/', 'json', false, 'json', request);
}

model DisableInstanceDasConfigRequest {
  engine: string(name='Engine', description='The database engine. Set the value to Redis.', example='Redis', position='Query'),
  instanceId: string(name='InstanceId', description='The database instance ID.', example='r-bp1nti25tc7bq5****', position='Query'),
  scaleType: string(name='ScaleType', description='The type of auto scaling. Valid values:

*   **specScale**: The specifications of a database instance are automatically scaled up or down.
*   **shardScale**: The number of shards for a database instance is automatically increased or decreased.
*   **bandwidthScale**: The bandwidth of a database instance is automatically increased or decreased.', example='bandwidthScale', position='Query'),
}

model DisableInstanceDasConfigResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The result of disabling the auto scaling feature for the database instance.', example='success'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='7172BECE-588A-5961-8126-C216E16B****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DisableInstanceDasConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DisableInstanceDasConfigResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation is applicable only to ApsaraDB for Redis instances.
  *
 */
async function disableInstanceDasConfig(request: DisableInstanceDasConfigRequest): DisableInstanceDasConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DisableInstanceDasConfig', 'POST', '/', 'json', false, 'json', request);
}

model DisableSqlConcurrencyControlRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.

>  The database instance must be an ApsaraDB RDS for MySQL instance or a PolarDB for MySQL cluster.', example='rm-2ze1jdv45i7l6****', position='Query'),
  itemId: long(name='ItemId', description='The ID of the throttling rule that is applied to the instance. You can call the [GetRunningSqlConcurrencyControlRules](~~223538~~) operation to query the ID.', example='1', position='Query'),
}

model DisableSqlConcurrencyControlResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The detailed information, including the error codes and the number of entries that are returned.', example='Null'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model DisableSqlConcurrencyControlResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: DisableSqlConcurrencyControlResponseBody(name='body'),
}

/**
  * This operation is applicable to the following database engines:
  * *   ApsaraDB RDS for MySQL
  * *   PolarDB for MySQL
  *
 */
async function disableSqlConcurrencyControl(request: DisableSqlConcurrencyControlRequest): DisableSqlConcurrencyControlResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'DisableSqlConcurrencyControl', 'POST', '/', 'json', false, 'json', request);
}

model EnableDasProRequest {
  instanceId: string(name='InstanceId', description='The database instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  sqlRetention?: int32(name='SqlRetention', description='The storage duration of SQL Explorer data. Unit: day. Default value: **30**. Valid values:

*   **30**
*   **180**
*   **365**
*   **1095**
*   **1825**', example='30', position='Query'),
  userId?: string(name='UserId', description='The ID of the Alibaba Cloud account that is used to create the database instance.

>  This parameter is optional. The system can automatically obtain the account ID based on the value of InstanceId when you call this operation.', example='196278346919****', position='Query'),
}

model EnableDasProResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The reserved parameter.', example='None'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message that contains information such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='7172BECE-588A-5961-8126-C216E16B****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
  synchro?: string(name='Synchro', description='The reserved parameter.', example='None'),
}

model EnableDasProResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: EnableDasProResponseBody(name='body'),
}

/**
  * *   If you use an SDK to call the API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation is applicable only to DAS Enterprise Edition V1.
  * >  If your database instance supports DAS Enterprise Edition V3, you cannot call this operation to enable DAS Enterprise Edition V1. You can call the [ModifySqlLogConfig](~~2778835~~) operation to enable DAS Enterprise Edition V3 for your database instance. For more information about the databases and regions supported by each version of DAS Enterprise Edition, see [Editions and supported features](~~156204~~).
  *
 */
async function enableDasPro(request: EnableDasProRequest): EnableDasProResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'EnableDasPro', 'POST', '/', 'json', false, 'json', request);
}

model EnableSqlConcurrencyControlRequest {
  concurrencyControlTime: long(name='ConcurrencyControlTime', description='The duration within which the SQL throttling rule takes effect. Unit: seconds.

>  The throttling rule takes effect only within this duration.', example='300', position='Query'),
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.

>  You must specify the instance ID only if your database instance is an ApsaraDB RDS for MySQL instance or a PolarDB for MySQL cluster.', example='rm-2ze1jdv45i7l6****', position='Query'),
  maxConcurrency: long(name='MaxConcurrency', description='The maximum number of concurrent SQL statements. Set this parameter to a positive integer.

>  When the number of concurrent SQL statements that contain the specified keywords reaches this upper limit, the throttling rule is triggered.', example='3', position='Query'),
  sqlKeywords: string(name='SqlKeywords', description='The keywords that are used to identify the SQL statements that need to be throttled.

>  If you specify multiple SQL keywords, separate them with tildes (~). If the number of concurrent SQL statements that contain all the specified SQL keywords reaches the specified upper limit, the throttling rule is triggered.', example='call~open~api~test~4~from~POP', position='Query'),
  sqlType: string(name='SqlType', description='The type of the SQL statements. Valid values:

*   **SELECT**
*   **UPDATE**
*   **DELETE**', example='SELECT', position='Query'),
}

model EnableSqlConcurrencyControlResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The detailed information, including the error codes and the number of entries that are returned.', example='Null'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model EnableSqlConcurrencyControlResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: EnableSqlConcurrencyControlResponseBody(name='body'),
}

/**
  * This operation supports the following database engines:
  * *   ApsaraDB RDS for MySQL
  * *   PolarDB for MySQL
  *
 */
async function enableSqlConcurrencyControl(request: EnableSqlConcurrencyControlRequest): EnableSqlConcurrencyControlResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'EnableSqlConcurrencyControl', 'POST', '/', 'json', false, 'json', request);
}

model GetAsyncErrorRequestListByCodeRequest {
  end?: long(name='End', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time. The interval between the start time and the end time cannot exceed 24 hours.', example='1642566830000', position='Query'),
  errorCode?: string(name='ErrorCode', description='The error code. You can call the [GetAsyncErrorRequestStatByCode](~~409804~~) operation to query the MySQL error codes that may be generated in the SQL Explorer results of an instance.', example='1064', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  This parameter must be specified if the database instance is a PolarDB for MySQL cluster.', example='pi-wz9s658475e58****', position='Query'),
  start?: long(name='Start', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The start time must be within the storage duration of the SQL Explorer feature of the database instance, and can be up to 90 days earlier than the current time.', example='1642556990714', position='Query'),
}

model GetAsyncErrorRequestListByCodeResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    complete?: boolean(name='complete', description='Indicates whether the asynchronous request was complete.

*   **true**
*   **false**', example='true'),
    fail?: boolean(name='fail', description='Indicates whether the asynchronous request failed. Valid values:

*   **true**
*   **false**', example='false'),
    isFinish?: boolean(name='isFinish', description='Indicates whether the asynchronous request was complete. Valid values:

*   **true**
*   **false**', example='true'),
    result?: [ 
      {
        instanceId?: string(name='instanceId', description='The instance ID', example='rm-2ze8g2am97624****'),
        sqlId?: string(name='sqlId', description='SQL ID.', example='ad78a4e7d3ce81590c9dc2d5f4bc****'),
      }
    ](name='result', description='The instance ID.'),
    resultId?: string(name='resultId', description='The ID of the asynchronous request.', example='async__c39d43ece52d35267cc4b92a0c26****'),
    state?: string(name='state', description='The state of the asynchronous request. Valid values:

*   **RUNNING**
*   **SUCCESS**
*   **FAIL**', example='SUCCESS'),
    timestamp?: long(name='timestamp', description='The time when the asynchronous request was made. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1644559407740'),
  }(name='Data', description='The data returned.', example='{         "fail": false,         "data": [             {                 "sqlId": "ad78a4e7d3ce81590c9dc2d5f4bc****",                 "instanceId": "rm-2ze8g2am97624****"             },             {                 "sqlId": "0f92feacd92c048b06a16617a633****",                 "instanceId": "rm-2ze8g2am97624****"             }         ],         "resultId": "async__c39d43ece52d35267cc4b92a0c26****",         "isFinish": true,         "state": "SUCCESS",         "complete": true,         "timestamp": 1644559407740     }'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='9CB97BC4-6479-55D0-B9D0-EA925AFE****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetAsyncErrorRequestListByCodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAsyncErrorRequestListByCodeResponseBody(name='body'),
}

/**
  * >  GetAsyncErrorRequestListByCode is an asynchronous operation. After a request is sent, the complete results are not returned immediately. If the value of **isFinish** is **false** in the response, wait for 1 second and then send a request again. If the value of **isFinish** is **true**, the complete results are returned.
  * *   This API operation supports only ApsaraDB RDS for MySQL instances and PolarDB for MySQL clusters for which Database Autonomy Service (DAS) Enterprise Edition is enabled. For more information, see [Purchase DAS Enterprise Edition](~~163298~~).
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function getAsyncErrorRequestListByCode(request: GetAsyncErrorRequestListByCodeRequest): GetAsyncErrorRequestListByCodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAsyncErrorRequestListByCode', 'POST', '/', 'json', false, 'json', request);
}

model GetAsyncErrorRequestStatByCodeRequest {
  dbName?: string(name='DbName', description='The name of a database.', example='testdb01', position='Query'),
  end?: long(name='End', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time. The interval between the start time and the end time cannot exceed 24 hours.', example='1642566830000', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  This parameter must be specified for PolarDB for MySQL clusters.', example='pi-wz9s658475e58****', position='Query'),
  start?: long(name='Start', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The start time must be within the storage duration of the SQL Explorer feature of the database instance and can be up to 90 days earlier than the current time.', example='1642556990714', position='Query'),
}

model GetAsyncErrorRequestStatByCodeResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    complete?: boolean(name='complete', description='Indicates whether the asynchronous request was complete.

*   **true**
*   **false**', example='true'),
    fail?: boolean(name='fail', description='Indicates whether the asynchronous request failed. Valid values:

*   **true**
*   **false**', example='false'),
    isFinish?: boolean(name='isFinish', description='Indicates whether the asynchronous request was complete. Valid values:

*   **true**
*   **false**', example='true'),
    result?: [ 
      {
        count?: int32(name='count', description='The number of SQL queries corresponding to the error code.', example='1'),
        errorCode?: string(name='errorCode', description='The error code returned if the request failed.', example='1062'),
        instanceId?: string(name='instanceId', description='The instance ID.', example='rm-2ze8g2am97624****'),
      }
    ](name='result', description='The number of SQL queries corresponding to the error code.'),
    resultId?: string(name='resultId', description='The ID of the asynchronous request.', example='async__fcd7c35788e62324622c3b4a03de****'),
    state?: string(name='state', description='The state of the asynchronous request. Valid values:

*   **RUNNING**
*   **SUCCESS**
*   **FAIL**', example='SUCCESS'),
    timestamp?: long(name='timestamp', description='The time when the asynchronous request was made. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1644560866961'),
  }(name='Data', description='The data returned.', example='{     "fail": false,     "data": [       {         "instanceId": "rm-2ze8g2am97624****",         "count": 1,         "errorCode": "1062"       },       {         "instanceId": "rm-2ze8g2am97624****",         "count": 2,         "errorCode": "1064"      }     ],     "resultId": "async__fcd7c35788e62324622c3b4a03de****",     "isFinish": true,     "state": "SUCCESS",     "complete": true,     "timestamp": 1644560866961   }'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='840F51F7-9C01-538D-94F6-AE712905****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetAsyncErrorRequestStatByCodeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAsyncErrorRequestStatByCodeResponseBody(name='body'),
}

/**
  * >  GetAsyncErrorRequestStatByCode is an asynchronous operation After a request is sent, the complete results are not returned immediately. If the value of **isFinish** is **false** in the response, wait for 1 second and then send a request again. If the value of **isFinish** is **true**, the complete results are returned.
  * *   This API operation supports only ApsaraDB RDS for MySQL instances and PolarDB for MySQL clusters for which Database Autonomy Service (DAS) Enterprise Edition is enabled. For more information, see [Purchase DAS Enterprise Edition](~~163298~~).
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function getAsyncErrorRequestStatByCode(request: GetAsyncErrorRequestStatByCodeRequest): GetAsyncErrorRequestStatByCodeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAsyncErrorRequestStatByCode', 'POST', '/', 'json', false, 'json', request);
}

model GetAsyncErrorRequestStatResultRequest {
  dbName?: string(name='DbName', description='The name of the database.', example='testdb01', position='Query'),
  end?: long(name='End', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time. The interval between the start time and the end time cannot exceed 24 hours.', example='1642566830000', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  This parameter must be specified for PolarDB for MySQL instances.', example='pi-bp179lg03445l****', position='Query'),
  sqlIdList?: string(name='SqlIdList', description='The ID of the SQL template. Separate multiple SQL IDs with commas (,). You can call the [GetAsyncErrorRequestListByCode](~~410746~~) operation to query the ID of the SQL query for which MySQL error code is returned.', example='ad78a4e7d3ce81590c9dc2d5f4bc****,0f92feacd92c048b06a16617a633****', position='Query'),
  start?: long(name='Start', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The beginning of the time range to query must be within the storage duration of the database instance and can be up to 90 days earlier than the current time.', example='1642556990714', position='Query'),
}

model GetAsyncErrorRequestStatResultResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    complete?: boolean(name='complete', description='Indicates whether the asynchronous request was complete.

*   **true**
*   **false**', example='true'),
    fail?: boolean(name='fail', description='Indicates whether the request failed. Valid values:

*   **true**
*   **false**', example='false'),
    isFinish?: boolean(name='isFinish', description='Indicates whether the asynchronous request was successful. Valid values:

*   **true**
*   **false**', example='true'),
    result?: [ map[string]DataResultValue ](name='result', description='The returned data of the asynchronous request.'),
    resultId?: string(name='resultId', description='The ID of the asynchronous request.', example='async__61f45ee381b2fa4e8a6545e3bee9****'),
    state?: string(name='state', description='The state of the asynchronous request. Valid values:

*   **RUNNING**: The asynchronous request is running.
*   **SUCCESS**: The asynchronous request is successful.
*   **FAIL**: The asynchronous request fails.', example='SUCCESS'),
    timestamp?: long(name='timestamp', description='The time when the asynchronous request was made. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1644558576717'),
  }(name='Data', description='The data returned.', example='{         "fail": false,         "data": {             "ad78a4e7d3ce81590c9dc2d5f4bc****": {                 "sqlId": "ad78a4e7d3ce81590c9dc2d5f4bc****",                 "instanceId": "rm-2ze8g2am97624****",                 "count": 1             },             "0f92feacd92c048b06a16617a633****": {                 "sqlId": "0f92feacd92c048b06a16617a633****",                 "instanceId": "rm-2ze8g2am97624****",                 "count": 2             }         },         "resultId": "async__61f45ee381b2fa4e8a6545e3bee9****",         "isFinish": true,         "state": "SUCCESS",         "complete": true,         "timestamp": 1644558576717     }'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='3FC3F8EB-3564-5D1A-B187-3B03E5B0****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetAsyncErrorRequestStatResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAsyncErrorRequestStatResultResponseBody(name='body'),
}

/**
  * >  GetAsyncErrorRequestStatResult is an asynchronous operation. After a request is sent, the complete results are not returned immediately. If the value of **isFinish** is **false** in the response, wait for 1 second and then send a request again. If the value of **isFinish** is **true**, the complete results are returned.
  * *   This API operation supports only ApsaraDB RDS for MySQL instances and PolarDB for MySQL clusters for which Database Autonomy Service (DAS) Enterprise Edition is enabled. For more information, see [Purchase DAS Enterprise Edition](~~163298~~).
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function getAsyncErrorRequestStatResult(request: GetAsyncErrorRequestStatResultRequest): GetAsyncErrorRequestStatResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAsyncErrorRequestStatResult', 'POST', '/', 'json', false, 'json', request);
}

model GetAutoIncrementUsageStatisticRequest {
  dbNames?: string(name='DbNames', description='The database name. If you specify a database, the operation queries the usage of auto-increment table IDs in the specified database. Otherwise, the operation queries the usage of auto-increment table IDs in all databases on the instance.

>  Specify the parameter value as a JSON array, such as \\[\\"db1\\",\\"db2\\"]. Separate multiple database names with commas (,).', example='[\\"db1\\",\\"db2\\"]', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  ratioFilter: double(name='RatioFilter', description='The usage threshold of auto-increment IDs. Only usage that exceeds the threshold can be returned. Valid values are decimals that range from 0 to 1.', example='0.9', position='Query'),
  realTime: boolean(name='RealTime', description='Specifies whether to query real-time data. Valid values:

*   **true**: queries data in real time except for data generated in the last 10 minutes.****
*   **false**: queries data generated in the last 2 hours. If no such data exists, queries the latest data.', example='false', position='Query'),
}

model GetAutoIncrementUsageStatisticResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    autoIncrementUsageList?: [ 
      {
        autoIncrementCurrentValue?: long(name='AutoIncrementCurrentValue', description='The latest auto-increment ID.', example='2147483647'),
        autoIncrementRatio?: double(name='AutoIncrementRatio', description='The usage ratio of auto-increment IDs.', example='1'),
        columnName?: string(name='ColumnName', description='The column name.', example='id'),
        dbName?: string(name='DbName', description='The database name.', example='db01'),
        maximumValue?: long(name='MaximumValue', description='The maximum auto-increment ID that is supported by the current data type.', example='2147483647'),
        tableName?: string(name='TableName', description='The table name.', example='test_table'),
      }
    ](name='AutoIncrementUsageList', description='The usage details of auto-increment IDs.'),
    errorInfo?: string(name='ErrorInfo', description='The error message returned if the task fails.', example='the given database name list invalid, none of the database names in the list exist on the instance'),
    finish?: boolean(name='Finish', description='Indicates whether the task is complete. Valid values:

*   **true**
*   **false**', example='false'),
    taskStatus?: string(name='TaskStatus', description='The task status. Valid values:

*   **INIT**: The task is being initialized.
*   **RUNNING**: The task is being executed.
*   **SUCCESS**: The task succeeds.
*   **FAIL**: The task fails.', example='INIT'),
    timestamp?: long(name='Timestamp', description='The time when the request was made. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1697183353000'),
  }(name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request is successful, **Successful** is returned. Otherwise, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='0A74B755-98B7-59DB-8724-1321B394****'),
  success?: boolean(name='Success', description='Indicates whether the request is successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetAutoIncrementUsageStatisticResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAutoIncrementUsageStatisticResponseBody(name='body'),
}

/**
  * *   This operation is applicable only to ApsaraDB RDS for MySQL instances and PolarDB for MySQL clusters.
  * *   If you use an Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call DAS, you must set the region to cn-shanghai.
  *
 */
async function getAutoIncrementUsageStatistic(request: GetAutoIncrementUsageStatisticRequest): GetAutoIncrementUsageStatisticResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAutoIncrementUsageStatistic', 'POST', '/', 'json', false, 'json', request);
}

model GetAutoResourceOptimizeRulesRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceIds?: string(name='InstanceIds', description='The database instance IDs.

*   Specify the parameter value as a JSON array, such as `[\\"Database account 1\\",\\"Database account 2\\"]`. Separate database instance IDs with commas (,).

*   By default, if you leave this parameter empty, all database instances for which the automatic fragment recycling feature has been enabled within the current Alibaba Cloud account are returned. The following types of database instances are returned:

    *   Database instances for which the automatic fragment recycling feature is currently enabled.
    *   Database instances for which the automatic fragment recycling feature was once enabled but is currently disabled, including those for which DAS Enterprise Edition has been disabled but excluding those that have been released.', example='[\\"rm-2ze8g2am97624****\\",\\"rm-2vc54m2a6pd6p****\\",\\"rm-2ze9xrhze0709****\\",\\"rm-2ze8g2am97627****\\"]', position='Query'),
}

model GetAutoResourceOptimizeRulesResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    enableAutoResourceOptimizeCount?: long(name='EnableAutoResourceOptimizeCount', description='The number of database instances for which the automatic fragment recycling feature is currently enabled.', example='1'),
    enableAutoResourceOptimizeList?: [ 
      {
        autoDefragment?: boolean(name='AutoDefragment', description='Indicates whether the automatic fragment recycling feature is enabled. Valid values:

*   **true**
*   **false**', example='true'),
        dasProOn?: boolean(name='DasProOn', description='Indicates whether DAS Enterprise Edition is enabled. Valid values:

*   **true**
*   **false**', example='true'),
        instanceId?: string(name='InstanceId', description='The database instance ID.', example='rm-2ze8g2am97624****'),
        tableFragmentationRatio?: double(name='TableFragmentationRatio', description='The fragmentation rate of a single physical table for which the automatic fragment recycling feature is enabled.', example='0.2'),
        tableSpaceSize?: double(name='TableSpaceSize', description='The minimum storage usage of a single physical table for which the automatic fragment recycling feature is enabled. Unit: GB.', example='10'),
        userId?: string(name='UserId', description='The ID of the Alibaba Cloud account that is used to create the database instance.', example='140692647406****'),
      }
    ](name='EnableAutoResourceOptimizeList', description='The database instances for which the automatic fragment recycling feature is currently enabled.'),
    hasEnableRuleButNotDasProCount?: long(name='HasEnableRuleButNotDasProCount', description='The number of database instances for which the automatic fragment recycling feature is enabled and DAS Enterprise Edition is disabled.', example='1'),
    hasEnableRuleButNotDasProList?: [ 
      {
        autoDefragment?: boolean(name='AutoDefragment', description='Indicates whether the automatic fragment recycling feature is enabled. Valid values:

*   **true**
*   **false**', example='true'),
        dasProOn?: boolean(name='DasProOn', description='Indicates whether DAS Enterprise Edition is enabled. Valid values:

*   **true**
*   **false**', example='false'),
        instanceId?: string(name='InstanceId', description='The database instance ID.', example='rm-2ze9xrhze0709****'),
        tableFragmentationRatio?: double(name='TableFragmentationRatio', description='The fragmentation rate of a single physical table for which the automatic fragment recycling feature is enabled.', example='0.2'),
        tableSpaceSize?: double(name='TableSpaceSize', description='The minimum storage usage of a single physical table for which the automatic fragment recycling feature is enabled. Unit: GB.', example='10'),
        userId?: string(name='UserId', description='The ID of the Alibaba Cloud account that is used to create the database instance.', example='140692647406****'),
      }
    ](name='HasEnableRuleButNotDasProList', description='The database instances for which the automatic fragment recycling feature is enabled and DAS Enterprise Edition is disabled.

>  Automatic fragment recycling tasks are run on this type of database instances only if DAS Enterprise Edition is enabled for the database instances again.'),
    neverEnableAutoResourceOptimizeOrReleasedInstanceCount?: long(name='NeverEnableAutoResourceOptimizeOrReleasedInstanceCount', description='The number of database instances that do not exist or for which the automatic fragment recycling feature has never been enabled.

>  If a database instance does not exist, the instance has been released or the specified instance ID is invalid.', example='1'),
    neverEnableAutoResourceOptimizeOrReleasedInstanceIdList?: [ string ](name='NeverEnableAutoResourceOptimizeOrReleasedInstanceIdList', description='The database instances that do not exist or for which the automatic fragment recycling feature has never been enabled.'),
    totalAutoResourceOptimizeRulesCount?: long(name='TotalAutoResourceOptimizeRulesCount', description='The number of database instances for which the automatic fragment recycling feature has been enabled.', example='3'),
    turnOffAutoResourceOptimizeCount?: long(name='TurnOffAutoResourceOptimizeCount', description='The number of database instances for which the automatic fragment recycling feature was once enabled but is currently disabled.', example='1'),
    turnOffAutoResourceOptimizeList?: [ 
      {
        autoDefragment?: boolean(name='AutoDefragment', description='Indicates whether the automatic fragment recycling feature is enabled. Valid values:

*   **true**:
*   **false**', example='false'),
        dasProOn?: boolean(name='DasProOn', description='Indicates whether DAS Enterprise Edition is enabled. Valid values:

*   **true**
*   **false**', example='true'),
        instanceId?: string(name='InstanceId', description='The database instance ID.', example='rm-2vc54m2a6pd6p****'),
        tableFragmentationRatio?: double(name='TableFragmentationRatio', description='The fragmentation rate of a single physical table for which the automatic fragment recycling feature is enabled.', example='0.2'),
        tableSpaceSize?: double(name='TableSpaceSize', description='The minimum storage usage of a single physical table for which the automatic fragment recycling feature is enabled. Unit: GB.', example='10'),
        userId?: string(name='UserId', description='The ID of the Alibaba Cloud account that is used to create the database instance.', example='140692647406****'),
      }
    ](name='TurnOffAutoResourceOptimizeList', description='The database instances for which the automatic fragment recycling feature was once enabled but is currently disabled.'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetAutoResourceOptimizeRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAutoResourceOptimizeRulesResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an SDK to call API operations of Database Autonomy Service (DAS), you must set the region ID to cn-shanghai.
  * *   The database instance is an ApsaraDB RDS for MySQL instance of High-availability Edition.
  * *   The database instance has four or more cores, and **innodb_file_per_table** is set to **ON**.
  *
 */
async function getAutoResourceOptimizeRules(request: GetAutoResourceOptimizeRulesRequest): GetAutoResourceOptimizeRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAutoResourceOptimizeRules', 'POST', '/', 'json', false, 'json', request);
}

model GetAutoThrottleRulesRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceIds?: string(name='InstanceIds', description='The database instance IDs.

*   Set this parameter to a JSON array that consists of multiple instance IDs. Separate instance IDs with commas (,). Example: `[\\"Instance ID1\\",\\"Instance ID2\\"]`.

*   By default, if you leave this parameter empty, all database instances for which the automatic SQL throttling feature has been enabled within the current Alibaba Cloud account are returned. The following types of database instances are returned:

    *   Database instances for which the automatic SQL throttling feature is currently enabled.
    *   Database instances for which the automatic SQL throttling feature was once enabled but is currently disabled. Released database instances are not included.', example='[\\"rm-2ze8g2am97624****\\",\\"rm-2vc54m2a6pd6p****\\",\\"rm-2ze9xrhze0709****\\"]', position='Query'),
}

model GetAutoThrottleRulesResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    enableAutoThrottleCount?: long(name='EnableAutoThrottleCount', description='The number of database instances for which the automatic SQL throttling feature is currently enabled.', example='1'),
    enableAutoThrottleList?: [ 
      {
        abnormalDuration?: double(name='AbnormalDuration', description='The maximum period of time during which an exception occurs when automatic SQL throttling is triggered. Unit: minutes.', example='2'),
        activeSessions?: long(name='ActiveSessions', description='The maximum number of active sessions.', example='32'),
        allowThrottleEndTime?: string(name='AllowThrottleEndTime', description='The end time of the throttling window. The value of this parameter is in UTC.', example='23:59Z'),
        allowThrottleStartTime?: string(name='AllowThrottleStartTime', description='The start time of the throttling window. The value of this parameter is in UTC.', example='00:00Z'),
        autoKillSession?: boolean(name='AutoKillSession', description='Indicates whether abnormal SQL statements in execution are terminated at a time. Valid values:

> Abnormal SQL statements use the same template as the SQL statements that need to be throttled.

* **true**
* **false**', example='true'),
        cpuSessionRelation?: string(name='CpuSessionRelation', description='The logical relationship between the CPU utilization threshold and the maximum number of active sessions. Valid values:

* **AND**
* **OR**', example='AND'),
        cpuUsage?: double(name='CpuUsage', description='The CPU utilization threshold.', example='70'),
        instanceId?: string(name='InstanceId', description='The database instance ID.', example='rm-2ze8g2am97624****'),
        maxThrottleTime?: double(name='MaxThrottleTime', description='The maximum throttling duration. Unit: minutes.', example='10'),
        userId?: string(name='UserId', description='The ID of the Alibaba Cloud account that is used to create the database instance.', example='140692647406****'),
        visible?: boolean(name='Visible', description='Indicates whether the automatic SQL throttling feature is enabled. Valid values:

* **true**
* **false**', example='true'),
      }
    ](name='EnableAutoThrottleList', description='The database instances for which the automatic SQL throttling feature is currently enabled.'),
    neverEnableAutoThrottleOrReleasedInstanceCount?: long(name='NeverEnableAutoThrottleOrReleasedInstanceCount', description='The number of database instances that do not exist or for which the automatic SQL throttling feature has never been enabled.

>  If a database instance does not exist, the instance has been released or the specified instance ID is invalid.', example='1'),
    neverEnableAutoThrottleOrReleasedInstanceIdList?: [ string ](name='NeverEnableAutoThrottleOrReleasedInstanceIdList', description='The number of database instances that do not exist or for which the automatic SQL throttling feature has never been enabled.

>  If a database instance does not exist, the instance has been released or the specified instance ID is invalid.'),
    totalAutoThrottleRulesCount?: long(name='TotalAutoThrottleRulesCount', description='The number of databases for which the automatic SQL throttling feature has been enabled.', example='3'),
    turnOffAutoThrottleCount?: long(name='TurnOffAutoThrottleCount', description='The number of database instances for which the automatic SQL throttling feature was once enabled but is currently disabled.', example='1'),
    turnOffAutoThrottleList?: [ 
      {
        abnormalDuration?: double(name='AbnormalDuration', description='The maximum period of time during which the automatic SQL throttling feature is triggered. Unit: minutes.', example='2'),
        activeSessions?: long(name='ActiveSessions', description='The maximum number of active sessions.', example='64'),
        allowThrottleEndTime?: string(name='AllowThrottleEndTime', description='The end time of the throttling window. The value of this parameter is in UTC.', example='23:59Z'),
        allowThrottleStartTime?: string(name='AllowThrottleStartTime', description='The start time of the throttling window. The value of this parameter is in UTC.', example='00:00Z'),
        autoKillSession?: boolean(name='AutoKillSession', description='Indicates whether abnormal SQL statements in execution are terminated at a time. Valid values:

> Abnormal SQL statements use the same template as the SQL statements that need to be throttled.

* **true**
* **false**', example='true'),
        cpuSessionRelation?: string(name='CpuSessionRelation', description='The logical relationship between the CPU utilization threshold and the maximum number of active sessions. Valid values:

* **AND**
* **OR**', example='OR'),
        cpuUsage?: double(name='CpuUsage', description='The CPU utilization threshold.', example='80'),
        instanceId?: string(name='InstanceId', description='The database instance ID.', example='rm-2ze9xrhze0709****'),
        maxThrottleTime?: double(name='MaxThrottleTime', description='The maximum throttling duration. Unit: minutes.', example='10'),
        userId?: string(name='UserId', description='The ID of the Alibaba Cloud account that is used to create the database instance.', example='140692647406****'),
        visible?: boolean(name='Visible', description='Indicates whether the automatic SQL throttling feature is enabled. Valid values:

* **true**
* **false**', example='false'),
      }
    ](name='TurnOffAutoThrottleList', description='The database instances for which the automatic SQL throttling feature was once enabled but is currently disabled.'),
  }(name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message that contains information such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='7172BECE-588A-5961-8126-C216E16B****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetAutoThrottleRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAutoThrottleRulesResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an SDK to call API operations of Database Autonomy Service (DAS), you must set the region ID to cn-shanghai.
  * *   The database instance that you want to manage is of one of the following types:
  *     *   ApsaraDB RDS for MySQL High-availability Edition or Enterprise Edition instance that runs MySQL 5.6, MySQL 5.7, or MySQL 8.0.
  *     *   PolarDB for MySQL Cluster Edition instance that runs MySQL 5.6, MySQL 5.7, or MySQL 8.0, or PolarDB for MySQL X-Engine Edition instance that runs MySQL 8.0.
  *
 */
async function getAutoThrottleRules(request: GetAutoThrottleRulesRequest): GetAutoThrottleRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAutoThrottleRules', 'POST', '/', 'json', false, 'json', request);
}

model GetAutonomousNotifyEventContentRequest {
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-18ff4a195d****', position='Query'),
  spanId: string(name='SpanId', description='The unique identifier of the event. You can call the [GetAutonomousNotifyEventsInRange](~~288371~~) operation to query the unique identifier returned by the SpanId response parameter.', example='7e7b2774-95b8-4fa3-bd9c-0ab47cb7****', position='Query'),
  context?: string(name='__context', description='The reserved parameter.', example='None', position='Query'),
}

model GetAutonomousNotifyEventContentResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The details of the notification events.', example='{\\"taskId\\":\\"7e1ba595-0889-48ff-a6ff-010f54991d****\\",\\"taskType\\":\\"SQL_OPTIMIZE\\",\\"advisorId\\":\\"636dc5f34664dd56ff0****\\",\\"sqlId\\":\\"e2b1d6c1ee1bb29555a828b59f16****\\",\\"indexAdviceCount\\":1,\\"indexAdvices\\":[{\\"schemaName\\":\\"das\\",\\"tableName\\":\\"students\\",\\"indexName\\":\\"idx_name\\",\\"columns\\":[\\"name\\"],\\"unique\\":false,\\"ddlAddIndex\\":\\"ALTER TABLE `das`.`students` ADD INDEX `idx_name` (`name`)\\",\\"priority\\":0,\\"optimizeId\\":\\"96232794517277511\\"}],\\"tuningAdvices\\":[],\\"improvement\\":8127.25,\\"supportLevel\\":3,\\"priority\\":\\"HIGH\\"}'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetAutonomousNotifyEventContentResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAutonomousNotifyEventContentResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  * *   After your instance is connected to DAS, notification events such as snapshot capture are triggered if DAS detects changes to database monitoring metrics during anomaly detection.
  * >  You can query the details of notification events only if the autonomy center is enabled. For more information, see [Autonomy center](~~152139~~).
  *
 */
async function getAutonomousNotifyEventContent(request: GetAutonomousNotifyEventContentRequest): GetAutonomousNotifyEventContentResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAutonomousNotifyEventContent', 'POST', '/', 'json', false, 'json', request);
}

model GetAutonomousNotifyEventsInRangeRequest {
  endTime: string(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time.', example='1568265711221', position='Query'),
  eventContext?: string(name='EventContext', description='The reserved parameter.', example='None', position='Query'),
  instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-18ff4a195d****', position='Query'),
  level?: string(name='Level', description='The urgency level of the events. If you specify this parameter, the MinLevel parameter does not take effect. Valid values:

*   **Notice**: events for which the system sends notifications.
*   **Optimization**: events that need to be optimized.
*   **Warn**: events for which the system sends warnings.
*   **Critical**: critical events.', example='Warn', position='Query'),
  minLevel?: string(name='MinLevel', description='The minimum urgency level of the events. Valid values:

*   **Notice**: events for which the system sends notifications.
*   **Optimization**: events that need to be optimized.
*   **Warn**: events for which the system sends warnings.
*   **Critical**: critical events.', example='Notice', position='Query'),
  nodeId?: string(name='NodeId', description='The ID of the node in a PolarDB for MySQL cluster. You can call the [DescribeDBClusters](~~98094~~) operation to query the node ID returned by the DBNodeId response parameter.

>  You must specify the node ID if your database instance is a PolarDB for MySQL cluster.', example='r-x****-db-0', position='Query'),
  pageOffset?: string(name='PageOffset', description='The page number. The value must be a positive integer. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries per page.', example='30', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1568269711000', position='Query'),
  context?: string(name='__context', description='The reserved parameter.', example='None', position='Query'),
}

model GetAutonomousNotifyEventsInRangeResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    extra?: string(name='Extra', description='The reserved parameter.', example='None'),
    list?: {
      t?: [ string ](name='T')
    }(name='List', description='The detailed information, including the error codes and the number of entries that are returned.'),
    pageNo?: long(name='PageNo', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    total?: long(name='Total', description='The total number of entries returned.', example='4'),
  }(name='Data', description='The detailed information, including the error codes and the number of entries that are returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetAutonomousNotifyEventsInRangeResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetAutonomousNotifyEventsInRangeResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  * *   After your instance is connected to DAS, notification events such as snapshot capture are triggered if DAS detects changes to database monitoring metrics during anomaly detection.
  * >  You can query the details of notification events only if the autonomy center is enabled. For more information, see [Autonomy center](~~152139~~).
  *
 */
async function getAutonomousNotifyEventsInRange(request: GetAutonomousNotifyEventsInRangeRequest): GetAutonomousNotifyEventsInRangeResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetAutonomousNotifyEventsInRange', 'POST', '/', 'json', false, 'json', request);
}

model GetBlockingDetailListRequest {
  dbNameList?: string(name='DbNameList', description='The database name list.

*   Separate multiple database names with commas (,).', example='school1,school2', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1682490480548', position='Query'),
  instanceId: string(name='InstanceId', description='The database instance ID.', example='rm-t4nfalp2ap421312z', position='Query'),
  pageNo?: string(name='PageNo', description='The page number. The value must be an integer that is greater than 0. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries per page. The value must be an integer that is greater than 0. Default value: 10.', example='10', position='Query'),
  queryHash?: string(name='QueryHash', description='The hash value of the SQL statement.', example='DC08B955CAD25E7B', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1679429913757', position='Query'),
}

model GetBlockingDetailListResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    list?: [ 
      {
        batchId?: long(name='BatchId', description='The batch ID.', example='1683530096156'),
        clientAppName?: string(name='ClientAppName', description='The client name.', example='.Net SqlClient Data Provider'),
        currentCollectionTime?: long(name='CurrentCollectionTime', description='The time when the blocking data was collected.', example='1700065800000'),
        dataBase?: string(name='DataBase', description='The database name.', example='school'),
        hostName?: string(name='HostName', description='The client hostname.', example='ALLBNMGTAPPRD01'),
        loginId?: string(name='LoginId', description='The username that is used for the logon.', example='Cheney603'),
        queryHash?: string(name='QueryHash', description='The hash value of the SQL statement.', example='6977DD06CD9CAFF2'),
        spid?: string(name='Spid', description='The session ID.', example='1717'),
        sqlText?: string(name='SqlText', description='The SQL statement.', example='select * from test1'),
        startTime?: string(name='StartTime', description='The time when the execution started.', example='1608888296000'),
        waitTimeMs?: long(name='WaitTimeMs', description='The blocking duration. Unit: milliseconds.', example='30000'),
        waitType?: string(name='WaitType', description='The wait type.', example='MISCELLANEOUS'),
      }
    ](name='List', description='The details of the data returned.'),
    pageNo?: long(name='PageNo', description='The page number of the page returned.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries returned on each page.', example='10'),
    total?: long(name='Total', description='The total number of entries returned.', example='19'),
  }(name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request is successful, **Successful** is returned. Otherwise, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request is successful. Valid values:

*   true
*   false', example='true'),
}

model GetBlockingDetailListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetBlockingDetailListResponseBody(name='body'),
}

/**
  * *   This operation is applicable only to ApsaraDB RDS for SQL Server instances.
  * *   If you use an Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call the API operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function getBlockingDetailList(request: GetBlockingDetailListRequest): GetBlockingDetailListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetBlockingDetailList', 'POST', '/', 'json', false, 'json', request);
}

model GetDBInstanceConnectivityDiagnosisRequest {
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  srcIp: string(name='SrcIp', description='The source IP address.', example='47.110.180.62', position='Query'),
}

model GetDBInstanceConnectivityDiagnosisResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    connCheckErrorCode?: string(name='connCheckErrorCode', description='The exception detection items:

*   **SRC_IP_NOT_IN_USER_WHITELIST**: The source IP address is not added to the whitelist of the user.
*   **VIP_NOT_EXISTS**: The Application Load Balancer (ALB) instance corresponding to the virtual IP address (VIP) does not exist.
*   **RS_NOT_EXISTS**: The resource sharing (RS) is not properly mounted.
*   **VIP_TUNNEL_ID_NOT_CONSISTENT**: The tunnel ID used by the VIP of the virtual private cloud (VPC) type is different from the tunnel ID of the VPC.
*   **VIP_VPC_CLOUD_INSTANCE_NOT_EXISTS**: The VIP of the VPC type does not exist.
*   **VIP_IS_NOT_NGLB**: The NGLB mode is disabled for the VIP.
*   **CUSTINS_NOT_ASSOCIATE_ECS_SECURITY_GROUP**: No security group is associated with the instance.
*   **SRC_IP_NOT_IN_USER_WHITELIST**: The source IP address is not added to the whitelist of the user.
*   **SRC_IP_NOT_IN_ADMIN_WHITELIST**: The source IP address is not added to the whitelist of the instance.
*   **SRC_IP_NOT_IN_ECS_SECURITY_GROUP**: The source IP address is not added to the security group that is associated with the instance.
*   **VPC_INSTANCE_IP_NOT_WORKING_STATUS**: The IP address in the VPC is in an abnormal state.', example='SRC_IP_NOT_IN_USER_WHITELIST'),
    connCheckErrorMessage?: string(name='connCheckErrorMessage', description='The details of the exception detection.', example='Src ip:47.110.180.62 not in user whitelist'),
    failType?: string(name='failType', description='The type of the exception:

*   **0**: an exception that can be handled by the user.
*   **1**: an exception that can be handled by a technical engineer.', example='0'),
    instanceId?: string(name='instanceId', description='The instance ID.', example='rm-2ze8g2am97624****'),
    success?: boolean(name='success', description='Indicates whether the connectivity test was passed:

*   **true**
*   **false**', example='false'),
  }(name='Data', description='The detailed information.'),
  message?: string(name='Message', description='The returned message.

> If the request was successful, **Successful** is returned. Otherwise, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetDBInstanceConnectivityDiagnosisResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDBInstanceConnectivityDiagnosisResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   The database instance that you want to manage is connected to DAS.
  *
 */
async function getDBInstanceConnectivityDiagnosis(request: GetDBInstanceConnectivityDiagnosisRequest): GetDBInstanceConnectivityDiagnosisResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDBInstanceConnectivityDiagnosis', 'POST', '/', 'json', false, 'json', request);
}

model GetDasProServiceUsageRequest {
  instanceId: string(name='InstanceId', description='The database instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  userId?: string(name='UserId', description='The ID of the Alibaba Cloud account that is used to create the database instance.

>  This parameter is optional. The system can automatically obtain the account ID based on the value of InstanceId when you call this operation.', example='196278346919****', position='Query'),
}

model GetDasProServiceUsageResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    commodityInstanceId?: string(name='commodityInstanceId', description='The ID of the DAS Enterprise Edition instance.', example='daspro-cn-v0h1l6i****'),
    engine?: string(name='engine', description='The type of the database engine.', example='MySQL'),
    expireTime?: long(name='expireTime', description='The point of time when DAS Enterprise Edition for the database instance expires. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1648742400000'),
    instanceAlias?: string(name='instanceAlias', description='The name of the database instance.', example='TESTDB01'),
    instanceId?: string(name='instanceId', description='The database instance ID.', example='rm-2ze8g2am97624****'),
    ip?: string(name='ip', description='The endpoint of the database instance.', example='rm-2ze8g2am97624****.mysql.****.com'),
    isSpare?: boolean(name='isSpare', description='Indicates whether DAS Enterprise Edition for the database instance has expired. Valid values:

*   **true**
*   **false**', example='false'),
    migrationPredictRemainingTime?: long(name='migrationPredictRemainingTime', description='The estimated remaining time for migrating the data generated by the SQL Explorer and Audit feature from the previous version to the new version. Unit: milliseconds.

>  This parameter is returned only when the SQL Explorer and Audit feature is migrated from the previous version to the new version.', example='60000'),
    port?: int32(name='port', description='The port number that is used to connect to the database instance.', example='3306'),
    region?: string(name='region', description='The region in which the database instance resides.', example='cn-shanghai'),
    serviceUnitId?: string(name='serviceUnitId', description='The service unit ID.', example='4'),
    sqlRetention?: string(name='sqlRetention', description='The storage duration of SQL Explorer data. Unit: days.', example='180'),
    startTime?: long(name='startTime', description='The time when DAS Enterprise Edition was enabled for the database instance. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1646100892000'),
    storageFreeQuotaInMB?: double(name='storageFreeQuotaInMB', description='The SQL Explorer storage space that is offered free-of-charge. Unit: MB.', example='5120'),
    storageUsed?: long(name='storageUsed', description='The storage usage of SQL Explorer of the database instance. Unit: bytes.', example='35903498'),
    userId?: string(name='userId', description='The ID of the Alibaba Cloud account that is used to create the database instance.', example='196278346919****'),
    vpcId?: string(name='vpcId', description='The virtual private cloud (VPC) ID.', example='vpc-2zentqj1sk4qmolci****'),
  }(name='Data', description='The data returned.', example='{         "storageFreeQuotaInMB": 5120,         "ip": "rm-2ze8g2am97624****.mysql.****.com",         "custinsId": 12448331,         "userId": "196278346919****",         "uuid": "hdm_b0ae36343407609bf3e8df8709d8****",         "expireTime": 1924963200000,         "instanceId": "rm-2ze8g2am97624****",         "storageUsed": 10773752667393,         "engine": "MySQL",         "instanceAlias": "TESTDB01_PROD",         "port": 3310,         "vpcId": "hdm_****",         "commodityInstanceId": "daspro-****",         "startTime": 1606381940000,         "isSpare": false,         "region": "cn-shanghai",         "serviceUnitId": "5",         "sqlRetention": 30     }'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='7172BECE-588A-5961-8126-C216E16B****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetDasProServiceUsageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDasProServiceUsageResponseBody(name='body'),
}

/**
  * *   For information about database instances that support this operation, see [Overview of DAS Enterprise Edition](~~190912~~).
  * *   If you use an Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation is applicable only to DAS Enterprise Edition V1 and V2.
  *
 */
async function getDasProServiceUsage(request: GetDasProServiceUsageRequest): GetDasProServiceUsageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDasProServiceUsage', 'POST', '/', 'json', false, 'json', request);
}

model GetDasSQLLogHotDataRequest {
  accountName?: string(name='AccountName', description='The account of the database.

>  You can specify multiple database accounts that are separated by spaces. Example: `user1 user2 user3`.', example='testuser', position='Body'),
  childDBInstanceIDs?: string(name='ChildDBInstanceIDs', description='The node ID.

>  This parameter must be specified if the database instance is a PolarDB for MySQL cluster.', example='pi-bp179lg03445l****', position='Body'),
  DBName?: string(name='DBName', description='The name of the database.

>  You can specify multiple database names that are separated by spaces. Example: `DB1 DB2 DB3`.', example='testDB', position='Body'),
  end: long(name='End', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time. The interval between the start time and the end time cannot exceed 24 hours.', example='1684820697000', position='Body'),
  fail?: string(name='Fail', description='The error code of SQL execution. You can call the [GetAsyncErrorRequestStatByCode](~~409804~~) operation to query MySQL error codes in SQL Explorer data.', example='1064', position='Body'),
  hostAddress?: string(name='HostAddress', description='The IP address of the client.

>  You can specify multiple IP addresses that are separated by spaces. Example: `IP1 IP2 IP3`.', example='47.100.XX.XX', position='Body'),
  instanceId: string(name='InstanceId', description='The ID of the database instance.', example='rm-2ze1jdv45i7l6****', position='Body'),
  logicalOperator?: string(name='LogicalOperator', description='The logical relationship among multiple keywords.

*   **or**
*   **and**', example='or', position='Body'),
  maxLatancy?: long(name='MaxLatancy', description='The maximum execution duration. Unit: microseconds. You can specify this parameter to query the SQL statements whose execution duration is smaller than the value of this parameter.', example='100', position='Body'),
  maxRecordsPerPage?: long(name='MaxRecordsPerPage', description='The maximum number of entries per page. Valid values: 5 to 100.', example='10', position='Body'),
  maxRows?: long(name='MaxRows', description='The reserved parameter. This parameter is not supported.', example='None', position='Body'),
  maxScanRows?: long(name='MaxScanRows', description='The maximum number of scanned rows. You can specify this parameter to query the SQL statements that scan a smaller number of rows than the value of this parameter.', example='10000', position='Body'),
  maxSpillCnt?: long(name='MaxSpillCnt', description='The reserved parameter. This parameter is not supported.', example='None', position='Body'),
  minLatancy?: long(name='MinLatancy', description='The minimum execution duration. Unit: microseconds. You can specify this parameter to query the SQL statements whose execution duration is greater than or equal to the value of this parameter.', example='10', position='Body'),
  minRows?: long(name='MinRows', description='The reserved parameter. This parameter is not supported.', example='None', position='Body'),
  minScanRows?: long(name='MinScanRows', description='The minimum number of scanned rows. You can specify this parameter to query the SQL statements that scan a larger or an equal number of rows than the value of this parameter.', example='10', position='Body'),
  minSpillCnt?: long(name='MinSpillCnt', description='The reserved parameter. This parameter is not supported.', example='None', position='Body'),
  pageNumbers?: long(name='PageNumbers', description='The page number. Pages start from page 1. Default value: 1.', example='2', position='Body'),
  queryKeyword?: string(name='QueryKeyword', description='The keyword that is used for the query.

>  The keyword must be at least four characters in length. You can specify multiple keywords that are separated by spaces. Fuzzy queries are not supported.', example='test', position='Body'),
  role?: string(name='Role', description='The reserved parameter. This parameter is not supported.', example='None', position='Body'),
  sortKey?: string(name='SortKey', description='The basis on which you want to sort the query results.

*   **SCAN_ROWS**: the number of scanned rows.
*   **UPDATE_ROWS**: the number of updated rows.
*   **CONSUME**: the time consumed.
*   **ORIGIN_TIME**: the execution duration.', example='SCAN_ROWS', position='Body'),
  sortMethod?: string(name='SortMethod', description='The order in which you want to sort the query results.

*   **ase**: ascending order.
*   **desc**: descending order.', example='ase', position='Body'),
  sqlType?: string(name='SqlType', description='The type of the SQL statement. Valid values:

*   **SELECT**
*   **UPDATE**
*   **DELETE**', example='SELECT', position='Body'),
  start: long(name='Start', description='The beginning of the time range to query. Specify the time in the UNIX timestamp format. Unit: millisecond.

>  You can query only the data generated after DAS Enterprise Edition V2 or V3 was enabled. The beginning of the time range to query can be up to seven days earlier than the current time.', example='1684734297000', position='Body'),
  state?: string(name='State', description='The execution results. You can specify **0** to query the SQL statements that are successfully executed. You can also specify an error code to query the corresponding SQL statements that fail to be executed.', example='0', position='Body'),
  threadID?: string(name='ThreadID', description='The thread ID.

>  You can specify multiple thread IDs that are separated by spaces. Example: `Thread ID1 Thread ID2 Thread ID3`.', example='657', position='Body'),
  traceId?: string(name='TraceId', description='The reserved parameter. This parameter is not supported.', example='None', position='Body'),
  transactionId?: string(name='TransactionId', description='The transaction ID.', example='0', position='Body'),
}

model GetDasSQLLogHotDataResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    extra?: any(name='Extra', description='The reserved parameter.', example='None'),
    list?: [ 
      {
        accountName?: string(name='AccountName', description='The account of the database.', example='testuser'),
        DBName?: string(name='DBName', description='The name of the database.', example='testDB'),
        executeTime?: string(name='ExecuteTime', description='The execution time. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-05-23 T12:11:20Z'),
        ext?: string(name='Ext', description='The extended information. This parameter is a reserved parameter.', example='None'),
        hostAddress?: string(name='HostAddress', description='The IP address of the client.', example='47.100.XX.XX'),
        latancy?: long(name='Latancy', description='The execution duration. Unit: microseconds.', example='10000'),
        lockTime?: long(name='LockTime', description='The lock wait duration. Unit: microseconds.', example='1'),
        logicRead?: long(name='LogicRead', description='The number of logical reads.', example='12'),
        originTime?: string(name='OriginTime', description='The execution time. The time follows the ISO 8601 standard in the yyyy-MM-ddTHH:mm:ssZ format. The time is displayed in UTC.', example='2023-05-23 T12:11:20.999Z'),
        physicAsyncRead?: long(name='PhysicAsyncRead', description='The number of physical asynchronous reads.', example='0'),
        physicSyncRead?: long(name='PhysicSyncRead', description='The number of physical synchronous reads.', example='0'),
        returnRows?: long(name='ReturnRows', description='The number of rows returned.', example='1'),
        SQLText?: string(name='SQLText', description='The content of the SQL statement.', example='select 1'),
        scanRows?: long(name='ScanRows', description='The number of rows scanned by the SQL statement.', example='29'),
        sqlType?: string(name='SqlType', description='The type of the SQL statement. Valid values:

* **SELECT**
* **UPDATE**
* **DELETE**', example='SELECT'),
        state?: string(name='State', description='The execution result. If a **0** is returned, the SQL statement was successfully executed. If an error code is returned, the SQL statement failed to be executed.', example='0'),
        threadID?: long(name='ThreadID', description='The thread ID.', example='657'),
        transactionId?: string(name='TransactionId', description='The transaction ID.', example='0'),
        updateRows?: long(name='UpdateRows', description='The number of updated rows.', example='30'),
      }
    ](name='List', description='The details of the data returned.'),
    pageNo?: long(name='PageNo', description='The page number.', example='2'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    total?: long(name='Total', description='The total number of entries returned.', example='20'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

> If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='0A74B755-98B7-59DB-8724-1321B394****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetDasSQLLogHotDataResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDasSQLLogHotDataResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or DAS SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call the API operations of DAS, you must set the region ID to cn-shanghai.
  * *   The database instance that you want to manage must be an ApsaraDB RDS for MySQL instance or a PolarDB for MySQL cluster in the China (Shanghai) region.
  * >  You can query only the data generated after DAS Enterprise Edition V2 or V3 was enabled. The beginning of the time range to query can be up to seven days earlier than the current time. The interval between the beginning and the end of the time range to query cannot exceed 24 hours.
  *
 */
async function getDasSQLLogHotData(request: GetDasSQLLogHotDataRequest): GetDasSQLLogHotDataResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDasSQLLogHotData', 'POST', '/', 'json', true, 'form', request);
}

model GetDeadLockDetailListRequest {
  dbNameList?: string(name='DbNameList', description='The database name list.', example='school1,school2', position='Query'),
  endTime: string(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1702360530292', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze2016723b328gs2', position='Query'),
  pageNo?: string(name='PageNo', description='The page number. The value must be an integer that is greater than 0. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries per page. Default value: 10.', example='5', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1701755730292', position='Query'),
}

model GetDeadLockDetailListResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    list?: [ 
      {
        batchId?: long(name='BatchId', description='The time when the data was collected.', example='1702301170701'),
        blockProcessList?: [ 
          {
            clientApp?: string(name='ClientApp', description='The client application.', example='Microsoft SQL Server Management Studio - Query'),
            databaseName?: string(name='DatabaseName', description='The database name.', example='school'),
            hostName?: string(name='HostName', description='The host name.', example='sd74020124'),
            lastTranStarted?: long(name='LastTranStarted', description='The time when the transaction started.', example='1702301152000'),
            lockMode?: string(name='LockMode', description='The lock mode.', example='U'),
            logUsed?: long(name='LogUsed', description='The size of the logs generated by the session.', example='352'),
            loginName?: string(name='LoginName', description='The username that is used for login.', example='sd74020124\\\\Administrator'),
            objectOwned?: string(name='ObjectOwned', description='The locked object.', example='school.dbo.test2'),
            objectRequested?: string(name='ObjectRequested', description='The object that the current transaction requested to lock.', example='school.dbo.test1'),
            ownMode?: string(name='OwnMode', description='The holding mode.', example='X'),
            spid?: long(name='Spid', description='The ID of the session that started the transaction.', example='61'),
            sqlText?: string(name='SqlText', description='The SQL statement.', example='update test1 set col1 =9'),
            status?: string(name='Status', description='The transaction status.', example='suspended'),
            victim?: long(name='Victim', description='The victim.', example='0'),
            waitMode?: string(name='WaitMode', description='The wait mode.', example='U'),
            waitResource?: string(name='WaitResource', description='The pending resource.', example='RID: 5:1:312:0'),
            waitResourceDescription?: string(name='WaitResourceDescription', description='The description of the pending resource.', example='RID:school:school.mdf:312:0'),
          }
        ](name='BlockProcessList', description='The blocking list.'),
        clientApp?: string(name='ClientApp', description='The client application.', example='Microsoft SQL Server Management Studio - Query'),
        databaseName?: string(name='DatabaseName', description='The database name.', example='school'),
        hostName?: string(name='HostName', description='The host name.', example='sd74020124'),
        lastTranStarted?: long(name='LastTranStarted', description='The time when the transaction started.', example='1702301141000'),
        lockMode?: string(name='LockMode', description='The lock mode.', example='U'),
        logUsed?: long(name='LogUsed', description='The size of the logs generated by the session.', example='352'),
        loginName?: string(name='LoginName', description='The username that is used for login.', example='sd74020124\\\\Administrator'),
        objectOwned?: string(name='ObjectOwned', description='The locked object.', example='school.dbo.test1'),
        objectRequested?: string(name='ObjectRequested', description='The object that the current transaction requested to lock.', example='school.dbo.test2'),
        ownMode?: string(name='OwnMode', description='The holding mode.', example='X'),
        spid?: long(name='Spid', description='The ID of the session that started the transaction.', example='56'),
        sqlText?: string(name='SqlText', description='The SQL statement.', example='update test2 set col1 =88'),
        status?: string(name='Status', description='The transaction status.', example='suspended'),
        victim?: long(name='Victim', description='The victim.', example='1'),
        waitMode?: string(name='WaitMode', description='The wait mode.', example='U'),
        waitResource?: string(name='WaitResource', description='The pending resource.', example='RID: 5:1:376:0'),
        waitResourceDescription?: string(name='WaitResourceDescription', description='The description of the pending resource.', example='RID:school:school.mdf:376:0'),
      }
    ](name='List', description='The details of the data returned.'),
    pageNo?: long(name='PageNo', description='The page number of the returned page.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries returned on each page.', example='10'),
    total?: long(name='Total', description='The total number of entries returned.', example='2'),
  }(name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request is successful, **Successful** is returned. Otherwise, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='840F51F7-9C01-538D-94F6-AE712905****'),
  success?: string(name='Success', description='Indicates whether the request is successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetDeadLockDetailListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDeadLockDetailListResponseBody(name='body'),
}

/**
  * *   This operation is applicable only to ApsaraDB RDS for SQL Server instances.
  * *   If you use an Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call the API operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function getDeadLockDetailList(request: GetDeadLockDetailListRequest): GetDeadLockDetailListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetDeadLockDetailList', 'POST', '/', 'json', false, 'json', request);
}

model GetEndpointSwitchTaskRequest {
  taskId?: string(name='TaskId', position='Query'),
  uid?: string(name='Uid', position='Query'),
  userId?: string(name='UserId', position='Query'),
  context?: string(name='__context', position='Query'),
  accessKey?: string(name='accessKey', position='Query'),
  signature?: string(name='signature', position='Query'),
  skipAuth?: string(name='skipAuth', position='Query'),
  timestamp?: string(name='timestamp', position='Query'),
}

model GetEndpointSwitchTaskResponseBody = {
  code?: string(name='Code'),
  data?: {
    accountId?: string(name='AccountId'),
    dbLinkId?: long(name='DbLinkId'),
    errMsg?: string(name='ErrMsg'),
    oriUuid?: string(name='OriUuid'),
    status?: string(name='Status'),
    taskId?: string(name='TaskId'),
    uuid?: string(name='Uuid'),
  }(name='Data'),
  message?: string(name='Message'),
  requestId?: string(name='RequestId'),
  success?: string(name='Success'),
  synchro?: string(name='Synchro'),
}

model GetEndpointSwitchTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEndpointSwitchTaskResponseBody(name='body'),
}

async function getEndpointSwitchTask(request: GetEndpointSwitchTaskRequest): GetEndpointSwitchTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetEndpointSwitchTask', 'POST', '/', 'json', false, 'json', request);
}

model GetErrorRequestSampleRequest {
  dbName?: string(name='DbName', description='The name of the database.', example='testdb01', position='Query'),
  end?: long(name='End', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time. The interval cannot exceed 24 hours.', example='1642566830000', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  You must specify the node ID if your database instance is a PolarDB for MySQL cluster.', example='pi-bp179lg03445l****', position='Query'),
  sqlId?: string(name='SqlId', description='The SQL query ID. You can call the [GetAsyncErrorRequestListByCode](~~410746~~) operation to query the ID of the SQL query for which MySQL error code is returned.', example='2cd4432556c3dab9d825ba363637****', position='Query'),
  start?: long(name='Start', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The start time must be within the storage duration of the SQL Explorer feature of the database instance, and can be up to 90 days earlier than the current time.', example='1642556990714', position='Query'),
}

model GetErrorRequestSampleResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: [ 
    {
      database?: string(name='database', description='The database name.', example='dbgateway'),
      errorCode?: string(name='errorCode', description='The error code that is returned.', example='1062'),
      instanceId?: string(name='instanceId', description='The instance ID.', example='rm-2ze8g2am97624****'),
      originHost?: string(name='originHost', description='The IP address of the client that executes the SQL statement.', example='172.16.1****'),
      sql?: string(name='sql', description='The SQL statement.', example='insert into meter_****'),
      sqlId?: string(name='sqlId', description='The SQL query ID.', example='2cd4432556c3dab9d825ba363637****'),
      tables?: [ string ](name='tables', description='The table information.'),
      timestamp?: long(name='timestamp', description='The time when the SQL query was executed. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1644476100435'),
      user?: string(name='user', description='The username of the account that is used to log on to the database.', example='dbgat****'),
    }
  ](name='Data', description='The returned data.', example='[         {             "sqlId": "2cd4432556c3dab9d825ba363637****",             "database": "dbgateway",             "originHost": "172.16.1****",             "tables": [                 "meter_****"             ],             "instanceId": "rm-2ze8g2am97624****",             "errorCode": "1062",             "user": "dbgat****",             "sql": "insert into meter_****\\n        ( \\n        ****\\n     )\\n        values (now(), now(), \\"bbbc8624-5e19-455a-9714-8466f688****\\", \\"2022-02-10 14:00:00\\", \\"{\\"endTime\\":\\"2022-02-10 14:00:00\\",\\"endTimestamp\\":1644472800,\\"startTime\\":\\"2022-02-10 13:00:00\\",\\"startTimestamp\\":1644469200}\\", null, null)",             "timestamp": 1644476100435         }]'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='7172BECE-588A-5961-8126-C216E16B****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetErrorRequestSampleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetErrorRequestSampleResponseBody(name='body'),
}

/**
  * >  GetErrorRequestSample is an asynchronous operation. After a request is sent, the complete results are not returned immediately. If the value of **isFinish** is **false** in the response, wait for 1 second and then send a request again. If the value of **isFinish** is **true**, the complete results are returned.
  * *   This API operation supports only ApsaraDB RDS for MySQL instances and PolarDB for MySQL clusters for which Database Autonomy Service (DAS) Enterprise Edition is enabled. For more information, see [Purchase DAS Enterprise Edition](~~163298~~).
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function getErrorRequestSample(request: GetErrorRequestSampleRequest): GetErrorRequestSampleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetErrorRequestSample', 'POST', '/', 'json', false, 'json', request);
}

model GetEventSubscriptionRequest {
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
}

model GetEventSubscriptionResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    active?: int32(name='active', description='Indicates whether the event subscription feature is enabled. Valid values:

*   **0**: The event subscription feature is disabled.
*   **1**: The event subscription feature is enabled.', example='1'),
    channelType?: string(name='channelType', description='The notification method. Valid values:

*   **hdm_alarm_sms**: text message.
*   **dingtalk**: DingTalk chatbot.
*   **hdm_alarm_sms_and_email**: text message and email.
*   **hdm_alarm_sms,dingtalk**: text message and DingTalk chatbot.', example='hdm_alarm_sms,dingtalk'),
    contactGroupName?: string(name='contactGroupName', description='The name of the contact group that receives alert notifications. Multiple names are separated by commas (,).', example='Default contact group'),
    contactGroups?: [ 
      {
        contacts?: string(name='contacts', description='The members of the alert contact group.', example='"[\\"Mr. Zhang\\",\\"Ms. Wang\\",\\"Mr. Li\\"]"'),
        description?: string(name='description', description='The description of the alert contact group.', example='Default contact'),
        name?: string(name='name', description='The name of the alert contact group.', example='Mr. Zhang'),
        userId?: string(name='userId', description='The user ID.', example='1088760496****'),
      }
    ](name='contactGroups', description='The alert contact groups.'),
    contactName?: string(name='contactName', description='The name of the subscriber who receives alert notifications. Multiple names are separated by commas (,).', example='Default contact'),
    contacts?: [ 
      {
        dingtalkHook?: string(name='dingtalkHook', description='The webhook URL of the DingTalk chatbot.', example='https://oapi.dingtalk.com/robot/send?access_token=68fa29a9eaf3ba9994f54fxxxc1aa9879700308f90e9c23ebfb3663642c9****'),
        email?: string(name='email', description='The email address of the alert contact.', example='a***@example.net'),
        groups?: [ string ](name='groups', description='The contact groups to which the alert contact belongs.'),
        isCmsReduplicated?: boolean(name='isCmsReduplicated', description='Indicates whether the alert contact name is the same as the contact name on CloudMonitor.

* **true**
* **false**', example='true'),
        name?: string(name='name', description='The name of the alert contact.', example='Mr. Zhang'),
        phone?: string(name='phone', description='The mobile number of the alert contact.', example='1390000****'),
        userId?: string(name='userId', description='The user ID.', example='1088760496****'),
      }
    ](name='contacts', description='The user ID.'),
    eventContext?: string(name='eventContext', description='The supported event scenarios. Only **AllContext** may be returned, which indicates that all scenarios are supported.', example='AllContext'),
    eventSendGroup?: [ string ](name='eventSendGroup', description='The supported event scenarios in which event subscription can be sent.'),
    gmtCreate?: long(name='gmtCreate', description='The time when event subscription was enabled. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1633071840000'),
    gmtModified?: long(name='gmtModified', description='The time when the event subscription settings were most recently modified. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1633071850000'),
    id?: long(name='id', description='The primary key ID of the database.', example='1'),
    instanceId?: string(name='instanceId', description='The instance ID.', example='rm-2ze8g2am97624****'),
    lang?: string(name='lang', description='The language of event notifications. Only **zh-CN** may be returned, which indicates that event notifications are sent in Chinese.', example='zh_CN'),
    level?: string(name='level', description='The risk level of the events that trigger notifications. Valid values:

*   **Notice**
*   **Optimization**
*   **Warn**
*   **Critical**', example='Optimization'),
    minInterval?: string(name='minInterval', description='The minimum interval between event notifications. Unit: seconds.', example='60'),
    userId?: string(name='userId', description='The user ID.', example='1088760496****'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetEventSubscriptionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEventSubscriptionResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  * *   The database instance that you want to manage is connected to DAS.
  *
 */
async function getEventSubscription(request: GetEventSubscriptionRequest): GetEventSubscriptionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetEventSubscription', 'POST', '/', 'json', false, 'json', request);
}

model GetFullRequestOriginStatByInstanceIdRequest {
  asc?: boolean(name='Asc', description='Specifies whether to sort the results in ascending order. By default, the results are not sorted in ascending order.', example='Disabled', position='Query'),
  end: long(name='End', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time. The interval between the start time and the end time cannot exceed 24 hours.', example='1644803409000', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  This parameter must be specified if the database instance is a PolarDB for MySQL cluster.', example='pi-bp12v7243x012****', position='Query'),
  orderBy?: string(name='OrderBy', description='The field by which the results to be returned are sorted. Default value: **count**. Valid values:

*   **count**: the number of executions.
*   **avgRt**: the average execution duration.
*   **rtRate**: the execution duration percentage.
*   **rowsExamined**: the total number of scanned rows.
*   **avgRowsExamined**: the average number of scanned rows.
*   **avgRowsReturned**: the average number of returned rows.', example='count', position='Query'),
  pageNo: int32(name='PageNo', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize: int32(name='PageSize', description='The number of entries per page. Default value: 20.', example='20', position='Query'),
  role?: string(name='Role', description='The role of the PolarDB-X 2.0 node. Valid values:

*   **polarx_cn**: compute node.
*   **polarx_en**: data node.', example='polarx_cn', position='Query'),
  sqlType?: string(name='SqlType', description='The type of the SQL statement. Valid values: **SELECT**, **INSERT**, **UPDATE**, **DELETE**, **LOGIN**, **LOGOUT**, **MERGE**, **ALTER**, **CREATEINDEX**, **DROPINDEX**, **CREATE**, **DROP**, **SET**, **DESC**, **REPLACE**, **CALL**, **BEGIN**, **DESCRIBE**, **ROLLBACK**, **FLUSH**, **USE**, **SHOW**, **START**, **COMMIT**, and **RENAME**.

>  If the database instance is an ApsaraDB RDS for MySQL instance, a PolarDB for MySQL cluster, or a PolarDB-X 2.0 instance, the statistics can be collected based on the SQL statement type.', example='SELECT', position='Query'),
  start: long(name='Start', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The start time must be within the storage duration of the SQL Explorer of the database instance, and can be up to 90 days earlier than the current time.', example='1644716649000', position='Query'),
  userId?: string(name='UserId', description='The ID of the Alibaba Cloud account that is used to create the database instance.

>  This parameter is optional. The system can automatically obtain the account ID based on the value of InstanceId when you call this operation.', example='196278346919****', position='Query'),
}

model GetFullRequestOriginStatByInstanceIdResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    list?: [ 
      {
        avgExaminedRows?: double(name='AvgExaminedRows', description='The average number of scanned rows.

> This parameter is returned only for ApsaraDB RDS for MySQL, ApsaraDB RDS for PostgreSQL, and PolarDB for MySQL databases.', example='10000'),
        avgFetchRows?: long(name='AvgFetchRows', description='The average number of rows that are fetched from data nodes by compute nodes on the PolarDB-X 2.0 instance.', example='0'),
        avgLockWaitTime?: double(name='AvgLockWaitTime', description='The average lock wait duration. Unit: seconds.', example='0.00009589874265269765'),
        avgLogicalRead?: double(name='AvgLogicalRead', description='The average number of logical reads.', example='654.4470327860251'),
        avgPhysicalAsyncRead?: long(name='AvgPhysicalAsyncRead', description='The average number of physical asynchronous reads.', example='0'),
        avgPhysicalSyncRead?: double(name='AvgPhysicalSyncRead', description='The average number of physical synchronous reads.', example='0'),
        avgReturnedRows?: double(name='AvgReturnedRows', description='The average number of returned rows.', example='10000'),
        avgRows?: long(name='AvgRows', description='The average number of rows.', example='0'),
        avgRt?: double(name='AvgRt', description='The average execution duration.', example='2.499'),
        avgSqlCount?: long(name='AvgSqlCount', description='The average number of SQL statements.', example='10000'),
        avgUpdatedRows?: double(name='AvgUpdatedRows', description='The average number of updated rows.

> This parameter is returned only for ApsaraDB RDS for MySQL and PolarDB-X 2.0 databases.', example='10000'),
        count?: long(name='Count', description='The total number of executions.', example='100000'),
        countRate?: double(name='CountRate', description='The percentage of the total number of executions.', example='0.0586'),
        database?: string(name='Database', description='The name of the database.', example='dbtest01'),
        errorCount?: long(name='ErrorCount', description='The number of failed executions.', example='1'),
        examinedRows?: long(name='ExaminedRows', description='The total number of scanned rows.

> This parameter is returned only for ApsaraDB RDS for MySQL, ApsaraDB RDS for PostgreSQL, and PolarDB for MySQL databases.', example='10000'),
        fetchRows?: long(name='FetchRows', description='The number of rows that are fetched from data nodes by compute nodes on the PolarDB-X 2.0 instance.', example='200'),
        ip?: string(name='Ip', description='The network address of the database instance.', example='rm-uf6dyi58dm6****.mysql.rds.aliy****.com'),
        key?: string(name='Key', description='The IP address of the client that executes the SQL statement.', example='172.26.6****'),
        lockWaitTime?: double(name='LockWaitTime', description='The lock wait duration. Unit: seconds.', example='1089.4177720290281'),
        logicalRead?: long(name='LogicalRead', description='The number of logical reads.', example='7.434573266E9'),
        originHost?: string(name='OriginHost', description='The IP address of the client that executes the SQL statement.', example='172.26.6****'),
        physicalAsyncRead?: long(name='PhysicalAsyncRead', description='The number of physical asynchronous reads.', example='0'),
        physicalSyncRead?: long(name='PhysicalSyncRead', description='The number of physical synchronous reads.', example='0'),
        port?: long(name='Port', description='The port number that is used to connect to the database instance.', example='3306'),
        rows?: long(name='Rows', description='The total number of rows updated or returned by the compute nodes of the PolarDB-X 2.0 instance.', example='0'),
        rtGreaterThanOneSecondCount?: long(name='RtGreaterThanOneSecondCount', description='The number of SQL statements that take longer than 1 second to execute.', example='2'),
        rtRate?: double(name='RtRate', description='The execution duration percentage.', example='0.1384'),
        sqlCount?: long(name='SqlCount', description='The number of SQL statements.', example='200'),
        sumUpdatedRows?: long(name='SumUpdatedRows', description='The total number of updated rows.', example='200'),
        version?: long(name='Version', description='The version number.', example='1'),
        vpcId?: string(name='VpcId', description='The virtual private cloud (VPC) ID.', example='vpc-2zentqj1sk4qmolci****'),
      }
    ](name='List', description='The details of the full request data.'),
    total?: long(name='Total', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='7172BECE-588A-5961-8126-C216E16B****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetFullRequestOriginStatByInstanceIdResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetFullRequestOriginStatByInstanceIdResponseBody(name='body'),
}

/**
  * The SQL Explorer feature allows you to check the health status of SQL statements and troubleshoot performance issues. For more information, see [SQL Explorer](~~204096~~).
  * *   For more information about database instances that support this feature, see [Overview](~~190912~~).
  * *   If you use an SDK to call API operations of Database Autonomy Service (DAS), you must set the region ID to cn-shanghai.
  *
 */
async function getFullRequestOriginStatByInstanceId(request: GetFullRequestOriginStatByInstanceIdRequest): GetFullRequestOriginStatByInstanceIdResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetFullRequestOriginStatByInstanceId', 'POST', '/', 'json', false, 'json', request);
}

model GetFullRequestSampleByInstanceIdRequest {
  end: long(name='End', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time. The interval between the start time and the end time must be equal to or greater than 1 hour.', example='1660104621000', position='Body'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Body'),
  role?: string(name='Role', description='The role of the PolarDB-X 2.0 node. Valid values:

*   **polarx_cn**: compute node.
*   **polarx_en**: data node.', example='polarx_cn', position='Query'),
  sqlId: string(name='SqlId', description='The SQL statement ID.', example='651b56fe9418d48edb8fdf0980ec****', position='Body'),
  start: long(name='Start', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The start time must be within the storage duration of the SQL Explorer feature of the database instance, and can be up to 90 days earlier than the current time.', example='1660097421000', position='Body'),
  userId?: string(name='UserId', description='The ID of the Alibaba Cloud account that is used to create the database instance.

>  This parameter is optional. The system can automatically obtain the account ID based on the value of InstanceId when you call this operation.', example='196278346919****', position='Body'),
}

model GetFullRequestSampleByInstanceIdResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: [ 
    {
      database?: string(name='Database', description='The name of the database.', example='dbtest'),
      frows?: long(name='Frows', description='The number of rows fetched by PolarDB-X 2.0 compute nodes.', example='0'),
      lockWaitTime?: double(name='LockWaitTime', description='The lock wait duration. Unit: seconds.', example='0.0137'),
      logicalRead?: double(name='LogicalRead', description='The number of logical reads.', example='165848'),
      originHost?: string(name='OriginHost', description='The source IP address.', example='172.17.XX.XX'),
      physicalAsyncRead?: double(name='PhysicalAsyncRead', description='The number of physical asynchronous reads.', example='0'),
      physicalSyncRead?: double(name='PhysicalSyncRead', description='The number of physical synchronous reads.', example='0'),
      rows?: long(name='Rows', description='The number of rows updated or returned on PolarDB-X 2.0 compute nodes.', example='0'),
      rowsExamined?: long(name='RowsExamined', description='The total number of scanned rows.

> This parameter is returned only for ApsaraDB RDS for MySQL, ApsaraDB RDS for PostgreSQL, and PolarDB for MySQL databases.', example='2048576'),
      rowsReturned?: long(name='RowsReturned', description='The number of rows returned by the SQL statement.', example='14'),
      rt?: double(name='Rt', description='The amount of time consumed to execute the SQL statement. Unit: seconds.', example='0.409789'),
      scanRows?: long(name='ScanRows', description='The number of scanned rows.', example='0'),
      scnt?: long(name='Scnt', description='The number of requests sent from PolarDB-X 2.0 compute nodes to data nodes.', example='0'),
      sql?: string(name='Sql', description='The sample SQL statement.', example='select * from testdb01 where ****'),
      sqlId?: string(name='SqlId', description='The SQL statement ID.', example='651b56fe9418d48edb8fdf0980ec****'),
      sqlType?: string(name='SqlType', description='The type of the SQL statement. Valid values: **SELECT**, **INSERT**, **UPDATE**, **DELETE**, **LOGIN**, **LOGOUT**, **MERGE**, **ALTER**, **CREATEINDEX**, **DROPINDEX**, **CREATE**, **DROP**, **SET**, **DESC**, **REPLACE**, **CALL**, **BEGIN**, **DESCRIBE**, **ROLLBACK**, **FLUSH**, **USE**, **SHOW**, **START**, **COMMIT**, and **RENAME**.', example='SELECT'),
      timestamp?: long(name='Timestamp', description='The time when the SQL statement was executed. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1660100753556'),
      updateRows?: long(name='UpdateRows', description='The number of updated rows.', example='0'),
      user?: string(name='User', description='The name of the user who executes the SQL statement.', example='testuser'),
    }
  ](name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message that contains information such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='0A74B755-98B7-59DB-8724-1321B394****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetFullRequestSampleByInstanceIdResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetFullRequestSampleByInstanceIdResponseBody(name='body'),
}

/**
  * The SQL Explorer feature allows you to check the health status of SQL statements and troubleshoot performance issues. For more information, see [SQL Explorer](~~204096~~).
  * *   For more information about the database engines that support SQL Explorer, see [SQL Explorer](~~204096~~).
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function getFullRequestSampleByInstanceId(request: GetFullRequestSampleByInstanceIdRequest): GetFullRequestSampleByInstanceIdResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetFullRequestSampleByInstanceId', 'POST', '/', 'json', true, 'form', request);
}

model GetFullRequestStatResultByInstanceIdRequest {
  asc?: boolean(name='Asc', description='Specifies whether to sort the results in ascending order. By default, the results are not sorted in ascending order.', example='Disabled', position='Query'),
  dbName?: string(name='DbName', description='The name of the database.', example='dbtest01', position='Query'),
  end: long(name='End', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time. The interval cannot exceed one day.', example='1645668213000', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  keyword?: string(name='Keyword', description='The keywords that are used for query.', example='dbtest01', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  You must specify the node ID if your database instance is a PolarDB for MySQL cluster.', example='pi-bp12v7243x012****', position='Query'),
  orderBy?: string(name='OrderBy', description='The field by which to sort the returned entries. Default value: **count**. Valid values:

*   **count**: the number of executions.
*   **avgRt**: the average execution duration.
*   **rtRate**: the execution duration percentage.
*   **rowsExamined**: the total number of scanned rows.
*   **avgRowsExamined**: the average number of scanned rows.
*   **avgRowsReturned**: the average number of returned rows.', example='count', position='Query'),
  originHost?: string(name='OriginHost', description='The IP address of the client that executes the SQL statement.

>  This parameter is optional. If this parameter is specified, the full request statistics of the specified IP address are collected. If this parameter is left empty, the full request statistics of the entire database instance are collected.', example='172.26.XX.XXX', position='Query'),
  pageNo: int32(name='PageNo', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize: int32(name='PageSize', description='The number of entries per page. Default value: 20.', example='20', position='Query'),
  role?: string(name='Role', description='The role of the node in the PolarDB-X 2.0 instance. Valid values:

*   **polarx_cn**: compute node.
*   **polarx_dn**: data node.', example='polarx_cn', position='Query'),
  sqlId?: string(name='SqlId', description='The SQL ID.

>  If this parameter is specified, the full request statistics of the specified SQL query are collected. If this parameter is left empty, the full request statistics of the entire database instance are collected.', example='d71f82be1eef72bd105128204d2e****', position='Query'),
  sqlType?: string(name='SqlType', description='The type of the SQL statement. Valid values: **SELECT**, **INSERT**, **UPDATE**, **DELETE**, **LOGIN**, **LOGOUT**, **MERGE**, **ALTER**, **CREATEINDEX**, **DROPINDEX**, **CREATE**, **DROP**, **SET**, **DESC**, **REPLACE**, **CALL**, **BEGIN**, **DESCRIBE**, **ROLLBACK**, **FLUSH**, **USE**, **SHOW**, **START**, **COMMIT**, and **RENAME**.

>  If your database instance is an ApsaraDB RDS for MySQL instance, a PolarDB for MySQL cluster, or a PolarDB-X 2.0 instance, the statistics can be collected based on the SQL statement type.', example='SELECT', position='Query'),
  start: long(name='Start', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The start time can be up to 90 days earlier than the current time.', example='1645581813000', position='Query'),
  userId?: string(name='UserId', description='The ID of the Alibaba Cloud account that was used to create the database instance.

>  This parameter is optional. The system can automatically obtain the Alibaba Cloud account ID based on the value of InstanceId when you call the GetFullRequestOriginStatByInstanceId operation.', example='196278346919****', position='Query'),
}

model GetFullRequestStatResultByInstanceIdResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    fail?: boolean(name='Fail', description='Indicates whether the asynchronous request failed. Valid values:

*   **true**
*   **false**', example='false'),
    isFinish?: boolean(name='IsFinish', description='Indicates whether the asynchronous request was complete. Valid values:

*   **true**
*   **false**', example='true'),
    result?: {
      list?: [ 
        {
          avgExaminedRows?: double(name='AvgExaminedRows', description='The average number of scanned rows.

> This parameter is returned only for ApsaraDB RDS for MySQL, ApsaraDB RDS for PostgreSQL, and PolarDB for MySQL databases.', example='10000'),
          avgFetchRows?: long(name='AvgFetchRows', description='The average number of rows that are fetched by compute nodes from data nodes on the PolarDB-X 2.0 instance.', example='0'),
          avgLockWaitTime?: double(name='AvgLockWaitTime', description='The average lock wait latency. Unit: seconds.', example='0.00009589874265269765'),
          avgLogicalRead?: double(name='AvgLogicalRead', description='The average number of logical reads.', example='654.4470327860251'),
          avgPhysicalAsyncRead?: long(name='AvgPhysicalAsyncRead', description='The average number of physical asynchronous reads.', example='0'),
          avgPhysicalSyncRead?: long(name='AvgPhysicalSyncRead', description='The average number of physical synchronous reads.', example='0'),
          avgReturnedRows?: double(name='AvgReturnedRows', description='The average number of returned rows.', example='10000'),
          avgRt?: double(name='AvgRt', description='The average execution duration.', example='2.499'),
          avgSqlCount?: long(name='AvgSqlCount', description='The average number of SQL statements.', example='10000'),
          avgUpdatedRows?: long(name='AvgUpdatedRows', description='The average number of updated rows.

 > This parameter is returned only for ApsaraDB RDS for MySQL and PolarDB-X 2.0 databases.', example='10000'),
          count?: long(name='Count', description='The total number of executions.', example='100000'),
          countRate?: double(name='CountRate', description='The percentage of the total number of executions.', example='0.0586'),
          database?: string(name='Database', description='The name of the database.', example='dbtest01'),
          errorCount?: long(name='ErrorCount', description='The number of failed executions.', example='1'),
          examinedRows?: long(name='ExaminedRows', description='The total number of scanned rows.

> This parameter is returned only for ApsaraDB RDS for MySQL, ApsaraDB RDS for PostgreSQL, and PolarDB for MySQL databases.', example='10000'),
          fetchRows?: long(name='FetchRows', description='The number of rows that are fetched by compute nodes from data nodes on the PolarDB-X 2.0 instance.', example='0'),
          ip?: string(name='Ip', description='The IP address of the database instance.', example='rm-uf6dyi58dm6****.mysql.rds.aliy****.com'),
          lockWaitTime?: double(name='LockWaitTime', description='The lock wait latency. Unit: seconds.', example='1089.4177720290281'),
          logicalRead?: long(name='LogicalRead', description='The number of logical reads.', example='7.434573266E9'),
          physicalAsyncRead?: long(name='PhysicalAsyncRead', description='The number of physical asynchronous reads.', example='0'),
          physicalSyncRead?: long(name='PhysicalSyncRead', description='The number of physical synchronous reads.', example='0'),
          port?: long(name='Port', description='The port number that is used to connect to the database instance.', example='3306'),
          psql?: string(name='Psql', description='The SQL template.', example='select * from dbtest01 where ****'),
          rows?: long(name='Rows', description='The total number of rows updated or returned by the compute nodes of the PolarDB-X 2.0 instance.', example='0'),
          rtGreaterThanOneSecondCount?: long(name='RtGreaterThanOneSecondCount', description='The number of SQL statements that take longer than 1 second to execute.', example='20'),
          rtRate?: double(name='RtRate', description='The execution duration percentage.', example='2.499'),
          sqlCount?: long(name='SqlCount', description='The number of SQL statements.', example='200'),
          sqlId?: string(name='SqlId', description='The SQL ID.', example='d71f82be1eef72bd105128204d2e****'),
          sumUpdatedRows?: long(name='SumUpdatedRows', description='The total number of updated rows.', example='100'),
          tables?: [ string ](name='Tables', description='The names of tables in the database.'),
          version?: long(name='Version', description='The version number.', example='1'),
          vpcId?: string(name='VpcId', description='The virtual private cloud (VPC) ID.', example='vpc-2zentqj1sk4qmolci****'),
        }
      ](name='List', description='The full request data.'),
      total?: long(name='Total', description='The total number of entries returned.', example='1'),
    }(name='Result', description='The returned full request data.'),
    resultId?: string(name='ResultId', description='The request ID.', example='9CB97BC4-6479-55D0-B9D0-EA925AFE****'),
    state?: string(name='State', description='The state of the asynchronous request. Valid values:

*   **RUNNING**
*   **SUCCESS**
*   **FAIL**', example='SUCCESS'),
    timestamp?: long(name='Timestamp', description='The time when the asynchronous request was sent. The value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1645668213000'),
  }(name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message that contains information such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='7172BECE-588A-5961-8126-C216E16B****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetFullRequestStatResultByInstanceIdResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetFullRequestStatResultByInstanceIdResponseBody(name='body'),
}

/**
  * >  The complete query results are not returned immediately after an asynchronous request is sent. If the value of isFinish is **false** in the response, wait for 1 second and send the request again. The complete query results are returned until the value of isFinish is **true**.
  * The SQL Explorer feature allows you to check the health status of SQL statements and troubleshoot performance issues. For more information, see [SQL Explorer](~~204096~~).
  * *   For more information about database instances that support SQL Explorer, see [Overview](~~190912~~).
  * *   If you use an SDK to call API operations of Database Autonomy Service (DAS), you must set the region ID to cn-shanghai.
  *
 */
async function getFullRequestStatResultByInstanceId(request: GetFullRequestStatResultByInstanceIdRequest): GetFullRequestStatResultByInstanceIdResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetFullRequestStatResultByInstanceId', 'POST', '/', 'json', false, 'json', request);
}

model GetHDMAliyunResourceSyncResultRequest {
  taskId?: string(name='TaskId', position='Query'),
  uid?: string(name='Uid', position='Query'),
  userId?: string(name='UserId', position='Query'),
  context?: string(name='__context', position='Query'),
  accessKey?: string(name='accessKey', position='Query'),
  signature?: string(name='signature', position='Query'),
  skipAuth?: string(name='skipAuth', position='Query'),
  timestamp?: string(name='timestamp', position='Query'),
}

model GetHDMAliyunResourceSyncResultResponseBody = {
  code?: string(name='Code'),
  data?: {
    errorMsg?: string(name='ErrorMsg'),
    results?: string(name='Results'),
    subResults?: {
      resourceSyncSubResult?: [ 
      {
        errMsg?: string(name='ErrMsg'),
        resourceType?: string(name='ResourceType'),
        success?: boolean(name='Success'),
        syncCount?: int32(name='SyncCount'),
      }
    ](name='ResourceSyncSubResult')
    }(name='SubResults'),
    syncStatus?: string(name='SyncStatus'),
  }(name='Data'),
  message?: string(name='Message'),
  requestId?: string(name='RequestId'),
  success?: string(name='Success'),
  synchro?: string(name='Synchro'),
}

model GetHDMAliyunResourceSyncResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetHDMAliyunResourceSyncResultResponseBody(name='body'),
}

async function getHDMAliyunResourceSyncResult(request: GetHDMAliyunResourceSyncResultRequest): GetHDMAliyunResourceSyncResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetHDMAliyunResourceSyncResult', 'POST', '/', 'json', false, 'json', request);
}

model GetHDMLastAliyunResourceSyncResultRequest {
  uid?: string(name='Uid', position='Query'),
  userId?: string(name='UserId', position='Query'),
  context?: string(name='__context', position='Query'),
  accessKey?: string(name='accessKey', position='Query'),
  signature?: string(name='signature', position='Query'),
  skipAuth?: string(name='skipAuth', position='Query'),
  timestamp?: string(name='timestamp', position='Query'),
}

model GetHDMLastAliyunResourceSyncResultResponseBody = {
  code?: string(name='Code'),
  data?: {
    errorMsg?: string(name='ErrorMsg'),
    results?: string(name='Results'),
    subResults?: {
      resourceSyncSubResult?: [ 
      {
        errMsg?: string(name='ErrMsg'),
        resourceType?: string(name='ResourceType'),
        success?: boolean(name='Success'),
        syncCount?: int32(name='SyncCount'),
      }
    ](name='ResourceSyncSubResult')
    }(name='SubResults'),
    syncStatus?: string(name='SyncStatus'),
  }(name='Data'),
  message?: string(name='Message'),
  requestId?: string(name='RequestId'),
  success?: string(name='Success'),
  synchro?: string(name='Synchro'),
}

model GetHDMLastAliyunResourceSyncResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetHDMLastAliyunResourceSyncResultResponseBody(name='body'),
}

async function getHDMLastAliyunResourceSyncResult(request: GetHDMLastAliyunResourceSyncResultRequest): GetHDMLastAliyunResourceSyncResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetHDMLastAliyunResourceSyncResult', 'POST', '/', 'json', false, 'json', request);
}

model GetInstanceInspectionsRequest {
  endTime: string(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time.', example='1655427625000', position='Query'),
  engine: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**
*   **Redis**
*   **PolarDBMySQL**', example='MySQL', position='Query'),
  instanceArea: string(name='InstanceArea', description='The type of the instance on which the database is deployed. Valid values:

*   **RDS**: an Alibaba Cloud database instance.
*   **ECS**: an ECS instance on which a self-managed database is deployed.
*   **IDC**: a self-managed database instance that is not deployed on Alibaba Cloud.

>  The value IDC specifies that the instance is deployed in a data center.', example='RDS', position='Query'),
  pageNo: string(name='PageNo', description='The page number. The value must be a positive integer. Default value: 1.', example='1', position='Query'),
  pageSize: string(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  resourceGroupId?: string(name='ResourceGroupId', description='The resource group ID.', example='rg-aek2eil6npi****', position='Query'),
  searchMap?: string(name='SearchMap', description='The filter condition, which can be specified in one of the following formats:

*   Specify the ID of a single instance in the {"InstanceId":"Instance ID"} format.
*   Specify the IDs of multiple instances in the {"InstanceIds":\\["Instance ID1","Instance ID2"]} format. Separate the instance IDs with commas (,).
*   Specify the region in which the instance resides in the {"region":"Region of the instance"} format.', example='{"InstanceId":"rm-bp10usoc1erj7****"}', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1655416825000', position='Query'),
}

model GetInstanceInspectionsResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    list?: [ 
      {
        autoFunction?: {
          autoIndex?: int32(name='AutoIndex', description='Indicates whether the feature of automatically creating and deleting indexes is enabled. Valid values:

*   **0**: disabled.
*   **1**: enabled.
*   **2**: not supported.', example='2'),
          autoLimitedSql?: int32(name='AutoLimitedSql', description='Indicates whether the automatic throttling feature is enabled. Valid values:

*   **0**: disabled.
*   **1**: enabled.
*   **2**: not supported.', example='2'),
          autoResourceOptimize?: int32(name='AutoResourceOptimize', description='Indicates whether the automatic fragment recycling feature is enabled. Valid values:

*   **0**: disabled.
*   **1**: enabled.
*   **2**: not supported.', example='0'),
          autoScale?: int32(name='AutoScale', description='Indicates whether the auto scaling feature is enabled. Valid values:

*   **0**: disabled.
*   **1**: enabled.
*   **2**: not supported.', example='0'),
          eventSubscription?: int32(name='EventSubscription', description='Indicates whether the event subscription feature is enabled. Valid values:

*   **0**: disabled.
*   **1**: enabled.
*   **2**: not supported.', example='0'),
        }(name='AutoFunction', description='Indicates whether the autonomy service is enabled.'),
        data?: map[string]any(name='Data', description='The data returned.', example='"data": { "hasDeadLock": false, "exceptionTableMap": {}, "bigTransactionCount": 0, "cpu": 4, "isRds": true, "rdsEnable": true, "enable": false, "activeSessions": [], "bigTransactionList": [], "bigSessionList": [ { "blockDuration": 0, "active": false, "Time": 0, "db": "" },'),
        enableDasPro?: int32(name='EnableDasPro', description='Indicates whether DAS Enterprise Edition is enabled. Valid values:

*   **0**: disabled.
*   **1**: enabled.
*   **2**: not supported.', example='0'),
        endTime?: long(name='EndTime', description='The end time of the inspection and scoring task. The value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time.', example='1608888296001'),
        gmtCreate?: long(name='GmtCreate', description='The time when the task was created. The value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1603247192000'),
        instance?: {
          accountId?: string(name='AccountId', description='The account ID. You can view the ID of the logon account by moving the pointer over the profile in the Alibaba Cloud management console.', example='108398049688****'),
          category?: string(name='Category', description='The connection mode of the instance. Valid values:

*   **standard**: standard mode.
*   **safe**: database proxy mode.', example='standard'),
          cpu?: string(name='Cpu', description='The CPU specification of the instance. For example, if a value of 8 is returned, the instance has eight CPU cores.', example='8'),
          engine?: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**
*   **Redis**
*   **PolarDBMySQL**', example='MySQL'),
          engineVersion?: string(name='EngineVersion', description='The version number of the database engine.', example='8.0'),
          instanceAlias?: string(name='InstanceAlias', description='The instance name.', example='test-01'),
          instanceArea?: string(name='InstanceArea', description='The type of the instance on which the database is deployed. Valid values:

*   **RDS**: an Alibaba Cloud database instance.
*   **ECS**: an Elastic Compute Service (ECS) instance on which a self-managed database is deployed.
*   **IDC**: a self-managed database instance that is not deployed on Alibaba Cloud.

>  The value IDC indicates that the instance is deployed in a data center.', example='RDS'),
          instanceClass?: string(name='InstanceClass', description='The instance type.', example='rds.mysql.s2.xlarge'),
          instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-bp10usoc1erj7****'),
          memory?: int32(name='Memory', description='The memory capacity of the database that is deployed on the instance. Unit: MB.', example='32768'),
          networkType?: string(name='NetworkType', description='The network type of the instance.', example='VPC'),
          nodeId?: string(name='NodeId', description='The ID of the node on the instance.', example='rm-bp10usoc1erj7****'),
          region?: string(name='Region', description='The region ID of the instance.', example='cn-hangzhou'),
          storage?: int32(name='Storage', description='The storage space of the instance. Unit: GB.', example='150'),
          uuid?: string(name='Uuid', description='The unique identifier of the instance.', example='hdm_3063db6792965c080a4bcb6e6304****'),
          vpcId?: string(name='VpcId', description='The ID of the virtual private cloud (VPC) in which the instance is deployed.', example='vpc-bp1knt7m55z9exoo7****'),
        }(name='Instance', description='The information about the instance.'),
        score?: int32(name='Score', description='The inspection score of the instance.', example='100'),
        scoreMap?: map[string]any(name='ScoreMap', description='The scores that are deducted for the instance.'),
        startTime?: long(name='StartTime', description='The start time of the inspection and scoring task. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1608888296000'),
        state?: int32(name='State', description='The state of the inspection and scoring task. Valid values:

*   **0**: The task is waiting for execution.
*   **1**: The task is in progress.
*   **2**: The task is complete.', example='2'),
        taskType?: int32(name='TaskType', description='The mode in which the inspection and scoring task was initiated. Valid values:

*   **0**: automatic mode.
*   **1**: manual mode.', example='0'),
      }
    ](name='List', description='The detailed information.'),
    pageNo?: long(name='PageNo', description='The page number. The value returned is a positive integer. Default value: 1.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page. Default value: 10.', example='10'),
    total?: long(name='Total', description='The total number of entries returned.', example='4'),
  }(name='Data', description='The details.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetInstanceInspectionsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetInstanceInspectionsResponseBody(name='body'),
}

/**
  * Database Autonomy Service (DAS) provides the inspection and scoring feature. This feature allows you to inspect and score the health status of your instance on a regular basis. This helps you obtain information about the status of your databases. For more information, see [Inspection and scoring](~~205659~~).
  * Before you call this operation, take note of the following items:
  * *   This operation is applicable only to ApsaraDB RDS for MySQL databases, self-managed MySQL databases hosted on Elastic Compute Service (ECS) instances, self-managed MySQL databases in data centers, ApsaraDB for Redis databases, and PolarDB for MySQL databases.
  * *   If you use an Alibaba Cloud SDK, make sure that the aliyun-sdk-core version is later than V4.3.3. We recommend that you use the latest version.
  * *   The version of DAS SDK must be V1.0.3 or later.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function getInstanceInspections(request: GetInstanceInspectionsRequest): GetInstanceInspectionsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetInstanceInspections', 'POST', '/', 'json', false, 'json', request);
}

model GetInstanceMissingIndexListRequest {
  avgTotalUserCost?: string(name='AvgTotalUserCost', description='The query condition based on the average cost savings.', example='<=|8', position='Query'),
  avgUserImpact?: string(name='AvgUserImpact', description='The query condition based on the performance improvement.', example='>|10000', position='Query'),
  endTime?: string(name='EndTime', description='The end time of the last seek.', example='1681869544000', position='Query'),
  indexCount?: string(name='IndexCount', description='The query condition based on the number of indexes.', example='>=|8', position='Query'),
  instanceId: string(name='InstanceId', description='The database instance ID.

>  Only ApsaraDB RDS for SQL Server instances are supported.', example='rm-************', position='Query'),
  objectName?: string(name='ObjectName', description='The object name.', example='bas_customer', position='Query'),
  pageNo?: string(name='PageNo', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  reservedPages?: string(name='ReservedPages', description='The query condition based on the total number of pages.', example='>=|100', position='Query'),
  reservedSize?: string(name='ReservedSize', description='The query condition based on the table size.', example='>=|100', position='Query'),
  rowCount?: string(name='RowCount', description='The query condition based on the number of table rows.', example='>=|100000', position='Query'),
  startTime?: string(name='StartTime', description='The start time of the last seek.', example='1679414400000', position='Query'),
  uniqueCompiles?: string(name='UniqueCompiles', description='The query condition based on the number of compilations.', example='>=|10000', position='Query'),
  userScans?: string(name='UserScans', description='The query condition based on the number of scans.', example='>=|10000', position='Query'),
  userSeeks?: string(name='UserSeeks', description='The query condition based on the number of seeks.', example='>=|1000', position='Query'),
}

model GetInstanceMissingIndexListResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    list?: [ 
      {
        avgTotalUserCost?: double(name='AvgTotalUserCost', description='The average cost savings.', example='4.67'),
        avgUserImpact?: double(name='AvgUserImpact', description='The performance improvement, in percentage.', example='98.3'),
        createIndex?: string(name='CreateIndex', description='The statement used to create the missing indexes.', example='CREATE INDEX [IX_CLOUDDBA_school_dbo_stu@col1_@col2] ON [school].[dbo].[stu]([col1],[col2],[col3]) INCLUDE ([col4],[col5]) WITH (FILLFACTOR = 90, ONLINE = OFF);'),
        databaseName?: string(name='DatabaseName', description='The database name.', example='school'),
        equalityColumns?: string(name='EqualityColumns', description='The index columns included in the equal operation.', example='col1,col2,col3'),
        includedColumns?: string(name='IncludedColumns', description='The columns on which indexes are missing.', example='col3,col4'),
        indexCount?: long(name='IndexCount', description='The number of indexes.', example='1'),
        inequalityColumns?: string(name='InequalityColumns', description='The index columns included in the not equal operation.', example='2392'),
        lastUserSeek?: long(name='LastUserSeek', description='The last seek time of a user.', example='1702023327000'),
        objectName?: string(name='ObjectName', description='The object name.', example='stu'),
        reservedPages?: long(name='ReservedPages', description='The total number of returned pages.', example='5025'),
        reservedSize?: double(name='ReservedSize', description='The table size.', example='39.26'),
        rowCount?: long(name='RowCount', description='The number of table rows.', example='226945'),
        schemaName?: string(name='SchemaName', description='The schema name.', example='dbo'),
        systemScans?: long(name='SystemScans', description='The number of scans.', example='0'),
        systemSeeks?: long(name='SystemSeeks', description='The number of seeks.', example='0'),
        uniqueCompiles?: long(name='UniqueCompiles', description='The number of compilations.', example='2392'),
        userScans?: long(name='UserScans', description='The number of scans performed by users.', example='0'),
        userSeeks?: long(name='UserSeeks', description='The number of seeks performed by users.', example='1081'),
      }
    ](name='List', description='The returned data.'),
    pageNo?: long(name='PageNo', description='The page number of the page returned.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    total?: long(name='Total', description='The total number of entries returned.', example='16'),
  }(name='Data', description='The detailed information.'),
  message?: string(name='Message', description='The returned message.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='0A74B755-98B7-59DB-8724-1321B394****'),
  success?: string(name='Success', description='Indicates whether the request is successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetInstanceMissingIndexListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetInstanceMissingIndexListResponseBody(name='body'),
}

/**
  * *   This operation is applicable only to ApsaraDB RDS for SQL Server instances.
  * *   If you use an Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call the API operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function getInstanceMissingIndexList(request: GetInstanceMissingIndexListRequest): GetInstanceMissingIndexListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetInstanceMissingIndexList', 'POST', '/', 'json', false, 'json', request);
}

model GetInstanceSqlOptimizeStatisticRequest {
  endTime: string(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1662518540764', position='Query'),
  filterEnable?: string(name='FilterEnable', description='Specifies whether to filter instances for which DAS Enterprise Edition is enabled. Valid values:

*   **true**
*   **false**

>  If you set this parameter to **true**, only database instances for which DAS Enterprise Edition is disabled are queried. If you set this parameter to **false**, all database instances are queried.', example='false', position='Query'),
  instanceId: string(name='InstanceId', description='The database instance ID.

>  The database instance must be an ApsaraDB RDS for MySQL instance or a PolarDB for MySQL cluster.', example='pc-wz90h9560rvdz****', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  For ApsaraDB RDS for MySQL Cluster Edition instances or PolarDB for MySQL clusters, you must specify the node ID.', example='pi-bp12v7243x012****', position='Query'),
  startTime: string(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1661308902060', position='Query'),
  threshold?: string(name='Threshold', description='The duration threshold for automatic SQL optimization events. After this parameter is specified, the system collects statistics on automatic SQL optimization events whose duration does not exceed the specified threshold.

>  This parameter is a reserved parameter and does not take effect.', example='None', position='Query'),
  useMerging?: string(name='UseMerging', description='Specifies whether to merge automatic SQL optimization events. Valid values:

*   **true**: merges automatic SQL optimization events.
*   **false**: does not merge automatic SQL optimization events.

>  This parameter is a reserved parameter and does not take effect.', example='true', position='Query'),
}

model GetInstanceSqlOptimizeStatisticResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    count?: int32(name='count', description='The total number of automatic SQL optimization events.', example='16'),
    improvement?: double(name='improvement', description='The multiple of the maximum improvement for returned automatic SQL optimization events.', example='1003'),
  }(name='Data', description='The details of the automatic SQL optimization events.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model GetInstanceSqlOptimizeStatisticResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetInstanceSqlOptimizeStatisticResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a Database Autonomy Service (DAS) SDK to call this API operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   The database engine is ApsaraDB RDS for MySQL or PolarDB for MySQL.
  *
 */
async function getInstanceSqlOptimizeStatistic(request: GetInstanceSqlOptimizeStatisticRequest): GetInstanceSqlOptimizeStatisticResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetInstanceSqlOptimizeStatistic', 'POST', '/', 'json', false, 'json', request);
}

model GetKillInstanceSessionTaskResultRequest {
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze1jdv45i7l6****', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  You must specify this parameter if your database instance is a PolarDB for MySQL cluster.', example='pi-8vbkfj5a756um****', position='Query'),
  taskId: string(name='TaskId', description='The task ID. You can obtain the task ID from the response parameters of the [CreateKillInstanceSessionTask](~~609246~~) operation.', example='f77d535b45405bd462b21caa3ee8****', position='Query'),
}

model GetKillInstanceSessionTaskResultResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    ignoredUserSessionCount?: long(name='IgnoredUserSessionCount', description='The number of ignored sessions, including sessions of the accounts that are specified by IgnoredUsers, sessions of internal O\\&M accounts of Alibaba Cloud, and **Binlog Dump** sessions.', example='9'),
    instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-2ze1jdv45i7l6****'),
    killFailCount?: long(name='KillFailCount', description='The number of sessions that failed to be terminated.', example='0'),
    killSuccessCount?: long(name='KillSuccessCount', description='The number of sessions that were terminated.', example='100'),
    nodeId?: string(name='NodeId', description='The node ID.

>  This parameter is returned only if the instance is a PolarDB for MySQL cluster.', example='pi-bp1h12rv501cv****'),
    result?: [ 
      {
        active?: boolean(name='Active', description='Indicates whether the session is active.

> If the type of the command is Query or Execute and the session in the transaction is not terminated, the session is active.', example='true'),
        command?: string(name='Command', description='The type of the command executed in the session.', example='Sleep'),
        db?: string(name='Db', description='The name of the database.', example='dbTest'),
        host?: string(name='Host', description='The IP address and port number of the host that initiated the session.', example='100.104.XX.XX:23428'),
        id?: long(name='Id', description='The session ID.', example='8357518'),
        info?: string(name='Info', description='The SQL statement executed in the session.', example='SELECT sleep(60)'),
        reason?: string(name='Reason', description='The description of the session when the session was terminated.

*   **SESSION_KILLED**: The session is terminated.
*   **SESSION_EXPIRED**: The session has expired.
*   **SESSION_NO_PERMISSION**: The account used to terminate the session has insufficient permissions.
*   **SESSION_ACCOUNT_ERROR**: The account or password used to terminate the session is invalid.
*   **SESSION_IGNORED_USER**: The session of the account does not need to be terminated.
*   **SESSION_INTERNAL_USER_OR_COMMAND**: The session is a session initiated by or a command run by an Alibaba Cloud O\\&M account.
*   **SESSION_KILL_TASK_TIMEOUT**: Timeout occurs when the session is terminated.
*   **SESSION_OTHER_ERROR**: Other errors occurred.', example='SESSION_KILLED'),
        state?: string(name='State', description='The status of the session.', example='Sending data'),
        taskId?: string(name='TaskId', description='The ID of the subtask that terminates the session.', example='task_d9e94107-6116-4ac3-b874-81466aff****'),
        time?: long(name='Time', description='The execution duration. Unit: seconds.', example='1'),
        user?: string(name='User', description='The account of the database.', example='testUser'),
      }
    ](name='Result', description='The details of the task that terminated sessions.'),
    sessions?: [ long ](name='Sessions', description='The session IDs.

>  If all sessions are terminated, the IDs of all sessions on the instance or node are returned.'),
    taskId?: string(name='TaskId', description='The task ID.', example='f77d535b45405bd462b21caa3ee8****'),
    taskState?: string(name='TaskState', description='The state of the task that terminates sessions.

*   **RUNNING**: The task is in progress.
*   **SUCCESS**: The task is successful.
*   **FAILURE**: The task failed.
*   **ERROR**: Other errors occur.', example='SUCCESS'),
    userId?: string(name='UserId', description='The ID of the Alibaba Cloud account.', example='164882191396****'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetKillInstanceSessionTaskResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetKillInstanceSessionTaskResultResponseBody(name='body'),
}

/**
  * *   This operation is applicable only to ApsaraDB RDS for MySQL instances and PolarDB for MySQL clusters.
  * *   If you use an Alibaba Cloud SDK or a Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function getKillInstanceSessionTaskResult(request: GetKillInstanceSessionTaskResultRequest): GetKillInstanceSessionTaskResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetKillInstanceSessionTaskResult', 'POST', '/', 'json', false, 'json', request);
}

model GetMongoDBCurrentOpRequest {
  filterDoc?: string(name='FilterDoc', description='The `db.currentOp()` command that is used to filter sessions. For more information, see [db.currentOp()](https://docs.mongodb.com/manual/reference/method/db.currentOp/) of MongoDB Documentation.', example='{ "active" : true }', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='dds-uf608087********', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  If you do not specify a node ID, the sessions of the primary node are queried by default.', example='23302531', position='Query'),
  role?: string(name='Role', description='A reserved parameter. You do not need to specify the parameter.', example='None', position='Query'),
}

model GetMongoDBCurrentOpResponseBody = {
  code?: long(name='Code', description='The response code.', example='200'),
  data?: {
    sessionList?: [ 
      {
        active?: boolean(name='Active', description='Indicates whether the operation is active. Valid values:

*   **true**
*   **false**', example='true'),
        client?: string(name='Client', description='The IP address of the client.', example='219.143.177.4:52324'),
        command?: string(name='Command', description='The document that contains the complete command object associated with the operation.', example='"command" : {
  "find" : "items",
  "filter" : {
    "sku" : 1403978
  },
  ...
  "$db" : "test"
}'),
        connectionId?: long(name='ConnectionId', description='The connection ID.', example='66378736'),
        desc?: string(name='Desc', description='The description of the connection.', example='conn1013858'),
        driver?: string(name='Driver', description='The driver for MongoDB.', example='mongo-java-driver|legacy@3.11.2'),
        host?: string(name='Host', description='The host.', example='a79******.cloud.et15:3328'),
        killPending?: boolean(name='KillPending', description='Indicates whether the operation is marked as terminated.

*   **true**
*   **false**', example='true'),
        ns?: string(name='Ns', description='The namespace.', example='admin.cmd'),
        op?: string(name='Op', description='The type of the operation.', example='update'),
        opId?: string(name='OpId', description='The operation ID.', example='14508'),
        osArch?: string(name='OsArch', description='The architecture of the operating system.', example='amd64'),
        osName?: string(name='OsName', description='The name of the operating system.', example='Linux'),
        osType?: string(name='OsType', description='The type of the operating system.', example='Linux'),
        planSummary?: string(name='PlanSummary', description='The description of the execution plan.', example='None'),
        platform?: string(name='Platform', description='The platform.', example='Java/Alibaba/1.8.0_152-b5'),
        secsRunning?: long(name='SecsRunning', description='The duration of the operation. Unit: seconds.', example='5'),
        shard?: string(name='Shard', description='The ID of the data shard.

>  This parameter is returned for sharded cluster instances.', example='d-bp1689995b78****'),
      }
    ](name='SessionList', description='The sessions.'),
    sessionStat?: {
      activeCount?: long(name='ActiveCount', description='The number of active sessions.', example='0'),
      clientStats?: map[string]DataSessionStatClientStatsValue(name='ClientStats', description='The statistics on the IP addresses of the clients.'),
      dbStats?: map[string]DataSessionStatDbStatsValue(name='DbStats', description='The statistics on the namespaces.'),
      longestSecsRunning?: long(name='LongestSecsRunning', description='The longest duration of a session. Unit: seconds.', example='0'),
      totalCount?: long(name='TotalCount', description='The total number of sessions.', example='55'),
    }(name='SessionStat', description='The statistics on the sessions.'),
    timestamp?: long(name='Timestamp', description='The time when the database sessions were returned. The value is in the UNIX timestamp format. Unit: milliseconds.', example='1692029584428'),
  }(name='Data', description='The details of the sessions.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. Otherwise, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='FC6C0929-29E1-59FD-8DFE-70D9D41E****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetMongoDBCurrentOpResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMongoDBCurrentOpResponseBody(name='body'),
}

/**
  * *   This operation is applicable only to MongoDB instances.
  * *   If you use an Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call API operations of DAS, you must set the region to cn-shanghai.
  *
 */
async function getMongoDBCurrentOp(request: GetMongoDBCurrentOpRequest): GetMongoDBCurrentOpResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMongoDBCurrentOp', 'POST', '/', 'json', false, 'json', request);
}

model GetMySQLAllSessionAsyncRequest {
  instanceId: string(name='InstanceId', description='The instance ID.

>  Only ApsaraDB RDS for MySQL, PolarDB for MySQL, and PolarDB-X 2.0 instances are supported.', example='rm-2ze8g2am97624****', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  You must specify this parameter for PolarDB for MySQL clusters. If you do not specify a node ID, the session data of the primary node is returned by default.', example='pi-wz954ryd8f893****', position='Query'),
  resultId?: string(name='ResultId', description='The asynchronous request ID.

>  GetMySQLAllSessionAsync is an asynchronous operation. After a request is sent, the system does not return complete results but returns a **request ID**. You need to use the **request ID** to initiate requests until the value of the **isFinish** field in the returned results is **true**, the complete results are returned. This indicates that to obtain complete data, you must call this operation at least twice.', example='async__507044db6c4eadfa2dab9b084e80****', position='Query'),
}

model GetMySQLAllSessionAsyncResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    complete?: boolean(name='Complete', description='Indicates whether the asynchronous request was complete. Valid values:

*   **true**
*   **false**', example='true'),
    fail?: boolean(name='Fail', description='Indicates whether the asynchronous request failed. Valid values:

*   **true**
*   **false**', example='false'),
    isFinish?: boolean(name='IsFinish', description='Indicates whether the asynchronous request was complete. Valid values:

*   **true**
*   **false**', example='true'),
    resultId?: string(name='ResultId', description='The ID of the asynchronous request.', example='async__507044db6c4eadfa2dab9b084e80****'),
    sessionData?: {
      activeSessionCount?: long(name='ActiveSessionCount', description='The total number of active sessions.', example='10'),
      clientStats?: [ 
        {
          activeCount?: long(name='ActiveCount', description='The number of active sessions that belong to the client IP address.

>  If the type of the command executed in the session is Query or Execute and the session in the transaction is not terminated, the session is active.', example='1'),
          key?: string(name='Key', description='The IP address of the client.', example='47.100.XX.XX'),
          threadIdList?: [ long ](name='ThreadIdList', description='The IDs of the sessions that belong to the client IP address.'),
          totalCount?: long(name='TotalCount', description='The total number of sessions that belong to the client IP address.', example='2'),
          userList?: [ string ](name='UserList', description='The database accounts to which the sessions belong.'),
        }
      ](name='ClientStats', description='The sessions that are counted by client IP address.'),
      dbStats?: [ 
        {
          activeCount?: long(name='ActiveCount', description='The number of active sessions of the database.

>  If the type of the command executed in the session is Query or Execute and the session in the transaction is not terminated, the session is active.', example='1'),
          key?: string(name='Key', description='The database name.', example='dbTest'),
          threadIdList?: [ long ](name='ThreadIdList', description='The IDs of the sessions of the database.'),
          totalCount?: long(name='TotalCount', description='The total number of sessions of the database.', example='2'),
          userList?: [ string ](name='UserList', description='The database accounts to which the sessions belong.'),
        }
      ](name='DbStats', description='The sessions that are counted by database.'),
      maxActiveTime?: long(name='MaxActiveTime', description='The maximum execution duration of an active session. Unit: seconds.', example='6'),
      sessionList?: [ 
        {
          client?: string(name='Client', description='The IP address of the client.', example='47.100.XX.XX'),
          command?: string(name='Command', description='The type of the command executed in the session.', example='Query'),
          dbName?: string(name='DbName', description='The database name.', example='dbTest'),
          sessionId?: long(name='SessionId', description='The session ID.', example='14521783'),
          sqlTemplateId?: string(name='SqlTemplateId', description='The SQL template ID.

>  This parameter is returned only when you use a PolarDB-X 2.0 instance.', example='a7cac1a9'),
          sqlText?: string(name='SqlText', description='The SQL statement executed in the session.', example='INSERT INTO ...'),
          state?: string(name='State', description='The status of the session.', example='starting'),
          time?: long(name='Time', description='The execution duration of the session. Unit: seconds.', example='6'),
          trxDuration?: long(name='TrxDuration', description='The duration of the transaction. Unit: seconds.', example='6'),
          trxId?: string(name='TrxId', description='The ID of the transaction to which the session belongs.', example='754300775132'),
          user?: string(name='User', description='The username of the database account.', example='testUser'),
          userClientAlias?: string(name='UserClientAlias', description='The alias of the IP address of the client.', example='master-shanghai'),
        }
      ](name='SessionList', description='The sessions.'),
      timeStamp?: long(name='TimeStamp', description='The time when the session was queried. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1659581514000020'),
      totalSessionCount?: long(name='TotalSessionCount', description='The total number of sessions.', example='988'),
      userStats?: [ 
        {
          activeCount?: long(name='ActiveCount', description='The number of active sessions within the account.

>  If the type of the command executed in the session is Query or Execute and the session in the transaction is not terminated, the session is active.', example='1'),
          key?: string(name='Key', description='The database account.', example='testUser'),
          threadIdList?: [ long ](name='ThreadIdList', description='The IDs of the sessions within the account.'),
          totalCount?: long(name='TotalCount', description='The total number of sessions within the account.', example='2'),
          userList?: [ string ](name='UserList', description='The database accounts to which the sessions belong.'),
        }
      ](name='UserStats', description='The sessions that are counted by database account.'),
    }(name='SessionData', description='The session data.'),
    state?: string(name='State', description='The state of the asynchronous request. Valid values:

*   **RUNNING**
*   **SUCCESS**
*   **FAIL**', example='SUCCESS'),
    timestamp?: long(name='Timestamp', description='The time when the asynchronous request was made. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1660100753556'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetMySQLAllSessionAsyncResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMySQLAllSessionAsyncResponseBody(name='body'),
}

/**
  * >  GetMySQLAllSessionAsync is an asynchronous operation. After a request is sent, the system does not return complete results but returns a request ID. You need to use the request ID to initiate requests until the value of the **isFinish** field in the returned results is **true**, the complete results are returned. This indicates that to obtain complete data, you must call this operation at least twice.
  * *   This operation is applicable only to ApsaraDB RDS for MySQL instances, PolarDB for MySQL clusters, and PolarDB-X 2.0 instances.
  * *   If you use an Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function getMySQLAllSessionAsync(request: GetMySQLAllSessionAsyncRequest): GetMySQLAllSessionAsyncResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetMySQLAllSessionAsync', 'POST', '/', 'json', false, 'json', request);
}

model GetPartitionsHeatmapRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceId?: string(name='InstanceId', description='The instance ID.', example='pxc-hzrciqy62c****', position='Query'),
  timeRange?: string(name='TimeRange', description='The time range to be queried. Valid values:

*   **LAST_ONE_HOURS**: the last hour.
*   **LAST_SIX_HOURS**: the last six hours.
*   **LAST_ONE_DAYS**: the last day.
*   **LAST_THREE_DAYS**: the last three days.
*   **LAST_SEVEN_DAYS**: the last seven days.', example='LAST_SIX_HOURS', position='Query'),
  type?: string(name='Type', description='The type of the data to be queried. Valid values:

*   **READ_ROWS**: the read rows.
*   **WRITTEN_ROWS**: the written rows.
*   **READ_WRITTEN_ROWS**: the read and written rows.
*   **UPDATE_ROWS**: the updated rows.
*   **INSERTED_ROWS**: the inserted rows.
*   **DELETED_ROWS**: the deleted rows.
*   **READ_ROWS_WITH_DN**: the read rows returned from a data node.
*   **WRITTEN_ROWS_WITH_DN**: the written rows returned from a data node.
*   **READ_WRITTEN_ROWS_WITH_DN**: the read and written rows returned from a data node.', example='WRITTEN_ROWS_WITH_DN', position='Query'),
}

model GetPartitionsHeatmapResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The hot data of the PolarDB-X 2.0 instance. The data is returned in JSON format.', example='{
    "boundAxis": [
        {
            "bound": "A,B,C,D",
            "labels": [
                "L1",
                "L2",
                "L3",
                "L4"
            ],
            "rows": 3171
        },
        {
            "bound": "A,B,C,D",
            "labels": [
                "L1",
                "L2",
                "L3",
                "L4"
            ],
            "rows": 277128
        }
    ],
    "dataMap": {
        "READ_WRITTEN_ROWS": [
            [
                0,
                0,
                0
            ],
            [
                0,
                0,
                0
            ]
        ]
    },
    "timeAxis": [
        1671701056070,
        1671701116551,
        1671701177020
    ]
}'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message that contains information such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='D00DB161-FEF6-5428-B37A-8D29A4C2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetPartitionsHeatmapResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPartitionsHeatmapResponseBody(name='body'),
}

/**
  * We recommend that you do not call this operation. The data is returned in a special format and is complex to parse. You can use the [heatmap](~~470302~~) feature of Database Autonomy Service (DAS) to query the data.
  *
 */
async function getPartitionsHeatmap(request: GetPartitionsHeatmapRequest): GetPartitionsHeatmapResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPartitionsHeatmap', 'POST', '/', 'json', false, 'json', request);
}

model GetPfsMetricTrendsRequest {
  endTime?: long(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time. You can view the data of up to seven days in the previous 30 days.', example='1678432430967', position='Body'),
  instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-m5ea73876ukci****', position='Body'),
  metric?: string(name='Metric', description='The metric whose trend you want to query. Valid values:

*   **count**: the number of executions.
*   **avgRt**: the average execution duration.
*   **rtRate**: the execution duration percentage.
*   **rowsExamined**: the total number of scanned rows.', example='Count', position='Body'),
  nodeId?: string(name='NodeId', description='The node ID.

>  You must specify this parameter for an ApsaraDB RDS for MySQL cluster instance and a PolarDB for MySQL cluster.', example='r-x****-db-0', position='Body'),
  startTime?: long(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1677461663092', position='Body'),
}

model GetPfsMetricTrendsResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: map[string][ DataValue   ](name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='F4C27966-284E-51C4-9407-DB50CAB8****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetPfsMetricTrendsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPfsMetricTrendsResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  * *   An ApsaraDB RDS for MySQL instance or a PolarDB for MySQL cluster is connected to DAS.
  * *   The new version of the performance insight feature is enabled for the database instance. For more information, see [Performance insight (new version)](~~469117~~).
  *
 */
async function getPfsMetricTrends(request: GetPfsMetricTrendsRequest): GetPfsMetricTrendsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPfsMetricTrends', 'POST', '/', 'json', true, 'form', request);
}

model GetPfsSqlSampleRequest {
  endTime: long(name='EndTime', description='The end of the time range to query. The value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time. You can view the data of up to seven days in the previous 30 days.', example='1678074351197', position='Body'),
  instanceId: string(name='InstanceId', description='The instance ID.

>  Only ApsaraDB RDS for MySQL instances and PolarDB for MySQL clusters are supported', example='rm-2ze1jdv45i7l6****', position='Body'),
  nodeId?: string(name='NodeId', description='The node ID.

>  For ApsaraDB RDS for MySQL Cluster Edition instances or PolarDB for MySQL clusters, you must specify the node ID.', example='r-x****-db-0', position='Body'),
  sqlId?: string(name='SqlId', description='The SQL ID.', example='651b56fe9418d48edb8fdf0980ec****', position='Body'),
  startTime: long(name='StartTime', description='The beginning of the time range to query. The value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1676511134614', position='Body'),
}

model GetPfsSqlSampleResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: [ 
    {
      createTmpDiskTables?: int32(name='CreateTmpDiskTables', description='The number of internal on-disk temporary tables that were created when the SQL statement was executed.', example='0'),
      createTmpTables?: int32(name='CreateTmpTables', description='The number of internal temporary tables that were created when the SQL statement was executed.', example='0'),
      db?: string(name='Db', description='The name of the database.', example='testDB'),
      endEventId?: int32(name='EndEventId', description='The end ID of the event. By default, the value of this parameter is NULL when the event starts and is changed to the event ID when the event ends.', example='0'),
      errors?: int32(name='Errors', description='The number of errors returned for the SQL statement.', example='0'),
      eventId?: int32(name='EventId', description='The event ID.', example='63735293'),
      eventName?: string(name='EventName', description='The name of the event.', example='statement/sql/select'),
      instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-2ze1jdv45i7l6****'),
      latency?: double(name='Latency', description='The execution duration. Unit: millisecond.', example='0.199'),
      lockLatency?: double(name='LockLatency', description='The lock wait duration. Unit: millisecond.', example='0.09'),
      logicId?: string(name='LogicId', description='The ID of the logical database.', example='xxxxx'),
      noGoodIndexUsed?: int32(name='NoGoodIndexUsed', description='Indicates whether the server failed to find an index that can be used for the SQL statement. Valid values:

*   **1**: yes.
*   **0**: no.', example='1'),
      noIndexUsed?: int32(name='NoIndexUsed', description='Indicates whether table scans were performed when indexes were not used. Valid values:

*   **1**: yes.
*   **0**: no.', example='1'),
      nodeId?: string(name='NodeId', description='The node ID.

>  This parameter is returned only for ApsaraDB RDS for MySQL Cluster Edition instances or PolarDB for MySQL clusters.', example='r-x****-db-0'),
      rowsAffected?: int32(name='RowsAffected', description='The number of rows affected by the SQL statement.', example='0'),
      rowsExamined?: int32(name='RowsExamined', description='The number of rows scanned by the SQL statement.', example='2048576'),
      rowsSent?: int32(name='RowsSent', description='The number of rows returned by the SQL statement.', example='0'),
      selectFullJoin?: int32(name='SelectFullJoin', description='The number of joins that are used to perform table scans without using indexes.

> : This parameter is used for the scenario in which indexes are not used in a union query. If the returned value is not 0, check the indexes of tables.', example='0'),
      selectFullRangeJoin?: int32(name='SelectFullRangeJoin', description='The number of joins that used ranges on referenced tables.', example='0'),
      selectRange?: int32(name='SelectRange', description='The number of joins that used ranges on the first table.', example='0'),
      selectRangeCheck?: int32(name='SelectRangeCheck', description='The number of joins that did not have key values. The keys and values were checked for each row of data.

> : This parameter is used for the scenario in which indexes are not used in a union query. If the returned value is not 0, check the indexes of tables.', example='0'),
      selectScan?: int32(name='SelectScan', description='The number of scans.', example='0'),
      sortMergePasses?: int32(name='SortMergePasses', description='The number of merges that the sorting algorithm must perform.', example='0'),
      sortRange?: int32(name='SortRange', description='The number of times the data was sorted by using ranges.', example='0'),
      sortRows?: int32(name='SortRows', description='The number of sorted rows.', example='0'),
      sortScan?: int32(name='SortScan', description='The number of sorts that were performed during table scans.', example='1'),
      sql?: string(name='Sql', description='The sample SQL statement.', example='select * from xxxx where ****'),
      sqlId?: string(name='SqlId', description='The SQL statement ID.', example='651b56fe9418d48edb8fdf0980ec****'),
      threadId?: int32(name='ThreadId', description='The thread ID.', example='81751940'),
      timestamp?: long(name='Timestamp', description='The time when the SQL statement was executed. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1660100753556'),
      userId?: string(name='UserId', description='The user ID.', example='196278346919****'),
      warnings?: int32(name='Warnings', description='The number of warnings returned for the SQL statement.', example='0'),
    }
  ](name='Data', description='The SQL sample data.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='9CB97BC4-6479-55D0-B9D0-EA925AFE****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model GetPfsSqlSampleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPfsSqlSampleResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a Database Autonomy Service (DAS) SDK to call this API operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   An ApsaraDB RDS for MySQL instance or a PolarDB for MySQL cluster is connected to DAS.
  * *   The new version of the performance insight feature is enabled for the database instance. For more information, see [Performance insight (new version)](~~469117~~).
  *
 */
async function getPfsSqlSample(request: GetPfsSqlSampleRequest): GetPfsSqlSampleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPfsSqlSample', 'POST', '/', 'json', true, 'form', request);
}

model GetPfsSqlSummariesRequest {
  asc?: boolean(name='Asc', description='Specifies whether to sort the returned entries in ascending order. Default value: **false**. Valid values:

*   **true**
*   **false**', example='false', position='Body'),
  endTime?: long(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time. You can view the data of up to seven days within the last month.', example='1679297005999', position='Body'),
  instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-uf61swc4cru0b****', position='Body'),
  keywords?: string(name='Keywords', description='The keywords of the SQL template. Separate multiple keywords with spaces.', example='select update', position='Body'),
  nodeId?: string(name='NodeId', description='The node ID.

>  This parameter must be specified if the database instance is an ApsaraDB RDS for MySQL Cluster Edition instance or a PolarDB for MySQL cluster.', example='r-****-db-0', position='Body'),
  orderBy?: string(name='OrderBy', description='The field by which to sort the returned entries. Default value: **count**.

*   **count**: the number of executions.
*   **avgRt**: the average execution duration.
*   **rtRate**: the execution duration percentage.
*   **rowsExamined**: the total number of scanned rows.
*   **avgRowsExamined**: the average number of scanned rows.
*   **avgRowsReturned**: the average number of returned rows.', example='count', position='Body'),
  pageNo?: int32(name='PageNo', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Body'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10. Valid values: 1 to 100.', example='10', position='Body'),
  sqlId?: string(name='SqlId', description='The SQL ID.

>  If this parameter is specified, the full request statistics of the specified SQL query are collected. If this parameter is left empty, the full request statistics of the entire database instance are collected.', example='651b56fe9418d48edb8fdf0980ec****', position='Body'),
  startTime?: long(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1675833788056', position='Body'),
}

model GetPfsSqlSummariesResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    extra?: any(name='Extra', description='The reserved parameter.', example='None'),
    list?: [ 
      {
        avgLatency?: double(name='AvgLatency', description='The average execution latency. Unit: millisecond.', example='0.1717'),
        count?: long(name='Count', description='The total number of executions.', example='100000'),
        countRate?: double(name='CountRate', description='The percentage of the number of executions.', example='0.0586'),
        cpuRate?: double(name='CpuRate', description='The ratio of the CPU execution duration to the total execution duration of the SQL statement.', example='0'),
        cpuTime?: double(name='CpuTime', description='The CPU execution duration. Unit: millisecond.', example='0'),
        dataReadTime?: double(name='DataReadTime', description='The data read duration. Unit: millisecond.', example='0'),
        dataReads?: int32(name='DataReads', description='The number of nodes from which data can be read.', example='0'),
        dataWriteTime?: double(name='DataWriteTime', description='The data write duration. Unit: millisecond.', example='0'),
        dataWrites?: int32(name='DataWrites', description='The number of nodes to which data can be written.', example='0'),
        db?: string(name='Db', description='The name of the database.', example='testDB'),
        elapsedTime?: double(name='ElapsedTime', description='The execution duration. Unit: millisecond.', example='0'),
        errCount?: long(name='ErrCount', description='The number of errors.', example='0'),
        firstTime?: long(name='FirstTime', description='The time when the SQL statement was executed for the first time. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1659308149000'),
        fullScan?: boolean(name='FullScan', description='Indicates whether full table scan was enabled. Valid values:

* **true**
* **false**', example='true'),
        id?: long(name='Id', description='The primary key ID.', example='26186357'),
        instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****'),
        lastTime?: long(name='LastTime', description='The time when the SQL statement was last modified. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1661306520000'),
        lockLatencyAvg?: double(name='LockLatencyAvg', description='The average lock wait latency. Unit: millisecond.', example='0'),
        logicId?: long(name='LogicId', description='The logical database ID.', example='58275984'),
        logicReads?: long(name='LogicReads', description='The number of logical nodes.', example='0'),
        maxLatency?: double(name='MaxLatency', description='The maximum execution latency. Unit: millisecond.', example='36.233'),
        mutexSpins?: int32(name='MutexSpins', description='The number of mutex spins.', example='1'),
        mutexWaits?: int32(name='MutexWaits', description='The number of mutex waits.', example='1'),
        nodeId?: string(name='NodeId', description='The node ID.

> This parameter is returned only if the database instance is an ApsaraDB RDS for MySQL Cluster Edition instance or a PolarDB for MySQL cluster.', example='r-x****-db-0'),
        physicalAsyncReads?: long(name='PhysicalAsyncReads', description='The number of physical asynchronous nodes.', example='0'),
        physicalReads?: long(name='PhysicalReads', description='The number of physical nodes.', example='0'),
        psql?: string(name='Psql', description='The SQL template.', example='select ?'),
        redoWrites?: long(name='RedoWrites', description='The number of redo nodes.', example='0'),
        rowsAffected?: long(name='RowsAffected', description='The number of rows that are affected by the SQL statement.', example='0'),
        rowsAffectedAvg?: double(name='RowsAffectedAvg', description='The average number of rows affected by the SQL statement.', example='0'),
        rowsExamined?: long(name='RowsExamined', description='The total number of scanned rows.', example='100'),
        rowsExaminedAvg?: double(name='RowsExaminedAvg', description='The average number of scanned rows.', example='0'),
        rowsSendAvg?: double(name='RowsSendAvg', description='The average number of returned rows.', example='0'),
        rowsSent?: long(name='RowsSent', description='The number of rows returned by the SQL statement.', example='0'),
        rowsSentAvg?: double(name='RowsSentAvg', description='The average number of rows returned for the SQL statement.', example='0.52'),
        rowsSorted?: long(name='RowsSorted', description='The number of sorted rows.', example='0'),
        rtRate?: double(name='RtRate', description='The execution duration percentage.', example='0.1384'),
        rwlockOsWaits?: int32(name='RwlockOsWaits', description='Indicates whether read/write splitting was enabled. Valid values:

* **0:** Read/write splitting was disabled.
* **1:** Read/write splitting was enabled.', example='0'),
        rwlockSpinRounds?: int32(name='RwlockSpinRounds', description='The read/write splitting parameters.', example='0'),
        rwlockSpinWaits?: int32(name='RwlockSpinWaits', description='Indices whether multi-index scanning was enabled. Valid values:

* **0:** Multi-index scanning was disabled.
* **1:** Multi-index scanning was enabled.', example='0'),
        selectFullJoinAvg?: double(name='SelectFullJoinAvg', description='The average number of joins that performed table scans without using indexes.

> If the value of this parameter is not 0, check the table indexes.', example='0'),
        selectFullRangeJoinAvg?: double(name='SelectFullRangeJoinAvg', description='The average number of joins that selected a range.', example='0'),
        selectRangeAvg?: double(name='SelectRangeAvg', description='The average selected range.', example='0'),
        selectScanAvg?: double(name='SelectScanAvg', description='The average number of scanned rows.', example='0'),
        semisyncDelayTime?: double(name='SemisyncDelayTime', description='The semi-synchronous replication latency. Unit: millisecond.', example='0.12'),
        serverLockTime?: double(name='ServerLockTime', description='The amount of time consumed for locking the server. Unit: millisecond.', example='0'),
        sortMergePasses?: long(name='SortMergePasses', description='The number of merges that the sorting algorithm must perform.', example='0'),
        sortRangeAvg?: double(name='SortRangeAvg', description='The average number of sorts that were performed by using a range.', example='0'),
        sortRowsAvg?: double(name='SortRowsAvg', description='The average number of sorted rows.', example='0'),
        sortScanAvg?: double(name='SortScanAvg', description='The average number of sorts that were performed during table scans.', example='0'),
        sqlId?: string(name='SqlId', description='The SQL template ID.', example='2e8147b5ca2dfc640dfd5e43d96a****'),
        sqlType?: string(name='SqlType', description='The type of the SQL statement. Valid values:

* **SELECT**
* **UPDATE**
* **DELETE**', example='SELECT'),
        tables?: [ string ](name='Tables', description='The names of tables in the database.'),
        timerWaitAvg?: double(name='TimerWaitAvg', description='The reserved parameter.', example='None'),
        timestamp?: long(name='Timestamp', description='The data timestamp. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1643040000000'),
        tmpDiskTables?: long(name='TmpDiskTables', description='The number of on-disk temporary tables.', example='0'),
        tmpDiskTablesAvg?: double(name='TmpDiskTablesAvg', description='The average number of on-disk temporary tables.', example='0'),
        tmpTables?: long(name='TmpTables', description='The number of temporary tables.', example='0'),
        tmpTablesAvg?: double(name='TmpTablesAvg', description='The average number of temporary tables.', example='0'),
        totalLatency?: double(name='TotalLatency', description='The execution latency. Unit: millisecond.', example='60913.256'),
        transactionLockTime?: double(name='TransactionLockTime', description='The amount of time consumed for locking the storage transaction. Unit: millisecond.', example='0'),
        userId?: string(name='UserId', description='The user ID.', example='196278346919****'),
        warnCount?: long(name='WarnCount', description='The number of warnings.', example='0'),
      }
    ](name='List', description='The detailed information.'),
    pageNo?: long(name='PageNo', description='The page number.', example='1'),
    pageSize?: long(name='PageSize', description='The number of entries per page.', example='10'),
    total?: long(name='Total', description='The total number of entries returned.', example='264'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='54F3DBAE-9420-511A-9C29-265E8C04****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetPfsSqlSummariesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetPfsSqlSummariesResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a Database Autonomy Service (DAS) SDK to call this API operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   An ApsaraDB RDS for MySQL instance or a PolarDB for MySQL cluster is connected to DAS.
  * *   The new version of the performance insight feature is enabled for the database instance. For more information, see [Performance insight (new version)](~~469117~~).
  *
 */
async function getPfsSqlSummaries(request: GetPfsSqlSummariesRequest): GetPfsSqlSummariesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetPfsSqlSummaries', 'POST', '/', 'json', true, 'form', request);
}

model GetQueryOptimizeDataStatsRequest {
  asc?: string(name='Asc', description='Specifies whether to sort the returned entries in ascending order. Default value: **true**. Valid values:

*   **true**: sorts the returned entries in ascending order.
*   **false**: does not sort the returned entries in ascending order.', example='true', position='Query'),
  dbNames?: string(name='DbNames', description='The name of the database to be queried.', example='testdb01', position='Query'),
  engine: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**
*   **PolarDBMySQL**
*   **PostgreSQL**', example='MySQL', position='Query'),
  instanceIds?: string(name='InstanceIds', description='The instance IDs. Separate multiple IDs with commas (,).', example='rm-2ze8g2am97624****', position='Query'),
  keywords?: string(name='Keywords', description='The keywords of the SQL template. Separate multiple keywords with spaces.', example='select update', position='Query'),
  logicalOperator?: string(name='LogicalOperator', description='The logical relationship between multiple keywords. Valid values:

*   **or**
*   **and**', example='or', position='Query'),
  onlyOptimizedSql?: string(name='OnlyOptimizedSql', description='Specifies whether to query only SQL templates that need to be optimized. Default value: **false**. Valid values:

*   **true**: queries only SQL templates that need to be optimized.
*   **false**: does not query only SQL statements that need to be optimized.', example='false', position='Query'),
  orderBy?: string(name='OrderBy', description='The field by which to sort the returned entries. Default value: **count**. Valid values:

*   **count**: the number of executions.
*   **maxQueryTime**: the longest execution time.
*   **avgQueryTime**: the average execution time.
*   **maxLockTime**: the longest lock wait time.
*   **avgLockTime**: the longest lock wait time.
*   **maxRowsExamined**: the largest number of scanned rows.
*   **avgRowsExamined**: the average number of scanned rows.
*   **maxRowsSent**: the largest number of returned rows.
*   **avgRowsSent**: the average number of returned rows.', example='count', position='Query'),
  pageNo?: string(name='PageNo', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: string(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  region?: string(name='Region', description='The region in which the instance resides. Valid values:

*   **cn-china**: Chinese mainland
*   **cn-hongkong**: China (Hong Kong)
*   **ap-southeast-1**: Singapore

This parameter takes effect only if **InstanceIds** is left empty. If you leave **InstanceIds** empty, the system obtains data from the region set by **Region**. By default, Region is set to **cn-china**. If you specify **InstanceIds**, **Region** does not take effect and the system obtains data from the region in which the first specified instance resides.****

>  Set this parameter to **cn-china** for the instances that are created in the regions in the Chinese mainland.', example='cn-china', position='Query'),
  rules?: string(name='Rules', description='The tags that are used to filter SQL templates. Separate multiple tags with commas (,). For more information, see [Query governance](~~290038~~).', example='DAS_NOT_IMPORTANT', position='Query'),
  sqlIds?: string(name='SqlIds', description='The SQL template ID. You can query the ID of a template by calling the [GetQueryOptimizeExecErrorStats](~~405235~~) operation.', example='2e8147b5ca2dfc640dfd5e43d96a****', position='Query'),
  tagNames?: string(name='TagNames', description='The reserved parameter.', example='None', position='Query'),
  time: string(name='Time', description='The time range to query. Specify the time in the UNIX timestamp format. Unit: milliseconds.', example='1642953600000', position='Query'),
  user?: string(name='User', description='The account of the database to be queried.', example='testUser', position='Query'),
}

model GetQueryOptimizeDataStatsResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    extra?: string(name='Extra', description='The reserved parameter.', example='None'),
    list?: [ 
      {
        avgLockTime?: double(name='AvgLockTime', description='The average lock wait time. Unit: seconds.', example='0.1'),
        avgQueryTime?: double(name='AvgQueryTime', description='The average query execution time. Unit: seconds.', example='1.1'),
        avgRowsAffected?: double(name='AvgRowsAffected', description='The average number of rows affected by the SQL statement.

> A value of -1 indicates that this parameter is not collected.', example='100.1'),
        avgRowsExamined?: double(name='AvgRowsExamined', description='The average number of scanned rows.', example='100.1'),
        avgRowsSent?: double(name='AvgRowsSent', description='The average number of returned rows.', example='100.1'),
        count?: int32(name='Count', description='The number of times that the SQL template is executed.', example='100'),
        dbname?: string(name='Dbname', description='The name of the database to which the SQL template belongs.', example='testdb01'),
        instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****'),
        maxLockTime?: double(name='MaxLockTime', description='The longest lock wait time. Unit: seconds.', example='0.1'),
        maxQueryTime?: double(name='MaxQueryTime', description='The longest query execution time. Unit: seconds.', example='1.1'),
        maxRowsAffected?: long(name='MaxRowsAffected', description='The largest number of rows affected by the SQL template.

> A value of -1 indicates that this parameter is not collected.', example='10000'),
        maxRowsExamined?: long(name='MaxRowsExamined', description='The largest number of scanned rows.', example='100000'),
        maxRowsSent?: long(name='MaxRowsSent', description='The largest number of returned rows.', example='10000'),
        psql?: string(name='Psql', description='The SQL template.', example='select 1'),
        ruleList?: [ 
          {
            name?: string(name='Name', description='The rule name.', example='DAS_NOT_IMPORTANT'),
            type?: string(name='Type', description='The type of the rule. Valid values:

* **Predefined**
* **UserDefined**', example='Predefined'),
          }
        ](name='RuleList', description='The information about the rules.'),
        sqlId?: string(name='SqlId', description='The SQL template ID.', example='2e8147b5ca2dfc640dfd5e43d96a****'),
        sqlSample?: string(name='SqlSample', description='The sample query that took the longest time to execute.', example='select 2'),
        sqlType?: string(name='SqlType', description='The type of the SQL statement.', example='INSERT'),
        user?: string(name='User', description='The account of the database.', example='testUser'),
      }
    ](name='List', description='The information about the SQL templates.'),
    pageNo?: int32(name='PageNo', description='The reserved parameter.', example='None'),
    pageSize?: int32(name='PageSize', description='The reserved parameter.', example='None'),
    total?: long(name='Total', description='The total number of entries returned.', example='10'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model GetQueryOptimizeDataStatsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetQueryOptimizeDataStatsResponseBody(name='body'),
}

/**
  * *   If you use an Alibaba Cloud SDK, make sure that the aliyun-sdk-core version is later than V2.1.8. We recommend that you use the latest version.
  * *   The version of your Database Autonomy Service (DAS) SDK must be V2.1.8 or later.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   PolarDB for MySQL
  *     *   ApsaraDB RDS for PostgreSQL
  *
 */
async function getQueryOptimizeDataStats(request: GetQueryOptimizeDataStatsRequest): GetQueryOptimizeDataStatsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetQueryOptimizeDataStats', 'GET', '/', 'json', false, 'json', request);
}

model GetQueryOptimizeDataTopRequest {
  engine: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**
*   **PolarDBMySQL**
*   **PostgreSQL**', example='MySQL', position='Query'),
  instanceIds?: string(name='InstanceIds', description='The instance IDs. Separate multiple IDs with commas (,).', example='rm-2ze8g2am97624****', position='Query'),
  region?: string(name='Region', description='The region in which the instance resides. Valid values:

*   **cn-china**: Chinese mainland
*   **cn-hongkong**: China (Hong Kong)
*   **ap-southeast-1**: Singapore

This parameter takes effect only if **InstanceIds** is left empty. If you leave **InstanceIds** empty, the system obtains data from the region set by **Region**. By default, Region is set to **cn-china**. If you specify **InstanceIds**, **Region** does not take effect and the system obtains data from the region in which the first specified instance resides.****

>  Set this parameter to **cn-china** for all your instances that reside in the regions in the Chinese mainland.', example='cn-china', position='Query'),
  tagNames?: string(name='TagNames', description='The reserved parameter.', example='None', position='Query'),
  time: string(name='Time', description='The time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1642953600000', position='Query'),
  type: string(name='Type', description='The type of instances that you want to query. Valid values:

*   **RED**: the best-performing instances
*   **BLACK**: the worst-performing instances', example='RED', position='Query'),
}

model GetQueryOptimizeDataTopResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    extra?: string(name='Extra', description='The reserved parameter.', example='None'),
    list?: [ 
      {
        instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****'),
        type?: string(name='Type', description='The metric name. Valid values:

* **sqlExecuteCount**: the number of slow SQL executions.
* **optimizedSqlExecuteCount**: the number of slow SQL executions that need to be optimized.', example='sqlExecuteCount'),
        value?: double(name='Value', description='The metric value.', example='100'),
      }
    ](name='List', description='The information about the instances.'),
    pageNo?: int32(name='PageNo', description='The reserved parameter.', example='None'),
    pageSize?: int32(name='PageSize', description='The reserved parameter.', example='None'),
    total?: long(name='Total', description='The total number of entries returned.', example='10'),
  }(name='Data', description='The detailed information.'),
  message?: string(name='Message', description='The returned message.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model GetQueryOptimizeDataTopResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetQueryOptimizeDataTopResponseBody(name='body'),
}

/**
  * *   If you use an Alibaba Cloud SDK, make sure that the aliyun-sdk-core version is later than V2.1.8. We recommend that you use the latest version.
  * *   The version of your Database Autonomy Service (DAS) SDK must be V2.1.8 or later.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   PolarDB for MySQL
  *     *   ApsaraDB RDS for PostgreSQL
  *
 */
async function getQueryOptimizeDataTop(request: GetQueryOptimizeDataTopRequest): GetQueryOptimizeDataTopResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetQueryOptimizeDataTop', 'GET', '/', 'json', false, 'json', request);
}

model GetQueryOptimizeDataTrendRequest {
  end: string(name='End', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The end time must be later than the start time, but not later than 00:00:00 (UTC+8) on the current day.', example='1643040000000', position='Query'),
  engine: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**
*   **PolarDBMySQL**
*   **PostgreSQL**', example='MySQL', position='Query'),
  instanceIds?: string(name='InstanceIds', description='The instance IDs. Separate multiple IDs with commas (,).', example='rm-2ze8g2am97624****', position='Query'),
  region?: string(name='Region', description='The region in which the instance resides. Valid values:

*   **cn-china**: Chinese mainland.
*   **cn-hongkong**: China (Hong Kong).
*   **ap-southeast-1**: Singapore.

This parameter takes effect only if **InstanceIds** is left empty. If you leave **InstanceIds** empty, the system obtains data from the region specified by **Region**. By default, Region is set to **cn-china**. If you specify **InstanceIds**, **Region** does not take effect and the system obtains data from the region in which the first specified instance resides.****

>  If your instances reside in the regions inside the Chinese mainland, set this parameter to **cn-china**.', example='cn-china', position='Query'),
  start: string(name='Start', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  You can specify a start time up to two months earlier than the current time.', example='1642435200000', position='Query'),
  tagNames?: string(name='TagNames', description='The reserved parameter.', example='None', position='Query'),
}

model GetQueryOptimizeDataTrendResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    extra?: string(name='Extra', description='The reserved parameter.', example='None'),
    list?: [ 
      {
        kpi?: string(name='Kpi', description='The name of the metric. Valid values:

* **sqlExecuteCount**: the number of executions of slow SQL queries.
* **sqlExecuteCountDiff**: the difference in the number of executions of slow SQL queries compared to the previous day.
* **sqlCount**: the number of slow SQL templates.
* **sqlCountDiff**: the difference in the number of slow SQL templates compared to the previous day.
* **optimizedSqlExecuteCount**: the number of optimizable executions of slow SQL queries.
* **optimizedSqlExecuteCountDiff**: the difference in the number of optimizable executions of slow SQL queries compared to the previous day.
* **optimizedSqlCount**: the number of optimizable slow SQL templates.
* **optimizedSqlCountDiff**: the difference in the number of optimizable slow SQL templates compared to the previous day.', example='sqlExecuteCount'),
        timestamp?: long(name='Timestamp', description='The data timestamp. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1643040000000'),
        value?: double(name='Value', description='The value of the metric.', example='1000'),
      }
    ](name='List', description='The details of the trend data.'),
    pageNo?: int32(name='PageNo', description='The reserved parameter.', example='None'),
    pageSize?: int32(name='PageSize', description='The reserved parameter.', example='None'),
    total?: long(name='Total', description='The total number of entries returned.', example='10'),
  }(name='Data', description='The detailed information.'),
  message?: string(name='Message', description='The returned message.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetQueryOptimizeDataTrendResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetQueryOptimizeDataTrendResponseBody(name='body'),
}

/**
  * *   If you use Alibaba Cloud SDK, make sure that the aliyun-sdk-core version is later than V2.1.8. We recommend that you use the latest version.
  * *   The version of your Database Autonomy Service (DAS) SDK must be V2.1.8 or later.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   PolarDB for MySQL
  *     *   ApsaraDB RDS for PostgreSQL
  *
 */
async function getQueryOptimizeDataTrend(request: GetQueryOptimizeDataTrendRequest): GetQueryOptimizeDataTrendResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetQueryOptimizeDataTrend', 'GET', '/', 'json', false, 'json', request);
}

model GetQueryOptimizeExecErrorSampleRequest {
  engine: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**
*   **PolarDBMySQL**
*   **PostgreSQL**', example='MySQL', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  sqlId: string(name='SqlId', description='The SQL template ID. You can call the [GetQueryOptimizeExecErrorStats](~~405235~~) operation to obtain the SQL template ID.', example='2e8147b5ca2dfc640dfd5e43d96a****', position='Query'),
  time: string(name='Time', description='The date to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1642953600000', position='Query'),
}

model GetQueryOptimizeExecErrorSampleResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    extra?: string(name='Extra', description='A reserved parameter.', example='None'),
    list?: [ 
      {
        dbname?: string(name='Dbname', description='The name of the database.', example='testdb01'),
        errorCode?: string(name='ErrorCode', description='The error code returned.', example='1146'),
        origHost?: string(name='OrigHost', description='The IP address of the client that executes the SQL statement.', example='100.104.XX.XX'),
        sqlId?: string(name='SqlId', description='The SQL template ID.', example='2e8147b5ca2dfc640dfd5e43d96a****'),
        sqlText?: string(name='SqlText', description='The content of the SQL statement that failed to be executed.', example='select * from test1'),
        timestamp?: long(name='Timestamp', description='The point in time when the failed SQL statement was executed. The value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1643020306739'),
        user?: string(name='User', description='The username of the client that executes the SQL statement.', example='test01'),
      }
    ](name='List', description='The queried data.'),
    pageNo?: int32(name='PageNo', description='A reserved parameter.', example='None'),
    pageSize?: int32(name='PageSize', description='A reserved parameter.', example='None'),
    total?: long(name='Total', description='The total number of entries returned.', example='2'),
  }(name='Data', description='The detailed information.'),
  message?: string(name='Message', description='The returned message.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetQueryOptimizeExecErrorSampleResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetQueryOptimizeExecErrorSampleResponseBody(name='body'),
}

/**
  * *   If you use Alibaba Cloud SDK, make sure that the aliyun-sdk-core version is later than V2.1.8. We recommend that you use the latest version.
  * *   The version of your Database Autonomy Service (DAS) SDK must be V2.1.8 or later.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   PolarDB for MySQL
  *     *   ApsaraDB RDS for PostgreSQL
  *
 */
async function getQueryOptimizeExecErrorSample(request: GetQueryOptimizeExecErrorSampleRequest): GetQueryOptimizeExecErrorSampleResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetQueryOptimizeExecErrorSample', 'GET', '/', 'json', false, 'json', request);
}

model GetQueryOptimizeExecErrorStatsRequest {
  asc?: string(name='Asc', description='Specifies whether to sort the returned entries in ascending order. Default value: **true**. Valid values:

*   **true**: sorts the returned entries in ascending order.
*   **false**: does not sort the returned entries in ascending order.', example='true', position='Query'),
  dbNames?: string(name='DbNames', description='The name of the database to be queried.', example='testdb01', position='Query'),
  engine: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**
*   **PolarDBMySQL**
*   **PostgreSQL**', example='MySQL', position='Query'),
  instanceIds?: string(name='InstanceIds', description='The instance IDs. Separate multiple IDs with commas (,).', example='rm-2ze8g2am97624****', position='Query'),
  keywords?: string(name='Keywords', description='The keywords of the SQL template. Separate multiple keywords with spaces.', example='select update', position='Query'),
  logicalOperator?: string(name='LogicalOperator', description='The logical relationship between multiple keywords. Valid values:

*   **or**
*   **and**', example='or', position='Query'),
  orderBy?: string(name='OrderBy', description='The field by which to sort the returned entries. Only error_count is supported, which specifies that the entries are sorted based on the number of failed executions.', example='error_count', position='Query'),
  pageNo: string(name='PageNo', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize: string(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  region?: string(name='Region', description='The region in which the instance resides. Valid values:

*   **cn-china**: Chinese mainland
*   **cn-hongkong**: China (Hong Kong)
*   **ap-southeast-1**: Singapore

This parameter takes effect only if **InstanceIds** is left empty. If you leave **InstanceIds** empty, the system obtains data from the region set by **Region**. By default, Region is set to **cn-china**. If you specify **InstanceIds**, **Region** does not take effect and the system obtains data from the region in which the first specified instance resides.****

>  Set this parameter to **cn-china** for the instances that are created in the regions in the Chinese mainland.', example='cn-china', position='Query'),
  time: string(name='Time', description='The time range to query. Specify the time in the UNIX timestamp format. Unit: milliseconds.', example='1642953600000', position='Query'),
}

model GetQueryOptimizeExecErrorStatsResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    extra?: string(name='Extra', description='The reserved parameter.', example='None'),
    list?: [ 
      {
        dbname?: string(name='Dbname', description='The name of the database.', example='testdb01'),
        errorCode?: string(name='ErrorCode', description='The error code returned if the request failed.', example='1146'),
        errorCount?: long(name='ErrorCount', description='The number of errors.', example='10'),
        instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****'),
        instanceName?: string(name='InstanceName', description='The alias of the database instance.', example='test01'),
        sqlId?: string(name='SqlId', description='The SQL template ID.', example='2e8147b5ca2dfc640dfd5e43d96a****'),
        sqlText?: string(name='SqlText', description='The content of the SQL template.', example='select * from test1'),
      }
    ](name='List', description='The information about the SQL templates that failed to execute.'),
    pageNo?: int32(name='PageNo', description='The page number.', example='1'),
    pageSize?: int32(name='PageSize', description='The number of entries per page.', example='10'),
    total?: long(name='Total', description='The total number of entries returned.', example='19'),
  }(name='Data', description='The detailed information, including the error codes and the number of entries that are returned.'),
  message?: string(name='Message', description='The returned message.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model GetQueryOptimizeExecErrorStatsResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetQueryOptimizeExecErrorStatsResponseBody(name='body'),
}

/**
  * *   If you use Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   PolarDB for MySQL
  *     *   ApsaraDB RDS for PostgreSQL
  *
 */
async function getQueryOptimizeExecErrorStats(request: GetQueryOptimizeExecErrorStatsRequest): GetQueryOptimizeExecErrorStatsResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetQueryOptimizeExecErrorStats', 'GET', '/', 'json', false, 'json', request);
}

model GetQueryOptimizeRuleListRequest {
  engine: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**
*   **PolarDBMySQL**
*   **PostgreSQL**', example='MySQL', position='Query'),
  instanceIds?: string(name='InstanceIds', description='The instance IDs. Separate multiple IDs with commas (,).', example='rm-2ze8g2am97624****', position='Query'),
  region?: string(name='Region', description='The region in which the instance resides. Valid values:

*   **cn-china**: Chinese mainland
*   **cn-hongkong**: China (Hong Kong)
*   **ap-southeast-1**: Singapore

This parameter takes effect only if **InstanceIds** is left empty. If you leave **InstanceIds** empty, the system obtains data from the region set by **Region**. By default, Region is set to **cn-china**. If you specify **InstanceIds**, **Region** does not take effect and the system obtains data from the region in which the first specified instance resides.****

>  If your instances reside in the regions in the Chinese mainland, set this parameter to **cn-china**.', example='cn-china', position='Query'),
  tagNames?: string(name='TagNames', description='A reserved parameter.', example='None', position='Query'),
}

model GetQueryOptimizeRuleListResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    extra?: string(name='Extra', description='A reserved parameter.', example='None'),
    list?: [ 
      {
        name?: string(name='Name', description='The name of the tag.', example='LARGE_ROWS_EXAMINED'),
        ruleId?: string(name='RuleId', description='A reserved parameter.', example='None'),
        type?: string(name='Type', description='The type of the tag. **Predefined** is returned, which indicates that the tag is added by the system.', example='Predefined'),
      }
    ](name='List', description='The information about tags.'),
    pageNo?: int32(name='PageNo', description='A reserved parameter.', example='None'),
    pageSize?: int32(name='PageSize', description='A reserved parameter.', example='None'),
    total?: long(name='Total', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The detailed information.'),
  message?: string(name='Message', description='The returned message.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetQueryOptimizeRuleListResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetQueryOptimizeRuleListResponseBody(name='body'),
}

/**
  * *   If you use Alibaba Cloud SDK, make sure that the aliyun-sdk-core version is later than V2.1.8. We recommend that you use the latest version.
  * *   The version of your Database Autonomy Service (DAS) SDK must be V2.1.8 or later.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   PolarDB for MySQL
  *     *   ApsaraDB RDS for PostgreSQL
  *
 */
async function getQueryOptimizeRuleList(request: GetQueryOptimizeRuleListRequest): GetQueryOptimizeRuleListResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetQueryOptimizeRuleList', 'GET', '/', 'json', false, 'json', request);
}

model GetQueryOptimizeShareUrlRequest {
  asc?: boolean(name='Asc', description='Specifies whether to sort the returned entries in ascending order. Default value: **true**. Valid values:

*   **true**
*   **false**', example='true', position='Query'),
  dbNames?: string(name='DbNames', description='The name of the database to be queried.', example='testdb01', position='Query'),
  engine: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**: ApsaraDB RDS for MySQL
*   **PolarDBMySQL**: PolarDB for MySQL
*   **PostgreSQL**: ApsaraDB RDS for PostgreSQL', example='MySQL', position='Query'),
  instanceIds?: string(name='InstanceIds', description='The instance IDs. Separate multiple IDs with commas (,).', example='rm-2ze1jdv45i7l6****', position='Query'),
  keywords?: string(name='Keywords', description='The keywords of the SQL template. Separate multiple keywords with spaces.', example='select update', position='Query'),
  logicalOperator?: string(name='LogicalOperator', description='The logical relationship between multiple keywords. Valid values:

*   **or**
*   **and**', example='or', position='Query'),
  onlyOptimizedSql?: boolean(name='OnlyOptimizedSql', description='Specifies whether to query only SQL templates that need to be optimized. Default value: **false**. Valid values:

*   **true**
*   **false**', example='true', position='Query'),
  orderBy?: string(name='OrderBy', description='The field by which to sort the returned entries. Default value: **count**. Valid values:

*   **count**: the number of executions.
*   **maxQueryTime**: the longest execution duration.
*   **avgQueryTime**: the average execution duration.
*   **maxLockTime**: the longest lock wait duration.
*   **avgLockTime**: the average lock wait duration.
*   **maxRowsExamined**: the largest number of scanned rows.
*   **avgRowsExamined**: the average number of scanned rows.
*   **maxRowsSent**: the largest number of returned rows.
*   **avgRowsSent**: the average number of returned rows.', example='count', position='Query'),
  pageNo?: int32(name='PageNo', description='The page number. Pages start from page 1. Default value: 1.', example='1', position='Query'),
  pageSize?: int32(name='PageSize', description='The number of entries per page. Default value: 10.', example='10', position='Query'),
  region?: string(name='Region', description='The region in which the instance resides. Valid values:

*   **cn-china**: Chinese mainland
*   **cn-hongkong**: China (Hong Kong)
*   **ap-southeast-1**: Singapore

This parameter takes effect only if **InstanceIds** is left empty. If you leave **InstanceIds** empty, the system obtains data from the region set by **Region**. By default, Region is set to **cn-china**. If you specify **InstanceIds**, **Region** does not take effect and the system obtains data from the region in which the first specified instance resides.****

>  If your instances reside in the regions in the Chinese mainland, set this parameter to **cn-china**.', example='cn-china', position='Query'),
  rules?: string(name='Rules', description='The tags that are used to filter SQL templates. Separate multiple tags with commas (,). For more information, see [Query governance](~~290038~~).', example='DAS_NOT_IMPORTANT', position='Query'),
  sqlIds?: string(name='SqlIds', description='The SQL template IDs. You can call the [GetQueryOptimizeExecErrorStats](~~405261~~) operation to obtain the SQL template IDs.', example='6068ce044e3dc9b903979672fb0b69df,d12515c015fc9f41a0778a9e1de0****', position='Query'),
  tagNames?: string(name='TagNames', description='A reserved parameter.', example='None', position='Query'),
  time: long(name='Time', description='The date to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1642953600000', position='Query'),
  user?: string(name='User', description='The account of the database to be queried.', example='testUser', position='Query'),
}

model GetQueryOptimizeShareUrlResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The share URL.', example='https://hdm.console.aliyun.com/#/queryOptimize?Keywords=&OnlyOptimizedSql=true&Time=1684771200000&Engine=MySQL&InstanceIds=&Rules=&PageNo=1&PageSize=10&OrderBy=count&Asc=false&SqlIds=&dbNames=&region=cn-china&user='),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message that contains information such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetQueryOptimizeShareUrlResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetQueryOptimizeShareUrlResponseBody(name='body'),
}

/**
  * *   If you use Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   PolarDB for MySQL
  *     *   ApsaraDB RDS for PostgreSQL
  *
 */
async function getQueryOptimizeShareUrl(request: GetQueryOptimizeShareUrlRequest): GetQueryOptimizeShareUrlResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetQueryOptimizeShareUrl', 'GET', '/', 'json', false, 'json', request);
}

model GetQueryOptimizeSolutionRequest {
  engine: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**
*   **PolarDBMySQL**
*   **PostgreSQL**', example='MySQL', position='Query'),
  instanceId?: string(name='InstanceId', description='The instance ID. You can call the [GetQueryOptimizeDataStats](~~405261~~) operation to query the instance ID.', example='rm-bp1o3z6beqpej****', position='Query'),
  ruleIds: string(name='RuleIds', description='The tag ID. For more information, see [Query governance](~~290038~~).', example='LARGE_ROWS_EXAMINED', position='Query'),
  sqlId: string(name='SqlId', description='The SQL template ID. You can call the [GetQueryOptimizeDataStats](~~405261~~) operation to query the SQL template ID.', example='05fecf7e7b3efd123c4d5197035f****', position='Query'),
}

model GetQueryOptimizeSolutionResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    extra?: string(name='Extra', description='The reserved parameter.', example='None'),
    list?: [ 
      {
        level?: string(name='Level', description='The severity level. Valid values:

* **INFO**
* **WARN**', example='INFO'),
        ruleId?: string(name='RuleId', description='The tag ID.', example='LARGE_ROWS_EXAMINED'),
        solution?: string(name='Solution', description='The suggestion.', example='LARGE_ROWS_EXAMINED_SOLUTION'),
        solutionExt?: string(name='SolutionExt', description='The reserved parameter.', example='None'),
      }
    ](name='List', description='The optimization suggestions.'),
    pageNo?: int32(name='PageNo', description='The reserved parameter.', example='None'),
    pageSize?: int32(name='PageSize', description='The reserved parameter.', example='None'),
    total?: long(name='Total', description='The total number of entries returned.', example='1'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='30FF4E40-17F3-5A51-AB23-43F30D9B****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetQueryOptimizeSolutionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetQueryOptimizeSolutionResponseBody(name='body'),
}

/**
  * *   If you use an Alibaba Cloud SDK or a Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   PolarDB for MySQL
  *     *   ApsaraDB RDS for PostgreSQL
  *
 */
async function getQueryOptimizeSolution(request: GetQueryOptimizeSolutionRequest): GetQueryOptimizeSolutionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetQueryOptimizeSolution', 'GET', '/', 'json', false, 'json', request);
}

model GetQueryOptimizeTagRequest {
  engine: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**: ApsaraDB RDS for MySQL
*   **PolarDBMySQL**: PolarDB for MySQL
*   **PostgreSQL**: ApsaraDB RDS for PostgreSQL', example='MySQL', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  sqlId: string(name='SqlId', description='The SQL template ID. You can call the [GetQueryOptimizeDataStats](~~405261~~) operation to query the SQL template ID.', example='29d9fef63e347d39c3436658a5fe5f2b', position='Query'),
}

model GetQueryOptimizeTagResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    comments?: string(name='Comments', description='The remarks.', example='Slow SQL queries of offline synchronization. No optimization is required.'),
    sqlId?: string(name='SqlId', description='The SQL template ID.', example='651b56fe9418d48edb8fdf0980ec****'),
    tags?: string(name='Tags', description='The SQL tags. Multiple tags are separated by commas (,).', example='DAS_IN_PLAN,DAS_NOT_IMPORTANT'),
  }(name='Data', description='The returned SQL tag data.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetQueryOptimizeTagResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetQueryOptimizeTagResponseBody(name='body'),
}

/**
  * *   If you use Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   PolarDB for MySQL
  *     *   ApsaraDB RDS for PostgreSQL
  *
 */
async function getQueryOptimizeTag(request: GetQueryOptimizeTagRequest): GetQueryOptimizeTagResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetQueryOptimizeTag', 'GET', '/', 'json', false, 'json', request);
}

model GetRedisAllSessionRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceId: string(name='InstanceId', description='The database instance ID.', example='r-2zemyfd1sh1u2i****', position='Query'),
}

model GetRedisAllSessionResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    sessions?: [ 
      {
        addr?: string(name='Addr', description='The IP address and port number of the client.', example='172.16.XX.XX:53458'),
        age?: string(name='Age', description='The connection duration of the session. Unit: seconds.', example='12'),
        client?: string(name='Client', description='The IP address of the client.', example='172.16.XX.XX'),
        clientDesc?: string(name='ClientDesc', description='The alias of the client.', example='prod ip'),
        cmd?: string(name='Cmd', description='The command that was last run.', example='PING'),
        db?: long(name='Db', description='The ID of the database that the client is using.', example='0'),
        events?: string(name='Events', description='The file descriptor event. Valid values:

*   **r**: Client sockets are readable in the event loop.
*   **w**: Client sockets are writable in the event loop.', example='r'),
        fd?: long(name='Fd', description='The file descriptor that is used by sockets.', example='73'),
        flags?: string(name='Flags', description='The client flag. Valid values:

*   **A**: The connection needs to be closed at the earliest opportunity.
*   **b**: The client is waiting for blocked events.
*   **c**: The connection is closed after all replies are written.
*   **d**: The monitored keys have been modified, and the `EXEC` command is about to fail.
*   **i**: The client is waiting for VM I/O operations. This value is no longer used.
*   **M**: The client is the primary node.
*   **N**: No special flags are configured.
*   **O**: The client is in monitor mode.
*   **r**: The client is a cluster node in read-only mode.
*   **S**: The client is a replica node in normal mode.
*   **u**: The client is not blocked.
*   **U**: The client is connected by using UNIX domain sockets.
*   **x**: The client is executing a transaction.', example='N'),
        id?: long(name='Id', description='The client ID.', example='9080586'),
        idle?: long(name='Idle', description='The duration during which the session is in the idle state. Unit: seconds.', example='8'),
        multi?: long(name='Multi', description='The number of commands in `MULTI` or `EXEC`.', example='-1'),
        name?: string(name='Name', description='The name of the client.', example='test'),
        nodeId?: string(name='NodeId', description='The node ID.', example='r-2zemyfd1sh1u2i****-proxy-14#1679****'),
        obl?: long(name='Obl', description='The size of the fixed output buffer. Unit: bytes.', example='0'),
        oll?: long(name='Oll', description='The number of objects contained in the output list.', example='0'),
        omem?: long(name='Omem', description='The size of the output buffer. Unit: bytes.', example='0'),
        psub?: long(name='Psub', description='The number of subscriptions that match the pattern.', example='0'),
        qbuf?: long(name='Qbuf', description='The size of the input buffer. Unit: bytes.', example='0'),
        qbufFree?: long(name='QbufFree', description='The remaining size of the input buffer. Unit: bytes.', example='0'),
        sub?: long(name='Sub', description='The number of subscribed channels.', example='0'),
      }
    ](name='Sessions', description='The information about the sessions.'),
    sourceStats?: [ 
      {
        count?: string(name='Count', description='The total number of sessions from the access source.', example='1'),
        ids?: [ long ](name='Ids', description='The client IDs.'),
        key?: string(name='Key', description='The access source.', example='172.16.XX.XX'),
      }
    ](name='SourceStats', description='The statistics on the access source.'),
    timestamp?: long(name='Timestamp', description='The time when the instance sessions were returned. The value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1660100753556'),
    total?: long(name='Total', description='The total number of sessions.', example='2'),
  }(name='Data', description='The session data.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='40C6E9AF-6C23-5614-AA83-34344CC6****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetRedisAllSessionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetRedisAllSessionResponseBody(name='body'),
}

/**
  * *   This operation is applicable only to ApsaraDB for Redis instances.
  * *   If you use an SDK to call operations of Database Autonomy Service (DAS), you must set the region ID to cn-shanghai.
  * >  This operation cannot be used to query sessions generated in direct connection mode on ApsaraDB for Redis cluster instances.
  *
 */
async function getRedisAllSession(request: GetRedisAllSessionRequest): GetRedisAllSessionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetRedisAllSession', 'POST', '/', 'json', false, 'json', request);
}

model GetRequestDiagnosisPageRequest {
  endTime: long(name='EndTime', description='The end of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1634972640000', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-0iwhhl8gx0ld6****', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  You must specify the node ID if your database instance is a PolarDB for MySQL, PolarDB for PostgreSQL (Compatible with Oracle), or ApsaraDB for MongoDB instance.', example='202****', position='Query'),
  pageNo: int32(name='PageNo', description='The page number. The value must be a positive integer. Default value: 1.', example='1', position='Query'),
  pageSize: int32(name='PageSize', description='The number of entries per page. The value must be a positive integer. Default value: 10.', example='10', position='Query'),
  startTime: long(name='StartTime', description='The beginning of the time range to query. Set this parameter to a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1633071840000', position='Query'),
}

model GetRequestDiagnosisPageResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    extra?: string(name='extra', description='Additional information.', example='{"":""}'),
    list?: [ 
      {
        accountId?: string(name='accountId', description='The user ID.', example='2093****'),
        dbSchema?: string(name='dbSchema', description='The name of the database.', example='das'),
        engine?: string(name='engine', description='The database engine. Valid values:

* **MySQL**
* **PostgreSQL**
* **SQLServer**
* **PolarDBMySQL**
* **PolarDBOracle**
* **MongoDB**', example='MySQL'),
        gmtCreate?: string(name='gmtCreate', description='The time when the SQL diagnostics task was created. The value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1633071840000'),
        gmtModified?: string(name='gmtModified', description='The time when the SQL diagnostics task was modified. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1633071850000'),
        messageId?: string(name='messageId', description='The unique ID of the diagnostics task.', example='61820b594664275c4429****'),
        param?: string(name='param', description='Additional information.', example='{"":""}'),
        result?: string(name='result', description='The result of the SQL diagnostics task. The result includes the following information:

* **endTime**: the end time of the SQL diagnostics task.
* **errorCode**: indicates whether the SQL diagnostics task is complete. Valid values:
  * **0001**: The SQL diagnostics task is complete.
  * **0003**: The SQL diagnostics task failed.

* **errorMessage**: the error message.
* **estimateCost**: the estimated cost.
  * **cpu**: the estimated CPU utilization of the index.
  * **io**: the estimated I/O usage of the index.
  * **rows**: the estimated values of the rows returned for the index.
* **improvement**: the performance improvement ratio.
* **indexAdvices**: the index recommendations, which include the following information:
  * **columns**: the index columns.
  * **ddlAddIndex**: the DDL statement for the index.
  * **indexName**: the name of the index.
  * **schemaName**: the name of the database.
  * **tableName**: the name of the table.
  * **unique**: indicates whether the index is unique.

* **ip**: the IP address of the instance.
* **messageId**: the ID of the diagnostics task.
* **port**: the port used to connect to the instance.
* **sqlTag**: the SQL tag.
* **startTime**: the start time of the SQL diagnostics task.
* **success**: indicates whether the request was successful.
* **support**: indicates whether the SQL statement can be diagnosed. Valid values:
  * **true**: The SQL statement can be diagnosed.
  * **false**: The SQL statement cannot be diagnosed.

* **tuningAdvices**: the SQL rewrite suggestions.', example='{ "endTime":1636354256000, "errorCode":"0001", "errorMessage":"TFX Successful", "estimateCost":{ "cpu":1.7878745150389268, "io":9.948402604746128, "rows":8.889372575194633 }, "improvement":12933.97, "indexAdvices":[ { "columns":[ "work_no" ], "ddlAddIndex":"ALTER TABLE `test`.`work_order` ADD INDEX `idx_workno` (`work_no`)", "indexName":"idx_workno", "schemaName":"test", "tableName":"work_order", "unique":false } ], "ip":"****.mysql.rds.aliyuncs.com", "messageId":"6188c8cb2f1365b16aee****", "port":3306, "sqlTag":"{\\"PRED_EQUAL\\":\\"Y\\",\\"CNT_QB\\":\\"1\\",\\"CNT_TB\\":\\"1\\"}", "startTime":1636354252000, "success":true, "support":true, "tuningAdvices":[ ] }'),
        sqlId?: string(name='sqlId', description='The SQL template ID.', example='0c95dae3afef77be06572612df9b****'),
        state?: int32(name='state', description='The status of the diagnostics task. Valid values:

* **0**: The diagnostics task is in progress.

* **1**: A diagnostics error occurred.

* **2**: The diagnostics task is complete.

* **3**: An SQL error occurred.

* **4**: An engine error occurred.', example='2'),
        uuid?: string(name='uuid', description='The unique ID of the diagnostics instance.', example='hdm_51fe9bc19ec413f4d530431af87a****'),
      }
    ](name='list', description='The SQL diagnostics records returned.'),
    pageNo?: long(name='pageNo', description='The page number. The value must be a positive integer. Default value: 1.', example='1'),
    pageSize?: long(name='pageSize', description='The number of entries per page. The value must be a positive integer. Default value: 10.', example='10'),
    total?: long(name='total', description='The total number of returned entries.', example='100'),
  }(name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message that contains information such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='800FBAF5-A539-5B97-A09E-C63AB2F7****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetRequestDiagnosisPageResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetRequestDiagnosisPageResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an SDK to call API operations of Database Autonomy Service (DAS), you must set the region ID to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   ApsaraDB RDS for PostgreSQL
  *     *   ApsaraDB RDS for SQL Server
  *     *   PolarDB for MySQL
  *     *   PolarDB for PostgreSQL (Compatible with Oracle)
  *     *   ApsaraDB for MongoDB
  * >  The minor engine version of the Apsara RDS for PostgreSQL instance must be 20220130 or later. For more information about how to check and update the minor engine version of an ApsaraDB RDS for PostgreSQL instance, see [Update the minor engine version of an ApsaraDB RDS for PostgreSQL instance](~~146895~~).
  *
 */
async function getRequestDiagnosisPage(request: GetRequestDiagnosisPageRequest): GetRequestDiagnosisPageResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetRequestDiagnosisPage', 'POST', '/', 'json', false, 'json', request);
}

model GetRequestDiagnosisResultRequest {
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-0iwhhl8gx0ld6****', position='Query'),
  messageId: string(name='MessageId', description='The unique ID of the diagnostics task. You can call the [CreateRequestDiagnosis](~~341609~~) operation to query the diagnostics task ID.', example='61820b594664275c4429****', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  You must specify the node ID if your database instance is a PolarDB for MySQL cluster, a PolarDB for PostgreSQL (compatible with Oracle) instance, or an ApsaraDB for MongoDB database.', example='202****', position='Query'),
  source?: string(name='Source', description='The source of the task.

>  This parameter is required if you call this operation in the DAS console. You do not need to specify this parameter when you call this operation.', example='None', position='Query'),
  sqlId?: string(name='SqlId', description='The SQL template ID.

>  This parameter is required if you call this operation in the DAS console. You do not need to specify this parameter when you call this operation.', example='None', position='Query'),
}

model GetRequestDiagnosisResultResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    accountId?: string(name='accountId', description='The user ID.', example='2093****'),
    dbSchema?: string(name='dbSchema', description='The name of the database.', example='das'),
    engine?: string(name='engine', description='The database engine. Valid values:

*   **MySQL**
*   **PostgreSQL**
*   **SQLServer**
*   **PolarDBMySQL**
*   **PolarDBOracle**
*   **MongoDB**', example='MySQL'),
    gmtCreate?: string(name='gmtCreate', description='The time when the SQL diagnostics task was created. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1633071840000'),
    gmtModified?: string(name='gmtModified', description='The time when the SQL diagnostics task was modified. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1633071850000'),
    messageId?: string(name='messageId', description='The unique ID of the diagnostics task.', example='61820b594664275c4429****'),
    param?: string(name='param', description='The additional information.', example='{"":""}'),
    result?: string(name='result', description='The result of the SQL diagnostics task. The result includes the following information:

*   **endTime**: the end time of the SQL diagnostics task.

*   **errorCode**: the error code.

    *   **0001**: The SQL diagnostics task is complete.
    *   **0003**: The SQL diagnostics task failed.

*   **errorMessage**: the error message.

*   **estimateCost**: the estimated cost.

    *   **cpu**: the estimated CPU utilization of the index.
    *   **io**: the estimated I/O usage of the index.
    *   **rows**: the estimated values of the rows returned for the index.

*   **improvement**: the performance improvement ratio.

*   **indexAdvices**: the index recommendations, which include the following information:

    *   **columns**: the index columns.
    *   **ddlAddIndex**: the DDL statement for the index.
    *   **indexName**: the name of the index.
    *   **schemaName**: the name of the database.
    *   **tableName**: the name of the table.
    *   **unique**: indicates whether the index is unique.

*   **ip**: the IP address of the instance.

*   **messageId**: the ID of the diagnostics task.

*   **port**: the port used to connect to the instance.

*   **sqlTag**: the SQL tag.

*   **startTime**: the start time of the SQL diagnostics task.

*   **success**: indicates whether the request was successful.

*   **support**: indicates whether the SQL statement can be diagnosed. Valid values:

    *   **true**
    *   **false**

*   **tuningAdvices** : the SQL rewrite suggestions.', example='{ "endTime":1636354256000, "errorCode":"0001", "errorMessage":"TFX succeeded", "estimateCost":{ "cpu":1.7878745150389268, "io":9.948402604746128, "rows":8.889372575194633 }, "improvement":12933.97, "indexAdvices":[ { "columns":[ "work_no" ], "ddlAddIndex":"ALTER TABLE `test`.`work_order` ADD INDEX `idx_workno` (`work_no`)", "indexName":"idx_workno", "schemaName":"test", "tableName":"work_order", "unique":false } ], "ip":"****.mysql.rds.aliyuncs.com", "messageId":"6188c8cb2f1365b16aee****", "port":3306, "sqlTag":"{\\"PRED_EQUAL\\":\\"Y\\",\\"CNT_QB\\":\\"1\\",\\"CNT_TB\\":\\"1\\"}", "startTime":1636354252000, "success":true, "support":true, "tuningAdvices":[ ] }'),
    sqlId?: string(name='sqlId', description='The SQL template ID.', example='0c95dae3afef77be06572612df9b****'),
    state?: int32(name='state', description='The state of the diagnostics task. Valid values:

*   **0**: The diagnostics task is in progress.
*   **1**: A diagnostics error occurred.
*   **2**: The diagnostics task is complete.
*   **3**: An SQL error occurred.
*   **4**: An engine error occurred.', example='2'),
    uuid?: string(name='uuid', description='The unique ID of the diagnostics instance.', example='hdm_51fe9bc19ec413f4d530431af87a****'),
  }(name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='800FBAF5-A539-5B97-A09E-C63AB2F7****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetRequestDiagnosisResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetRequestDiagnosisResultResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an SDK to call operations of Database Autonomy Service (DAS), you must set the region ID to cn-shanghai.
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL
  *     *   ApsaraDB RDS for PostgreSQL
  *     *   ApsaraDB RDS for SQL Server
  *     *   PolarDB for MySQL
  *     *   PolarDB for PostgreSQL (compatible with Oracle)
  *     *   ApsaraDB for MongoDB
  * >  The minor engine version of the Apsara RDS for PostgreSQL instance must be 20220130 or later. For more information about how to check and update the minor engine version of an ApsaraDB RDS for PostgreSQL instance, see [Update the minor engine version of an ApsaraDB RDS for PostgreSQL instance](~~146895~~).
  *
 */
async function getRequestDiagnosisResult(request: GetRequestDiagnosisResultRequest): GetRequestDiagnosisResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetRequestDiagnosisResult', 'POST', '/', 'json', false, 'json', request);
}

model GetRunningSqlConcurrencyControlRulesRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.

>  You must specify this parameter only if your database instance is an ApsaraDB RDS for MySQL instance or a PolarDB for MySQL cluster.', example='rm-2ze1jdv45i7l6****', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. The value must be a positive integer. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. The value must be a positive integer. Default value: 10.', example='10', position='Query'),
}

model GetRunningSqlConcurrencyControlRulesResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    list?: {
      runningRules?: [ 
      {
        concurrencyControlTime?: long(name='ConcurrencyControlTime', description='The duration within which the SQL throttling rule takes effect. Unit: seconds.

> The throttling rule takes effect only within this duration.', example='600'),
        instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-2ze1jdv45i7l6****'),
        itemId?: long(name='ItemId', description='The ID of the throttling rule that is applied to the instance.', example='16'),
        keywordsHash?: string(name='KeywordsHash', description='The hash value of the SQL keywords. The hash value is calculated based on the SQL keywords that are contained in the SQL statements to which the throttling rule is applied.', example='b0b8aceeb43baea87b219c81767b****'),
        maxConcurrency?: string(name='MaxConcurrency', description='The maximum number of concurrent SQL statements. The value is a positive integer.

> If the number of concurrent SQL statements that contain the specified keywords reaches this upper limit, the throttling rule is triggered.', example='2'),
        sqlKeywords?: string(name='SqlKeywords', description='The keywords contained in the SQL statements to which the throttling rule was applied.

> SQL keywords are separated by tildes (~). If the number of concurrent SQL statements that contain all the specified SQL keywords reaches the specified upper limit, the throttling rule is triggered.', example='call~open~api~test~4~from~POP'),
        sqlType?: string(name='SqlType', description='The type of the SQL statements. Valid values:

* **SELECT**
* **UPDATE**
* **DELETE**', example='SELECT'),
        startTime?: long(name='StartTime', description='The time when the throttling rule started to take effect. The value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1608888296000'),
        status?: string(name='Status', description='The status of the throttling rule. The value of **Open** indicates that the throttling rule is in effect.', example='Open'),
        userId?: string(name='UserId', description='The Alibaba Cloud account ID.', example='testxxx'),
      }
    ](name='runningRules')
    }(name='List', description='The returned data.'),
    total?: long(name='Total', description='The total number of entries returned.', example='2'),
  }(name='Data', description='The detailed information, including the error codes and the number of entries that are returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetRunningSqlConcurrencyControlRulesResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetRunningSqlConcurrencyControlRulesResponseBody(name='body'),
}

/**
  * This operation supports the following database engines:
  * *   ApsaraDB RDS for MySQL
  * *   PolarDB for MySQL
  *
 */
async function getRunningSqlConcurrencyControlRules(request: GetRunningSqlConcurrencyControlRulesRequest): GetRunningSqlConcurrencyControlRulesResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetRunningSqlConcurrencyControlRules', 'POST', '/', 'json', false, 'json', request);
}

model GetSqlConcurrencyControlKeywordsFromSqlTextRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze5hpn2b99d2****', position='Query'),
  sqlText: string(name='SqlText', description='The SQL statement based on which a throttling keyword string is to be generated.', example='SELECT * FROM test where name = \\"das\\"', position='Query'),
}

model GetSqlConcurrencyControlKeywordsFromSqlTextResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The throttling keyword string that was generated based on the SQL statement.', example='SELECT~FROM~test~where~name'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='30A643F5-D7A6-55F5-AB75-DF501427****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetSqlConcurrencyControlKeywordsFromSqlTextResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSqlConcurrencyControlKeywordsFromSqlTextResponseBody(name='body'),
}

/**
  * This operation supports the following database engines:
  * *   ApsaraDB RDS for MySQL
  * *   PolarDB for MySQL
  *
 */
async function getSqlConcurrencyControlKeywordsFromSqlText(request: GetSqlConcurrencyControlKeywordsFromSqlTextRequest): GetSqlConcurrencyControlKeywordsFromSqlTextResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSqlConcurrencyControlKeywordsFromSqlText', 'POST', '/', 'json', false, 'json', request);
}

model GetSqlConcurrencyControlRulesHistoryRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.

>  Only ApsaraDB RDS for MySQL instances and PolarDB for MySQL clusters are supported.', example='rm-2ze1jdv45i7l6****', position='Query'),
  pageNo?: long(name='PageNo', description='The page number. The value must be an integer that is greater than 0. Default value: 1.', example='1', position='Query'),
  pageSize?: long(name='PageSize', description='The number of entries per page. The value must be an integer that is greater than 0. Default value: 10.', example='10', position='Query'),
}

model GetSqlConcurrencyControlRulesHistoryResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    list?: {
      rules?: [ 
      {
        concurrencyControlTime?: long(name='ConcurrencyControlTime', description='The duration within which the SQL throttling rule takes effect. Unit: seconds.

>  The throttling rule takes effect only within this duration.', example='600'),
        instanceId?: string(name='InstanceId', description='The instance ID.', example='rm-2ze1jdv45i7l6****'),
        itemId?: long(name='ItemId', description='The ID of the throttling rule that is applied to the instance.', example='16'),
        keywordsHash?: string(name='KeywordsHash', description='The hash value of the SQL keywords. The SQL keywords are contained in the SQL statements to which the throttling rule is applied.', example='b0b8aceeb43baea87b219c81767b****'),
        maxConcurrency?: long(name='MaxConcurrency', description='The maximum number of concurrent SQL statements. Set this parameter to a positive integer.

>  When the number of concurrent SQL statements that contain the specified keywords reaches this upper limit, the throttling rule is triggered.', example='2'),
        sqlKeywords?: string(name='SqlKeywords', description='The keywords that are used to identify the SQL statements that need to be throttled.

> SQL keywords are separated with tildes (~). When the number of concurrent SQL statements that contain all the specified SQL keywords reaches the specified upper limit, the throttling rule is triggered.', example='call~open~api~test~4~from~POP'),
        sqlType?: string(name='SqlType', description='The type of the SQL statements. Valid values:

* **SELECT**
* **UPDATE**
* **DELETE**', example='SELECT'),
        startTime?: long(name='StartTime', description='The beginning of the time range to query. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1608888296000'),
        status?: string(name='Status', description='The state of the throttling rule. Valid values:

* **Open**: The throttling rule is in effect.
* **Closed**: The throttling rule was in effect.', example='Open'),
        userId?: string(name='UserId', description='The user ID.', example='testxxx'),
      }
    ](name='rules')
    }(name='List', description='The list of the queried throttling rules.'),
    total?: long(name='Total', description='The total number of entries returned.', example='4'),
  }(name='Data', description='The detailed information, including the error codes and the number of entries that are returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**: The request was successful.
*   **false**: The request failed.', example='true'),
}

model GetSqlConcurrencyControlRulesHistoryResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSqlConcurrencyControlRulesHistoryResponseBody(name='body'),
}

/**
  * This operation supports the following database engines:
  * *   ApsaraDB RDS for MySQL
  * *   PolarDB for MySQL
  *
 */
async function getSqlConcurrencyControlRulesHistory(request: GetSqlConcurrencyControlRulesHistoryRequest): GetSqlConcurrencyControlRulesHistoryResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSqlConcurrencyControlRulesHistory', 'POST', '/', 'json', false, 'json', request);
}

model GetSqlOptimizeAdviceRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  endDt?: string(name='EndDt', description='The end date of the time range to query. Specify the date in the *yyyyMMdd* format. The time must be in UTC.

*   The default value of this parameter is one day before the current day.
*   The value must be earlier than the current day. The interval between the start date and the end date cannot exceed 30 days.', example='20210917', position='Query'),
  engine?: string(name='Engine', description='The database engine. Valid values:

*   **MySQL**: ApsaraDB RDS for MySQL.
*   **PolarDBMySQL**: PolarDB for MySQL.', example='MySQL', position='Query'),
  instanceIds?: string(name='InstanceIds', description='The instance ID.

>  You must specify the instance ID only if your database instance is an ApsaraDB RDS for MySQL instance or a PolarDB for MySQL cluster.', example='rm-2ze1jdv45i7l6****', position='Query'),
  region?: string(name='Region', description='The region in which the instance resides. Valid values:

*   **cn-china**: Chinese mainland.
*   **cn-hongkong**: China (Hong Kong).
*   **ap-southeast-1**: Singapore.

This parameter takes effect only if **InstanceIds** is left empty. If you leave **InstanceIds** empty, the system obtains data from the region specified by **Region**. By default, Region is set to **cn-china**. If you specify **InstanceIds**, **Region** does not take effect, and the system obtains data from the region in which the first specified instance resides.****

>  If your instances reside in the regions inside the Chinese mainland, set this parameter to **cn-china**.', example='cn-china', position='Query'),
  startDt?: string(name='StartDt', description='The start date of the time range to query. Specify the date in the *yyyyMMdd* format. The time must be in UTC.

*   The default value of this parameter is one day before the current day.
*   The value must be earlier than the current day.', example='20210916', position='Query'),
}

model GetSqlOptimizeAdviceResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    createTime?: string(name='CreateTime', description='The time when the task was created. The value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1632303861000'),
    downloadUrl?: string(name='DownloadUrl', description='The URL that is used to download the file.', example='https://das-sql-optimize.oss-cn-shanghai.aliyuncs.com/adb/oss_sql_optimize_advice/1083*******'),
    expireTime?: string(name='ExpireTime', description='The time when the file expires. The value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.

>  The file expires three days after the task is created.', example='1632563061000'),
    status?: string(name='Status', description='The status of the task. Valid values:

*   **INIT**: The task is being initialized.
*   **RUNNING**: The task is running.
*   **FINISH**: The task is complete.
*   **FAILED**: The task failed.', example='FINISH'),
    statusCode?: string(name='StatusCode', description='The status code of the task. Valid values:

*   **NO_DATA**: No data is returned.
*   **INTERNAL_ERROR**: An internal error occurred.
*   **SUCCESS**: The task is successful.', example='SUCCESS'),
    taskId?: string(name='TaskId', description='The task ID.', example='2021091710461519216****'),
  }(name='Data', description='The detailed information, including the error codes and the number of entries that are returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, Successful is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetSqlOptimizeAdviceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetSqlOptimizeAdviceResponseBody(name='body'),
}

/**
  * The SQL diagnostics feature provides optimization suggestions for instances based on diagnostics results. You can use the optimization suggestions to optimize instance indexes. For more information, see [Automatic SQL optimization](~~167895~~).
  * >  You can call this operation to query only the optimization suggestions that are automatically generated by the SQL diagnostics feature.
  * Before you call this operation, take note of the following items:
  * *   This operation is applicable to ApsaraDB RDS for MySQL instances and PolarDB for MySQL clusters.
  * *   If you use an Alibaba Cloud SDK or DAS SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function getSqlOptimizeAdvice(request: GetSqlOptimizeAdviceRequest): GetSqlOptimizeAdviceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetSqlOptimizeAdvice', 'POST', '/', 'json', false, 'json', request);
}

model GetStorageAnalysisResultRequest {
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-bp10xxxxxxxxx', position='Query'),
  nodeId?: string(name='NodeId', description='The node ID.

>  This parameter is reserved.', example='202****', position='Query'),
  taskId: string(name='TaskId', description='The task ID. You can obtain the task ID from the response of the [CreateStorageAnalysisTask](~~2639140~~) operation.', example='910f83f4b96df0524ddc5749f615****', position='Query'),
}

model GetStorageAnalysisResultResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    analyzedDbCount?: long(name='AnalyzedDbCount', description='The number of databases that have been analyzed.', example='2'),
    storageAnalysisResult?: {
      analysisErrorType?: string(name='AnalysisErrorType', description='The reason why the analysis on the database and table fails.

*   **DB_OR_TABLE_NOT_EXIST**: The specified database or table does not exist.
*   **DB_NOT_EXIST**: The specified database does not exist.', example='DB_NOT_EXIST'),
      analysisSuccess?: boolean(name='AnalysisSuccess', description='Indicates whether the analysis on the database and table is successful.', example='true'),
      dailyIncrement?: long(name='DailyIncrement', description='The estimated average daily growth of the used storage space in the previous seven days. Unit: bytes.', example='0'),
      estimateAvailableDays?: long(name='EstimateAvailableDays', description='The estimated number of days for which the remaining storage space is available.', example='99'),
      needOptimizeItemList?: [ 
        {
          associatedData?: string(name='AssociatedData', description='The data associated with the items to be optimized, which is in the JSON format.', example='{
    "autoIncrementCurrentValue": 2147483647,
    "autoIncrementRatio": 1,
    "dbName": "testdb01",
    "maximumValue": 2147483647,
    "columnName": "id",
    "tableName": "test_table"
}'),
          dbName?: string(name='DbName', description='The name of the database.', example='testdb01'),
          optimizeAdvice?: string(name='OptimizeAdvice', description='The optimization suggestion. Valid values:

*   **NEED_ANALYZE_TABLE**: Execute the `ANALYZE TABLE` statement on the table during off-peak hours.
*   **NEED_OPTIMIZE_TABLE**: Reclaim space fragments during off-peak hours.
*   **CHANGE_TABLE_ENGINE_IF_NECESSARY**: Change the storage engine type of a table after risk assessment.
*   **AUTO_INCREMENT_ID_BE_TO_RUN_OUT**: Pay attention to the usage of auto-increment IDs.
*   **DUPLICATE_INDEX**: Optimize indexes of tables.
*   **TABLE_SIZE**: Pay attention to the table size.
*   **TABLE_ROWS_AND_AVG_ROW_LENGTH**: Pay attention to the number of rows in a table and the average row length.
*   **STORAGE_USED_PERCENT**: Pay attention to the space usage to prevent the instance from being locked if the instance is full.', example='NEED_OPTIMIZE_TABLE'),
          optimizeItemName?: string(name='OptimizeItemName', description='The item to be optimized. Valid values:

*   **NEED_ANALYZE_TABLE**: tables whose storage statistics obtained from `information_schema.tables` are 50 GB larger or smaller than the physical file sizes.
*   **NEED_OPTIMIZE_TABLE**: tables whose space fragments are larger than 6 GB and whose fragmentation rates are greater than 30%. The fragmentation rate of a table is generally calculated based on the following formula: `Fragmentation rate = DataFree/(DataSize + IndexSize + DataFree)`. In this topic, PhyTotalSize = DataSize + IndexSize + DataFree. Thus, the fragmentation rate can be calculated based on the following formula: `Fragmentation rate = DataFree/PhyTotalSize`.
*   **TABLE_ENGINE**: tables whose storage engines are not InnoDB or XEngine.
*   **AUTO_INCREMENT_ID_BE_TO_RUN_OUT**: tables whose usages of auto-increment IDs exceed 80%.
*   **DUPLICATE_INDEX**: tables whose indexes are redundant or duplicate.
*   **TABLE_SIZE**: single tables whose sizes are larger than 50 GB.
*   **TABLE_ROWS_AND_AVG_ROW_LENGTH**: single tables that contain more than 5 million rows and whose average row lengths exceed 10 KB.
*   **TOTAL_DATA_FREE**: instances whose reclaimable spaces are larger than 60 GB and whose total fragmentation rate is larger than 5%.
*   **STORAGE_USED_PERCENT**: instances whose space usage is larger than 90%.', example='NEED_OPTIMIZE_TABLE'),
          tableName?: string(name='TableName', description='The name of the table.', example='test_table'),
        }
      ](name='NeedOptimizeItemList', description='The items to be optimized, which are generated based on DAS default rules. You can ignore these items based on your business requirements, and create custom rules to generate items to be optimized based on other basic data that is returned.'),
      tableStats?: [ 
        {
          avgRowLength?: long(name='AvgRowLength', description='The average length of rows. Unit: bytes.', example='154'),
          dataFree?: long(name='DataFree', description='The size of space fragments. Unit: bytes.', example='7340032'),
          dataSize?: long(name='DataSize', description='The storage space occupied by data. Unit: bytes.', example='1982857216'),
          dbName?: string(name='DbName', description='The name of the database.', example='testdb01'),
          engine?: string(name='Engine', description='The type of the storage engine used by the table.', example='InnoDB'),
          fragmentSize?: long(name='FragmentSize', description='可回收空间大小（碎片空间大小），单位为Byte。

> 该参数仅适用于MongoDB实例。表碎片率计算方式为：`FragmentSize/PhyTotalSize`。', example='362221568'),
          indexSize?: long(name='IndexSize', description='The storage space occupied by indexes. Unit: bytes.', example='1022296064'),
          phyTotalSize?: long(name='PhyTotalSize', description='The storage space of the table. Unit: bytes.

>  The value of this parameter is the sum of the values of **DataSize**, **IndexSize**, and **DataFree**.', example='3012493312'),
          physicalFileSize?: long(name='PhysicalFileSize', description='The physical file size of the table. Unit: bytes.

>  You may fail to obtain the physical file size because of the deployment mode of the database instance.', example='3057655808'),
          tableName?: string(name='TableName', description='The name of the table.', example='test_table'),
          tableRows?: long(name='TableRows', description='The number of rows in the table.', example='12794732'),
          tableType?: string(name='TableType', description='The type of the table.', example='BASE TABLE'),
          totalSize?: long(name='TotalSize', description='The storage space occupied by table data and indexes. Unit: bytes.

>  The value of this parameter is the sum of the values of **DataSize** and **IndexSize**.', example='3005153280'),
        }
      ](name='TableStats', description='The information about the table.'),
      totalFreeStorageSize?: long(name='TotalFreeStorageSize', description='The size of remaining storage.

>  Unit: bytes.', example='146403229696'),
      totalStorageSize?: long(name='TotalStorageSize', description='The total size of instance storage.

>  Unit: bytes.', example='214748364800'),
      totalUsedStorageSize?: long(name='TotalUsedStorageSize', description='The size of used storage.

>  Unit: bytes.', example='68345135104'),
    }(name='StorageAnalysisResult', description='The details of storage analysis.'),
    taskFinish?: boolean(name='TaskFinish', description='Indicates whether the task is complete.', example='true'),
    taskId?: string(name='TaskId', description='The task ID.', example='910f83f4b96df0524ddc5749f615****'),
    taskProgress?: long(name='TaskProgress', description='The task progress.

>  Valid values are integers that range from 0 to 100.', example='50'),
    taskState?: string(name='TaskState', description='The status of the storage analysis task. Valid values:

*   **INIT**: The task is being initialized.
*   **PENDING**: The task is being queued for execution.
*   **RECEIVED**: The task is received for execution.
*   **RUNNING**: The task is being executed.
*   **RETRY**: The task is being retried.
*   **SUCCESS**: The task succeeds.
*   **FAILURE**: The task fails.', example='RUNNING'),
    taskSuccess?: boolean(name='TaskSuccess', description='Indicates whether the task is successful.', example='true'),
    totalDbCount?: long(name='TotalDbCount', description='The number of databases that need to be analyzed in the storage analysis task.', example='32'),
  }(name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request is successful, **Successful** is returned. Otherwise, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: boolean(name='Success', description='Indicates whether the request is successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model GetStorageAnalysisResultResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetStorageAnalysisResultResponseBody(name='body'),
}

/**
  * >  The physical file size indicates the actual size of an obtained file. Only specific deployment modes of database instances support the display of physical file sizes. The statistics on tables are obtained from `information_schema.tables`. Statistics in MySQL are not updated in real time. Therefore, the statistics may be different from the physical file sizes. If you want to obtain the latest data, you can execute the `ANALYZE TABLE` statement on the relevant tables during off-peak hours.
  * *   This operation is applicable only to ApsaraDB RDS for MySQL instances, PolarDB for MySQL clusters, and ApsaraDB for MongoDB instances.
  * *   If you use an Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call API operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function getStorageAnalysisResult(request: GetStorageAnalysisResultRequest): GetStorageAnalysisResultResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'GetStorageAnalysisResult', 'POST', '/', 'json', false, 'json', request);
}

model KillInstanceAllSessionRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='r-8vbcyr4sw0c4yc****', position='Query'),
}

model KillInstanceAllSessionResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The reserved parameter.', example='None'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model KillInstanceAllSessionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: KillInstanceAllSessionResponseBody(name='body'),
}

/**
  * *   This operation is applicable only to ApsaraDB for Redis.
  * *   If you use Alibaba Cloud SDK, make sure that the aliyun-sdk-core version is later than V4.3.3. We recommend that you use the latest version.
  * *   The version of your Database Autonomy Service (DAS) SDK must be V1.0.2 or later.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function killInstanceAllSession(request: KillInstanceAllSessionRequest): KillInstanceAllSessionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'KillInstanceAllSession', 'POST', '/', 'json', false, 'json', request);
}

model ModifyAutoScalingConfigRequest {
  bandwidth?: {
    apply?: boolean(name='Apply', description='Specifies whether to apply the **Bandwidth** configuration of the automatic bandwidth adjustment feature. Valid values:

*   **true**
*   **false**', example='true'),
    bandwidthUsageLowerThreshold?: int32(name='BandwidthUsageLowerThreshold', description='The average bandwidth usage threshold that triggers automatic bandwidth downgrade. Unit: %. Valid values:

*   **10**
*   **20**
*   **30**', example='30', minimum=10, maximum=70),
    bandwidthUsageUpperThreshold?: int32(name='BandwidthUsageUpperThreshold', description='The average bandwidth usage threshold that triggers automatic bandwidth upgrade. Unit: %. Valid values:

*   **50**
*   **60**
*   **70**
*   **80**
*   **90**
*   **95**', example='70', minimum=50, maximum=95),
    downgrade?: boolean(name='Downgrade', description='Specifies whether to enable the automatic bandwidth downgrade feature. Valid values:

*   **true**
*   **false**', example='true'),
    observationWindowSize?: string(name='ObservationWindowSize', description='The observation window of the automatic bandwidth adjustment feature. The value of this parameter consists of a numeric value and a time unit suffix. The **m** time unit suffix specifies the minute. Valid values:

*   **1m**
*   **5m**
*   **10m**
*   **15m**
*   **30m**', example='5m'),
    upgrade?: boolean(name='Upgrade', description='Specifies whether to enable the automatic bandwidth upgrade feature. Valid values:

*   **true**
*   **false**', example='true'),
  }(name='Bandwidth', description='The configuration item of the automatic bandwidth adjustment feature.', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  resource?: {
    apply?: boolean(name='Apply', description='Specifies whether to apply the **Resource** configuration of the auto scaling feature for resources. Valid values:

*   **true**
*   **false**', example='true'),
    cpuUsageUpperThreshold?: int32(name='CpuUsageUpperThreshold', description='The average CPU utilization threshold that triggers automatic scale-out of resources. Unit: %. Valid values:

*   **70**
*   **80**
*   **90**', example='70'),
    downgradeObservationWindowSize?: string(name='DowngradeObservationWindowSize', description='The observation window of the automatic resource scale-in feature. The value of this parameter consists of a numeric value and a time unit suffix. The **m** time unit suffix specifies the minute. Valid values:

*   **1m**
*   **3m**
*   **5m**
*   **10m**
*   **20m**
*   **30m**', example='5m'),
    enable?: boolean(name='Enable', description='Specifies whether to enable the auto scaling feature for resources. Valid values:

*   **true**
*   **false**', example='true'),
    upgradeObservationWindowSize?: string(name='UpgradeObservationWindowSize', description='The observation window of the automatic resource scale-out feature. The value of this parameter consists of a numeric value and a time unit suffix. The **m** time unit suffix specifies the minute. Valid values:

*   **1m**
*   **3m**
*   **5m**
*   **10m**
*   **20m**
*   **30m**', example='5m'),
  }(name='Resource', description='The configuration item of the auto scaling feature for resources.', position='Query'),
  shard?: {
    apply?: boolean(name='Apply', description='Specifies whether to apply the **Shard** configuration of the auto scaling feature for shards. Valid values:

*   **true**
*   **false**

> The auto scaling feature for shards is available only for ApsaraDB for Redis Community Edition cloud-native instances on the China site (aliyun.com).', example='true'),
    downgrade?: boolean(name='Downgrade', description='Specifies whether to enable the feature of automatically removing shards. Valid values:

*   **true**
*   **false**

>  The feature of automatically removing shards is in canary release.', example='true'),
    downgradeObservationWindowSize?: string(name='DowngradeObservationWindowSize', description='The observation window of the feature of automatically removing shards. The value of this parameter consists of a numeric value and a time unit suffix. The **h** time unit suffix specifies the hour. The **d** time unit suffix specifies the day. Valid values:

*   **1h**
*   **2h**
*   **3h**
*   **1d**
*   **7d**', example='1h'),
    maxShards?: int32(name='MaxShards', description='The maximum number of shards in the instance. The value must be a positive integer. Valid values: 4 to 32.', example='16', minimum=2, maximum=64),
    memUsageLowerThreshold?: int32(name='MemUsageLowerThreshold', description='The average memory usage threshold that triggers automatic removal of shards. Unit: %. Valid values:

*   **10**
*   **20**
*   **30**', example='30'),
    memUsageUpperThreshold?: int32(name='MemUsageUpperThreshold', description='The average memory usage threshold that triggers automatic adding of shards. Unit: %. Valid values:

*   **50**
*   **60**
*   **70**
*   **80**
*   **90**', example='70'),
    minShards?: int32(name='MinShards', description='The minimum number of shards in the instance. The value must be a positive integer. Valid values: 4 to 32.', example='4', minimum=2, maximum=64),
    upgrade?: boolean(name='Upgrade', description='Specifies whether to enable the feature of automatically adding shards. Valid values:

*   **true**
*   **false**', example='true'),
    upgradeObservationWindowSize?: string(name='UpgradeObservationWindowSize', description='The observation window of the feature of automatically adding shards. The value of this parameter consists of a numeric value and a time unit suffix. The **m** time unit suffix specifies the minute. Valid values:

*   **5m**
*   **10m**
*   **15m**
*   **30m**', example='5m'),
  }(name='Shard', description='The configuration item of the auto scaling feature for shards.', position='Query'),
  spec?: {
    apply?: boolean(name='Apply', description='Specifies whether to apply the **Spec** configuration of the auto scaling feature for specifications. Valid values:

*   **true**
*   **false**', example='true'),
    coolDownTime?: string(name='CoolDownTime', description='The quiescent period. The value of this parameter consists of a numeric value and a time unit suffix. The **m** time unit suffix specifies the minute, the **h** time unit suffix specifies the hour, and the **d** time suffix unit specifies the day.

*   Valid values for PolarDB for MySQL Cluster Edition instances: **5m**, **10m**, **30m**, **1h**, **2h**, **3h**, **1d**, and **7d**.
*   Valid values for ApsaraDB RDS for MySQL High-availability Edition instances that use standard SSDs or ESSDs: **5m**, **10m**, **30m**, **1h**, **2h**, **3h**, **1d**, and **7d**.', example='5m'),
    cpuUsageUpperThreshold?: int32(name='CpuUsageUpperThreshold', description='The average CPU utilization threshold that triggers automatic specification scale-up. Unit: %. Valid values:

*   **50**
*   **60**
*   **70**
*   **80**
*   **90**

> This parameter must be specified if the database instance is a PolarDB for MySQL Cluster Edition instance or an ApsaraDB RDS for MySQL High-availability Edition instance that uses standard SSDs or ESSDs.', example='70'),
    downgrade?: boolean(name='Downgrade', description='Specifies whether to enable the automatic specification scale-down feature. Valid values:

*   **true**
*   **false**

> This parameter must be specified if the database instance is a PolarDB for MySQL Cluster Edition instance or an ApsaraDB RDS for MySQL High-availability Edition instance that uses standard SSDs or ESSDs.', example='true'),
    maxReadOnlyNodes?: int32(name='MaxReadOnlyNodes', description='The maximum number of read-only nodes of the instance.

> This parameter must be specified if the database instance is a PolarDB for MySQL Cluster Edition instance.', example='10', minimum=1, maximum=15),
    maxSpec?: string(name='MaxSpec', description='The maximum specifications to which the database instance can be scaled up. The database instance can be upgraded only to a database instance of the same edition with higher specifications. For information about the specifications of different database instances, see the following topics:

*   PolarDB for MySQL Cluster Edition instances: [Specifications of compute nodes](~~102542~~)
*   ApsaraDB RDS for MySQL High-availability Edition instances that use standard SSDs or ESSDs: [Specifications](~~276974~~)', example='polar.mysql.x8.12xlarge'),
    memUsageUpperThreshold?: int32(name='MemUsageUpperThreshold', description='The average memory usage threshold that triggers automatic specification scale-up. Unit: %. Valid values:

*   **50**
*   **60**
*   **70**
*   **80**
*   **90**

> This parameter must be specified if the database instance is an ApsaraDB for Redis Community Edition cloud-native instance on the China site (aliyun.com).', example='70'),
    observationWindowSize?: string(name='ObservationWindowSize', description='The observation window. The value of this parameter consists of a numeric value and a time unit suffix. The **m** time unit suffix specifies the minute and the **h** time unit suffix specifies the hour.

*   Valid values for PolarDB for MySQL Cluster Edition instances: **5m**, **10m**, **15m**, and **30m**.
*   Valid values for ApsaraDB RDS for MySQL High-availability Edition instances that use standard SSDs or ESSDs: **5m**, **20m**, **30m**, **40m**, and **1h**.
*   Valid values for ApsaraDB for Redis Community Edition cloud-native instances: **5m**, **10m**, **15m**, and **30m**.', example='5m'),
    upgrade?: boolean(name='Upgrade', description='Specifies whether to enable the automatic specification scale-up feature. Valid values:

*   **true**
*   **false**', example='true'),
  }(name='Spec', description='The configuration item of the auto scaling feature for specifications.', position='Query'),
  storage?: {
    apply?: boolean(name='Apply', description='Specifies whether to apply the **Storage** configuration of the automatic storage expansion feature. Valid values:

*   **true**
*   **false**', example='true'),
    diskUsageUpperThreshold?: int32(name='DiskUsageUpperThreshold', description='The average storage usage threshold that triggers automatic storage expansion. Unit: %. Valid values:

*   **50**
*   **60**
*   **70**
*   **80**
*   **90**', example='70'),
    maxStorage?: int32(name='MaxStorage', description='The maximum storage size of the database instance. The value must be greater than or equal to the total storage size of the instance. Valid values of different types of instances:

*   If the ApsaraDB for RDS instance uses ESSDs, the value of this parameter can be set to 32000, in GB.
*   If the ApsaraDB for RDS instance uses standard SSDs, the value of this parameter can be set to 6000, in GB.

>  The ApsaraDB RDS for MySQL instances that use standard SSDs are discontinued. We recommend that you [upgrade the storage type of an ApsaraDB RDS for MySQL instance from standard SSDs to ESSDs](~~314678~~).', example='32000', minimum=20, maximum=32000),
    upgrade?: boolean(name='Upgrade', description='Specifies whether to enable the automatic storage expansion feature. Valid values:

*   **true**
*   **false**', example='true'),
  }(name='Storage', description='The configuration item of the automatic storage expansion feature.', position='Query'),
}

model ModifyAutoScalingConfigResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model ModifyAutoScalingConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifyAutoScalingConfigResponseBody(name='body'),
}

/**
  * You can call this operation to modify the following auto scaling configurations of an instance: **auto scaling for specifications**, **automatic storage expansion**, **automatic bandwidth adjustment**, and **auto scaling for resources**.
  * *   You can modify the configurations of the **auto scaling feature for specifications** for the following types of database instances:
  *     *   PolarDB for MySQL Cluster Edition instances. For more information about the feature and the billing rules, see [Automatic performance scaling](~~169686~~).
  *     *   ApsaraDB RDS for MySQL High-availability Edition instances that use standard SSDs or enhanced SSDs (ESSDs). For more information about the feature and the billing rules, see [Automatic performance scaling](~~169686~~).
  * *   You can modify the configurations of the **automatic storage expansion** feature for the following types of database instances:
  *     *   ApsaraDB RDS for MySQL High-availability Edition instances that use standard SSDs or ESSDs. For more information about the feature and the billing rules, see [Automatic space expansion](~~173345~~).
  * *   You can modify the configurations of the **automatic bandwidth adjustment** feature for the following types of database instances:
  *     *   ApsaraDB for Redis Classic (Local Disk-based) Edition instances. For more information about the feature and the billing rules, see [Automatic bandwidth adjustment](~~216312~~).
  * *   You can modify the configurations of the **auto scaling feature for resources** for the following types of database instances:
  *     *   General-purpose ApsaraDB RDS for MySQL Enterprise Edition instances. For more information about the feature and the billing rules, see [Automatic performance scaling](~~169686~~).
  * *   If you use an Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  *
 */
async function modifyAutoScalingConfig(request: ModifyAutoScalingConfigRequest): ModifyAutoScalingConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifyAutoScalingConfig', 'POST', '/', 'json', false, 'json', request);
}

model ModifySqlLogConfigRequest {
  enable?: boolean(name='Enable', description='Specifies whether to enable DAS Enterprise Edition. Valid values:

*   **true**
*   **false**

>  This parameter is required if you want to enable DAS Enterprise Edition. By default, the latest version of DAS Enterprise Edition that supports the database instance is enabled.', example='true', position='Body'),
  filters?: [ 
    {
      key?: string(name='Key', description='A reserved parameter.', example='None'),
      value?: string(name='Value', description='A reserved parameter.', example='None'),
    }
  ](name='Filters', description='A reserved parameter.', position='Query'),
  hotRetention?: int32(name='HotRetention', description='The number of days for which the SQL Explorer and Audit data is stored in hot storage. Valid values: 1 to 7.

>  This parameter is required if only DAS Enterprise Edition V3 can be enabled for the database instance.', example='1', position='Body'),
  instanceId: string(name='InstanceId', description='The ID of the database instance.', example='rr-2ze770smbq3tpr2o9', position='Body'),
  requestEnable?: boolean(name='RequestEnable', description='Specifies whether to enable the SQL Explorer feature. Valid values:

*   **true**
*   **false**

>  This parameter is required if only DAS Enterprise Edition V3 can be enabled for the database instance.', example='true', position='Body'),
  retention?: int32(name='Retention', description='The total storage duration of the SQL Explorer and Audit data. Unit: day. Valid values:

*   7
*   30
*   180
*   365

>  If you want to enable DAS Enterprise Edition V3, the value of this parameter must be greater than or equal to 30.', example='30', position='Body'),
}

model ModifySqlLogConfigResponseBody = {
  code?: string(name='Code', description='The response code.', example='403'),
  data?: {
    coldEnable?: boolean(name='ColdEnable', description='Indicates whether the cold data storage is enabled. Valid values:

*   **true**
*   **false**', example='true'),
    coldRetention?: int32(name='ColdRetention', description='The number of days for which the SQL Explorer and Audit data is stored in cold storage. The value is calculated by using the following formula: Value of ColdRetention = Value of Retention - Value of HotRetention.``', example='23'),
    coldStartTime?: long(name='ColdStartTime', description='The time when the cold data storage was enabled. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1683712800000'),
    collectorVersion?: string(name='CollectorVersion', description='The collector version. Valid values:

*   **MYSQL_V0**
*   **MYSQL_V1**
*   **MYSQL_V2**
*   **MYSQL_V3**
*   **PG_V1**
*   **rdspg_v1**
*   **polarpg_v1**', example='MYSQL_V3'),
    hotEnable?: boolean(name='HotEnable', description='Indicates whether the hot data storage is enabled. Valid values:

*   **true**
*   **false**', example='true'),
    hotRetention?: int32(name='HotRetention', description='The number of days for which the SQL Explorer and Audit data is stored in hot storage.', example='7'),
    hotStartTime?: long(name='HotStartTime', description='The time when the hot data storage was enabled. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1683712800000'),
    logFilter?: string(name='LogFilter', description='A reserved parameter.', example='None'),
    requestEnable?: boolean(name='RequestEnable', description='Indicates whether the SQL Explorer feature is enabled. Valid values:

*   **true**
*   **false**', example='false'),
    requestStartTime?: long(name='RequestStartTime', description='The time when the SQL Explorer feature was enabled. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1683712800000'),
    requestStopTime?: long(name='RequestStopTime', description='The time when DAS Enterprise Edition V1 expired. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1715335200000'),
    retention?: int32(name='Retention', description='The total storage duration of the SQL Explorer and Audit data. Unit: day.', example='30'),
    sqlLogEnable?: boolean(name='SqlLogEnable', description='Indicates whether DAS Enterprise Edition is enabled. Valid values:

*   **true**
*   **false**', example='true'),
    sqlLogState?: string(name='SqlLogState', description='The state of data migration. Valid values:

*   **FINISH**: The historical data is migrated.
*   **RUNNING**: The historical data is being migrated.
*   **FAILURE**: The historical data fails to be migrated.', example='FINISH'),
    sqlLogVisibleTime?: long(name='SqlLogVisibleTime', description='The time when DAS Enterprise Edition was enabled. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1683712800000'),
    supportVersion?: string(name='SupportVersion', description='The latest version of DAS Enterprise Edition that supports the database instance. Valid values:

*   **SQL_LOG_V0**: DAS Enterprise Edition V0.
*   **SQL_LOG_V1**: DAS Enterprise Edition V1.
*   **SQL_LOG_V2**: DAS Enterprise Edition V2.
*   **SQL_LOG_V3**: DAS Enterprise Edition V3.
*   **SQL_LOG_NOT_ENABLE**: DAS Enterprise Edition is not enabled.
*   **SQL_LOG_NOT_SUPPORT**: DAS Enterprise Edition is not supported.', example='SQL_LOG_V3'),
    version?: string(name='Version', description='The version of DAS Enterprise Edition that is enabled for the database instance. Valid values:

*   **SQL_LOG_V0**: DAS Enterprise Edition V0.
*   **SQL_LOG_V1**: DAS Enterprise Edition V1.
*   **SQL_LOG_V2**: DAS Enterprise Edition V2.
*   **SQL_LOG_V3**: DAS Enterprise Edition V3.
*   **SQL_LOG_NOT_ENABLE**: DAS Enterprise Edition is not enabled.
*   **SQL_LOG_NOT_SUPPORT**: DAS Enterprise Edition is not supported.', example='SQL_LOG_V3'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='03C88D8E-1541-518E-8BFF-BEC6589B6334'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='False'),
}

model ModifySqlLogConfigResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: ModifySqlLogConfigResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or a DAS SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call operations of DAS, you must set the region ID to cn-shanghai.
  * *   By default, the latest version of DAS Enterprise Edition that supports the database instance is enabled. For information about the databases and regions that are supported by different versions of DAS Enterprise Edition, see [Editions and supported features](~~156204~~).
  *
 */
async function modifySqlLogConfig(request: ModifySqlLogConfigRequest): ModifySqlLogConfigResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'ModifySqlLogConfig', 'POST', '/', 'json', true, 'form', request);
}

model RunCloudBenchTaskRequest {
  taskId: string(name='TaskId', description='The stress testing task ID. You can call the [DescribeCloudBenchTasks](~~230670~~) operation to query the task ID.', example='e5cec704-0518-430f-8263-76f4dcds****', position='Query'),
}

model RunCloudBenchTaskResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    preCheckItem?: [ 
    {
      code?: int32(name='Code', description='The HTTP status code returned.', example='200'),
      details?: string(name='Details', description='The detailed information of the check item.', example='"Data": { "total": 1, "list":[...] }, "Code": 200, "Success": true }'),
      message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
      name?: string(name='Name', description='The name of the check item. Valid values:

* **SqlArchiveStatusChecker**: checks whether SQL Explorer is available.
* **BenchClientEnvChecker**: checks whether the runtime environment for programs on the stress testing client is available.
* **SpecChecker**: checks whether the destination instance type and the instance type of the stress testing client support this API operation.
* **SourceInstanceChecker**: checks whether the account of the source instance is available and whether the source instance is connected to the destination instance.
* **BenchTargetChecker**: checks whether the account of the destination instance is available and whether the source instance is connected to the destination instance.', example='BenchTargetChecker'),
      order?: int32(name='Order', description='The sequence number of the check item. Valid values: **0** to **10**.', example='0'),
      status?: string(name='Status', description='The status of the task. Valid values:

*   **SUCCESS**: The task is successful.
*   **IGNORED**: The task is ignored.
*   **RUNNING**: The task is running.
*   **EXCEPTION**: An error occurred.', example='SUCCESS'),
    }
  ](name='PreCheckItem')
  }(name='Data', description='The detailed information, including the error codes and the number of returned entries.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model RunCloudBenchTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: RunCloudBenchTaskResponseBody(name='body'),
}

/**
  * Database Autonomy Service (DAS) provides the intelligent stress testing feature. This feature helps you check whether your instance needs to be scaled up to effectively handle traffic spikes. For more information, see [Intelligent stress testing](~~155068~~).
  *
 */
async function runCloudBenchTask(request: RunCloudBenchTaskRequest): RunCloudBenchTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'RunCloudBenchTask', 'POST', '/', 'json', false, 'json', request);
}

model SetEventSubscriptionRequest {
  active?: string(name='Active', description='Specifies whether to enable the event subscription feature. Valid values:

*   **0**: disables the event subscription feature.
*   **1**: enables the event subscription feature.', example='1', position='Query'),
  channelType?: string(name='ChannelType', description='The notification method. Valid values:

*   **hdm_alarm_sms**: text message.
*   **dingtalk**: DingTalk chatbot.
*   **hdm_alarm_sms_and_email**: text message and email.
*   **hdm_alarm_sms,dingtalk**: text message and DingTalk chatbot.', example='hdm_alarm_sms,dingtalk', position='Query'),
  contactGroupName?: string(name='ContactGroupName', description='The name of the contact group that receives alert notifications. Separate multiple names with commas (,).', example='Default contact group', position='Query'),
  contactName?: string(name='ContactName', description='The name of the contact who receives alert notifications. Separate multiple names with commas (,).', example='Default contact', position='Query'),
  dispatchRule?: string(name='DispatchRule', description='The notification rules based on the event type. If you leave this parameter empty, the values of **MinInterval** and **ChannelType** prevail.

Specify this parameter in the following format: `{"silenced": {"Event type 1":Specifies whether to enable adaptive silence, "Event type 2":Specify whether to enable adaptive silence},"min_interval": {"Event type 1":Minimum interval between event notifications, "Event type 2":Minimum interval between event notifications},"alert_type": {"Event type 1":"Notification method", "Event type 2":"Notification method"}}`.

*   **silenced**: specifies whether to enable adaptive silence. After you enable adaptive silence, the interval between consecutive alert notifications for an event is the greater one of the minimum interval specified by **min_interval** and one third of the event duration. Valid values:

    *   1: enables adaptive silence.
    *   2: disables adaptive silence.

*   **min_interval**: the minimum interval between event notifications. Unit: seconds.

*   **alert_type**: the notification method. Valid values:

    *   **hdm_alarm_sms**: text message.
    *   **dingtalk**: DingTalk chatbot.
    *   **hdm_alarm_sms_and_email**: text message and email.
    *   **hdm_alarm_sms,dingtalk**: text message and DingTalk chatbot.', example='{"silenced": {"AutoScale":1, "SQLThrottle":0, "TimeSeriesAbnormal": 1}, "min_interval": {"AutoScale":300, "SQLThrottle":360, "TimeSeriesAbnormal": 120}, "alert_type": {"AutoScale":"hdm_alarm_sms", "SQLThrottle":"hdm_alarm_sms_and_email", "TimeSeriesAbnormal": "hdm_alarm_sms,dingtalk"}}', position='Query'),
  eventContext?: string(name='EventContext', description='The supported event scenarios. You can set the value to **AllContext**, which indicates that all scenarios are supported.', example='AllContext', position='Query'),
  instanceId: string(name='InstanceId', description='The instance ID.', example='rm-2ze8g2am97624****', position='Query'),
  lang?: string(name='Lang', description='The language of event notifications. You can set the value to **zh-CN**, which indicates that event notifications are sent in Chinese.', example='zh-CN', position='Query'),
  level?: string(name='Level', description='The risk level of the events. Valid values:

*   **Notice**: events that trigger notifications, including events at the **Notice**, **Optimization**, **Warn**, and **Critical** levels.
*   **Optimization**: events that trigger optimizations, including events at the **Optimization**, **Warn**, and **Critical** levels.
*   **Warn**: events that trigger warnings, including events at the **Warn** and **Critical** levels.
*   **Critical**: events that trigger critical warnings.

The following content describes the events at each level in detail:

*   Notice: events that are related to database exceptions for which no suggestions are generated.
*   Optimization: events for which optimization suggestions are generated based on the status of the database.
*   Warn: events that may affect the running of the database.
*   Critical: events that affect the running of the database.', example='Optimization', position='Query'),
  minInterval?: string(name='MinInterval', description='The minimum interval between consecutive event notifications. Unit: seconds.', example='60', position='Query'),
  severity?: string(name='Severity', description='The alert severity based on the event type.

Specify this parameter in the following format: `{"Event type 1":"Alert severity", "Event type 2":"Alert severity"}`.

Valid values of event types:

*   **AutoScale**: auto scaling event.
*   **SQLThrottle**: throttling event.
*   **TimeSeriesAbnormal**: event for detecting time series anomalies.
*   **SQLOptimize**: SQL optimization event.
*   **ResourceOptimize**: storage optimization event.

Valid values of alert severities:

*   **info**
*   **noticed**
*   **warning**
*   **critical**', example='{"AutoScale":"critical","SQLThrottle":"info","TimeSeriesAbnormal":"warning"}', position='Query'),
}

model SetEventSubscriptionResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    active?: int32(name='active', description='Indicates whether the event subscription feature is enabled. Valid values:

*   **0**: The event subscription feature is disabled.
*   **1**: The event subscription feature is enabled.', example='1'),
    channelType?: string(name='channelType', description='The notification method. Valid values:

*   **hdm_alarm_sms**: text message.
*   **dingtalk**: DingTalk chatbot.
*   **hdm_alarm_sms_and_email**: text message and email.
*   **hdm_alarm_sms,dingtalk**: text message and DingTalk chatbot.', example='hdm_alarm_sms,dingtalk'),
    contactGroupName?: string(name='contactGroupName', description='The name of the contact group that receives alert notifications. Multiple names are separated by commas (,).', example='Default contact group'),
    contactName?: string(name='contactName', description='The name of the contact who receives alert notifications. Multiple names are separated by commas (,).', example='Default contact'),
    eventContext?: string(name='eventContext', description='The supported event scenarios. Only **AllContext** is returned for this parameter, which indicates that all scenarios are supported.', example='AllContext'),
    instanceId?: string(name='instanceId', description='The instance ID.', example='rm-2ze8g2am97624****'),
    lang?: string(name='lang', description='The language of event notifications. Only **zh-CN** is returned for this parameter, which indicates that event notifications are sent in Chinese.', example='zh_CN'),
    level?: string(name='level', description='The risk level of the events. Valid values:

*   **Notice**
*   **Optimization**
*   **Warn**
*   **Critical**', example='Optimization'),
    minInterval?: int32(name='minInterval', description='The minimum interval between consecutive event notifications. Unit: seconds.', example='60'),
    userId?: string(name='userId', description='The user ID.', example='1088760496****'),
  }(name='Data', description='The detailed information.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='097F0C56-B252-515A-B602-FC56EF93EF8A'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model SetEventSubscriptionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SetEventSubscriptionResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an Alibaba Cloud SDK or Database Autonomy Service (DAS) SDK to call this operation, we recommend that you use the latest version of the SDK.
  * *   If you use an SDK to call the API operations of DAS, you must set the region ID to cn-shanghai.
  * *   Make sure that the database instance that you want to manage is connected to DAS.
  *
 */
async function setEventSubscription(request: SetEventSubscriptionRequest): SetEventSubscriptionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SetEventSubscription', 'POST', '/', 'json', false, 'json', request);
}

model StopCloudBenchTaskRequest {
  taskId: string(name='TaskId', description='The stress testing task ID. You can call the [DescribeCloudBenchTasks](~~230670~~) operation to query the task ID.', example='e5cec704-0518-430f-8263-76f4dcds****', position='Query'),
}

model StopCloudBenchTaskResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: string(name='Data', description='The reserved parameter.', example='None'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model StopCloudBenchTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: StopCloudBenchTaskResponseBody(name='body'),
}

/**
  * Database Autonomy Service (DAS) provides the intelligent stress testing feature. This feature helps you check whether your instance needs to be scaled up to effectively handle traffic spikes. For more information, see [Intelligent stress testing](~~155068~~).
  *
 */
async function stopCloudBenchTask(request: StopCloudBenchTaskRequest): StopCloudBenchTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'StopCloudBenchTask', 'POST', '/', 'json', false, 'json', request);
}

model SyncHDMAliyunResourceRequest {
  async?: string(name='Async', position='Query'),
  resourceTypes?: string(name='ResourceTypes', position='Query'),
  uid?: string(name='Uid', position='Query'),
  userId?: string(name='UserId', position='Query'),
  waitForModifySecurityIps?: string(name='WaitForModifySecurityIps', position='Query'),
  context?: string(name='__context', position='Query'),
  accessKey?: string(name='accessKey', position='Query'),
  signature?: string(name='signature', position='Query'),
  skipAuth?: string(name='skipAuth', position='Query'),
  timestamp?: string(name='timestamp', position='Query'),
}

model SyncHDMAliyunResourceResponseBody = {
  code?: string(name='Code'),
  data?: string(name='Data'),
  message?: string(name='Message'),
  requestId?: string(name='RequestId'),
  success?: string(name='Success'),
  synchro?: string(name='Synchro'),
}

model SyncHDMAliyunResourceResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: SyncHDMAliyunResourceResponseBody(name='body'),
}

async function syncHDMAliyunResource(request: SyncHDMAliyunResourceRequest): SyncHDMAliyunResourceResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'SyncHDMAliyunResource', 'POST', '/', 'json', false, 'json', request);
}

model UpdateAutoResourceOptimizeRulesAsyncRequest {
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  instanceIds: string(name='InstanceIds', description='The database instance IDs.

>  Set this parameter to a JSON array that consists of multiple instance IDs. Separate instance IDs with commas (,). Example: `[\\"Instance ID1\\", \\"Instance ID2\\"]`.', example='[\\"rm-2ze8g2am97624****\\",\\"rm-2ze9xrhze0709****\\"]', position='Query'),
  resultId?: string(name='ResultId', description='The ID of the asynchronous request.

>  Asynchronous calls do not immediately return the complete results. To obtain the complete results, you must use the value of **ResultId** returned in the response to re-initiate the call until the value of **isFinish** is **true**.**** In this case, you must call this operation at least twice.', example='async__507044db6c4eadfa2dab9b084e80****', position='Query'),
  tableFragmentationRatio: double(name='TableFragmentationRatio', description='The fragmentation rate that triggers automatic fragment recycling of a single physical table. Valid values: **0.10** to **0.99**.', example='0.2', position='Query'),
  tableSpaceSize: double(name='TableSpaceSize', description='The minimum storage usage that triggers automatic fragment recycling of a single physical table. Valid values: **5** to **100**. Unit: GB.', example='10', position='Query'),
}

model UpdateAutoResourceOptimizeRulesAsyncResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    complete?: boolean(name='Complete', description='Indicates whether the asynchronous request was complete. Valid values:

*   **true**
*   **false**', example='true'),
    configResponse?: {
      configFailInstanceCount?: long(name='ConfigFailInstanceCount', description='The number of database instances for which the parameters failed to be configured.', example='1'),
      configFailInstanceList?: [ 
        {
          configSuccess?: boolean(name='ConfigSuccess', description='Indicates whether the parameters are configured. Valid values:

* **true**

* **false**', example='false'),
          errorMessage?: string(name='ErrorMessage', description='The error message returned.', example='Only Support DAS Pro High-availability Edition RDS MySQL 5.6, 5.7, 8.0 instance, and CPU cores >= 4, innodb_file_per_table=ON'),
          instanceId?: string(name='InstanceId', description='The database instance ID.', example='rm-2ze9xrhze0709****'),
        }
      ](name='ConfigFailInstanceList', description='The database instances for which the parameters failed to be configured.'),
      configSuccessInstanceCount?: long(name='ConfigSuccessInstanceCount', description='The number of database instances for which the parameters are configured.', example='1'),
      configSuccessInstanceList?: [ 
        {
          configSuccess?: boolean(name='ConfigSuccess', description='Indicates whether the parameters are configured. Valid values:

* **true**

* **false**', example='true'),
          instanceId?: string(name='InstanceId', description='The database instance ID.', example='rm-2ze8g2am97624****'),
        }
      ](name='ConfigSuccessInstanceList', description='The database instances for which the parameters are configured.'),
      totalInstanceCount?: long(name='TotalInstanceCount', description='The total number of database instances.', example='2'),
    }(name='ConfigResponse', description='The returned data of the configuration.

>  The data is returned only if the value of isFinish is **true**. This value indicates that the asynchronous request is complete.'),
    fail?: boolean(name='Fail', description='Indicates whether the asynchronous request failed. Valid values:

*   **true**
*   **false**', example='false'),
    isFinish?: boolean(name='IsFinish', description='Indicates whether the asynchronous request was complete. Valid values:

*   **true**
*   **false**', example='true'),
    resultId?: string(name='ResultId', description='The ID of the asynchronous request.', example='async__20ee808e72257f16a4fe024057ca****'),
    state?: string(name='State', description='The state of the asynchronous request. Valid values:

*   **RUNNING**
*   **SUCCESS**
*   **FAIL**', example='SUCCESS'),
    timestamp?: long(name='Timestamp', description='The time when the asynchronous request was made. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1645668213000'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='9CB97BC4-6479-55D0-B9D0-EA925AFE****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model UpdateAutoResourceOptimizeRulesAsyncResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAutoResourceOptimizeRulesAsyncResponseBody(name='body'),
}

/**
  * >  Asynchronous calls do not immediately return the complete results. To obtain the complete results, you must use the value of **ResultId** returned in the response to re-initiate the call until the value of **isFinish** is **true**.**** In this case, you must call this operation at least twice.
  * Before you call this operation, take note of the following items:
  * *   If you use an SDK to call the API operations of Database Autonomy Service (DAS), you must set the region ID to cn-shanghai.
  * *   The database instances must be an ApsaraDB RDS for MySQL High-availability Edition instance.
  * *   DAS Enterprise Edition must be enabled for the database instance. You can call the call [DescribeInstanceDasPro](~~413866~~) operation to query whether DAS Enterprise Edition is enabled.
  * *   The database instance has four or more CPU cores, and **innodb_file_per_table** is set to **ON**.
  *
 */
async function updateAutoResourceOptimizeRulesAsync(request: UpdateAutoResourceOptimizeRulesAsyncRequest): UpdateAutoResourceOptimizeRulesAsyncResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateAutoResourceOptimizeRulesAsync', 'POST', '/', 'json', false, 'json', request);
}

model UpdateAutoSqlOptimizeStatusRequest {
  instances: string(name='Instances', description='The database instance IDs. Separate multiple IDs with commas (,).

>  You can specify up to 50 instance IDs.', example='rm-bp10usoc1erj7****,rm-bp10usoc1erj7****', position='Query'),
  status: int32(name='Status', description='The status of the automatic SQL optimization feature. Valid values:

*   **0**: The automatic SQL optimization feature is disabled.
*   **1**: **SQL diagnosis and automatic index creation** is specified.
*   **3**: **SQL diagnosis only** is specified.', example='1', position='Query'),
}

model UpdateAutoSqlOptimizeStatusResponseBody = {
  code?: string(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    errorCode?: string(name='ErrorCode', description='The error code. Valid values:

*   **-1001**: indicates that the specified parameter is invalid.
*   **-91029**: indicates that a system error occurred.', example='-1001'),
    errorMsg?: string(name='ErrorMsg', description='The error message.', example='invalid param'),
    success?: string(name='Success', description='Indicates whether the request initiated to configure the automatic SQL optimization feature was successful. Valid values:

*   **true**
*   **false**', example='false'),
  }(name='Data', description='The returned data.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='A52AD37C-35ED-581A-AC23-2232BE54****'),
  success?: string(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model UpdateAutoSqlOptimizeStatusResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAutoSqlOptimizeStatusResponseBody(name='body'),
}

/**
  * Before you call this operation, take note of the following items:
  * *   If you use an SDK to call API operations of Database Autonomy Service (DAS), you must set the region ID to cn-shanghai.
  * *   DAS Enterprise Edition must be enabled for the database instance that you want to manage. To enable DAS Enterprise Edition for a database instance, you can call the [EnableDasPro](~~411645~~) operation.
  * *   The autonomy service must be enabled for the database instance that you want to manage. For more information, see [Autonomy center](~~152139~~).
  * *   This operation supports the following database engines:
  *     *   ApsaraDB RDS for MySQL High-availability Edition or Enterprise Edition
  *     *   PolarDB for MySQL Cluster Edition or X-Engine Edition
  *
 */
async function updateAutoSqlOptimizeStatus(request: UpdateAutoSqlOptimizeStatusRequest): UpdateAutoSqlOptimizeStatusResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateAutoSqlOptimizeStatus', 'POST', '/', 'json', false, 'json', request);
}

model UpdateAutoThrottleRulesAsyncRequest {
  abnormalDuration: double(name='AbnormalDuration', description='The duration threshold for triggering automatic SQL throttling. Set this parameter to an integer that is greater than or equal to 2. Unit: minutes.', example='2', position='Query'),
  activeSessions: long(name='ActiveSessions', description='The threshold for the number of active sessions.

*   If this parameter and CpuUsage are in the **OR** relationship, set this parameter to an integer that is greater than or equal to 16.
*   If this parameter and CpuUsage are in the **AND** relationship, set this parameter to an integer that is greater than or equal to 2.', example='16', position='Query'),
  allowThrottleEndTime: string(name='AllowThrottleEndTime', description='The end time of the throttling window. The time must be in UTC.', example='23:59Z', position='Query'),
  allowThrottleStartTime: string(name='AllowThrottleStartTime', description='The start time of the throttling window. The time must be in UTC.', example='00:00Z', position='Query'),
  autoKillSession: boolean(name='AutoKillSession', description='Specifies whether to terminate abnormal SQL statements in execution at the same time. Valid values:

>  Abnormal SQL statements use the same template as the SQL statements to be throttled.

*   **true**
*   **false**', example='true', position='Query'),
  consoleContext?: string(name='ConsoleContext', description='The reserved parameter.', example='None', position='Query'),
  cpuSessionRelation: string(name='CpuSessionRelation', description='The logical relationship between the CPU utilization threshold and the maximum number of active sessions. Valid values:

*   **AND**
*   **OR**', example='OR', position='Query'),
  cpuUsage: double(name='CpuUsage', description='The threshold for CPU utilization. Valid values: 70% to 100%.', example='70', position='Query'),
  instanceIds: string(name='InstanceIds', description='The database instance IDs.

>  Set this parameter to a JSON array that consists of multiple instance IDs. Separate instance IDs with commas (,). Example: `[\\"Instance ID1\\", \\"Instance ID2\\"]`.', example='[\\"rm-2ze8g2am97624****\\",\\"rm-2ze9xrhze0709****\\"]', position='Query'),
  maxThrottleTime: double(name='MaxThrottleTime', description='The maximum throttling duration. Set this parameter to a positive integer. Unit: minutes.', example='10', position='Query'),
  resultId?: string(name='ResultId', description='The ID of the asynchronous request.

>  You can leave this parameter empty when you call the operation to initiate the request for the first time, and use the value of this parameter contained in the response to the first request for subsequent requests.', example='async__507044db6c4eadfa2dab9b084e80****', position='Query'),
}

model UpdateAutoThrottleRulesAsyncResponseBody = {
  code?: long(name='Code', description='The HTTP status code returned.', example='200'),
  data?: {
    complete?: boolean(name='Complete', description='Indicates whether the asynchronous request was complete. Valid values:

*   **true**
*   **false**', example='true'),
    configResponse?: {
      configFailInstanceCount?: long(name='ConfigFailInstanceCount', description='The number of database instances for which the parameters failed to be configured.', example='1'),
      configFailInstanceList?: [ 
        {
          configSuccess?: boolean(name='ConfigSuccess', description='Indicates whether the parameters are configured. Valid values:

* **true**

* **false**', example='false'),
          errorMessage?: string(name='ErrorMessage', description='The error message returned.', example='instance das autonomy service is off or can not find instance'),
          instanceId?: string(name='InstanceId', description='The database instance ID.', example='rm-2ze9xrhze0709****'),
        }
      ](name='ConfigFailInstanceList', description='The database instances for which the parameters failed to be configured.'),
      configSuccessInstanceCount?: long(name='ConfigSuccessInstanceCount', description='The number of database instances for which the parameters are configured.', example='1'),
      configSuccessInstanceList?: [ 
        {
          configSuccess?: boolean(name='ConfigSuccess', description='Indicates whether the parameters are configured. Valid values:

* **true**

* **false**', example='true'),
          instanceId?: string(name='InstanceId', description='The database instance ID.', example='rm-2ze8g2am97624****'),
        }
      ](name='ConfigSuccessInstanceList', description='The database instances for which the parameters are configured.'),
      totalInstanceCount?: long(name='TotalInstanceCount', description='The total number of database instances.', example='2'),
    }(name='ConfigResponse', description='The returned data of the configuration.

>  The data is returned only if the value of isFinish is **true**. This value indicates that the asynchronous request is complete.'),
    fail?: boolean(name='Fail', description='Indicates whether the asynchronous request failed. Valid values:

*   **true**
*   **false**', example='false'),
    isFinish?: boolean(name='IsFinish', description='Indicates whether the asynchronous request was complete. Valid values:

*   **true**
*   **false**', example='true'),
    resultId?: string(name='ResultId', description='The ID of the asynchronous request.', example='async__665ee69612f1627c7fd9f3c85075****'),
    state?: string(name='State', description='The state of the asynchronous request. Valid values:

*   **RUNNING**
*   **SUCCESS**
*   **FAIL**', example='SUCCESS'),
    timestamp?: long(name='Timestamp', description='The time when the asynchronous request was made. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1645668213000'),
  }(name='Data', description='The data returned.'),
  message?: string(name='Message', description='The returned message.

>  If the request was successful, **Successful** is returned. If the request failed, an error message such as an error code is returned.', example='Successful'),
  requestId?: string(name='RequestId', description='The request ID.', example='B6D17591-B48B-4D31-9CD6-9B9796B2****'),
  success?: boolean(name='Success', description='Indicates whether the request was successful. Valid values:

*   **true**
*   **false**', example='true'),
}

model UpdateAutoThrottleRulesAsyncResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: UpdateAutoThrottleRulesAsyncResponseBody(name='body'),
}

/**
  * >  Asynchronous calls do not immediately return the complete results. You must use the value of **ResultId** returned in the response to re-initiate the call until the value of **isFinish** is **true**.
  * Before you call this operation, take note of the following items:
  * *   If you use an SDK to call the API operations of Database Autonomy Service (DAS), you must set the region ID to cn-shanghai.
  * *   The autonomy service must be enabled for the database instance that you want to manage. For more information, see [Autonomy center](~~152139~~).
  * *   The database instance that you want to manage must be of one of the following types:
  *     *   ApsaraDB RDS for MySQL High-availability Edition or Enterprise Edition that runs MySQL 5.6, MySQL 5.7, or MySQL 8.0
  *     *   PolarDB for MySQL Cluster Edition that runs MySQL 5.6, MySQL 5.7, or MySQL 8.0, or PolarDB for MySQL X-Engine Edition that runs MySQL 8.0
  *
 */
async function updateAutoThrottleRulesAsync(request: UpdateAutoThrottleRulesAsyncRequest): UpdateAutoThrottleRulesAsyncResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RPC', 'UpdateAutoThrottleRulesAsync', 'POST', '/', 'json', false, 'json', request);
}

model DataResultValue = {
  sqlId?: string(name='sqlId', description='The SQL ID.', example='ad78a4e7d3ce81590c9dc2d5f4bc****'),
  instanceId?: string(name='instanceId', description='The instance ID.', example='rm-2ze8g2am97624****'),
  count?: int32(name='count', description='The number of failed executions.', example='1'),
}

model DataSessionStatClientStatsValue = {
  activeCount?: long(name='ActiveCount', description='The number of clients whose IP addresses are active.', example='0'),
  totalCount?: long(name='TotalCount', description='The total number of IP addresses of clients.', example='11'),
}

model DataSessionStatDbStatsValue = {
  activeCount?: long(name='ActiveCount', description='The number of active namespaces.', example='0'),
  totalCount?: long(name='TotalCount', description='The total number of namespaces.', example='11'),
}

model DataValue = {
  timestamp?: string(name='Timestamp', description='The timestamp. This value is a UNIX timestamp representing the number of milliseconds that have elapsed since January 1, 1970, 00:00:00 UTC.', example='1681975870000'),
  value?: any(name='Value', description='The value of the metric.', example='478.28'),
}

