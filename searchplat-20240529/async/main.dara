/**
  *
  */
import BaseClientBuilder;
import TeaAsyncHandler;
import TeaRequest;
import AsyncRequestBody;
import RequestBody;
import AsyncResponseHandler;
import ClientConfiguration;
import ClientExecutionParams;
extends BaseClientBuilder;
type @product = string
type @version = string
type @endpointRule = string
type @endpointMap = map[string]string
type @REQUEST = TeaRequest
type @handler = TeaAsyncHandler

init(configuration: ClientConfiguration){
  @handler = new TeaAsyncHandler(configuration);
  @product = 'Searchplat';
  @version = '2024-05-29';
  @endpointRule = '';
  @endpointMap = {
  };
}

function close(): void {
  @handler.close();
}

model CreateDocumentAnalyzeTaskRequest {
  workspaceName: string(name='workspace_name', description='This parameter is required.', position='Path'),
  serviceId: string(name='service_id', description='This parameter is required.', position='Path'),
  document?: {
    content?: string(name='content'),
    fileName?: string(name='file_name'),
    fileType?: string(name='file_type'),
    url?: string(name='url'),
  }(name='document', position='Body'),
  output?: {
    imageStorage?: string(name='image_storage'),
  }(name='output', position='Body'),
  strategy?: {
    enableSemantic?: boolean(name='enable_semantic'),
  }(name='strategy', position='Body'),
}

model CreateDocumentAnalyzeTaskResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    taskId?: string(name='task_id'),
  }(name='result'),
}

model CreateDocumentAnalyzeTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDocumentAnalyzeTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateDocumentAnalyzeTask  CreateDocumentAnalyzeTaskRequest
  * @return CreateDocumentAnalyzeTaskResponse
 */
async function createDocumentAnalyzeTask(request: CreateDocumentAnalyzeTaskRequest): CreateDocumentAnalyzeTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'CreateDocumentAnalyzeTask', 'POST', '/v3/openapi/workspaces/{workspace_name}/document-analyze/{service_id}/async', 'json', false, 'json', request);
}

model CreateImageAnalyzeTaskRequest {
  workspaceName: string(name='workspace_name', description='This parameter is required.', position='Path'),
  serviceId: string(name='service_id', description='This parameter is required.', position='Path'),
  document?: {
    content?: string(name='content'),
    fileName?: string(name='file_name'),
    fileType?: string(name='file_type'),
    url?: string(name='url'),
  }(name='document', position='Body'),
}

model CreateImageAnalyzeTaskResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    taskId?: string(name='task_id'),
  }(name='result'),
}

model CreateImageAnalyzeTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateImageAnalyzeTaskResponseBody(name='body'),
}

/**
  * @param request  the request parameters of CreateImageAnalyzeTask  CreateImageAnalyzeTaskRequest
  * @return CreateImageAnalyzeTaskResponse
 */
async function createImageAnalyzeTask(request: CreateImageAnalyzeTaskRequest): CreateImageAnalyzeTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'CreateImageAnalyzeTask', 'POST', '/v3/openapi/workspaces/{workspace_name}/image-analyze/{service_id}/async', 'json', false, 'json', request);
}

model GetDocumentAnalyzeTaskStatusRequest {
  workspaceName: string(name='workspace_name', description='This parameter is required.', position='Path'),
  serviceId: string(name='service_id', description='This parameter is required.', position='Path'),
  taskId: string(name='task_id', description='This parameter is required.', position='Query'),
}

model GetDocumentAnalyzeTaskStatusResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    data?: {
      content?: string(name='content'),
      contentType?: string(name='content_type'),
      pageNum?: int32(name='page_num'),
    }(name='data'),
    error?: string(name='error'),
    status?: string(name='status'),
    taskId?: string(name='task_id'),
  }(name='result'),
  usage?: {
    imageCount?: long(name='image_count'),
    tableCount?: long(name='table_count'),
    tokenCount?: long(name='token_count'),
  }(name='usage'),
}

model GetDocumentAnalyzeTaskStatusResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDocumentAnalyzeTaskStatusResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDocumentAnalyzeTaskStatus  GetDocumentAnalyzeTaskStatusRequest
  * @return GetDocumentAnalyzeTaskStatusResponse
 */
async function getDocumentAnalyzeTaskStatus(request: GetDocumentAnalyzeTaskStatusRequest): GetDocumentAnalyzeTaskStatusResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetDocumentAnalyzeTaskStatus', 'GET', '/v3/openapi/workspaces/{workspace_name}/document-analyze/{service_id}/async/task-status', 'json', false, 'json', request);
}

model GetDocumentRankRequest {
  workspaceName: string(name='workspace_name', description='This parameter is required.', position='Path'),
  serviceId: string(name='service_id', description='This parameter is required.', position='Path'),
  docs: [ string ](name='docs', description='This parameter is required.', position='Body'),
  query: string(name='query', description='This parameter is required.', position='Body'),
}

model GetDocumentRankResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    scores?: [ 
      {
        index?: int32(name='index'),
        score?: double(name='score'),
      }
    ](name='scores'),
  }(name='result'),
  usage?: {
    docCount?: long(name='doc_count'),
  }(name='usage'),
}

model GetDocumentRankResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDocumentRankResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDocumentRank  GetDocumentRankRequest
  * @return GetDocumentRankResponse
 */
async function getDocumentRank(request: GetDocumentRankRequest): GetDocumentRankResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetDocumentRank', 'POST', '/v3/openapi/workspaces/{workspace_name}/ranker/{service_id}', 'json', false, 'json', request);
}

model GetDocumentSplitRequest {
  workspaceName: string(name='workspace_name', description='This parameter is required.', position='Path'),
  serviceId: string(name='service_id', description='This parameter is required.', position='Path'),
  document: {
    content?: string(name='content'),
    contentEncoding?: string(name='content_encoding'),
    contentType?: string(name='content_type'),
  }(name='document', description='This parameter is required.', position='Body'),
  strategy?: {
    computeType?: string(name='compute_type'),
    maxChunkSize?: long(name='max_chunk_size'),
    needSentence?: boolean(name='need_sentence'),
  }(name='strategy', position='Body'),
}

model GetDocumentSplitResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    chunks?: [ 
      {
        content?: string(name='content'),
        meta?: map[string]string(name='meta'),
      }
    ](name='chunks'),
    nodes?: [ map[string]string ](name='nodes'),
    richTexts?: [ 
      {
        content?: string(name='content'),
        meta?: map[string]string(name='meta'),
      }
    ](name='rich_texts'),
    sentences?: [ 
      {
        content?: string(name='content'),
        meta?: map[string]string(name='meta'),
      }
    ](name='sentences'),
  }(name='result'),
  usage?: {
    tokenCount?: long(name='token_count'),
  }(name='usage'),
}

model GetDocumentSplitResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDocumentSplitResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetDocumentSplit  GetDocumentSplitRequest
  * @return GetDocumentSplitResponse
 */
async function getDocumentSplit(request: GetDocumentSplitRequest): GetDocumentSplitResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetDocumentSplit', 'POST', '/v3/openapi/workspaces/{workspace_name}/document-split/{service_id}', 'json', false, 'json', request);
}

model GetEmbeddingTuningRequest {
  workspaceName?: string(name='workspace_name', position='Path'),
  serviceId?: string(name='service_id', position='Path'),
  input?: [[ float ]  ](name='input', position='Body'),
  parameters?: map[string]any(name='parameters', position='Body'),
}

model GetEmbeddingTuningResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    output?: [[ float ]    ](name='output'),
  }(name='result'),
  usage?: {
    docCount?: int32(name='doc_count'),
  }(name='usage'),
}

model GetEmbeddingTuningResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetEmbeddingTuningResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetEmbeddingTuning  GetEmbeddingTuningRequest
  * @return GetEmbeddingTuningResponse
 */
async function getEmbeddingTuning(request: GetEmbeddingTuningRequest): GetEmbeddingTuningResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetEmbeddingTuning', 'POST', '/v3/openapi/workspaces/{workspace_name}/embedding-tuning/{service_id}', 'json', false, 'json', request);
}

model GetImageAnalyzeTaskStatusRequest {
  workspaceName: string(name='workspace_name', description='This parameter is required.', position='Path'),
  serviceId: string(name='service_id', description='This parameter is required.', position='Path'),
  taskId: string(name='task_id', description='This parameter is required.', position='Query'),
}

model GetImageAnalyzeTaskStatusResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    data?: {
      content?: string(name='content'),
      contentType?: string(name='content_type'),
      pageNum?: int32(name='page_num'),
    }(name='data'),
    error?: string(name='error'),
    status?: string(name='status'),
    taskId?: string(name='task_id'),
  }(name='result'),
  usage?: {
    pvCount?: long(name='pv_count'),
    tokenCount?: long(name='token_count'),
  }(name='usage'),
}

model GetImageAnalyzeTaskStatusResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetImageAnalyzeTaskStatusResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetImageAnalyzeTaskStatus  GetImageAnalyzeTaskStatusRequest
  * @return GetImageAnalyzeTaskStatusResponse
 */
async function getImageAnalyzeTaskStatus(request: GetImageAnalyzeTaskStatusRequest): GetImageAnalyzeTaskStatusResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetImageAnalyzeTaskStatus', 'GET', '/v3/openapi/workspaces/{workspace_name}/image-analyze/{service_id}/async/task-status', 'json', false, 'json', request);
}

model GetMultiModalEmbeddingRequest {
  workspaceName: string(name='workspace_name', description='This parameter is required.', position='Path'),
  serviceId: string(name='service_id', description='This parameter is required.', position='Path'),
  input?: [ 
    {
      image?: string(name='image'),
      text?: string(name='text'),
    }
  ](name='input', position='Body'),
}

model GetMultiModalEmbeddingResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    embeddings?: [ 
      {
        embedding?: [ double ](name='embedding'),
        index?: long(name='index'),
      }
    ](name='embeddings'),
  }(name='result'),
  usage?: {
    image?: long(name='image'),
    tokenCount?: long(name='token_count'),
  }(name='usage'),
}

model GetMultiModalEmbeddingResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetMultiModalEmbeddingResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetMultiModalEmbedding  GetMultiModalEmbeddingRequest
  * @return GetMultiModalEmbeddingResponse
 */
async function getMultiModalEmbedding(request: GetMultiModalEmbeddingRequest): GetMultiModalEmbeddingResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetMultiModalEmbedding', 'POST', '/v3/openapi/workspaces/{workspace_name}/multi-modal-embedding/{service_id}', 'json', false, 'json', request);
}

model GetPredictionRequest {
  deploymentId: string(name='deployment_id', description='This parameter is required.', position='Path'),
  token?: string(name='Token', position='Header'),
  body?: string(name='body', position='Body'),
}

model GetPredictionResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: string(name='body'),
}

/**
  * @param request  the request parameters of GetPrediction  GetPredictionRequest
  * @return GetPredictionResponse
 */
async function getPrediction(request: GetPredictionRequest): GetPredictionResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetPrediction', 'POST', '/v3/openapi/deployments/{deployment_id}/predict', 'string', false, 'json', request);
}

model GetQueryAnalysisRequest {
  workspaceName: string(name='workspace_name', description='This parameter is required.', position='Path'),
  serviceId: string(name='service_id', description='This parameter is required.', position='Path'),
  functions?: [ 
    {
      name?: string(name='name'),
      parameters?: map[string]any(name='parameters'),
    }
  ](name='functions', position='Body'),
  history?: [ 
    {
      content?: string(name='content'),
      role?: string(name='role'),
    }
  ](name='history', position='Body'),
  query: string(name='query', description='This parameter is required.', position='Body'),
}

model GetQueryAnalysisResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    intent?: string(name='intent'),
    queries?: [ string ](name='queries'),
    query?: string(name='query'),
    sql?: map[string]any(name='sql'),
  }(name='result'),
  usage?: {
    inputTokens?: long(name='input_tokens'),
    outputTokens?: long(name='output_tokens'),
    totalTokens?: long(name='total_tokens'),
  }(name='usage'),
}

model GetQueryAnalysisResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetQueryAnalysisResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetQueryAnalysis  GetQueryAnalysisRequest
  * @return GetQueryAnalysisResponse
 */
async function getQueryAnalysis(request: GetQueryAnalysisRequest): GetQueryAnalysisResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetQueryAnalysis', 'POST', '/v3/openapi/workspaces/{workspace_name}/query-analyze/{service_id}', 'json', false, 'json', request);
}

model GetTextEmbeddingRequest {
  workspaceName: string(name='workspace_name', description='This parameter is required.', position='Path'),
  serviceId: string(name='service_id', description='This parameter is required.', position='Path'),
  input: [ string ](name='input', description='This parameter is required.', position='Body'),
  inputType?: string(name='input_type', example='document', position='Body'),
}

model GetTextEmbeddingResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    embeddings?: [ 
      {
        embedding?: [ double ](name='embedding'),
        index?: int32(name='index'),
      }
    ](name='embeddings'),
  }(name='result'),
  usage?: {
    tokenCount?: long(name='token_count'),
  }(name='usage'),
}

model GetTextEmbeddingResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTextEmbeddingResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTextEmbedding  GetTextEmbeddingRequest
  * @return GetTextEmbeddingResponse
 */
async function getTextEmbedding(request: GetTextEmbeddingRequest): GetTextEmbeddingResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetTextEmbedding', 'POST', '/v3/openapi/workspaces/{workspace_name}/text-embedding/{service_id}', 'json', false, 'json', request);
}

model GetTextGenerationRequest {
  workspaceName: string(name='workspace_name', description='This parameter is required.', position='Path'),
  serviceId: string(name='service_id', description='This parameter is required.', position='Path'),
  csiLevel?: string(name='csi_level', position='Body'),
  enableSearch?: boolean(name='enable_search', position='Body'),
  messages: [ 
    {
      content?: string(name='content'),
      role?: string(name='role'),
    }
  ](name='messages', description='This parameter is required.', position='Body'),
  parameters?: map[string]any(name='parameters', position='Body'),
  stream?: boolean(name='stream', position='Body'),
}

model GetTextGenerationResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    searchResults?: [ 
      {
        title?: string(name='title'),
        url?: string(name='url'),
      }
    ](name='search_results'),
    text?: string(name='text'),
  }(name='result'),
  usage?: {
    inputTokens?: long(name='input_tokens'),
    outputTokens?: long(name='output_tokens'),
    totalTokens?: long(name='total_tokens'),
  }(name='usage'),
}

model GetTextGenerationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTextGenerationResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTextGeneration  GetTextGenerationRequest
  * @return GetTextGenerationResponse
 */
async function getTextGeneration(request: GetTextGenerationRequest): GetTextGenerationResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetTextGeneration', 'POST', '/v3/openapi/workspaces/{workspace_name}/text-generation/{service_id}', 'json', false, 'json', request);
}

model GetTextSparseEmbeddingRequest {
  workspaceName: string(name='workspace_name', description='This parameter is required.', position='Path'),
  serviceId: string(name='service_id', description='This parameter is required.', position='Path'),
  input: [ string ](name='input', description='This parameter is required.', position='Body'),
  inputType?: string(name='input_type', example='document', position='Body'),
  returnToken?: boolean(name='return_token', position='Body'),
}

model GetTextSparseEmbeddingResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    sparseEmbeddings?: [ 
      {
        embedding?: [ 
          {
            token?: string(name='token'),
            tokenId?: int32(name='token_id'),
            weight?: float(name='weight'),
          }
        ](name='embedding'),
        index?: int32(name='index'),
      }
    ](name='sparse_embeddings'),
  }(name='result'),
  usage?: {
    tokenCount?: long(name='token_count'),
  }(name='usage'),
}

model GetTextSparseEmbeddingResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTextSparseEmbeddingResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetTextSparseEmbedding  GetTextSparseEmbeddingRequest
  * @return GetTextSparseEmbeddingResponse
 */
async function getTextSparseEmbedding(request: GetTextSparseEmbeddingRequest): GetTextSparseEmbeddingResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetTextSparseEmbedding', 'POST', '/v3/openapi/workspaces/{workspace_name}/text-sparse-embedding/{service_id}', 'json', false, 'json', request);
}

model GetWebSearchRequest {
  workspaceName: string(name='workspace_name', description='This parameter is required.', position='Path'),
  serviceId: string(name='service_id', description='This parameter is required.', position='Path'),
  query: string(name='query', description='This parameter is required.', position='Body'),
  topK?: long(name='top_k', position='Body'),
  way?: string(name='way', position='Body'),
}

model GetWebSearchResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    searchResult?: [ 
      {
        content?: string(name='content'),
        link?: string(name='link'),
        position?: long(name='position'),
        snippet?: string(name='snippet'),
        tilte?: string(name='tilte'),
      }
    ](name='search_result'),
  }(name='result'),
  usage?: {
    filter_model_input_tokens?: long(name='filter_model.input_tokens'),
    filter_model_output_tokens?: long(name='filter_model.output_tokens'),
    filter_model_total_tokens?: long(name='filter_model.total_tokens'),
    rewrite_model_input_tokens?: long(name='rewrite_model.input_tokens'),
    rewrite_model_output_tokens?: long(name='rewrite_model.output_tokens'),
    rewrite_model_total_tokens?: long(name='rewrite_model.total_tokens'),
    searchCount?: long(name='search_count'),
  }(name='usage'),
}

model GetWebSearchResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetWebSearchResponseBody(name='body'),
}

/**
  * @param request  the request parameters of GetWebSearch  GetWebSearchRequest
  * @return GetWebSearchResponse
 */
async function getWebSearch(request: GetWebSearchRequest): GetWebSearchResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetWebSearch', 'POST', '/v3/openapi/workspaces/{workspace_name}/web-search/{service_id}', 'json', false, 'json', request);
}

