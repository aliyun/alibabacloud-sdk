/**
 *
 */
import BaseClientBuilder;
import TeaAsyncHandler;
import TeaRequest;
import AsyncRequestBody;
import RequestBody;
import AsyncResponseHandler;
import ClientConfiguration;
import ClientExecutionParams;
extends BaseClientBuilder;
type @product = string
type @version = string
type @endpointRule = string
type @endpointMap = map[string]string
type @REQUEST = TeaRequest
type @handler = TeaAsyncHandler

init(configuration: ClientConfiguration){
  @handler = new TeaAsyncHandler(configuration);
  @product = 'Searchplat';
  @version = '2024-05-29';
  @endpointRule = '';
  @endpointMap = {
  };
}

function close(): void {
  @handler.close();
}

model CreateDocumentAnalyzeTaskRequest {
  workspaceName: string(name='workspace_name', position='Path'),
  serviceId: string(name='service_id', position='Path'),
  document?: {
    content?: string(name='content'),
    fileName?: string(name='file_name'),
    fileType?: string(name='file_type'),
    url?: string(name='url'),
  }(name='document', position='Body'),
  output?: {
    imageStorage?: string(name='image_storage'),
  }(name='output', position='Body'),
}

model CreateDocumentAnalyzeTaskResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    taskId?: string(name='task_id'),
  }(name='result'),
}

model CreateDocumentAnalyzeTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateDocumentAnalyzeTaskResponseBody(name='body'),
}

async function createDocumentAnalyzeTask(request: CreateDocumentAnalyzeTaskRequest): CreateDocumentAnalyzeTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'CreateDocumentAnalyzeTask', 'POST', '/v3/openapi/workspaces/{workspace_name}/document-analyze/{service_id}/async', 'json', false, 'json', request);
}

model CreateImageAnalyzeTaskRequest {
  workspaceName: string(name='workspace_name', position='Path'),
  serviceId: string(name='service_id', position='Path'),
  document?: {
    content?: string(name='content'),
    fileName?: string(name='file_name'),
    fileType?: string(name='file_type'),
    url?: string(name='url'),
  }(name='document', position='Body'),
}

model CreateImageAnalyzeTaskResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    taskId?: string(name='task_id'),
  }(name='result'),
}

model CreateImageAnalyzeTaskResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: CreateImageAnalyzeTaskResponseBody(name='body'),
}

async function createImageAnalyzeTask(request: CreateImageAnalyzeTaskRequest): CreateImageAnalyzeTaskResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'CreateImageAnalyzeTask', 'POST', '/v3/openapi/workspaces/{workspace_name}/image-analyze/{service_id}/async', 'json', false, 'json', request);
}

model GetDocumentAnalyzeTaskStatusRequest {
  workspaceName: string(name='workspace_name', position='Path'),
  serviceId: string(name='service_id', position='Path'),
  taskId: string(name='task_id', position='Query'),
}

model GetDocumentAnalyzeTaskStatusResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    data?: {
      content?: string(name='content'),
      contentType?: string(name='content_type'),
      pageNum?: int32(name='page_num'),
    }(name='data'),
    error?: string(name='error'),
    status?: string(name='status'),
    taskId?: string(name='task_id'),
  }(name='result'),
  usage?: {
    imageCount?: long(name='image_count'),
    tableCount?: long(name='table_count'),
    tokenCount?: long(name='token_count'),
  }(name='usage'),
}

model GetDocumentAnalyzeTaskStatusResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDocumentAnalyzeTaskStatusResponseBody(name='body'),
}

async function getDocumentAnalyzeTaskStatus(request: GetDocumentAnalyzeTaskStatusRequest): GetDocumentAnalyzeTaskStatusResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetDocumentAnalyzeTaskStatus', 'GET', '/v3/openapi/workspaces/{workspace_name}/document-analyze/{service_id}/async/task-status', 'json', false, 'json', request);
}

model GetDocumentRankRequest {
  workspaceName: string(name='workspace_name', position='Path'),
  serviceId: string(name='service_id', position='Path'),
  docs: [ string ](name='docs', position='Body'),
  query: string(name='query', position='Body'),
}

model GetDocumentRankResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    scores?: [ 
      {
        index?: int32(name='index'),
        score?: double(name='score'),
      }
    ](name='scores'),
  }(name='result'),
  usage?: {
    docCount?: long(name='doc_count'),
  }(name='usage'),
}

model GetDocumentRankResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDocumentRankResponseBody(name='body'),
}

async function getDocumentRank(request: GetDocumentRankRequest): GetDocumentRankResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetDocumentRank', 'POST', '/v3/openapi/workspaces/{workspace_name}/ranker/{service_id}', 'json', false, 'json', request);
}

model GetDocumentSplitRequest {
  workspaceName: string(name='workspace_name', position='Path'),
  serviceId: string(name='service_id', position='Path'),
  document: {
    content?: string(name='content'),
    contentEncoding?: string(name='content_encoding'),
    contentType?: string(name='content_type'),
  }(name='document', position='Body'),
  strategy?: {
    computeType?: string(name='compute_type'),
    maxChunkSize?: long(name='max_chunk_size'),
    needSentence?: boolean(name='need_sentence'),
  }(name='strategy', position='Body'),
}

model GetDocumentSplitResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    chunks?: [ 
      {
        content?: string(name='content'),
        meta?: map[string]string(name='meta'),
      }
    ](name='chunks'),
    nodes?: [ map[string]string ](name='nodes'),
    richTexts?: [ 
      {
        content?: string(name='content'),
        meta?: map[string]string(name='meta'),
      }
    ](name='rich_texts'),
    sentences?: [ 
      {
        content?: string(name='content'),
        meta?: map[string]string(name='meta'),
      }
    ](name='sentences'),
  }(name='result'),
  usage?: {
    tokenCount?: long(name='token_count'),
  }(name='usage'),
}

model GetDocumentSplitResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetDocumentSplitResponseBody(name='body'),
}

async function getDocumentSplit(request: GetDocumentSplitRequest): GetDocumentSplitResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetDocumentSplit', 'POST', '/v3/openapi/workspaces/{workspace_name}/document-split/{service_id}', 'json', false, 'json', request);
}

model GetImageAnalyzeTaskStatusRequest {
  workspaceName: string(name='workspace_name', position='Path'),
  serviceId: string(name='service_id', position='Path'),
  taskId: string(name='task_id', position='Query'),
}

model GetImageAnalyzeTaskStatusResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    data?: {
      content?: string(name='content'),
      contentType?: string(name='content_type'),
      pageNum?: int32(name='page_num'),
    }(name='data'),
    error?: string(name='error'),
    status?: string(name='status'),
    taskId?: string(name='task_id'),
  }(name='result'),
  usage?: {
    pvCount?: long(name='pv_count'),
    tokenCount?: long(name='token_count'),
  }(name='usage'),
}

model GetImageAnalyzeTaskStatusResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetImageAnalyzeTaskStatusResponseBody(name='body'),
}

async function getImageAnalyzeTaskStatus(request: GetImageAnalyzeTaskStatusRequest): GetImageAnalyzeTaskStatusResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetImageAnalyzeTaskStatus', 'GET', '/v3/openapi/workspaces/{workspace_name}/image-analyze/{service_id}/async/task-status', 'json', false, 'json', request);
}

model GetQueryAnalysisRequest {
  workspaceName: string(name='workspace_name', position='Path'),
  serviceId: string(name='service_id', position='Path'),
  functions?: [ 
    {
      name?: string(name='name'),
      parameters?: map[string]any(name='parameters'),
    }
  ](name='functions', position='Body'),
  history?: [ 
    {
      content?: string(name='content'),
      role?: string(name='role'),
    }
  ](name='history', position='Body'),
  query: string(name='query', position='Body'),
}

model GetQueryAnalysisResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    intent?: string(name='intent'),
    queries?: [ string ](name='queries'),
    query?: string(name='query'),
    sql?: map[string]any(name='sql'),
  }(name='result'),
  usage?: {
    inputTokens?: long(name='input_tokens'),
    outputTokens?: long(name='output_tokens'),
    totalTokens?: long(name='total_tokens'),
  }(name='usage'),
}

model GetQueryAnalysisResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetQueryAnalysisResponseBody(name='body'),
}

async function getQueryAnalysis(request: GetQueryAnalysisRequest): GetQueryAnalysisResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetQueryAnalysis', 'POST', '/v3/openapi/workspaces/{workspace_name}/query-analyze/{service_id}', 'json', false, 'json', request);
}

model GetTextEmbeddingRequest {
  workspaceName: string(name='workspace_name', position='Path'),
  serviceId: string(name='service_id', position='Path'),
  input: [ string ](name='input', position='Body'),
  inputType?: string(name='input_type', example='document', position='Body'),
}

model GetTextEmbeddingResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    embeddings?: [ 
      {
        embedding?: [ double ](name='embedding'),
        index?: int32(name='index'),
      }
    ](name='embeddings'),
  }(name='result'),
  usage?: {
    tokenCount?: long(name='token_count'),
  }(name='usage'),
}

model GetTextEmbeddingResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTextEmbeddingResponseBody(name='body'),
}

async function getTextEmbedding(request: GetTextEmbeddingRequest): GetTextEmbeddingResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetTextEmbedding', 'POST', '/v3/openapi/workspaces/{workspace_name}/text-embedding/{service_id}', 'json', false, 'json', request);
}

model GetTextGenerationRequest {
  workspaceName: string(name='workspace_name', position='Path'),
  serviceId: string(name='service_id', position='Path'),
  csiLevel?: string(name='csi_level', position='Body'),
  messages: [ 
    {
      content?: string(name='content'),
      role?: string(name='role'),
    }
  ](name='messages', position='Body'),
  parameters?: map[string]string(name='parameters', position='Body'),
  stream?: boolean(name='stream', position='Body'),
}

model GetTextGenerationResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    text?: string(name='text'),
  }(name='result'),
  usage?: {
    inputTokens?: long(name='input_tokens'),
    outputTokens?: long(name='output_tokens'),
    totalTokens?: long(name='total_tokens'),
  }(name='usage'),
}

model GetTextGenerationResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTextGenerationResponseBody(name='body'),
}

async function getTextGeneration(request: GetTextGenerationRequest): GetTextGenerationResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetTextGeneration', 'POST', '/v3/openapi/workspaces/{workspace_name}/text-generation/{service_id}', 'json', false, 'json', request);
}

model GetTextSparseEmbeddingRequest {
  workspaceName: string(name='workspace_name', position='Path'),
  serviceId: string(name='service_id', position='Path'),
  input: [ string ](name='input', position='Body'),
  inputType?: string(name='input_type', example='document', position='Body'),
  returnToken?: boolean(name='return_token', position='Body'),
}

model GetTextSparseEmbeddingResponseBody = {
  latency?: int32(name='latency'),
  requestId?: string(name='request_id'),
  result?: {
    sparseEmbeddings?: [ 
      {
        embedding?: [ 
          {
            token?: string(name='token'),
            tokenId?: int32(name='token_id'),
            weight?: float(name='weight'),
          }
        ](name='embedding'),
        index?: int32(name='index'),
      }
    ](name='sparse_embeddings'),
  }(name='result'),
  usage?: {
    tokenCount?: long(name='token_count'),
  }(name='usage'),
}

model GetTextSparseEmbeddingResponse = {
  headers?: map[string]string(name='headers'),
  statusCode?: int32(name='statusCode'),
  body?: GetTextSparseEmbeddingResponseBody(name='body'),
}

async function getTextSparseEmbedding(request: GetTextSparseEmbeddingRequest): GetTextSparseEmbeddingResponse {
  @handler.validateRequestModel(request);
  return @handler.do('RESTFUL', 'GetTextSparseEmbedding', 'POST', '/v3/openapi/workspaces/{workspace_name}/text-sparse-embedding/{service_id}', 'json', false, 'json', request);
}

